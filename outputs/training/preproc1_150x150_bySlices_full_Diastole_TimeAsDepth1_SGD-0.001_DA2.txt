nohup: ignoring input
Running experiment preproc1_150x150_bySlices_dataset_full_Diastole_TimeAsDepth_1_SGD-0.001_DA2
Going to train with the GPU in the slot 0 -> device model: GeForce GTX 1080
Model architecture:
 TimeAsDepth_1(
  (conv_block): Sequential(
    (0): Conv2d(30, 64, kernel_size=(3, 3), stride=(2, 2))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))
    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU()
    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (7): Dropout(p=0.4, inplace=False)
    (8): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))
    (9): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): ReLU()
    (11): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))
    (12): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (13): ReLU()
    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (15): Dropout(p=0.4, inplace=False)
    (16): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))
    (17): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): ReLU()
    (19): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))
    (20): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (21): ReLU()
    (22): Dropout(p=0.4, inplace=False)
    (23): AdaptiveAvgPool2d(output_size=(1, 1))
  )
  (flatten): Flatten()
  (dense_block): Sequential(
    (0): Linear(in_features=256, out_features=1024, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.4, inplace=False)
    (3): Linear(in_features=1024, out_features=1, bias=True)
  )
) 


############################
# TRAIN PHASE:  100 epochs #
############################

Epoch 0: 
Train batch 1/42 - 466.5ms/batch - loss: 255.01221 - diff: 170.87mlTrain batch 2/42 - 190.1ms/batch - loss: 259.16222 - diff: 168.38mlTrain batch 3/42 - 198.1ms/batch - loss: 182.85070 - diff: 129.06mlTrain batch 4/42 - 190.1ms/batch - loss: 315.28773 - diff: 162.50mlTrain batch 5/42 - 192.2ms/batch - loss: 302.72648 - diff: 163.69mlTrain batch 6/42 - 189.3ms/batch - loss: 290.92063 - diff: 163.57mlTrain batch 7/42 - 190.7ms/batch - loss: 280.47188 - diff: 162.78mlTrain batch 8/42 - 189.3ms/batch - loss: 273.75603 - diff: 162.55mlTrain batch 9/42 - 191.3ms/batch - loss: 261.43614 - diff: 158.95mlTrain batch 10/42 - 189.3ms/batch - loss: 274.14916 - diff: 158.41mlTrain batch 11/42 - 188.7ms/batch - loss: 273.81693 - diff: 159.90mlTrain batch 12/42 - 189.3ms/batch - loss: 280.08210 - diff: 160.06mlTrain batch 13/42 - 208.9ms/batch - loss: 274.29953 - diff: 159.28mlTrain batch 14/42 - 190.6ms/batch - loss: 263.29747 - diff: 155.10mlTrain batch 15/42 - 205.4ms/batch - loss: 258.29550 - diff: 152.33mlTrain batch 16/42 - 189.3ms/batch - loss: 255.07946 - diff: 151.71mlTrain batch 17/42 - 203.5ms/batch - loss: 250.77512 - diff: 150.74mlTrain batch 18/42 - 189.1ms/batch - loss: 245.82527 - diff: 149.52mlTrain batch 19/42 - 191.7ms/batch - loss: 241.78382 - diff: 148.25mlTrain batch 20/42 - 189.5ms/batch - loss: 234.66882 - diff: 145.39mlTrain batch 21/42 - 188.6ms/batch - loss: 228.18487 - diff: 142.39mlTrain batch 22/42 - 188.9ms/batch - loss: 222.77972 - diff: 139.87mlTrain batch 23/42 - 193.3ms/batch - loss: 215.76426 - diff: 136.65mlTrain batch 24/42 - 189.4ms/batch - loss: 209.59976 - diff: 133.75mlTrain batch 25/42 - 193.6ms/batch - loss: 203.48204 - diff: 131.08mlTrain batch 26/42 - 188.5ms/batch - loss: 198.10153 - diff: 128.72mlTrain batch 27/42 - 194.0ms/batch - loss: 192.11137 - diff: 125.95mlTrain batch 28/42 - 188.8ms/batch - loss: 187.16133 - diff: 123.56mlTrain batch 29/42 - 194.7ms/batch - loss: 183.55855 - diff: 121.89mlTrain batch 30/42 - 191.5ms/batch - loss: 178.61007 - diff: 119.50mlTrain batch 31/42 - 190.1ms/batch - loss: 174.06177 - diff: 117.38mlTrain batch 32/42 - 190.5ms/batch - loss: 169.61911 - diff: 115.27mlTrain batch 33/42 - 190.4ms/batch - loss: 166.28512 - diff: 113.72mlTrain batch 34/42 - 189.4ms/batch - loss: 162.57826 - diff: 112.00mlTrain batch 35/42 - 193.8ms/batch - loss: 158.85780 - diff: 110.23mlTrain batch 36/42 - 190.5ms/batch - loss: 155.20156 - diff: 108.41mlTrain batch 37/42 - 189.9ms/batch - loss: 152.18474 - diff: 106.95mlTrain batch 38/42 - 191.6ms/batch - loss: 149.07379 - diff: 105.40mlTrain batch 39/42 - 191.4ms/batch - loss: 146.30283 - diff: 104.14mlTrain batch 40/42 - 189.4ms/batch - loss: 143.50656 - diff: 102.86mlTrain batch 41/42 - 189.8ms/batch - loss: 140.99402 - diff: 101.58mlTrain batch 42/42 - 133.9ms/batch - loss: 139.60798 - diff: 100.80mlTrain batch 42/42 - 235.9s 133.9ms/batch - loss: 139.60798 - diff: 100.80ml
Test 130.7s: val_loss: 31914.26667 - diff: 1781.89ml
Saving new best model in models/checkpoints/preproc1_150x150_bySlices_dataset_full_Diastole_TimeAsDepth_1_SGD-0.001_DA2_best

Epoch 1: current best loss = 31914.26667, at epoch 0
Train batch 1/42 - 190.2ms/batch - loss: 36.17722 - diff: 54.05mlTrain batch 2/42 - 189.3ms/batch - loss: 39.63137 - diff: 55.62mlTrain batch 3/42 - 209.9ms/batch - loss: 35.88212 - diff: 52.31mlTrain batch 4/42 - 190.8ms/batch - loss: 35.27045 - diff: 52.37mlTrain batch 5/42 - 197.4ms/batch - loss: 33.78248 - diff: 50.93mlTrain batch 6/42 - 191.7ms/batch - loss: 34.46528 - diff: 51.76mlTrain batch 7/42 - 189.0ms/batch - loss: 36.76277 - diff: 52.62mlTrain batch 8/42 - 192.6ms/batch - loss: 35.89672 - diff: 52.20mlTrain batch 9/42 - 198.3ms/batch - loss: 36.75132 - diff: 52.11mlTrain batch 10/42 - 191.9ms/batch - loss: 37.40745 - diff: 52.23mlTrain batch 11/42 - 190.3ms/batch - loss: 36.62898 - diff: 51.93mlTrain batch 12/42 - 191.9ms/batch - loss: 36.27076 - diff: 51.88mlTrain batch 13/42 - 188.8ms/batch - loss: 35.32337 - diff: 51.37mlTrain batch 14/42 - 194.2ms/batch - loss: 35.59778 - diff: 51.61mlTrain batch 15/42 - 196.4ms/batch - loss: 35.34643 - diff: 51.33mlTrain batch 16/42 - 188.6ms/batch - loss: 34.60953 - diff: 50.88mlTrain batch 17/42 - 197.5ms/batch - loss: 34.51846 - diff: 50.92mlTrain batch 18/42 - 189.0ms/batch - loss: 34.05909 - diff: 50.75mlTrain batch 19/42 - 236.8ms/batch - loss: 33.92792 - diff: 50.64mlTrain batch 20/42 - 184.5ms/batch - loss: 34.07541 - diff: 50.67mlTrain batch 21/42 - 187.4ms/batch - loss: 33.64256 - diff: 50.40mlTrain batch 22/42 - 183.5ms/batch - loss: 34.17490 - diff: 50.34mlTrain batch 23/42 - 201.4ms/batch - loss: 34.03659 - diff: 50.26mlTrain batch 24/42 - 184.1ms/batch - loss: 34.00547 - diff: 50.22mlTrain batch 25/42 - 187.3ms/batch - loss: 34.35774 - diff: 50.33mlTrain batch 26/42 - 183.6ms/batch - loss: 34.62282 - diff: 50.37mlTrain batch 27/42 - 184.4ms/batch - loss: 35.06199 - diff: 50.61mlTrain batch 28/42 - 182.7ms/batch - loss: 35.30924 - diff: 50.76mlTrain batch 29/42 - 188.9ms/batch - loss: 35.16665 - diff: 50.51mlTrain batch 30/42 - 184.6ms/batch - loss: 34.99290 - diff: 50.44mlTrain batch 31/42 - 182.3ms/batch - loss: 35.19408 - diff: 50.47mlTrain batch 32/42 - 184.1ms/batch - loss: 34.86320 - diff: 50.24mlTrain batch 33/42 - 183.4ms/batch - loss: 34.94207 - diff: 50.34mlTrain batch 34/42 - 183.1ms/batch - loss: 34.81209 - diff: 50.31mlTrain batch 35/42 - 207.1ms/batch - loss: 34.75381 - diff: 50.26mlTrain batch 36/42 - 184.8ms/batch - loss: 34.79351 - diff: 50.15mlTrain batch 37/42 - 182.8ms/batch - loss: 34.64841 - diff: 50.04mlTrain batch 38/42 - 183.7ms/batch - loss: 34.65518 - diff: 50.00mlTrain batch 39/42 - 183.3ms/batch - loss: 34.56905 - diff: 50.02mlTrain batch 40/42 - 184.2ms/batch - loss: 34.29754 - diff: 49.92mlTrain batch 41/42 - 188.9ms/batch - loss: 34.18583 - diff: 49.84mlTrain batch 42/42 - 129.4ms/batch - loss: 34.83242 - diff: 49.87mlTrain batch 42/42 - 349.4s 129.4ms/batch - loss: 34.83242 - diff: 49.87ml
Test 133.1s: val_loss: 27.65814 - diff: 45.94ml
Saving new best model in models/checkpoints/preproc1_150x150_bySlices_dataset_full_Diastole_TimeAsDepth_1_SGD-0.001_DA2_best

Epoch 2: current best loss = 27.65814, at epoch 1
Train batch 1/42 - 189.2ms/batch - loss: 23.38547 - diff: 42.78mlTrain batch 2/42 - 184.8ms/batch - loss: 26.25590 - diff: 46.02mlTrain batch 3/42 - 188.9ms/batch - loss: 27.74645 - diff: 47.18mlTrain batch 4/42 - 184.3ms/batch - loss: 26.55565 - diff: 46.04mlTrain batch 5/42 - 182.7ms/batch - loss: 28.73976 - diff: 46.14mlTrain batch 6/42 - 183.2ms/batch - loss: 28.03008 - diff: 45.57mlTrain batch 7/42 - 191.6ms/batch - loss: 27.44564 - diff: 45.39mlTrain batch 8/42 - 183.6ms/batch - loss: 28.01125 - diff: 46.27mlTrain batch 9/42 - 189.6ms/batch - loss: 28.89791 - diff: 46.34mlTrain batch 10/42 - 184.9ms/batch - loss: 29.11398 - diff: 46.35mlTrain batch 11/42 - 183.7ms/batch - loss: 28.30674 - diff: 45.84mlTrain batch 12/42 - 184.4ms/batch - loss: 29.68208 - diff: 46.47mlTrain batch 13/42 - 183.5ms/batch - loss: 30.31396 - diff: 46.64mlTrain batch 14/42 - 183.4ms/batch - loss: 30.24240 - diff: 46.64mlTrain batch 15/42 - 189.6ms/batch - loss: 30.96251 - diff: 46.65mlTrain batch 16/42 - 184.7ms/batch - loss: 31.66236 - diff: 46.98mlTrain batch 17/42 - 183.0ms/batch - loss: 32.03104 - diff: 47.33mlTrain batch 18/42 - 182.7ms/batch - loss: 31.84106 - diff: 47.28mlTrain batch 19/42 - 196.4ms/batch - loss: 31.56531 - diff: 47.09mlTrain batch 20/42 - 184.2ms/batch - loss: 32.15883 - diff: 47.45mlTrain batch 21/42 - 188.0ms/batch - loss: 31.97722 - diff: 47.39mlTrain batch 22/42 - 182.8ms/batch - loss: 31.97267 - diff: 47.59mlTrain batch 23/42 - 212.3ms/batch - loss: 32.16591 - diff: 47.72mlTrain batch 24/42 - 182.5ms/batch - loss: 32.76225 - diff: 47.83mlTrain batch 25/42 - 185.6ms/batch - loss: 32.98045 - diff: 48.00mlTrain batch 26/42 - 182.7ms/batch - loss: 33.17136 - diff: 48.20mlTrain batch 27/42 - 183.2ms/batch - loss: 33.58528 - diff: 48.39mlTrain batch 28/42 - 188.2ms/batch - loss: 33.48613 - diff: 48.24mlTrain batch 29/42 - 185.4ms/batch - loss: 33.49380 - diff: 48.34mlTrain batch 30/42 - 182.6ms/batch - loss: 33.43512 - diff: 48.35mlTrain batch 31/42 - 182.7ms/batch - loss: 33.23986 - diff: 48.26mlTrain batch 32/42 - 185.4ms/batch - loss: 33.23342 - diff: 48.30mlTrain batch 33/42 - 183.3ms/batch - loss: 33.18345 - diff: 48.31mlTrain batch 34/42 - 189.4ms/batch - loss: 32.98041 - diff: 48.19mlTrain batch 35/42 - 185.6ms/batch - loss: 32.74497 - diff: 48.00mlTrain batch 36/42 - 183.4ms/batch - loss: 32.65937 - diff: 48.05mlTrain batch 37/42 - 183.4ms/batch - loss: 32.44202 - diff: 47.92mlTrain batch 38/42 - 184.1ms/batch - loss: 32.28000 - diff: 47.85mlTrain batch 39/42 - 184.0ms/batch - loss: 32.10829 - diff: 47.72mlTrain batch 40/42 - 182.9ms/batch - loss: 32.01482 - diff: 47.61mlTrain batch 41/42 - 188.7ms/batch - loss: 31.96854 - diff: 47.61mlTrain batch 42/42 - 128.5ms/batch - loss: 32.54172 - diff: 47.67mlTrain batch 42/42 - 350.0s 128.5ms/batch - loss: 32.54172 - diff: 47.67ml
Test 133.6s: val_loss: 25.84969 - diff: 43.26ml
Saving new best model in models/checkpoints/preproc1_150x150_bySlices_dataset_full_Diastole_TimeAsDepth_1_SGD-0.001_DA2_best

Epoch 3: current best loss = 25.84969, at epoch 2
Train batch 1/42 - 188.9ms/batch - loss: 24.21176 - diff: 41.42mlTrain batch 2/42 - 185.4ms/batch - loss: 24.53603 - diff: 43.72mlTrain batch 3/42 - 193.8ms/batch - loss: 30.75916 - diff: 45.82mlTrain batch 4/42 - 184.2ms/batch - loss: 30.28462 - diff: 45.95mlTrain batch 5/42 - 183.2ms/batch - loss: 34.88915 - diff: 47.97mlTrain batch 6/42 - 184.1ms/batch - loss: 35.56331 - diff: 48.45mlTrain batch 7/42 - 183.5ms/batch - loss: 35.16988 - diff: 49.16mlTrain batch 8/42 - 184.4ms/batch - loss: 35.53030 - diff: 48.88mlTrain batch 9/42 - 15806.6ms/batch - loss: 35.64663 - diff: 49.25mlTrain batch 10/42 - 185.7ms/batch - loss: 34.82032 - diff: 48.82mlTrain batch 11/42 - 184.0ms/batch - loss: 34.07631 - diff: 48.31mlTrain batch 12/42 - 183.7ms/batch - loss: 33.76263 - diff: 48.40mlTrain batch 13/42 - 182.8ms/batch - loss: 33.56804 - diff: 48.39mlTrain batch 14/42 - 182.7ms/batch - loss: 33.58513 - diff: 48.72mlTrain batch 15/42 - 190.4ms/batch - loss: 33.16325 - diff: 48.54mlTrain batch 16/42 - 182.4ms/batch - loss: 33.12898 - diff: 48.51mlTrain batch 17/42 - 185.7ms/batch - loss: 33.22717 - diff: 48.61mlTrain batch 18/42 - 185.5ms/batch - loss: 32.98935 - diff: 48.45mlTrain batch 19/42 - 199.8ms/batch - loss: 33.58899 - diff: 48.86mlTrain batch 20/42 - 182.7ms/batch - loss: 34.63948 - diff: 49.62mlTrain batch 21/42 - 192.2ms/batch - loss: 34.39232 - diff: 49.51mlTrain batch 22/42 - 182.9ms/batch - loss: 34.08703 - diff: 49.35mlTrain batch 23/42 - 199.4ms/batch - loss: 33.77173 - diff: 49.08mlTrain batch 24/42 - 183.2ms/batch - loss: 33.44862 - diff: 48.76mlTrain batch 25/42 - 183.5ms/batch - loss: 33.45994 - diff: 48.68mlTrain batch 26/42 - 183.4ms/batch - loss: 33.08094 - diff: 48.48mlTrain batch 27/42 - 183.2ms/batch - loss: 32.80736 - diff: 48.38mlTrain batch 28/42 - 183.7ms/batch - loss: 33.00562 - diff: 48.48mlTrain batch 29/42 - 187.9ms/batch - loss: 32.96790 - diff: 48.46mlTrain batch 30/42 - 184.5ms/batch - loss: 33.23030 - diff: 48.51mlTrain batch 31/42 - 183.1ms/batch - loss: 33.03694 - diff: 48.37mlTrain batch 32/42 - 183.1ms/batch - loss: 33.15904 - diff: 48.30mlTrain batch 33/42 - 183.5ms/batch - loss: 33.00114 - diff: 48.30mlTrain batch 34/42 - 182.8ms/batch - loss: 33.00648 - diff: 48.41mlTrain batch 35/42 - 188.4ms/batch - loss: 32.93229 - diff: 48.28mlTrain batch 36/42 - 184.8ms/batch - loss: 33.01676 - diff: 48.20mlTrain batch 37/42 - 182.6ms/batch - loss: 32.73642 - diff: 48.03mlTrain batch 38/42 - 183.0ms/batch - loss: 32.55502 - diff: 47.94mlTrain batch 39/42 - 182.6ms/batch - loss: 32.38641 - diff: 47.87mlTrain batch 40/42 - 182.7ms/batch - loss: 32.59496 - diff: 48.00mlTrain batch 41/42 - 188.7ms/batch - loss: 32.60289 - diff: 48.09mlTrain batch 42/42 - 130.1ms/batch - loss: 32.75767 - diff: 48.10mlTrain batch 42/42 - 352.1s 130.1ms/batch - loss: 32.75767 - diff: 48.10ml
Test 132.6s: val_loss: 31.52913 - diff: 49.08ml

Epoch 4: current best loss = 25.84969, at epoch 2
Train batch 1/42 - 189.7ms/batch - loss: 39.06131 - diff: 49.56mlTrain batch 2/42 - 184.2ms/batch - loss: 32.56322 - diff: 46.85mlTrain batch 3/42 - 188.8ms/batch - loss: 34.10935 - diff: 48.83mlTrain batch 4/42 - 184.7ms/batch - loss: 35.20341 - diff: 48.41mlTrain batch 5/42 - 183.3ms/batch - loss: 34.17402 - diff: 47.61mlTrain batch 6/42 - 184.7ms/batch - loss: 35.35106 - diff: 48.48mlTrain batch 7/42 - 202.1ms/batch - loss: 35.59824 - diff: 49.18mlTrain batch 8/42 - 185.5ms/batch - loss: 36.35783 - diff: 49.67mlTrain batch 9/42 - 191.8ms/batch - loss: 36.90496 - diff: 50.46mlTrain batch 10/42 - 185.1ms/batch - loss: 36.41543 - diff: 50.14mlTrain batch 11/42 - 183.3ms/batch - loss: 36.88731 - diff: 50.19mlTrain batch 12/42 - 185.7ms/batch - loss: 36.86321 - diff: 50.01mlTrain batch 13/42 - 182.6ms/batch - loss: 35.92799 - diff: 49.50mlTrain batch 14/42 - 187.0ms/batch - loss: 35.37289 - diff: 49.48mlTrain batch 15/42 - 198.2ms/batch - loss: 34.93253 - diff: 49.38mlTrain batch 16/42 - 184.3ms/batch - loss: 35.59674 - diff: 49.78mlTrain batch 17/42 - 192.9ms/batch - loss: 35.15618 - diff: 49.53mlTrain batch 18/42 - 183.3ms/batch - loss: 34.81086 - diff: 49.26mlTrain batch 19/42 - 190.8ms/batch - loss: 34.54922 - diff: 49.15mlTrain batch 20/42 - 188.4ms/batch - loss: 34.52796 - diff: 49.13mlTrain batch 21/42 - 194.0ms/batch - loss: 33.90224 - diff: 48.79mlTrain batch 22/42 - 182.4ms/batch - loss: 34.13244 - diff: 48.95mlTrain batch 23/42 - 193.2ms/batch - loss: 33.98061 - diff: 49.07mlTrain batch 24/42 - 183.8ms/batch - loss: 34.37228 - diff: 49.24mlTrain batch 25/42 - 190.1ms/batch - loss: 34.01671 - diff: 49.07mlTrain batch 26/42 - 183.2ms/batch - loss: 33.93880 - diff: 49.05mlTrain batch 27/42 - 183.9ms/batch - loss: 33.85400 - diff: 49.00mlTrain batch 28/42 - 183.4ms/batch - loss: 33.68590 - diff: 48.83mlTrain batch 29/42 - 187.7ms/batch - loss: 33.98766 - diff: 49.05mlTrain batch 30/42 - 182.7ms/batch - loss: 34.28817 - diff: 49.21mlTrain batch 31/42 - 183.2ms/batch - loss: 34.12435 - diff: 49.00mlTrain batch 32/42 - 184.7ms/batch - loss: 34.23108 - diff: 49.19mlTrain batch 33/42 - 185.3ms/batch - loss: 33.85003 - diff: 48.88mlTrain batch 34/42 - 183.7ms/batch - loss: 33.90352 - diff: 48.74mlTrain batch 35/42 - 187.5ms/batch - loss: 33.57285 - diff: 48.53mlTrain batch 36/42 - 184.9ms/batch - loss: 33.37348 - diff: 48.44mlTrain batch 37/42 - 184.7ms/batch - loss: 33.19589 - diff: 48.37mlTrain batch 38/42 - 183.1ms/batch - loss: 33.09911 - diff: 48.35mlTrain batch 39/42 - 182.8ms/batch - loss: 32.78668 - diff: 48.15mlTrain batch 40/42 - 184.5ms/batch - loss: 32.57273 - diff: 47.97mlTrain batch 41/42 - 187.8ms/batch - loss: 32.59387 - diff: 47.94mlTrain batch 42/42 - 129.0ms/batch - loss: 32.74456 - diff: 47.85mlTrain batch 42/42 - 361.8s 129.0ms/batch - loss: 32.74456 - diff: 47.85ml
Test 135.9s: val_loss: 25.77853 - diff: 43.44ml
Saving new best model in models/checkpoints/preproc1_150x150_bySlices_dataset_full_Diastole_TimeAsDepth_1_SGD-0.001_DA2_best

Epoch 5: current best loss = 25.77853, at epoch 4
Train batch 1/42 - 188.9ms/batch - loss: 43.93288 - diff: 54.09mlTrain batch 2/42 - 184.6ms/batch - loss: 36.17447 - diff: 51.54mlTrain batch 3/42 - 185.3ms/batch - loss: 34.42052 - diff: 50.70mlTrain batch 4/42 - 183.9ms/batch - loss: 33.75682 - diff: 49.08mlTrain batch 5/42 - 188.0ms/batch - loss: 31.92073 - diff: 48.18mlTrain batch 6/42 - 184.6ms/batch - loss: 30.52019 - diff: 47.33mlTrain batch 7/42 - 183.0ms/batch - loss: 31.76201 - diff: 47.63mlTrain batch 8/42 - 183.2ms/batch - loss: 31.13336 - diff: 46.97mlTrain batch 9/42 - 186.0ms/batch - loss: 30.85715 - diff: 46.65mlTrain batch 10/42 - 183.4ms/batch - loss: 31.84287 - diff: 46.94mlTrain batch 11/42 - 186.7ms/batch - loss: 31.98271 - diff: 47.31mlTrain batch 12/42 - 188.7ms/batch - loss: 33.32111 - diff: 47.83mlTrain batch 13/42 - 182.8ms/batch - loss: 33.57680 - diff: 47.71mlTrain batch 14/42 - 184.3ms/batch - loss: 33.12448 - diff: 47.39mlTrain batch 15/42 - 187.3ms/batch - loss: 33.08999 - diff: 47.25mlTrain batch 16/42 - 184.2ms/batch - loss: 32.68999 - diff: 47.19mlTrain batch 17/42 - 203.1ms/batch - loss: 33.38223 - diff: 47.60mlTrain batch 18/42 - 183.8ms/batch - loss: 33.00125 - diff: 47.38mlTrain batch 19/42 - 189.4ms/batch - loss: 32.47898 - diff: 47.09mlTrain batch 20/42 - 182.9ms/batch - loss: 32.82320 - diff: 47.23mlTrain batch 21/42 - 223.1ms/batch - loss: 32.65894 - diff: 47.22mlTrain batch 22/42 - 184.0ms/batch - loss: 32.17790 - diff: 46.84mlTrain batch 23/42 - 186.1ms/batch - loss: 31.73788 - diff: 46.60mlTrain batch 24/42 - 183.5ms/batch - loss: 31.67023 - diff: 46.77mlTrain batch 25/42 - 194.4ms/batch - loss: 31.65085 - diff: 46.76mlTrain batch 26/42 - 184.3ms/batch - loss: 31.26366 - diff: 46.48mlTrain batch 27/42 - 184.1ms/batch - loss: 30.84739 - diff: 46.25mlTrain batch 28/42 - 184.8ms/batch - loss: 30.76033 - diff: 46.21mlTrain batch 29/42 - 185.0ms/batch - loss: 30.83725 - diff: 46.13mlTrain batch 30/42 - 182.7ms/batch - loss: 30.91720 - diff: 46.17mlTrain batch 31/42 - 189.0ms/batch - loss: 30.72582 - diff: 46.17mlTrain batch 32/42 - 184.5ms/batch - loss: 30.75123 - diff: 46.17mlTrain batch 33/42 - 184.6ms/batch - loss: 30.96859 - diff: 46.24mlTrain batch 34/42 - 184.7ms/batch - loss: 30.77833 - diff: 46.13mlTrain batch 35/42 - 184.4ms/batch - loss: 30.89112 - diff: 46.19mlTrain batch 36/42 - 183.0ms/batch - loss: 30.64415 - diff: 46.02mlTrain batch 37/42 - 189.8ms/batch - loss: 30.39565 - diff: 45.88mlTrain batch 38/42 - 184.7ms/batch - loss: 30.32151 - diff: 45.89mlTrain batch 39/42 - 183.1ms/batch - loss: 30.37566 - diff: 45.96mlTrain batch 40/42 - 182.9ms/batch - loss: 30.58199 - diff: 45.99mlTrain batch 41/42 - 183.6ms/batch - loss: 30.44069 - diff: 45.94mlTrain batch 42/42 - 128.4ms/batch - loss: 30.47078 - diff: 45.87mlTrain batch 42/42 - 356.9s 128.4ms/batch - loss: 30.47078 - diff: 45.87ml
Test 139.2s: val_loss: 26.90294 - diff: 44.85ml

Epoch 6: current best loss = 25.77853, at epoch 4
Train batch 1/42 - 184.1ms/batch - loss: 26.12260 - diff: 45.19mlTrain batch 2/42 - 183.2ms/batch - loss: 22.59116 - diff: 41.80mlTrain batch 3/42 - 189.9ms/batch - loss: 24.39319 - diff: 42.76mlTrain batch 4/42 - 184.4ms/batch - loss: 27.31964 - diff: 44.07mlTrain batch 5/42 - 185.6ms/batch - loss: 28.86498 - diff: 44.62mlTrain batch 6/42 - 184.3ms/batch - loss: 28.46930 - diff: 44.20mlTrain batch 7/42 - 184.5ms/batch - loss: 29.51318 - diff: 44.53mlTrain batch 8/42 - 184.8ms/batch - loss: 29.65071 - diff: 45.01mlTrain batch 9/42 - 190.2ms/batch - loss: 29.09963 - diff: 44.75mlTrain batch 10/42 - 184.7ms/batch - loss: 28.24706 - diff: 44.43mlTrain batch 11/42 - 183.2ms/batch - loss: 28.84814 - diff: 44.62mlTrain batch 12/42 - 183.8ms/batch - loss: 29.06962 - diff: 44.89mlTrain batch 13/42 - 182.7ms/batch - loss: 30.01676 - diff: 45.37mlTrain batch 14/42 - 182.7ms/batch - loss: 30.07822 - diff: 45.59mlTrain batch 15/42 - 200.3ms/batch - loss: 29.92466 - diff: 45.64mlTrain batch 16/42 - 183.8ms/batch - loss: 30.59445 - diff: 46.00mlTrain batch 17/42 - 185.3ms/batch - loss: 31.20442 - diff: 46.34mlTrain batch 18/42 - 183.0ms/batch - loss: 31.26737 - diff: 46.30mlTrain batch 19/42 - 203.0ms/batch - loss: 30.55443 - diff: 45.79mlTrain batch 20/42 - 184.1ms/batch - loss: 30.72680 - diff: 45.84mlTrain batch 21/42 - 188.2ms/batch - loss: 30.60049 - diff: 45.57mlTrain batch 22/42 - 183.2ms/batch - loss: 30.97892 - diff: 45.69mlTrain batch 23/42 - 201.4ms/batch - loss: 31.23502 - diff: 45.78mlTrain batch 24/42 - 183.7ms/batch - loss: 31.27196 - diff: 45.95mlTrain batch 25/42 - 188.1ms/batch - loss: 31.16588 - diff: 46.06mlTrain batch 26/42 - 182.9ms/batch - loss: 31.23753 - diff: 46.22mlTrain batch 27/42 - 183.9ms/batch - loss: 31.56002 - diff: 46.37mlTrain batch 28/42 - 182.6ms/batch - loss: 31.93103 - diff: 46.54mlTrain batch 29/42 - 190.6ms/batch - loss: 31.59765 - diff: 46.35mlTrain batch 30/42 - 183.8ms/batch - loss: 31.52618 - diff: 46.38mlTrain batch 31/42 - 185.8ms/batch - loss: 31.35768 - diff: 46.34mlTrain batch 32/42 - 183.6ms/batch - loss: 31.35610 - diff: 46.22mlTrain batch 33/42 - 183.2ms/batch - loss: 31.06396 - diff: 46.11mlTrain batch 34/42 - 182.8ms/batch - loss: 30.94721 - diff: 46.07mlTrain batch 35/42 - 189.0ms/batch - loss: 30.76233 - diff: 45.97mlTrain batch 36/42 - 185.8ms/batch - loss: 30.81217 - diff: 46.06mlTrain batch 37/42 - 182.6ms/batch - loss: 30.62660 - diff: 45.94mlTrain batch 38/42 - 183.6ms/batch - loss: 30.47787 - diff: 45.89mlTrain batch 39/42 - 183.8ms/batch - loss: 30.27318 - diff: 45.78mlTrain batch 40/42 - 182.9ms/batch - loss: 30.15749 - diff: 45.73mlTrain batch 41/42 - 183.9ms/batch - loss: 30.15491 - diff: 45.79mlTrain batch 42/42 - 128.6ms/batch - loss: 30.72984 - diff: 45.86mlTrain batch 42/42 - 366.1s 128.6ms/batch - loss: 30.72984 - diff: 45.86ml
Test 134.6s: val_loss: 24.38690 - diff: 42.44ml
Saving new best model in models/checkpoints/preproc1_150x150_bySlices_dataset_full_Diastole_TimeAsDepth_1_SGD-0.001_DA2_best

Epoch 7: current best loss = 24.38690, at epoch 6
Train batch 1/42 - 190.4ms/batch - loss: 18.62961 - diff: 37.80mlTrain batch 2/42 - 184.6ms/batch - loss: 29.62138 - diff: 45.77mlTrain batch 3/42 - 183.3ms/batch - loss: 30.26740 - diff: 45.95mlTrain batch 4/42 - 184.3ms/batch - loss: 29.65059 - diff: 46.05mlTrain batch 5/42 - 189.0ms/batch - loss: 30.09092 - diff: 46.39mlTrain batch 6/42 - 183.8ms/batch - loss: 33.75145 - diff: 48.06mlTrain batch 7/42 - 183.5ms/batch - loss: 34.89610 - diff: 47.97mlTrain batch 8/42 - 183.5ms/batch - loss: 34.48342 - diff: 48.51mlTrain batch 9/42 - 182.7ms/batch - loss: 33.61354 - diff: 48.35mlTrain batch 10/42 - 183.2ms/batch - loss: 32.91685 - diff: 47.94mlTrain batch 11/42 - 184.6ms/batch - loss: 32.70201 - diff: 48.18mlTrain batch 12/42 - 184.1ms/batch - loss: 32.21987 - diff: 47.85mlTrain batch 13/42 - 188.0ms/batch - loss: 32.42065 - diff: 47.99mlTrain batch 14/42 - 185.2ms/batch - loss: 33.06363 - diff: 48.11mlTrain batch 15/42 - 185.0ms/batch - loss: 32.64458 - diff: 47.99mlTrain batch 16/42 - 183.2ms/batch - loss: 32.68772 - diff: 48.24mlTrain batch 17/42 - 212.6ms/batch - loss: 32.49406 - diff: 48.33mlTrain batch 18/42 - 184.4ms/batch - loss: 32.10527 - diff: 48.02mlTrain batch 19/42 - 185.3ms/batch - loss: 31.76471 - diff: 47.67mlTrain batch 20/42 - 182.7ms/batch - loss: 31.34147 - diff: 47.39mlTrain batch 21/42 - 201.8ms/batch - loss: 31.57988 - diff: 47.44mlTrain batch 22/42 - 184.7ms/batch - loss: 32.38502 - diff: 47.72mlTrain batch 23/42 - 187.6ms/batch - loss: 32.06862 - diff: 47.49mlTrain batch 24/42 - 182.8ms/batch - loss: 31.91664 - diff: 47.21mlTrain batch 25/42 - 191.5ms/batch - loss: 31.74985 - diff: 47.07mlTrain batch 26/42 - 184.7ms/batch - loss: 31.75181 - diff: 47.12mlTrain batch 27/42 - 186.1ms/batch - loss: 31.31224 - diff: 46.81mlTrain batch 28/42 - 184.6ms/batch - loss: 30.99883 - diff: 46.58mlTrain batch 29/42 - 187.3ms/batch - loss: 30.77587 - diff: 46.49mlTrain batch 30/42 - 183.6ms/batch - loss: 30.98547 - diff: 46.71mlTrain batch 31/42 - 189.6ms/batch - loss: 31.35147 - diff: 46.81mlTrain batch 32/42 - 184.1ms/batch - loss: 31.31781 - diff: 46.89mlTrain batch 33/42 - 183.2ms/batch - loss: 31.35319 - diff: 47.02mlTrain batch 34/42 - 182.4ms/batch - loss: 31.14858 - diff: 46.89mlTrain batch 35/42 - 183.3ms/batch - loss: 31.04994 - diff: 46.77mlTrain batch 36/42 - 183.3ms/batch - loss: 30.86966 - diff: 46.64mlTrain batch 37/42 - 188.3ms/batch - loss: 30.95503 - diff: 46.72mlTrain batch 38/42 - 189.0ms/batch - loss: 30.88318 - diff: 46.64mlTrain batch 39/42 - 183.2ms/batch - loss: 30.58934 - diff: 46.39mlTrain batch 40/42 - 184.2ms/batch - loss: 30.53044 - diff: 46.43mlTrain batch 41/42 - 183.0ms/batch - loss: 30.36982 - diff: 46.38mlTrain batch 42/42 - 128.6ms/batch - loss: 30.80981 - diff: 46.42mlTrain batch 42/42 - 368.0s 128.6ms/batch - loss: 30.80981 - diff: 46.42ml
Test 140.3s: val_loss: 25.75410 - diff: 42.58ml

Epoch 8: current best loss = 24.38690, at epoch 6
Train batch 1/42 - 185.3ms/batch - loss: 27.39662 - diff: 46.16mlTrain batch 2/42 - 183.0ms/batch - loss: 27.57045 - diff: 46.36mlTrain batch 3/42 - 190.5ms/batch - loss: 27.78942 - diff: 45.58mlTrain batch 4/42 - 185.5ms/batch - loss: 29.05546 - diff: 45.56mlTrain batch 5/42 - 182.8ms/batch - loss: 31.18234 - diff: 46.89mlTrain batch 6/42 - 182.8ms/batch - loss: 29.34228 - diff: 45.62mlTrain batch 7/42 - 183.4ms/batch - loss: 30.52609 - diff: 46.65mlTrain batch 8/42 - 184.0ms/batch - loss: 32.00063 - diff: 46.67mlTrain batch 9/42 - 184.8ms/batch - loss: 31.54068 - diff: 46.66mlTrain batch 10/42 - 183.3ms/batch - loss: 30.84233 - diff: 46.41mlTrain batch 11/42 - 189.2ms/batch - loss: 30.47964 - diff: 46.33mlTrain batch 12/42 - 184.9ms/batch - loss: 30.97793 - diff: 46.69mlTrain batch 13/42 - 182.9ms/batch - loss: 31.08130 - diff: 46.84mlTrain batch 14/42 - 184.2ms/batch - loss: 31.05737 - diff: 46.82mlTrain batch 15/42 - 185.8ms/batch - loss: 31.16075 - diff: 46.74mlTrain batch 16/42 - 183.7ms/batch - loss: 31.10857 - diff: 46.83mlTrain batch 17/42 - 200.2ms/batch - loss: 31.37606 - diff: 46.76mlTrain batch 18/42 - 183.9ms/batch - loss: 31.31797 - diff: 46.45mlTrain batch 19/42 - 185.4ms/batch - loss: 31.51376 - diff: 46.35mlTrain batch 20/42 - 182.9ms/batch - loss: 31.24285 - diff: 46.32mlTrain batch 21/42 - 201.2ms/batch - loss: 31.17985 - diff: 46.46mlTrain batch 22/42 - 184.9ms/batch - loss: 31.18499 - diff: 46.62mlTrain batch 23/42 - 185.4ms/batch - loss: 30.93196 - diff: 46.63mlTrain batch 24/42 - 182.8ms/batch - loss: 31.25611 - diff: 46.72mlTrain batch 25/42 - 189.3ms/batch - loss: 31.23683 - diff: 46.80mlTrain batch 26/42 - 182.8ms/batch - loss: 31.25766 - diff: 46.82mlTrain batch 27/42 - 183.7ms/batch - loss: 30.98126 - diff: 46.64mlTrain batch 28/42 - 183.8ms/batch - loss: 30.75963 - diff: 46.56mlTrain batch 29/42 - 183.3ms/batch - loss: 30.46474 - diff: 46.43mlTrain batch 30/42 - 183.0ms/batch - loss: 30.33692 - diff: 46.36mlTrain batch 31/42 - 188.2ms/batch - loss: 30.46748 - diff: 46.43mlTrain batch 32/42 - 184.4ms/batch - loss: 30.20531 - diff: 46.24mlTrain batch 33/42 - 187.7ms/batch - loss: 30.06922 - diff: 46.21mlTrain batch 34/42 - 197.4ms/batch - loss: 29.87871 - diff: 46.13mlTrain batch 35/42 - 182.7ms/batch - loss: 30.09250 - diff: 46.24mlTrain batch 36/42 - 185.0ms/batch - loss: 30.01300 - diff: 46.24mlTrain batch 37/42 - 187.2ms/batch - loss: 29.71806 - diff: 45.98mlTrain batch 38/42 - 183.2ms/batch - loss: 29.63097 - diff: 45.90mlTrain batch 39/42 - 184.3ms/batch - loss: 29.50216 - diff: 45.87mlTrain batch 40/42 - 183.2ms/batch - loss: 29.42166 - diff: 45.86mlTrain batch 41/42 - 183.8ms/batch - loss: 29.46297 - diff: 45.82mlTrain batch 42/42 - 268.3ms/batch - loss: 29.56088 - diff: 45.71mlTrain batch 42/42 - 363.4s 268.3ms/batch - loss: 29.56088 - diff: 45.71ml
Test 138.6s: val_loss: 24.43421 - diff: 42.37ml

Epoch 9: current best loss = 24.38690, at epoch 6
Train batch 1/42 - 203.3ms/batch - loss: 29.14293 - diff: 45.79mlTrain batch 2/42 - 184.7ms/batch - loss: 26.36134 - diff: 44.45mlTrain batch 3/42 - 188.4ms/batch - loss: 26.79786 - diff: 44.36mlTrain batch 4/42 - 185.3ms/batch - loss: 25.23103 - diff: 43.67mlTrain batch 5/42 - 184.0ms/batch - loss: 25.22922 - diff: 43.93mlTrain batch 6/42 - 182.7ms/batch - loss: 26.45809 - diff: 43.84mlTrain batch 7/42 - 183.8ms/batch - loss: 26.16142 - diff: 43.73mlTrain batch 8/42 - 183.0ms/batch - loss: 26.09917 - diff: 43.67mlTrain batch 9/42 - 187.5ms/batch - loss: 26.91793 - diff: 44.26mlTrain batch 10/42 - 185.3ms/batch - loss: 26.41620 - diff: 44.04mlTrain batch 11/42 - 182.8ms/batch - loss: 26.20898 - diff: 43.85mlTrain batch 12/42 - 183.2ms/batch - loss: 26.82240 - diff: 44.14mlTrain batch 13/42 - 182.2ms/batch - loss: 27.08470 - diff: 44.17mlTrain batch 14/42 - 182.5ms/batch - loss: 28.36728 - diff: 44.78mlTrain batch 15/42 - 201.4ms/batch - loss: 28.22059 - diff: 44.80mlTrain batch 16/42 - 184.6ms/batch - loss: 28.48847 - diff: 45.19mlTrain batch 17/42 - 185.3ms/batch - loss: 28.57992 - diff: 45.41mlTrain batch 18/42 - 182.7ms/batch - loss: 28.04098 - diff: 45.09mlTrain batch 19/42 - 185.2ms/batch - loss: 28.41308 - diff: 45.05mlTrain batch 20/42 - 182.7ms/batch - loss: 28.05426 - diff: 44.75mlTrain batch 21/42 - 201.2ms/batch - loss: 28.17714 - diff: 44.92mlTrain batch 22/42 - 183.7ms/batch - loss: 28.23173 - diff: 45.03mlTrain batch 23/42 - 185.6ms/batch - loss: 28.46773 - diff: 45.14mlTrain batch 24/42 - 182.6ms/batch - loss: 28.48590 - diff: 45.20mlTrain batch 25/42 - 194.5ms/batch - loss: 28.41426 - diff: 45.21mlTrain batch 26/42 - 185.1ms/batch - loss: 29.02577 - diff: 45.39mlTrain batch 27/42 - 184.0ms/batch - loss: 28.99256 - diff: 45.46mlTrain batch 28/42 - 184.0ms/batch - loss: 28.97503 - diff: 45.40mlTrain batch 29/42 - 183.7ms/batch - loss: 28.94316 - diff: 45.40mlTrain batch 30/42 - 183.8ms/batch - loss: 28.75012 - diff: 45.31mlTrain batch 31/42 - 189.8ms/batch - loss: 29.00998 - diff: 45.41mlTrain batch 32/42 - 184.5ms/batch - loss: 29.34388 - diff: 45.48mlTrain batch 33/42 - 184.3ms/batch - loss: 29.27245 - diff: 45.43mlTrain batch 34/42 - 184.5ms/batch - loss: 29.28234 - diff: 45.32mlTrain batch 35/42 - 198.1ms/batch - loss: 29.11512 - diff: 45.23mlTrain batch 36/42 - 184.6ms/batch - loss: 29.06104 - diff: 45.19mlTrain batch 37/42 - 202.8ms/batch - loss: 28.96651 - diff: 45.19mlTrain batch 38/42 - 185.3ms/batch - loss: 29.34234 - diff: 45.40mlTrain batch 39/42 - 186.3ms/batch - loss: 29.47128 - diff: 45.57mlTrain batch 40/42 - 201.0ms/batch - loss: 29.51548 - diff: 45.53mlTrain batch 41/42 - 183.0ms/batch - loss: 29.75567 - diff: 45.65mlTrain batch 42/42 - 128.7ms/batch - loss: 29.85825 - diff: 45.62mlTrain batch 42/42 - 361.8s 128.7ms/batch - loss: 29.85825 - diff: 45.62ml
Test 139.6s: val_loss: 25.44863 - diff: 43.32ml

Epoch 10: current best loss = 24.38690, at epoch 6
Train batch 1/42 - 195.1ms/batch - loss: 41.61110 - diff: 51.12mlTrain batch 2/42 - 185.0ms/batch - loss: 36.52497 - diff: 52.21mlTrain batch 3/42 - 182.7ms/batch - loss: 31.38003 - diff: 49.42mlTrain batch 4/42 - 182.7ms/batch - loss: 30.68387 - diff: 48.18mlTrain batch 5/42 - 183.3ms/batch - loss: 30.99166 - diff: 47.70mlTrain batch 6/42 - 182.3ms/batch - loss: 32.10867 - diff: 48.49mlTrain batch 7/42 - 189.6ms/batch - loss: 33.86979 - diff: 48.76mlTrain batch 8/42 - 184.9ms/batch - loss: 34.96073 - diff: 49.82mlTrain batch 9/42 - 183.0ms/batch - loss: 34.19174 - diff: 49.47mlTrain batch 10/42 - 182.8ms/batch - loss: 33.54078 - diff: 49.06mlTrain batch 11/42 - 183.0ms/batch - loss: 32.95819 - diff: 48.61mlTrain batch 12/42 - 182.7ms/batch - loss: 31.76158 - diff: 47.81mlTrain batch 13/42 - 183.0ms/batch - loss: 31.03813 - diff: 47.29mlTrain batch 14/42 - 182.7ms/batch - loss: 31.51470 - diff: 47.56mlTrain batch 15/42 - 199.9ms/batch - loss: 30.74327 - diff: 46.93mlTrain batch 16/42 - 184.6ms/batch - loss: 30.51813 - diff: 46.95mlTrain batch 17/42 - 185.0ms/batch - loss: 31.62637 - diff: 47.38mlTrain batch 18/42 - 182.9ms/batch - loss: 31.72787 - diff: 47.36mlTrain batch 19/42 - 200.4ms/batch - loss: 31.45177 - diff: 47.17mlTrain batch 20/42 - 183.9ms/batch - loss: 31.04398 - diff: 46.95mlTrain batch 21/42 - 185.4ms/batch - loss: 30.95054 - diff: 47.01mlTrain batch 22/42 - 182.6ms/batch - loss: 30.79387 - diff: 46.95mlTrain batch 23/42 - 193.3ms/batch - loss: 30.46306 - diff: 46.48mlTrain batch 24/42 - 184.6ms/batch - loss: 30.26014 - diff: 46.37mlTrain batch 25/42 - 185.5ms/batch - loss: 30.18645 - diff: 46.37mlTrain batch 26/42 - 182.9ms/batch - loss: 30.01731 - diff: 46.31mlTrain batch 27/42 - 184.6ms/batch - loss: 29.85162 - diff: 46.18mlTrain batch 28/42 - 183.8ms/batch - loss: 29.84831 - diff: 46.20mlTrain batch 29/42 - 189.5ms/batch - loss: 29.56488 - diff: 45.95mlTrain batch 30/42 - 183.7ms/batch - loss: 29.31293 - diff: 45.74mlTrain batch 31/42 - 183.8ms/batch - loss: 29.12494 - diff: 45.62mlTrain batch 32/42 - 183.3ms/batch - loss: 29.31385 - diff: 45.75mlTrain batch 33/42 - 183.2ms/batch - loss: 29.25203 - diff: 45.81mlTrain batch 34/42 - 182.7ms/batch - loss: 29.37874 - diff: 45.83mlTrain batch 35/42 - 189.9ms/batch - loss: 29.66238 - diff: 45.96mlTrain batch 36/42 - 185.1ms/batch - loss: 29.77049 - diff: 45.92mlTrain batch 37/42 - 182.5ms/batch - loss: 29.64004 - diff: 45.91mlTrain batch 38/42 - 186.1ms/batch - loss: 29.63866 - diff: 45.88mlTrain batch 39/42 - 184.1ms/batch - loss: 29.49039 - diff: 45.84mlTrain batch 40/42 - 182.4ms/batch - loss: 29.67633 - diff: 45.87mlTrain batch 41/42 - 192.2ms/batch - loss: 29.44399 - diff: 45.72mlTrain batch 42/42 - 128.1ms/batch - loss: 29.61967 - diff: 45.67mlTrain batch 42/42 - 365.0s 128.1ms/batch - loss: 29.61967 - diff: 45.67ml
Test 137.6s: val_loss: 24.52054 - diff: 42.45ml

Epoch 11: current best loss = 24.38690, at epoch 6
Train batch 1/42 - 184.9ms/batch - loss: 30.17141 - diff: 44.01mlTrain batch 2/42 - 182.9ms/batch - loss: 26.50732 - diff: 43.23mlTrain batch 3/42 - 183.9ms/batch - loss: 28.61446 - diff: 45.22mlTrain batch 4/42 - 183.9ms/batch - loss: 26.82065 - diff: 43.82mlTrain batch 5/42 - 189.0ms/batch - loss: 28.11015 - diff: 44.13mlTrain batch 6/42 - 183.3ms/batch - loss: 29.61286 - diff: 44.55mlTrain batch 7/42 - 183.8ms/batch - loss: 29.51042 - diff: 44.15mlTrain batch 8/42 - 183.7ms/batch - loss: 30.67137 - diff: 45.02mlTrain batch 9/42 - 183.1ms/batch - loss: 30.32865 - diff: 44.84mlTrain batch 10/42 - 182.7ms/batch - loss: 30.45009 - diff: 45.43mlTrain batch 11/42 - 186.5ms/batch - loss: 29.88273 - diff: 45.16mlTrain batch 12/42 - 182.9ms/batch - loss: 30.70145 - diff: 45.40mlTrain batch 13/42 - 182.3ms/batch - loss: 30.71999 - diff: 45.70mlTrain batch 14/42 - 183.5ms/batch - loss: 30.51364 - diff: 45.47mlTrain batch 15/42 - 182.9ms/batch - loss: 30.21798 - diff: 45.39mlTrain batch 16/42 - 182.6ms/batch - loss: 30.55865 - diff: 45.59mlTrain batch 17/42 - 191.0ms/batch - loss: 30.44116 - diff: 45.89mlTrain batch 18/42 - 184.3ms/batch - loss: 30.29960 - diff: 45.96mlTrain batch 19/42 - 187.4ms/batch - loss: 29.79170 - diff: 45.63mlTrain batch 20/42 - 183.7ms/batch - loss: 30.43379 - diff: 45.85mlTrain batch 21/42 - 192.6ms/batch - loss: 30.82283 - diff: 46.11mlTrain batch 22/42 - 182.3ms/batch - loss: 30.59721 - diff: 45.98mlTrain batch 23/42 - 185.3ms/batch - loss: 30.35846 - diff: 45.95mlTrain batch 24/42 - 182.8ms/batch - loss: 30.05698 - diff: 45.88mlTrain batch 25/42 - 189.4ms/batch - loss: 30.03552 - diff: 45.91mlTrain batch 26/42 - 184.9ms/batch - loss: 29.84756 - diff: 45.82mlTrain batch 27/42 - 183.4ms/batch - loss: 29.97323 - diff: 45.80mlTrain batch 28/42 - 182.5ms/batch - loss: 30.04627 - diff: 45.72mlTrain batch 29/42 - 182.4ms/batch - loss: 29.71184 - diff: 45.51mlTrain batch 30/42 - 189.6ms/batch - loss: 30.01307 - diff: 45.79mlTrain batch 31/42 - 190.0ms/batch - loss: 29.83781 - diff: 45.81mlTrain batch 32/42 - 186.7ms/batch - loss: 29.72151 - diff: 45.75mlTrain batch 33/42 - 183.2ms/batch - loss: 29.48248 - diff: 45.61mlTrain batch 34/42 - 183.9ms/batch - loss: 29.35238 - diff: 45.53mlTrain batch 35/42 - 183.8ms/batch - loss: 29.30358 - diff: 45.46mlTrain batch 36/42 - 184.0ms/batch - loss: 29.39250 - diff: 45.47mlTrain batch 37/42 - 186.5ms/batch - loss: 29.14496 - diff: 45.36mlTrain batch 38/42 - 182.7ms/batch - loss: 29.34429 - diff: 45.50mlTrain batch 39/42 - 183.3ms/batch - loss: 29.45652 - diff: 45.52mlTrain batch 40/42 - 183.3ms/batch - loss: 29.34242 - diff: 45.48mlTrain batch 41/42 - 184.2ms/batch - loss: 29.16707 - diff: 45.38mlTrain batch 42/42 - 128.8ms/batch - loss: 29.25681 - diff: 45.33mlTrain batch 42/42 - 362.6s 128.8ms/batch - loss: 29.25681 - diff: 45.33ml
Test 139.8s: val_loss: 25.55453 - diff: 43.61ml

Epoch 12: current best loss = 24.38690, at epoch 6
Train batch 1/42 - 188.5ms/batch - loss: 34.88319 - diff: 47.07mlTrain batch 2/42 - 183.4ms/batch - loss: 34.20559 - diff: 46.49mlTrain batch 3/42 - 199.4ms/batch - loss: 30.80448 - diff: 44.54mlTrain batch 4/42 - 182.5ms/batch - loss: 29.99324 - diff: 44.78mlTrain batch 5/42 - 199.5ms/batch - loss: 29.11161 - diff: 44.30mlTrain batch 6/42 - 183.5ms/batch - loss: 29.61383 - diff: 44.52mlTrain batch 7/42 - 200.0ms/batch - loss: 29.61217 - diff: 44.99mlTrain batch 8/42 - 183.8ms/batch - loss: 30.33130 - diff: 45.53mlTrain batch 9/42 - 188.3ms/batch - loss: 29.35105 - diff: 45.03mlTrain batch 10/42 - 187.0ms/batch - loss: 28.48353 - diff: 44.55mlTrain batch 11/42 - 185.6ms/batch - loss: 29.00329 - diff: 45.05mlTrain batch 12/42 - 184.2ms/batch - loss: 29.70378 - diff: 45.73mlTrain batch 13/42 - 184.2ms/batch - loss: 29.99533 - diff: 45.92mlTrain batch 14/42 - 182.9ms/batch - loss: 29.79180 - diff: 46.10mlTrain batch 15/42 - 188.3ms/batch - loss: 29.93735 - diff: 46.40mlTrain batch 16/42 - 183.7ms/batch - loss: 30.02500 - diff: 46.22mlTrain batch 17/42 - 183.2ms/batch - loss: 30.06153 - diff: 46.11mlTrain batch 18/42 - 182.8ms/batch - loss: 30.06475 - diff: 46.19mlTrain batch 19/42 - 190.1ms/batch - loss: 30.22333 - diff: 46.11mlTrain batch 20/42 - 184.0ms/batch - loss: 30.06556 - diff: 46.15mlTrain batch 21/42 - 183.6ms/batch - loss: 30.10235 - diff: 46.44mlTrain batch 22/42 - 182.3ms/batch - loss: 29.56725 - diff: 46.07mlTrain batch 23/42 - 189.7ms/batch - loss: 30.29039 - diff: 46.34mlTrain batch 24/42 - 182.7ms/batch - loss: 30.52852 - diff: 46.57mlTrain batch 25/42 - 191.1ms/batch - loss: 30.56276 - diff: 46.64mlTrain batch 26/42 - 183.6ms/batch - loss: 30.35471 - diff: 46.64mlTrain batch 27/42 - 183.4ms/batch - loss: 30.53983 - diff: 46.83mlTrain batch 28/42 - 188.3ms/batch - loss: 30.51370 - diff: 46.90mlTrain batch 29/42 - 184.8ms/batch - loss: 30.68418 - diff: 46.85mlTrain batch 30/42 - 183.8ms/batch - loss: 30.43596 - diff: 46.65mlTrain batch 31/42 - 184.1ms/batch - loss: 30.45966 - diff: 46.50mlTrain batch 32/42 - 183.8ms/batch - loss: 30.27617 - diff: 46.36mlTrain batch 33/42 - 184.1ms/batch - loss: 30.12018 - diff: 46.31mlTrain batch 34/42 - 189.6ms/batch - loss: 30.12859 - diff: 46.42mlTrain batch 35/42 - 186.0ms/batch - loss: 30.59232 - diff: 46.50mlTrain batch 36/42 - 183.7ms/batch - loss: 30.83843 - diff: 46.58mlTrain batch 37/42 - 182.4ms/batch - loss: 31.01822 - diff: 46.64mlTrain batch 38/42 - 184.0ms/batch - loss: 30.80718 - diff: 46.50mlTrain batch 39/42 - 183.2ms/batch - loss: 30.62271 - diff: 46.36mlTrain batch 40/42 - 183.5ms/batch - loss: 30.60167 - diff: 46.36mlTrain batch 41/42 - 186.2ms/batch - loss: 30.67417 - diff: 46.40mlTrain batch 42/42 - 128.9ms/batch - loss: 31.02203 - diff: 46.48mlTrain batch 42/42 - 364.1s 128.9ms/batch - loss: 31.02203 - diff: 46.48ml
Test 140.8s: val_loss: 24.20470 - diff: 42.15ml
Saving new best model in models/checkpoints/preproc1_150x150_bySlices_dataset_full_Diastole_TimeAsDepth_1_SGD-0.001_DA2_best

Epoch 13: current best loss = 24.20470, at epoch 12
Train batch 1/42 - 189.3ms/batch - loss: 27.45725 - diff: 46.40mlTrain batch 2/42 - 186.7ms/batch - loss: 29.77715 - diff: 46.51mlTrain batch 3/42 - 191.4ms/batch - loss: 27.37547 - diff: 45.89mlTrain batch 4/42 - 189.3ms/batch - loss: 28.50308 - diff: 45.06mlTrain batch 5/42 - 187.4ms/batch - loss: 30.10039 - diff: 45.77mlTrain batch 6/42 - 185.7ms/batch - loss: 28.45459 - diff: 44.99mlTrain batch 7/42 - 182.9ms/batch - loss: 28.78539 - diff: 45.47mlTrain batch 8/42 - 183.8ms/batch - loss: 29.08768 - diff: 45.70mlTrain batch 9/42 - 183.6ms/batch - loss: 29.98419 - diff: 46.04mlTrain batch 10/42 - 183.4ms/batch - loss: 29.62793 - diff: 45.66mlTrain batch 11/42 - 188.5ms/batch - loss: 29.90709 - diff: 46.25mlTrain batch 12/42 - 185.3ms/batch - loss: 29.68084 - diff: 45.66mlTrain batch 13/42 - 184.5ms/batch - loss: 29.91864 - diff: 45.79mlTrain batch 14/42 - 184.7ms/batch - loss: 29.62178 - diff: 45.56mlTrain batch 15/42 - 182.4ms/batch - loss: 29.46268 - diff: 45.57mlTrain batch 16/42 - 182.8ms/batch - loss: 29.43309 - diff: 45.45mlTrain batch 17/42 - 198.3ms/batch - loss: 29.31169 - diff: 45.52mlTrain batch 18/42 - 183.5ms/batch - loss: 29.77335 - diff: 45.63mlTrain batch 19/42 - 185.3ms/batch - loss: 29.76397 - diff: 45.57mlTrain batch 20/42 - 182.9ms/batch - loss: 29.56756 - diff: 45.60mlTrain batch 21/42 - 203.5ms/batch - loss: 29.56904 - diff: 45.77mlTrain batch 22/42 - 184.9ms/batch - loss: 29.25758 - diff: 45.68mlTrain batch 23/42 - 185.2ms/batch - loss: 28.98189 - diff: 45.54mlTrain batch 24/42 - 182.7ms/batch - loss: 29.24223 - diff: 45.50mlTrain batch 25/42 - 206.6ms/batch - loss: 29.04188 - diff: 45.42mlTrain batch 26/42 - 184.8ms/batch - loss: 29.05389 - diff: 45.55mlTrain batch 27/42 - 192.6ms/batch - loss: 28.67049 - diff: 45.32mlTrain batch 28/42 - 182.9ms/batch - loss: 28.65874 - diff: 45.29mlTrain batch 29/42 - 185.6ms/batch - loss: 28.71002 - diff: 45.34mlTrain batch 30/42 - 183.1ms/batch - loss: 29.01709 - diff: 45.42mlTrain batch 31/42 - 196.3ms/batch - loss: 28.81614 - diff: 45.29mlTrain batch 32/42 - 199.3ms/batch - loss: 28.66981 - diff: 45.22mlTrain batch 33/42 - 183.1ms/batch - loss: 28.59679 - diff: 45.23mlTrain batch 34/42 - 183.7ms/batch - loss: 28.49978 - diff: 45.19mlTrain batch 35/42 - 182.1ms/batch - loss: 28.30371 - diff: 45.04mlTrain batch 36/42 - 184.1ms/batch - loss: 28.99103 - diff: 45.29mlTrain batch 37/42 - 188.7ms/batch - loss: 29.08852 - diff: 45.30mlTrain batch 38/42 - 185.6ms/batch - loss: 29.03138 - diff: 45.22mlTrain batch 39/42 - 183.6ms/batch - loss: 29.38462 - diff: 45.50mlTrain batch 40/42 - 184.0ms/batch - loss: 29.46405 - diff: 45.63mlTrain batch 41/42 - 183.8ms/batch - loss: 29.32160 - diff: 45.53mlTrain batch 42/42 - 128.2ms/batch - loss: 29.60507 - diff: 45.52mlTrain batch 42/42 - 364.4s 128.2ms/batch - loss: 29.60507 - diff: 45.52ml
Test 140.8s: val_loss: 31.40236 - diff: 47.34ml

Epoch 14: current best loss = 24.20470, at epoch 12
Train batch 1/42 - 199.6ms/batch - loss: 19.66866 - diff: 38.98mlTrain batch 2/42 - 184.4ms/batch - loss: 26.80985 - diff: 43.69mlTrain batch 3/42 - 188.5ms/batch - loss: 27.22574 - diff: 44.59mlTrain batch 4/42 - 184.5ms/batch - loss: 34.82542 - diff: 49.72mlTrain batch 5/42 - 184.0ms/batch - loss: 35.50745 - diff: 49.89mlTrain batch 6/42 - 182.8ms/batch - loss: 34.22068 - diff: 49.06mlTrain batch 7/42 - 184.2ms/batch - loss: 34.33976 - diff: 48.36mlTrain batch 8/42 - 182.8ms/batch - loss: 33.85220 - diff: 48.02mlTrain batch 9/42 - 188.3ms/batch - loss: 33.37606 - diff: 47.67mlTrain batch 10/42 - 185.5ms/batch - loss: 32.06642 - diff: 46.88mlTrain batch 11/42 - 184.2ms/batch - loss: 31.26209 - diff: 46.54mlTrain batch 12/42 - 184.0ms/batch - loss: 30.56234 - diff: 46.35mlTrain batch 13/42 - 183.4ms/batch - loss: 30.08973 - diff: 46.15mlTrain batch 14/42 - 184.3ms/batch - loss: 29.52723 - diff: 45.69mlTrain batch 15/42 - 188.3ms/batch - loss: 29.32573 - diff: 45.59mlTrain batch 16/42 - 184.0ms/batch - loss: 30.01950 - diff: 45.89mlTrain batch 17/42 - 185.3ms/batch - loss: 30.20854 - diff: 45.90mlTrain batch 18/42 - 182.7ms/batch - loss: 30.18437 - diff: 45.81mlTrain batch 19/42 - 191.4ms/batch - loss: 30.19218 - diff: 46.02mlTrain batch 20/42 - 183.5ms/batch - loss: 30.56226 - diff: 46.12mlTrain batch 21/42 - 185.2ms/batch - loss: 30.75159 - diff: 46.11mlTrain batch 22/42 - 182.7ms/batch - loss: 30.71386 - diff: 46.19mlTrain batch 23/42 - 199.5ms/batch - loss: 30.13849 - diff: 45.81mlTrain batch 24/42 - 183.2ms/batch - loss: 29.86327 - diff: 45.70mlTrain batch 25/42 - 185.5ms/batch - loss: 29.83616 - diff: 45.65mlTrain batch 26/42 - 183.4ms/batch - loss: 29.71128 - diff: 45.58mlTrain batch 27/42 - 183.4ms/batch - loss: 29.74464 - diff: 45.49mlTrain batch 28/42 - 190.8ms/batch - loss: 29.76516 - diff: 45.59mlTrain batch 29/42 - 188.2ms/batch - loss: 29.77265 - diff: 45.57mlTrain batch 30/42 - 183.7ms/batch - loss: 29.35262 - diff: 45.26mlTrain batch 31/42 - 183.4ms/batch - loss: 29.69788 - diff: 45.44mlTrain batch 32/42 - 183.2ms/batch - loss: 29.50709 - diff: 45.36mlTrain batch 33/42 - 187.9ms/batch - loss: 29.47798 - diff: 45.33mlTrain batch 34/42 - 183.8ms/batch - loss: 29.40378 - diff: 45.33mlTrain batch 35/42 - 184.5ms/batch - loss: 29.51391 - diff: 45.35mlTrain batch 36/42 - 184.8ms/batch - loss: 29.54858 - diff: 45.45mlTrain batch 37/42 - 183.6ms/batch - loss: 29.49123 - diff: 45.47mlTrain batch 38/42 - 184.2ms/batch - loss: 29.36691 - diff: 45.43mlTrain batch 39/42 - 184.1ms/batch - loss: 29.94940 - diff: 45.65mlTrain batch 40/42 - 182.7ms/batch - loss: 29.94165 - diff: 45.70mlTrain batch 41/42 - 191.1ms/batch - loss: 30.03965 - diff: 45.64mlTrain batch 42/42 - 139.7ms/batch - loss: 30.30519 - diff: 45.70mlTrain batch 42/42 - 365.0s 139.7ms/batch - loss: 30.30519 - diff: 45.70ml
Test 139.2s: val_loss: 26.32110 - diff: 44.32ml

Epoch 15: current best loss = 24.20470, at epoch 12
Train batch 1/42 - 188.6ms/batch - loss: 42.48761 - diff: 47.92mlTrain batch 2/42 - 183.6ms/batch - loss: 35.96952 - diff: 47.65mlTrain batch 3/42 - 183.3ms/batch - loss: 32.53753 - diff: 46.99mlTrain batch 4/42 - 182.7ms/batch - loss: 30.73868 - diff: 46.40mlTrain batch 5/42 - 188.6ms/batch - loss: 31.10437 - diff: 47.01mlTrain batch 6/42 - 184.3ms/batch - loss: 29.32601 - diff: 45.80mlTrain batch 7/42 - 182.4ms/batch - loss: 29.20140 - diff: 45.54mlTrain batch 8/42 - 184.2ms/batch - loss: 30.67808 - diff: 46.23mlTrain batch 9/42 - 183.6ms/batch - loss: 31.74518 - diff: 46.26mlTrain batch 10/42 - 184.6ms/batch - loss: 31.71379 - diff: 45.88mlTrain batch 11/42 - 189.1ms/batch - loss: 31.43434 - diff: 45.88mlTrain batch 12/42 - 184.2ms/batch - loss: 32.06698 - diff: 46.31mlTrain batch 13/42 - 183.4ms/batch - loss: 32.69300 - diff: 46.64mlTrain batch 14/42 - 185.2ms/batch - loss: 32.30240 - diff: 46.54mlTrain batch 15/42 - 182.8ms/batch - loss: 32.27643 - diff: 46.22mlTrain batch 16/42 - 182.4ms/batch - loss: 31.80288 - diff: 46.10mlTrain batch 17/42 - 187.5ms/batch - loss: 32.37866 - diff: 46.49mlTrain batch 18/42 - 183.7ms/batch - loss: 32.01870 - diff: 46.39mlTrain batch 19/42 - 183.0ms/batch - loss: 31.83487 - diff: 46.44mlTrain batch 20/42 - 183.1ms/batch - loss: 31.58370 - diff: 46.44mlTrain batch 21/42 - 188.9ms/batch - loss: 31.24727 - diff: 46.24mlTrain batch 22/42 - 183.1ms/batch - loss: 30.86991 - diff: 46.03mlTrain batch 23/42 - 182.4ms/batch - loss: 30.38138 - diff: 45.66mlTrain batch 24/42 - 182.9ms/batch - loss: 30.08443 - diff: 45.51mlTrain batch 25/42 - 188.2ms/batch - loss: 30.29055 - diff: 45.48mlTrain batch 26/42 - 184.2ms/batch - loss: 30.66873 - diff: 45.73mlTrain batch 27/42 - 182.9ms/batch - loss: 30.53056 - diff: 45.78mlTrain batch 28/42 - 182.4ms/batch - loss: 30.55874 - diff: 45.84mlTrain batch 29/42 - 188.2ms/batch - loss: 30.55768 - diff: 45.87mlTrain batch 30/42 - 185.3ms/batch - loss: 30.36762 - diff: 45.76mlTrain batch 31/42 - 184.3ms/batch - loss: 30.60902 - diff: 45.90mlTrain batch 32/42 - 182.5ms/batch - loss: 30.89324 - diff: 46.01mlTrain batch 33/42 - 184.4ms/batch - loss: 30.70018 - diff: 45.94mlTrain batch 34/42 - 185.3ms/batch - loss: 30.41187 - diff: 45.79mlTrain batch 35/42 - 188.1ms/batch - loss: 30.47959 - diff: 45.78mlTrain batch 36/42 - 185.9ms/batch - loss: 30.36811 - diff: 45.72mlTrain batch 37/42 - 183.8ms/batch - loss: 30.32740 - diff: 45.80mlTrain batch 38/42 - 185.0ms/batch - loss: 30.27789 - diff: 45.81mlTrain batch 39/42 - 183.4ms/batch - loss: 30.17657 - diff: 45.71mlTrain batch 40/42 - 186.4ms/batch - loss: 30.24597 - diff: 45.78mlTrain batch 41/42 - 183.0ms/batch - loss: 30.13140 - diff: 45.70mlTrain batch 42/42 - 128.8ms/batch - loss: 30.13084 - diff: 45.58mlTrain batch 42/42 - 360.1s 128.8ms/batch - loss: 30.13084 - diff: 45.58ml
Test 137.5s: val_loss: 25.12338 - diff: 43.22ml

Epoch 16: current best loss = 24.20470, at epoch 12
Train batch 1/42 - 188.7ms/batch - loss: 27.52996 - diff: 41.80mlTrain batch 2/42 - 184.3ms/batch - loss: 38.79368 - diff: 45.31mlTrain batch 3/42 - 190.1ms/batch - loss: 35.19861 - diff: 45.05mlTrain batch 4/42 - 184.6ms/batch - loss: 35.08997 - diff: 45.66mlTrain batch 5/42 - 183.5ms/batch - loss: 34.59240 - diff: 46.27mlTrain batch 6/42 - 184.8ms/batch - loss: 34.88445 - diff: 46.26mlTrain batch 7/42 - 183.5ms/batch - loss: 33.98188 - diff: 46.46mlTrain batch 8/42 - 183.5ms/batch - loss: 32.91150 - diff: 45.97mlTrain batch 9/42 - 189.6ms/batch - loss: 31.77215 - diff: 45.55mlTrain batch 10/42 - 184.2ms/batch - loss: 31.23655 - diff: 45.24mlTrain batch 11/42 - 182.9ms/batch - loss: 30.25912 - diff: 44.81mlTrain batch 12/42 - 183.7ms/batch - loss: 29.92892 - diff: 44.77mlTrain batch 13/42 - 184.0ms/batch - loss: 29.25836 - diff: 44.44mlTrain batch 14/42 - 183.5ms/batch - loss: 29.63607 - diff: 44.63mlTrain batch 15/42 - 191.0ms/batch - loss: 29.27795 - diff: 44.48mlTrain batch 16/42 - 184.8ms/batch - loss: 29.07325 - diff: 44.37mlTrain batch 17/42 - 187.2ms/batch - loss: 28.62227 - diff: 44.17mlTrain batch 18/42 - 182.9ms/batch - loss: 28.47988 - diff: 44.08mlTrain batch 19/42 - 198.8ms/batch - loss: 28.35185 - diff: 44.16mlTrain batch 20/42 - 183.1ms/batch - loss: 27.93930 - diff: 43.89mlTrain batch 21/42 - 189.7ms/batch - loss: 28.06722 - diff: 43.95mlTrain batch 22/42 - 183.3ms/batch - loss: 28.30366 - diff: 44.19mlTrain batch 23/42 - 200.7ms/batch - loss: 28.14003 - diff: 44.17mlTrain batch 24/42 - 183.9ms/batch - loss: 28.06108 - diff: 44.07mlTrain batch 25/42 - 185.7ms/batch - loss: 27.84276 - diff: 43.96mlTrain batch 26/42 - 182.5ms/batch - loss: 27.74558 - diff: 44.01mlTrain batch 27/42 - 207.4ms/batch - loss: 27.98834 - diff: 44.23mlTrain batch 28/42 - 184.4ms/batch - loss: 27.84143 - diff: 44.14mlTrain batch 29/42 - 192.0ms/batch - loss: 27.88889 - diff: 44.24mlTrain batch 30/42 - 182.9ms/batch - loss: 27.96556 - diff: 44.41mlTrain batch 31/42 - 184.5ms/batch - loss: 28.42570 - diff: 44.61mlTrain batch 32/42 - 183.0ms/batch - loss: 28.88311 - diff: 44.69mlTrain batch 33/42 - 187.3ms/batch - loss: 29.32189 - diff: 44.78mlTrain batch 34/42 - 183.1ms/batch - loss: 29.28598 - diff: 44.78mlTrain batch 35/42 - 182.8ms/batch - loss: 29.19304 - diff: 44.73mlTrain batch 36/42 - 182.7ms/batch - loss: 28.98386 - diff: 44.64mlTrain batch 37/42 - 186.3ms/batch - loss: 29.12230 - diff: 44.68mlTrain batch 38/42 - 182.5ms/batch - loss: 29.01395 - diff: 44.69mlTrain batch 39/42 - 188.1ms/batch - loss: 28.87088 - diff: 44.61mlTrain batch 40/42 - 184.9ms/batch - loss: 28.87745 - diff: 44.66mlTrain batch 41/42 - 183.7ms/batch - loss: 28.84097 - diff: 44.55mlTrain batch 42/42 - 128.8ms/batch - loss: 28.98621 - diff: 44.55mlTrain batch 42/42 - 365.2s 128.8ms/batch - loss: 28.98621 - diff: 44.55ml
Test 140.8s: val_loss: 22.81007 - diff: 40.76ml
Saving new best model in models/checkpoints/preproc1_150x150_bySlices_dataset_full_Diastole_TimeAsDepth_1_SGD-0.001_DA2_best

Epoch 17: current best loss = 22.81007, at epoch 16
Train batch 1/42 - 187.5ms/batch - loss: 28.53981 - diff: 50.62mlTrain batch 2/42 - 184.3ms/batch - loss: 27.06473 - diff: 47.63mlTrain batch 3/42 - 189.8ms/batch - loss: 25.88284 - diff: 44.67mlTrain batch 4/42 - 184.0ms/batch - loss: 28.90972 - diff: 45.44mlTrain batch 5/42 - 182.5ms/batch - loss: 27.54832 - diff: 44.81mlTrain batch 6/42 - 182.1ms/batch - loss: 27.20865 - diff: 44.03mlTrain batch 7/42 - 187.3ms/batch - loss: 26.85982 - diff: 43.90mlTrain batch 8/42 - 183.5ms/batch - loss: 28.13599 - diff: 44.33mlTrain batch 9/42 - 187.7ms/batch - loss: 27.32794 - diff: 43.92mlTrain batch 10/42 - 183.3ms/batch - loss: 27.13912 - diff: 43.89mlTrain batch 11/42 - 183.7ms/batch - loss: 27.02459 - diff: 43.99mlTrain batch 12/42 - 183.1ms/batch - loss: 27.07545 - diff: 44.37mlTrain batch 13/42 - 183.3ms/batch - loss: 27.21072 - diff: 44.54mlTrain batch 14/42 - 185.6ms/batch - loss: 26.84827 - diff: 44.47mlTrain batch 15/42 - 190.9ms/batch - loss: 27.35600 - diff: 44.48mlTrain batch 16/42 - 184.2ms/batch - loss: 27.40273 - diff: 44.61mlTrain batch 17/42 - 183.3ms/batch - loss: 27.08359 - diff: 44.50mlTrain batch 18/42 - 182.5ms/batch - loss: 27.30448 - diff: 44.41mlTrain batch 19/42 - 195.9ms/batch - loss: 27.79818 - diff: 44.56mlTrain batch 20/42 - 183.7ms/batch - loss: 28.52209 - diff: 44.80mlTrain batch 21/42 - 185.6ms/batch - loss: 28.82696 - diff: 45.22mlTrain batch 22/42 - 182.1ms/batch - loss: 28.56602 - diff: 44.96mlTrain batch 23/42 - 201.0ms/batch - loss: 28.20425 - diff: 44.65mlTrain batch 24/42 - 183.8ms/batch - loss: 28.28637 - diff: 44.73mlTrain batch 25/42 - 186.0ms/batch - loss: 28.58602 - diff: 44.79mlTrain batch 26/42 - 182.6ms/batch - loss: 28.41745 - diff: 44.76mlTrain batch 27/42 - 190.1ms/batch - loss: 28.36725 - diff: 44.64mlTrain batch 28/42 - 183.3ms/batch - loss: 28.17737 - diff: 44.54mlTrain batch 29/42 - 184.3ms/batch - loss: 27.98488 - diff: 44.44mlTrain batch 30/42 - 183.4ms/batch - loss: 28.61172 - diff: 44.61mlTrain batch 31/42 - 183.9ms/batch - loss: 28.41345 - diff: 44.56mlTrain batch 32/42 - 183.9ms/batch - loss: 28.53289 - diff: 44.77mlTrain batch 33/42 - 191.5ms/batch - loss: 28.50450 - diff: 44.86mlTrain batch 34/42 - 184.4ms/batch - loss: 28.42514 - diff: 44.81mlTrain batch 35/42 - 182.8ms/batch - loss: 28.28130 - diff: 44.69mlTrain batch 36/42 - 184.2ms/batch - loss: 28.19473 - diff: 44.63mlTrain batch 37/42 - 187.0ms/batch - loss: 28.07160 - diff: 44.53mlTrain batch 38/42 - 182.6ms/batch - loss: 28.00781 - diff: 44.47mlTrain batch 39/42 - 186.3ms/batch - loss: 27.98343 - diff: 44.51mlTrain batch 40/42 - 182.8ms/batch - loss: 28.39595 - diff: 44.59mlTrain batch 41/42 - 182.2ms/batch - loss: 28.20096 - diff: 44.50mlTrain batch 42/42 - 128.7ms/batch - loss: 28.31476 - diff: 44.46mlTrain batch 42/42 - 366.4s 128.7ms/batch - loss: 28.31476 - diff: 44.46ml
Test 138.6s: val_loss: 23.83687 - diff: 41.52ml

Epoch 18: current best loss = 22.81007, at epoch 16
Train batch 1/42 - 192.0ms/batch - loss: 19.22608 - diff: 36.70mlTrain batch 2/42 - 184.7ms/batch - loss: 20.88101 - diff: 38.94mlTrain batch 3/42 - 188.4ms/batch - loss: 21.81642 - diff: 39.91mlTrain batch 4/42 - 183.5ms/batch - loss: 22.99066 - diff: 41.40mlTrain batch 5/42 - 183.8ms/batch - loss: 22.32009 - diff: 40.87mlTrain batch 6/42 - 183.1ms/batch - loss: 22.24849 - diff: 41.10mlTrain batch 7/42 - 184.2ms/batch - loss: 22.53048 - diff: 41.37mlTrain batch 8/42 - 183.8ms/batch - loss: 22.94544 - diff: 41.55mlTrain batch 9/42 - 187.9ms/batch - loss: 23.68352 - diff: 42.01mlTrain batch 10/42 - 184.7ms/batch - loss: 24.52891 - diff: 42.20mlTrain batch 11/42 - 183.2ms/batch - loss: 23.84898 - diff: 41.58mlTrain batch 12/42 - 183.5ms/batch - loss: 23.92443 - diff: 41.83mlTrain batch 13/42 - 182.4ms/batch - loss: 24.40773 - diff: 42.19mlTrain batch 14/42 - 189.4ms/batch - loss: 24.70973 - diff: 42.52mlTrain batch 15/42 - 186.9ms/batch - loss: 24.56202 - diff: 42.50mlTrain batch 16/42 - 183.8ms/batch - loss: 24.38061 - diff: 42.39mlTrain batch 17/42 - 207.8ms/batch - loss: 24.50555 - diff: 42.62mlTrain batch 18/42 - 184.4ms/batch - loss: 24.73096 - diff: 42.52mlTrain batch 19/42 - 185.3ms/batch - loss: 25.60334 - diff: 42.85mlTrain batch 20/42 - 183.4ms/batch - loss: 26.11864 - diff: 43.12mlTrain batch 21/42 - 200.7ms/batch - loss: 26.36454 - diff: 43.34mlTrain batch 22/42 - 184.2ms/batch - loss: 26.16066 - diff: 43.21mlTrain batch 23/42 - 185.2ms/batch - loss: 26.21011 - diff: 43.44mlTrain batch 24/42 - 182.7ms/batch - loss: 26.07265 - diff: 43.35mlTrain batch 25/42 - 199.8ms/batch - loss: 25.92747 - diff: 43.30mlTrain batch 26/42 - 183.4ms/batch - loss: 25.63967 - diff: 43.11mlTrain batch 27/42 - 185.9ms/batch - loss: 25.45874 - diff: 42.89mlTrain batch 28/42 - 183.5ms/batch - loss: 25.76384 - diff: 42.95mlTrain batch 29/42 - 185.7ms/batch - loss: 25.60543 - diff: 42.81mlTrain batch 30/42 - 183.0ms/batch - loss: 25.67933 - diff: 42.88mlTrain batch 31/42 - 189.1ms/batch - loss: 25.91431 - diff: 43.22mlTrain batch 32/42 - 184.8ms/batch - loss: 26.37998 - diff: 43.45mlTrain batch 33/42 - 184.1ms/batch - loss: 26.60240 - diff: 43.49mlTrain batch 34/42 - 183.5ms/batch - loss: 26.51973 - diff: 43.43mlTrain batch 35/42 - 183.6ms/batch - loss: 26.89680 - diff: 43.51mlTrain batch 36/42 - 182.7ms/batch - loss: 27.36211 - diff: 43.67mlTrain batch 37/42 - 188.1ms/batch - loss: 27.86418 - diff: 43.95mlTrain batch 38/42 - 185.4ms/batch - loss: 28.02815 - diff: 44.18mlTrain batch 39/42 - 183.3ms/batch - loss: 28.21610 - diff: 44.36mlTrain batch 40/42 - 185.0ms/batch - loss: 28.15263 - diff: 44.30mlTrain batch 41/42 - 183.8ms/batch - loss: 28.06834 - diff: 44.22mlTrain batch 42/42 - 128.4ms/batch - loss: 28.22006 - diff: 44.20mlTrain batch 42/42 - 368.7s 128.4ms/batch - loss: 28.22006 - diff: 44.20ml
Test 141.5s: val_loss: 24.28518 - diff: 42.27ml

Epoch 19: current best loss = 22.81007, at epoch 16
Train batch 1/42 - 188.9ms/batch - loss: 49.50714 - diff: 52.82mlTrain batch 2/42 - 185.3ms/batch - loss: 42.37642 - diff: 51.40mlTrain batch 3/42 - 183.9ms/batch - loss: 35.92735 - diff: 48.71mlTrain batch 4/42 - 183.7ms/batch - loss: 33.15078 - diff: 47.59mlTrain batch 5/42 - 183.6ms/batch - loss: 30.89740 - diff: 46.07mlTrain batch 6/42 - 182.7ms/batch - loss: 30.69977 - diff: 46.31mlTrain batch 7/42 - 188.4ms/batch - loss: 30.48435 - diff: 45.98mlTrain batch 8/42 - 185.1ms/batch - loss: 30.09146 - diff: 45.85mlTrain batch 9/42 - 183.7ms/batch - loss: 29.42193 - diff: 45.71mlTrain batch 10/42 - 183.7ms/batch - loss: 29.86143 - diff: 46.63mlTrain batch 11/42 - 183.6ms/batch - loss: 28.60579 - diff: 45.60mlTrain batch 12/42 - 183.5ms/batch - loss: 28.58807 - diff: 45.64mlTrain batch 13/42 - 182.7ms/batch - loss: 28.40158 - diff: 45.52mlTrain batch 14/42 - 183.1ms/batch - loss: 28.03081 - diff: 45.29mlTrain batch 15/42 - 188.6ms/batch - loss: 27.58161 - diff: 44.93mlTrain batch 16/42 - 184.1ms/batch - loss: 27.75975 - diff: 44.99mlTrain batch 17/42 - 187.0ms/batch - loss: 27.18799 - diff: 44.54mlTrain batch 18/42 - 182.3ms/batch - loss: 26.98279 - diff: 44.48mlTrain batch 19/42 - 203.9ms/batch - loss: 27.56795 - diff: 44.76mlTrain batch 20/42 - 184.7ms/batch - loss: 27.28251 - diff: 44.49mlTrain batch 21/42 - 192.4ms/batch - loss: 27.13899 - diff: 44.40mlTrain batch 22/42 - 183.7ms/batch - loss: 27.52433 - diff: 44.55mlTrain batch 23/42 - 205.7ms/batch - loss: 27.27467 - diff: 44.46mlTrain batch 24/42 - 184.9ms/batch - loss: 27.24871 - diff: 44.51mlTrain batch 25/42 - 185.8ms/batch - loss: 27.75883 - diff: 44.59mlTrain batch 26/42 - 183.2ms/batch - loss: 28.01208 - diff: 44.64mlTrain batch 27/42 - 190.6ms/batch - loss: 28.28298 - diff: 44.99mlTrain batch 28/42 - 185.0ms/batch - loss: 28.15306 - diff: 45.02mlTrain batch 29/42 - 193.6ms/batch - loss: 28.25157 - diff: 44.93mlTrain batch 30/42 - 183.8ms/batch - loss: 28.05757 - diff: 44.75mlTrain batch 31/42 - 196.6ms/batch - loss: 28.36780 - diff: 44.84mlTrain batch 32/42 - 184.1ms/batch - loss: 28.47299 - diff: 44.83mlTrain batch 33/42 - 189.2ms/batch - loss: 28.51897 - diff: 44.92mlTrain batch 34/42 - 184.2ms/batch - loss: 28.69504 - diff: 44.90mlTrain batch 35/42 - 183.4ms/batch - loss: 28.91113 - diff: 44.99mlTrain batch 36/42 - 183.4ms/batch - loss: 28.96240 - diff: 45.02mlTrain batch 37/42 - 183.8ms/batch - loss: 28.94241 - diff: 44.91mlTrain batch 38/42 - 183.3ms/batch - loss: 28.80451 - diff: 44.87mlTrain batch 39/42 - 204.4ms/batch - loss: 28.68353 - diff: 44.83mlTrain batch 40/42 - 197.2ms/batch - loss: 28.44485 - diff: 44.69mlTrain batch 41/42 - 183.9ms/batch - loss: 28.30229 - diff: 44.58mlTrain batch 42/42 - 129.4ms/batch - loss: 28.51762 - diff: 44.58mlTrain batch 42/42 - 366.7s 129.4ms/batch - loss: 28.51762 - diff: 44.58ml
Test 140.6s: val_loss: 23.76678 - diff: 42.24ml

Epoch 20: current best loss = 22.81007, at epoch 16
Train batch 1/42 - 185.3ms/batch - loss: 19.81829 - diff: 38.21mlTrain batch 2/42 - 182.8ms/batch - loss: 26.34039 - diff: 42.06mlTrain batch 3/42 - 184.7ms/batch - loss: 28.97074 - diff: 43.90mlTrain batch 4/42 - 182.6ms/batch - loss: 30.43846 - diff: 44.96mlTrain batch 5/42 - 188.1ms/batch - loss: 29.76924 - diff: 44.78mlTrain batch 6/42 - 183.6ms/batch - loss: 32.04574 - diff: 45.16mlTrain batch 7/42 - 183.7ms/batch - loss: 31.83185 - diff: 45.39mlTrain batch 8/42 - 183.5ms/batch - loss: 30.61244 - diff: 44.83mlTrain batch 9/42 - 187.3ms/batch - loss: 30.84625 - diff: 45.01mlTrain batch 10/42 - 183.4ms/batch - loss: 29.95879 - diff: 44.56mlTrain batch 11/42 - 190.4ms/batch - loss: 29.76976 - diff: 44.74mlTrain batch 12/42 - 184.2ms/batch - loss: 29.91113 - diff: 44.54mlTrain batch 13/42 - 188.1ms/batch - loss: 29.47136 - diff: 44.35mlTrain batch 14/42 - 184.5ms/batch - loss: 29.12535 - diff: 44.18mlTrain batch 15/42 - 183.8ms/batch - loss: 28.66201 - diff: 43.96mlTrain batch 16/42 - 182.8ms/batch - loss: 29.94337 - diff: 44.62mlTrain batch 17/42 - 190.8ms/batch - loss: 31.10800 - diff: 45.09mlTrain batch 18/42 - 183.5ms/batch - loss: 30.61164 - diff: 44.91mlTrain batch 19/42 - 187.6ms/batch - loss: 30.08960 - diff: 44.64mlTrain batch 20/42 - 182.5ms/batch - loss: 29.86505 - diff: 44.50mlTrain batch 21/42 - 195.2ms/batch - loss: 29.63145 - diff: 44.37mlTrain batch 22/42 - 182.8ms/batch - loss: 29.88535 - diff: 44.44mlTrain batch 23/42 - 186.8ms/batch - loss: 29.71048 - diff: 44.42mlTrain batch 24/42 - 182.7ms/batch - loss: 29.63352 - diff: 44.43mlTrain batch 25/42 - 201.2ms/batch - loss: 29.42414 - diff: 44.31mlTrain batch 26/42 - 184.1ms/batch - loss: 29.44298 - diff: 44.50mlTrain batch 27/42 - 182.9ms/batch - loss: 29.17757 - diff: 44.37mlTrain batch 28/42 - 184.6ms/batch - loss: 28.95349 - diff: 44.21mlTrain batch 29/42 - 183.6ms/batch - loss: 28.70542 - diff: 44.12mlTrain batch 30/42 - 183.1ms/batch - loss: 28.76309 - diff: 44.28mlTrain batch 31/42 - 188.5ms/batch - loss: 28.50420 - diff: 44.17mlTrain batch 32/42 - 183.7ms/batch - loss: 28.48953 - diff: 44.12mlTrain batch 33/42 - 182.4ms/batch - loss: 28.26082 - diff: 44.03mlTrain batch 34/42 - 183.2ms/batch - loss: 28.39672 - diff: 44.15mlTrain batch 35/42 - 183.0ms/batch - loss: 28.32862 - diff: 44.21mlTrain batch 36/42 - 185.0ms/batch - loss: 28.37641 - diff: 44.30mlTrain batch 37/42 - 188.8ms/batch - loss: 28.14123 - diff: 44.15mlTrain batch 38/42 - 183.5ms/batch - loss: 28.10192 - diff: 44.12mlTrain batch 39/42 - 182.8ms/batch - loss: 28.42329 - diff: 44.28mlTrain batch 40/42 - 183.0ms/batch - loss: 28.25264 - diff: 44.22mlTrain batch 41/42 - 183.8ms/batch - loss: 28.22735 - diff: 44.26mlTrain batch 42/42 - 128.6ms/batch - loss: 28.23374 - diff: 44.17mlTrain batch 42/42 - 365.8s 128.6ms/batch - loss: 28.23374 - diff: 44.17ml
Test 139.1s: val_loss: 22.78026 - diff: 40.78ml
Saving new best model in models/checkpoints/preproc1_150x150_bySlices_dataset_full_Diastole_TimeAsDepth_1_SGD-0.001_DA2_best

Epoch 21: current best loss = 22.78026, at epoch 20
Train batch 1/42 - 184.5ms/batch - loss: 26.18317 - diff: 46.66mlTrain batch 2/42 - 183.8ms/batch - loss: 24.89136 - diff: 43.77mlTrain batch 3/42 - 188.6ms/batch - loss: 23.11943 - diff: 42.37mlTrain batch 4/42 - 184.8ms/batch - loss: 23.23057 - diff: 41.98mlTrain batch 5/42 - 183.3ms/batch - loss: 23.03955 - diff: 41.74mlTrain batch 6/42 - 183.5ms/batch - loss: 23.26932 - diff: 42.12mlTrain batch 7/42 - 183.5ms/batch - loss: 24.15253 - diff: 42.28mlTrain batch 8/42 - 183.5ms/batch - loss: 24.16107 - diff: 42.54mlTrain batch 9/42 - 188.3ms/batch - loss: 24.37836 - diff: 42.52mlTrain batch 10/42 - 185.5ms/batch - loss: 24.19185 - diff: 42.08mlTrain batch 11/42 - 184.0ms/batch - loss: 24.08067 - diff: 42.03mlTrain batch 12/42 - 184.4ms/batch - loss: 24.45482 - diff: 42.55mlTrain batch 13/42 - 182.9ms/batch - loss: 23.86162 - diff: 42.06mlTrain batch 14/42 - 184.6ms/batch - loss: 24.78072 - diff: 42.38mlTrain batch 15/42 - 189.1ms/batch - loss: 25.38019 - diff: 42.78mlTrain batch 16/42 - 184.4ms/batch - loss: 25.69567 - diff: 42.94mlTrain batch 17/42 - 185.7ms/batch - loss: 26.27346 - diff: 43.26mlTrain batch 18/42 - 183.4ms/batch - loss: 25.96875 - diff: 43.03mlTrain batch 19/42 - 186.3ms/batch - loss: 25.83004 - diff: 42.97mlTrain batch 20/42 - 182.6ms/batch - loss: 25.63707 - diff: 42.89mlTrain batch 21/42 - 207.0ms/batch - loss: 25.84768 - diff: 42.91mlTrain batch 22/42 - 183.9ms/batch - loss: 25.86473 - diff: 43.00mlTrain batch 23/42 - 185.0ms/batch - loss: 26.20334 - diff: 43.24mlTrain batch 24/42 - 183.0ms/batch - loss: 26.55042 - diff: 43.46mlTrain batch 25/42 - 200.5ms/batch - loss: 26.58178 - diff: 43.43mlTrain batch 26/42 - 184.2ms/batch - loss: 26.31889 - diff: 43.24mlTrain batch 27/42 - 185.3ms/batch - loss: 26.91878 - diff: 43.56mlTrain batch 28/42 - 183.1ms/batch - loss: 27.03517 - diff: 43.67mlTrain batch 29/42 - 185.2ms/batch - loss: 26.93456 - diff: 43.58mlTrain batch 30/42 - 183.6ms/batch - loss: 26.82104 - diff: 43.53mlTrain batch 31/42 - 195.2ms/batch - loss: 26.78703 - diff: 43.48mlTrain batch 32/42 - 184.3ms/batch - loss: 26.75734 - diff: 43.50mlTrain batch 33/42 - 184.3ms/batch - loss: 26.57120 - diff: 43.42mlTrain batch 34/42 - 183.4ms/batch - loss: 26.82585 - diff: 43.67mlTrain batch 35/42 - 183.6ms/batch - loss: 26.66585 - diff: 43.58mlTrain batch 36/42 - 183.2ms/batch - loss: 26.68161 - diff: 43.48mlTrain batch 37/42 - 184.7ms/batch - loss: 26.43245 - diff: 43.32mlTrain batch 38/42 - 183.2ms/batch - loss: 26.49072 - diff: 43.39mlTrain batch 39/42 - 188.6ms/batch - loss: 26.48327 - diff: 43.42mlTrain batch 40/42 - 183.1ms/batch - loss: 26.71064 - diff: 43.56mlTrain batch 41/42 - 196.3ms/batch - loss: 26.78771 - diff: 43.55mlTrain batch 42/42 - 129.3ms/batch - loss: 26.99891 - diff: 43.56mlTrain batch 42/42 - 363.4s 129.3ms/batch - loss: 26.99891 - diff: 43.56ml
Test 139.5s: val_loss: 25.25235 - diff: 42.04ml

Epoch 22: current best loss = 22.78026, at epoch 20
Train batch 1/42 - 192.0ms/batch - loss: 24.03451 - diff: 42.47mlTrain batch 2/42 - 184.1ms/batch - loss: 31.30632 - diff: 44.69mlTrain batch 3/42 - 184.8ms/batch - loss: 29.18975 - diff: 44.64mlTrain batch 4/42 - 182.9ms/batch - loss: 30.01162 - diff: 46.44mlTrain batch 5/42 - 189.4ms/batch - loss: 29.57557 - diff: 46.15mlTrain batch 6/42 - 184.8ms/batch - loss: 30.43577 - diff: 46.15mlTrain batch 7/42 - 183.8ms/batch - loss: 32.50265 - diff: 46.37mlTrain batch 8/42 - 183.4ms/batch - loss: 31.28955 - diff: 45.44mlTrain batch 9/42 - 184.1ms/batch - loss: 30.72754 - diff: 45.36mlTrain batch 10/42 - 182.9ms/batch - loss: 30.17768 - diff: 45.36mlTrain batch 11/42 - 188.9ms/batch - loss: 29.30136 - diff: 44.88mlTrain batch 12/42 - 185.2ms/batch - loss: 28.31074 - diff: 44.12mlTrain batch 13/42 - 184.1ms/batch - loss: 28.84327 - diff: 44.17mlTrain batch 14/42 - 183.3ms/batch - loss: 29.47224 - diff: 44.46mlTrain batch 15/42 - 184.0ms/batch - loss: 29.31524 - diff: 44.46mlTrain batch 16/42 - 183.1ms/batch - loss: 29.62432 - diff: 44.64mlTrain batch 17/42 - 190.4ms/batch - loss: 29.64947 - diff: 44.86mlTrain batch 18/42 - 184.6ms/batch - loss: 29.48780 - diff: 44.97mlTrain batch 19/42 - 187.7ms/batch - loss: 29.01089 - diff: 44.74mlTrain batch 20/42 - 182.3ms/batch - loss: 29.07516 - diff: 44.71mlTrain batch 21/42 - 201.7ms/batch - loss: 29.70487 - diff: 44.92mlTrain batch 22/42 - 183.3ms/batch - loss: 29.45167 - diff: 44.77mlTrain batch 23/42 - 188.1ms/batch - loss: 29.19913 - diff: 44.70mlTrain batch 24/42 - 183.5ms/batch - loss: 29.09621 - diff: 44.81mlTrain batch 25/42 - 204.5ms/batch - loss: 29.45405 - diff: 45.16mlTrain batch 26/42 - 184.1ms/batch - loss: 29.12799 - diff: 44.99mlTrain batch 27/42 - 187.6ms/batch - loss: 28.68565 - diff: 44.58mlTrain batch 28/42 - 182.7ms/batch - loss: 28.57344 - diff: 44.53mlTrain batch 29/42 - 191.3ms/batch - loss: 28.70903 - diff: 44.66mlTrain batch 30/42 - 184.2ms/batch - loss: 28.72226 - diff: 44.69mlTrain batch 31/42 - 191.8ms/batch - loss: 28.35216 - diff: 44.41mlTrain batch 32/42 - 185.8ms/batch - loss: 28.33865 - diff: 44.54mlTrain batch 33/42 - 183.4ms/batch - loss: 28.73867 - diff: 44.75mlTrain batch 34/42 - 182.9ms/batch - loss: 28.94694 - diff: 44.78mlTrain batch 35/42 - 183.2ms/batch - loss: 28.72676 - diff: 44.66mlTrain batch 36/42 - 183.4ms/batch - loss: 29.05830 - diff: 44.85mlTrain batch 37/42 - 189.0ms/batch - loss: 29.27102 - diff: 44.98mlTrain batch 38/42 - 183.9ms/batch - loss: 29.22944 - diff: 44.98mlTrain batch 39/42 - 183.0ms/batch - loss: 29.11093 - diff: 44.96mlTrain batch 40/42 - 183.3ms/batch - loss: 28.83476 - diff: 44.78mlTrain batch 41/42 - 183.3ms/batch - loss: 29.15782 - diff: 44.86mlTrain batch 42/42 - 127.7ms/batch - loss: 29.19396 - diff: 44.80mlTrain batch 42/42 - 369.3s 127.7ms/batch - loss: 29.19396 - diff: 44.80ml
Test 139.1s: val_loss: 23.35943 - diff: 41.16ml

Epoch 23: current best loss = 22.78026, at epoch 20
Train batch 1/42 - 191.8ms/batch - loss: 24.56515 - diff: 43.37mlTrain batch 2/42 - 184.4ms/batch - loss: 28.31479 - diff: 43.68mlTrain batch 3/42 - 184.1ms/batch - loss: 27.80636 - diff: 42.34mlTrain batch 4/42 - 182.6ms/batch - loss: 25.12417 - diff: 41.20mlTrain batch 5/42 - 185.4ms/batch - loss: 23.74088 - diff: 40.39mlTrain batch 6/42 - 182.7ms/batch - loss: 23.56135 - diff: 40.23mlTrain batch 7/42 - 186.6ms/batch - loss: 25.57143 - diff: 40.97mlTrain batch 8/42 - 183.9ms/batch - loss: 25.90888 - diff: 41.49mlTrain batch 9/42 - 186.0ms/batch - loss: 25.18078 - diff: 41.26mlTrain batch 10/42 - 190.8ms/batch - loss: 26.64465 - diff: 42.31mlTrain batch 11/42 - 183.3ms/batch - loss: 26.41819 - diff: 42.32mlTrain batch 12/42 - 184.5ms/batch - loss: 27.43114 - diff: 42.59mlTrain batch 13/42 - 183.5ms/batch - loss: 26.85693 - diff: 42.43mlTrain batch 14/42 - 182.9ms/batch - loss: 27.13973 - diff: 42.51mlTrain batch 15/42 - 187.8ms/batch - loss: 27.39436 - diff: 42.89mlTrain batch 16/42 - 185.7ms/batch - loss: 27.62413 - diff: 42.91mlTrain batch 17/42 - 183.3ms/batch - loss: 27.95234 - diff: 43.19mlTrain batch 18/42 - 184.1ms/batch - loss: 28.19369 - diff: 43.34mlTrain batch 19/42 - 199.9ms/batch - loss: 27.83276 - diff: 43.13mlTrain batch 20/42 - 183.7ms/batch - loss: 27.51450 - diff: 42.95mlTrain batch 21/42 - 185.6ms/batch - loss: 28.07199 - diff: 43.30mlTrain batch 22/42 - 182.3ms/batch - loss: 28.02644 - diff: 43.37mlTrain batch 23/42 - 201.0ms/batch - loss: 27.63728 - diff: 43.22mlTrain batch 24/42 - 184.8ms/batch - loss: 27.35245 - diff: 43.10mlTrain batch 25/42 - 185.6ms/batch - loss: 27.36659 - diff: 43.15mlTrain batch 26/42 - 184.7ms/batch - loss: 27.55821 - diff: 43.27mlTrain batch 27/42 - 198.5ms/batch - loss: 27.44701 - diff: 43.31mlTrain batch 28/42 - 182.5ms/batch - loss: 27.27964 - diff: 43.32mlTrain batch 29/42 - 184.6ms/batch - loss: 27.68086 - diff: 43.49mlTrain batch 30/42 - 188.2ms/batch - loss: 27.57419 - diff: 43.51mlTrain batch 31/42 - 185.0ms/batch - loss: 27.35268 - diff: 43.36mlTrain batch 32/42 - 184.7ms/batch - loss: 27.22560 - diff: 43.31mlTrain batch 33/42 - 188.2ms/batch - loss: 27.07080 - diff: 43.25mlTrain batch 34/42 - 183.3ms/batch - loss: 26.94599 - diff: 43.13mlTrain batch 35/42 - 183.3ms/batch - loss: 26.85301 - diff: 43.10mlTrain batch 36/42 - 183.9ms/batch - loss: 26.77035 - diff: 43.11mlTrain batch 37/42 - 182.2ms/batch - loss: 26.67181 - diff: 43.11mlTrain batch 38/42 - 182.7ms/batch - loss: 26.71330 - diff: 43.20mlTrain batch 39/42 - 190.7ms/batch - loss: 26.64844 - diff: 43.24mlTrain batch 40/42 - 184.1ms/batch - loss: 27.02910 - diff: 43.34mlTrain batch 41/42 - 183.4ms/batch - loss: 26.91542 - diff: 43.32mlTrain batch 42/42 - 128.7ms/batch - loss: 27.26289 - diff: 43.41mlTrain batch 42/42 - 365.0s 128.7ms/batch - loss: 27.26289 - diff: 43.41ml
Test 142.3s: val_loss: 21.59291 - diff: 40.30ml
Saving new best model in models/checkpoints/preproc1_150x150_bySlices_dataset_full_Diastole_TimeAsDepth_1_SGD-0.001_DA2_best

Epoch 24: current best loss = 21.59291, at epoch 23
Train batch 1/42 - 192.5ms/batch - loss: 30.65156 - diff: 42.54mlTrain batch 2/42 - 207.2ms/batch - loss: 26.43439 - diff: 42.41mlTrain batch 3/42 - 188.7ms/batch - loss: 25.44006 - diff: 42.31mlTrain batch 4/42 - 185.0ms/batch - loss: 27.91371 - diff: 42.93mlTrain batch 5/42 - 183.8ms/batch - loss: 27.45491 - diff: 43.60mlTrain batch 6/42 - 183.9ms/batch - loss: 29.44577 - diff: 44.43mlTrain batch 7/42 - 182.8ms/batch - loss: 29.11220 - diff: 44.17mlTrain batch 8/42 - 182.8ms/batch - loss: 28.11329 - diff: 43.45mlTrain batch 9/42 - 185.6ms/batch - loss: 27.97289 - diff: 43.45mlTrain batch 10/42 - 183.8ms/batch - loss: 27.14310 - diff: 42.96mlTrain batch 11/42 - 190.5ms/batch - loss: 26.65560 - diff: 42.68mlTrain batch 12/42 - 185.3ms/batch - loss: 26.06618 - diff: 42.31mlTrain batch 13/42 - 187.5ms/batch - loss: 25.74857 - diff: 42.36mlTrain batch 14/42 - 183.7ms/batch - loss: 25.81973 - diff: 42.45mlTrain batch 15/42 - 183.8ms/batch - loss: 25.79814 - diff: 42.56mlTrain batch 16/42 - 182.7ms/batch - loss: 25.65382 - diff: 42.60mlTrain batch 17/42 - 186.2ms/batch - loss: 25.82964 - diff: 42.87mlTrain batch 18/42 - 183.4ms/batch - loss: 25.42508 - diff: 42.56mlTrain batch 19/42 - 187.1ms/batch - loss: 25.86470 - diff: 42.78mlTrain batch 20/42 - 182.7ms/batch - loss: 25.95083 - diff: 42.77mlTrain batch 21/42 - 200.4ms/batch - loss: 26.15581 - diff: 42.84mlTrain batch 22/42 - 182.9ms/batch - loss: 26.02190 - diff: 42.73mlTrain batch 23/42 - 187.6ms/batch - loss: 26.11799 - diff: 42.83mlTrain batch 24/42 - 182.8ms/batch - loss: 25.95827 - diff: 42.77mlTrain batch 25/42 - 211.6ms/batch - loss: 25.88971 - diff: 42.65mlTrain batch 26/42 - 186.0ms/batch - loss: 26.04865 - diff: 42.65mlTrain batch 27/42 - 186.2ms/batch - loss: 26.37011 - diff: 42.83mlTrain batch 28/42 - 182.3ms/batch - loss: 26.42921 - diff: 43.04mlTrain batch 29/42 - 192.0ms/batch - loss: 26.80849 - diff: 43.25mlTrain batch 30/42 - 185.2ms/batch - loss: 27.12854 - diff: 43.38mlTrain batch 31/42 - 185.6ms/batch - loss: 27.16890 - diff: 43.47mlTrain batch 32/42 - 183.4ms/batch - loss: 27.26732 - diff: 43.54mlTrain batch 33/42 - 183.5ms/batch - loss: 27.14294 - diff: 43.46mlTrain batch 34/42 - 182.3ms/batch - loss: 27.12933 - diff: 43.52mlTrain batch 35/42 - 187.7ms/batch - loss: 27.07691 - diff: 43.59mlTrain batch 36/42 - 185.5ms/batch - loss: 27.21250 - diff: 43.61mlTrain batch 37/42 - 183.7ms/batch - loss: 27.05659 - diff: 43.56mlTrain batch 38/42 - 183.6ms/batch - loss: 26.97529 - diff: 43.51mlTrain batch 39/42 - 186.2ms/batch - loss: 27.19848 - diff: 43.58mlTrain batch 40/42 - 183.2ms/batch - loss: 27.11441 - diff: 43.57mlTrain batch 41/42 - 185.9ms/batch - loss: 26.93256 - diff: 43.41mlTrain batch 42/42 - 128.5ms/batch - loss: 27.15415 - diff: 43.42mlTrain batch 42/42 - 369.9s 128.5ms/batch - loss: 27.15415 - diff: 43.42ml
Test 143.6s: val_loss: 22.49765 - diff: 41.27ml

Epoch 25: current best loss = 21.59291, at epoch 23
Train batch 1/42 - 189.1ms/batch - loss: 23.44502 - diff: 43.43mlTrain batch 2/42 - 185.6ms/batch - loss: 24.25799 - diff: 43.91mlTrain batch 3/42 - 189.5ms/batch - loss: 26.85894 - diff: 44.42mlTrain batch 4/42 - 198.6ms/batch - loss: 27.41761 - diff: 43.72mlTrain batch 5/42 - 184.3ms/batch - loss: 26.21602 - diff: 43.16mlTrain batch 6/42 - 183.5ms/batch - loss: 25.24402 - diff: 42.12mlTrain batch 7/42 - 183.8ms/batch - loss: 24.45532 - diff: 41.72mlTrain batch 8/42 - 183.2ms/batch - loss: 25.58700 - diff: 42.24mlTrain batch 9/42 - 189.4ms/batch - loss: 25.95139 - diff: 42.36mlTrain batch 10/42 - 184.8ms/batch - loss: 26.44696 - diff: 42.96mlTrain batch 11/42 - 183.1ms/batch - loss: 26.06796 - diff: 42.95mlTrain batch 12/42 - 183.5ms/batch - loss: 25.52956 - diff: 42.67mlTrain batch 13/42 - 182.8ms/batch - loss: 26.13331 - diff: 42.94mlTrain batch 14/42 - 183.3ms/batch - loss: 26.65050 - diff: 43.24mlTrain batch 15/42 - 186.9ms/batch - loss: 26.41169 - diff: 43.23mlTrain batch 16/42 - 183.9ms/batch - loss: 26.26810 - diff: 43.29mlTrain batch 17/42 - 188.3ms/batch - loss: 26.29952 - diff: 43.55mlTrain batch 18/42 - 182.7ms/batch - loss: 26.09923 - diff: 43.44mlTrain batch 19/42 - 199.8ms/batch - loss: 26.08925 - diff: 43.43mlTrain batch 20/42 - 184.5ms/batch - loss: 26.21542 - diff: 43.56mlTrain batch 21/42 - 186.1ms/batch - loss: 26.40405 - diff: 43.74mlTrain batch 22/42 - 184.7ms/batch - loss: 26.13727 - diff: 43.54mlTrain batch 23/42 - 200.4ms/batch - loss: 25.82761 - diff: 43.23mlTrain batch 24/42 - 183.5ms/batch - loss: 25.96428 - diff: 43.24mlTrain batch 25/42 - 185.9ms/batch - loss: 25.96343 - diff: 43.31mlTrain batch 26/42 - 183.5ms/batch - loss: 25.97885 - diff: 43.38mlTrain batch 27/42 - 202.5ms/batch - loss: 26.71755 - diff: 43.61mlTrain batch 28/42 - 185.0ms/batch - loss: 26.52981 - diff: 43.38mlTrain batch 29/42 - 186.1ms/batch - loss: 27.13469 - diff: 43.60mlTrain batch 30/42 - 183.4ms/batch - loss: 27.25007 - diff: 43.69mlTrain batch 31/42 - 183.8ms/batch - loss: 27.29007 - diff: 43.81mlTrain batch 32/42 - 183.0ms/batch - loss: 27.20122 - diff: 43.81mlTrain batch 33/42 - 189.5ms/batch - loss: 27.11259 - diff: 43.82mlTrain batch 34/42 - 185.5ms/batch - loss: 26.98754 - diff: 43.69mlTrain batch 35/42 - 183.7ms/batch - loss: 26.91579 - diff: 43.68mlTrain batch 36/42 - 183.3ms/batch - loss: 26.83310 - diff: 43.46mlTrain batch 37/42 - 183.0ms/batch - loss: 26.90667 - diff: 43.53mlTrain batch 38/42 - 184.1ms/batch - loss: 26.87409 - diff: 43.52mlTrain batch 39/42 - 188.2ms/batch - loss: 26.78275 - diff: 43.48mlTrain batch 40/42 - 183.7ms/batch - loss: 26.60948 - diff: 43.35mlTrain batch 41/42 - 182.8ms/batch - loss: 26.76945 - diff: 43.43mlTrain batch 42/42 - 127.8ms/batch - loss: 26.89180 - diff: 43.37mlTrain batch 42/42 - 364.8s 127.8ms/batch - loss: 26.89180 - diff: 43.37ml
Test 137.1s: val_loss: 27.65375 - diff: 47.46ml

Epoch 26: current best loss = 21.59291, at epoch 23
Train batch 1/42 - 189.8ms/batch - loss: 26.08441 - diff: 45.48mlTrain batch 2/42 - 184.2ms/batch - loss: 28.85361 - diff: 45.46mlTrain batch 3/42 - 184.2ms/batch - loss: 25.24575 - diff: 43.03mlTrain batch 4/42 - 183.2ms/batch - loss: 25.45322 - diff: 43.50mlTrain batch 5/42 - 183.6ms/batch - loss: 28.74856 - diff: 45.37mlTrain batch 6/42 - 184.1ms/batch - loss: 27.70955 - diff: 44.67mlTrain batch 7/42 - 186.3ms/batch - loss: 26.60139 - diff: 43.75mlTrain batch 8/42 - 183.3ms/batch - loss: 26.87941 - diff: 43.33mlTrain batch 9/42 - 183.9ms/batch - loss: 26.56358 - diff: 42.91mlTrain batch 10/42 - 182.8ms/batch - loss: 26.67625 - diff: 42.80mlTrain batch 11/42 - 183.4ms/batch - loss: 27.29980 - diff: 43.11mlTrain batch 12/42 - 183.3ms/batch - loss: 27.29902 - diff: 43.38mlTrain batch 13/42 - 189.5ms/batch - loss: 27.10327 - diff: 43.41mlTrain batch 14/42 - 183.6ms/batch - loss: 27.12308 - diff: 43.42mlTrain batch 15/42 - 182.8ms/batch - loss: 27.35420 - diff: 43.53mlTrain batch 16/42 - 184.1ms/batch - loss: 27.55802 - diff: 43.49mlTrain batch 17/42 - 183.6ms/batch - loss: 27.46985 - diff: 43.52mlTrain batch 18/42 - 182.5ms/batch - loss: 27.52294 - diff: 43.75mlTrain batch 19/42 - 204.9ms/batch - loss: 27.54133 - diff: 43.78mlTrain batch 20/42 - 184.0ms/batch - loss: 27.35572 - diff: 43.76mlTrain batch 21/42 - 185.6ms/batch - loss: 27.25098 - diff: 43.51mlTrain batch 22/42 - 182.7ms/batch - loss: 27.12268 - diff: 43.50mlTrain batch 23/42 - 206.0ms/batch - loss: 27.22643 - diff: 43.61mlTrain batch 24/42 - 184.5ms/batch - loss: 27.22758 - diff: 43.64mlTrain batch 25/42 - 191.5ms/batch - loss: 27.05691 - diff: 43.55mlTrain batch 26/42 - 182.9ms/batch - loss: 26.72168 - diff: 43.34mlTrain batch 27/42 - 203.9ms/batch - loss: 27.34782 - diff: 43.59mlTrain batch 28/42 - 183.9ms/batch - loss: 27.52592 - diff: 43.59mlTrain batch 29/42 - 186.3ms/batch - loss: 27.46114 - diff: 43.65mlTrain batch 30/42 - 183.5ms/batch - loss: 27.14909 - diff: 43.44mlTrain batch 31/42 - 185.7ms/batch - loss: 27.12637 - diff: 43.45mlTrain batch 32/42 - 183.4ms/batch - loss: 26.85513 - diff: 43.26mlTrain batch 33/42 - 188.0ms/batch - loss: 27.35071 - diff: 43.52mlTrain batch 34/42 - 184.9ms/batch - loss: 27.20655 - diff: 43.50mlTrain batch 35/42 - 184.9ms/batch - loss: 27.08644 - diff: 43.52mlTrain batch 36/42 - 183.2ms/batch - loss: 27.16930 - diff: 43.68mlTrain batch 37/42 - 183.3ms/batch - loss: 27.53960 - diff: 43.82mlTrain batch 38/42 - 182.4ms/batch - loss: 27.64471 - diff: 43.81mlTrain batch 39/42 - 188.1ms/batch - loss: 27.45196 - diff: 43.66mlTrain batch 40/42 - 187.3ms/batch - loss: 27.30711 - diff: 43.62mlTrain batch 41/42 - 182.9ms/batch - loss: 27.12589 - diff: 43.50mlTrain batch 42/42 - 128.3ms/batch - loss: 27.28101 - diff: 43.41mlTrain batch 42/42 - 361.3s 128.3ms/batch - loss: 27.28101 - diff: 43.41ml
Test 137.7s: val_loss: 63.44191 - diff: 71.43ml

Epoch 27: current best loss = 21.59291, at epoch 23
Train batch 1/42 - 189.2ms/batch - loss: 26.23470 - diff: 46.11mlTrain batch 2/42 - 182.1ms/batch - loss: 30.70213 - diff: 47.36mlTrain batch 3/42 - 190.4ms/batch - loss: 29.07375 - diff: 47.06mlTrain batch 4/42 - 190.0ms/batch - loss: 27.10018 - diff: 45.72mlTrain batch 5/42 - 185.3ms/batch - loss: 26.78469 - diff: 45.14mlTrain batch 6/42 - 183.4ms/batch - loss: 28.49789 - diff: 45.37mlTrain batch 7/42 - 186.8ms/batch - loss: 28.41442 - diff: 45.12mlTrain batch 8/42 - 184.7ms/batch - loss: 31.01635 - diff: 46.39mlTrain batch 9/42 - 192.0ms/batch - loss: 31.54735 - diff: 47.23mlTrain batch 10/42 - 184.2ms/batch - loss: 30.50366 - diff: 46.61mlTrain batch 11/42 - 183.1ms/batch - loss: 30.37175 - diff: 46.70mlTrain batch 12/42 - 183.3ms/batch - loss: 30.35493 - diff: 46.15mlTrain batch 13/42 - 182.6ms/batch - loss: 30.77890 - diff: 46.26mlTrain batch 14/42 - 183.2ms/batch - loss: 30.38618 - diff: 46.21mlTrain batch 15/42 - 188.2ms/batch - loss: 29.69209 - diff: 45.77mlTrain batch 16/42 - 184.7ms/batch - loss: 29.81064 - diff: 45.83mlTrain batch 17/42 - 185.9ms/batch - loss: 29.77724 - diff: 46.07mlTrain batch 18/42 - 182.5ms/batch - loss: 29.62314 - diff: 45.72mlTrain batch 19/42 - 199.7ms/batch - loss: 29.37075 - diff: 45.60mlTrain batch 20/42 - 184.0ms/batch - loss: 29.88026 - diff: 45.84mlTrain batch 21/42 - 186.1ms/batch - loss: 30.70241 - diff: 45.96mlTrain batch 22/42 - 182.4ms/batch - loss: 31.04819 - diff: 46.00mlTrain batch 23/42 - 203.2ms/batch - loss: 31.00198 - diff: 46.10mlTrain batch 24/42 - 184.4ms/batch - loss: 31.02460 - diff: 46.18mlTrain batch 25/42 - 187.9ms/batch - loss: 31.69545 - diff: 46.50mlTrain batch 26/42 - 182.9ms/batch - loss: 31.58281 - diff: 46.63mlTrain batch 27/42 - 191.6ms/batch - loss: 31.39756 - diff: 46.55mlTrain batch 28/42 - 184.7ms/batch - loss: 30.93757 - diff: 46.22mlTrain batch 29/42 - 185.6ms/batch - loss: 30.74180 - diff: 46.18mlTrain batch 30/42 - 184.7ms/batch - loss: 30.45201 - diff: 46.00mlTrain batch 31/42 - 183.9ms/batch - loss: 30.29027 - diff: 45.89mlTrain batch 32/42 - 183.9ms/batch - loss: 30.16401 - diff: 45.89mlTrain batch 33/42 - 187.1ms/batch - loss: 30.15073 - diff: 45.97mlTrain batch 34/42 - 182.6ms/batch - loss: 30.12735 - diff: 46.02mlTrain batch 35/42 - 183.3ms/batch - loss: 29.98533 - diff: 45.91mlTrain batch 36/42 - 183.7ms/batch - loss: 29.72867 - diff: 45.77mlTrain batch 37/42 - 182.8ms/batch - loss: 29.51415 - diff: 45.64mlTrain batch 38/42 - 183.3ms/batch - loss: 29.19905 - diff: 45.43mlTrain batch 39/42 - 188.4ms/batch - loss: 29.05146 - diff: 45.31mlTrain batch 40/42 - 184.2ms/batch - loss: 28.87506 - diff: 45.23mlTrain batch 41/42 - 197.3ms/batch - loss: 28.64655 - diff: 45.08mlTrain batch 42/42 - 128.6ms/batch - loss: 28.70715 - diff: 44.99mlTrain batch 42/42 - 366.0s 128.6ms/batch - loss: 28.70715 - diff: 44.99ml
Test 137.8s: val_loss: 20.77429 - diff: 38.65ml
Saving new best model in models/checkpoints/preproc1_150x150_bySlices_dataset_full_Diastole_TimeAsDepth_1_SGD-0.001_DA2_best

Epoch 28: current best loss = 20.77429, at epoch 27
Train batch 1/42 - 184.2ms/batch - loss: 31.36473 - diff: 47.82mlTrain batch 2/42 - 183.2ms/batch - loss: 28.57304 - diff: 43.75mlTrain batch 3/42 - 182.7ms/batch - loss: 26.93025 - diff: 43.41mlTrain batch 4/42 - 183.6ms/batch - loss: 29.46522 - diff: 44.24mlTrain batch 5/42 - 189.4ms/batch - loss: 28.91587 - diff: 44.75mlTrain batch 6/42 - 186.1ms/batch - loss: 27.08013 - diff: 43.75mlTrain batch 7/42 - 182.6ms/batch - loss: 28.64779 - diff: 44.24mlTrain batch 8/42 - 182.9ms/batch - loss: 27.74609 - diff: 43.77mlTrain batch 9/42 - 183.2ms/batch - loss: 27.40890 - diff: 43.68mlTrain batch 10/42 - 183.4ms/batch - loss: 26.43181 - diff: 42.94mlTrain batch 11/42 - 190.8ms/batch - loss: 25.92947 - diff: 42.73mlTrain batch 12/42 - 185.4ms/batch - loss: 26.28113 - diff: 42.80mlTrain batch 13/42 - 185.2ms/batch - loss: 25.54789 - diff: 42.22mlTrain batch 14/42 - 183.2ms/batch - loss: 25.86395 - diff: 42.37mlTrain batch 15/42 - 182.5ms/batch - loss: 25.50122 - diff: 42.10mlTrain batch 16/42 - 182.9ms/batch - loss: 25.51892 - diff: 42.19mlTrain batch 17/42 - 199.3ms/batch - loss: 25.74636 - diff: 42.15mlTrain batch 18/42 - 184.7ms/batch - loss: 25.44708 - diff: 42.04mlTrain batch 19/42 - 186.3ms/batch - loss: 25.41532 - diff: 42.11mlTrain batch 20/42 - 182.6ms/batch - loss: 25.44361 - diff: 42.17mlTrain batch 21/42 - 198.2ms/batch - loss: 25.82495 - diff: 42.43mlTrain batch 22/42 - 182.3ms/batch - loss: 25.72815 - diff: 42.50mlTrain batch 23/42 - 185.3ms/batch - loss: 25.72503 - diff: 42.68mlTrain batch 24/42 - 182.7ms/batch - loss: 25.67578 - diff: 42.66mlTrain batch 25/42 - 200.9ms/batch - loss: 25.96122 - diff: 42.75mlTrain batch 26/42 - 184.6ms/batch - loss: 25.86204 - diff: 42.65mlTrain batch 27/42 - 186.8ms/batch - loss: 26.07882 - diff: 42.57mlTrain batch 28/42 - 182.8ms/batch - loss: 26.07635 - diff: 42.64mlTrain batch 29/42 - 185.7ms/batch - loss: 25.89898 - diff: 42.55mlTrain batch 30/42 - 183.3ms/batch - loss: 26.08198 - diff: 42.59mlTrain batch 31/42 - 190.4ms/batch - loss: 26.00663 - diff: 42.59mlTrain batch 32/42 - 187.5ms/batch - loss: 25.97523 - diff: 42.63mlTrain batch 33/42 - 182.9ms/batch - loss: 25.81815 - diff: 42.60mlTrain batch 34/42 - 182.7ms/batch - loss: 25.94355 - diff: 42.67mlTrain batch 35/42 - 183.6ms/batch - loss: 25.97599 - diff: 42.66mlTrain batch 36/42 - 182.6ms/batch - loss: 25.91675 - diff: 42.67mlTrain batch 37/42 - 186.5ms/batch - loss: 26.12960 - diff: 42.83mlTrain batch 38/42 - 183.9ms/batch - loss: 25.99647 - diff: 42.77mlTrain batch 39/42 - 183.4ms/batch - loss: 25.99713 - diff: 42.78mlTrain batch 40/42 - 184.0ms/batch - loss: 26.04495 - diff: 42.76mlTrain batch 41/42 - 189.9ms/batch - loss: 26.25249 - diff: 42.81mlTrain batch 42/42 - 137.2ms/batch - loss: 26.71140 - diff: 42.83mlTrain batch 42/42 - 365.6s 137.2ms/batch - loss: 26.71140 - diff: 42.83ml
Test 140.9s: val_loss: 21.96739 - diff: 39.36ml

Epoch 29: current best loss = 20.77429, at epoch 27
Train batch 1/42 - 188.4ms/batch - loss: 25.09165 - diff: 45.10mlTrain batch 2/42 - 183.1ms/batch - loss: 23.19899 - diff: 43.46mlTrain batch 3/42 - 183.4ms/batch - loss: 23.05724 - diff: 42.58mlTrain batch 4/42 - 184.2ms/batch - loss: 22.74717 - diff: 42.22mlTrain batch 5/42 - 183.3ms/batch - loss: 23.21879 - diff: 41.98mlTrain batch 6/42 - 183.6ms/batch - loss: 23.56954 - diff: 41.97mlTrain batch 7/42 - 188.0ms/batch - loss: 23.24260 - diff: 41.46mlTrain batch 8/42 - 184.3ms/batch - loss: 23.57908 - diff: 41.75mlTrain batch 9/42 - 185.2ms/batch - loss: 23.01625 - diff: 41.45mlTrain batch 10/42 - 183.0ms/batch - loss: 23.24672 - diff: 41.77mlTrain batch 11/42 - 184.1ms/batch - loss: 25.03537 - diff: 42.54mlTrain batch 12/42 - 183.5ms/batch - loss: 24.42473 - diff: 42.08mlTrain batch 13/42 - 183.7ms/batch - loss: 24.93152 - diff: 42.16mlTrain batch 14/42 - 182.4ms/batch - loss: 25.19102 - diff: 42.51mlTrain batch 15/42 - 186.8ms/batch - loss: 24.96348 - diff: 42.46mlTrain batch 16/42 - 183.0ms/batch - loss: 24.81766 - diff: 42.37mlTrain batch 17/42 - 185.9ms/batch - loss: 24.68462 - diff: 42.23mlTrain batch 18/42 - 182.9ms/batch - loss: 24.72743 - diff: 42.24mlTrain batch 19/42 - 200.1ms/batch - loss: 24.69020 - diff: 42.07mlTrain batch 20/42 - 184.3ms/batch - loss: 25.47133 - diff: 42.42mlTrain batch 21/42 - 187.8ms/batch - loss: 25.55960 - diff: 42.37mlTrain batch 22/42 - 182.7ms/batch - loss: 25.62441 - diff: 42.54mlTrain batch 23/42 - 203.4ms/batch - loss: 25.90409 - diff: 42.65mlTrain batch 24/42 - 183.8ms/batch - loss: 26.21714 - diff: 42.75mlTrain batch 25/42 - 185.1ms/batch - loss: 26.43456 - diff: 43.04mlTrain batch 26/42 - 182.5ms/batch - loss: 26.70139 - diff: 43.27mlTrain batch 27/42 - 202.4ms/batch - loss: 26.54263 - diff: 43.18mlTrain batch 28/42 - 182.8ms/batch - loss: 26.52025 - diff: 43.23mlTrain batch 29/42 - 191.2ms/batch - loss: 27.10000 - diff: 43.64mlTrain batch 30/42 - 184.4ms/batch - loss: 27.14409 - diff: 43.78mlTrain batch 31/42 - 186.1ms/batch - loss: 26.96325 - diff: 43.66mlTrain batch 32/42 - 183.4ms/batch - loss: 26.68490 - diff: 43.48mlTrain batch 33/42 - 184.5ms/batch - loss: 27.03981 - diff: 43.59mlTrain batch 34/42 - 182.8ms/batch - loss: 27.22722 - diff: 43.76mlTrain batch 35/42 - 189.3ms/batch - loss: 27.26451 - diff: 43.84mlTrain batch 36/42 - 185.7ms/batch - loss: 27.03788 - diff: 43.72mlTrain batch 37/42 - 182.5ms/batch - loss: 27.01588 - diff: 43.75mlTrain batch 38/42 - 182.5ms/batch - loss: 27.11460 - diff: 43.81mlTrain batch 39/42 - 182.9ms/batch - loss: 27.15807 - diff: 43.79mlTrain batch 40/42 - 184.0ms/batch - loss: 27.18812 - diff: 43.80mlTrain batch 41/42 - 183.7ms/batch - loss: 27.16704 - diff: 43.82mlTrain batch 42/42 - 128.1ms/batch - loss: 27.51063 - diff: 43.83mlTrain batch 42/42 - 365.7s 128.1ms/batch - loss: 27.51063 - diff: 43.83ml
Test 136.0s: val_loss: 23.41150 - diff: 41.63ml

Epoch 30: current best loss = 20.77429, at epoch 27
Train batch 1/42 - 190.5ms/batch - loss: 19.97404 - diff: 39.17mlTrain batch 2/42 - 184.2ms/batch - loss: 23.45701 - diff: 42.57mlTrain batch 3/42 - 189.3ms/batch - loss: 23.54908 - diff: 42.63mlTrain batch 4/42 - 185.7ms/batch - loss: 24.16969 - diff: 43.39mlTrain batch 5/42 - 183.5ms/batch - loss: 25.69507 - diff: 43.18mlTrain batch 6/42 - 182.3ms/batch - loss: 25.62111 - diff: 43.15mlTrain batch 7/42 - 184.3ms/batch - loss: 25.04044 - diff: 42.48mlTrain batch 8/42 - 183.9ms/batch - loss: 25.30071 - diff: 42.93mlTrain batch 9/42 - 188.9ms/batch - loss: 24.93364 - diff: 42.85mlTrain batch 10/42 - 184.4ms/batch - loss: 26.75532 - diff: 43.92mlTrain batch 11/42 - 183.3ms/batch - loss: 26.45493 - diff: 43.83mlTrain batch 12/42 - 184.0ms/batch - loss: 26.06054 - diff: 43.65mlTrain batch 13/42 - 182.6ms/batch - loss: 26.03197 - diff: 43.53mlTrain batch 14/42 - 183.9ms/batch - loss: 26.07960 - diff: 43.39mlTrain batch 15/42 - 188.4ms/batch - loss: 25.81732 - diff: 43.08mlTrain batch 16/42 - 183.8ms/batch - loss: 25.83734 - diff: 43.09mlTrain batch 17/42 - 185.4ms/batch - loss: 25.85650 - diff: 43.10mlTrain batch 18/42 - 183.7ms/batch - loss: 25.94970 - diff: 43.08mlTrain batch 19/42 - 198.9ms/batch - loss: 26.13963 - diff: 43.23mlTrain batch 20/42 - 182.4ms/batch - loss: 25.73124 - diff: 42.91mlTrain batch 21/42 - 187.0ms/batch - loss: 25.27789 - diff: 42.53mlTrain batch 22/42 - 182.5ms/batch - loss: 25.18100 - diff: 42.59mlTrain batch 23/42 - 209.8ms/batch - loss: 25.29316 - diff: 42.73mlTrain batch 24/42 - 186.4ms/batch - loss: 25.49576 - diff: 42.71mlTrain batch 25/42 - 187.5ms/batch - loss: 25.85517 - diff: 43.06mlTrain batch 26/42 - 183.0ms/batch - loss: 25.87437 - diff: 43.25mlTrain batch 27/42 - 191.2ms/batch - loss: 26.16211 - diff: 43.18mlTrain batch 28/42 - 184.7ms/batch - loss: 26.21977 - diff: 43.20mlTrain batch 29/42 - 188.5ms/batch - loss: 26.39446 - diff: 43.35mlTrain batch 30/42 - 199.5ms/batch - loss: 26.39195 - diff: 43.38mlTrain batch 31/42 - 185.0ms/batch - loss: 26.54918 - diff: 43.42mlTrain batch 32/42 - 183.8ms/batch - loss: 26.44831 - diff: 43.40mlTrain batch 33/42 - 190.1ms/batch - loss: 26.75260 - diff: 43.50mlTrain batch 34/42 - 186.1ms/batch - loss: 26.46144 - diff: 43.29mlTrain batch 35/42 - 184.9ms/batch - loss: 26.37535 - diff: 43.27mlTrain batch 36/42 - 183.7ms/batch - loss: 26.45166 - diff: 43.40mlTrain batch 37/42 - 185.7ms/batch - loss: 26.64095 - diff: 43.47mlTrain batch 38/42 - 183.6ms/batch - loss: 26.58112 - diff: 43.47mlTrain batch 39/42 - 183.6ms/batch - loss: 27.01973 - diff: 43.57mlTrain batch 40/42 - 184.1ms/batch - loss: 27.05699 - diff: 43.51mlTrain batch 41/42 - 187.7ms/batch - loss: 26.92820 - diff: 43.44mlTrain batch 42/42 - 129.7ms/batch - loss: 26.98673 - diff: 43.39mlTrain batch 42/42 - 364.1s 129.7ms/batch - loss: 26.98673 - diff: 43.39ml
Test 137.9s: val_loss: 21.86493 - diff: 39.47ml

Epoch 31: current best loss = 20.77429, at epoch 27
Train batch 1/42 - 189.1ms/batch - loss: 23.27100 - diff: 41.77mlTrain batch 2/42 - 183.9ms/batch - loss: 33.37310 - diff: 45.10mlTrain batch 3/42 - 185.3ms/batch - loss: 30.67223 - diff: 43.94mlTrain batch 4/42 - 182.6ms/batch - loss: 27.27095 - diff: 42.04mlTrain batch 5/42 - 190.0ms/batch - loss: 25.37209 - diff: 41.19mlTrain batch 6/42 - 185.9ms/batch - loss: 25.47919 - diff: 41.76mlTrain batch 7/42 - 184.0ms/batch - loss: 24.54347 - diff: 41.36mlTrain batch 8/42 - 183.5ms/batch - loss: 23.55513 - diff: 40.93mlTrain batch 9/42 - 185.5ms/batch - loss: 23.96164 - diff: 41.39mlTrain batch 10/42 - 183.4ms/batch - loss: 23.65243 - diff: 41.27mlTrain batch 11/42 - 190.3ms/batch - loss: 23.92940 - diff: 41.65mlTrain batch 12/42 - 184.2ms/batch - loss: 23.81152 - diff: 41.64mlTrain batch 13/42 - 183.9ms/batch - loss: 24.40992 - diff: 41.71mlTrain batch 14/42 - 183.2ms/batch - loss: 24.50552 - diff: 41.97mlTrain batch 15/42 - 184.3ms/batch - loss: 24.94753 - diff: 42.24mlTrain batch 16/42 - 182.7ms/batch - loss: 25.13463 - diff: 42.30mlTrain batch 17/42 - 199.7ms/batch - loss: 24.91406 - diff: 42.23mlTrain batch 18/42 - 183.0ms/batch - loss: 24.84422 - diff: 42.17mlTrain batch 19/42 - 185.7ms/batch - loss: 25.12689 - diff: 42.51mlTrain batch 20/42 - 182.7ms/batch - loss: 25.06656 - diff: 42.52mlTrain batch 21/42 - 201.8ms/batch - loss: 25.38298 - diff: 42.67mlTrain batch 22/42 - 183.7ms/batch - loss: 25.13990 - diff: 42.47mlTrain batch 23/42 - 189.5ms/batch - loss: 24.70451 - diff: 42.07mlTrain batch 24/42 - 183.0ms/batch - loss: 24.75525 - diff: 42.15mlTrain batch 25/42 - 207.5ms/batch - loss: 25.19618 - diff: 42.16mlTrain batch 26/42 - 185.0ms/batch - loss: 25.68387 - diff: 42.33mlTrain batch 27/42 - 192.9ms/batch - loss: 25.79440 - diff: 42.31mlTrain batch 28/42 - 183.0ms/batch - loss: 25.77087 - diff: 42.35mlTrain batch 29/42 - 197.9ms/batch - loss: 25.65227 - diff: 42.29mlTrain batch 30/42 - 183.4ms/batch - loss: 25.42959 - diff: 42.21mlTrain batch 31/42 - 207.7ms/batch - loss: 25.29391 - diff: 42.14mlTrain batch 32/42 - 201.3ms/batch - loss: 25.13092 - diff: 42.07mlTrain batch 33/42 - 184.4ms/batch - loss: 25.29391 - diff: 42.23mlTrain batch 34/42 - 184.9ms/batch - loss: 25.22906 - diff: 42.26mlTrain batch 35/42 - 184.2ms/batch - loss: 25.21530 - diff: 42.35mlTrain batch 36/42 - 183.3ms/batch - loss: 25.11894 - diff: 42.34mlTrain batch 37/42 - 189.3ms/batch - loss: 25.31306 - diff: 42.36mlTrain batch 38/42 - 184.2ms/batch - loss: 25.41382 - diff: 42.50mlTrain batch 39/42 - 202.1ms/batch - loss: 25.30844 - diff: 42.45mlTrain batch 40/42 - 183.3ms/batch - loss: 25.92989 - diff: 42.62mlTrain batch 41/42 - 183.5ms/batch - loss: 25.79834 - diff: 42.58mlTrain batch 42/42 - 128.6ms/batch - loss: 25.93337 - diff: 42.56mlTrain batch 42/42 - 368.3s 128.6ms/batch - loss: 25.93337 - diff: 42.56ml
Test 140.0s: val_loss: 21.05499 - diff: 40.24ml

Epoch 32: current best loss = 20.77429, at epoch 27
Train batch 1/42 - 189.5ms/batch - loss: 25.79330 - diff: 45.31mlTrain batch 2/42 - 183.6ms/batch - loss: 28.16361 - diff: 46.45mlTrain batch 3/42 - 189.2ms/batch - loss: 27.89245 - diff: 45.42mlTrain batch 4/42 - 183.5ms/batch - loss: 26.02492 - diff: 44.09mlTrain batch 5/42 - 183.8ms/batch - loss: 25.39487 - diff: 43.86mlTrain batch 6/42 - 182.5ms/batch - loss: 25.55002 - diff: 44.18mlTrain batch 7/42 - 183.1ms/batch - loss: 24.65426 - diff: 43.53mlTrain batch 8/42 - 183.7ms/batch - loss: 24.83627 - diff: 43.90mlTrain batch 9/42 - 188.5ms/batch - loss: 26.03538 - diff: 44.16mlTrain batch 10/42 - 184.2ms/batch - loss: 25.67180 - diff: 43.83mlTrain batch 11/42 - 182.6ms/batch - loss: 25.49533 - diff: 43.71mlTrain batch 12/42 - 184.8ms/batch - loss: 26.86788 - diff: 44.20mlTrain batch 13/42 - 183.1ms/batch - loss: 28.46305 - diff: 44.89mlTrain batch 14/42 - 182.9ms/batch - loss: 28.04762 - diff: 44.72mlTrain batch 15/42 - 188.0ms/batch - loss: 27.83804 - diff: 44.60mlTrain batch 16/42 - 184.9ms/batch - loss: 27.86419 - diff: 44.60mlTrain batch 17/42 - 200.8ms/batch - loss: 28.15094 - diff: 44.62mlTrain batch 18/42 - 183.5ms/batch - loss: 28.40796 - diff: 44.82mlTrain batch 19/42 - 207.8ms/batch - loss: 28.37520 - diff: 44.77mlTrain batch 20/42 - 183.6ms/batch - loss: 28.98478 - diff: 45.20mlTrain batch 21/42 - 185.7ms/batch - loss: 29.01764 - diff: 45.34mlTrain batch 22/42 - 182.8ms/batch - loss: 29.28554 - diff: 45.42mlTrain batch 23/42 - 207.5ms/batch - loss: 29.28802 - diff: 45.30mlTrain batch 24/42 - 184.8ms/batch - loss: 29.33459 - diff: 45.21mlTrain batch 25/42 - 187.3ms/batch - loss: 29.45332 - diff: 45.12mlTrain batch 26/42 - 182.9ms/batch - loss: 29.40173 - diff: 44.92mlTrain batch 27/42 - 190.9ms/batch - loss: 29.43418 - diff: 44.94mlTrain batch 28/42 - 184.0ms/batch - loss: 29.06242 - diff: 44.77mlTrain batch 29/42 - 183.3ms/batch - loss: 28.93097 - diff: 44.63mlTrain batch 30/42 - 183.3ms/batch - loss: 28.66702 - diff: 44.52mlTrain batch 31/42 - 183.6ms/batch - loss: 28.50642 - diff: 44.46mlTrain batch 32/42 - 188.3ms/batch - loss: 28.56666 - diff: 44.44mlTrain batch 33/42 - 191.2ms/batch - loss: 28.26761 - diff: 44.21mlTrain batch 34/42 - 185.3ms/batch - loss: 28.14153 - diff: 44.19mlTrain batch 35/42 - 184.4ms/batch - loss: 28.08190 - diff: 44.14mlTrain batch 36/42 - 183.5ms/batch - loss: 27.99445 - diff: 44.10mlTrain batch 37/42 - 183.6ms/batch - loss: 27.94148 - diff: 44.08mlTrain batch 38/42 - 182.8ms/batch - loss: 27.69567 - diff: 43.93mlTrain batch 39/42 - 195.6ms/batch - loss: 27.67326 - diff: 43.97mlTrain batch 40/42 - 184.1ms/batch - loss: 27.54068 - diff: 43.91mlTrain batch 41/42 - 184.1ms/batch - loss: 27.62778 - diff: 43.88mlTrain batch 42/42 - 129.2ms/batch - loss: 27.62223 - diff: 43.76mlTrain batch 42/42 - 368.3s 129.2ms/batch - loss: 27.62223 - diff: 43.76ml
Test 140.8s: val_loss: 42.77199 - diff: 61.27ml

Epoch 33: current best loss = 20.77429, at epoch 27
Train batch 1/42 - 184.9ms/batch - loss: 21.99132 - diff: 39.52mlTrain batch 2/42 - 183.1ms/batch - loss: 22.86925 - diff: 41.13mlTrain batch 3/42 - 188.5ms/batch - loss: 22.05758 - diff: 38.99mlTrain batch 4/42 - 184.3ms/batch - loss: 22.55432 - diff: 40.28mlTrain batch 5/42 - 183.8ms/batch - loss: 23.93892 - diff: 40.96mlTrain batch 6/42 - 183.6ms/batch - loss: 25.22141 - diff: 41.87mlTrain batch 7/42 - 183.2ms/batch - loss: 25.09336 - diff: 42.04mlTrain batch 8/42 - 183.0ms/batch - loss: 25.42567 - diff: 41.58mlTrain batch 9/42 - 188.5ms/batch - loss: 27.86147 - diff: 42.34mlTrain batch 10/42 - 184.7ms/batch - loss: 27.04395 - diff: 41.94mlTrain batch 11/42 - 183.2ms/batch - loss: 26.80694 - diff: 42.35mlTrain batch 12/42 - 183.8ms/batch - loss: 25.99996 - diff: 42.00mlTrain batch 13/42 - 182.9ms/batch - loss: 25.73392 - diff: 41.99mlTrain batch 14/42 - 182.1ms/batch - loss: 25.57371 - diff: 42.07mlTrain batch 15/42 - 189.2ms/batch - loss: 25.73322 - diff: 42.32mlTrain batch 16/42 - 183.9ms/batch - loss: 25.96057 - diff: 42.44mlTrain batch 17/42 - 185.7ms/batch - loss: 25.84915 - diff: 42.30mlTrain batch 18/42 - 182.4ms/batch - loss: 25.62307 - diff: 42.27mlTrain batch 19/42 - 199.9ms/batch - loss: 25.37021 - diff: 42.20mlTrain batch 20/42 - 184.0ms/batch - loss: 25.65807 - diff: 42.42mlTrain batch 21/42 - 188.4ms/batch - loss: 25.50567 - diff: 42.37mlTrain batch 22/42 - 182.8ms/batch - loss: 25.06056 - diff: 42.07mlTrain batch 23/42 - 202.9ms/batch - loss: 24.96786 - diff: 42.07mlTrain batch 24/42 - 184.3ms/batch - loss: 24.86552 - diff: 42.00mlTrain batch 25/42 - 192.0ms/batch - loss: 24.85665 - diff: 42.00mlTrain batch 26/42 - 182.4ms/batch - loss: 25.04182 - diff: 42.04mlTrain batch 27/42 - 191.5ms/batch - loss: 24.98789 - diff: 42.05mlTrain batch 28/42 - 184.6ms/batch - loss: 25.27842 - diff: 42.37mlTrain batch 29/42 - 187.4ms/batch - loss: 25.27759 - diff: 42.38mlTrain batch 30/42 - 184.1ms/batch - loss: 25.26360 - diff: 42.46mlTrain batch 31/42 - 184.3ms/batch - loss: 25.49022 - diff: 42.67mlTrain batch 32/42 - 183.8ms/batch - loss: 25.21791 - diff: 42.47mlTrain batch 33/42 - 192.2ms/batch - loss: 25.04606 - diff: 42.35mlTrain batch 34/42 - 184.7ms/batch - loss: 25.34369 - diff: 42.46mlTrain batch 35/42 - 184.8ms/batch - loss: 25.31286 - diff: 42.52mlTrain batch 36/42 - 182.9ms/batch - loss: 25.27283 - diff: 42.53mlTrain batch 37/42 - 185.6ms/batch - loss: 25.42914 - diff: 42.54mlTrain batch 38/42 - 183.8ms/batch - loss: 25.74306 - diff: 42.59mlTrain batch 39/42 - 187.7ms/batch - loss: 25.88575 - diff: 42.70mlTrain batch 40/42 - 185.3ms/batch - loss: 25.79451 - diff: 42.62mlTrain batch 41/42 - 183.7ms/batch - loss: 25.79317 - diff: 42.66mlTrain batch 42/42 - 133.2ms/batch - loss: 26.03625 - diff: 42.66mlTrain batch 42/42 - 372.7s 133.2ms/batch - loss: 26.03625 - diff: 42.66ml
Test 141.9s: val_loss: 24.67299 - diff: 42.30ml

Epoch 34: current best loss = 20.77429, at epoch 27
Train batch 1/42 - 187.4ms/batch - loss: 22.06512 - diff: 41.09mlTrain batch 2/42 - 184.4ms/batch - loss: 25.72904 - diff: 43.27mlTrain batch 3/42 - 189.7ms/batch - loss: 25.07258 - diff: 44.11mlTrain batch 4/42 - 184.8ms/batch - loss: 24.03893 - diff: 43.02mlTrain batch 5/42 - 183.2ms/batch - loss: 24.19420 - diff: 43.65mlTrain batch 6/42 - 183.3ms/batch - loss: 23.84958 - diff: 43.33mlTrain batch 7/42 - 183.2ms/batch - loss: 24.57778 - diff: 43.88mlTrain batch 8/42 - 182.8ms/batch - loss: 25.97918 - diff: 44.20mlTrain batch 9/42 - 189.8ms/batch - loss: 25.41047 - diff: 43.59mlTrain batch 10/42 - 185.0ms/batch - loss: 25.02116 - diff: 42.77mlTrain batch 11/42 - 183.6ms/batch - loss: 25.23111 - diff: 43.25mlTrain batch 12/42 - 183.6ms/batch - loss: 24.66703 - diff: 42.86mlTrain batch 13/42 - 182.7ms/batch - loss: 24.08087 - diff: 42.45mlTrain batch 14/42 - 184.4ms/batch - loss: 24.98684 - diff: 42.33mlTrain batch 15/42 - 188.2ms/batch - loss: 25.00997 - diff: 42.27mlTrain batch 16/42 - 184.4ms/batch - loss: 25.74010 - diff: 42.71mlTrain batch 17/42 - 188.2ms/batch - loss: 25.59003 - diff: 42.70mlTrain batch 18/42 - 183.0ms/batch - loss: 25.96358 - diff: 42.83mlTrain batch 19/42 - 198.9ms/batch - loss: 26.02229 - diff: 43.07mlTrain batch 20/42 - 183.2ms/batch - loss: 25.79427 - diff: 42.99mlTrain batch 21/42 - 189.5ms/batch - loss: 25.70605 - diff: 42.97mlTrain batch 22/42 - 196.0ms/batch - loss: 25.68127 - diff: 42.94mlTrain batch 23/42 - 200.9ms/batch - loss: 25.49856 - diff: 42.92mlTrain batch 24/42 - 183.6ms/batch - loss: 25.47214 - diff: 42.94mlTrain batch 25/42 - 185.8ms/batch - loss: 25.54369 - diff: 43.00mlTrain batch 26/42 - 182.1ms/batch - loss: 25.28052 - diff: 42.78mlTrain batch 27/42 - 186.8ms/batch - loss: 25.36019 - diff: 42.91mlTrain batch 28/42 - 182.9ms/batch - loss: 25.05702 - diff: 42.66mlTrain batch 29/42 - 192.6ms/batch - loss: 25.43149 - diff: 42.79mlTrain batch 30/42 - 184.8ms/batch - loss: 25.13316 - diff: 42.54mlTrain batch 31/42 - 192.2ms/batch - loss: 25.12816 - diff: 42.49mlTrain batch 32/42 - 184.3ms/batch - loss: 25.38132 - diff: 42.53mlTrain batch 33/42 - 183.3ms/batch - loss: 25.41558 - diff: 42.62mlTrain batch 34/42 - 184.8ms/batch - loss: 25.75295 - diff: 42.82mlTrain batch 35/42 - 190.5ms/batch - loss: 25.75710 - diff: 42.83mlTrain batch 36/42 - 187.1ms/batch - loss: 25.67097 - diff: 42.78mlTrain batch 37/42 - 193.2ms/batch - loss: 25.46585 - diff: 42.62mlTrain batch 38/42 - 183.8ms/batch - loss: 25.51807 - diff: 42.70mlTrain batch 39/42 - 182.5ms/batch - loss: 25.86156 - diff: 42.84mlTrain batch 40/42 - 183.6ms/batch - loss: 25.96173 - diff: 42.94mlTrain batch 41/42 - 183.1ms/batch - loss: 25.80144 - diff: 42.82mlTrain batch 42/42 - 128.6ms/batch - loss: 26.60229 - diff: 42.93mlTrain batch 42/42 - 367.6s 128.6ms/batch - loss: 26.60229 - diff: 42.93ml
Test 140.4s: val_loss: 21.87088 - diff: 39.88ml

Epoch 35: current best loss = 20.77429, at epoch 27
Train batch 1/42 - 190.2ms/batch - loss: 18.50222 - diff: 37.71mlTrain batch 2/42 - 184.8ms/batch - loss: 19.98851 - diff: 39.45mlTrain batch 3/42 - 183.3ms/batch - loss: 19.50355 - diff: 38.61mlTrain batch 4/42 - 183.2ms/batch - loss: 19.85113 - diff: 38.65mlTrain batch 5/42 - 187.6ms/batch - loss: 19.66598 - diff: 38.46mlTrain batch 6/42 - 183.8ms/batch - loss: 20.40044 - diff: 39.12mlTrain batch 7/42 - 182.8ms/batch - loss: 20.03635 - diff: 39.02mlTrain batch 8/42 - 182.7ms/batch - loss: 20.33817 - diff: 39.13mlTrain batch 9/42 - 186.5ms/batch - loss: 20.70331 - diff: 39.54mlTrain batch 10/42 - 183.0ms/batch - loss: 20.55222 - diff: 39.48mlTrain batch 11/42 - 188.5ms/batch - loss: 20.91346 - diff: 39.11mlTrain batch 12/42 - 184.4ms/batch - loss: 21.63389 - diff: 39.47mlTrain batch 13/42 - 182.7ms/batch - loss: 21.59023 - diff: 39.65mlTrain batch 14/42 - 183.5ms/batch - loss: 21.79684 - diff: 40.05mlTrain batch 15/42 - 182.8ms/batch - loss: 22.34735 - diff: 40.60mlTrain batch 16/42 - 183.2ms/batch - loss: 22.19864 - diff: 40.41mlTrain batch 17/42 - 191.8ms/batch - loss: 22.11701 - diff: 40.30mlTrain batch 18/42 - 183.4ms/batch - loss: 23.21997 - diff: 40.63mlTrain batch 19/42 - 187.1ms/batch - loss: 23.72191 - diff: 40.96mlTrain batch 20/42 - 182.8ms/batch - loss: 24.40705 - diff: 41.34mlTrain batch 21/42 - 201.4ms/batch - loss: 24.25474 - diff: 41.37mlTrain batch 22/42 - 184.3ms/batch - loss: 24.35489 - diff: 41.58mlTrain batch 23/42 - 186.7ms/batch - loss: 24.13244 - diff: 41.46mlTrain batch 24/42 - 182.2ms/batch - loss: 24.21181 - diff: 41.64mlTrain batch 25/42 - 200.3ms/batch - loss: 24.03719 - diff: 41.59mlTrain batch 26/42 - 184.2ms/batch - loss: 23.87213 - diff: 41.48mlTrain batch 27/42 - 182.5ms/batch - loss: 23.85483 - diff: 41.52mlTrain batch 28/42 - 183.6ms/batch - loss: 24.16599 - diff: 41.71mlTrain batch 29/42 - 182.5ms/batch - loss: 24.08904 - diff: 41.67mlTrain batch 30/42 - 183.6ms/batch - loss: 23.97812 - diff: 41.64mlTrain batch 31/42 - 189.7ms/batch - loss: 24.34760 - diff: 41.76mlTrain batch 32/42 - 184.3ms/batch - loss: 24.39036 - diff: 41.88mlTrain batch 33/42 - 183.5ms/batch - loss: 24.27512 - diff: 41.80mlTrain batch 34/42 - 184.4ms/batch - loss: 24.30338 - diff: 41.86mlTrain batch 35/42 - 183.8ms/batch - loss: 24.28918 - diff: 41.87mlTrain batch 36/42 - 182.8ms/batch - loss: 24.33786 - diff: 41.85mlTrain batch 37/42 - 188.2ms/batch - loss: 24.77830 - diff: 41.94mlTrain batch 38/42 - 185.7ms/batch - loss: 25.11787 - diff: 42.12mlTrain batch 39/42 - 183.0ms/batch - loss: 25.28986 - diff: 42.20mlTrain batch 40/42 - 183.9ms/batch - loss: 25.74307 - diff: 42.30mlTrain batch 41/42 - 183.1ms/batch - loss: 26.20018 - diff: 42.48mlTrain batch 42/42 - 128.8ms/batch - loss: 26.23378 - diff: 42.39mlTrain batch 42/42 - 365.1s 128.8ms/batch - loss: 26.23378 - diff: 42.39ml
Test 138.4s: val_loss: 27.79614 - diff: 44.02ml

Epoch 36: current best loss = 20.77429, at epoch 27
Train batch 1/42 - 190.2ms/batch - loss: 19.01968 - diff: 36.23mlTrain batch 2/42 - 186.4ms/batch - loss: 24.42304 - diff: 39.77mlTrain batch 3/42 - 187.0ms/batch - loss: 25.81735 - diff: 41.89mlTrain batch 4/42 - 183.6ms/batch - loss: 27.33344 - diff: 42.67mlTrain batch 5/42 - 184.0ms/batch - loss: 27.69209 - diff: 43.40mlTrain batch 6/42 - 183.2ms/batch - loss: 28.00872 - diff: 44.02mlTrain batch 7/42 - 187.8ms/batch - loss: 27.20264 - diff: 43.17mlTrain batch 8/42 - 184.1ms/batch - loss: 26.58019 - diff: 42.82mlTrain batch 9/42 - 182.6ms/batch - loss: 26.25626 - diff: 42.55mlTrain batch 10/42 - 182.9ms/batch - loss: 26.32432 - diff: 42.63mlTrain batch 11/42 - 184.0ms/batch - loss: 26.07178 - diff: 42.25mlTrain batch 12/42 - 182.8ms/batch - loss: 25.41349 - diff: 41.75mlTrain batch 13/42 - 189.1ms/batch - loss: 25.09738 - diff: 41.77mlTrain batch 14/42 - 184.4ms/batch - loss: 25.51338 - diff: 41.96mlTrain batch 15/42 - 183.2ms/batch - loss: 26.63402 - diff: 42.42mlTrain batch 16/42 - 182.5ms/batch - loss: 26.23035 - diff: 42.37mlTrain batch 17/42 - 185.0ms/batch - loss: 25.82445 - diff: 42.22mlTrain batch 18/42 - 182.5ms/batch - loss: 25.63607 - diff: 42.13mlTrain batch 19/42 - 200.7ms/batch - loss: 25.18953 - diff: 41.84mlTrain batch 20/42 - 184.1ms/batch - loss: 25.34409 - diff: 42.05mlTrain batch 21/42 - 185.5ms/batch - loss: 25.87786 - diff: 42.34mlTrain batch 22/42 - 182.6ms/batch - loss: 25.85855 - diff: 42.39mlTrain batch 23/42 - 206.4ms/batch - loss: 26.24699 - diff: 42.70mlTrain batch 24/42 - 184.8ms/batch - loss: 26.31805 - diff: 42.71mlTrain batch 25/42 - 185.0ms/batch - loss: 26.25632 - diff: 42.75mlTrain batch 26/42 - 182.8ms/batch - loss: 26.55166 - diff: 42.66mlTrain batch 27/42 - 184.9ms/batch - loss: 26.28785 - diff: 42.55mlTrain batch 28/42 - 183.4ms/batch - loss: 26.23961 - diff: 42.48mlTrain batch 29/42 - 191.5ms/batch - loss: 26.00979 - diff: 42.36mlTrain batch 30/42 - 183.9ms/batch - loss: 26.02088 - diff: 42.39mlTrain batch 31/42 - 184.7ms/batch - loss: 25.94067 - diff: 42.40mlTrain batch 32/42 - 184.6ms/batch - loss: 25.79085 - diff: 42.33mlTrain batch 33/42 - 183.4ms/batch - loss: 25.65919 - diff: 42.30mlTrain batch 34/42 - 184.8ms/batch - loss: 25.65257 - diff: 42.34mlTrain batch 35/42 - 189.5ms/batch - loss: 25.83724 - diff: 42.37mlTrain batch 36/42 - 184.5ms/batch - loss: 25.67950 - diff: 42.32mlTrain batch 37/42 - 182.9ms/batch - loss: 25.84136 - diff: 42.49mlTrain batch 38/42 - 183.7ms/batch - loss: 25.93836 - diff: 42.43mlTrain batch 39/42 - 185.8ms/batch - loss: 25.87594 - diff: 42.47mlTrain batch 40/42 - 183.0ms/batch - loss: 25.75480 - diff: 42.50mlTrain batch 41/42 - 183.4ms/batch - loss: 25.76423 - diff: 42.50mlTrain batch 42/42 - 128.7ms/batch - loss: 26.10653 - diff: 42.56mlTrain batch 42/42 - 369.9s 128.7ms/batch - loss: 26.10653 - diff: 42.56ml
Test 139.2s: val_loss: 20.57390 - diff: 38.14ml
Saving new best model in models/checkpoints/preproc1_150x150_bySlices_dataset_full_Diastole_TimeAsDepth_1_SGD-0.001_DA2_best

Epoch 37: current best loss = 20.57390, at epoch 36
Train batch 1/42 - 189.4ms/batch - loss: 23.59497 - diff: 41.37mlTrain batch 2/42 - 190.0ms/batch - loss: 23.96420 - diff: 42.27mlTrain batch 3/42 - 187.7ms/batch - loss: 24.51679 - diff: 44.26mlTrain batch 4/42 - 186.2ms/batch - loss: 23.77163 - diff: 43.57mlTrain batch 5/42 - 183.2ms/batch - loss: 23.03087 - diff: 43.27mlTrain batch 6/42 - 183.0ms/batch - loss: 23.71744 - diff: 42.71mlTrain batch 7/42 - 183.0ms/batch - loss: 24.69373 - diff: 42.58mlTrain batch 8/42 - 184.2ms/batch - loss: 24.32423 - diff: 42.27mlTrain batch 9/42 - 190.4ms/batch - loss: 23.45557 - diff: 41.63mlTrain batch 10/42 - 184.1ms/batch - loss: 23.32212 - diff: 41.71mlTrain batch 11/42 - 183.6ms/batch - loss: 22.98299 - diff: 41.51mlTrain batch 12/42 - 183.8ms/batch - loss: 22.69832 - diff: 41.29mlTrain batch 13/42 - 183.2ms/batch - loss: 23.16428 - diff: 41.41mlTrain batch 14/42 - 184.0ms/batch - loss: 23.82753 - diff: 41.68mlTrain batch 15/42 - 187.3ms/batch - loss: 23.79829 - diff: 41.76mlTrain batch 16/42 - 183.8ms/batch - loss: 23.99618 - diff: 42.11mlTrain batch 17/42 - 184.9ms/batch - loss: 23.54966 - diff: 41.77mlTrain batch 18/42 - 182.5ms/batch - loss: 23.86272 - diff: 41.74mlTrain batch 19/42 - 205.6ms/batch - loss: 24.08974 - diff: 41.89mlTrain batch 20/42 - 184.5ms/batch - loss: 24.31454 - diff: 41.74mlTrain batch 21/42 - 185.1ms/batch - loss: 24.24249 - diff: 41.69mlTrain batch 22/42 - 183.3ms/batch - loss: 24.77013 - diff: 41.82mlTrain batch 23/42 - 205.2ms/batch - loss: 24.78759 - diff: 41.90mlTrain batch 24/42 - 184.5ms/batch - loss: 24.85997 - diff: 42.09mlTrain batch 25/42 - 188.6ms/batch - loss: 24.63974 - diff: 41.96mlTrain batch 26/42 - 183.6ms/batch - loss: 24.36478 - diff: 41.79mlTrain batch 27/42 - 205.6ms/batch - loss: 24.79474 - diff: 41.87mlTrain batch 28/42 - 192.0ms/batch - loss: 24.87699 - diff: 41.99mlTrain batch 29/42 - 190.9ms/batch - loss: 25.08189 - diff: 42.06mlTrain batch 30/42 - 185.7ms/batch - loss: 25.41290 - diff: 42.21mlTrain batch 31/42 - 188.8ms/batch - loss: 25.53248 - diff: 42.46mlTrain batch 32/42 - 183.0ms/batch - loss: 25.68058 - diff: 42.64mlTrain batch 33/42 - 184.0ms/batch - loss: 25.54119 - diff: 42.58mlTrain batch 34/42 - 184.0ms/batch - loss: 25.84044 - diff: 42.69mlTrain batch 35/42 - 191.6ms/batch - loss: 26.25942 - diff: 43.00mlTrain batch 36/42 - 185.1ms/batch - loss: 26.16166 - diff: 42.96mlTrain batch 37/42 - 183.7ms/batch - loss: 26.48467 - diff: 43.11mlTrain batch 38/42 - 182.8ms/batch - loss: 26.27735 - diff: 42.97mlTrain batch 39/42 - 182.6ms/batch - loss: 26.33256 - diff: 43.10mlTrain batch 40/42 - 183.6ms/batch - loss: 26.30527 - diff: 43.20mlTrain batch 41/42 - 188.6ms/batch - loss: 26.29557 - diff: 43.28mlTrain batch 42/42 - 129.4ms/batch - loss: 26.50330 - diff: 43.27mlTrain batch 42/42 - 369.9s 129.4ms/batch - loss: 26.50330 - diff: 43.27ml
Test 137.9s: val_loss: 22.52028 - diff: 40.29ml

Epoch 38: current best loss = 20.57390, at epoch 36
Train batch 1/42 - 189.0ms/batch - loss: 26.34156 - diff: 43.12mlTrain batch 2/42 - 183.4ms/batch - loss: 28.77871 - diff: 44.89mlTrain batch 3/42 - 189.8ms/batch - loss: 30.48532 - diff: 44.49mlTrain batch 4/42 - 184.8ms/batch - loss: 30.20114 - diff: 44.10mlTrain batch 5/42 - 198.3ms/batch - loss: 28.87248 - diff: 44.12mlTrain batch 6/42 - 182.8ms/batch - loss: 27.60933 - diff: 43.73mlTrain batch 7/42 - 183.3ms/batch - loss: 27.89695 - diff: 43.58mlTrain batch 8/42 - 182.6ms/batch - loss: 26.82786 - diff: 42.94mlTrain batch 9/42 - 187.8ms/batch - loss: 26.58159 - diff: 43.01mlTrain batch 10/42 - 184.3ms/batch - loss: 26.02393 - diff: 42.70mlTrain batch 11/42 - 183.4ms/batch - loss: 27.38159 - diff: 42.90mlTrain batch 12/42 - 182.3ms/batch - loss: 28.21408 - diff: 43.55mlTrain batch 13/42 - 201.8ms/batch - loss: 27.58191 - diff: 43.30mlTrain batch 14/42 - 185.8ms/batch - loss: 27.31076 - diff: 43.27mlTrain batch 15/42 - 186.3ms/batch - loss: 27.06396 - diff: 42.92mlTrain batch 16/42 - 182.2ms/batch - loss: 27.18528 - diff: 43.14mlTrain batch 17/42 - 182.9ms/batch - loss: 27.06323 - diff: 43.35mlTrain batch 18/42 - 182.6ms/batch - loss: 26.71403 - diff: 43.16mlTrain batch 19/42 - 190.1ms/batch - loss: 26.60294 - diff: 43.22mlTrain batch 20/42 - 182.4ms/batch - loss: 27.00233 - diff: 43.62mlTrain batch 21/42 - 189.8ms/batch - loss: 26.91370 - diff: 43.74mlTrain batch 22/42 - 182.4ms/batch - loss: 26.96316 - diff: 43.85mlTrain batch 23/42 - 206.3ms/batch - loss: 27.22060 - diff: 43.86mlTrain batch 24/42 - 183.9ms/batch - loss: 27.63540 - diff: 44.09mlTrain batch 25/42 - 186.3ms/batch - loss: 27.46402 - diff: 44.01mlTrain batch 26/42 - 182.5ms/batch - loss: 28.26532 - diff: 44.22mlTrain batch 27/42 - 189.8ms/batch - loss: 28.08733 - diff: 44.16mlTrain batch 28/42 - 185.0ms/batch - loss: 28.25674 - diff: 44.34mlTrain batch 29/42 - 192.1ms/batch - loss: 28.09413 - diff: 44.25mlTrain batch 30/42 - 184.1ms/batch - loss: 27.84642 - diff: 44.13mlTrain batch 31/42 - 183.0ms/batch - loss: 27.98203 - diff: 44.10mlTrain batch 32/42 - 183.7ms/batch - loss: 27.84611 - diff: 44.00mlTrain batch 33/42 - 189.1ms/batch - loss: 27.98888 - diff: 43.95mlTrain batch 34/42 - 184.0ms/batch - loss: 27.79924 - diff: 43.88mlTrain batch 35/42 - 182.6ms/batch - loss: 27.63604 - diff: 43.80mlTrain batch 36/42 - 182.7ms/batch - loss: 27.75006 - diff: 44.03mlTrain batch 37/42 - 182.7ms/batch - loss: 27.51797 - diff: 43.88mlTrain batch 38/42 - 183.5ms/batch - loss: 27.47807 - diff: 43.89mlTrain batch 39/42 - 188.6ms/batch - loss: 27.35803 - diff: 43.76mlTrain batch 40/42 - 185.3ms/batch - loss: 27.34622 - diff: 43.76mlTrain batch 41/42 - 182.6ms/batch - loss: 27.22009 - diff: 43.73mlTrain batch 42/42 - 128.1ms/batch - loss: 27.51101 - diff: 43.73mlTrain batch 42/42 - 368.0s 128.1ms/batch - loss: 27.51101 - diff: 43.73ml
Test 138.7s: val_loss: 25.67836 - diff: 45.01ml

Epoch 39: current best loss = 20.57390, at epoch 36
Train batch 1/42 - 188.8ms/batch - loss: 20.15535 - diff: 41.60mlTrain batch 2/42 - 183.5ms/batch - loss: 20.63699 - diff: 40.17mlTrain batch 3/42 - 188.9ms/batch - loss: 25.13050 - diff: 41.64mlTrain batch 4/42 - 186.0ms/batch - loss: 25.80667 - diff: 42.94mlTrain batch 5/42 - 184.8ms/batch - loss: 25.80536 - diff: 43.05mlTrain batch 6/42 - 183.9ms/batch - loss: 27.41183 - diff: 44.04mlTrain batch 7/42 - 184.2ms/batch - loss: 27.59035 - diff: 44.53mlTrain batch 8/42 - 184.1ms/batch - loss: 26.39639 - diff: 43.37mlTrain batch 9/42 - 188.4ms/batch - loss: 27.03316 - diff: 43.44mlTrain batch 10/42 - 186.9ms/batch - loss: 26.44149 - diff: 43.08mlTrain batch 11/42 - 184.0ms/batch - loss: 25.79432 - diff: 42.71mlTrain batch 12/42 - 184.1ms/batch - loss: 25.29142 - diff: 42.29mlTrain batch 13/42 - 183.1ms/batch - loss: 24.82680 - diff: 41.94mlTrain batch 14/42 - 185.0ms/batch - loss: 24.68146 - diff: 41.96mlTrain batch 15/42 - 188.5ms/batch - loss: 25.08037 - diff: 42.06mlTrain batch 16/42 - 184.3ms/batch - loss: 25.48185 - diff: 42.28mlTrain batch 17/42 - 188.2ms/batch - loss: 25.84391 - diff: 42.11mlTrain batch 18/42 - 182.4ms/batch - loss: 25.47017 - diff: 41.89mlTrain batch 19/42 - 187.9ms/batch - loss: 25.50250 - diff: 41.94mlTrain batch 20/42 - 183.3ms/batch - loss: 25.70092 - diff: 42.10mlTrain batch 21/42 - 206.4ms/batch - loss: 25.76232 - diff: 42.03mlTrain batch 22/42 - 183.8ms/batch - loss: 26.03967 - diff: 42.19mlTrain batch 23/42 - 185.4ms/batch - loss: 25.84068 - diff: 42.19mlTrain batch 24/42 - 182.3ms/batch - loss: 26.00991 - diff: 42.12mlTrain batch 25/42 - 195.9ms/batch - loss: 26.35282 - diff: 42.31mlTrain batch 26/42 - 184.2ms/batch - loss: 26.33553 - diff: 42.36mlTrain batch 27/42 - 185.7ms/batch - loss: 26.05361 - diff: 42.22mlTrain batch 28/42 - 186.3ms/batch - loss: 25.80354 - diff: 42.11mlTrain batch 29/42 - 188.4ms/batch - loss: 25.56328 - diff: 42.00mlTrain batch 30/42 - 183.0ms/batch - loss: 25.35000 - diff: 41.93mlTrain batch 31/42 - 188.8ms/batch - loss: 25.15490 - diff: 41.84mlTrain batch 32/42 - 185.4ms/batch - loss: 25.40039 - diff: 41.95mlTrain batch 33/42 - 183.6ms/batch - loss: 25.93730 - diff: 42.11mlTrain batch 34/42 - 183.5ms/batch - loss: 25.67964 - diff: 41.91mlTrain batch 35/42 - 183.2ms/batch - loss: 25.75759 - diff: 42.07mlTrain batch 36/42 - 183.2ms/batch - loss: 25.76127 - diff: 42.16mlTrain batch 37/42 - 189.0ms/batch - loss: 25.56736 - diff: 42.06mlTrain batch 38/42 - 185.9ms/batch - loss: 25.39698 - diff: 41.94mlTrain batch 39/42 - 183.5ms/batch - loss: 25.35683 - diff: 41.95mlTrain batch 40/42 - 182.8ms/batch - loss: 25.30051 - diff: 41.95mlTrain batch 41/42 - 183.0ms/batch - loss: 25.54762 - diff: 42.07mlTrain batch 42/42 - 128.2ms/batch - loss: 25.72640 - diff: 42.08mlTrain batch 42/42 - 369.1s 128.2ms/batch - loss: 25.72640 - diff: 42.08ml
Test 140.4s: val_loss: 214.24663 - diff: 143.85ml

Epoch 40: current best loss = 20.57390, at epoch 36
Train batch 1/42 - 185.3ms/batch - loss: 23.45534 - diff: 43.18mlTrain batch 2/42 - 182.9ms/batch - loss: 27.85541 - diff: 45.30mlTrain batch 3/42 - 192.3ms/batch - loss: 24.77463 - diff: 41.97mlTrain batch 4/42 - 184.5ms/batch - loss: 23.14894 - diff: 40.66mlTrain batch 5/42 - 183.7ms/batch - loss: 27.25326 - diff: 42.89mlTrain batch 6/42 - 183.6ms/batch - loss: 26.21963 - diff: 42.37mlTrain batch 7/42 - 183.4ms/batch - loss: 25.46122 - diff: 42.28mlTrain batch 8/42 - 183.3ms/batch - loss: 24.84084 - diff: 42.21mlTrain batch 9/42 - 190.6ms/batch - loss: 24.55897 - diff: 41.96mlTrain batch 10/42 - 183.9ms/batch - loss: 24.97811 - diff: 42.62mlTrain batch 11/42 - 182.8ms/batch - loss: 25.26920 - diff: 42.40mlTrain batch 12/42 - 182.9ms/batch - loss: 24.95275 - diff: 42.13mlTrain batch 13/42 - 183.7ms/batch - loss: 25.63516 - diff: 42.59mlTrain batch 14/42 - 183.0ms/batch - loss: 25.97687 - diff: 42.80mlTrain batch 15/42 - 188.3ms/batch - loss: 25.67264 - diff: 42.67mlTrain batch 16/42 - 183.9ms/batch - loss: 25.42499 - diff: 42.66mlTrain batch 17/42 - 185.8ms/batch - loss: 25.64814 - diff: 42.81mlTrain batch 18/42 - 182.2ms/batch - loss: 25.59182 - diff: 42.72mlTrain batch 19/42 - 182.7ms/batch - loss: 26.49184 - diff: 43.04mlTrain batch 20/42 - 188.0ms/batch - loss: 26.97970 - diff: 43.37mlTrain batch 21/42 - 188.9ms/batch - loss: 26.85587 - diff: 43.38mlTrain batch 22/42 - 182.5ms/batch - loss: 26.69373 - diff: 43.28mlTrain batch 23/42 - 200.1ms/batch - loss: 26.50474 - diff: 43.16mlTrain batch 24/42 - 183.4ms/batch - loss: 26.29272 - diff: 42.96mlTrain batch 25/42 - 185.9ms/batch - loss: 26.41069 - diff: 42.97mlTrain batch 26/42 - 182.9ms/batch - loss: 26.41987 - diff: 42.93mlTrain batch 27/42 - 189.4ms/batch - loss: 26.24449 - diff: 42.83mlTrain batch 28/42 - 185.7ms/batch - loss: 26.00610 - diff: 42.64mlTrain batch 29/42 - 182.4ms/batch - loss: 25.89051 - diff: 42.63mlTrain batch 30/42 - 183.0ms/batch - loss: 25.90583 - diff: 42.72mlTrain batch 31/42 - 186.3ms/batch - loss: 25.59460 - diff: 42.45mlTrain batch 32/42 - 182.6ms/batch - loss: 26.00860 - diff: 42.65mlTrain batch 33/42 - 188.7ms/batch - loss: 26.14882 - diff: 42.67mlTrain batch 34/42 - 184.3ms/batch - loss: 25.93430 - diff: 42.51mlTrain batch 35/42 - 184.2ms/batch - loss: 25.83610 - diff: 42.53mlTrain batch 36/42 - 182.9ms/batch - loss: 25.65197 - diff: 42.46mlTrain batch 37/42 - 183.1ms/batch - loss: 25.42062 - diff: 42.32mlTrain batch 38/42 - 182.7ms/batch - loss: 25.16182 - diff: 42.15mlTrain batch 39/42 - 189.3ms/batch - loss: 25.10633 - diff: 42.13mlTrain batch 40/42 - 183.7ms/batch - loss: 25.12946 - diff: 42.12mlTrain batch 41/42 - 183.6ms/batch - loss: 25.07043 - diff: 42.07mlTrain batch 42/42 - 128.7ms/batch - loss: 25.30574 - diff: 42.00mlTrain batch 42/42 - 364.2s 128.7ms/batch - loss: 25.30574 - diff: 42.00ml
Test 139.0s: val_loss: 20.84933 - diff: 39.62ml

Epoch 41: current best loss = 20.57390, at epoch 36
Train batch 1/42 - 187.8ms/batch - loss: 18.21223 - diff: 37.45mlTrain batch 2/42 - 183.7ms/batch - loss: 21.30734 - diff: 42.04mlTrain batch 3/42 - 189.3ms/batch - loss: 23.91372 - diff: 42.64mlTrain batch 4/42 - 184.7ms/batch - loss: 23.58903 - diff: 42.39mlTrain batch 5/42 - 184.5ms/batch - loss: 31.36576 - diff: 44.87mlTrain batch 6/42 - 182.8ms/batch - loss: 29.62071 - diff: 44.28mlTrain batch 7/42 - 182.8ms/batch - loss: 29.27510 - diff: 43.80mlTrain batch 8/42 - 183.0ms/batch - loss: 29.62910 - diff: 44.02mlTrain batch 9/42 - 188.4ms/batch - loss: 29.32757 - diff: 44.14mlTrain batch 10/42 - 183.9ms/batch - loss: 28.52309 - diff: 43.73mlTrain batch 11/42 - 188.3ms/batch - loss: 27.85970 - diff: 43.48mlTrain batch 12/42 - 200.1ms/batch - loss: 27.73327 - diff: 43.35mlTrain batch 13/42 - 183.3ms/batch - loss: 27.79160 - diff: 43.29mlTrain batch 14/42 - 182.3ms/batch - loss: 27.72034 - diff: 43.13mlTrain batch 15/42 - 188.8ms/batch - loss: 27.32892 - diff: 43.03mlTrain batch 16/42 - 184.7ms/batch - loss: 27.07531 - diff: 43.02mlTrain batch 17/42 - 186.9ms/batch - loss: 26.76343 - diff: 42.73mlTrain batch 18/42 - 182.1ms/batch - loss: 26.82242 - diff: 42.73mlTrain batch 19/42 - 203.9ms/batch - loss: 26.49589 - diff: 42.50mlTrain batch 20/42 - 183.9ms/batch - loss: 26.15824 - diff: 42.27mlTrain batch 21/42 - 185.3ms/batch - loss: 25.89084 - diff: 42.16mlTrain batch 22/42 - 183.0ms/batch - loss: 25.85391 - diff: 42.06mlTrain batch 23/42 - 200.4ms/batch - loss: 25.93042 - diff: 42.18mlTrain batch 24/42 - 184.7ms/batch - loss: 26.06772 - diff: 42.52mlTrain batch 25/42 - 185.4ms/batch - loss: 25.86345 - diff: 42.39mlTrain batch 26/42 - 183.1ms/batch - loss: 25.77376 - diff: 42.33mlTrain batch 27/42 - 204.8ms/batch - loss: 25.92944 - diff: 42.48mlTrain batch 28/42 - 182.9ms/batch - loss: 25.92301 - diff: 42.46mlTrain batch 29/42 - 206.3ms/batch - loss: 25.93481 - diff: 42.45mlTrain batch 30/42 - 183.5ms/batch - loss: 25.93329 - diff: 42.54mlTrain batch 31/42 - 187.1ms/batch - loss: 25.61581 - diff: 42.33mlTrain batch 32/42 - 183.1ms/batch - loss: 25.67154 - diff: 42.34mlTrain batch 33/42 - 193.5ms/batch - loss: 25.70166 - diff: 42.36mlTrain batch 34/42 - 184.6ms/batch - loss: 25.57159 - diff: 42.31mlTrain batch 35/42 - 182.4ms/batch - loss: 25.60135 - diff: 42.42mlTrain batch 36/42 - 184.6ms/batch - loss: 25.49197 - diff: 42.37mlTrain batch 37/42 - 183.8ms/batch - loss: 25.44676 - diff: 42.37mlTrain batch 38/42 - 182.9ms/batch - loss: 25.65768 - diff: 42.47mlTrain batch 39/42 - 183.3ms/batch - loss: 25.76162 - diff: 42.50mlTrain batch 40/42 - 184.6ms/batch - loss: 25.70802 - diff: 42.49mlTrain batch 41/42 - 187.7ms/batch - loss: 25.62795 - diff: 42.40mlTrain batch 42/42 - 129.0ms/batch - loss: 25.97165 - diff: 42.40mlTrain batch 42/42 - 368.4s 129.0ms/batch - loss: 25.97165 - diff: 42.40ml
Test 139.2s: val_loss: 22.02983 - diff: 40.87ml

Epoch 42: current best loss = 20.57390, at epoch 36
Train batch 1/42 - 188.5ms/batch - loss: 24.60109 - diff: 44.31mlTrain batch 2/42 - 184.4ms/batch - loss: 24.81576 - diff: 44.02mlTrain batch 3/42 - 194.1ms/batch - loss: 24.05788 - diff: 42.28mlTrain batch 4/42 - 184.0ms/batch - loss: 24.65793 - diff: 41.77mlTrain batch 5/42 - 186.9ms/batch - loss: 24.72476 - diff: 41.91mlTrain batch 6/42 - 183.2ms/batch - loss: 23.79259 - diff: 41.35mlTrain batch 7/42 - 184.6ms/batch - loss: 22.97435 - diff: 40.93mlTrain batch 8/42 - 183.8ms/batch - loss: 24.47825 - diff: 41.66mlTrain batch 9/42 - 188.9ms/batch - loss: 24.11251 - diff: 41.57mlTrain batch 10/42 - 183.7ms/batch - loss: 24.23143 - diff: 42.00mlTrain batch 11/42 - 187.6ms/batch - loss: 23.86703 - diff: 42.10mlTrain batch 12/42 - 185.8ms/batch - loss: 23.54901 - diff: 41.76mlTrain batch 13/42 - 182.7ms/batch - loss: 24.02000 - diff: 41.97mlTrain batch 14/42 - 187.1ms/batch - loss: 24.58944 - diff: 42.53mlTrain batch 15/42 - 191.9ms/batch - loss: 25.31501 - diff: 42.62mlTrain batch 16/42 - 185.6ms/batch - loss: 25.27030 - diff: 42.71mlTrain batch 17/42 - 190.4ms/batch - loss: 26.11846 - diff: 43.33mlTrain batch 18/42 - 182.9ms/batch - loss: 26.57572 - diff: 43.43mlTrain batch 19/42 - 185.4ms/batch - loss: 26.40154 - diff: 43.23mlTrain batch 20/42 - 182.2ms/batch - loss: 25.94620 - diff: 42.86mlTrain batch 21/42 - 200.6ms/batch - loss: 25.81429 - diff: 42.76mlTrain batch 22/42 - 184.0ms/batch - loss: 25.72095 - diff: 42.70mlTrain batch 23/42 - 186.0ms/batch - loss: 25.50844 - diff: 42.61mlTrain batch 24/42 - 183.1ms/batch - loss: 25.48186 - diff: 42.65mlTrain batch 25/42 - 201.6ms/batch - loss: 25.77447 - diff: 42.87mlTrain batch 26/42 - 182.5ms/batch - loss: 26.36214 - diff: 43.15mlTrain batch 27/42 - 192.3ms/batch - loss: 26.44152 - diff: 43.24mlTrain batch 28/42 - 184.2ms/batch - loss: 26.40018 - diff: 43.25mlTrain batch 29/42 - 183.2ms/batch - loss: 26.23793 - diff: 43.20mlTrain batch 30/42 - 182.5ms/batch - loss: 26.30885 - diff: 43.21mlTrain batch 31/42 - 186.8ms/batch - loss: 26.05607 - diff: 43.05mlTrain batch 32/42 - 183.7ms/batch - loss: 26.00971 - diff: 43.15mlTrain batch 33/42 - 183.2ms/batch - loss: 25.95765 - diff: 43.21mlTrain batch 34/42 - 183.1ms/batch - loss: 25.74457 - diff: 43.07mlTrain batch 35/42 - 183.9ms/batch - loss: 25.67591 - diff: 43.08mlTrain batch 36/42 - 187.8ms/batch - loss: 25.93350 - diff: 43.02mlTrain batch 37/42 - 184.3ms/batch - loss: 25.91454 - diff: 42.92mlTrain batch 38/42 - 182.3ms/batch - loss: 26.19042 - diff: 43.11mlTrain batch 39/42 - 182.9ms/batch - loss: 26.13728 - diff: 43.12mlTrain batch 40/42 - 182.9ms/batch - loss: 26.28437 - diff: 43.17mlTrain batch 41/42 - 184.9ms/batch - loss: 26.17099 - diff: 43.10mlTrain batch 42/42 - 128.6ms/batch - loss: 26.05492 - diff: 42.94mlTrain batch 42/42 - 364.6s 128.6ms/batch - loss: 26.05492 - diff: 42.94ml
Test 140.3s: val_loss: 24.91915 - diff: 42.14ml

Epoch 43: current best loss = 20.57390, at epoch 36
Train batch 1/42 - 184.6ms/batch - loss: 38.88522 - diff: 47.30mlTrain batch 2/42 - 183.1ms/batch - loss: 37.75006 - diff: 45.76mlTrain batch 3/42 - 189.2ms/batch - loss: 33.22203 - diff: 44.36mlTrain batch 4/42 - 184.7ms/batch - loss: 30.48696 - diff: 44.18mlTrain batch 5/42 - 185.2ms/batch - loss: 30.57860 - diff: 44.60mlTrain batch 6/42 - 182.8ms/batch - loss: 29.21763 - diff: 43.97mlTrain batch 7/42 - 184.1ms/batch - loss: 28.32031 - diff: 43.58mlTrain batch 8/42 - 182.8ms/batch - loss: 27.08964 - diff: 42.98mlTrain batch 9/42 - 189.6ms/batch - loss: 26.57173 - diff: 42.62mlTrain batch 10/42 - 184.8ms/batch - loss: 26.33547 - diff: 42.51mlTrain batch 11/42 - 198.1ms/batch - loss: 25.53810 - diff: 41.94mlTrain batch 12/42 - 183.1ms/batch - loss: 25.58414 - diff: 41.97mlTrain batch 13/42 - 183.1ms/batch - loss: 25.49313 - diff: 42.13mlTrain batch 14/42 - 184.6ms/batch - loss: 25.19426 - diff: 42.10mlTrain batch 15/42 - 190.1ms/batch - loss: 25.09516 - diff: 42.18mlTrain batch 16/42 - 184.4ms/batch - loss: 25.02174 - diff: 42.20mlTrain batch 17/42 - 188.3ms/batch - loss: 24.80466 - diff: 42.17mlTrain batch 18/42 - 182.5ms/batch - loss: 24.74060 - diff: 42.17mlTrain batch 19/42 - 187.6ms/batch - loss: 24.73169 - diff: 42.26mlTrain batch 20/42 - 188.5ms/batch - loss: 24.91779 - diff: 42.28mlTrain batch 21/42 - 186.9ms/batch - loss: 25.77951 - diff: 42.57mlTrain batch 22/42 - 182.4ms/batch - loss: 25.69615 - diff: 42.67mlTrain batch 23/42 - 188.5ms/batch - loss: 25.58292 - diff: 42.66mlTrain batch 24/42 - 183.0ms/batch - loss: 25.76260 - diff: 42.76mlTrain batch 25/42 - 185.8ms/batch - loss: 25.58452 - diff: 42.62mlTrain batch 26/42 - 183.2ms/batch - loss: 25.52469 - diff: 42.56mlTrain batch 27/42 - 188.0ms/batch - loss: 25.95604 - diff: 42.76mlTrain batch 28/42 - 183.3ms/batch - loss: 25.86866 - diff: 42.73mlTrain batch 29/42 - 183.1ms/batch - loss: 25.79893 - diff: 42.74mlTrain batch 30/42 - 182.6ms/batch - loss: 25.68089 - diff: 42.64mlTrain batch 31/42 - 183.0ms/batch - loss: 25.51315 - diff: 42.48mlTrain batch 32/42 - 188.9ms/batch - loss: 25.44107 - diff: 42.49mlTrain batch 33/42 - 185.3ms/batch - loss: 25.36818 - diff: 42.52mlTrain batch 34/42 - 182.8ms/batch - loss: 25.66996 - diff: 42.59mlTrain batch 35/42 - 182.5ms/batch - loss: 25.96138 - diff: 42.61mlTrain batch 36/42 - 183.0ms/batch - loss: 25.83880 - diff: 42.55mlTrain batch 37/42 - 182.3ms/batch - loss: 26.05316 - diff: 42.68mlTrain batch 38/42 - 188.0ms/batch - loss: 25.94086 - diff: 42.65mlTrain batch 39/42 - 186.8ms/batch - loss: 25.77867 - diff: 42.56mlTrain batch 40/42 - 183.0ms/batch - loss: 25.72483 - diff: 42.56mlTrain batch 41/42 - 184.1ms/batch - loss: 25.53061 - diff: 42.43mlTrain batch 42/42 - 128.3ms/batch - loss: 25.55252 - diff: 42.33mlTrain batch 42/42 - 367.5s 128.3ms/batch - loss: 25.55252 - diff: 42.33ml
Test 139.2s: val_loss: 20.44046 - diff: 38.10ml
Saving new best model in models/checkpoints/preproc1_150x150_bySlices_dataset_full_Diastole_TimeAsDepth_1_SGD-0.001_DA2_best

Epoch 44: current best loss = 20.44046, at epoch 43
Train batch 1/42 - 184.8ms/batch - loss: 17.65312 - diff: 36.48mlTrain batch 2/42 - 183.1ms/batch - loss: 21.09408 - diff: 40.35mlTrain batch 3/42 - 183.0ms/batch - loss: 20.99306 - diff: 39.89mlTrain batch 4/42 - 182.8ms/batch - loss: 20.23183 - diff: 39.32mlTrain batch 5/42 - 187.8ms/batch - loss: 19.92516 - diff: 39.30mlTrain batch 6/42 - 182.8ms/batch - loss: 19.36825 - diff: 38.78mlTrain batch 7/42 - 185.1ms/batch - loss: 20.07095 - diff: 39.34mlTrain batch 8/42 - 184.2ms/batch - loss: 22.51573 - diff: 40.56mlTrain batch 9/42 - 188.6ms/batch - loss: 22.07947 - diff: 40.46mlTrain batch 10/42 - 183.7ms/batch - loss: 23.09546 - diff: 40.96mlTrain batch 11/42 - 188.5ms/batch - loss: 23.40989 - diff: 41.51mlTrain batch 12/42 - 185.9ms/batch - loss: 23.28896 - diff: 41.58mlTrain batch 13/42 - 187.1ms/batch - loss: 23.37003 - diff: 41.77mlTrain batch 14/42 - 188.0ms/batch - loss: 24.43471 - diff: 41.99mlTrain batch 15/42 - 183.5ms/batch - loss: 25.10548 - diff: 42.15mlTrain batch 16/42 - 182.7ms/batch - loss: 25.46211 - diff: 42.31mlTrain batch 17/42 - 187.3ms/batch - loss: 25.15878 - diff: 42.23mlTrain batch 18/42 - 183.7ms/batch - loss: 25.03838 - diff: 42.23mlTrain batch 19/42 - 183.1ms/batch - loss: 25.46246 - diff: 42.32mlTrain batch 20/42 - 182.9ms/batch - loss: 25.30097 - diff: 42.19mlTrain batch 21/42 - 189.3ms/batch - loss: 25.13168 - diff: 42.03mlTrain batch 22/42 - 184.4ms/batch - loss: 24.89597 - diff: 41.88mlTrain batch 23/42 - 187.4ms/batch - loss: 25.06006 - diff: 41.88mlTrain batch 24/42 - 187.7ms/batch - loss: 24.75876 - diff: 41.75mlTrain batch 25/42 - 189.8ms/batch - loss: 24.50408 - diff: 41.58mlTrain batch 26/42 - 182.5ms/batch - loss: 24.34514 - diff: 41.54mlTrain batch 27/42 - 183.2ms/batch - loss: 24.81518 - diff: 41.64mlTrain batch 28/42 - 182.5ms/batch - loss: 24.48071 - diff: 41.42mlTrain batch 29/42 - 183.1ms/batch - loss: 24.28823 - diff: 41.33mlTrain batch 30/42 - 187.9ms/batch - loss: 24.14477 - diff: 41.28mlTrain batch 31/42 - 183.8ms/batch - loss: 24.22092 - diff: 41.35mlTrain batch 32/42 - 184.3ms/batch - loss: 24.14041 - diff: 41.33mlTrain batch 33/42 - 183.3ms/batch - loss: 24.13863 - diff: 41.39mlTrain batch 34/42 - 185.8ms/batch - loss: 24.08557 - diff: 41.38mlTrain batch 35/42 - 183.1ms/batch - loss: 24.09814 - diff: 41.44mlTrain batch 36/42 - 188.2ms/batch - loss: 24.17014 - diff: 41.59mlTrain batch 37/42 - 184.4ms/batch - loss: 24.20337 - diff: 41.74mlTrain batch 38/42 - 182.9ms/batch - loss: 24.24834 - diff: 41.78mlTrain batch 39/42 - 182.8ms/batch - loss: 24.49365 - diff: 41.83mlTrain batch 40/42 - 182.7ms/batch - loss: 24.95715 - diff: 41.91mlTrain batch 41/42 - 183.5ms/batch - loss: 24.97548 - diff: 41.97mlTrain batch 42/42 - 128.7ms/batch - loss: 25.17079 - diff: 41.97mlTrain batch 42/42 - 360.5s 128.7ms/batch - loss: 25.17079 - diff: 41.97ml
Test 138.7s: val_loss: 21.63565 - diff: 39.54ml

Epoch 45: current best loss = 20.44046, at epoch 43
Train batch 1/42 - 196.3ms/batch - loss: 28.24876 - diff: 40.85mlTrain batch 2/42 - 185.2ms/batch - loss: 28.08813 - diff: 44.67mlTrain batch 3/42 - 200.2ms/batch - loss: 27.28779 - diff: 44.26mlTrain batch 4/42 - 183.4ms/batch - loss: 27.43195 - diff: 44.96mlTrain batch 5/42 - 187.3ms/batch - loss: 25.92552 - diff: 43.62mlTrain batch 6/42 - 182.6ms/batch - loss: 26.20448 - diff: 42.72mlTrain batch 7/42 - 190.3ms/batch - loss: 26.23563 - diff: 42.67mlTrain batch 8/42 - 188.3ms/batch - loss: 26.06904 - diff: 42.23mlTrain batch 9/42 - 183.2ms/batch - loss: 25.62794 - diff: 42.06mlTrain batch 10/42 - 183.4ms/batch - loss: 26.48387 - diff: 42.61mlTrain batch 11/42 - 184.4ms/batch - loss: 25.74574 - diff: 42.22mlTrain batch 12/42 - 184.1ms/batch - loss: 25.48676 - diff: 42.00mlTrain batch 13/42 - 188.2ms/batch - loss: 25.19541 - diff: 41.86mlTrain batch 14/42 - 185.6ms/batch - loss: 25.14536 - diff: 41.95mlTrain batch 15/42 - 184.5ms/batch - loss: 24.86136 - diff: 41.86mlTrain batch 16/42 - 182.6ms/batch - loss: 25.28238 - diff: 41.99mlTrain batch 17/42 - 193.1ms/batch - loss: 24.97167 - diff: 41.91mlTrain batch 18/42 - 184.4ms/batch - loss: 24.96889 - diff: 41.91mlTrain batch 19/42 - 187.4ms/batch - loss: 24.88043 - diff: 41.94mlTrain batch 20/42 - 182.5ms/batch - loss: 25.03105 - diff: 42.19mlTrain batch 21/42 - 200.1ms/batch - loss: 24.81440 - diff: 42.07mlTrain batch 22/42 - 184.4ms/batch - loss: 24.45977 - diff: 41.88mlTrain batch 23/42 - 187.7ms/batch - loss: 24.62811 - diff: 41.89mlTrain batch 24/42 - 182.5ms/batch - loss: 24.78157 - diff: 41.86mlTrain batch 25/42 - 213.0ms/batch - loss: 24.85649 - diff: 41.77mlTrain batch 26/42 - 184.5ms/batch - loss: 24.56609 - diff: 41.62mlTrain batch 27/42 - 185.3ms/batch - loss: 24.44100 - diff: 41.58mlTrain batch 28/42 - 182.3ms/batch - loss: 24.40568 - diff: 41.60mlTrain batch 29/42 - 188.5ms/batch - loss: 24.40811 - diff: 41.63mlTrain batch 30/42 - 182.9ms/batch - loss: 24.21521 - diff: 41.43mlTrain batch 31/42 - 190.9ms/batch - loss: 24.00661 - diff: 41.28mlTrain batch 32/42 - 185.3ms/batch - loss: 23.84362 - diff: 41.18mlTrain batch 33/42 - 184.7ms/batch - loss: 23.76555 - diff: 41.20mlTrain batch 34/42 - 195.8ms/batch - loss: 23.99670 - diff: 41.26mlTrain batch 35/42 - 185.2ms/batch - loss: 23.81796 - diff: 41.18mlTrain batch 36/42 - 182.9ms/batch - loss: 23.74833 - diff: 41.18mlTrain batch 37/42 - 190.3ms/batch - loss: 23.86118 - diff: 41.17mlTrain batch 38/42 - 185.3ms/batch - loss: 23.76117 - diff: 41.16mlTrain batch 39/42 - 183.4ms/batch - loss: 23.93554 - diff: 41.27mlTrain batch 40/42 - 185.0ms/batch - loss: 24.03774 - diff: 41.31mlTrain batch 41/42 - 182.9ms/batch - loss: 23.92521 - diff: 41.24mlTrain batch 42/42 - 128.9ms/batch - loss: 24.59972 - diff: 41.47mlTrain batch 42/42 - 371.4s 128.9ms/batch - loss: 24.59972 - diff: 41.47ml
Test 136.9s: val_loss: 21.83247 - diff: 40.98ml

Epoch 46: current best loss = 20.44046, at epoch 43
Train batch 1/42 - 189.2ms/batch - loss: 35.11584 - diff: 46.48mlTrain batch 2/42 - 184.4ms/batch - loss: 31.01585 - diff: 44.68mlTrain batch 3/42 - 187.3ms/batch - loss: 27.97843 - diff: 42.84mlTrain batch 4/42 - 183.0ms/batch - loss: 26.63950 - diff: 42.83mlTrain batch 5/42 - 183.6ms/batch - loss: 26.17786 - diff: 42.65mlTrain batch 6/42 - 182.4ms/batch - loss: 25.67653 - diff: 42.63mlTrain batch 7/42 - 182.5ms/batch - loss: 25.31067 - diff: 42.44mlTrain batch 8/42 - 184.3ms/batch - loss: 24.46215 - diff: 41.77mlTrain batch 9/42 - 187.8ms/batch - loss: 23.66178 - diff: 41.07mlTrain batch 10/42 - 184.9ms/batch - loss: 23.32832 - diff: 40.95mlTrain batch 11/42 - 184.9ms/batch - loss: 22.59931 - diff: 40.21mlTrain batch 12/42 - 184.5ms/batch - loss: 23.41739 - diff: 40.64mlTrain batch 13/42 - 182.8ms/batch - loss: 23.56657 - diff: 40.92mlTrain batch 14/42 - 185.1ms/batch - loss: 23.49218 - diff: 40.91mlTrain batch 15/42 - 188.5ms/batch - loss: 23.46427 - diff: 41.08mlTrain batch 16/42 - 183.7ms/batch - loss: 23.98684 - diff: 41.15mlTrain batch 17/42 - 185.7ms/batch - loss: 23.78426 - diff: 41.12mlTrain batch 18/42 - 182.8ms/batch - loss: 23.54337 - diff: 41.02mlTrain batch 19/42 - 201.2ms/batch - loss: 23.52684 - diff: 41.10mlTrain batch 20/42 - 184.3ms/batch - loss: 23.52607 - diff: 41.14mlTrain batch 21/42 - 187.2ms/batch - loss: 24.01224 - diff: 41.36mlTrain batch 22/42 - 182.7ms/batch - loss: 24.01029 - diff: 41.38mlTrain batch 23/42 - 198.8ms/batch - loss: 23.79200 - diff: 41.11mlTrain batch 24/42 - 184.3ms/batch - loss: 23.72750 - diff: 41.05mlTrain batch 25/42 - 191.2ms/batch - loss: 23.72371 - diff: 41.01mlTrain batch 26/42 - 182.9ms/batch - loss: 23.63157 - diff: 40.96mlTrain batch 27/42 - 186.3ms/batch - loss: 23.76085 - diff: 40.89mlTrain batch 28/42 - 182.9ms/batch - loss: 23.84516 - diff: 41.04mlTrain batch 29/42 - 194.2ms/batch - loss: 23.95249 - diff: 41.16mlTrain batch 30/42 - 185.3ms/batch - loss: 23.94903 - diff: 41.24mlTrain batch 31/42 - 184.6ms/batch - loss: 23.88023 - diff: 41.22mlTrain batch 32/42 - 182.6ms/batch - loss: 23.80530 - diff: 41.16mlTrain batch 33/42 - 188.6ms/batch - loss: 24.37855 - diff: 41.30mlTrain batch 34/42 - 183.3ms/batch - loss: 24.52474 - diff: 41.44mlTrain batch 35/42 - 190.1ms/batch - loss: 24.70095 - diff: 41.67mlTrain batch 36/42 - 187.3ms/batch - loss: 24.51974 - diff: 41.56mlTrain batch 37/42 - 182.5ms/batch - loss: 24.42844 - diff: 41.53mlTrain batch 38/42 - 182.5ms/batch - loss: 24.48824 - diff: 41.49mlTrain batch 39/42 - 183.8ms/batch - loss: 24.61273 - diff: 41.59mlTrain batch 40/42 - 182.5ms/batch - loss: 24.69557 - diff: 41.60mlTrain batch 41/42 - 183.5ms/batch - loss: 24.73868 - diff: 41.69mlTrain batch 42/42 - 127.9ms/batch - loss: 25.00585 - diff: 41.74mlTrain batch 42/42 - 369.8s 127.9ms/batch - loss: 25.00585 - diff: 41.74ml
Test 140.8s: val_loss: 28.37638 - diff: 48.39ml

Epoch 47: current best loss = 20.44046, at epoch 43
Train batch 1/42 - 190.1ms/batch - loss: 25.91339 - diff: 44.44mlTrain batch 2/42 - 183.8ms/batch - loss: 27.09565 - diff: 43.69mlTrain batch 3/42 - 182.8ms/batch - loss: 25.41101 - diff: 41.78mlTrain batch 4/42 - 182.9ms/batch - loss: 27.41822 - diff: 42.50mlTrain batch 5/42 - 187.9ms/batch - loss: 25.49660 - diff: 41.31mlTrain batch 6/42 - 183.4ms/batch - loss: 26.45110 - diff: 41.68mlTrain batch 7/42 - 182.9ms/batch - loss: 26.62367 - diff: 42.39mlTrain batch 8/42 - 183.5ms/batch - loss: 26.44229 - diff: 42.61mlTrain batch 9/42 - 182.6ms/batch - loss: 25.65611 - diff: 42.15mlTrain batch 10/42 - 183.8ms/batch - loss: 24.74748 - diff: 41.46mlTrain batch 11/42 - 188.4ms/batch - loss: 24.65505 - diff: 41.36mlTrain batch 12/42 - 184.1ms/batch - loss: 24.58719 - diff: 41.33mlTrain batch 13/42 - 183.5ms/batch - loss: 25.50903 - diff: 41.73mlTrain batch 14/42 - 182.6ms/batch - loss: 25.19691 - diff: 41.83mlTrain batch 15/42 - 183.8ms/batch - loss: 25.00519 - diff: 41.70mlTrain batch 16/42 - 182.7ms/batch - loss: 25.29138 - diff: 41.97mlTrain batch 17/42 - 206.4ms/batch - loss: 25.46799 - diff: 42.42mlTrain batch 18/42 - 182.3ms/batch - loss: 25.89063 - diff: 42.54mlTrain batch 19/42 - 185.8ms/batch - loss: 25.88593 - diff: 42.68mlTrain batch 20/42 - 182.2ms/batch - loss: 26.08730 - diff: 42.69mlTrain batch 21/42 - 201.1ms/batch - loss: 25.99890 - diff: 42.70mlTrain batch 22/42 - 182.9ms/batch - loss: 25.98551 - diff: 42.81mlTrain batch 23/42 - 188.6ms/batch - loss: 25.66703 - diff: 42.67mlTrain batch 24/42 - 183.0ms/batch - loss: 25.19188 - diff: 42.23mlTrain batch 25/42 - 202.4ms/batch - loss: 25.44271 - diff: 42.20mlTrain batch 26/42 - 185.4ms/batch - loss: 25.54400 - diff: 42.31mlTrain batch 27/42 - 183.5ms/batch - loss: 25.45490 - diff: 42.34mlTrain batch 28/42 - 182.6ms/batch - loss: 25.16072 - diff: 42.19mlTrain batch 29/42 - 183.9ms/batch - loss: 25.21619 - diff: 42.05mlTrain batch 30/42 - 184.5ms/batch - loss: 25.28114 - diff: 41.94mlTrain batch 31/42 - 189.3ms/batch - loss: 25.18409 - diff: 41.91mlTrain batch 32/42 - 184.8ms/batch - loss: 25.07180 - diff: 41.88mlTrain batch 33/42 - 183.1ms/batch - loss: 24.86131 - diff: 41.73mlTrain batch 34/42 - 183.1ms/batch - loss: 24.96092 - diff: 41.87mlTrain batch 35/42 - 183.6ms/batch - loss: 24.90177 - diff: 41.89mlTrain batch 36/42 - 183.2ms/batch - loss: 24.97993 - diff: 41.97mlTrain batch 37/42 - 189.3ms/batch - loss: 24.69809 - diff: 41.76mlTrain batch 38/42 - 184.8ms/batch - loss: 24.53041 - diff: 41.71mlTrain batch 39/42 - 182.7ms/batch - loss: 24.64121 - diff: 41.67mlTrain batch 40/42 - 184.3ms/batch - loss: 24.54896 - diff: 41.61mlTrain batch 41/42 - 183.9ms/batch - loss: 24.57978 - diff: 41.52mlTrain batch 42/42 - 128.3ms/batch - loss: 24.69963 - diff: 41.43mlTrain batch 42/42 - 368.2s 128.3ms/batch - loss: 24.69963 - diff: 41.43ml
Test 139.3s: val_loss: 20.32830 - diff: 39.00ml
Saving new best model in models/checkpoints/preproc1_150x150_bySlices_dataset_full_Diastole_TimeAsDepth_1_SGD-0.001_DA2_best

Epoch 48: current best loss = 20.32830, at epoch 47
Train batch 1/42 - 186.0ms/batch - loss: 27.90157 - diff: 46.97mlTrain batch 2/42 - 183.3ms/batch - loss: 29.78259 - diff: 45.54mlTrain batch 3/42 - 190.7ms/batch - loss: 25.65443 - diff: 42.74mlTrain batch 4/42 - 184.1ms/batch - loss: 23.55003 - diff: 41.55mlTrain batch 5/42 - 183.7ms/batch - loss: 22.68608 - diff: 40.37mlTrain batch 6/42 - 182.4ms/batch - loss: 22.26232 - diff: 39.83mlTrain batch 7/42 - 187.5ms/batch - loss: 22.36241 - diff: 40.20mlTrain batch 8/42 - 183.3ms/batch - loss: 21.64563 - diff: 39.54mlTrain batch 9/42 - 195.2ms/batch - loss: 21.38472 - diff: 39.30mlTrain batch 10/42 - 188.4ms/batch - loss: 23.35655 - diff: 40.36mlTrain batch 11/42 - 184.8ms/batch - loss: 23.11659 - diff: 40.34mlTrain batch 12/42 - 183.6ms/batch - loss: 23.16444 - diff: 40.44mlTrain batch 13/42 - 183.5ms/batch - loss: 23.90821 - diff: 40.76mlTrain batch 14/42 - 183.1ms/batch - loss: 24.16920 - diff: 40.87mlTrain batch 15/42 - 191.2ms/batch - loss: 24.27286 - diff: 40.72mlTrain batch 16/42 - 183.9ms/batch - loss: 24.47651 - diff: 41.13mlTrain batch 17/42 - 185.8ms/batch - loss: 25.27233 - diff: 41.60mlTrain batch 18/42 - 182.5ms/batch - loss: 24.89925 - diff: 41.37mlTrain batch 19/42 - 204.1ms/batch - loss: 24.50278 - diff: 41.11mlTrain batch 20/42 - 184.2ms/batch - loss: 24.36219 - diff: 41.12mlTrain batch 21/42 - 185.3ms/batch - loss: 24.25607 - diff: 41.05mlTrain batch 22/42 - 182.4ms/batch - loss: 24.21859 - diff: 40.98mlTrain batch 23/42 - 202.3ms/batch - loss: 24.27611 - diff: 41.12mlTrain batch 24/42 - 185.2ms/batch - loss: 24.29497 - diff: 41.32mlTrain batch 25/42 - 188.0ms/batch - loss: 24.10114 - diff: 41.26mlTrain batch 26/42 - 182.8ms/batch - loss: 24.03944 - diff: 41.24mlTrain batch 27/42 - 185.5ms/batch - loss: 23.93121 - diff: 41.28mlTrain batch 28/42 - 183.8ms/batch - loss: 23.77490 - diff: 41.18mlTrain batch 29/42 - 188.6ms/batch - loss: 24.10672 - diff: 41.26mlTrain batch 30/42 - 183.3ms/batch - loss: 24.10191 - diff: 41.42mlTrain batch 31/42 - 184.1ms/batch - loss: 24.25025 - diff: 41.42mlTrain batch 32/42 - 183.5ms/batch - loss: 24.21641 - diff: 41.44mlTrain batch 33/42 - 183.5ms/batch - loss: 24.11645 - diff: 41.42mlTrain batch 34/42 - 184.6ms/batch - loss: 24.31863 - diff: 41.56mlTrain batch 35/42 - 188.3ms/batch - loss: 24.41081 - diff: 41.61mlTrain batch 36/42 - 184.4ms/batch - loss: 24.36642 - diff: 41.57mlTrain batch 37/42 - 182.7ms/batch - loss: 24.22659 - diff: 41.50mlTrain batch 38/42 - 183.6ms/batch - loss: 24.10792 - diff: 41.39mlTrain batch 39/42 - 183.8ms/batch - loss: 24.06457 - diff: 41.39mlTrain batch 40/42 - 186.5ms/batch - loss: 24.20431 - diff: 41.45mlTrain batch 41/42 - 188.1ms/batch - loss: 24.14418 - diff: 41.38mlTrain batch 42/42 - 129.0ms/batch - loss: 24.46465 - diff: 41.44mlTrain batch 42/42 - 364.7s 129.0ms/batch - loss: 24.46465 - diff: 41.44ml
Test 139.7s: val_loss: 20.09240 - diff: 38.84ml
Saving new best model in models/checkpoints/preproc1_150x150_bySlices_dataset_full_Diastole_TimeAsDepth_1_SGD-0.001_DA2_best

Epoch 49: current best loss = 20.09240, at epoch 48
Train batch 1/42 - 189.2ms/batch - loss: 37.56927 - diff: 50.02mlTrain batch 2/42 - 184.0ms/batch - loss: 31.81231 - diff: 48.88mlTrain batch 3/42 - 184.6ms/batch - loss: 26.98063 - diff: 45.16mlTrain batch 4/42 - 184.9ms/batch - loss: 25.31241 - diff: 43.83mlTrain batch 5/42 - 187.7ms/batch - loss: 25.04387 - diff: 42.16mlTrain batch 6/42 - 184.6ms/batch - loss: 26.10538 - diff: 42.38mlTrain batch 7/42 - 183.2ms/batch - loss: 26.04892 - diff: 41.84mlTrain batch 8/42 - 183.0ms/batch - loss: 25.30415 - diff: 41.40mlTrain batch 9/42 - 183.7ms/batch - loss: 25.22717 - diff: 41.02mlTrain batch 10/42 - 182.8ms/batch - loss: 27.03697 - diff: 42.21mlTrain batch 11/42 - 188.6ms/batch - loss: 26.40570 - diff: 42.11mlTrain batch 12/42 - 182.7ms/batch - loss: 25.57176 - diff: 41.63mlTrain batch 13/42 - 185.5ms/batch - loss: 25.09261 - diff: 41.33mlTrain batch 14/42 - 184.1ms/batch - loss: 25.46130 - diff: 41.60mlTrain batch 15/42 - 182.3ms/batch - loss: 25.76916 - diff: 41.98mlTrain batch 16/42 - 182.9ms/batch - loss: 25.64349 - diff: 41.90mlTrain batch 17/42 - 190.7ms/batch - loss: 25.87049 - diff: 42.20mlTrain batch 18/42 - 183.5ms/batch - loss: 26.47168 - diff: 42.71mlTrain batch 19/42 - 191.7ms/batch - loss: 26.40677 - diff: 42.81mlTrain batch 20/42 - 182.9ms/batch - loss: 26.10916 - diff: 42.73mlTrain batch 21/42 - 201.1ms/batch - loss: 25.73271 - diff: 42.54mlTrain batch 22/42 - 183.4ms/batch - loss: 25.63119 - diff: 42.49mlTrain batch 23/42 - 187.8ms/batch - loss: 25.82630 - diff: 42.72mlTrain batch 24/42 - 182.7ms/batch - loss: 25.57121 - diff: 42.60mlTrain batch 25/42 - 199.8ms/batch - loss: 25.48542 - diff: 42.57mlTrain batch 26/42 - 184.8ms/batch - loss: 25.50027 - diff: 42.68mlTrain batch 27/42 - 185.7ms/batch - loss: 25.66470 - diff: 42.78mlTrain batch 28/42 - 183.2ms/batch - loss: 25.74435 - diff: 42.96mlTrain batch 29/42 - 184.9ms/batch - loss: 25.85125 - diff: 43.04mlTrain batch 30/42 - 182.2ms/batch - loss: 25.85091 - diff: 43.11mlTrain batch 31/42 - 188.7ms/batch - loss: 25.85797 - diff: 43.10mlTrain batch 32/42 - 183.8ms/batch - loss: 25.70587 - diff: 42.93mlTrain batch 33/42 - 183.8ms/batch - loss: 25.50999 - diff: 42.80mlTrain batch 34/42 - 182.5ms/batch - loss: 25.44732 - diff: 42.76mlTrain batch 35/42 - 183.8ms/batch - loss: 25.37339 - diff: 42.80mlTrain batch 36/42 - 183.3ms/batch - loss: 25.29303 - diff: 42.78mlTrain batch 37/42 - 188.9ms/batch - loss: 25.18020 - diff: 42.72mlTrain batch 38/42 - 186.4ms/batch - loss: 25.08081 - diff: 42.72mlTrain batch 39/42 - 183.3ms/batch - loss: 24.99916 - diff: 42.65mlTrain batch 40/42 - 182.9ms/batch - loss: 25.42532 - diff: 42.77mlTrain batch 41/42 - 183.1ms/batch - loss: 25.33301 - diff: 42.71mlTrain batch 42/42 - 128.8ms/batch - loss: 25.42013 - diff: 42.65mlTrain batch 42/42 - 365.9s 128.8ms/batch - loss: 25.42013 - diff: 42.65ml
Test 137.9s: val_loss: 26.79492 - diff: 46.38ml

Epoch 50: current best loss = 20.09240, at epoch 48
Train batch 1/42 - 199.9ms/batch - loss: 32.86229 - diff: 49.02mlTrain batch 2/42 - 183.2ms/batch - loss: 29.04324 - diff: 48.21mlTrain batch 3/42 - 189.5ms/batch - loss: 26.21062 - diff: 45.68mlTrain batch 4/42 - 184.9ms/batch - loss: 26.27707 - diff: 46.11mlTrain batch 5/42 - 184.1ms/batch - loss: 26.20744 - diff: 45.42mlTrain batch 6/42 - 182.8ms/batch - loss: 26.29195 - diff: 45.43mlTrain batch 7/42 - 183.4ms/batch - loss: 25.49373 - diff: 44.89mlTrain batch 8/42 - 183.4ms/batch - loss: 24.96240 - diff: 44.22mlTrain batch 9/42 - 189.1ms/batch - loss: 24.77270 - diff: 44.12mlTrain batch 10/42 - 183.6ms/batch - loss: 25.32340 - diff: 43.90mlTrain batch 11/42 - 183.4ms/batch - loss: 24.06289 - diff: 42.59mlTrain batch 12/42 - 183.1ms/batch - loss: 24.84632 - diff: 42.64mlTrain batch 13/42 - 184.3ms/batch - loss: 24.29581 - diff: 42.28mlTrain batch 14/42 - 183.0ms/batch - loss: 24.30404 - diff: 42.31mlTrain batch 15/42 - 188.2ms/batch - loss: 24.37811 - diff: 42.57mlTrain batch 16/42 - 184.0ms/batch - loss: 23.98936 - diff: 42.34mlTrain batch 17/42 - 185.2ms/batch - loss: 24.07360 - diff: 42.49mlTrain batch 18/42 - 182.5ms/batch - loss: 23.74731 - diff: 42.18mlTrain batch 19/42 - 199.3ms/batch - loss: 23.36074 - diff: 41.91mlTrain batch 20/42 - 183.5ms/batch - loss: 23.12992 - diff: 41.74mlTrain batch 21/42 - 185.3ms/batch - loss: 22.75515 - diff: 41.43mlTrain batch 22/42 - 183.0ms/batch - loss: 22.54540 - diff: 41.21mlTrain batch 23/42 - 199.6ms/batch - loss: 22.48483 - diff: 41.16mlTrain batch 24/42 - 186.6ms/batch - loss: 22.51471 - diff: 41.19mlTrain batch 25/42 - 185.4ms/batch - loss: 22.28619 - diff: 40.97mlTrain batch 26/42 - 182.6ms/batch - loss: 23.03859 - diff: 41.37mlTrain batch 27/42 - 183.5ms/batch - loss: 23.08415 - diff: 41.51mlTrain batch 28/42 - 188.3ms/batch - loss: 22.96819 - diff: 41.43mlTrain batch 29/42 - 187.3ms/batch - loss: 23.27627 - diff: 41.50mlTrain batch 30/42 - 183.1ms/batch - loss: 23.17381 - diff: 41.40mlTrain batch 31/42 - 184.0ms/batch - loss: 23.04416 - diff: 41.31mlTrain batch 32/42 - 183.4ms/batch - loss: 22.98086 - diff: 41.22mlTrain batch 33/42 - 184.6ms/batch - loss: 23.03499 - diff: 41.23mlTrain batch 34/42 - 189.1ms/batch - loss: 23.55280 - diff: 41.43mlTrain batch 35/42 - 184.8ms/batch - loss: 23.77835 - diff: 41.39mlTrain batch 36/42 - 183.8ms/batch - loss: 23.70553 - diff: 41.37mlTrain batch 37/42 - 183.7ms/batch - loss: 24.21030 - diff: 41.54mlTrain batch 38/42 - 183.0ms/batch - loss: 24.15949 - diff: 41.51mlTrain batch 39/42 - 183.1ms/batch - loss: 24.97073 - diff: 41.99mlTrain batch 40/42 - 183.1ms/batch - loss: 25.17006 - diff: 42.17mlTrain batch 41/42 - 188.8ms/batch - loss: 25.47458 - diff: 42.38mlTrain batch 42/42 - 129.3ms/batch - loss: 25.72461 - diff: 42.37mlTrain batch 42/42 - 369.3s 129.3ms/batch - loss: 25.72461 - diff: 42.37ml
Test 137.2s: val_loss: 29.53076 - diff: 49.54ml

Epoch 51: current best loss = 20.09240, at epoch 48
Train batch 1/42 - 185.7ms/batch - loss: 25.94565 - diff: 40.15mlTrain batch 2/42 - 184.0ms/batch - loss: 22.11022 - diff: 38.99mlTrain batch 3/42 - 183.9ms/batch - loss: 25.69406 - diff: 40.59mlTrain batch 4/42 - 183.2ms/batch - loss: 25.22182 - diff: 41.14mlTrain batch 5/42 - 190.5ms/batch - loss: 28.08970 - diff: 42.56mlTrain batch 6/42 - 184.4ms/batch - loss: 27.74457 - diff: 42.58mlTrain batch 7/42 - 183.6ms/batch - loss: 27.68944 - diff: 43.18mlTrain batch 8/42 - 184.1ms/batch - loss: 27.81677 - diff: 43.03mlTrain batch 9/42 - 183.4ms/batch - loss: 26.94828 - diff: 42.60mlTrain batch 10/42 - 183.3ms/batch - loss: 26.59210 - diff: 42.43mlTrain batch 11/42 - 187.7ms/batch - loss: 25.91156 - diff: 42.02mlTrain batch 12/42 - 184.3ms/batch - loss: 25.38265 - diff: 41.77mlTrain batch 13/42 - 183.2ms/batch - loss: 25.21956 - diff: 41.93mlTrain batch 14/42 - 182.6ms/batch - loss: 24.87833 - diff: 41.64mlTrain batch 15/42 - 182.8ms/batch - loss: 25.36051 - diff: 41.70mlTrain batch 16/42 - 182.3ms/batch - loss: 24.92280 - diff: 41.50mlTrain batch 17/42 - 189.8ms/batch - loss: 24.60102 - diff: 41.25mlTrain batch 18/42 - 182.4ms/batch - loss: 24.53453 - diff: 40.99mlTrain batch 19/42 - 185.5ms/batch - loss: 24.85535 - diff: 41.10mlTrain batch 20/42 - 188.7ms/batch - loss: 24.70613 - diff: 41.09mlTrain batch 21/42 - 198.7ms/batch - loss: 24.50042 - diff: 40.93mlTrain batch 22/42 - 182.4ms/batch - loss: 24.45596 - diff: 40.94mlTrain batch 23/42 - 186.2ms/batch - loss: 24.30651 - diff: 40.88mlTrain batch 24/42 - 182.3ms/batch - loss: 24.12506 - diff: 40.92mlTrain batch 25/42 - 191.6ms/batch - loss: 23.92590 - diff: 40.75mlTrain batch 26/42 - 184.7ms/batch - loss: 23.87774 - diff: 40.70mlTrain batch 27/42 - 186.1ms/batch - loss: 24.00918 - diff: 40.75mlTrain batch 28/42 - 183.5ms/batch - loss: 24.08179 - diff: 40.78mlTrain batch 29/42 - 183.0ms/batch - loss: 24.40647 - diff: 41.17mlTrain batch 30/42 - 183.1ms/batch - loss: 24.29946 - diff: 41.21mlTrain batch 31/42 - 188.4ms/batch - loss: 24.45657 - diff: 41.22mlTrain batch 32/42 - 183.6ms/batch - loss: 24.73656 - diff: 41.29mlTrain batch 33/42 - 182.5ms/batch - loss: 24.99908 - diff: 41.38mlTrain batch 34/42 - 183.0ms/batch - loss: 24.96727 - diff: 41.44mlTrain batch 35/42 - 183.1ms/batch - loss: 25.17543 - diff: 41.55mlTrain batch 36/42 - 183.6ms/batch - loss: 25.08042 - diff: 41.56mlTrain batch 37/42 - 188.9ms/batch - loss: 25.02140 - diff: 41.60mlTrain batch 38/42 - 185.0ms/batch - loss: 24.86275 - diff: 41.52mlTrain batch 39/42 - 182.2ms/batch - loss: 25.02610 - diff: 41.62mlTrain batch 40/42 - 183.7ms/batch - loss: 25.01230 - diff: 41.66mlTrain batch 41/42 - 183.0ms/batch - loss: 25.20385 - diff: 41.73mlTrain batch 42/42 - 129.1ms/batch - loss: 25.48881 - diff: 41.70mlTrain batch 42/42 - 366.8s 129.1ms/batch - loss: 25.48881 - diff: 41.70ml
Test 136.4s: val_loss: 21.71060 - diff: 38.98ml

Epoch 52: current best loss = 20.09240, at epoch 48
Train batch 1/42 - 188.9ms/batch - loss: 30.76465 - diff: 48.13mlTrain batch 2/42 - 183.5ms/batch - loss: 28.09060 - diff: 46.06mlTrain batch 3/42 - 189.2ms/batch - loss: 26.50862 - diff: 44.78mlTrain batch 4/42 - 185.2ms/batch - loss: 26.81577 - diff: 44.68mlTrain batch 5/42 - 184.4ms/batch - loss: 26.63679 - diff: 44.25mlTrain batch 6/42 - 183.6ms/batch - loss: 25.20620 - diff: 43.10mlTrain batch 7/42 - 183.1ms/batch - loss: 25.67526 - diff: 43.69mlTrain batch 8/42 - 184.3ms/batch - loss: 24.81999 - diff: 43.08mlTrain batch 9/42 - 187.9ms/batch - loss: 23.84127 - diff: 42.36mlTrain batch 10/42 - 183.7ms/batch - loss: 23.25498 - diff: 41.53mlTrain batch 11/42 - 184.6ms/batch - loss: 23.95878 - diff: 41.71mlTrain batch 12/42 - 183.9ms/batch - loss: 23.97649 - diff: 41.64mlTrain batch 13/42 - 182.3ms/batch - loss: 23.85671 - diff: 41.11mlTrain batch 14/42 - 183.0ms/batch - loss: 24.04401 - diff: 41.01mlTrain batch 15/42 - 189.4ms/batch - loss: 24.31950 - diff: 41.27mlTrain batch 16/42 - 184.0ms/batch - loss: 24.31091 - diff: 41.57mlTrain batch 17/42 - 185.6ms/batch - loss: 24.31688 - diff: 41.50mlTrain batch 18/42 - 183.6ms/batch - loss: 24.29266 - diff: 41.42mlTrain batch 19/42 - 200.6ms/batch - loss: 24.44005 - diff: 41.53mlTrain batch 20/42 - 184.0ms/batch - loss: 24.59640 - diff: 41.64mlTrain batch 21/42 - 185.6ms/batch - loss: 24.92189 - diff: 41.66mlTrain batch 22/42 - 182.9ms/batch - loss: 24.94241 - diff: 41.82mlTrain batch 23/42 - 200.6ms/batch - loss: 25.03030 - diff: 42.05mlTrain batch 24/42 - 184.1ms/batch - loss: 24.87221 - diff: 42.04mlTrain batch 25/42 - 185.3ms/batch - loss: 24.58249 - diff: 41.85mlTrain batch 26/42 - 183.2ms/batch - loss: 24.84785 - diff: 42.05mlTrain batch 27/42 - 184.5ms/batch - loss: 24.76121 - diff: 42.09mlTrain batch 28/42 - 182.3ms/batch - loss: 24.62435 - diff: 41.94mlTrain batch 29/42 - 188.9ms/batch - loss: 24.71227 - diff: 42.04mlTrain batch 30/42 - 183.6ms/batch - loss: 25.22607 - diff: 42.39mlTrain batch 31/42 - 183.5ms/batch - loss: 25.40537 - diff: 42.41mlTrain batch 32/42 - 184.5ms/batch - loss: 25.35315 - diff: 42.44mlTrain batch 33/42 - 183.2ms/batch - loss: 25.07095 - diff: 42.21mlTrain batch 34/42 - 184.4ms/batch - loss: 24.95803 - diff: 42.12mlTrain batch 35/42 - 188.5ms/batch - loss: 25.38227 - diff: 42.15mlTrain batch 36/42 - 185.1ms/batch - loss: 25.29296 - diff: 42.14mlTrain batch 37/42 - 183.6ms/batch - loss: 25.39823 - diff: 42.15mlTrain batch 38/42 - 183.8ms/batch - loss: 25.26170 - diff: 42.09mlTrain batch 39/42 - 182.6ms/batch - loss: 25.36370 - diff: 42.14mlTrain batch 40/42 - 183.9ms/batch - loss: 25.30908 - diff: 42.18mlTrain batch 41/42 - 186.8ms/batch - loss: 25.15102 - diff: 42.11mlTrain batch 42/42 - 129.4ms/batch - loss: 25.74677 - diff: 42.09mlTrain batch 42/42 - 362.8s 129.4ms/batch - loss: 25.74677 - diff: 42.09ml
Test 136.3s: val_loss: 22.89742 - diff: 43.59ml

Epoch 53: current best loss = 20.09240, at epoch 48
Train batch 1/42 - 190.1ms/batch - loss: 25.30984 - diff: 40.96mlTrain batch 2/42 - 184.3ms/batch - loss: 32.21322 - diff: 44.77mlTrain batch 3/42 - 188.3ms/batch - loss: 29.10973 - diff: 43.77mlTrain batch 4/42 - 185.2ms/batch - loss: 26.90952 - diff: 42.76mlTrain batch 5/42 - 184.3ms/batch - loss: 26.39140 - diff: 42.49mlTrain batch 6/42 - 182.4ms/batch - loss: 25.71507 - diff: 42.20mlTrain batch 7/42 - 183.0ms/batch - loss: 25.80488 - diff: 42.36mlTrain batch 8/42 - 183.9ms/batch - loss: 25.24903 - diff: 42.14mlTrain batch 9/42 - 188.2ms/batch - loss: 26.84119 - diff: 42.91mlTrain batch 10/42 - 184.5ms/batch - loss: 26.75956 - diff: 43.17mlTrain batch 11/42 - 189.1ms/batch - loss: 25.89104 - diff: 42.60mlTrain batch 12/42 - 183.6ms/batch - loss: 25.42384 - diff: 42.22mlTrain batch 13/42 - 187.6ms/batch - loss: 25.95418 - diff: 42.38mlTrain batch 14/42 - 184.4ms/batch - loss: 27.48797 - diff: 42.78mlTrain batch 15/42 - 192.8ms/batch - loss: 27.67773 - diff: 42.77mlTrain batch 16/42 - 183.6ms/batch - loss: 27.60026 - diff: 42.94mlTrain batch 17/42 - 185.6ms/batch - loss: 27.40375 - diff: 42.95mlTrain batch 18/42 - 182.7ms/batch - loss: 27.00156 - diff: 42.65mlTrain batch 19/42 - 185.6ms/batch - loss: 27.04567 - diff: 42.53mlTrain batch 20/42 - 182.5ms/batch - loss: 27.17604 - diff: 42.60mlTrain batch 21/42 - 201.3ms/batch - loss: 26.51047 - diff: 42.11mlTrain batch 22/42 - 183.3ms/batch - loss: 26.55834 - diff: 42.11mlTrain batch 23/42 - 188.6ms/batch - loss: 26.77273 - diff: 42.26mlTrain batch 24/42 - 182.4ms/batch - loss: 26.58183 - diff: 42.24mlTrain batch 25/42 - 200.3ms/batch - loss: 26.22008 - diff: 41.97mlTrain batch 26/42 - 184.4ms/batch - loss: 26.04398 - diff: 41.88mlTrain batch 27/42 - 188.0ms/batch - loss: 25.79286 - diff: 41.74mlTrain batch 28/42 - 182.8ms/batch - loss: 25.82921 - diff: 41.82mlTrain batch 29/42 - 191.5ms/batch - loss: 25.52430 - diff: 41.64mlTrain batch 30/42 - 184.4ms/batch - loss: 25.38114 - diff: 41.59mlTrain batch 31/42 - 190.2ms/batch - loss: 25.27651 - diff: 41.53mlTrain batch 32/42 - 183.7ms/batch - loss: 25.11818 - diff: 41.43mlTrain batch 33/42 - 183.3ms/batch - loss: 25.18420 - diff: 41.42mlTrain batch 34/42 - 182.8ms/batch - loss: 25.04863 - diff: 41.35mlTrain batch 35/42 - 183.8ms/batch - loss: 24.82612 - diff: 41.19mlTrain batch 36/42 - 183.4ms/batch - loss: 24.73021 - diff: 41.12mlTrain batch 37/42 - 184.2ms/batch - loss: 24.61845 - diff: 41.06mlTrain batch 38/42 - 183.3ms/batch - loss: 24.70441 - diff: 41.05mlTrain batch 39/42 - 190.8ms/batch - loss: 24.55674 - diff: 40.99mlTrain batch 40/42 - 185.0ms/batch - loss: 24.83865 - diff: 41.16mlTrain batch 41/42 - 183.1ms/batch - loss: 24.78622 - diff: 41.13mlTrain batch 42/42 - 128.4ms/batch - loss: 24.86873 - diff: 41.10mlTrain batch 42/42 - 365.6s 128.4ms/batch - loss: 24.86873 - diff: 41.10ml
Test 137.9s: val_loss: 19.73725 - diff: 37.84ml
Saving new best model in models/checkpoints/preproc1_150x150_bySlices_dataset_full_Diastole_TimeAsDepth_1_SGD-0.001_DA2_best

Epoch 54: current best loss = 19.73725, at epoch 53
Train batch 1/42 - 188.8ms/batch - loss: 29.59142 - diff: 43.06mlTrain batch 2/42 - 184.5ms/batch - loss: 24.08324 - diff: 40.97mlTrain batch 3/42 - 191.1ms/batch - loss: 25.20768 - diff: 42.32mlTrain batch 4/42 - 185.7ms/batch - loss: 26.02098 - diff: 42.32mlTrain batch 5/42 - 183.8ms/batch - loss: 25.09443 - diff: 41.72mlTrain batch 6/42 - 182.9ms/batch - loss: 25.00291 - diff: 42.21mlTrain batch 7/42 - 182.8ms/batch - loss: 25.49464 - diff: 41.80mlTrain batch 8/42 - 184.4ms/batch - loss: 25.06551 - diff: 41.31mlTrain batch 9/42 - 187.2ms/batch - loss: 24.29164 - diff: 41.02mlTrain batch 10/42 - 204.0ms/batch - loss: 23.91685 - diff: 40.72mlTrain batch 11/42 - 184.0ms/batch - loss: 24.03086 - diff: 41.01mlTrain batch 12/42 - 186.2ms/batch - loss: 23.92860 - diff: 41.14mlTrain batch 13/42 - 185.4ms/batch - loss: 23.72405 - diff: 40.92mlTrain batch 14/42 - 182.9ms/batch - loss: 23.77847 - diff: 41.07mlTrain batch 15/42 - 190.3ms/batch - loss: 23.73243 - diff: 41.15mlTrain batch 16/42 - 182.4ms/batch - loss: 23.08487 - diff: 40.65mlTrain batch 17/42 - 185.4ms/batch - loss: 23.70727 - diff: 40.83mlTrain batch 18/42 - 182.4ms/batch - loss: 24.14864 - diff: 40.92mlTrain batch 19/42 - 209.3ms/batch - loss: 23.74277 - diff: 40.60mlTrain batch 20/42 - 184.0ms/batch - loss: 24.47159 - diff: 41.12mlTrain batch 21/42 - 185.0ms/batch - loss: 24.83937 - diff: 41.25mlTrain batch 22/42 - 182.3ms/batch - loss: 24.75855 - diff: 41.15mlTrain batch 23/42 - 198.6ms/batch - loss: 24.84797 - diff: 41.22mlTrain batch 24/42 - 182.5ms/batch - loss: 24.53944 - diff: 41.03mlTrain batch 25/42 - 185.2ms/batch - loss: 24.42984 - diff: 41.03mlTrain batch 26/42 - 182.8ms/batch - loss: 24.37891 - diff: 41.07mlTrain batch 27/42 - 184.1ms/batch - loss: 24.19042 - diff: 40.91mlTrain batch 28/42 - 183.3ms/batch - loss: 24.30780 - diff: 40.88mlTrain batch 29/42 - 188.0ms/batch - loss: 23.95384 - diff: 40.61mlTrain batch 30/42 - 182.9ms/batch - loss: 24.28455 - diff: 40.69mlTrain batch 31/42 - 183.5ms/batch - loss: 24.81830 - diff: 40.99mlTrain batch 32/42 - 183.1ms/batch - loss: 24.59566 - diff: 40.90mlTrain batch 33/42 - 183.4ms/batch - loss: 24.53551 - diff: 40.91mlTrain batch 34/42 - 183.1ms/batch - loss: 24.34644 - diff: 40.80mlTrain batch 35/42 - 188.3ms/batch - loss: 24.11658 - diff: 40.64mlTrain batch 36/42 - 185.4ms/batch - loss: 24.14930 - diff: 40.69mlTrain batch 37/42 - 182.8ms/batch - loss: 24.23825 - diff: 40.77mlTrain batch 38/42 - 183.6ms/batch - loss: 24.15514 - diff: 40.76mlTrain batch 39/42 - 183.9ms/batch - loss: 24.24486 - diff: 40.92mlTrain batch 40/42 - 184.4ms/batch - loss: 24.31424 - diff: 41.07mlTrain batch 41/42 - 188.2ms/batch - loss: 24.26205 - diff: 41.04mlTrain batch 42/42 - 129.8ms/batch - loss: 24.34126 - diff: 40.98mlTrain batch 42/42 - 364.0s 129.8ms/batch - loss: 24.34126 - diff: 40.98ml
Test 136.8s: val_loss: 23.92399 - diff: 40.94ml

Epoch 55: current best loss = 19.73725, at epoch 53
Train batch 1/42 - 195.8ms/batch - loss: 25.77386 - diff: 43.11mlTrain batch 2/42 - 185.1ms/batch - loss: 22.71492 - diff: 40.84mlTrain batch 3/42 - 184.7ms/batch - loss: 25.38731 - diff: 41.25mlTrain batch 4/42 - 183.2ms/batch - loss: 28.91798 - diff: 42.73mlTrain batch 5/42 - 183.0ms/batch - loss: 27.87741 - diff: 42.80mlTrain batch 6/42 - 183.2ms/batch - loss: 28.24330 - diff: 42.42mlTrain batch 7/42 - 188.4ms/batch - loss: 28.79384 - diff: 42.63mlTrain batch 8/42 - 184.1ms/batch - loss: 28.18744 - diff: 42.40mlTrain batch 9/42 - 187.6ms/batch - loss: 28.94673 - diff: 42.77mlTrain batch 10/42 - 185.0ms/batch - loss: 28.37077 - diff: 42.61mlTrain batch 11/42 - 188.9ms/batch - loss: 28.14992 - diff: 42.74mlTrain batch 12/42 - 203.3ms/batch - loss: 28.02709 - diff: 43.00mlTrain batch 13/42 - 182.9ms/batch - loss: 27.56232 - diff: 42.93mlTrain batch 14/42 - 182.4ms/batch - loss: 27.02276 - diff: 42.54mlTrain batch 15/42 - 200.1ms/batch - loss: 27.16100 - diff: 42.55mlTrain batch 16/42 - 183.5ms/batch - loss: 26.84621 - diff: 42.37mlTrain batch 17/42 - 187.3ms/batch - loss: 26.51510 - diff: 42.31mlTrain batch 18/42 - 183.3ms/batch - loss: 25.89353 - diff: 41.98mlTrain batch 19/42 - 201.8ms/batch - loss: 26.10021 - diff: 42.16mlTrain batch 20/42 - 182.9ms/batch - loss: 25.78391 - diff: 42.10mlTrain batch 21/42 - 185.3ms/batch - loss: 25.42478 - diff: 41.98mlTrain batch 22/42 - 182.3ms/batch - loss: 25.30499 - diff: 41.90mlTrain batch 23/42 - 201.8ms/batch - loss: 25.16888 - diff: 41.79mlTrain batch 24/42 - 183.6ms/batch - loss: 24.98819 - diff: 41.71mlTrain batch 25/42 - 192.9ms/batch - loss: 24.81878 - diff: 41.63mlTrain batch 26/42 - 183.3ms/batch - loss: 24.85381 - diff: 41.68mlTrain batch 27/42 - 189.2ms/batch - loss: 24.73324 - diff: 41.58mlTrain batch 28/42 - 183.3ms/batch - loss: 24.79033 - diff: 41.62mlTrain batch 29/42 - 188.2ms/batch - loss: 24.65698 - diff: 41.60mlTrain batch 30/42 - 182.7ms/batch - loss: 24.53702 - diff: 41.49mlTrain batch 31/42 - 183.4ms/batch - loss: 24.50290 - diff: 41.56mlTrain batch 32/42 - 182.4ms/batch - loss: 24.48448 - diff: 41.63mlTrain batch 33/42 - 183.9ms/batch - loss: 24.40481 - diff: 41.52mlTrain batch 34/42 - 182.9ms/batch - loss: 24.37156 - diff: 41.50mlTrain batch 35/42 - 188.3ms/batch - loss: 24.31441 - diff: 41.46mlTrain batch 36/42 - 185.6ms/batch - loss: 24.71780 - diff: 41.59mlTrain batch 37/42 - 182.2ms/batch - loss: 24.89156 - diff: 41.73mlTrain batch 38/42 - 183.3ms/batch - loss: 24.77656 - diff: 41.70mlTrain batch 39/42 - 202.4ms/batch - loss: 24.74237 - diff: 41.79mlTrain batch 40/42 - 184.3ms/batch - loss: 24.75196 - diff: 41.84mlTrain batch 41/42 - 195.9ms/batch - loss: 24.80254 - diff: 41.81mlTrain batch 42/42 - 142.9ms/batch - loss: 24.99220 - diff: 41.77mlTrain batch 42/42 - 371.7s 142.9ms/batch - loss: 24.99220 - diff: 41.77ml
Test 138.1s: val_loss: 29.51804 - diff: 46.81ml

Epoch 56: current best loss = 19.73725, at epoch 53
Train batch 1/42 - 188.1ms/batch - loss: 39.43156 - diff: 49.79mlTrain batch 2/42 - 183.4ms/batch - loss: 36.22284 - diff: 47.17mlTrain batch 3/42 - 186.8ms/batch - loss: 33.28435 - diff: 45.58mlTrain batch 4/42 - 184.4ms/batch - loss: 34.14634 - diff: 45.42mlTrain batch 5/42 - 184.3ms/batch - loss: 32.70059 - diff: 45.82mlTrain batch 6/42 - 182.8ms/batch - loss: 31.56757 - diff: 45.78mlTrain batch 7/42 - 183.4ms/batch - loss: 30.05457 - diff: 45.22mlTrain batch 8/42 - 183.5ms/batch - loss: 28.98641 - diff: 44.22mlTrain batch 9/42 - 188.9ms/batch - loss: 28.97967 - diff: 44.27mlTrain batch 10/42 - 184.1ms/batch - loss: 28.28905 - diff: 43.65mlTrain batch 11/42 - 183.6ms/batch - loss: 27.88508 - diff: 43.47mlTrain batch 12/42 - 183.6ms/batch - loss: 27.73000 - diff: 42.98mlTrain batch 13/42 - 182.5ms/batch - loss: 27.80198 - diff: 43.01mlTrain batch 14/42 - 182.6ms/batch - loss: 27.97814 - diff: 43.07mlTrain batch 15/42 - 199.9ms/batch - loss: 27.58585 - diff: 42.98mlTrain batch 16/42 - 183.8ms/batch - loss: 27.32821 - diff: 42.90mlTrain batch 17/42 - 192.3ms/batch - loss: 26.90091 - diff: 42.59mlTrain batch 18/42 - 182.7ms/batch - loss: 26.31117 - diff: 42.10mlTrain batch 19/42 - 211.6ms/batch - loss: 26.42112 - diff: 42.01mlTrain batch 20/42 - 183.9ms/batch - loss: 26.28057 - diff: 42.05mlTrain batch 21/42 - 192.8ms/batch - loss: 26.27313 - diff: 42.02mlTrain batch 22/42 - 183.0ms/batch - loss: 26.15090 - diff: 41.97mlTrain batch 23/42 - 225.6ms/batch - loss: 26.12314 - diff: 42.03mlTrain batch 24/42 - 183.1ms/batch - loss: 26.49422 - diff: 42.28mlTrain batch 25/42 - 187.8ms/batch - loss: 26.52809 - diff: 42.30mlTrain batch 26/42 - 183.1ms/batch - loss: 26.59201 - diff: 42.31mlTrain batch 27/42 - 184.0ms/batch - loss: 26.35274 - diff: 42.08mlTrain batch 28/42 - 184.6ms/batch - loss: 26.10895 - diff: 41.93mlTrain batch 29/42 - 194.2ms/batch - loss: 26.03087 - diff: 41.90mlTrain batch 30/42 - 184.3ms/batch - loss: 25.90733 - diff: 41.87mlTrain batch 31/42 - 183.1ms/batch - loss: 25.76012 - diff: 41.85mlTrain batch 32/42 - 184.3ms/batch - loss: 25.88794 - diff: 41.83mlTrain batch 33/42 - 184.0ms/batch - loss: 25.80831 - diff: 41.90mlTrain batch 34/42 - 184.1ms/batch - loss: 25.90694 - diff: 42.02mlTrain batch 35/42 - 187.2ms/batch - loss: 25.81122 - diff: 41.98mlTrain batch 36/42 - 185.0ms/batch - loss: 25.81918 - diff: 42.05mlTrain batch 37/42 - 183.7ms/batch - loss: 25.67796 - diff: 41.82mlTrain batch 38/42 - 183.5ms/batch - loss: 25.50991 - diff: 41.71mlTrain batch 39/42 - 182.3ms/batch - loss: 25.36907 - diff: 41.68mlTrain batch 40/42 - 183.3ms/batch - loss: 25.36231 - diff: 41.68mlTrain batch 41/42 - 183.4ms/batch - loss: 25.15595 - diff: 41.56mlTrain batch 42/42 - 129.0ms/batch - loss: 25.25809 - diff: 41.53mlTrain batch 42/42 - 366.0s 129.0ms/batch - loss: 25.25809 - diff: 41.53ml
Test 139.3s: val_loss: 23.87154 - diff: 40.91ml

Epoch 57: current best loss = 19.73725, at epoch 53
Train batch 1/42 - 185.3ms/batch - loss: 25.55138 - diff: 44.86mlTrain batch 2/42 - 182.9ms/batch - loss: 22.13790 - diff: 41.44mlTrain batch 3/42 - 203.5ms/batch - loss: 20.49325 - diff: 39.65mlTrain batch 4/42 - 183.5ms/batch - loss: 21.69204 - diff: 40.11mlTrain batch 5/42 - 183.8ms/batch - loss: 22.07530 - diff: 40.22mlTrain batch 6/42 - 183.2ms/batch - loss: 21.95183 - diff: 40.09mlTrain batch 7/42 - 183.2ms/batch - loss: 22.57171 - diff: 40.59mlTrain batch 8/42 - 182.6ms/batch - loss: 22.47605 - diff: 40.58mlTrain batch 9/42 - 189.4ms/batch - loss: 22.53039 - diff: 40.73mlTrain batch 10/42 - 582.8ms/batch - loss: 22.34524 - diff: 40.58mlTrain batch 11/42 - 183.4ms/batch - loss: 21.98530 - diff: 40.26mlTrain batch 12/42 - 184.0ms/batch - loss: 23.02513 - diff: 40.77mlTrain batch 13/42 - 183.2ms/batch - loss: 23.08878 - diff: 40.92mlTrain batch 14/42 - 183.1ms/batch - loss: 22.71556 - diff: 40.59mlTrain batch 15/42 - 190.8ms/batch - loss: 22.82817 - diff: 40.50mlTrain batch 16/42 - 183.7ms/batch - loss: 22.77047 - diff: 40.36mlTrain batch 17/42 - 185.9ms/batch - loss: 22.54884 - diff: 40.27mlTrain batch 18/42 - 183.0ms/batch - loss: 22.63796 - diff: 40.34mlTrain batch 19/42 - 200.6ms/batch - loss: 22.42554 - diff: 40.25mlTrain batch 20/42 - 183.7ms/batch - loss: 22.60932 - diff: 40.45mlTrain batch 21/42 - 185.7ms/batch - loss: 22.63023 - diff: 40.44mlTrain batch 22/42 - 182.5ms/batch - loss: 22.47805 - diff: 40.29mlTrain batch 23/42 - 198.3ms/batch - loss: 22.80472 - diff: 40.55mlTrain batch 24/42 - 182.4ms/batch - loss: 23.44639 - diff: 40.69mlTrain batch 25/42 - 186.1ms/batch - loss: 23.36814 - diff: 40.76mlTrain batch 26/42 - 183.3ms/batch - loss: 23.23819 - diff: 40.73mlTrain batch 27/42 - 186.8ms/batch - loss: 23.32825 - diff: 40.76mlTrain batch 28/42 - 184.2ms/batch - loss: 23.28319 - diff: 40.77mlTrain batch 29/42 - 188.5ms/batch - loss: 23.07157 - diff: 40.64mlTrain batch 30/42 - 184.2ms/batch - loss: 22.82497 - diff: 40.40mlTrain batch 31/42 - 182.9ms/batch - loss: 22.95648 - diff: 40.43mlTrain batch 32/42 - 183.9ms/batch - loss: 23.12865 - diff: 40.57mlTrain batch 33/42 - 183.9ms/batch - loss: 23.21368 - diff: 40.58mlTrain batch 34/42 - 182.5ms/batch - loss: 23.31882 - diff: 40.56mlTrain batch 35/42 - 190.0ms/batch - loss: 23.48257 - diff: 40.65mlTrain batch 36/42 - 185.5ms/batch - loss: 23.38154 - diff: 40.64mlTrain batch 37/42 - 183.8ms/batch - loss: 23.14108 - diff: 40.49mlTrain batch 38/42 - 182.9ms/batch - loss: 23.88539 - diff: 40.89mlTrain batch 39/42 - 184.5ms/batch - loss: 23.79823 - diff: 40.84mlTrain batch 40/42 - 182.7ms/batch - loss: 23.68928 - diff: 40.76mlTrain batch 41/42 - 188.8ms/batch - loss: 23.52195 - diff: 40.67mlTrain batch 42/42 - 129.4ms/batch - loss: 23.88811 - diff: 40.70mlTrain batch 42/42 - 368.2s 129.4ms/batch - loss: 23.88811 - diff: 40.70ml
Test 140.0s: val_loss: 20.23561 - diff: 38.69ml

Epoch 58: current best loss = 19.73725, at epoch 53
Train batch 1/42 - 192.9ms/batch - loss: 17.34842 - diff: 37.02mlTrain batch 2/42 - 182.8ms/batch - loss: 25.01682 - diff: 40.93mlTrain batch 3/42 - 188.1ms/batch - loss: 22.40876 - diff: 38.58mlTrain batch 4/42 - 184.3ms/batch - loss: 22.58200 - diff: 39.26mlTrain batch 5/42 - 183.1ms/batch - loss: 22.18679 - diff: 38.92mlTrain batch 6/42 - 182.7ms/batch - loss: 22.48681 - diff: 39.14mlTrain batch 7/42 - 183.1ms/batch - loss: 22.41086 - diff: 39.26mlTrain batch 8/42 - 182.7ms/batch - loss: 21.47668 - diff: 38.65mlTrain batch 9/42 - 188.2ms/batch - loss: 21.78091 - diff: 39.17mlTrain batch 10/42 - 185.1ms/batch - loss: 22.23983 - diff: 39.38mlTrain batch 11/42 - 184.3ms/batch - loss: 21.86828 - diff: 39.13mlTrain batch 12/42 - 183.2ms/batch - loss: 22.45405 - diff: 39.23mlTrain batch 13/42 - 183.0ms/batch - loss: 23.14791 - diff: 39.53mlTrain batch 14/42 - 182.8ms/batch - loss: 22.86175 - diff: 39.34mlTrain batch 15/42 - 188.7ms/batch - loss: 23.27645 - diff: 39.80mlTrain batch 16/42 - 184.1ms/batch - loss: 23.42300 - diff: 40.21mlTrain batch 17/42 - 182.8ms/batch - loss: 23.70093 - diff: 40.53mlTrain batch 18/42 - 182.7ms/batch - loss: 23.65906 - diff: 40.60mlTrain batch 19/42 - 190.8ms/batch - loss: 23.25782 - diff: 40.31mlTrain batch 20/42 - 184.0ms/batch - loss: 22.99574 - diff: 40.14mlTrain batch 21/42 - 185.3ms/batch - loss: 22.78461 - diff: 40.01mlTrain batch 22/42 - 182.9ms/batch - loss: 23.07657 - diff: 40.23mlTrain batch 23/42 - 190.7ms/batch - loss: 23.29981 - diff: 40.52mlTrain batch 24/42 - 184.9ms/batch - loss: 23.20798 - diff: 40.63mlTrain batch 25/42 - 182.3ms/batch - loss: 23.34153 - diff: 40.91mlTrain batch 26/42 - 183.3ms/batch - loss: 23.47803 - diff: 40.93mlTrain batch 27/42 - 183.7ms/batch - loss: 23.98781 - diff: 40.95mlTrain batch 28/42 - 183.1ms/batch - loss: 23.88352 - diff: 40.90mlTrain batch 29/42 - 190.6ms/batch - loss: 24.09308 - diff: 40.90mlTrain batch 30/42 - 186.2ms/batch - loss: 23.91334 - diff: 40.78mlTrain batch 31/42 - 183.0ms/batch - loss: 24.11675 - diff: 40.88mlTrain batch 32/42 - 182.6ms/batch - loss: 23.96511 - diff: 40.86mlTrain batch 33/42 - 183.4ms/batch - loss: 23.78687 - diff: 40.75mlTrain batch 34/42 - 183.5ms/batch - loss: 23.69035 - diff: 40.73mlTrain batch 35/42 - 188.7ms/batch - loss: 23.46914 - diff: 40.54mlTrain batch 36/42 - 184.2ms/batch - loss: 23.61529 - diff: 40.56mlTrain batch 37/42 - 182.7ms/batch - loss: 23.74039 - diff: 40.63mlTrain batch 38/42 - 183.9ms/batch - loss: 23.86079 - diff: 40.70mlTrain batch 39/42 - 183.7ms/batch - loss: 23.99883 - diff: 40.92mlTrain batch 40/42 - 183.1ms/batch - loss: 24.01856 - diff: 41.00mlTrain batch 41/42 - 182.9ms/batch - loss: 23.91692 - diff: 40.95mlTrain batch 42/42 - 127.3ms/batch - loss: 24.57687 - diff: 41.07mlTrain batch 42/42 - 364.8s 127.3ms/batch - loss: 24.57687 - diff: 41.07ml
Test 136.2s: val_loss: 28.04415 - diff: 47.69ml

Epoch 59: current best loss = 19.73725, at epoch 53
Train batch 1/42 - 190.3ms/batch - loss: 19.74765 - diff: 37.48mlTrain batch 2/42 - 185.0ms/batch - loss: 21.11202 - diff: 40.96mlTrain batch 3/42 - 188.5ms/batch - loss: 22.27458 - diff: 41.57mlTrain batch 4/42 - 183.8ms/batch - loss: 23.83947 - diff: 41.32mlTrain batch 5/42 - 184.2ms/batch - loss: 25.30955 - diff: 41.82mlTrain batch 6/42 - 183.9ms/batch - loss: 24.81759 - diff: 41.24mlTrain batch 7/42 - 183.4ms/batch - loss: 24.74105 - diff: 41.15mlTrain batch 8/42 - 182.4ms/batch - loss: 25.61309 - diff: 41.33mlTrain batch 9/42 - 189.5ms/batch - loss: 25.80711 - diff: 41.24mlTrain batch 10/42 - 184.0ms/batch - loss: 27.36240 - diff: 42.46mlTrain batch 11/42 - 182.3ms/batch - loss: 27.29771 - diff: 42.80mlTrain batch 12/42 - 183.1ms/batch - loss: 26.70311 - diff: 42.64mlTrain batch 13/42 - 182.6ms/batch - loss: 26.21722 - diff: 42.58mlTrain batch 14/42 - 182.2ms/batch - loss: 25.50049 - diff: 42.05mlTrain batch 15/42 - 218.7ms/batch - loss: 25.73477 - diff: 42.16mlTrain batch 16/42 - 184.0ms/batch - loss: 25.93612 - diff: 41.93mlTrain batch 17/42 - 187.7ms/batch - loss: 26.21284 - diff: 42.29mlTrain batch 18/42 - 182.1ms/batch - loss: 25.97313 - diff: 42.29mlTrain batch 19/42 - 205.1ms/batch - loss: 25.84735 - diff: 42.23mlTrain batch 20/42 - 186.3ms/batch - loss: 26.03991 - diff: 42.32mlTrain batch 21/42 - 185.9ms/batch - loss: 26.34618 - diff: 42.82mlTrain batch 22/42 - 183.1ms/batch - loss: 26.20029 - diff: 42.82mlTrain batch 23/42 - 207.6ms/batch - loss: 26.23425 - diff: 42.81mlTrain batch 24/42 - 183.7ms/batch - loss: 25.96253 - diff: 42.72mlTrain batch 25/42 - 185.5ms/batch - loss: 25.82734 - diff: 42.69mlTrain batch 26/42 - 183.2ms/batch - loss: 25.66403 - diff: 42.53mlTrain batch 27/42 - 183.7ms/batch - loss: 25.62473 - diff: 42.55mlTrain batch 28/42 - 184.8ms/batch - loss: 25.44065 - diff: 42.48mlTrain batch 29/42 - 192.6ms/batch - loss: 25.19200 - diff: 42.29mlTrain batch 30/42 - 184.5ms/batch - loss: 24.89346 - diff: 42.08mlTrain batch 31/42 - 183.6ms/batch - loss: 24.70831 - diff: 41.91mlTrain batch 32/42 - 183.3ms/batch - loss: 24.44318 - diff: 41.72mlTrain batch 33/42 - 187.8ms/batch - loss: 24.49399 - diff: 41.66mlTrain batch 34/42 - 200.5ms/batch - loss: 24.42949 - diff: 41.65mlTrain batch 35/42 - 189.5ms/batch - loss: 24.56919 - diff: 41.73mlTrain batch 36/42 - 185.3ms/batch - loss: 24.42041 - diff: 41.62mlTrain batch 37/42 - 186.1ms/batch - loss: 24.34346 - diff: 41.58mlTrain batch 38/42 - 184.5ms/batch - loss: 24.22673 - diff: 41.47mlTrain batch 39/42 - 183.6ms/batch - loss: 24.09496 - diff: 41.41mlTrain batch 40/42 - 183.2ms/batch - loss: 24.15123 - diff: 41.49mlTrain batch 41/42 - 183.2ms/batch - loss: 24.48820 - diff: 41.64mlTrain batch 42/42 - 128.5ms/batch - loss: 24.59051 - diff: 41.62mlTrain batch 42/42 - 367.8s 128.5ms/batch - loss: 24.59051 - diff: 41.62ml
Test 137.6s: val_loss: 19.29743 - diff: 37.65ml
Saving new best model in models/checkpoints/preproc1_150x150_bySlices_dataset_full_Diastole_TimeAsDepth_1_SGD-0.001_DA2_best

Epoch 60: current best loss = 19.29743, at epoch 59
Train batch 1/42 - 191.9ms/batch - loss: 18.78512 - diff: 37.06mlTrain batch 2/42 - 185.7ms/batch - loss: 19.50339 - diff: 37.72mlTrain batch 3/42 - 184.4ms/batch - loss: 21.15709 - diff: 39.34mlTrain batch 4/42 - 183.7ms/batch - loss: 21.85561 - diff: 39.18mlTrain batch 5/42 - 183.2ms/batch - loss: 21.51578 - diff: 39.02mlTrain batch 6/42 - 183.3ms/batch - loss: 21.77799 - diff: 39.51mlTrain batch 7/42 - 182.8ms/batch - loss: 21.78134 - diff: 39.96mlTrain batch 8/42 - 182.7ms/batch - loss: 21.93230 - diff: 40.23mlTrain batch 9/42 - 188.8ms/batch - loss: 21.51027 - diff: 39.81mlTrain batch 10/42 - 185.7ms/batch - loss: 21.65570 - diff: 40.04mlTrain batch 11/42 - 184.0ms/batch - loss: 21.17128 - diff: 39.56mlTrain batch 12/42 - 182.4ms/batch - loss: 21.30942 - diff: 39.56mlTrain batch 13/42 - 183.2ms/batch - loss: 21.34124 - diff: 39.38mlTrain batch 14/42 - 182.6ms/batch - loss: 21.53399 - diff: 39.52mlTrain batch 15/42 - 194.3ms/batch - loss: 21.24556 - diff: 39.28mlTrain batch 16/42 - 184.2ms/batch - loss: 21.51481 - diff: 39.54mlTrain batch 17/42 - 183.6ms/batch - loss: 21.36037 - diff: 39.60mlTrain batch 18/42 - 182.8ms/batch - loss: 21.65092 - diff: 39.76mlTrain batch 19/42 - 190.3ms/batch - loss: 21.76849 - diff: 39.80mlTrain batch 20/42 - 183.0ms/batch - loss: 21.70064 - diff: 39.73mlTrain batch 21/42 - 185.4ms/batch - loss: 21.57961 - diff: 39.69mlTrain batch 22/42 - 182.8ms/batch - loss: 21.87404 - diff: 39.83mlTrain batch 23/42 - 201.2ms/batch - loss: 21.90011 - diff: 39.91mlTrain batch 24/42 - 184.2ms/batch - loss: 21.89573 - diff: 39.89mlTrain batch 25/42 - 182.8ms/batch - loss: 21.82378 - diff: 39.80mlTrain batch 26/42 - 184.7ms/batch - loss: 21.80885 - diff: 39.78mlTrain batch 27/42 - 186.8ms/batch - loss: 22.29315 - diff: 39.87mlTrain batch 28/42 - 182.9ms/batch - loss: 22.30924 - diff: 39.71mlTrain batch 29/42 - 189.5ms/batch - loss: 22.98586 - diff: 39.95mlTrain batch 30/42 - 184.0ms/batch - loss: 22.97685 - diff: 40.01mlTrain batch 31/42 - 183.6ms/batch - loss: 22.86900 - diff: 39.95mlTrain batch 32/42 - 183.3ms/batch - loss: 22.87763 - diff: 39.94mlTrain batch 33/42 - 183.0ms/batch - loss: 22.99891 - diff: 39.98mlTrain batch 34/42 - 182.4ms/batch - loss: 22.82423 - diff: 39.82mlTrain batch 35/42 - 189.4ms/batch - loss: 23.29309 - diff: 40.07mlTrain batch 36/42 - 184.4ms/batch - loss: 23.13088 - diff: 40.04mlTrain batch 37/42 - 183.5ms/batch - loss: 23.11463 - diff: 40.11mlTrain batch 38/42 - 183.1ms/batch - loss: 23.12712 - diff: 40.22mlTrain batch 39/42 - 182.4ms/batch - loss: 23.01150 - diff: 40.11mlTrain batch 40/42 - 184.0ms/batch - loss: 23.07591 - diff: 40.18mlTrain batch 41/42 - 212.8ms/batch - loss: 22.99109 - diff: 40.13mlTrain batch 42/42 - 129.5ms/batch - loss: 23.04083 - diff: 40.05mlTrain batch 42/42 - 366.7s 129.5ms/batch - loss: 23.04083 - diff: 40.05ml
Test 139.9s: val_loss: 21.08533 - diff: 39.09ml

Epoch 61: current best loss = 19.29743, at epoch 59
Train batch 1/42 - 188.7ms/batch - loss: 23.42695 - diff: 35.51mlTrain batch 2/42 - 184.5ms/batch - loss: 22.40780 - diff: 38.38mlTrain batch 3/42 - 183.0ms/batch - loss: 22.37523 - diff: 39.10mlTrain batch 4/42 - 182.8ms/batch - loss: 20.82356 - diff: 38.29mlTrain batch 5/42 - 187.9ms/batch - loss: 21.40906 - diff: 38.81mlTrain batch 6/42 - 184.7ms/batch - loss: 23.03832 - diff: 39.54mlTrain batch 7/42 - 183.2ms/batch - loss: 22.45224 - diff: 39.52mlTrain batch 8/42 - 182.8ms/batch - loss: 22.52860 - diff: 39.74mlTrain batch 9/42 - 184.5ms/batch - loss: 22.50498 - diff: 39.80mlTrain batch 10/42 - 184.8ms/batch - loss: 22.53474 - diff: 39.99mlTrain batch 11/42 - 189.2ms/batch - loss: 22.52572 - diff: 40.14mlTrain batch 12/42 - 183.8ms/batch - loss: 22.34978 - diff: 40.11mlTrain batch 13/42 - 182.7ms/batch - loss: 22.04925 - diff: 39.92mlTrain batch 14/42 - 182.5ms/batch - loss: 22.46795 - diff: 40.40mlTrain batch 15/42 - 185.2ms/batch - loss: 22.26094 - diff: 40.36mlTrain batch 16/42 - 182.4ms/batch - loss: 22.34262 - diff: 40.24mlTrain batch 17/42 - 201.1ms/batch - loss: 22.55758 - diff: 40.48mlTrain batch 18/42 - 183.4ms/batch - loss: 22.69789 - diff: 40.64mlTrain batch 19/42 - 187.5ms/batch - loss: 22.56904 - diff: 40.53mlTrain batch 20/42 - 182.3ms/batch - loss: 22.39348 - diff: 40.46mlTrain batch 21/42 - 200.5ms/batch - loss: 22.27925 - diff: 40.47mlTrain batch 22/42 - 183.5ms/batch - loss: 22.24248 - diff: 40.52mlTrain batch 23/42 - 185.4ms/batch - loss: 22.07818 - diff: 40.43mlTrain batch 24/42 - 183.2ms/batch - loss: 22.20640 - diff: 40.36mlTrain batch 25/42 - 192.8ms/batch - loss: 22.20113 - diff: 40.36mlTrain batch 26/42 - 183.7ms/batch - loss: 22.46976 - diff: 40.40mlTrain batch 27/42 - 190.1ms/batch - loss: 22.42236 - diff: 40.36mlTrain batch 28/42 - 183.6ms/batch - loss: 22.39354 - diff: 40.36mlTrain batch 29/42 - 187.1ms/batch - loss: 22.72249 - diff: 40.49mlTrain batch 30/42 - 182.5ms/batch - loss: 22.87509 - diff: 40.52mlTrain batch 31/42 - 191.6ms/batch - loss: 23.06957 - diff: 40.60mlTrain batch 32/42 - 184.1ms/batch - loss: 23.04284 - diff: 40.59mlTrain batch 33/42 - 197.3ms/batch - loss: 23.00053 - diff: 40.54mlTrain batch 34/42 - 183.4ms/batch - loss: 22.93552 - diff: 40.51mlTrain batch 35/42 - 183.3ms/batch - loss: 23.15237 - diff: 40.62mlTrain batch 36/42 - 183.7ms/batch - loss: 22.94177 - diff: 40.48mlTrain batch 37/42 - 183.6ms/batch - loss: 23.15524 - diff: 40.66mlTrain batch 38/42 - 183.8ms/batch - loss: 23.31130 - diff: 40.78mlTrain batch 39/42 - 188.9ms/batch - loss: 23.30847 - diff: 40.77mlTrain batch 40/42 - 184.5ms/batch - loss: 23.19718 - diff: 40.70mlTrain batch 41/42 - 182.6ms/batch - loss: 23.31299 - diff: 40.76mlTrain batch 42/42 - 129.1ms/batch - loss: 23.61033 - diff: 40.83mlTrain batch 42/42 - 372.5s 129.1ms/batch - loss: 23.61033 - diff: 40.83ml
Test 138.9s: val_loss: 25.17507 - diff: 43.93ml

Epoch 62: current best loss = 19.29743, at epoch 59
Train batch 1/42 - 188.5ms/batch - loss: 21.50033 - diff: 39.63mlTrain batch 2/42 - 183.1ms/batch - loss: 19.78843 - diff: 37.68mlTrain batch 3/42 - 188.3ms/batch - loss: 18.72824 - diff: 37.03mlTrain batch 4/42 - 185.0ms/batch - loss: 20.03186 - diff: 38.75mlTrain batch 5/42 - 183.5ms/batch - loss: 19.34555 - diff: 38.03mlTrain batch 6/42 - 183.4ms/batch - loss: 19.42644 - diff: 38.08mlTrain batch 7/42 - 183.5ms/batch - loss: 20.02252 - diff: 38.52mlTrain batch 8/42 - 182.9ms/batch - loss: 20.39588 - diff: 39.18mlTrain batch 9/42 - 188.6ms/batch - loss: 20.34904 - diff: 39.39mlTrain batch 10/42 - 185.6ms/batch - loss: 20.13021 - diff: 39.43mlTrain batch 11/42 - 183.9ms/batch - loss: 20.11787 - diff: 39.45mlTrain batch 12/42 - 182.6ms/batch - loss: 20.05269 - diff: 39.32mlTrain batch 13/42 - 183.4ms/batch - loss: 19.85380 - diff: 39.12mlTrain batch 14/42 - 182.3ms/batch - loss: 20.58469 - diff: 39.12mlTrain batch 15/42 - 200.6ms/batch - loss: 21.16258 - diff: 39.49mlTrain batch 16/42 - 183.7ms/batch - loss: 21.43226 - diff: 39.70mlTrain batch 17/42 - 192.2ms/batch - loss: 21.29243 - diff: 39.62mlTrain batch 18/42 - 182.2ms/batch - loss: 21.79515 - diff: 39.98mlTrain batch 19/42 - 215.9ms/batch - loss: 21.68398 - diff: 39.98mlTrain batch 20/42 - 183.8ms/batch - loss: 21.79550 - diff: 40.19mlTrain batch 21/42 - 187.3ms/batch - loss: 22.07845 - diff: 40.39mlTrain batch 22/42 - 182.8ms/batch - loss: 22.25663 - diff: 40.33mlTrain batch 23/42 - 210.1ms/batch - loss: 22.53476 - diff: 40.42mlTrain batch 24/42 - 184.7ms/batch - loss: 22.56898 - diff: 40.61mlTrain batch 25/42 - 188.9ms/batch - loss: 22.76177 - diff: 40.85mlTrain batch 26/42 - 183.0ms/batch - loss: 22.80880 - diff: 40.82mlTrain batch 27/42 - 188.3ms/batch - loss: 22.85311 - diff: 40.86mlTrain batch 28/42 - 183.0ms/batch - loss: 23.03729 - diff: 40.78mlTrain batch 29/42 - 187.7ms/batch - loss: 23.02099 - diff: 40.69mlTrain batch 30/42 - 183.9ms/batch - loss: 23.03048 - diff: 40.68mlTrain batch 31/42 - 183.7ms/batch - loss: 23.23474 - diff: 40.68mlTrain batch 32/42 - 184.8ms/batch - loss: 23.12582 - diff: 40.67mlTrain batch 33/42 - 198.1ms/batch - loss: 23.31950 - diff: 40.74mlTrain batch 34/42 - 183.5ms/batch - loss: 23.20401 - diff: 40.69mlTrain batch 35/42 - 204.2ms/batch - loss: 23.21661 - diff: 40.62mlTrain batch 36/42 - 185.9ms/batch - loss: 23.12283 - diff: 40.57mlTrain batch 37/42 - 199.7ms/batch - loss: 23.08611 - diff: 40.55mlTrain batch 38/42 - 185.4ms/batch - loss: 23.05675 - diff: 40.56mlTrain batch 39/42 - 199.1ms/batch - loss: 23.51414 - diff: 40.81mlTrain batch 40/42 - 184.2ms/batch - loss: 23.68550 - diff: 40.93mlTrain batch 41/42 - 189.6ms/batch - loss: 23.73116 - diff: 40.99mlTrain batch 42/42 - 129.5ms/batch - loss: 23.86145 - diff: 40.96mlTrain batch 42/42 - 370.5s 129.5ms/batch - loss: 23.86145 - diff: 40.96ml
Test 138.6s: val_loss: 23.51716 - diff: 40.65ml

Epoch 63: current best loss = 19.29743, at epoch 59
Train batch 1/42 - 190.0ms/batch - loss: 18.51644 - diff: 36.37mlTrain batch 2/42 - 185.8ms/batch - loss: 20.89649 - diff: 38.82mlTrain batch 3/42 - 183.4ms/batch - loss: 25.17543 - diff: 39.47mlTrain batch 4/42 - 183.7ms/batch - loss: 28.51977 - diff: 40.68mlTrain batch 5/42 - 183.6ms/batch - loss: 27.66262 - diff: 41.04mlTrain batch 6/42 - 182.9ms/batch - loss: 26.90927 - diff: 40.96mlTrain batch 7/42 - 188.2ms/batch - loss: 26.37610 - diff: 41.25mlTrain batch 8/42 - 185.8ms/batch - loss: 26.78206 - diff: 42.12mlTrain batch 9/42 - 184.7ms/batch - loss: 26.98840 - diff: 42.62mlTrain batch 10/42 - 183.6ms/batch - loss: 26.01534 - diff: 42.17mlTrain batch 11/42 - 183.2ms/batch - loss: 25.56863 - diff: 41.93mlTrain batch 12/42 - 183.0ms/batch - loss: 25.39808 - diff: 41.95mlTrain batch 13/42 - 188.2ms/batch - loss: 25.22420 - diff: 41.86mlTrain batch 14/42 - 184.1ms/batch - loss: 24.39497 - diff: 41.24mlTrain batch 15/42 - 187.5ms/batch - loss: 24.19037 - diff: 41.22mlTrain batch 16/42 - 182.3ms/batch - loss: 23.91554 - diff: 41.12mlTrain batch 17/42 - 205.3ms/batch - loss: 24.22637 - diff: 41.56mlTrain batch 18/42 - 184.4ms/batch - loss: 23.95893 - diff: 41.48mlTrain batch 19/42 - 187.3ms/batch - loss: 23.56197 - diff: 41.16mlTrain batch 20/42 - 183.6ms/batch - loss: 24.01774 - diff: 41.46mlTrain batch 21/42 - 200.6ms/batch - loss: 24.44630 - diff: 41.56mlTrain batch 22/42 - 183.7ms/batch - loss: 24.35012 - diff: 41.46mlTrain batch 23/42 - 185.7ms/batch - loss: 24.38851 - diff: 41.50mlTrain batch 24/42 - 182.8ms/batch - loss: 24.63991 - diff: 41.73mlTrain batch 25/42 - 191.1ms/batch - loss: 24.51044 - diff: 41.76mlTrain batch 26/42 - 184.5ms/batch - loss: 24.50539 - diff: 41.76mlTrain batch 27/42 - 184.7ms/batch - loss: 24.52688 - diff: 41.76mlTrain batch 28/42 - 183.2ms/batch - loss: 24.35596 - diff: 41.61mlTrain batch 29/42 - 183.8ms/batch - loss: 24.21990 - diff: 41.51mlTrain batch 30/42 - 183.9ms/batch - loss: 24.34293 - diff: 41.56mlTrain batch 31/42 - 189.0ms/batch - loss: 24.52994 - diff: 41.55mlTrain batch 32/42 - 185.3ms/batch - loss: 24.45746 - diff: 41.59mlTrain batch 33/42 - 183.5ms/batch - loss: 24.46928 - diff: 41.60mlTrain batch 34/42 - 183.0ms/batch - loss: 24.71977 - diff: 41.70mlTrain batch 35/42 - 183.9ms/batch - loss: 24.73423 - diff: 41.73mlTrain batch 36/42 - 183.3ms/batch - loss: 24.68610 - diff: 41.68mlTrain batch 37/42 - 188.6ms/batch - loss: 24.64914 - diff: 41.55mlTrain batch 38/42 - 185.8ms/batch - loss: 24.32594 - diff: 41.28mlTrain batch 39/42 - 183.5ms/batch - loss: 24.15888 - diff: 41.22mlTrain batch 40/42 - 184.2ms/batch - loss: 24.32860 - diff: 41.36mlTrain batch 41/42 - 183.0ms/batch - loss: 24.16224 - diff: 41.25mlTrain batch 42/42 - 128.3ms/batch - loss: 24.26477 - diff: 41.21mlTrain batch 42/42 - 367.7s 128.3ms/batch - loss: 24.26477 - diff: 41.21ml
Test 142.7s: val_loss: 25.19444 - diff: 42.82ml

Epoch 64: current best loss = 19.29743, at epoch 59
Train batch 1/42 - 188.5ms/batch - loss: 20.26091 - diff: 40.08mlTrain batch 2/42 - 185.1ms/batch - loss: 23.83474 - diff: 42.23mlTrain batch 3/42 - 183.3ms/batch - loss: 24.31012 - diff: 41.37mlTrain batch 4/42 - 184.6ms/batch - loss: 23.26407 - diff: 40.89mlTrain batch 5/42 - 182.8ms/batch - loss: 23.13532 - diff: 41.16mlTrain batch 6/42 - 185.3ms/batch - loss: 23.08054 - diff: 41.49mlTrain batch 7/42 - 189.1ms/batch - loss: 23.10396 - diff: 41.24mlTrain batch 8/42 - 186.9ms/batch - loss: 22.44982 - diff: 40.39mlTrain batch 9/42 - 182.8ms/batch - loss: 22.68909 - diff: 40.45mlTrain batch 10/42 - 183.8ms/batch - loss: 22.89508 - diff: 40.65mlTrain batch 11/42 - 184.0ms/batch - loss: 22.78687 - diff: 40.81mlTrain batch 12/42 - 183.0ms/batch - loss: 22.64605 - diff: 40.72mlTrain batch 13/42 - 188.3ms/batch - loss: 22.81930 - diff: 40.59mlTrain batch 14/42 - 183.9ms/batch - loss: 24.07574 - diff: 41.10mlTrain batch 15/42 - 188.4ms/batch - loss: 23.56845 - diff: 40.69mlTrain batch 16/42 - 182.4ms/batch - loss: 23.09617 - diff: 40.38mlTrain batch 17/42 - 199.0ms/batch - loss: 23.21651 - diff: 40.47mlTrain batch 18/42 - 184.1ms/batch - loss: 22.82162 - diff: 40.22mlTrain batch 19/42 - 186.3ms/batch - loss: 22.54375 - diff: 40.08mlTrain batch 20/42 - 183.0ms/batch - loss: 22.36981 - diff: 40.02mlTrain batch 21/42 - 205.7ms/batch - loss: 22.19432 - diff: 39.88mlTrain batch 22/42 - 184.0ms/batch - loss: 21.91977 - diff: 39.56mlTrain batch 23/42 - 185.6ms/batch - loss: 21.65382 - diff: 39.33mlTrain batch 24/42 - 183.3ms/batch - loss: 21.78242 - diff: 39.55mlTrain batch 25/42 - 190.2ms/batch - loss: 21.51027 - diff: 39.39mlTrain batch 26/42 - 183.7ms/batch - loss: 22.31241 - diff: 39.66mlTrain batch 27/42 - 185.5ms/batch - loss: 22.70404 - diff: 39.79mlTrain batch 28/42 - 183.5ms/batch - loss: 22.74596 - diff: 39.69mlTrain batch 29/42 - 187.0ms/batch - loss: 22.80537 - diff: 39.88mlTrain batch 30/42 - 184.3ms/batch - loss: 22.80995 - diff: 40.00mlTrain batch 31/42 - 188.6ms/batch - loss: 22.90176 - diff: 40.05mlTrain batch 32/42 - 184.9ms/batch - loss: 22.69199 - diff: 39.91mlTrain batch 33/42 - 184.3ms/batch - loss: 22.51341 - diff: 39.73mlTrain batch 34/42 - 184.2ms/batch - loss: 22.37765 - diff: 39.67mlTrain batch 35/42 - 186.1ms/batch - loss: 22.47201 - diff: 39.76mlTrain batch 36/42 - 194.9ms/batch - loss: 22.30142 - diff: 39.66mlTrain batch 37/42 - 191.0ms/batch - loss: 22.34640 - diff: 39.71mlTrain batch 38/42 - 186.7ms/batch - loss: 22.64080 - diff: 39.82mlTrain batch 39/42 - 185.8ms/batch - loss: 22.59444 - diff: 39.76mlTrain batch 40/42 - 185.0ms/batch - loss: 22.60965 - diff: 39.77mlTrain batch 41/42 - 186.2ms/batch - loss: 22.64530 - diff: 39.85mlTrain batch 42/42 - 142.7ms/batch - loss: 22.78435 - diff: 39.86mlTrain batch 42/42 - 370.7s 142.7ms/batch - loss: 22.78435 - diff: 39.86ml
Test 138.5s: val_loss: 23.05088 - diff: 40.00ml

Epoch 65: current best loss = 19.29743, at epoch 59
Train batch 1/42 - 183.6ms/batch - loss: 27.92734 - diff: 40.54mlTrain batch 2/42 - 183.7ms/batch - loss: 22.97232 - diff: 38.56mlTrain batch 3/42 - 201.6ms/batch - loss: 21.38750 - diff: 37.62mlTrain batch 4/42 - 183.3ms/batch - loss: 22.23634 - diff: 38.05mlTrain batch 5/42 - 183.3ms/batch - loss: 23.83151 - diff: 38.94mlTrain batch 6/42 - 184.1ms/batch - loss: 22.97370 - diff: 38.51mlTrain batch 7/42 - 182.7ms/batch - loss: 23.09424 - diff: 39.18mlTrain batch 8/42 - 183.3ms/batch - loss: 23.34376 - diff: 38.91mlTrain batch 9/42 - 189.6ms/batch - loss: 22.84264 - diff: 38.97mlTrain batch 10/42 - 183.8ms/batch - loss: 22.93214 - diff: 39.47mlTrain batch 11/42 - 183.3ms/batch - loss: 23.66165 - diff: 39.97mlTrain batch 12/42 - 183.0ms/batch - loss: 24.20713 - diff: 40.43mlTrain batch 13/42 - 182.4ms/batch - loss: 23.92716 - diff: 40.42mlTrain batch 14/42 - 183.1ms/batch - loss: 23.72722 - diff: 40.40mlTrain batch 15/42 - 188.7ms/batch - loss: 23.51948 - diff: 40.23mlTrain batch 16/42 - 184.0ms/batch - loss: 23.07181 - diff: 39.90mlTrain batch 17/42 - 183.3ms/batch - loss: 22.87541 - diff: 39.80mlTrain batch 18/42 - 184.4ms/batch - loss: 22.46410 - diff: 39.54mlTrain batch 19/42 - 191.9ms/batch - loss: 23.02665 - diff: 39.82mlTrain batch 20/42 - 185.1ms/batch - loss: 22.84733 - diff: 39.81mlTrain batch 21/42 - 185.7ms/batch - loss: 22.52380 - diff: 39.64mlTrain batch 22/42 - 182.3ms/batch - loss: 22.58506 - diff: 39.77mlTrain batch 23/42 - 207.0ms/batch - loss: 22.42454 - diff: 39.72mlTrain batch 24/42 - 183.5ms/batch - loss: 22.33040 - diff: 39.64mlTrain batch 25/42 - 184.7ms/batch - loss: 22.12755 - diff: 39.49mlTrain batch 26/42 - 182.9ms/batch - loss: 22.23446 - diff: 39.59mlTrain batch 27/42 - 183.2ms/batch - loss: 22.53014 - diff: 39.67mlTrain batch 28/42 - 182.8ms/batch - loss: 22.74835 - diff: 39.82mlTrain batch 29/42 - 188.1ms/batch - loss: 22.74747 - diff: 39.94mlTrain batch 30/42 - 183.8ms/batch - loss: 22.64773 - diff: 39.86mlTrain batch 31/42 - 183.8ms/batch - loss: 22.52887 - diff: 39.82mlTrain batch 32/42 - 184.0ms/batch - loss: 22.82845 - diff: 39.88mlTrain batch 33/42 - 183.5ms/batch - loss: 22.78737 - diff: 39.83mlTrain batch 34/42 - 182.7ms/batch - loss: 23.34002 - diff: 40.11mlTrain batch 35/42 - 186.2ms/batch - loss: 23.34526 - diff: 40.11mlTrain batch 36/42 - 184.9ms/batch - loss: 23.26663 - diff: 40.08mlTrain batch 37/42 - 183.9ms/batch - loss: 23.28809 - diff: 40.15mlTrain batch 38/42 - 183.0ms/batch - loss: 23.35443 - diff: 40.08mlTrain batch 39/42 - 184.6ms/batch - loss: 23.32588 - diff: 40.08mlTrain batch 40/42 - 183.2ms/batch - loss: 23.24050 - diff: 40.06mlTrain batch 41/42 - 188.8ms/batch - loss: 23.03194 - diff: 39.93mlTrain batch 42/42 - 129.4ms/batch - loss: 23.12499 - diff: 39.86mlTrain batch 42/42 - 366.4s 129.4ms/batch - loss: 23.12499 - diff: 39.86ml
Test 137.5s: val_loss: 24.14095 - diff: 43.87ml

Epoch 66: current best loss = 19.29743, at epoch 59
Train batch 1/42 - 188.0ms/batch - loss: 21.17605 - diff: 39.82mlTrain batch 2/42 - 183.5ms/batch - loss: 22.53027 - diff: 40.56mlTrain batch 3/42 - 185.3ms/batch - loss: 20.74837 - diff: 39.74mlTrain batch 4/42 - 183.1ms/batch - loss: 20.47120 - diff: 39.37mlTrain batch 5/42 - 187.1ms/batch - loss: 20.43995 - diff: 39.06mlTrain batch 6/42 - 192.1ms/batch - loss: 21.82718 - diff: 40.13mlTrain batch 7/42 - 182.2ms/batch - loss: 22.82698 - diff: 40.42mlTrain batch 8/42 - 182.8ms/batch - loss: 24.62535 - diff: 41.40mlTrain batch 9/42 - 184.6ms/batch - loss: 24.67609 - diff: 41.67mlTrain batch 10/42 - 183.4ms/batch - loss: 24.68100 - diff: 41.48mlTrain batch 11/42 - 193.6ms/batch - loss: 23.97553 - diff: 40.94mlTrain batch 12/42 - 184.4ms/batch - loss: 23.66451 - diff: 40.73mlTrain batch 13/42 - 183.2ms/batch - loss: 23.28435 - diff: 40.43mlTrain batch 14/42 - 183.0ms/batch - loss: 24.14339 - diff: 40.66mlTrain batch 15/42 - 185.8ms/batch - loss: 24.58243 - diff: 40.89mlTrain batch 16/42 - 182.8ms/batch - loss: 24.13424 - diff: 40.76mlTrain batch 17/42 - 201.0ms/batch - loss: 24.10656 - diff: 40.77mlTrain batch 18/42 - 184.1ms/batch - loss: 24.35827 - diff: 40.99mlTrain batch 19/42 - 187.7ms/batch - loss: 24.60910 - diff: 41.12mlTrain batch 20/42 - 182.4ms/batch - loss: 24.33881 - diff: 40.92mlTrain batch 21/42 - 204.7ms/batch - loss: 23.98219 - diff: 40.78mlTrain batch 22/42 - 183.5ms/batch - loss: 23.65463 - diff: 40.49mlTrain batch 23/42 - 185.6ms/batch - loss: 23.46479 - diff: 40.31mlTrain batch 24/42 - 182.8ms/batch - loss: 23.60465 - diff: 40.19mlTrain batch 25/42 - 192.6ms/batch - loss: 23.28125 - diff: 40.00mlTrain batch 26/42 - 185.9ms/batch - loss: 23.17316 - diff: 39.98mlTrain batch 27/42 - 184.1ms/batch - loss: 22.88413 - diff: 39.80mlTrain batch 28/42 - 183.2ms/batch - loss: 22.90432 - diff: 39.90mlTrain batch 29/42 - 188.2ms/batch - loss: 22.84029 - diff: 39.98mlTrain batch 30/42 - 183.3ms/batch - loss: 22.73274 - diff: 39.95mlTrain batch 31/42 - 187.3ms/batch - loss: 22.48029 - diff: 39.75mlTrain batch 32/42 - 184.6ms/batch - loss: 22.43447 - diff: 39.75mlTrain batch 33/42 - 184.0ms/batch - loss: 22.53987 - diff: 39.81mlTrain batch 34/42 - 183.5ms/batch - loss: 22.47332 - diff: 39.84mlTrain batch 35/42 - 182.8ms/batch - loss: 22.34372 - diff: 39.76mlTrain batch 36/42 - 182.9ms/batch - loss: 22.47933 - diff: 39.79mlTrain batch 37/42 - 188.2ms/batch - loss: 22.54420 - diff: 39.88mlTrain batch 38/42 - 185.1ms/batch - loss: 22.67441 - diff: 39.96mlTrain batch 39/42 - 184.7ms/batch - loss: 22.59645 - diff: 39.97mlTrain batch 40/42 - 183.1ms/batch - loss: 22.60148 - diff: 39.95mlTrain batch 41/42 - 182.9ms/batch - loss: 22.65050 - diff: 40.05mlTrain batch 42/42 - 129.5ms/batch - loss: 22.65786 - diff: 39.96mlTrain batch 42/42 - 371.4s 129.5ms/batch - loss: 22.65786 - diff: 39.96ml
Test 139.7s: val_loss: 19.16516 - diff: 36.66ml
Saving new best model in models/checkpoints/preproc1_150x150_bySlices_dataset_full_Diastole_TimeAsDepth_1_SGD-0.001_DA2_best

Epoch 67: current best loss = 19.16516, at epoch 66
Train batch 1/42 - 189.6ms/batch - loss: 23.89679 - diff: 44.57mlTrain batch 2/42 - 184.5ms/batch - loss: 23.59212 - diff: 43.15mlTrain batch 3/42 - 183.5ms/batch - loss: 25.07832 - diff: 42.33mlTrain batch 4/42 - 184.6ms/batch - loss: 23.97233 - diff: 41.75mlTrain batch 5/42 - 183.7ms/batch - loss: 24.23055 - diff: 42.44mlTrain batch 6/42 - 183.0ms/batch - loss: 23.26810 - diff: 41.62mlTrain batch 7/42 - 188.6ms/batch - loss: 26.04760 - diff: 42.46mlTrain batch 8/42 - 184.9ms/batch - loss: 24.51261 - diff: 41.30mlTrain batch 9/42 - 183.8ms/batch - loss: 23.70106 - diff: 40.70mlTrain batch 10/42 - 182.8ms/batch - loss: 23.61177 - diff: 40.30mlTrain batch 11/42 - 183.2ms/batch - loss: 23.09831 - diff: 40.13mlTrain batch 12/42 - 182.7ms/batch - loss: 22.96706 - diff: 40.00mlTrain batch 13/42 - 183.1ms/batch - loss: 22.69665 - diff: 40.03mlTrain batch 14/42 - 182.6ms/batch - loss: 23.19818 - diff: 40.28mlTrain batch 15/42 - 199.5ms/batch - loss: 22.93382 - diff: 40.23mlTrain batch 16/42 - 183.9ms/batch - loss: 22.84365 - diff: 40.34mlTrain batch 17/42 - 185.7ms/batch - loss: 23.19045 - diff: 40.56mlTrain batch 18/42 - 182.6ms/batch - loss: 23.30488 - diff: 40.82mlTrain batch 19/42 - 197.4ms/batch - loss: 23.25148 - diff: 40.81mlTrain batch 20/42 - 182.7ms/batch - loss: 23.35781 - diff: 40.52mlTrain batch 21/42 - 185.4ms/batch - loss: 23.24180 - diff: 40.38mlTrain batch 22/42 - 182.8ms/batch - loss: 22.87427 - diff: 40.10mlTrain batch 23/42 - 205.6ms/batch - loss: 22.80185 - diff: 40.02mlTrain batch 24/42 - 184.5ms/batch - loss: 22.69638 - diff: 40.00mlTrain batch 25/42 - 189.0ms/batch - loss: 22.86811 - diff: 40.29mlTrain batch 26/42 - 183.3ms/batch - loss: 22.71729 - diff: 40.18mlTrain batch 27/42 - 185.7ms/batch - loss: 22.83130 - diff: 40.33mlTrain batch 28/42 - 183.7ms/batch - loss: 22.64182 - diff: 40.25mlTrain batch 29/42 - 189.1ms/batch - loss: 22.49176 - diff: 40.12mlTrain batch 30/42 - 184.6ms/batch - loss: 22.43049 - diff: 40.12mlTrain batch 31/42 - 182.8ms/batch - loss: 22.16617 - diff: 39.91mlTrain batch 32/42 - 182.9ms/batch - loss: 21.92691 - diff: 39.72mlTrain batch 33/42 - 182.5ms/batch - loss: 22.97523 - diff: 40.08mlTrain batch 34/42 - 183.1ms/batch - loss: 23.03512 - diff: 40.14mlTrain batch 35/42 - 187.4ms/batch - loss: 22.99733 - diff: 40.12mlTrain batch 36/42 - 184.6ms/batch - loss: 22.96156 - diff: 40.18mlTrain batch 37/42 - 183.5ms/batch - loss: 22.97008 - diff: 40.24mlTrain batch 38/42 - 184.6ms/batch - loss: 22.79241 - diff: 40.08mlTrain batch 39/42 - 183.7ms/batch - loss: 22.68544 - diff: 40.02mlTrain batch 40/42 - 182.8ms/batch - loss: 22.45544 - diff: 39.84mlTrain batch 41/42 - 189.4ms/batch - loss: 22.39908 - diff: 39.80mlTrain batch 42/42 - 130.1ms/batch - loss: 22.55788 - diff: 39.82mlTrain batch 42/42 - 365.2s 130.1ms/batch - loss: 22.55788 - diff: 39.82ml
Test 139.7s: val_loss: 22.07595 - diff: 40.86ml

Epoch 68: current best loss = 19.16516, at epoch 66
Train batch 1/42 - 189.6ms/batch - loss: 25.42497 - diff: 42.37mlTrain batch 2/42 - 184.6ms/batch - loss: 22.70440 - diff: 41.24mlTrain batch 3/42 - 183.8ms/batch - loss: 22.34117 - diff: 41.22mlTrain batch 4/42 - 183.6ms/batch - loss: 25.87012 - diff: 41.52mlTrain batch 5/42 - 188.2ms/batch - loss: 24.31625 - diff: 40.72mlTrain batch 6/42 - 182.8ms/batch - loss: 24.36557 - diff: 40.82mlTrain batch 7/42 - 182.9ms/batch - loss: 23.83219 - diff: 40.77mlTrain batch 8/42 - 184.1ms/batch - loss: 23.75655 - diff: 40.86mlTrain batch 9/42 - 184.1ms/batch - loss: 23.06403 - diff: 40.39mlTrain batch 10/42 - 183.8ms/batch - loss: 23.46178 - diff: 41.05mlTrain batch 11/42 - 190.4ms/batch - loss: 23.03065 - diff: 40.88mlTrain batch 12/42 - 186.0ms/batch - loss: 23.30365 - diff: 40.58mlTrain batch 13/42 - 182.8ms/batch - loss: 23.24446 - diff: 40.62mlTrain batch 14/42 - 182.5ms/batch - loss: 23.03159 - diff: 40.49mlTrain batch 15/42 - 187.4ms/batch - loss: 23.70918 - diff: 40.86mlTrain batch 16/42 - 183.2ms/batch - loss: 23.99587 - diff: 40.99mlTrain batch 17/42 - 199.7ms/batch - loss: 23.82435 - diff: 40.94mlTrain batch 18/42 - 184.3ms/batch - loss: 23.86330 - diff: 41.16mlTrain batch 19/42 - 185.6ms/batch - loss: 23.63587 - diff: 41.08mlTrain batch 20/42 - 182.9ms/batch - loss: 23.56042 - diff: 40.91mlTrain batch 21/42 - 203.8ms/batch - loss: 23.53851 - diff: 40.88mlTrain batch 22/42 - 184.0ms/batch - loss: 23.44224 - diff: 40.82mlTrain batch 23/42 - 185.5ms/batch - loss: 23.90342 - diff: 40.95mlTrain batch 24/42 - 182.9ms/batch - loss: 23.90605 - diff: 40.88mlTrain batch 25/42 - 191.8ms/batch - loss: 23.91046 - diff: 40.99mlTrain batch 26/42 - 184.6ms/batch - loss: 24.32878 - diff: 41.30mlTrain batch 27/42 - 184.2ms/batch - loss: 24.51977 - diff: 41.38mlTrain batch 28/42 - 182.8ms/batch - loss: 24.36984 - diff: 41.28mlTrain batch 29/42 - 183.6ms/batch - loss: 24.20621 - diff: 41.12mlTrain batch 30/42 - 182.4ms/batch - loss: 24.23441 - diff: 41.14mlTrain batch 31/42 - 190.3ms/batch - loss: 23.94473 - diff: 40.93mlTrain batch 32/42 - 184.7ms/batch - loss: 23.61297 - diff: 40.69mlTrain batch 33/42 - 199.5ms/batch - loss: 23.53981 - diff: 40.56mlTrain batch 34/42 - 183.9ms/batch - loss: 23.52016 - diff: 40.61mlTrain batch 35/42 - 188.3ms/batch - loss: 23.48330 - diff: 40.59mlTrain batch 36/42 - 185.7ms/batch - loss: 23.46671 - diff: 40.56mlTrain batch 37/42 - 187.7ms/batch - loss: 23.56255 - diff: 40.69mlTrain batch 38/42 - 185.9ms/batch - loss: 23.44976 - diff: 40.67mlTrain batch 39/42 - 185.4ms/batch - loss: 23.46167 - diff: 40.72mlTrain batch 40/42 - 183.8ms/batch - loss: 23.62373 - diff: 40.82mlTrain batch 41/42 - 183.8ms/batch - loss: 23.58885 - diff: 40.78mlTrain batch 42/42 - 129.4ms/batch - loss: 23.55615 - diff: 40.67mlTrain batch 42/42 - 369.9s 129.4ms/batch - loss: 23.55615 - diff: 40.67ml
Test 140.0s: val_loss: 50.28404 - diff: 67.53ml

Epoch 69: current best loss = 19.16516, at epoch 66
Train batch 1/42 - 189.9ms/batch - loss: 24.48731 - diff: 43.08mlTrain batch 2/42 - 184.4ms/batch - loss: 22.81829 - diff: 42.24mlTrain batch 3/42 - 183.6ms/batch - loss: 24.34041 - diff: 42.59mlTrain batch 4/42 - 184.9ms/batch - loss: 23.53511 - diff: 41.43mlTrain batch 5/42 - 183.6ms/batch - loss: 25.59226 - diff: 42.26mlTrain batch 6/42 - 184.7ms/batch - loss: 23.99185 - diff: 41.40mlTrain batch 7/42 - 189.1ms/batch - loss: 24.69833 - diff: 41.60mlTrain batch 8/42 - 185.2ms/batch - loss: 24.66315 - diff: 41.61mlTrain batch 9/42 - 184.0ms/batch - loss: 25.07406 - diff: 41.94mlTrain batch 10/42 - 182.3ms/batch - loss: 25.87828 - diff: 42.97mlTrain batch 11/42 - 183.6ms/batch - loss: 25.95919 - diff: 42.83mlTrain batch 12/42 - 182.9ms/batch - loss: 25.40976 - diff: 42.39mlTrain batch 13/42 - 187.5ms/batch - loss: 25.26406 - diff: 42.39mlTrain batch 14/42 - 183.8ms/batch - loss: 25.14993 - diff: 42.39mlTrain batch 15/42 - 184.9ms/batch - loss: 25.71152 - diff: 42.67mlTrain batch 16/42 - 184.3ms/batch - loss: 25.71744 - diff: 42.37mlTrain batch 17/42 - 185.3ms/batch - loss: 25.59631 - diff: 42.13mlTrain batch 18/42 - 182.4ms/batch - loss: 25.28248 - diff: 41.97mlTrain batch 19/42 - 201.0ms/batch - loss: 24.80766 - diff: 41.59mlTrain batch 20/42 - 184.0ms/batch - loss: 24.85370 - diff: 41.69mlTrain batch 21/42 - 187.4ms/batch - loss: 24.85087 - diff: 41.72mlTrain batch 22/42 - 182.9ms/batch - loss: 24.77591 - diff: 41.62mlTrain batch 23/42 - 215.2ms/batch - loss: 25.41750 - diff: 41.98mlTrain batch 24/42 - 184.0ms/batch - loss: 25.39931 - diff: 42.01mlTrain batch 25/42 - 188.7ms/batch - loss: 25.36917 - diff: 41.95mlTrain batch 26/42 - 182.5ms/batch - loss: 25.24664 - diff: 41.85mlTrain batch 27/42 - 186.4ms/batch - loss: 25.04961 - diff: 41.75mlTrain batch 28/42 - 182.9ms/batch - loss: 25.10993 - diff: 41.93mlTrain batch 29/42 - 189.5ms/batch - loss: 25.26927 - diff: 41.96mlTrain batch 30/42 - 184.8ms/batch - loss: 25.17463 - diff: 41.89mlTrain batch 31/42 - 183.9ms/batch - loss: 25.22813 - diff: 41.83mlTrain batch 32/42 - 183.7ms/batch - loss: 25.06642 - diff: 41.73mlTrain batch 33/42 - 183.8ms/batch - loss: 25.23171 - diff: 41.77mlTrain batch 34/42 - 184.2ms/batch - loss: 25.01236 - diff: 41.61mlTrain batch 35/42 - 189.0ms/batch - loss: 24.80968 - diff: 41.49mlTrain batch 36/42 - 184.0ms/batch - loss: 24.83570 - diff: 41.51mlTrain batch 37/42 - 182.7ms/batch - loss: 24.68442 - diff: 41.42mlTrain batch 38/42 - 183.7ms/batch - loss: 24.82162 - diff: 41.43mlTrain batch 39/42 - 185.1ms/batch - loss: 24.81631 - diff: 41.41mlTrain batch 40/42 - 182.7ms/batch - loss: 24.61035 - diff: 41.29mlTrain batch 41/42 - 189.7ms/batch - loss: 24.47757 - diff: 41.23mlTrain batch 42/42 - 129.9ms/batch - loss: 24.74347 - diff: 41.26mlTrain batch 42/42 - 370.4s 129.9ms/batch - loss: 24.74347 - diff: 41.26ml
Test 141.4s: val_loss: 18.65666 - diff: 37.60ml
Saving new best model in models/checkpoints/preproc1_150x150_bySlices_dataset_full_Diastole_TimeAsDepth_1_SGD-0.001_DA2_best

Epoch 70: current best loss = 18.65666, at epoch 69
Train batch 1/42 - 205.6ms/batch - loss: 21.46323 - diff: 41.06mlTrain batch 2/42 - 184.9ms/batch - loss: 21.16650 - diff: 39.64mlTrain batch 3/42 - 182.9ms/batch - loss: 20.24506 - diff: 38.28mlTrain batch 4/42 - 183.3ms/batch - loss: 21.15683 - diff: 38.97mlTrain batch 5/42 - 183.5ms/batch - loss: 20.07659 - diff: 38.35mlTrain batch 6/42 - 182.4ms/batch - loss: 19.71009 - diff: 38.08mlTrain batch 7/42 - 189.1ms/batch - loss: 20.02344 - diff: 38.46mlTrain batch 8/42 - 184.1ms/batch - loss: 19.94869 - diff: 38.51mlTrain batch 9/42 - 184.0ms/batch - loss: 20.04871 - diff: 38.61mlTrain batch 10/42 - 183.3ms/batch - loss: 20.16078 - diff: 38.59mlTrain batch 11/42 - 183.7ms/batch - loss: 20.39127 - diff: 38.74mlTrain batch 12/42 - 182.8ms/batch - loss: 20.13740 - diff: 38.55mlTrain batch 13/42 - 188.7ms/batch - loss: 20.12210 - diff: 38.68mlTrain batch 14/42 - 183.7ms/batch - loss: 20.47637 - diff: 38.80mlTrain batch 15/42 - 185.9ms/batch - loss: 20.06392 - diff: 38.42mlTrain batch 16/42 - 182.1ms/batch - loss: 19.80114 - diff: 38.12mlTrain batch 17/42 - 191.6ms/batch - loss: 20.51300 - diff: 38.49mlTrain batch 18/42 - 184.6ms/batch - loss: 20.25590 - diff: 38.31mlTrain batch 19/42 - 185.6ms/batch - loss: 20.54140 - diff: 38.47mlTrain batch 20/42 - 182.5ms/batch - loss: 20.84501 - diff: 38.72mlTrain batch 21/42 - 193.7ms/batch - loss: 21.30940 - diff: 39.03mlTrain batch 22/42 - 184.3ms/batch - loss: 21.88862 - diff: 39.43mlTrain batch 23/42 - 187.0ms/batch - loss: 21.89731 - diff: 39.57mlTrain batch 24/42 - 182.6ms/batch - loss: 21.75284 - diff: 39.43mlTrain batch 25/42 - 189.5ms/batch - loss: 21.66953 - diff: 39.41mlTrain batch 26/42 - 183.1ms/batch - loss: 21.50690 - diff: 39.36mlTrain batch 27/42 - 182.5ms/batch - loss: 21.46421 - diff: 39.33mlTrain batch 28/42 - 183.0ms/batch - loss: 21.34660 - diff: 39.26mlTrain batch 29/42 - 186.0ms/batch - loss: 21.62633 - diff: 39.35mlTrain batch 30/42 - 182.6ms/batch - loss: 21.74781 - diff: 39.35mlTrain batch 31/42 - 189.7ms/batch - loss: 21.56951 - diff: 39.24mlTrain batch 32/42 - 185.0ms/batch - loss: 21.50725 - diff: 39.23mlTrain batch 33/42 - 187.1ms/batch - loss: 21.59146 - diff: 39.21mlTrain batch 34/42 - 183.3ms/batch - loss: 21.74233 - diff: 39.36mlTrain batch 35/42 - 183.5ms/batch - loss: 21.72211 - diff: 39.39mlTrain batch 36/42 - 183.9ms/batch - loss: 21.60605 - diff: 39.35mlTrain batch 37/42 - 184.8ms/batch - loss: 21.76624 - diff: 39.47mlTrain batch 38/42 - 187.8ms/batch - loss: 21.61220 - diff: 39.35mlTrain batch 39/42 - 184.6ms/batch - loss: 21.55140 - diff: 39.41mlTrain batch 40/42 - 184.1ms/batch - loss: 21.51274 - diff: 39.39mlTrain batch 41/42 - 184.6ms/batch - loss: 21.67655 - diff: 39.46mlTrain batch 42/42 - 128.9ms/batch - loss: 22.02588 - diff: 39.52mlTrain batch 42/42 - 368.5s 128.9ms/batch - loss: 22.02588 - diff: 39.52ml
Test 139.8s: val_loss: 20.24615 - diff: 39.88ml

Epoch 71: current best loss = 18.65666, at epoch 69
Train batch 1/42 - 187.1ms/batch - loss: 31.53403 - diff: 45.71mlTrain batch 2/42 - 184.3ms/batch - loss: 26.14870 - diff: 42.93mlTrain batch 3/42 - 183.5ms/batch - loss: 23.20708 - diff: 40.59mlTrain batch 4/42 - 183.0ms/batch - loss: 22.24148 - diff: 40.17mlTrain batch 5/42 - 184.2ms/batch - loss: 23.03470 - diff: 40.20mlTrain batch 6/42 - 183.3ms/batch - loss: 23.15860 - diff: 39.87mlTrain batch 7/42 - 189.8ms/batch - loss: 24.46894 - diff: 40.01mlTrain batch 8/42 - 184.8ms/batch - loss: 24.11716 - diff: 39.90mlTrain batch 9/42 - 183.3ms/batch - loss: 23.06596 - diff: 39.20mlTrain batch 10/42 - 183.6ms/batch - loss: 22.72289 - diff: 39.30mlTrain batch 11/42 - 182.9ms/batch - loss: 22.74024 - diff: 39.47mlTrain batch 12/42 - 183.8ms/batch - loss: 22.43094 - diff: 39.45mlTrain batch 13/42 - 187.7ms/batch - loss: 22.82334 - diff: 39.47mlTrain batch 14/42 - 183.4ms/batch - loss: 22.99091 - diff: 39.48mlTrain batch 15/42 - 182.6ms/batch - loss: 22.46796 - diff: 39.23mlTrain batch 16/42 - 182.9ms/batch - loss: 23.25375 - diff: 39.55mlTrain batch 17/42 - 188.1ms/batch - loss: 23.24089 - diff: 39.42mlTrain batch 18/42 - 183.9ms/batch - loss: 23.08053 - diff: 39.41mlTrain batch 19/42 - 183.3ms/batch - loss: 23.07991 - diff: 39.61mlTrain batch 20/42 - 182.9ms/batch - loss: 22.91863 - diff: 39.53mlTrain batch 21/42 - 188.0ms/batch - loss: 22.92281 - diff: 39.66mlTrain batch 22/42 - 185.1ms/batch - loss: 22.76682 - diff: 39.52mlTrain batch 23/42 - 182.5ms/batch - loss: 22.74265 - diff: 39.58mlTrain batch 24/42 - 189.3ms/batch - loss: 22.71400 - diff: 39.64mlTrain batch 25/42 - 184.1ms/batch - loss: 23.18664 - diff: 39.79mlTrain batch 26/42 - 184.3ms/batch - loss: 23.12315 - diff: 39.71mlTrain batch 27/42 - 183.2ms/batch - loss: 23.00408 - diff: 39.68mlTrain batch 28/42 - 184.7ms/batch - loss: 23.00542 - diff: 39.80mlTrain batch 29/42 - 183.0ms/batch - loss: 22.95992 - diff: 39.76mlTrain batch 30/42 - 188.2ms/batch - loss: 22.86805 - diff: 39.75mlTrain batch 31/42 - 190.5ms/batch - loss: 22.69868 - diff: 39.64mlTrain batch 32/42 - 184.2ms/batch - loss: 22.96296 - diff: 39.68mlTrain batch 33/42 - 184.4ms/batch - loss: 22.76387 - diff: 39.60mlTrain batch 34/42 - 183.3ms/batch - loss: 22.60122 - diff: 39.49mlTrain batch 35/42 - 201.9ms/batch - loss: 22.69352 - diff: 39.59mlTrain batch 36/42 - 188.0ms/batch - loss: 22.82149 - diff: 39.70mlTrain batch 37/42 - 188.8ms/batch - loss: 22.77997 - diff: 39.80mlTrain batch 38/42 - 183.1ms/batch - loss: 22.51397 - diff: 39.58mlTrain batch 39/42 - 186.0ms/batch - loss: 22.65375 - diff: 39.68mlTrain batch 40/42 - 184.3ms/batch - loss: 22.56234 - diff: 39.67mlTrain batch 41/42 - 183.2ms/batch - loss: 22.40845 - diff: 39.56mlTrain batch 42/42 - 138.1ms/batch - loss: 22.46110 - diff: 39.52mlTrain batch 42/42 - 367.7s 138.1ms/batch - loss: 22.46110 - diff: 39.52ml
Test 140.5s: val_loss: 19.00862 - diff: 38.25ml

Epoch 72: current best loss = 18.65666, at epoch 69
Train batch 1/42 - 184.9ms/batch - loss: 18.57505 - diff: 38.45mlTrain batch 2/42 - 183.9ms/batch - loss: 18.20772 - diff: 38.14mlTrain batch 3/42 - 187.8ms/batch - loss: 17.72508 - diff: 37.68mlTrain batch 4/42 - 184.8ms/batch - loss: 17.89884 - diff: 37.55mlTrain batch 5/42 - 184.2ms/batch - loss: 17.64497 - diff: 37.41mlTrain batch 6/42 - 184.3ms/batch - loss: 18.06610 - diff: 37.61mlTrain batch 7/42 - 189.3ms/batch - loss: 18.69558 - diff: 38.11mlTrain batch 8/42 - 184.2ms/batch - loss: 18.75389 - diff: 38.24mlTrain batch 9/42 - 206.2ms/batch - loss: 18.62557 - diff: 38.23mlTrain batch 10/42 - 184.2ms/batch - loss: 18.81691 - diff: 37.63mlTrain batch 11/42 - 182.5ms/batch - loss: 19.31225 - diff: 38.02mlTrain batch 12/42 - 182.7ms/batch - loss: 20.30361 - diff: 38.44mlTrain batch 13/42 - 182.4ms/batch - loss: 20.02628 - diff: 38.31mlTrain batch 14/42 - 182.5ms/batch - loss: 19.99886 - diff: 38.11mlTrain batch 15/42 - 204.1ms/batch - loss: 21.08293 - diff: 38.69mlTrain batch 16/42 - 183.4ms/batch - loss: 20.78153 - diff: 38.54mlTrain batch 17/42 - 185.4ms/batch - loss: 20.83983 - diff: 38.60mlTrain batch 18/42 - 182.9ms/batch - loss: 21.29374 - diff: 38.67mlTrain batch 19/42 - 204.7ms/batch - loss: 21.01291 - diff: 38.47mlTrain batch 20/42 - 184.8ms/batch - loss: 21.14210 - diff: 38.61mlTrain batch 21/42 - 192.2ms/batch - loss: 21.21600 - diff: 38.79mlTrain batch 22/42 - 182.3ms/batch - loss: 21.07648 - diff: 38.77mlTrain batch 23/42 - 205.6ms/batch - loss: 20.89273 - diff: 38.62mlTrain batch 24/42 - 198.5ms/batch - loss: 20.73037 - diff: 38.51mlTrain batch 25/42 - 185.6ms/batch - loss: 20.95196 - diff: 38.62mlTrain batch 26/42 - 183.2ms/batch - loss: 20.79123 - diff: 38.44mlTrain batch 27/42 - 183.8ms/batch - loss: 20.62202 - diff: 38.35mlTrain batch 28/42 - 182.8ms/batch - loss: 20.48841 - diff: 38.24mlTrain batch 29/42 - 207.8ms/batch - loss: 20.38346 - diff: 38.18mlTrain batch 30/42 - 184.1ms/batch - loss: 20.38106 - diff: 38.18mlTrain batch 31/42 - 185.2ms/batch - loss: 20.36111 - diff: 38.17mlTrain batch 32/42 - 182.8ms/batch - loss: 20.59598 - diff: 38.23mlTrain batch 33/42 - 201.5ms/batch - loss: 20.67915 - diff: 38.39mlTrain batch 34/42 - 187.2ms/batch - loss: 20.62366 - diff: 38.38mlTrain batch 35/42 - 193.2ms/batch - loss: 20.73836 - diff: 38.42mlTrain batch 36/42 - 184.4ms/batch - loss: 20.80304 - diff: 38.48mlTrain batch 37/42 - 183.1ms/batch - loss: 20.91252 - diff: 38.47mlTrain batch 38/42 - 198.2ms/batch - loss: 20.91396 - diff: 38.49mlTrain batch 39/42 - 183.3ms/batch - loss: 20.89194 - diff: 38.50mlTrain batch 40/42 - 184.8ms/batch - loss: 20.89203 - diff: 38.57mlTrain batch 41/42 - 183.6ms/batch - loss: 21.21987 - diff: 38.71mlTrain batch 42/42 - 128.5ms/batch - loss: 21.21377 - diff: 38.60mlTrain batch 42/42 - 367.8s 128.5ms/batch - loss: 21.21377 - diff: 38.60ml
Test 138.0s: val_loss: 39.74291 - diff: 58.53ml

Epoch 73: current best loss = 18.65666, at epoch 69
Train batch 1/42 - 190.3ms/batch - loss: 20.07398 - diff: 39.85mlTrain batch 2/42 - 185.0ms/batch - loss: 21.78724 - diff: 40.95mlTrain batch 3/42 - 183.4ms/batch - loss: 23.77278 - diff: 41.04mlTrain batch 4/42 - 183.1ms/batch - loss: 23.44445 - diff: 40.96mlTrain batch 5/42 - 183.3ms/batch - loss: 23.55723 - diff: 40.99mlTrain batch 6/42 - 183.0ms/batch - loss: 22.49246 - diff: 40.21mlTrain batch 7/42 - 188.6ms/batch - loss: 22.03975 - diff: 39.90mlTrain batch 8/42 - 186.9ms/batch - loss: 21.89246 - diff: 39.96mlTrain batch 9/42 - 182.9ms/batch - loss: 22.85620 - diff: 39.98mlTrain batch 10/42 - 183.6ms/batch - loss: 22.48675 - diff: 39.86mlTrain batch 11/42 - 182.6ms/batch - loss: 22.28043 - diff: 39.63mlTrain batch 12/42 - 183.7ms/batch - loss: 23.04983 - diff: 40.24mlTrain batch 13/42 - 187.9ms/batch - loss: 22.50034 - diff: 39.90mlTrain batch 14/42 - 184.4ms/batch - loss: 22.33451 - diff: 39.74mlTrain batch 15/42 - 185.2ms/batch - loss: 22.12608 - diff: 39.70mlTrain batch 16/42 - 187.2ms/batch - loss: 21.85688 - diff: 39.47mlTrain batch 17/42 - 199.1ms/batch - loss: 21.73943 - diff: 39.49mlTrain batch 18/42 - 184.5ms/batch - loss: 21.66353 - diff: 39.43mlTrain batch 19/42 - 185.6ms/batch - loss: 21.65298 - diff: 39.45mlTrain batch 20/42 - 182.9ms/batch - loss: 22.08532 - diff: 39.56mlTrain batch 21/42 - 203.8ms/batch - loss: 21.85954 - diff: 39.41mlTrain batch 22/42 - 184.4ms/batch - loss: 22.32213 - diff: 39.70mlTrain batch 23/42 - 185.3ms/batch - loss: 22.65169 - diff: 39.72mlTrain batch 24/42 - 182.3ms/batch - loss: 22.54245 - diff: 39.75mlTrain batch 25/42 - 184.9ms/batch - loss: 22.29063 - diff: 39.57mlTrain batch 26/42 - 183.2ms/batch - loss: 22.34135 - diff: 39.65mlTrain batch 27/42 - 189.2ms/batch - loss: 22.17697 - diff: 39.58mlTrain batch 28/42 - 183.9ms/batch - loss: 22.21155 - diff: 39.60mlTrain batch 29/42 - 184.4ms/batch - loss: 22.00502 - diff: 39.51mlTrain batch 30/42 - 182.3ms/batch - loss: 22.04535 - diff: 39.60mlTrain batch 31/42 - 183.3ms/batch - loss: 22.02050 - diff: 39.57mlTrain batch 32/42 - 183.2ms/batch - loss: 21.96027 - diff: 39.57mlTrain batch 33/42 - 190.3ms/batch - loss: 21.83658 - diff: 39.42mlTrain batch 34/42 - 185.8ms/batch - loss: 21.63017 - diff: 39.29mlTrain batch 35/42 - 184.0ms/batch - loss: 21.97288 - diff: 39.42mlTrain batch 36/42 - 183.1ms/batch - loss: 21.87718 - diff: 39.39mlTrain batch 37/42 - 182.5ms/batch - loss: 22.02596 - diff: 39.43mlTrain batch 38/42 - 185.3ms/batch - loss: 21.83367 - diff: 39.23mlTrain batch 39/42 - 186.3ms/batch - loss: 21.79954 - diff: 39.27mlTrain batch 40/42 - 182.9ms/batch - loss: 21.74715 - diff: 39.26mlTrain batch 41/42 - 183.8ms/batch - loss: 21.71886 - diff: 39.27mlTrain batch 42/42 - 128.8ms/batch - loss: 21.82939 - diff: 39.26mlTrain batch 42/42 - 364.8s 128.8ms/batch - loss: 21.82939 - diff: 39.26ml
Test 139.3s: val_loss: 18.72727 - diff: 36.91ml

Epoch 74: current best loss = 18.65666, at epoch 69
Train batch 1/42 - 185.6ms/batch - loss: 19.91657 - diff: 37.55mlTrain batch 2/42 - 184.0ms/batch - loss: 20.94728 - diff: 38.60mlTrain batch 3/42 - 184.6ms/batch - loss: 21.13316 - diff: 38.98mlTrain batch 4/42 - 183.5ms/batch - loss: 21.22959 - diff: 39.26mlTrain batch 5/42 - 192.0ms/batch - loss: 21.60710 - diff: 39.75mlTrain batch 6/42 - 184.8ms/batch - loss: 20.92070 - diff: 38.62mlTrain batch 7/42 - 183.3ms/batch - loss: 20.89349 - diff: 38.85mlTrain batch 8/42 - 182.8ms/batch - loss: 21.71803 - diff: 39.32mlTrain batch 9/42 - 183.0ms/batch - loss: 21.79011 - diff: 39.03mlTrain batch 10/42 - 182.9ms/batch - loss: 21.48300 - diff: 38.85mlTrain batch 11/42 - 187.9ms/batch - loss: 21.53334 - diff: 39.11mlTrain batch 12/42 - 184.5ms/batch - loss: 22.46478 - diff: 39.60mlTrain batch 13/42 - 182.9ms/batch - loss: 23.25698 - diff: 39.86mlTrain batch 14/42 - 182.3ms/batch - loss: 23.20611 - diff: 40.05mlTrain batch 15/42 - 188.6ms/batch - loss: 23.49855 - diff: 40.09mlTrain batch 16/42 - 187.9ms/batch - loss: 23.42286 - diff: 40.08mlTrain batch 17/42 - 191.0ms/batch - loss: 23.38916 - diff: 40.12mlTrain batch 18/42 - 182.3ms/batch - loss: 23.34983 - diff: 40.06mlTrain batch 19/42 - 188.3ms/batch - loss: 23.11827 - diff: 39.96mlTrain batch 20/42 - 187.6ms/batch - loss: 22.79358 - diff: 39.78mlTrain batch 21/42 - 187.1ms/batch - loss: 23.56695 - diff: 40.18mlTrain batch 22/42 - 182.8ms/batch - loss: 24.18286 - diff: 40.80mlTrain batch 23/42 - 193.2ms/batch - loss: 24.84076 - diff: 41.06mlTrain batch 24/42 - 184.2ms/batch - loss: 25.24721 - diff: 41.30mlTrain batch 25/42 - 182.6ms/batch - loss: 25.23449 - diff: 41.14mlTrain batch 26/42 - 184.1ms/batch - loss: 25.33969 - diff: 41.27mlTrain batch 27/42 - 183.6ms/batch - loss: 25.16099 - diff: 41.19mlTrain batch 28/42 - 188.7ms/batch - loss: 25.51857 - diff: 41.33mlTrain batch 29/42 - 184.5ms/batch - loss: 25.48971 - diff: 41.39mlTrain batch 30/42 - 183.5ms/batch - loss: 25.79525 - diff: 41.67mlTrain batch 31/42 - 187.1ms/batch - loss: 25.53258 - diff: 41.58mlTrain batch 32/42 - 183.9ms/batch - loss: 25.44715 - diff: 41.65mlTrain batch 33/42 - 183.2ms/batch - loss: 25.39678 - diff: 41.66mlTrain batch 34/42 - 188.7ms/batch - loss: 25.60378 - diff: 41.70mlTrain batch 35/42 - 186.1ms/batch - loss: 27.77849 - diff: 41.83mlTrain batch 36/42 - 182.9ms/batch - loss: 28.41532 - diff: 42.21mlTrain batch 37/42 - 199.5ms/batch - loss: 28.56218 - diff: 42.41mlTrain batch 38/42 - 183.1ms/batch - loss: 28.73731 - diff: 42.43mlTrain batch 39/42 - 199.4ms/batch - loss: 28.84502 - diff: 42.50mlTrain batch 40/42 - 183.4ms/batch - loss: 28.96086 - diff: 42.77mlTrain batch 41/42 - 193.5ms/batch - loss: 29.00529 - diff: 42.97mlTrain batch 42/42 - 129.6ms/batch - loss: 29.32046 - diff: 43.06mlTrain batch 42/42 - 368.2s 129.6ms/batch - loss: 29.32046 - diff: 43.06ml
Test 138.2s: val_loss: 5393.36658 - diff: 404.51ml

Epoch 75: current best loss = 18.65666, at epoch 69
Train batch 1/42 - 189.2ms/batch - loss: 35.00891 - diff: 48.97mlTrain batch 2/42 - 185.3ms/batch - loss: 40.79260 - diff: 52.81mlTrain batch 3/42 - 189.7ms/batch - loss: 38.99051 - diff: 50.37mlTrain batch 4/42 - 184.5ms/batch - loss: 34.91480 - diff: 47.90mlTrain batch 5/42 - 189.4ms/batch - loss: 32.57758 - diff: 46.86mlTrain batch 6/42 - 182.7ms/batch - loss: 33.98967 - diff: 47.36mlTrain batch 7/42 - 183.8ms/batch - loss: 33.51524 - diff: 47.23mlTrain batch 8/42 - 184.7ms/batch - loss: 33.24745 - diff: 47.47mlTrain batch 9/42 - 204.1ms/batch - loss: 34.87802 - diff: 47.67mlTrain batch 10/42 - 185.7ms/batch - loss: 37.38129 - diff: 48.02mlTrain batch 11/42 - 183.0ms/batch - loss: 19112.03981 - diff: 357.73mlTrain batch 12/42 - 185.2ms/batch - loss: 802709587055.36975 - diff: 2266905.50mlTrain batch 13/42 - 182.6ms/batch - loss: inf - diff: 71132153854099200147456.00mlTrain batch 14/42 - 182.4ms/batch - loss: nan - diff: nanmlTrain batch 15/42 - 205.9ms/batch - loss: nan - diff: nanmlTrain batch 16/42 - 200.9ms/batch - loss: nan - diff: nanmlTrain batch 17/42 - 189.3ms/batch - loss: nan - diff: nanmlTrain batch 18/42 - 182.4ms/batch - loss: nan - diff: nanmlTrain batch 19/42 - 203.8ms/batch - loss: nan - diff: nanmlTrain batch 20/42 - 184.4ms/batch - loss: nan - diff: nanmlTrain batch 21/42 - 187.0ms/batch - loss: nan - diff: nanmlTrain batch 22/42 - 182.2ms/batch - loss: nan - diff: nanmlTrain batch 23/42 - 200.2ms/batch - loss: nan - diff: nanmlTrain batch 24/42 - 183.4ms/batch - loss: nan - diff: nanmlTrain batch 25/42 - 185.3ms/batch - loss: nan - diff: nanmlTrain batch 26/42 - 183.9ms/batch - loss: nan - diff: nanmlTrain batch 27/42 - 185.6ms/batch - loss: nan - diff: nanmlTrain batch 28/42 - 184.4ms/batch - loss: nan - diff: nanmlTrain batch 29/42 - 190.1ms/batch - loss: nan - diff: nanmlTrain batch 30/42 - 187.8ms/batch - loss: nan - diff: nanmlTrain batch 31/42 - 185.7ms/batch - loss: nan - diff: nanmlTrain batch 32/42 - 184.3ms/batch - loss: nan - diff: nanmlTrain batch 33/42 - 185.3ms/batch - loss: nan - diff: nanmlTrain batch 34/42 - 185.6ms/batch - loss: nan - diff: nanmlTrain batch 35/42 - 189.2ms/batch - loss: nan - diff: nanmlTrain batch 36/42 - 183.9ms/batch - loss: nan - diff: nanmlTrain batch 37/42 - 182.9ms/batch - loss: nan - diff: nanmlTrain batch 38/42 - 183.1ms/batch - loss: nan - diff: nanmlTrain batch 39/42 - 183.9ms/batch - loss: nan - diff: nanmlTrain batch 40/42 - 184.4ms/batch - loss: nan - diff: nanmlTrain batch 41/42 - 188.7ms/batch - loss: nan - diff: nanmlTrain batch 42/42 - 131.0ms/batch - loss: nan - diff: nanmlTrain batch 42/42 - 372.0s 131.0ms/batch - loss: nan - diff: nanml
Test 141.5s: val_loss: nan - diff: nanml

Epoch 76: current best loss = 18.65666, at epoch 69
Train batch 1/42 - 189.7ms/batch - loss: nan - diff: nanmlTrain batch 2/42 - 184.1ms/batch - loss: nan - diff: nanmlTrain batch 3/42 - 184.0ms/batch - loss: nan - diff: nanmlTrain batch 4/42 - 183.0ms/batch - loss: nan - diff: nanmlTrain batch 5/42 - 188.4ms/batch - loss: nan - diff: nanmlTrain batch 6/42 - 184.6ms/batch - loss: nan - diff: nanmlTrain batch 7/42 - 185.9ms/batch - loss: nan - diff: nanmlTrain batch 8/42 - 183.6ms/batch - loss: nan - diff: nanmlTrain batch 9/42 - 182.6ms/batch - loss: nan - diff: nanmlTrain batch 10/42 - 183.1ms/batch - loss: nan - diff: nanmlTrain batch 11/42 - 188.9ms/batch - loss: nan - diff: nanmlTrain batch 12/42 - 185.8ms/batch - loss: nan - diff: nanmlTrain batch 13/42 - 185.3ms/batch - loss: nan - diff: nanmlTrain batch 14/42 - 182.6ms/batch - loss: nan - diff: nanmlTrain batch 15/42 - 185.8ms/batch - loss: nan - diff: nanmlTrain batch 16/42 - 182.4ms/batch - loss: nan - diff: nanmlTrain batch 17/42 - 207.5ms/batch - loss: nan - diff: nanmlTrain batch 18/42 - 183.5ms/batch - loss: nan - diff: nanmlTrain batch 19/42 - 189.3ms/batch - loss: nan - diff: nanmlTrain batch 20/42 - 182.4ms/batch - loss: nan - diff: nanmlTrain batch 21/42 - 3252.3ms/batch - loss: nan - diff: nanmlTrain batch 22/42 - 191.0ms/batch - loss: nan - diff: nanmlTrain batch 23/42 - 188.5ms/batch - loss: nan - diff: nanmlTrain batch 24/42 - 182.4ms/batch - loss: nan - diff: nanmlTrain batch 25/42 - 185.2ms/batch - loss: nan - diff: nanmlTrain batch 26/42 - 182.5ms/batch - loss: nan - diff: nanmlTrain batch 27/42 - 192.7ms/batch - loss: nan - diff: nanmlTrain batch 28/42 - 184.6ms/batch - loss: nan - diff: nanmlTrain batch 29/42 - 186.1ms/batch - loss: nan - diff: nanmlTrain batch 30/42 - 182.5ms/batch - loss: nan - diff: nanmlTrain batch 31/42 - 182.5ms/batch - loss: nan - diff: nanmlTrain batch 32/42 - 182.9ms/batch - loss: nan - diff: nanmlTrain batch 33/42 - 187.5ms/batch - loss: nan - diff: nanmlTrain batch 34/42 - 184.7ms/batch - loss: nan - diff: nanmlTrain batch 35/42 - 182.1ms/batch - loss: nan - diff: nanmlTrain batch 36/42 - 182.8ms/batch - loss: nan - diff: nanmlTrain batch 37/42 - 183.3ms/batch - loss: nan - diff: nanmlTrain batch 38/42 - 184.1ms/batch - loss: nan - diff: nanmlTrain batch 39/42 - 183.4ms/batch - loss: nan - diff: nanmlTrain batch 40/42 - 183.3ms/batch - loss: nan - diff: nanmlTrain batch 41/42 - 187.3ms/batch - loss: nan - diff: nanmlTrain batch 42/42 - 210.2ms/batch - loss: nan - diff: nanmlTrain batch 42/42 - 364.2s 210.2ms/batch - loss: nan - diff: nanml
Test 138.4s: val_loss: nan - diff: nanml

Epoch 77: current best loss = 18.65666, at epoch 69
Train batch 1/42 - 188.0ms/batch - loss: nan - diff: nanmlTrain batch 2/42 - 183.2ms/batch - loss: nan - diff: nanmlTrain batch 3/42 - 187.9ms/batch - loss: nan - diff: nanmlTrain batch 4/42 - 184.2ms/batch - loss: nan - diff: nanmlTrain batch 5/42 - 184.1ms/batch - loss: nan - diff: nanmlTrain batch 6/42 - 183.2ms/batch - loss: nan - diff: nanmlTrain batch 7/42 - 182.3ms/batch - loss: nan - diff: nanmlTrain batch 8/42 - 185.5ms/batch - loss: nan - diff: nanmlTrain batch 9/42 - 188.7ms/batch - loss: nan - diff: nanmlTrain batch 10/42 - 183.7ms/batch - loss: nan - diff: nanmlTrain batch 11/42 - 183.1ms/batch - loss: nan - diff: nanmlTrain batch 12/42 - 182.8ms/batch - loss: nan - diff: nanmlTrain batch 13/42 - 182.4ms/batch - loss: nan - diff: nanmlTrain batch 14/42 - 182.4ms/batch - loss: nan - diff: nanmlTrain batch 15/42 - 204.9ms/batch - loss: nan - diff: nanmlTrain batch 16/42 - 184.7ms/batch - loss: nan - diff: nanmlTrain batch 17/42 - 187.3ms/batch - loss: nan - diff: nanmlTrain batch 18/42 - 182.8ms/batch - loss: nan - diff: nanmlTrain batch 19/42 - 199.5ms/batch - loss: nan - diff: nanmlTrain batch 20/42 - 184.1ms/batch - loss: nan - diff: nanmlTrain batch 21/42 - 187.3ms/batch - loss: nan - diff: nanmlTrain batch 22/42 - 182.1ms/batch - loss: nan - diff: nanmlTrain batch 23/42 - 201.4ms/batch - loss: nan - diff: nanmlTrain batch 24/42 - 186.3ms/batch - loss: nan - diff: nanmlTrain batch 25/42 - 187.8ms/batch - loss: nan - diff: nanmlTrain batch 26/42 - 183.1ms/batch - loss: nan - diff: nanmlTrain batch 27/42 - 186.5ms/batch - loss: nan - diff: nanmlTrain batch 28/42 - 182.7ms/batch - loss: nan - diff: nanmlTrain batch 29/42 - 196.3ms/batch - loss: nan - diff: nanmlTrain batch 30/42 - 183.3ms/batch - loss: nan - diff: nanmlTrain batch 31/42 - 183.6ms/batch - loss: nan - diff: nanmlTrain batch 32/42 - 188.4ms/batch - loss: nan - diff: nanmlTrain batch 33/42 - 187.7ms/batch - loss: nan - diff: nanmlTrain batch 34/42 - 201.7ms/batch - loss: nan - diff: nanmlTrain batch 35/42 - 207.2ms/batch - loss: nan - diff: nanmlTrain batch 36/42 - 196.2ms/batch - loss: nan - diff: nanmlTrain batch 37/42 - 204.6ms/batch - loss: nan - diff: nanmlTrain batch 38/42 - 200.9ms/batch - loss: nan - diff: nanmlTrain batch 39/42 - 182.2ms/batch - loss: nan - diff: nanmlTrain batch 40/42 - 183.4ms/batch - loss: nan - diff: nanmlTrain batch 41/42 - 188.6ms/batch - loss: nan - diff: nanmlTrain batch 42/42 - 130.1ms/batch - loss: nan - diff: nanmlTrain batch 42/42 - 372.7s 130.1ms/batch - loss: nan - diff: nanml
Test 138.6s: val_loss: nan - diff: nanml

Epoch 78: current best loss = 18.65666, at epoch 69
Train batch 1/42 - 188.0ms/batch - loss: nan - diff: nanmlTrain batch 2/42 - 182.7ms/batch - loss: nan - diff: nanmlTrain batch 3/42 - 190.1ms/batch - loss: nan - diff: nanmlTrain batch 4/42 - 184.7ms/batch - loss: nan - diff: nanmlTrain batch 5/42 - 184.3ms/batch - loss: nan - diff: nanmlTrain batch 6/42 - 182.4ms/batch - loss: nan - diff: nanmlTrain batch 7/42 - 182.5ms/batch - loss: nan - diff: nanmlTrain batch 8/42 - 182.7ms/batch - loss: nan - diff: nanmlTrain batch 9/42 - 188.2ms/batch - loss: nan - diff: nanmlTrain batch 10/42 - 184.4ms/batch - loss: nan - diff: nanmlTrain batch 11/42 - 200.8ms/batch - loss: nan - diff: nanmlTrain batch 12/42 - 184.7ms/batch - loss: nan - diff: nanmlTrain batch 13/42 - 183.6ms/batch - loss: nan - diff: nanmlTrain batch 14/42 - 182.5ms/batch - loss: nan - diff: nanmlTrain batch 15/42 - 202.6ms/batch - loss: nan - diff: nanmlTrain batch 16/42 - 184.0ms/batch - loss: nan - diff: nanmlTrain batch 17/42 - 185.3ms/batch - loss: nan - diff: nanmlTrain batch 18/42 - 182.5ms/batch - loss: nan - diff: nanmlTrain batch 19/42 - 204.0ms/batch - loss: nan - diff: nanmlTrain batch 20/42 - 183.8ms/batch - loss: nan - diff: nanmlTrain batch 21/42 - 185.1ms/batch - loss: nan - diff: nanmlTrain batch 22/42 - 182.9ms/batch - loss: nan - diff: nanmlTrain batch 23/42 - 202.8ms/batch - loss: nan - diff: nanmlTrain batch 24/42 - 183.4ms/batch - loss: nan - diff: nanmlTrain batch 25/42 - 190.9ms/batch - loss: nan - diff: nanmlTrain batch 26/42 - 183.2ms/batch - loss: nan - diff: nanmlTrain batch 27/42 - 185.5ms/batch - loss: nan - diff: nanmlTrain batch 28/42 - 182.6ms/batch - loss: nan - diff: nanmlTrain batch 29/42 - 188.0ms/batch - loss: nan - diff: nanmlTrain batch 30/42 - 183.5ms/batch - loss: nan - diff: nanmlTrain batch 31/42 - 183.2ms/batch - loss: nan - diff: nanmlTrain batch 32/42 - 183.8ms/batch - loss: nan - diff: nanmlTrain batch 33/42 - 183.4ms/batch - loss: nan - diff: nanmlTrain batch 34/42 - 183.4ms/batch - loss: nan - diff: nanmlTrain batch 35/42 - 188.2ms/batch - loss: nan - diff: nanmlTrain batch 36/42 - 187.9ms/batch - loss: nan - diff: nanmlTrain batch 37/42 - 183.6ms/batch - loss: nan - diff: nanmlTrain batch 38/42 - 183.9ms/batch - loss: nan - diff: nanmlTrain batch 39/42 - 183.1ms/batch - loss: nan - diff: nanmlTrain batch 40/42 - 182.5ms/batch - loss: nan - diff: nanmlTrain batch 41/42 - 188.8ms/batch - loss: nan - diff: nanmlTrain batch 42/42 - 129.2ms/batch - loss: nan - diff: nanmlTrain batch 42/42 - 367.6s 129.2ms/batch - loss: nan - diff: nanml
Test 140.6s: val_loss: nan - diff: nanml

Epoch 79: current best loss = 18.65666, at epoch 69
Train batch 1/42 - 187.8ms/batch - loss: nan - diff: nanmlTrain batch 2/42 - 183.2ms/batch - loss: nan - diff: nanmlTrain batch 3/42 - 183.8ms/batch - loss: nan - diff: nanmlTrain batch 4/42 - 182.8ms/batch - loss: nan - diff: nanmlTrain batch 5/42 - 187.6ms/batch - loss: nan - diff: nanmlTrain batch 6/42 - 184.3ms/batch - loss: nan - diff: nanmlTrain batch 7/42 - 184.0ms/batch - loss: nan - diff: nanmlTrain batch 8/42 - 182.7ms/batch - loss: nan - diff: nanmlTrain batch 9/42 - 184.7ms/batch - loss: nan - diff: nanmlTrain batch 10/42 - 183.0ms/batch - loss: nan - diff: nanmlTrain batch 11/42 - 188.3ms/batch - loss: nan - diff: nanmlTrain batch 12/42 - 184.8ms/batch - loss: nan - diff: nanmlTrain batch 13/42 - 183.4ms/batch - loss: nan - diff: nanmlTrain batch 14/42 - 182.9ms/batch - loss: nan - diff: nanmlTrain batch 15/42 - 192.2ms/batch - loss: nan - diff: nanmlTrain batch 16/42 - 183.0ms/batch - loss: nan - diff: nanmlTrain batch 17/42 - 210.9ms/batch - loss: nan - diff: nanmlTrain batch 18/42 - 184.3ms/batch - loss: nan - diff: nanmlTrain batch 19/42 - 187.3ms/batch - loss: nan - diff: nanmlTrain batch 20/42 - 183.2ms/batch - loss: nan - diff: nanmlTrain batch 21/42 - 201.5ms/batch - loss: nan - diff: nanmlTrain batch 22/42 - 183.8ms/batch - loss: nan - diff: nanmlTrain batch 23/42 - 185.5ms/batch - loss: nan - diff: nanmlTrain batch 24/42 - 182.9ms/batch - loss: nan - diff: nanmlTrain batch 25/42 - 200.3ms/batch - loss: nan - diff: nanmlTrain batch 26/42 - 184.4ms/batch - loss: nan - diff: nanmlTrain batch 27/42 - 185.5ms/batch - loss: nan - diff: nanmlTrain batch 28/42 - 184.0ms/batch - loss: nan - diff: nanmlTrain batch 29/42 - 183.4ms/batch - loss: nan - diff: nanmlTrain batch 30/42 - 184.7ms/batch - loss: nan - diff: nanmlTrain batch 31/42 - 189.5ms/batch - loss: nan - diff: nanmlTrain batch 32/42 - 184.3ms/batch - loss: nan - diff: nanmlTrain batch 33/42 - 185.9ms/batch - loss: nan - diff: nanmlTrain batch 34/42 - 182.5ms/batch - loss: nan - diff: nanmlTrain batch 35/42 - 184.2ms/batch - loss: nan - diff: nanmlTrain batch 36/42 - 182.1ms/batch - loss: nan - diff: nanmlTrain batch 37/42 - 189.5ms/batch - loss: nan - diff: nanmlTrain batch 38/42 - 184.2ms/batch - loss: nan - diff: nanmlTrain batch 39/42 - 182.6ms/batch - loss: nan - diff: nanmlTrain batch 40/42 - 182.3ms/batch - loss: nan - diff: nanmlTrain batch 41/42 - 183.3ms/batch - loss: nan - diff: nanmlTrain batch 42/42 - 128.9ms/batch - loss: nan - diff: nanmlTrain batch 42/42 - 365.7s 128.9ms/batch - loss: nan - diff: nanml
Test 136.6s: val_loss: nan - diff: nanml

Epoch 80: current best loss = 18.65666, at epoch 69
Train batch 1/42 - 190.6ms/batch - loss: nan - diff: nanmlTrain batch 2/42 - 190.0ms/batch - loss: nan - diff: nanmlTrain batch 3/42 - 188.9ms/batch - loss: nan - diff: nanmlTrain batch 4/42 - 184.7ms/batch - loss: nan - diff: nanmlTrain batch 5/42 - 182.9ms/batch - loss: nan - diff: nanmlTrain batch 6/42 - 184.2ms/batch - loss: nan - diff: nanmlTrain batch 7/42 - 183.7ms/batch - loss: nan - diff: nanmlTrain batch 8/42 - 183.8ms/batch - loss: nan - diff: nanmlTrain batch 9/42 - 191.7ms/batch - loss: nan - diff: nanmlTrain batch 10/42 - 187.0ms/batch - loss: nan - diff: nanmlTrain batch 11/42 - 183.7ms/batch - loss: nan - diff: nanmlTrain batch 12/42 - 183.1ms/batch - loss: nan - diff: nanmlTrain batch 13/42 - 198.2ms/batch - loss: nan - diff: nanmlTrain batch 14/42 - 182.5ms/batch - loss: nan - diff: nanmlTrain batch 15/42 - 195.7ms/batch - loss: nan - diff: nanmlTrain batch 16/42 - 184.9ms/batch - loss: nan - diff: nanmlTrain batch 17/42 - 185.7ms/batch - loss: nan - diff: nanmlTrain batch 18/42 - 182.6ms/batch - loss: nan - diff: nanmlTrain batch 19/42 - 200.5ms/batch - loss: nan - diff: nanmlTrain batch 20/42 - 183.6ms/batch - loss: nan - diff: nanmlTrain batch 21/42 - 185.6ms/batch - loss: nan - diff: nanmlTrain batch 22/42 - 183.0ms/batch - loss: nan - diff: nanmlTrain batch 23/42 - 190.5ms/batch - loss: nan - diff: nanmlTrain batch 24/42 - 184.3ms/batch - loss: nan - diff: nanmlTrain batch 25/42 - 185.6ms/batch - loss: nan - diff: nanmlTrain batch 26/42 - 183.6ms/batch - loss: nan - diff: nanmlTrain batch 27/42 - 183.2ms/batch - loss: nan - diff: nanmlTrain batch 28/42 - 188.3ms/batch - loss: nan - diff: nanmlTrain batch 29/42 - 185.0ms/batch - loss: nan - diff: nanmlTrain batch 30/42 - 183.0ms/batch - loss: nan - diff: nanmlTrain batch 31/42 - 183.3ms/batch - loss: nan - diff: nanmlTrain batch 32/42 - 183.5ms/batch - loss: nan - diff: nanmlTrain batch 33/42 - 183.0ms/batch - loss: nan - diff: nanmlTrain batch 34/42 - 188.3ms/batch - loss: nan - diff: nanmlTrain batch 35/42 - 185.8ms/batch - loss: nan - diff: nanmlTrain batch 36/42 - 183.4ms/batch - loss: nan - diff: nanmlTrain batch 37/42 - 182.8ms/batch - loss: nan - diff: nanmlTrain batch 38/42 - 183.5ms/batch - loss: nan - diff: nanmlTrain batch 39/42 - 182.7ms/batch - loss: nan - diff: nanmlTrain batch 40/42 - 182.9ms/batch - loss: nan - diff: nanmlTrain batch 41/42 - 188.9ms/batch - loss: nan - diff: nanmlTrain batch 42/42 - 130.4ms/batch - loss: nan - diff: nanmlTrain batch 42/42 - 363.2s 130.4ms/batch - loss: nan - diff: nanml
Test 141.2s: val_loss: nan - diff: nanml
Epoch    81: reducing learning rate of group 0 to 5.0000e-04.

Epoch 81: current best loss = 18.65666, at epoch 69
Train batch 1/42 - 189.1ms/batch - loss: nan - diff: nanmlTrain batch 2/42 - 184.7ms/batch - loss: nan - diff: nanmlTrain batch 3/42 - 188.0ms/batch - loss: nan - diff: nanmlTrain batch 4/42 - 185.2ms/batch - loss: nan - diff: nanmlTrain batch 5/42 - 182.8ms/batch - loss: nan - diff: nanmlTrain batch 6/42 - 184.7ms/batch - loss: nan - diff: nanmlTrain batch 7/42 - 183.4ms/batch - loss: nan - diff: nanmlTrain batch 8/42 - 182.6ms/batch - loss: nan - diff: nanmlTrain batch 9/42 - 187.0ms/batch - loss: nan - diff: nanmlTrain batch 10/42 - 185.7ms/batch - loss: nan - diff: nanmlTrain batch 11/42 - 183.2ms/batch - loss: nan - diff: nanmlTrain batch 12/42 - 185.3ms/batch - loss: nan - diff: nanmlTrain batch 13/42 - 183.2ms/batch - loss: nan - diff: nanmlTrain batch 14/42 - 198.2ms/batch - loss: nan - diff: nanmlTrain batch 15/42 - 187.5ms/batch - loss: nan - diff: nanmlTrain batch 16/42 - 184.3ms/batch - loss: nan - diff: nanmlTrain batch 17/42 - 182.4ms/batch - loss: nan - diff: nanmlTrain batch 18/42 - 182.5ms/batch - loss: nan - diff: nanmlTrain batch 19/42 - 187.1ms/batch - loss: nan - diff: nanmlTrain batch 20/42 - 182.9ms/batch - loss: nan - diff: nanmlTrain batch 21/42 - 191.0ms/batch - loss: nan - diff: nanmlTrain batch 22/42 - 182.6ms/batch - loss: nan - diff: nanmlTrain batch 23/42 - 191.8ms/batch - loss: nan - diff: nanmlTrain batch 24/42 - 183.8ms/batch - loss: nan - diff: nanmlTrain batch 25/42 - 185.8ms/batch - loss: nan - diff: nanmlTrain batch 26/42 - 182.8ms/batch - loss: nan - diff: nanmlTrain batch 27/42 - 188.1ms/batch - loss: nan - diff: nanmlTrain batch 28/42 - 190.7ms/batch - loss: nan - diff: nanmlTrain batch 29/42 - 183.6ms/batch - loss: nan - diff: nanmlTrain batch 30/42 - 183.2ms/batch - loss: nan - diff: nanmlTrain batch 31/42 - 182.7ms/batch - loss: nan - diff: nanmlTrain batch 32/42 - 183.3ms/batch - loss: nan - diff: nanmlTrain batch 33/42 - 186.7ms/batch - loss: nan - diff: nanmlTrain batch 34/42 - 183.1ms/batch - loss: nan - diff: nanmlTrain batch 35/42 - 184.8ms/batch - loss: nan - diff: nanmlTrain batch 36/42 - 183.0ms/batch - loss: nan - diff: nanmlTrain batch 37/42 - 182.2ms/batch - loss: nan - diff: nanmlTrain batch 38/42 - 183.6ms/batch - loss: nan - diff: nanmlTrain batch 39/42 - 183.3ms/batch - loss: nan - diff: nanmlTrain batch 40/42 - 188.9ms/batch - loss: nan - diff: nanmlTrain batch 41/42 - 187.5ms/batch - loss: nan - diff: nanmlTrain batch 42/42 - 128.3ms/batch - loss: nan - diff: nanmlTrain batch 42/42 - 361.9s 128.3ms/batch - loss: nan - diff: nanml
Test 139.2s: val_loss: nan - diff: nanml

Epoch 82: current best loss = 18.65666, at epoch 69
Train batch 1/42 - 189.3ms/batch - loss: nan - diff: nanmlTrain batch 2/42 - 185.6ms/batch - loss: nan - diff: nanmlTrain batch 3/42 - 183.2ms/batch - loss: nan - diff: nanmlTrain batch 4/42 - 183.5ms/batch - loss: nan - diff: nanmlTrain batch 5/42 - 188.2ms/batch - loss: nan - diff: nanmlTrain batch 6/42 - 184.6ms/batch - loss: nan - diff: nanmlTrain batch 7/42 - 184.8ms/batch - loss: nan - diff: nanmlTrain batch 8/42 - 183.1ms/batch - loss: nan - diff: nanmlTrain batch 9/42 - 182.6ms/batch - loss: nan - diff: nanmlTrain batch 10/42 - 183.6ms/batch - loss: nan - diff: nanmlTrain batch 11/42 - 188.9ms/batch - loss: nan - diff: nanmlTrain batch 12/42 - 187.1ms/batch - loss: nan - diff: nanmlTrain batch 13/42 - 183.1ms/batch - loss: nan - diff: nanmlTrain batch 14/42 - 182.8ms/batch - loss: nan - diff: nanmlTrain batch 15/42 - 182.7ms/batch - loss: nan - diff: nanmlTrain batch 16/42 - 182.5ms/batch - loss: nan - diff: nanmlTrain batch 17/42 - 202.2ms/batch - loss: nan - diff: nanmlTrain batch 18/42 - 183.4ms/batch - loss: nan - diff: nanmlTrain batch 19/42 - 187.8ms/batch - loss: nan - diff: nanmlTrain batch 20/42 - 183.2ms/batch - loss: nan - diff: nanmlTrain batch 21/42 - 201.5ms/batch - loss: nan - diff: nanmlTrain batch 22/42 - 184.3ms/batch - loss: nan - diff: nanmlTrain batch 23/42 - 185.7ms/batch - loss: nan - diff: nanmlTrain batch 24/42 - 182.4ms/batch - loss: nan - diff: nanmlTrain batch 25/42 - 210.5ms/batch - loss: nan - diff: nanmlTrain batch 26/42 - 184.1ms/batch - loss: nan - diff: nanmlTrain batch 27/42 - 187.5ms/batch - loss: nan - diff: nanmlTrain batch 28/42 - 183.0ms/batch - loss: nan - diff: nanmlTrain batch 29/42 - 186.1ms/batch - loss: nan - diff: nanmlTrain batch 30/42 - 183.8ms/batch - loss: nan - diff: nanmlTrain batch 31/42 - 199.6ms/batch - loss: nan - diff: nanmlTrain batch 32/42 - 183.4ms/batch - loss: nan - diff: nanmlTrain batch 33/42 - 183.2ms/batch - loss: nan - diff: nanmlTrain batch 34/42 - 183.2ms/batch - loss: nan - diff: nanmlTrain batch 35/42 - 183.5ms/batch - loss: nan - diff: nanmlTrain batch 36/42 - 183.0ms/batch - loss: nan - diff: nanmlTrain batch 37/42 - 188.3ms/batch - loss: nan - diff: nanmlTrain batch 38/42 - 184.5ms/batch - loss: nan - diff: nanmlTrain batch 39/42 - 183.5ms/batch - loss: nan - diff: nanmlTrain batch 40/42 - 183.8ms/batch - loss: nan - diff: nanmlTrain batch 41/42 - 183.3ms/batch - loss: nan - diff: nanmlTrain batch 42/42 - 128.3ms/batch - loss: nan - diff: nanmlTrain batch 42/42 - 369.8s 128.3ms/batch - loss: nan - diff: nanml
Test 138.1s: val_loss: nan - diff: nanml

Epoch 83: current best loss = 18.65666, at epoch 69
Train batch 1/42 - 189.0ms/batch - loss: nan - diff: nanmlTrain batch 2/42 - 184.6ms/batch - loss: nan - diff: nanmlTrain batch 3/42 - 185.8ms/batch - loss: nan - diff: nanmlTrain batch 4/42 - 183.5ms/batch - loss: nan - diff: nanmlTrain batch 5/42 - 183.6ms/batch - loss: nan - diff: nanmlTrain batch 6/42 - 183.4ms/batch - loss: nan - diff: nanmlTrain batch 7/42 - 184.4ms/batch - loss: nan - diff: nanmlTrain batch 8/42 - 183.1ms/batch - loss: nan - diff: nanmlTrain batch 9/42 - 187.9ms/batch - loss: nan - diff: nanmlTrain batch 10/42 - 185.3ms/batch - loss: nan - diff: nanmlTrain batch 11/42 - 183.2ms/batch - loss: nan - diff: nanmlTrain batch 12/42 - 183.1ms/batch - loss: nan - diff: nanmlTrain batch 13/42 - 183.3ms/batch - loss: nan - diff: nanmlTrain batch 14/42 - 182.9ms/batch - loss: nan - diff: nanmlTrain batch 15/42 - 185.4ms/batch - loss: nan - diff: nanmlTrain batch 16/42 - 182.4ms/batch - loss: nan - diff: nanmlTrain batch 17/42 - 185.0ms/batch - loss: nan - diff: nanmlTrain batch 18/42 - 183.5ms/batch - loss: nan - diff: nanmlTrain batch 19/42 - 209.9ms/batch - loss: nan - diff: nanmlTrain batch 20/42 - 183.4ms/batch - loss: nan - diff: nanmlTrain batch 21/42 - 185.9ms/batch - loss: nan - diff: nanmlTrain batch 22/42 - 182.8ms/batch - loss: nan - diff: nanmlTrain batch 23/42 - 212.9ms/batch - loss: nan - diff: nanmlTrain batch 24/42 - 184.5ms/batch - loss: nan - diff: nanmlTrain batch 25/42 - 185.2ms/batch - loss: nan - diff: nanmlTrain batch 26/42 - 183.6ms/batch - loss: nan - diff: nanmlTrain batch 27/42 - 206.8ms/batch - loss: nan - diff: nanmlTrain batch 28/42 - 185.1ms/batch - loss: nan - diff: nanmlTrain batch 29/42 - 184.4ms/batch - loss: nan - diff: nanmlTrain batch 30/42 - 190.9ms/batch - loss: nan - diff: nanmlTrain batch 31/42 - 182.9ms/batch - loss: nan - diff: nanmlTrain batch 32/42 - 183.3ms/batch - loss: nan - diff: nanmlTrain batch 33/42 - 189.8ms/batch - loss: nan - diff: nanmlTrain batch 34/42 - 186.2ms/batch - loss: nan - diff: nanmlTrain batch 35/42 - 182.8ms/batch - loss: nan - diff: nanmlTrain batch 36/42 - 183.5ms/batch - loss: nan - diff: nanmlTrain batch 37/42 - 182.9ms/batch - loss: nan - diff: nanmlTrain batch 38/42 - 182.6ms/batch - loss: nan - diff: nanmlTrain batch 39/42 - 191.9ms/batch - loss: nan - diff: nanmlTrain batch 40/42 - 184.6ms/batch - loss: nan - diff: nanmlTrain batch 41/42 - 183.1ms/batch - loss: nan - diff: nanmlTrain batch 42/42 - 128.5ms/batch - loss: nan - diff: nanmlTrain batch 42/42 - 370.8s 128.5ms/batch - loss: nan - diff: nanml
Test 138.1s: val_loss: nan - diff: nanml

Epoch 84: current best loss = 18.65666, at epoch 69
Train batch 1/42 - 187.2ms/batch - loss: nan - diff: nanmlTrain batch 2/42 - 184.6ms/batch - loss: nan - diff: nanmlTrain batch 3/42 - 187.8ms/batch - loss: nan - diff: nanmlTrain batch 4/42 - 183.7ms/batch - loss: nan - diff: nanmlTrain batch 5/42 - 183.0ms/batch - loss: nan - diff: nanmlTrain batch 6/42 - 183.2ms/batch - loss: nan - diff: nanmlTrain batch 7/42 - 184.4ms/batch - loss: nan - diff: nanmlTrain batch 8/42 - 183.5ms/batch - loss: nan - diff: nanmlTrain batch 9/42 - 188.9ms/batch - loss: nan - diff: nanmlTrain batch 10/42 - 184.2ms/batch - loss: nan - diff: nanmlTrain batch 11/42 - 182.7ms/batch - loss: nan - diff: nanmlTrain batch 12/42 - 182.8ms/batch - loss: nan - diff: nanmlTrain batch 13/42 - 183.0ms/batch - loss: nan - diff: nanmlTrain batch 14/42 - 184.0ms/batch - loss: nan - diff: nanmlTrain batch 15/42 - 187.8ms/batch - loss: nan - diff: nanmlTrain batch 16/42 - 182.4ms/batch - loss: nan - diff: nanmlTrain batch 17/42 - 203.3ms/batch - loss: nan - diff: nanmlTrain batch 18/42 - 186.0ms/batch - loss: nan - diff: nanmlTrain batch 19/42 - 187.7ms/batch - loss: nan - diff: nanmlTrain batch 20/42 - 182.6ms/batch - loss: nan - diff: nanmlTrain batch 21/42 - 200.9ms/batch - loss: nan - diff: nanmlTrain batch 22/42 - 184.5ms/batch - loss: nan - diff: nanmlTrain batch 23/42 - 185.3ms/batch - loss: nan - diff: nanmlTrain batch 24/42 - 182.6ms/batch - loss: nan - diff: nanmlTrain batch 25/42 - 197.7ms/batch - loss: nan - diff: nanmlTrain batch 26/42 - 183.1ms/batch - loss: nan - diff: nanmlTrain batch 27/42 - 187.5ms/batch - loss: nan - diff: nanmlTrain batch 28/42 - 183.1ms/batch - loss: nan - diff: nanmlTrain batch 29/42 - 185.8ms/batch - loss: nan - diff: nanmlTrain batch 30/42 - 183.4ms/batch - loss: nan - diff: nanmlTrain batch 31/42 - 188.3ms/batch - loss: nan - diff: nanmlTrain batch 32/42 - 184.3ms/batch - loss: nan - diff: nanmlTrain batch 33/42 - 183.3ms/batch - loss: nan - diff: nanmlTrain batch 34/42 - 183.4ms/batch - loss: nan - diff: nanmlTrain batch 35/42 - 184.8ms/batch - loss: nan - diff: nanmlTrain batch 36/42 - 183.8ms/batch - loss: nan - diff: nanmlTrain batch 37/42 - 188.0ms/batch - loss: nan - diff: nanmlTrain batch 38/42 - 184.6ms/batch - loss: nan - diff: nanmlTrain batch 39/42 - 184.1ms/batch - loss: nan - diff: nanmlTrain batch 40/42 - 182.6ms/batch - loss: nan - diff: nanmlTrain batch 41/42 - 184.2ms/batch - loss: nan - diff: nanmlTrain batch 42/42 - 129.1ms/batch - loss: nan - diff: nanmlTrain batch 42/42 - 366.5s 129.1ms/batch - loss: nan - diff: nanml
Test 139.4s: val_loss: nan - diff: nanml

Epoch 85: current best loss = 18.65666, at epoch 69
Train batch 1/42 - 198.1ms/batch - loss: nan - diff: nanmlTrain batch 2/42 - 183.5ms/batch - loss: nan - diff: nanmlTrain batch 3/42 - 188.3ms/batch - loss: nan - diff: nanmlTrain batch 4/42 - 188.4ms/batch - loss: nan - diff: nanmlTrain batch 5/42 - 184.5ms/batch - loss: nan - diff: nanmlTrain batch 6/42 - 182.6ms/batch - loss: nan - diff: nanmlTrain batch 7/42 - 183.5ms/batch - loss: nan - diff: nanmlTrain batch 8/42 - 183.4ms/batch - loss: nan - diff: nanmlTrain batch 9/42 - 188.0ms/batch - loss: nan - diff: nanmlTrain batch 10/42 - 184.3ms/batch - loss: nan - diff: nanmlTrain batch 11/42 - 183.3ms/batch - loss: nan - diff: nanmlTrain batch 12/42 - 183.9ms/batch - loss: nan - diff: nanmlTrain batch 13/42 - 183.0ms/batch - loss: nan - diff: nanmlTrain batch 14/42 - 183.3ms/batch - loss: nan - diff: nanmlTrain batch 15/42 - 187.3ms/batch - loss: nan - diff: nanmlTrain batch 16/42 - 182.7ms/batch - loss: nan - diff: nanmlTrain batch 17/42 - 185.5ms/batch - loss: nan - diff: nanmlTrain batch 18/42 - 182.3ms/batch - loss: nan - diff: nanmlTrain batch 19/42 - 190.6ms/batch - loss: nan - diff: nanmlTrain batch 20/42 - 183.5ms/batch - loss: nan - diff: nanmlTrain batch 21/42 - 186.9ms/batch - loss: nan - diff: nanmlTrain batch 22/42 - 182.7ms/batch - loss: nan - diff: nanmlTrain batch 23/42 - 200.3ms/batch - loss: nan - diff: nanmlTrain batch 24/42 - 184.5ms/batch - loss: nan - diff: nanmlTrain batch 25/42 - 185.2ms/batch - loss: nan - diff: nanmlTrain batch 26/42 - 182.9ms/batch - loss: nan - diff: nanmlTrain batch 27/42 - 188.1ms/batch - loss: nan - diff: nanmlTrain batch 28/42 - 183.8ms/batch - loss: nan - diff: nanmlTrain batch 29/42 - 182.8ms/batch - loss: nan - diff: nanmlTrain batch 30/42 - 183.1ms/batch - loss: nan - diff: nanmlTrain batch 31/42 - 183.6ms/batch - loss: nan - diff: nanmlTrain batch 32/42 - 183.8ms/batch - loss: nan - diff: nanmlTrain batch 33/42 - 188.7ms/batch - loss: nan - diff: nanmlTrain batch 34/42 - 183.7ms/batch - loss: nan - diff: nanmlTrain batch 35/42 - 183.5ms/batch - loss: nan - diff: nanmlTrain batch 36/42 - 183.7ms/batch - loss: nan - diff: nanmlTrain batch 37/42 - 199.8ms/batch - loss: nan - diff: nanmlTrain batch 38/42 - 184.4ms/batch - loss: nan - diff: nanmlTrain batch 39/42 - 187.6ms/batch - loss: nan - diff: nanmlTrain batch 40/42 - 184.2ms/batch - loss: nan - diff: nanmlTrain batch 41/42 - 183.4ms/batch - loss: nan - diff: nanmlTrain batch 42/42 - 127.9ms/batch - loss: nan - diff: nanmlTrain batch 42/42 - 367.3s 127.9ms/batch - loss: nan - diff: nanml
Test 139.7s: val_loss: nan - diff: nanml

Epoch 86: current best loss = 18.65666, at epoch 69
Train batch 1/42 - 189.8ms/batch - loss: nan - diff: nanmlTrain batch 2/42 - 183.3ms/batch - loss: nan - diff: nanmlTrain batch 3/42 - 188.0ms/batch - loss: nan - diff: nanmlTrain batch 4/42 - 184.7ms/batch - loss: nan - diff: nanmlTrain batch 5/42 - 182.7ms/batch - loss: nan - diff: nanmlTrain batch 6/42 - 182.6ms/batch - loss: nan - diff: nanmlTrain batch 7/42 - 183.2ms/batch - loss: nan - diff: nanmlTrain batch 8/42 - 183.6ms/batch - loss: nan - diff: nanmlTrain batch 9/42 - 193.4ms/batch - loss: nan - diff: nanmlTrain batch 10/42 - 186.3ms/batch - loss: nan - diff: nanmlTrain batch 11/42 - 182.6ms/batch - loss: nan - diff: nanmlTrain batch 12/42 - 183.0ms/batch - loss: nan - diff: nanmlTrain batch 13/42 - 183.5ms/batch - loss: nan - diff: nanmlTrain batch 14/42 - 184.0ms/batch - loss: nan - diff: nanmlTrain batch 15/42 - 188.4ms/batch - loss: nan - diff: nanmlTrain batch 16/42 - 184.8ms/batch - loss: nan - diff: nanmlTrain batch 17/42 - 192.6ms/batch - loss: nan - diff: nanmlTrain batch 18/42 - 182.3ms/batch - loss: nan - diff: nanmlTrain batch 19/42 - 207.5ms/batch - loss: nan - diff: nanmlTrain batch 20/42 - 183.7ms/batch - loss: nan - diff: nanmlTrain batch 21/42 - 185.5ms/batch - loss: nan - diff: nanmlTrain batch 22/42 - 182.6ms/batch - loss: nan - diff: nanmlTrain batch 23/42 - 204.5ms/batch - loss: nan - diff: nanmlTrain batch 24/42 - 182.8ms/batch - loss: nan - diff: nanmlTrain batch 25/42 - 185.2ms/batch - loss: nan - diff: nanmlTrain batch 26/42 - 182.5ms/batch - loss: nan - diff: nanmlTrain batch 27/42 - 183.9ms/batch - loss: nan - diff: nanmlTrain batch 28/42 - 183.3ms/batch - loss: nan - diff: nanmlTrain batch 29/42 - 189.1ms/batch - loss: nan - diff: nanmlTrain batch 30/42 - 184.3ms/batch - loss: nan - diff: nanmlTrain batch 31/42 - 183.2ms/batch - loss: nan - diff: nanmlTrain batch 32/42 - 184.0ms/batch - loss: nan - diff: nanmlTrain batch 33/42 - 189.1ms/batch - loss: nan - diff: nanmlTrain batch 34/42 - 184.0ms/batch - loss: nan - diff: nanmlTrain batch 35/42 - 183.0ms/batch - loss: nan - diff: nanmlTrain batch 36/42 - 184.7ms/batch - loss: nan - diff: nanmlTrain batch 37/42 - 184.2ms/batch - loss: nan - diff: nanmlTrain batch 38/42 - 183.3ms/batch - loss: nan - diff: nanmlTrain batch 39/42 - 182.6ms/batch - loss: nan - diff: nanmlTrain batch 40/42 - 182.3ms/batch - loss: nan - diff: nanmlTrain batch 41/42 - 188.6ms/batch - loss: nan - diff: nanmlTrain batch 42/42 - 129.7ms/batch - loss: nan - diff: nanmlTrain batch 42/42 - 366.2s 129.7ms/batch - loss: nan - diff: nanml
Test 137.3s: val_loss: nan - diff: nanml

Epoch 87: current best loss = 18.65666, at epoch 69
Train batch 1/42 - 192.9ms/batch - loss: nan - diff: nanmlTrain batch 2/42 - 185.9ms/batch - loss: nan - diff: nanmlTrain batch 3/42 - 184.0ms/batch - loss: nan - diff: nanmlTrain batch 4/42 - 183.1ms/batch - loss: nan - diff: nanmlTrain batch 5/42 - 190.9ms/batch - loss: nan - diff: nanmlTrain batch 6/42 - 183.7ms/batch - loss: nan - diff: nanmlTrain batch 7/42 - 186.0ms/batch - loss: nan - diff: nanmlTrain batch 8/42 - 196.1ms/batch - loss: nan - diff: nanmlTrain batch 9/42 - 184.1ms/batch - loss: nan - diff: nanmlTrain batch 10/42 - 182.3ms/batch - loss: nan - diff: nanmlTrain batch 11/42 - 188.3ms/batch - loss: nan - diff: nanmlTrain batch 12/42 - 184.4ms/batch - loss: nan - diff: nanmlTrain batch 13/42 - 184.5ms/batch - loss: nan - diff: nanmlTrain batch 14/42 - 182.6ms/batch - loss: nan - diff: nanmlTrain batch 15/42 - 184.9ms/batch - loss: nan - diff: nanmlTrain batch 16/42 - 182.5ms/batch - loss: nan - diff: nanmlTrain batch 17/42 - 205.1ms/batch - loss: nan - diff: nanmlTrain batch 18/42 - 184.2ms/batch - loss: nan - diff: nanmlTrain batch 19/42 - 185.3ms/batch - loss: nan - diff: nanmlTrain batch 20/42 - 182.7ms/batch - loss: nan - diff: nanmlTrain batch 21/42 - 205.4ms/batch - loss: nan - diff: nanmlTrain batch 22/42 - 183.7ms/batch - loss: nan - diff: nanmlTrain batch 23/42 - 185.2ms/batch - loss: nan - diff: nanmlTrain batch 24/42 - 182.5ms/batch - loss: nan - diff: nanmlTrain batch 25/42 - 207.2ms/batch - loss: nan - diff: nanmlTrain batch 26/42 - 184.7ms/batch - loss: nan - diff: nanmlTrain batch 27/42 - 188.7ms/batch - loss: nan - diff: nanmlTrain batch 28/42 - 183.9ms/batch - loss: nan - diff: nanmlTrain batch 29/42 - 183.2ms/batch - loss: nan - diff: nanmlTrain batch 30/42 - 182.7ms/batch - loss: nan - diff: nanmlTrain batch 31/42 - 189.3ms/batch - loss: nan - diff: nanmlTrain batch 32/42 - 183.9ms/batch - loss: nan - diff: nanmlTrain batch 33/42 - 183.6ms/batch - loss: nan - diff: nanmlTrain batch 34/42 - 184.1ms/batch - loss: nan - diff: nanmlTrain batch 35/42 - 183.3ms/batch - loss: nan - diff: nanmlTrain batch 36/42 - 184.5ms/batch - loss: nan - diff: nanmlTrain batch 37/42 - 187.1ms/batch - loss: nan - diff: nanmlTrain batch 38/42 - 184.2ms/batch - loss: nan - diff: nanmlTrain batch 39/42 - 183.6ms/batch - loss: nan - diff: nanmlTrain batch 40/42 - 182.7ms/batch - loss: nan - diff: nanmlTrain batch 41/42 - 183.0ms/batch - loss: nan - diff: nanmlTrain batch 42/42 - 128.0ms/batch - loss: nan - diff: nanmlTrain batch 42/42 - 369.0s 128.0ms/batch - loss: nan - diff: nanml
Test 139.5s: val_loss: nan - diff: nanml

Epoch 88: current best loss = 18.65666, at epoch 69
Train batch 1/42 - 190.2ms/batch - loss: nan - diff: nanmlTrain batch 2/42 - 183.8ms/batch - loss: nan - diff: nanmlTrain batch 3/42 - 186.0ms/batch - loss: nan - diff: nanmlTrain batch 4/42 - 183.5ms/batch - loss: nan - diff: nanmlTrain batch 5/42 - 183.6ms/batch - loss: nan - diff: nanmlTrain batch 6/42 - 182.5ms/batch - loss: nan - diff: nanmlTrain batch 7/42 - 183.2ms/batch - loss: nan - diff: nanmlTrain batch 8/42 - 182.4ms/batch - loss: nan - diff: nanmlTrain batch 9/42 - 189.5ms/batch - loss: nan - diff: nanmlTrain batch 10/42 - 184.1ms/batch - loss: nan - diff: nanmlTrain batch 11/42 - 199.4ms/batch - loss: nan - diff: nanmlTrain batch 12/42 - 183.2ms/batch - loss: nan - diff: nanmlTrain batch 13/42 - 184.2ms/batch - loss: nan - diff: nanmlTrain batch 14/42 - 182.6ms/batch - loss: nan - diff: nanmlTrain batch 15/42 - 187.3ms/batch - loss: nan - diff: nanmlTrain batch 16/42 - 182.1ms/batch - loss: nan - diff: nanmlTrain batch 17/42 - 182.7ms/batch - loss: nan - diff: nanmlTrain batch 18/42 - 183.7ms/batch - loss: nan - diff: nanmlTrain batch 19/42 - 193.2ms/batch - loss: nan - diff: nanmlTrain batch 20/42 - 183.2ms/batch - loss: nan - diff: nanmlTrain batch 21/42 - 185.2ms/batch - loss: nan - diff: nanmlTrain batch 22/42 - 182.4ms/batch - loss: nan - diff: nanmlTrain batch 23/42 - 198.6ms/batch - loss: nan - diff: nanmlTrain batch 24/42 - 182.5ms/batch - loss: nan - diff: nanmlTrain batch 25/42 - 185.5ms/batch - loss: nan - diff: nanmlTrain batch 26/42 - 183.0ms/batch - loss: nan - diff: nanmlTrain batch 27/42 - 183.9ms/batch - loss: nan - diff: nanmlTrain batch 28/42 - 187.8ms/batch - loss: nan - diff: nanmlTrain batch 29/42 - 183.5ms/batch - loss: nan - diff: nanmlTrain batch 30/42 - 183.0ms/batch - loss: nan - diff: nanmlTrain batch 31/42 - 183.6ms/batch - loss: nan - diff: nanmlTrain batch 32/42 - 183.1ms/batch - loss: nan - diff: nanmlTrain batch 33/42 - 183.1ms/batch - loss: nan - diff: nanmlTrain batch 34/42 - 187.9ms/batch - loss: nan - diff: nanmlTrain batch 35/42 - 184.7ms/batch - loss: nan - diff: nanmlTrain batch 36/42 - 185.3ms/batch - loss: nan - diff: nanmlTrain batch 37/42 - 183.0ms/batch - loss: nan - diff: nanmlTrain batch 38/42 - 183.9ms/batch - loss: nan - diff: nanmlTrain batch 39/42 - 184.6ms/batch - loss: nan - diff: nanmlTrain batch 40/42 - 183.1ms/batch - loss: nan - diff: nanmlTrain batch 41/42 - 188.5ms/batch - loss: nan - diff: nanmlTrain batch 42/42 - 130.2ms/batch - loss: nan - diff: nanmlTrain batch 42/42 - 368.4s 130.2ms/batch - loss: nan - diff: nanml
Test 139.6s: val_loss: nan - diff: nanml

Epoch 89: current best loss = 18.65666, at epoch 69
Train batch 1/42 - 206.2ms/batch - loss: nan - diff: nanmlTrain batch 2/42 - 184.7ms/batch - loss: nan - diff: nanmlTrain batch 3/42 - 184.2ms/batch - loss: nan - diff: nanmlTrain batch 4/42 - 183.4ms/batch - loss: nan - diff: nanmlTrain batch 5/42 - 186.2ms/batch - loss: nan - diff: nanmlTrain batch 6/42 - 182.7ms/batch - loss: nan - diff: nanmlTrain batch 7/42 - 186.8ms/batch - loss: nan - diff: nanmlTrain batch 8/42 - 185.1ms/batch - loss: nan - diff: nanmlTrain batch 9/42 - 184.4ms/batch - loss: nan - diff: nanmlTrain batch 10/42 - 185.9ms/batch - loss: nan - diff: nanmlTrain batch 11/42 - 183.4ms/batch - loss: nan - diff: nanmlTrain batch 12/42 - 185.2ms/batch - loss: nan - diff: nanmlTrain batch 13/42 - 188.1ms/batch - loss: nan - diff: nanmlTrain batch 14/42 - 184.3ms/batch - loss: nan - diff: nanmlTrain batch 15/42 - 185.0ms/batch - loss: nan - diff: nanmlTrain batch 16/42 - 183.5ms/batch - loss: nan - diff: nanmlTrain batch 17/42 - 199.5ms/batch - loss: nan - diff: nanmlTrain batch 18/42 - 184.4ms/batch - loss: nan - diff: nanmlTrain batch 19/42 - 185.4ms/batch - loss: nan - diff: nanmlTrain batch 20/42 - 182.4ms/batch - loss: nan - diff: nanmlTrain batch 21/42 - 203.7ms/batch - loss: nan - diff: nanmlTrain batch 22/42 - 183.9ms/batch - loss: nan - diff: nanmlTrain batch 23/42 - 185.6ms/batch - loss: nan - diff: nanmlTrain batch 24/42 - 182.5ms/batch - loss: nan - diff: nanmlTrain batch 25/42 - 190.9ms/batch - loss: nan - diff: nanmlTrain batch 26/42 - 184.1ms/batch - loss: nan - diff: nanmlTrain batch 27/42 - 186.1ms/batch - loss: nan - diff: nanmlTrain batch 28/42 - 183.2ms/batch - loss: nan - diff: nanmlTrain batch 29/42 - 183.2ms/batch - loss: nan - diff: nanmlTrain batch 30/42 - 183.4ms/batch - loss: nan - diff: nanmlTrain batch 31/42 - 189.0ms/batch - loss: nan - diff: nanmlTrain batch 32/42 - 184.2ms/batch - loss: nan - diff: nanmlTrain batch 33/42 - 185.3ms/batch - loss: nan - diff: nanmlTrain batch 34/42 - 182.9ms/batch - loss: nan - diff: nanmlTrain batch 35/42 - 183.3ms/batch - loss: nan - diff: nanmlTrain batch 36/42 - 183.1ms/batch - loss: nan - diff: nanmlTrain batch 37/42 - 183.0ms/batch - loss: nan - diff: nanmlTrain batch 38/42 - 182.8ms/batch - loss: nan - diff: nanmlTrain batch 39/42 - 187.1ms/batch - loss: nan - diff: nanmlTrain batch 40/42 - 183.5ms/batch - loss: nan - diff: nanmlTrain batch 41/42 - 182.9ms/batch - loss: nan - diff: nanmlTrain batch 42/42 - 128.4ms/batch - loss: nan - diff: nanmlTrain batch 42/42 - 362.0s 128.4ms/batch - loss: nan - diff: nanml
Test 138.3s: val_loss: nan - diff: nanml

Epoch 90: current best loss = 18.65666, at epoch 69
Train batch 1/42 - 184.8ms/batch - loss: nan - diff: nanmlTrain batch 2/42 - 183.6ms/batch - loss: nan - diff: nanmlTrain batch 3/42 - 183.4ms/batch - loss: nan - diff: nanmlTrain batch 4/42 - 183.5ms/batch - loss: nan - diff: nanmlTrain batch 5/42 - 190.1ms/batch - loss: nan - diff: nanmlTrain batch 6/42 - 186.1ms/batch - loss: nan - diff: nanmlTrain batch 7/42 - 188.5ms/batch - loss: nan - diff: nanmlTrain batch 8/42 - 183.3ms/batch - loss: nan - diff: nanmlTrain batch 9/42 - 185.1ms/batch - loss: nan - diff: nanmlTrain batch 10/42 - 183.9ms/batch - loss: nan - diff: nanmlTrain batch 11/42 - 188.7ms/batch - loss: nan - diff: nanmlTrain batch 12/42 - 187.1ms/batch - loss: nan - diff: nanmlTrain batch 13/42 - 182.7ms/batch - loss: nan - diff: nanmlTrain batch 14/42 - 182.9ms/batch - loss: nan - diff: nanmlTrain batch 15/42 - 185.7ms/batch - loss: nan - diff: nanmlTrain batch 16/42 - 182.9ms/batch - loss: nan - diff: nanmlTrain batch 17/42 - 198.5ms/batch - loss: nan - diff: nanmlTrain batch 18/42 - 182.8ms/batch - loss: nan - diff: nanmlTrain batch 19/42 - 188.1ms/batch - loss: nan - diff: nanmlTrain batch 20/42 - 183.2ms/batch - loss: nan - diff: nanmlTrain batch 21/42 - 214.9ms/batch - loss: nan - diff: nanmlTrain batch 22/42 - 182.7ms/batch - loss: nan - diff: nanmlTrain batch 23/42 - 185.6ms/batch - loss: nan - diff: nanmlTrain batch 24/42 - 182.8ms/batch - loss: nan - diff: nanmlTrain batch 25/42 - 191.5ms/batch - loss: nan - diff: nanmlTrain batch 26/42 - 184.3ms/batch - loss: nan - diff: nanmlTrain batch 27/42 - 183.9ms/batch - loss: nan - diff: nanmlTrain batch 28/42 - 184.1ms/batch - loss: nan - diff: nanmlTrain batch 29/42 - 184.0ms/batch - loss: nan - diff: nanmlTrain batch 30/42 - 183.2ms/batch - loss: nan - diff: nanmlTrain batch 31/42 - 188.8ms/batch - loss: nan - diff: nanmlTrain batch 32/42 - 185.2ms/batch - loss: nan - diff: nanmlTrain batch 33/42 - 183.0ms/batch - loss: nan - diff: nanmlTrain batch 34/42 - 200.9ms/batch - loss: nan - diff: nanmlTrain batch 35/42 - 183.4ms/batch - loss: nan - diff: nanmlTrain batch 36/42 - 184.3ms/batch - loss: nan - diff: nanmlTrain batch 37/42 - 190.2ms/batch - loss: nan - diff: nanmlTrain batch 38/42 - 182.7ms/batch - loss: nan - diff: nanmlTrain batch 39/42 - 183.2ms/batch - loss: nan - diff: nanmlTrain batch 40/42 - 184.1ms/batch - loss: nan - diff: nanmlTrain batch 41/42 - 183.3ms/batch - loss: nan - diff: nanmlTrain batch 42/42 - 128.3ms/batch - loss: nan - diff: nanmlTrain batch 42/42 - 366.5s 128.3ms/batch - loss: nan - diff: nanml
Test 137.8s: val_loss: nan - diff: nanml

Epoch 91: current best loss = 18.65666, at epoch 69
Train batch 1/42 - 188.6ms/batch - loss: nan - diff: nanmlTrain batch 2/42 - 184.2ms/batch - loss: nan - diff: nanmlTrain batch 3/42 - 188.6ms/batch - loss: nan - diff: nanmlTrain batch 4/42 - 185.5ms/batch - loss: nan - diff: nanmlTrain batch 5/42 - 188.5ms/batch - loss: nan - diff: nanmlTrain batch 6/42 - 184.3ms/batch - loss: nan - diff: nanmlTrain batch 7/42 - 183.5ms/batch - loss: nan - diff: nanmlTrain batch 8/42 - 183.6ms/batch - loss: nan - diff: nanmlTrain batch 9/42 - 189.8ms/batch - loss: nan - diff: nanmlTrain batch 10/42 - 183.0ms/batch - loss: nan - diff: nanmlTrain batch 11/42 - 182.3ms/batch - loss: nan - diff: nanmlTrain batch 12/42 - 182.9ms/batch - loss: nan - diff: nanmlTrain batch 13/42 - 184.2ms/batch - loss: nan - diff: nanmlTrain batch 14/42 - 183.5ms/batch - loss: nan - diff: nanmlTrain batch 15/42 - 196.9ms/batch - loss: nan - diff: nanmlTrain batch 16/42 - 184.1ms/batch - loss: nan - diff: nanmlTrain batch 17/42 - 184.9ms/batch - loss: nan - diff: nanmlTrain batch 18/42 - 183.0ms/batch - loss: nan - diff: nanmlTrain batch 19/42 - 197.0ms/batch - loss: nan - diff: nanmlTrain batch 20/42 - 183.3ms/batch - loss: nan - diff: nanmlTrain batch 21/42 - 191.5ms/batch - loss: nan - diff: nanmlTrain batch 22/42 - 183.2ms/batch - loss: nan - diff: nanmlTrain batch 23/42 - 210.8ms/batch - loss: nan - diff: nanmlTrain batch 24/42 - 183.9ms/batch - loss: nan - diff: nanmlTrain batch 25/42 - 185.9ms/batch - loss: nan - diff: nanmlTrain batch 26/42 - 182.9ms/batch - loss: nan - diff: nanmlTrain batch 27/42 - 183.5ms/batch - loss: nan - diff: nanmlTrain batch 28/42 - 183.1ms/batch - loss: nan - diff: nanmlTrain batch 29/42 - 189.4ms/batch - loss: nan - diff: nanmlTrain batch 30/42 - 183.8ms/batch - loss: nan - diff: nanmlTrain batch 31/42 - 183.6ms/batch - loss: nan - diff: nanmlTrain batch 32/42 - 183.7ms/batch - loss: nan - diff: nanmlTrain batch 33/42 - 183.4ms/batch - loss: nan - diff: nanmlTrain batch 34/42 - 182.4ms/batch - loss: nan - diff: nanmlTrain batch 35/42 - 185.4ms/batch - loss: nan - diff: nanmlTrain batch 36/42 - 182.7ms/batch - loss: nan - diff: nanmlTrain batch 37/42 - 182.8ms/batch - loss: nan - diff: nanmlTrain batch 38/42 - 184.0ms/batch - loss: nan - diff: nanmlTrain batch 39/42 - 183.8ms/batch - loss: nan - diff: nanmlTrain batch 40/42 - 184.0ms/batch - loss: nan - diff: nanmlTrain batch 41/42 - 188.7ms/batch - loss: nan - diff: nanmlTrain batch 42/42 - 131.0ms/batch - loss: nan - diff: nanmlTrain batch 42/42 - 369.8s 131.0ms/batch - loss: nan - diff: nanml
Test 138.0s: val_loss: nan - diff: nanml
Epoch    92: reducing learning rate of group 0 to 2.5000e-04.

Epoch 92: current best loss = 18.65666, at epoch 69
Train batch 1/42 - 194.3ms/batch - loss: nan - diff: nanmlTrain batch 2/42 - 183.6ms/batch - loss: nan - diff: nanmlTrain batch 3/42 - 183.4ms/batch - loss: nan - diff: nanmlTrain batch 4/42 - 182.7ms/batch - loss: nan - diff: nanmlTrain batch 5/42 - 183.2ms/batch - loss: nan - diff: nanmlTrain batch 6/42 - 183.8ms/batch - loss: nan - diff: nanmlTrain batch 7/42 - 189.7ms/batch - loss: nan - diff: nanmlTrain batch 8/42 - 199.0ms/batch - loss: nan - diff: nanmlTrain batch 9/42 - 193.2ms/batch - loss: nan - diff: nanmlTrain batch 10/42 - 185.1ms/batch - loss: nan - diff: nanmlTrain batch 11/42 - 185.1ms/batch - loss: nan - diff: nanmlTrain batch 12/42 - 183.1ms/batch - loss: nan - diff: nanmlTrain batch 13/42 - 189.0ms/batch - loss: nan - diff: nanmlTrain batch 14/42 - 183.9ms/batch - loss: nan - diff: nanmlTrain batch 15/42 - 185.3ms/batch - loss: nan - diff: nanmlTrain batch 16/42 - 182.6ms/batch - loss: nan - diff: nanmlTrain batch 17/42 - 192.1ms/batch - loss: nan - diff: nanmlTrain batch 18/42 - 183.2ms/batch - loss: nan - diff: nanmlTrain batch 19/42 - 185.5ms/batch - loss: nan - diff: nanmlTrain batch 20/42 - 182.4ms/batch - loss: nan - diff: nanmlTrain batch 21/42 - 205.9ms/batch - loss: nan - diff: nanmlTrain batch 22/42 - 185.0ms/batch - loss: nan - diff: nanmlTrain batch 23/42 - 188.3ms/batch - loss: nan - diff: nanmlTrain batch 24/42 - 183.1ms/batch - loss: nan - diff: nanmlTrain batch 25/42 - 200.0ms/batch - loss: nan - diff: nanmlTrain batch 26/42 - 184.6ms/batch - loss: nan - diff: nanmlTrain batch 27/42 - 186.8ms/batch - loss: nan - diff: nanmlTrain batch 28/42 - 183.2ms/batch - loss: nan - diff: nanmlTrain batch 29/42 - 183.7ms/batch - loss: nan - diff: nanmlTrain batch 30/42 - 183.7ms/batch - loss: nan - diff: nanmlTrain batch 31/42 - 189.6ms/batch - loss: nan - diff: nanmlTrain batch 32/42 - 186.7ms/batch - loss: nan - diff: nanmlTrain batch 33/42 - 182.3ms/batch - loss: nan - diff: nanmlTrain batch 34/42 - 183.3ms/batch - loss: nan - diff: nanmlTrain batch 35/42 - 182.9ms/batch - loss: nan - diff: nanmlTrain batch 36/42 - 183.8ms/batch - loss: nan - diff: nanmlTrain batch 37/42 - 189.1ms/batch - loss: nan - diff: nanmlTrain batch 38/42 - 186.2ms/batch - loss: nan - diff: nanmlTrain batch 39/42 - 185.0ms/batch - loss: nan - diff: nanmlTrain batch 40/42 - 183.5ms/batch - loss: nan - diff: nanmlTrain batch 41/42 - 183.6ms/batch - loss: nan - diff: nanmlTrain batch 42/42 - 128.2ms/batch - loss: nan - diff: nanmlTrain batch 42/42 - 367.3s 128.2ms/batch - loss: nan - diff: nanml
Test 136.8s: val_loss: nan - diff: nanml

Epoch 93: current best loss = 18.65666, at epoch 69
Train batch 1/42 - 185.1ms/batch - loss: nan - diff: nanmlTrain batch 2/42 - 182.5ms/batch - loss: nan - diff: nanmlTrain batch 3/42 - 188.3ms/batch - loss: nan - diff: nanmlTrain batch 4/42 - 183.5ms/batch - loss: nan - diff: nanmlTrain batch 5/42 - 183.5ms/batch - loss: nan - diff: nanmlTrain batch 6/42 - 183.5ms/batch - loss: nan - diff: nanmlTrain batch 7/42 - 184.0ms/batch - loss: nan - diff: nanmlTrain batch 8/42 - 208.0ms/batch - loss: nan - diff: nanmlTrain batch 9/42 - 188.7ms/batch - loss: nan - diff: nanmlTrain batch 10/42 - 189.5ms/batch - loss: nan - diff: nanmlTrain batch 11/42 - 182.9ms/batch - loss: nan - diff: nanmlTrain batch 12/42 - 183.1ms/batch - loss: nan - diff: nanmlTrain batch 13/42 - 184.3ms/batch - loss: nan - diff: nanmlTrain batch 14/42 - 184.3ms/batch - loss: nan - diff: nanmlTrain batch 15/42 - 187.2ms/batch - loss: nan - diff: nanmlTrain batch 16/42 - 184.0ms/batch - loss: nan - diff: nanmlTrain batch 17/42 - 185.5ms/batch - loss: nan - diff: nanmlTrain batch 18/42 - 182.3ms/batch - loss: nan - diff: nanmlTrain batch 19/42 - 186.8ms/batch - loss: nan - diff: nanmlTrain batch 20/42 - 183.6ms/batch - loss: nan - diff: nanmlTrain batch 21/42 - 184.9ms/batch - loss: nan - diff: nanmlTrain batch 22/42 - 183.1ms/batch - loss: nan - diff: nanmlTrain batch 23/42 - 203.2ms/batch - loss: nan - diff: nanmlTrain batch 24/42 - 182.9ms/batch - loss: nan - diff: nanmlTrain batch 25/42 - 191.4ms/batch - loss: nan - diff: nanmlTrain batch 26/42 - 183.1ms/batch - loss: nan - diff: nanmlTrain batch 27/42 - 185.5ms/batch - loss: nan - diff: nanmlTrain batch 28/42 - 182.3ms/batch - loss: nan - diff: nanmlTrain batch 29/42 - 188.4ms/batch - loss: nan - diff: nanmlTrain batch 30/42 - 185.2ms/batch - loss: nan - diff: nanmlTrain batch 31/42 - 183.7ms/batch - loss: nan - diff: nanmlTrain batch 32/42 - 183.0ms/batch - loss: nan - diff: nanmlTrain batch 33/42 - 184.1ms/batch - loss: nan - diff: nanmlTrain batch 34/42 - 183.3ms/batch - loss: nan - diff: nanmlTrain batch 35/42 - 189.5ms/batch - loss: nan - diff: nanmlTrain batch 36/42 - 186.9ms/batch - loss: nan - diff: nanmlTrain batch 37/42 - 183.1ms/batch - loss: nan - diff: nanmlTrain batch 38/42 - 183.8ms/batch - loss: nan - diff: nanmlTrain batch 39/42 - 182.8ms/batch - loss: nan - diff: nanmlTrain batch 40/42 - 184.3ms/batch - loss: nan - diff: nanmlTrain batch 41/42 - 186.5ms/batch - loss: nan - diff: nanmlTrain batch 42/42 - 127.8ms/batch - loss: nan - diff: nanmlTrain batch 42/42 - 364.6s 127.8ms/batch - loss: nan - diff: nanml
Test 136.0s: val_loss: nan - diff: nanml

Epoch 94: current best loss = 18.65666, at epoch 69
Train batch 1/42 - 190.0ms/batch - loss: nan - diff: nanmlTrain batch 2/42 - 183.9ms/batch - loss: nan - diff: nanmlTrain batch 3/42 - 185.2ms/batch - loss: nan - diff: nanmlTrain batch 4/42 - 183.0ms/batch - loss: nan - diff: nanmlTrain batch 5/42 - 203.7ms/batch - loss: nan - diff: nanmlTrain batch 6/42 - 184.6ms/batch - loss: nan - diff: nanmlTrain batch 7/42 - 187.9ms/batch - loss: nan - diff: nanmlTrain batch 8/42 - 182.9ms/batch - loss: nan - diff: nanmlTrain batch 9/42 - 182.8ms/batch - loss: nan - diff: nanmlTrain batch 10/42 - 182.8ms/batch - loss: nan - diff: nanmlTrain batch 11/42 - 188.0ms/batch - loss: nan - diff: nanmlTrain batch 12/42 - 185.4ms/batch - loss: nan - diff: nanmlTrain batch 13/42 - 183.6ms/batch - loss: nan - diff: nanmlTrain batch 14/42 - 182.2ms/batch - loss: nan - diff: nanmlTrain batch 15/42 - 183.5ms/batch - loss: nan - diff: nanmlTrain batch 16/42 - 182.3ms/batch - loss: nan - diff: nanmlTrain batch 17/42 - 201.5ms/batch - loss: nan - diff: nanmlTrain batch 18/42 - 183.6ms/batch - loss: nan - diff: nanmlTrain batch 19/42 - 185.0ms/batch - loss: nan - diff: nanmlTrain batch 20/42 - 182.4ms/batch - loss: nan - diff: nanmlTrain batch 21/42 - 206.3ms/batch - loss: nan - diff: nanmlTrain batch 22/42 - 185.1ms/batch - loss: nan - diff: nanmlTrain batch 23/42 - 185.1ms/batch - loss: nan - diff: nanmlTrain batch 24/42 - 182.9ms/batch - loss: nan - diff: nanmlTrain batch 25/42 - 200.5ms/batch - loss: nan - diff: nanmlTrain batch 26/42 - 184.5ms/batch - loss: nan - diff: nanmlTrain batch 27/42 - 186.2ms/batch - loss: nan - diff: nanmlTrain batch 28/42 - 184.2ms/batch - loss: nan - diff: nanmlTrain batch 29/42 - 192.6ms/batch - loss: nan - diff: nanmlTrain batch 30/42 - 183.3ms/batch - loss: nan - diff: nanmlTrain batch 31/42 - 186.9ms/batch - loss: nan - diff: nanmlTrain batch 32/42 - 183.6ms/batch - loss: nan - diff: nanmlTrain batch 33/42 - 183.6ms/batch - loss: nan - diff: nanmlTrain batch 34/42 - 182.4ms/batch - loss: nan - diff: nanmlTrain batch 35/42 - 183.6ms/batch - loss: nan - diff: nanmlTrain batch 36/42 - 183.5ms/batch - loss: nan - diff: nanmlTrain batch 37/42 - 188.6ms/batch - loss: nan - diff: nanmlTrain batch 38/42 - 183.8ms/batch - loss: nan - diff: nanmlTrain batch 39/42 - 182.3ms/batch - loss: nan - diff: nanmlTrain batch 40/42 - 182.7ms/batch - loss: nan - diff: nanmlTrain batch 41/42 - 183.4ms/batch - loss: nan - diff: nanmlTrain batch 42/42 - 129.0ms/batch - loss: nan - diff: nanmlTrain batch 42/42 - 369.3s 129.0ms/batch - loss: nan - diff: nanml
Test 139.3s: val_loss: nan - diff: nanml

Epoch 95: current best loss = 18.65666, at epoch 69
Train batch 1/42 - 192.0ms/batch - loss: nan - diff: nanmlTrain batch 2/42 - 185.4ms/batch - loss: nan - diff: nanmlTrain batch 3/42 - 182.7ms/batch - loss: nan - diff: nanmlTrain batch 4/42 - 184.1ms/batch - loss: nan - diff: nanmlTrain batch 5/42 - 183.0ms/batch - loss: nan - diff: nanmlTrain batch 6/42 - 183.6ms/batch - loss: nan - diff: nanmlTrain batch 7/42 - 183.5ms/batch - loss: nan - diff: nanmlTrain batch 8/42 - 184.2ms/batch - loss: nan - diff: nanmlTrain batch 9/42 - 188.8ms/batch - loss: nan - diff: nanmlTrain batch 10/42 - 184.8ms/batch - loss: nan - diff: nanmlTrain batch 11/42 - 184.8ms/batch - loss: nan - diff: nanmlTrain batch 12/42 - 185.2ms/batch - loss: nan - diff: nanmlTrain batch 13/42 - 187.7ms/batch - loss: nan - diff: nanmlTrain batch 14/42 - 200.2ms/batch - loss: nan - diff: nanmlTrain batch 15/42 - 202.5ms/batch - loss: nan - diff: nanmlTrain batch 16/42 - 184.9ms/batch - loss: nan - diff: nanmlTrain batch 17/42 - 187.8ms/batch - loss: nan - diff: nanmlTrain batch 18/42 - 183.9ms/batch - loss: nan - diff: nanmlTrain batch 19/42 - 213.3ms/batch - loss: nan - diff: nanmlTrain batch 20/42 - 185.1ms/batch - loss: nan - diff: nanmlTrain batch 21/42 - 186.1ms/batch - loss: nan - diff: nanmlTrain batch 22/42 - 196.4ms/batch - loss: nan - diff: nanmlTrain batch 23/42 - 200.6ms/batch - loss: nan - diff: nanmlTrain batch 24/42 - 183.5ms/batch - loss: nan - diff: nanmlTrain batch 25/42 - 185.6ms/batch - loss: nan - diff: nanmlTrain batch 26/42 - 183.3ms/batch - loss: nan - diff: nanmlTrain batch 27/42 - 183.5ms/batch - loss: nan - diff: nanmlTrain batch 28/42 - 182.7ms/batch - loss: nan - diff: nanmlTrain batch 29/42 - 189.8ms/batch - loss: nan - diff: nanmlTrain batch 30/42 - 185.0ms/batch - loss: nan - diff: nanmlTrain batch 31/42 - 182.6ms/batch - loss: nan - diff: nanmlTrain batch 32/42 - 182.4ms/batch - loss: nan - diff: nanmlTrain batch 33/42 - 184.0ms/batch - loss: nan - diff: nanmlTrain batch 34/42 - 184.5ms/batch - loss: nan - diff: nanmlTrain batch 35/42 - 190.6ms/batch - loss: nan - diff: nanmlTrain batch 36/42 - 184.4ms/batch - loss: nan - diff: nanmlTrain batch 37/42 - 182.7ms/batch - loss: nan - diff: nanmlTrain batch 38/42 - 183.3ms/batch - loss: nan - diff: nanmlTrain batch 39/42 - 182.6ms/batch - loss: nan - diff: nanmlTrain batch 40/42 - 182.9ms/batch - loss: nan - diff: nanmlTrain batch 41/42 - 188.1ms/batch - loss: nan - diff: nanmlTrain batch 42/42 - 129.2ms/batch - loss: nan - diff: nanmlTrain batch 42/42 - 367.6s 129.2ms/batch - loss: nan - diff: nanml
Test 139.4s: val_loss: nan - diff: nanml

Epoch 96: current best loss = 18.65666, at epoch 69
Train batch 1/42 - 189.8ms/batch - loss: nan - diff: nanmlTrain batch 2/42 - 185.0ms/batch - loss: nan - diff: nanmlTrain batch 3/42 - 183.1ms/batch - loss: nan - diff: nanmlTrain batch 4/42 - 182.7ms/batch - loss: nan - diff: nanmlTrain batch 5/42 - 183.9ms/batch - loss: nan - diff: nanmlTrain batch 6/42 - 183.4ms/batch - loss: nan - diff: nanmlTrain batch 7/42 - 188.9ms/batch - loss: nan - diff: nanmlTrain batch 8/42 - 185.1ms/batch - loss: nan - diff: nanmlTrain batch 9/42 - 183.1ms/batch - loss: nan - diff: nanmlTrain batch 10/42 - 183.2ms/batch - loss: nan - diff: nanmlTrain batch 11/42 - 184.9ms/batch - loss: nan - diff: nanmlTrain batch 12/42 - 185.2ms/batch - loss: nan - diff: nanmlTrain batch 13/42 - 186.7ms/batch - loss: nan - diff: nanmlTrain batch 14/42 - 183.6ms/batch - loss: nan - diff: nanmlTrain batch 15/42 - 185.4ms/batch - loss: nan - diff: nanmlTrain batch 16/42 - 182.1ms/batch - loss: nan - diff: nanmlTrain batch 17/42 - 200.0ms/batch - loss: nan - diff: nanmlTrain batch 18/42 - 182.6ms/batch - loss: nan - diff: nanmlTrain batch 19/42 - 185.1ms/batch - loss: nan - diff: nanmlTrain batch 20/42 - 182.9ms/batch - loss: nan - diff: nanmlTrain batch 21/42 - 190.6ms/batch - loss: nan - diff: nanmlTrain batch 22/42 - 182.8ms/batch - loss: nan - diff: nanmlTrain batch 23/42 - 186.9ms/batch - loss: nan - diff: nanmlTrain batch 24/42 - 182.5ms/batch - loss: nan - diff: nanmlTrain batch 25/42 - 188.4ms/batch - loss: nan - diff: nanmlTrain batch 26/42 - 184.5ms/batch - loss: nan - diff: nanmlTrain batch 27/42 - 183.5ms/batch - loss: nan - diff: nanmlTrain batch 28/42 - 185.6ms/batch - loss: nan - diff: nanmlTrain batch 29/42 - 183.7ms/batch - loss: nan - diff: nanmlTrain batch 30/42 - 182.9ms/batch - loss: nan - diff: nanmlTrain batch 31/42 - 188.5ms/batch - loss: nan - diff: nanmlTrain batch 32/42 - 184.5ms/batch - loss: nan - diff: nanmlTrain batch 33/42 - 182.6ms/batch - loss: nan - diff: nanmlTrain batch 34/42 - 182.5ms/batch - loss: nan - diff: nanmlTrain batch 35/42 - 184.6ms/batch - loss: nan - diff: nanmlTrain batch 36/42 - 183.6ms/batch - loss: nan - diff: nanmlTrain batch 37/42 - 188.8ms/batch - loss: nan - diff: nanmlTrain batch 38/42 - 184.7ms/batch - loss: nan - diff: nanmlTrain batch 39/42 - 183.6ms/batch - loss: nan - diff: nanmlTrain batch 40/42 - 183.4ms/batch - loss: nan - diff: nanmlTrain batch 41/42 - 183.3ms/batch - loss: nan - diff: nanmlTrain batch 42/42 - 128.4ms/batch - loss: nan - diff: nanmlTrain batch 42/42 - 364.0s 128.4ms/batch - loss: nan - diff: nanml
Test 139.6s: val_loss: nan - diff: nanml

Epoch 97: current best loss = 18.65666, at epoch 69
Train batch 1/42 - 183.1ms/batch - loss: nan - diff: nanmlTrain batch 2/42 - 183.9ms/batch - loss: nan - diff: nanmlTrain batch 3/42 - 186.3ms/batch - loss: nan - diff: nanmlTrain batch 4/42 - 183.1ms/batch - loss: nan - diff: nanmlTrain batch 5/42 - 183.0ms/batch - loss: nan - diff: nanmlTrain batch 6/42 - 183.2ms/batch - loss: nan - diff: nanmlTrain batch 7/42 - 183.5ms/batch - loss: nan - diff: nanmlTrain batch 8/42 - 185.5ms/batch - loss: nan - diff: nanmlTrain batch 9/42 - 187.9ms/batch - loss: nan - diff: nanmlTrain batch 10/42 - 185.8ms/batch - loss: nan - diff: nanmlTrain batch 11/42 - 182.6ms/batch - loss: nan - diff: nanmlTrain batch 12/42 - 183.3ms/batch - loss: nan - diff: nanmlTrain batch 13/42 - 183.6ms/batch - loss: nan - diff: nanmlTrain batch 14/42 - 183.1ms/batch - loss: nan - diff: nanmlTrain batch 15/42 - 198.8ms/batch - loss: nan - diff: nanmlTrain batch 16/42 - 184.4ms/batch - loss: nan - diff: nanmlTrain batch 17/42 - 184.8ms/batch - loss: nan - diff: nanmlTrain batch 18/42 - 182.9ms/batch - loss: nan - diff: nanmlTrain batch 19/42 - 200.0ms/batch - loss: nan - diff: nanmlTrain batch 20/42 - 184.7ms/batch - loss: nan - diff: nanmlTrain batch 21/42 - 190.7ms/batch - loss: nan - diff: nanmlTrain batch 22/42 - 198.9ms/batch - loss: nan - diff: nanmlTrain batch 23/42 - 207.1ms/batch - loss: nan - diff: nanmlTrain batch 24/42 - 185.5ms/batch - loss: nan - diff: nanmlTrain batch 25/42 - 185.5ms/batch - loss: nan - diff: nanmlTrain batch 26/42 - 182.8ms/batch - loss: nan - diff: nanmlTrain batch 27/42 - 183.1ms/batch - loss: nan - diff: nanmlTrain batch 28/42 - 183.4ms/batch - loss: nan - diff: nanmlTrain batch 29/42 - 189.4ms/batch - loss: nan - diff: nanmlTrain batch 30/42 - 184.4ms/batch - loss: nan - diff: nanmlTrain batch 31/42 - 183.7ms/batch - loss: nan - diff: nanmlTrain batch 32/42 - 182.9ms/batch - loss: nan - diff: nanmlTrain batch 33/42 - 183.8ms/batch - loss: nan - diff: nanmlTrain batch 34/42 - 190.4ms/batch - loss: nan - diff: nanmlTrain batch 35/42 - 188.3ms/batch - loss: nan - diff: nanmlTrain batch 36/42 - 184.4ms/batch - loss: nan - diff: nanmlTrain batch 37/42 - 183.9ms/batch - loss: nan - diff: nanmlTrain batch 38/42 - 189.8ms/batch - loss: nan - diff: nanmlTrain batch 39/42 - 197.8ms/batch - loss: nan - diff: nanmlTrain batch 40/42 - 197.6ms/batch - loss: nan - diff: nanmlTrain batch 41/42 - 194.3ms/batch - loss: nan - diff: nanmlTrain batch 42/42 - 131.1ms/batch - loss: nan - diff: nanmlTrain batch 42/42 - 366.3s 131.1ms/batch - loss: nan - diff: nanml
Test 137.3s: val_loss: nan - diff: nanml

Epoch 98: current best loss = 18.65666, at epoch 69
Train batch 1/42 - 187.5ms/batch - loss: nan - diff: nanmlTrain batch 2/42 - 183.5ms/batch - loss: nan - diff: nanmlTrain batch 3/42 - 199.5ms/batch - loss: nan - diff: nanmlTrain batch 4/42 - 183.1ms/batch - loss: nan - diff: nanmlTrain batch 5/42 - 184.6ms/batch - loss: nan - diff: nanmlTrain batch 6/42 - 183.4ms/batch - loss: nan - diff: nanmlTrain batch 7/42 - 188.5ms/batch - loss: nan - diff: nanmlTrain batch 8/42 - 184.4ms/batch - loss: nan - diff: nanmlTrain batch 9/42 - 182.8ms/batch - loss: nan - diff: nanmlTrain batch 10/42 - 184.5ms/batch - loss: nan - diff: nanmlTrain batch 11/42 - 184.3ms/batch - loss: nan - diff: nanmlTrain batch 12/42 - 184.0ms/batch - loss: nan - diff: nanmlTrain batch 13/42 - 186.5ms/batch - loss: nan - diff: nanmlTrain batch 14/42 - 182.2ms/batch - loss: nan - diff: nanmlTrain batch 15/42 - 185.0ms/batch - loss: nan - diff: nanmlTrain batch 16/42 - 182.2ms/batch - loss: nan - diff: nanmlTrain batch 17/42 - 191.1ms/batch - loss: nan - diff: nanmlTrain batch 18/42 - 183.1ms/batch - loss: nan - diff: nanmlTrain batch 19/42 - 185.9ms/batch - loss: nan - diff: nanmlTrain batch 20/42 - 182.6ms/batch - loss: nan - diff: nanmlTrain batch 21/42 - 191.1ms/batch - loss: nan - diff: nanmlTrain batch 22/42 - 183.9ms/batch - loss: nan - diff: nanmlTrain batch 23/42 - 187.6ms/batch - loss: nan - diff: nanmlTrain batch 24/42 - 182.3ms/batch - loss: nan - diff: nanmlTrain batch 25/42 - 187.8ms/batch - loss: nan - diff: nanmlTrain batch 26/42 - 185.2ms/batch - loss: nan - diff: nanmlTrain batch 27/42 - 184.4ms/batch - loss: nan - diff: nanmlTrain batch 28/42 - 183.4ms/batch - loss: nan - diff: nanmlTrain batch 29/42 - 183.4ms/batch - loss: nan - diff: nanmlTrain batch 30/42 - 183.2ms/batch - loss: nan - diff: nanmlTrain batch 31/42 - 189.0ms/batch - loss: nan - diff: nanmlTrain batch 32/42 - 184.1ms/batch - loss: nan - diff: nanmlTrain batch 33/42 - 183.2ms/batch - loss: nan - diff: nanmlTrain batch 34/42 - 184.9ms/batch - loss: nan - diff: nanmlTrain batch 35/42 - 182.9ms/batch - loss: nan - diff: nanmlTrain batch 36/42 - 183.3ms/batch - loss: nan - diff: nanmlTrain batch 37/42 - 188.0ms/batch - loss: nan - diff: nanmlTrain batch 38/42 - 184.7ms/batch - loss: nan - diff: nanmlTrain batch 39/42 - 184.8ms/batch - loss: nan - diff: nanmlTrain batch 40/42 - 182.6ms/batch - loss: nan - diff: nanmlTrain batch 41/42 - 182.9ms/batch - loss: nan - diff: nanmlTrain batch 42/42 - 128.4ms/batch - loss: nan - diff: nanmlTrain batch 42/42 - 368.2s 128.4ms/batch - loss: nan - diff: nanml
Test 138.2s: val_loss: nan - diff: nanml

Epoch 99: current best loss = 18.65666, at epoch 69
Train batch 1/42 - 189.9ms/batch - loss: nan - diff: nanmlTrain batch 2/42 - 184.3ms/batch - loss: nan - diff: nanmlTrain batch 3/42 - 200.6ms/batch - loss: nan - diff: nanmlTrain batch 4/42 - 183.5ms/batch - loss: nan - diff: nanmlTrain batch 5/42 - 185.1ms/batch - loss: nan - diff: nanmlTrain batch 6/42 - 186.2ms/batch - loss: nan - diff: nanmlTrain batch 7/42 - 194.0ms/batch - loss: nan - diff: nanmlTrain batch 8/42 - 184.3ms/batch - loss: nan - diff: nanmlTrain batch 9/42 - 183.1ms/batch - loss: nan - diff: nanmlTrain batch 10/42 - 183.0ms/batch - loss: nan - diff: nanmlTrain batch 11/42 - 183.0ms/batch - loss: nan - diff: nanmlTrain batch 12/42 - 182.9ms/batch - loss: nan - diff: nanmlTrain batch 13/42 - 182.3ms/batch - loss: nan - diff: nanmlTrain batch 14/42 - 184.4ms/batch - loss: nan - diff: nanmlTrain batch 15/42 - 187.8ms/batch - loss: nan - diff: nanmlTrain batch 16/42 - 184.8ms/batch - loss: nan - diff: nanmlTrain batch 17/42 - 185.9ms/batch - loss: nan - diff: nanmlTrain batch 18/42 - 182.9ms/batch - loss: nan - diff: nanmlTrain batch 19/42 - 198.9ms/batch - loss: nan - diff: nanmlTrain batch 20/42 - 182.2ms/batch - loss: nan - diff: nanmlTrain batch 21/42 - 185.7ms/batch - loss: nan - diff: nanmlTrain batch 22/42 - 182.9ms/batch - loss: nan - diff: nanmlTrain batch 23/42 - 191.0ms/batch - loss: nan - diff: nanmlTrain batch 24/42 - 184.2ms/batch - loss: nan - diff: nanmlTrain batch 25/42 - 192.8ms/batch - loss: nan - diff: nanmlTrain batch 26/42 - 182.8ms/batch - loss: nan - diff: nanmlTrain batch 27/42 - 188.8ms/batch - loss: nan - diff: nanmlTrain batch 28/42 - 184.7ms/batch - loss: nan - diff: nanmlTrain batch 29/42 - 186.4ms/batch - loss: nan - diff: nanmlTrain batch 30/42 - 183.1ms/batch - loss: nan - diff: nanmlTrain batch 31/42 - 183.3ms/batch - loss: nan - diff: nanmlTrain batch 32/42 - 183.8ms/batch - loss: nan - diff: nanmlTrain batch 33/42 - 188.1ms/batch - loss: nan - diff: nanmlTrain batch 34/42 - 184.7ms/batch - loss: nan - diff: nanmlTrain batch 35/42 - 183.2ms/batch - loss: nan - diff: nanmlTrain batch 36/42 - 184.2ms/batch - loss: nan - diff: nanmlTrain batch 37/42 - 183.7ms/batch - loss: nan - diff: nanmlTrain batch 38/42 - 182.3ms/batch - loss: nan - diff: nanmlTrain batch 39/42 - 188.6ms/batch - loss: nan - diff: nanmlTrain batch 40/42 - 184.3ms/batch - loss: nan - diff: nanmlTrain batch 41/42 - 182.9ms/batch - loss: nan - diff: nanmlTrain batch 42/42 - 128.5ms/batch - loss: nan - diff: nanmlTrain batch 42/42 - 369.6s 128.5ms/batch - loss: nan - diff: nanml
Test 139.1s: val_loss: nan - diff: nanml

