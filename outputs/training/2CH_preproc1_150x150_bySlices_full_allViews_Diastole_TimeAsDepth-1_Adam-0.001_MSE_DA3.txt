nohup: ignoring input
Running experiment 2CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_TimeAsDepth_1_Adam-0.001_MSE_DA3
Going to train with the GPU in the slot 1 -> device model: GeForce RTX 2080
Model architecture:
 TimeAsDepth_1(
  (conv_block): Sequential(
    (0): Conv2d(30, 64, kernel_size=(3, 3), stride=(2, 2))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))
    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU()
    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (7): Dropout(p=0.4, inplace=False)
    (8): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))
    (9): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): ReLU()
    (11): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))
    (12): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (13): ReLU()
    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (15): Dropout(p=0.4, inplace=False)
    (16): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))
    (17): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): ReLU()
    (19): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))
    (20): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (21): ReLU()
    (22): Dropout(p=0.4, inplace=False)
    (23): AdaptiveAvgPool2d(output_size=(1, 1))
  )
  (flatten): Flatten()
  (dense_block): Sequential(
    (0): Linear(in_features=256, out_features=1024, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.4, inplace=False)
    (3): Linear(in_features=1024, out_features=1, bias=True)
  )
) 


############################
# TRAIN PHASE:  100 epochs #
############################

Epoch 0: 
Train batch 1/4 - 125.6ms/batch - loss: 242.47162 - diff: 167.50mlTrain batch 2/4 - 116.8ms/batch - loss: 233.92276 - diff: 164.28mlTrain batch 3/4 - 119.5ms/batch - loss: 235.53764 - diff: 163.90mlTrain batch 4/4 - 104.9ms/batch - loss: 244.68544 - diff: 164.46mlTrain batch 4/4 - 12.5s 104.9ms/batch - loss: 244.68544 - diff: 164.46ml
Test 0.6s: val_loss: 280.11221 - diff: 157.19ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_TimeAsDepth_1_Adam-0.001_MSE_DA3_best

Epoch 1: current best loss = 280.11221, at epoch 0
Train batch 1/4 - 120.6ms/batch - loss: 212.70296 - diff: 157.50mlTrain batch 2/4 - 112.7ms/batch - loss: 224.71273 - diff: 160.39mlTrain batch 3/4 - 119.4ms/batch - loss: 223.95561 - diff: 160.33mlTrain batch 4/4 - 111.7ms/batch - loss: 233.05234 - diff: 160.08mlTrain batch 4/4 - 10.6s 111.7ms/batch - loss: 233.05234 - diff: 160.08ml
Test 0.6s: val_loss: 257.62278 - diff: 148.44ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_TimeAsDepth_1_Adam-0.001_MSE_DA3_best

Epoch 2: current best loss = 257.62278, at epoch 1
Train batch 1/4 - 119.0ms/batch - loss: 207.49770 - diff: 155.65mlTrain batch 2/4 - 112.6ms/batch - loss: 213.70154 - diff: 156.42mlTrain batch 3/4 - 119.5ms/batch - loss: 204.52559 - diff: 152.50mlTrain batch 4/4 - 111.7ms/batch - loss: 217.10189 - diff: 153.92mlTrain batch 4/4 - 10.6s 111.7ms/batch - loss: 217.10189 - diff: 153.92ml
Test 0.6s: val_loss: 245.33782 - diff: 146.75ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_TimeAsDepth_1_Adam-0.001_MSE_DA3_best

Epoch 3: current best loss = 245.33782, at epoch 2
Train batch 1/4 - 120.4ms/batch - loss: 228.94257 - diff: 158.51mlTrain batch 2/4 - 116.8ms/batch - loss: 205.64455 - diff: 150.34mlTrain batch 3/4 - 119.3ms/batch - loss: 198.68795 - diff: 148.15mlTrain batch 4/4 - 107.1ms/batch - loss: 194.55814 - diff: 145.42mlTrain batch 4/4 - 10.7s 107.1ms/batch - loss: 194.55814 - diff: 145.42ml
Test 0.6s: val_loss: 224.47316 - diff: 137.49ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_TimeAsDepth_1_Adam-0.001_MSE_DA3_best

Epoch 4: current best loss = 224.47316, at epoch 3
Train batch 1/4 - 120.6ms/batch - loss: 162.69852 - diff: 131.34mlTrain batch 2/4 - 120.2ms/batch - loss: 171.86441 - diff: 136.50mlTrain batch 3/4 - 119.3ms/batch - loss: 167.82826 - diff: 135.91mlTrain batch 4/4 - 107.0ms/batch - loss: 167.73203 - diff: 134.60mlTrain batch 4/4 - 10.6s 107.0ms/batch - loss: 167.73203 - diff: 134.60ml
Test 0.6s: val_loss: 95.80997 - diff: 84.31ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_TimeAsDepth_1_Adam-0.001_MSE_DA3_best

Epoch 5: current best loss = 95.80997, at epoch 4
Train batch 1/4 - 120.3ms/batch - loss: 156.27524 - diff: 127.80mlTrain batch 2/4 - 115.5ms/batch - loss: 143.78944 - diff: 123.96mlTrain batch 3/4 - 119.5ms/batch - loss: 140.39836 - diff: 122.47mlTrain batch 4/4 - 106.0ms/batch - loss: 138.38950 - diff: 120.80mlTrain batch 4/4 - 10.6s 106.0ms/batch - loss: 138.38950 - diff: 120.80ml
Test 0.6s: val_loss: 83.97520 - diff: 81.02ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_TimeAsDepth_1_Adam-0.001_MSE_DA3_best

Epoch 6: current best loss = 83.97520, at epoch 5
Train batch 1/4 - 120.7ms/batch - loss: 109.38358 - diff: 106.72mlTrain batch 2/4 - 120.1ms/batch - loss: 109.44009 - diff: 106.68mlTrain batch 3/4 - 119.4ms/batch - loss: 105.94020 - diff: 104.97mlTrain batch 4/4 - 111.7ms/batch - loss: 104.83638 - diff: 103.32mlTrain batch 4/4 - 10.5s 111.7ms/batch - loss: 104.83638 - diff: 103.32ml
Test 0.6s: val_loss: 236.98058 - diff: 141.82ml

Epoch 7: current best loss = 83.97520, at epoch 5
Train batch 1/4 - 118.1ms/batch - loss: 91.58493 - diff: 92.19mlTrain batch 2/4 - 114.4ms/batch - loss: 85.98511 - diff: 91.98mlTrain batch 3/4 - 119.4ms/batch - loss: 77.93907 - diff: 86.76mlTrain batch 4/4 - 108.8ms/batch - loss: 73.81734 - diff: 83.29mlTrain batch 4/4 - 10.7s 108.8ms/batch - loss: 73.81734 - diff: 83.29ml
Test 0.6s: val_loss: 141.49789 - diff: 108.77ml

Epoch 8: current best loss = 83.97520, at epoch 5
Train batch 1/4 - 120.3ms/batch - loss: 58.01210 - diff: 68.95mlTrain batch 2/4 - 118.7ms/batch - loss: 52.49028 - diff: 66.26mlTrain batch 3/4 - 119.3ms/batch - loss: 49.71766 - diff: 64.76mlTrain batch 4/4 - 109.1ms/batch - loss: 47.44991 - diff: 62.89mlTrain batch 4/4 - 10.6s 109.1ms/batch - loss: 47.44991 - diff: 62.89ml
Test 0.6s: val_loss: 70.32184 - diff: 73.40ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_TimeAsDepth_1_Adam-0.001_MSE_DA3_best

Epoch 9: current best loss = 70.32184, at epoch 8
Train batch 1/4 - 120.2ms/batch - loss: 26.45926 - diff: 45.81mlTrain batch 2/4 - 116.2ms/batch - loss: 28.68649 - diff: 45.83mlTrain batch 3/4 - 119.3ms/batch - loss: 26.17248 - diff: 43.93mlTrain batch 4/4 - 106.8ms/batch - loss: 26.13013 - diff: 42.77mlTrain batch 4/4 - 10.6s 106.8ms/batch - loss: 26.13013 - diff: 42.77ml
Test 0.6s: val_loss: 22.58695 - diff: 41.17ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_TimeAsDepth_1_Adam-0.001_MSE_DA3_best

Epoch 10: current best loss = 22.58695, at epoch 9
Train batch 1/4 - 120.5ms/batch - loss: 11.95116 - diff: 29.95mlTrain batch 2/4 - 113.7ms/batch - loss: 13.14824 - diff: 30.35mlTrain batch 3/4 - 119.5ms/batch - loss: 14.49216 - diff: 31.75mlTrain batch 4/4 - 104.6ms/batch - loss: 16.56273 - diff: 32.71mlTrain batch 4/4 - 10.6s 104.6ms/batch - loss: 16.56273 - diff: 32.71ml
Test 0.6s: val_loss: 155.71989 - diff: 114.09ml

Epoch 11: current best loss = 22.58695, at epoch 9
Train batch 1/4 - 120.3ms/batch - loss: 14.68333 - diff: 33.72mlTrain batch 2/4 - 112.8ms/batch - loss: 13.07163 - diff: 31.81mlTrain batch 3/4 - 119.4ms/batch - loss: 14.32799 - diff: 32.37mlTrain batch 4/4 - 104.8ms/batch - loss: 15.00252 - diff: 32.60mlTrain batch 4/4 - 10.7s 104.8ms/batch - loss: 15.00252 - diff: 32.60ml
Test 0.6s: val_loss: 35.35352 - diff: 48.27ml

Epoch 12: current best loss = 22.58695, at epoch 9
Train batch 1/4 - 120.5ms/batch - loss: 15.49858 - diff: 33.90mlTrain batch 2/4 - 113.0ms/batch - loss: 16.29687 - diff: 36.07mlTrain batch 3/4 - 119.4ms/batch - loss: 16.80275 - diff: 35.77mlTrain batch 4/4 - 112.0ms/batch - loss: 16.93887 - diff: 35.87mlTrain batch 4/4 - 10.7s 112.0ms/batch - loss: 16.93887 - diff: 35.87ml
Test 0.6s: val_loss: 58.97116 - diff: 66.27ml

Epoch 13: current best loss = 22.58695, at epoch 9
Train batch 1/4 - 120.5ms/batch - loss: 15.37416 - diff: 29.76mlTrain batch 2/4 - 120.5ms/batch - loss: 17.87046 - diff: 34.34mlTrain batch 3/4 - 119.4ms/batch - loss: 17.09556 - diff: 33.84mlTrain batch 4/4 - 111.6ms/batch - loss: 17.09272 - diff: 34.13mlTrain batch 4/4 - 10.7s 111.6ms/batch - loss: 17.09272 - diff: 34.13ml
Test 0.6s: val_loss: 65.70868 - diff: 71.61ml

Epoch 14: current best loss = 22.58695, at epoch 9
Train batch 1/4 - 120.5ms/batch - loss: 17.27018 - diff: 35.33mlTrain batch 2/4 - 112.8ms/batch - loss: 15.02588 - diff: 33.44mlTrain batch 3/4 - 119.4ms/batch - loss: 15.39981 - diff: 32.51mlTrain batch 4/4 - 111.6ms/batch - loss: 15.36646 - diff: 32.42mlTrain batch 4/4 - 10.6s 111.6ms/batch - loss: 15.36646 - diff: 32.42ml
Test 0.6s: val_loss: 13.49524 - diff: 29.75ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_TimeAsDepth_1_Adam-0.001_MSE_DA3_best

Epoch 15: current best loss = 13.49524, at epoch 14
Train batch 1/4 - 119.5ms/batch - loss: 14.14739 - diff: 32.69mlTrain batch 2/4 - 112.8ms/batch - loss: 11.73858 - diff: 29.48mlTrain batch 3/4 - 119.5ms/batch - loss: 12.25959 - diff: 29.09mlTrain batch 4/4 - 111.7ms/batch - loss: 13.38391 - diff: 29.59mlTrain batch 4/4 - 10.6s 111.7ms/batch - loss: 13.38391 - diff: 29.59ml
Test 0.6s: val_loss: 14.72235 - diff: 31.71ml

Epoch 16: current best loss = 13.49524, at epoch 14
Train batch 1/4 - 120.0ms/batch - loss: 13.72750 - diff: 30.26mlTrain batch 2/4 - 119.6ms/batch - loss: 13.51747 - diff: 29.29mlTrain batch 3/4 - 119.3ms/batch - loss: 12.56463 - diff: 28.85mlTrain batch 4/4 - 111.6ms/batch - loss: 12.12757 - diff: 28.23mlTrain batch 4/4 - 10.6s 111.6ms/batch - loss: 12.12757 - diff: 28.23ml
Test 0.6s: val_loss: 34.09831 - diff: 46.46ml

Epoch 17: current best loss = 13.49524, at epoch 14
Train batch 1/4 - 120.4ms/batch - loss: 9.77051 - diff: 27.65mlTrain batch 2/4 - 120.2ms/batch - loss: 10.59956 - diff: 26.26mlTrain batch 3/4 - 119.2ms/batch - loss: 11.36105 - diff: 27.06mlTrain batch 4/4 - 110.4ms/batch - loss: 12.36380 - diff: 28.55mlTrain batch 4/4 - 10.7s 110.4ms/batch - loss: 12.36380 - diff: 28.55ml
Test 0.6s: val_loss: 15.34326 - diff: 29.00ml

Epoch 18: current best loss = 13.49524, at epoch 14
Train batch 1/4 - 120.3ms/batch - loss: 10.79286 - diff: 24.39mlTrain batch 2/4 - 117.7ms/batch - loss: 9.94537 - diff: 25.54mlTrain batch 3/4 - 119.2ms/batch - loss: 12.05908 - diff: 27.08mlTrain batch 4/4 - 111.6ms/batch - loss: 12.03312 - diff: 27.29mlTrain batch 4/4 - 10.6s 111.6ms/batch - loss: 12.03312 - diff: 27.29ml
Test 0.6s: val_loss: 36.76718 - diff: 48.64ml

Epoch 19: current best loss = 13.49524, at epoch 14
Train batch 1/4 - 120.3ms/batch - loss: 7.55222 - diff: 23.95mlTrain batch 2/4 - 113.0ms/batch - loss: 11.08795 - diff: 26.25mlTrain batch 3/4 - 119.4ms/batch - loss: 12.34396 - diff: 28.28mlTrain batch 4/4 - 111.9ms/batch - loss: 11.87711 - diff: 27.89mlTrain batch 4/4 - 10.6s 111.9ms/batch - loss: 11.87711 - diff: 27.89ml
Test 0.6s: val_loss: 14.71812 - diff: 29.12ml

Epoch 20: current best loss = 13.49524, at epoch 14
Train batch 1/4 - 118.7ms/batch - loss: 18.19350 - diff: 30.51mlTrain batch 2/4 - 112.9ms/batch - loss: 13.19958 - diff: 27.55mlTrain batch 3/4 - 117.9ms/batch - loss: 12.26981 - diff: 27.49mlTrain batch 4/4 - 107.8ms/batch - loss: 11.94448 - diff: 27.24mlTrain batch 4/4 - 10.6s 107.8ms/batch - loss: 11.94448 - diff: 27.24ml
Test 0.6s: val_loss: 13.20351 - diff: 27.40ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_TimeAsDepth_1_Adam-0.001_MSE_DA3_best

Epoch 21: current best loss = 13.20351, at epoch 20
Train batch 1/4 - 120.3ms/batch - loss: 6.93374 - diff: 22.22mlTrain batch 2/4 - 113.7ms/batch - loss: 8.33894 - diff: 24.19mlTrain batch 3/4 - 119.3ms/batch - loss: 11.19898 - diff: 26.95mlTrain batch 4/4 - 111.8ms/batch - loss: 11.84650 - diff: 27.54mlTrain batch 4/4 - 10.6s 111.8ms/batch - loss: 11.84650 - diff: 27.54ml
Test 0.6s: val_loss: 18.92491 - diff: 32.95ml

Epoch 22: current best loss = 13.20351, at epoch 20
Train batch 1/4 - 120.2ms/batch - loss: 9.31298 - diff: 27.34mlTrain batch 2/4 - 114.9ms/batch - loss: 9.07403 - diff: 26.44mlTrain batch 3/4 - 119.1ms/batch - loss: 8.90141 - diff: 25.74mlTrain batch 4/4 - 111.3ms/batch - loss: 11.41159 - diff: 27.26mlTrain batch 4/4 - 10.6s 111.3ms/batch - loss: 11.41159 - diff: 27.26ml
Test 0.6s: val_loss: 19.58106 - diff: 34.48ml

Epoch 23: current best loss = 13.20351, at epoch 20
Train batch 1/4 - 118.6ms/batch - loss: 11.83503 - diff: 26.88mlTrain batch 2/4 - 112.7ms/batch - loss: 10.61646 - diff: 26.58mlTrain batch 3/4 - 119.5ms/batch - loss: 10.30040 - diff: 26.81mlTrain batch 4/4 - 111.9ms/batch - loss: 10.34453 - diff: 26.67mlTrain batch 4/4 - 10.7s 111.9ms/batch - loss: 10.34453 - diff: 26.67ml
Test 0.6s: val_loss: 12.29969 - diff: 27.21ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_TimeAsDepth_1_Adam-0.001_MSE_DA3_best

Epoch 24: current best loss = 12.29969, at epoch 23
Train batch 1/4 - 120.2ms/batch - loss: 10.37864 - diff: 26.41mlTrain batch 2/4 - 120.2ms/batch - loss: 9.89770 - diff: 26.31mlTrain batch 3/4 - 119.3ms/batch - loss: 9.20794 - diff: 25.69mlTrain batch 4/4 - 109.0ms/batch - loss: 9.73518 - diff: 26.19mlTrain batch 4/4 - 10.7s 109.0ms/batch - loss: 9.73518 - diff: 26.19ml
Test 0.6s: val_loss: 12.08919 - diff: 26.59ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_TimeAsDepth_1_Adam-0.001_MSE_DA3_best

Epoch 25: current best loss = 12.08919, at epoch 24
Train batch 1/4 - 120.5ms/batch - loss: 6.77929 - diff: 21.74mlTrain batch 2/4 - 113.9ms/batch - loss: 6.99239 - diff: 22.82mlTrain batch 3/4 - 119.4ms/batch - loss: 8.74786 - diff: 24.28mlTrain batch 4/4 - 105.0ms/batch - loss: 9.43771 - diff: 25.01mlTrain batch 4/4 - 10.6s 105.0ms/batch - loss: 9.43771 - diff: 25.01ml
Test 0.6s: val_loss: 22.91085 - diff: 38.50ml

Epoch 26: current best loss = 12.08919, at epoch 24
Train batch 1/4 - 120.3ms/batch - loss: 10.70561 - diff: 25.17mlTrain batch 2/4 - 120.5ms/batch - loss: 8.95752 - diff: 23.90mlTrain batch 3/4 - 119.6ms/batch - loss: 8.99682 - diff: 24.46mlTrain batch 4/4 - 106.6ms/batch - loss: 9.26993 - diff: 24.95mlTrain batch 4/4 - 10.6s 106.6ms/batch - loss: 9.26993 - diff: 24.95ml
Test 0.6s: val_loss: 34.20100 - diff: 49.66ml

Epoch 27: current best loss = 12.08919, at epoch 24
Train batch 1/4 - 120.4ms/batch - loss: 7.59402 - diff: 23.44mlTrain batch 2/4 - 115.7ms/batch - loss: 7.68452 - diff: 24.05mlTrain batch 3/4 - 119.4ms/batch - loss: 9.70956 - diff: 25.84mlTrain batch 4/4 - 105.7ms/batch - loss: 10.34967 - diff: 26.41mlTrain batch 4/4 - 10.7s 105.7ms/batch - loss: 10.34967 - diff: 26.41ml
Test 0.6s: val_loss: 24.26454 - diff: 38.98ml

Epoch 28: current best loss = 12.08919, at epoch 24
Train batch 1/4 - 120.0ms/batch - loss: 8.35554 - diff: 25.06mlTrain batch 2/4 - 119.4ms/batch - loss: 8.36092 - diff: 24.87mlTrain batch 3/4 - 119.5ms/batch - loss: 9.75802 - diff: 26.71mlTrain batch 4/4 - 105.0ms/batch - loss: 9.83886 - diff: 26.27mlTrain batch 4/4 - 10.7s 105.0ms/batch - loss: 9.83886 - diff: 26.27ml
Test 0.6s: val_loss: 87.06972 - diff: 83.23ml

Epoch 29: current best loss = 12.08919, at epoch 24
Train batch 1/4 - 120.7ms/batch - loss: 10.85147 - diff: 27.71mlTrain batch 2/4 - 113.0ms/batch - loss: 11.37368 - diff: 27.82mlTrain batch 3/4 - 118.1ms/batch - loss: 9.88701 - diff: 26.57mlTrain batch 4/4 - 104.7ms/batch - loss: 10.58506 - diff: 27.17mlTrain batch 4/4 - 10.7s 104.7ms/batch - loss: 10.58506 - diff: 27.17ml
Test 0.6s: val_loss: 11.59996 - diff: 26.41ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_TimeAsDepth_1_Adam-0.001_MSE_DA3_best

Epoch 30: current best loss = 11.59996, at epoch 29
Train batch 1/4 - 118.6ms/batch - loss: 10.14046 - diff: 26.43mlTrain batch 2/4 - 112.8ms/batch - loss: 11.59317 - diff: 28.09mlTrain batch 3/4 - 117.9ms/batch - loss: 10.71690 - diff: 27.56mlTrain batch 4/4 - 104.7ms/batch - loss: 9.98042 - diff: 26.64mlTrain batch 4/4 - 10.6s 104.7ms/batch - loss: 9.98042 - diff: 26.64ml
Test 0.6s: val_loss: 13.08387 - diff: 25.43ml

Epoch 31: current best loss = 11.59996, at epoch 29
Train batch 1/4 - 120.5ms/batch - loss: 7.74351 - diff: 23.18mlTrain batch 2/4 - 117.2ms/batch - loss: 7.66644 - diff: 24.01mlTrain batch 3/4 - 119.4ms/batch - loss: 9.64518 - diff: 26.03mlTrain batch 4/4 - 104.7ms/batch - loss: 10.27302 - diff: 26.05mlTrain batch 4/4 - 10.6s 104.7ms/batch - loss: 10.27302 - diff: 26.05ml
Test 0.6s: val_loss: 9.45664 - diff: 23.50ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_TimeAsDepth_1_Adam-0.001_MSE_DA3_best

Epoch 32: current best loss = 9.45664, at epoch 31
Train batch 1/4 - 120.3ms/batch - loss: 10.58277 - diff: 27.84mlTrain batch 2/4 - 117.5ms/batch - loss: 8.68549 - diff: 24.76mlTrain batch 3/4 - 119.3ms/batch - loss: 8.43577 - diff: 24.87mlTrain batch 4/4 - 104.9ms/batch - loss: 9.10320 - diff: 24.94mlTrain batch 4/4 - 10.6s 104.9ms/batch - loss: 9.10320 - diff: 24.94ml
Test 0.6s: val_loss: 16.23162 - diff: 32.30ml

Epoch 33: current best loss = 9.45664, at epoch 31
Train batch 1/4 - 120.4ms/batch - loss: 6.87008 - diff: 22.81mlTrain batch 2/4 - 120.2ms/batch - loss: 6.78896 - diff: 22.62mlTrain batch 3/4 - 119.4ms/batch - loss: 7.96983 - diff: 24.04mlTrain batch 4/4 - 106.5ms/batch - loss: 9.18376 - diff: 25.09mlTrain batch 4/4 - 10.6s 106.5ms/batch - loss: 9.18376 - diff: 25.09ml
Test 0.6s: val_loss: 18.44800 - diff: 33.38ml

Epoch 34: current best loss = 9.45664, at epoch 31
Train batch 1/4 - 120.5ms/batch - loss: 7.17406 - diff: 21.99mlTrain batch 2/4 - 120.3ms/batch - loss: 8.50217 - diff: 23.89mlTrain batch 3/4 - 119.5ms/batch - loss: 8.89811 - diff: 24.50mlTrain batch 4/4 - 111.7ms/batch - loss: 9.27788 - diff: 25.03mlTrain batch 4/4 - 10.6s 111.7ms/batch - loss: 9.27788 - diff: 25.03ml
Test 0.6s: val_loss: 10.00213 - diff: 25.46ml

Epoch 35: current best loss = 9.45664, at epoch 31
Train batch 1/4 - 120.1ms/batch - loss: 9.57037 - diff: 24.34mlTrain batch 2/4 - 113.0ms/batch - loss: 10.16013 - diff: 25.53mlTrain batch 3/4 - 119.5ms/batch - loss: 9.39641 - diff: 25.09mlTrain batch 4/4 - 111.6ms/batch - loss: 9.38145 - diff: 25.31mlTrain batch 4/4 - 10.6s 111.6ms/batch - loss: 9.38145 - diff: 25.31ml
Test 0.6s: val_loss: 49.37715 - diff: 60.41ml

Epoch 36: current best loss = 9.45664, at epoch 31
Train batch 1/4 - 120.2ms/batch - loss: 8.46265 - diff: 25.40mlTrain batch 2/4 - 118.7ms/batch - loss: 8.13938 - diff: 24.38mlTrain batch 3/4 - 119.4ms/batch - loss: 9.60436 - diff: 26.10mlTrain batch 4/4 - 109.0ms/batch - loss: 9.10167 - diff: 25.50mlTrain batch 4/4 - 10.7s 109.0ms/batch - loss: 9.10167 - diff: 25.50ml
Test 0.6s: val_loss: 20.94052 - diff: 38.38ml

Epoch 37: current best loss = 9.45664, at epoch 31
Train batch 1/4 - 119.1ms/batch - loss: 8.14648 - diff: 25.46mlTrain batch 2/4 - 112.9ms/batch - loss: 8.94345 - diff: 25.67mlTrain batch 3/4 - 119.5ms/batch - loss: 9.25185 - diff: 25.27mlTrain batch 4/4 - 110.5ms/batch - loss: 9.04711 - diff: 25.00mlTrain batch 4/4 - 10.6s 110.5ms/batch - loss: 9.04711 - diff: 25.00ml
Test 0.6s: val_loss: 10.55371 - diff: 24.86ml

Epoch 38: current best loss = 9.45664, at epoch 31
Train batch 1/4 - 119.1ms/batch - loss: 7.72176 - diff: 24.19mlTrain batch 2/4 - 117.8ms/batch - loss: 9.30155 - diff: 25.90mlTrain batch 3/4 - 119.6ms/batch - loss: 8.29587 - diff: 24.27mlTrain batch 4/4 - 109.2ms/batch - loss: 8.23733 - diff: 24.12mlTrain batch 4/4 - 10.6s 109.2ms/batch - loss: 8.23733 - diff: 24.12ml
Test 0.6s: val_loss: 12.33044 - diff: 26.24ml

Epoch 39: current best loss = 9.45664, at epoch 31
Train batch 1/4 - 120.4ms/batch - loss: 8.18475 - diff: 24.17mlTrain batch 2/4 - 114.8ms/batch - loss: 7.58418 - diff: 23.64mlTrain batch 3/4 - 119.7ms/batch - loss: 8.36893 - diff: 24.32mlTrain batch 4/4 - 105.5ms/batch - loss: 8.63346 - diff: 24.65mlTrain batch 4/4 - 10.7s 105.5ms/batch - loss: 8.63346 - diff: 24.65ml
Test 0.6s: val_loss: 15.75975 - diff: 29.31ml

Epoch 40: current best loss = 9.45664, at epoch 31
Train batch 1/4 - 120.7ms/batch - loss: 8.41455 - diff: 24.76mlTrain batch 2/4 - 113.3ms/batch - loss: 8.25015 - diff: 24.59mlTrain batch 3/4 - 119.5ms/batch - loss: 8.07644 - diff: 24.34mlTrain batch 4/4 - 104.7ms/batch - loss: 9.04845 - diff: 24.86mlTrain batch 4/4 - 10.7s 104.7ms/batch - loss: 9.04845 - diff: 24.86ml
Test 0.6s: val_loss: 33.90761 - diff: 48.35ml

Epoch 41: current best loss = 9.45664, at epoch 31
Train batch 1/4 - 120.7ms/batch - loss: 6.81647 - diff: 23.19mlTrain batch 2/4 - 113.4ms/batch - loss: 6.57180 - diff: 22.63mlTrain batch 3/4 - 119.4ms/batch - loss: 7.61276 - diff: 23.24mlTrain batch 4/4 - 104.8ms/batch - loss: 8.17690 - diff: 23.71mlTrain batch 4/4 - 10.7s 104.8ms/batch - loss: 8.17690 - diff: 23.71ml
Test 0.6s: val_loss: 43.34781 - diff: 58.64ml

Epoch 42: current best loss = 9.45664, at epoch 31
Train batch 1/4 - 120.3ms/batch - loss: 10.10339 - diff: 26.17mlTrain batch 2/4 - 120.2ms/batch - loss: 8.30715 - diff: 24.08mlTrain batch 3/4 - 119.4ms/batch - loss: 7.70399 - diff: 23.47mlTrain batch 4/4 - 111.7ms/batch - loss: 7.96917 - diff: 23.58mlTrain batch 4/4 - 10.7s 111.7ms/batch - loss: 7.96917 - diff: 23.58ml
Test 0.6s: val_loss: 19.53047 - diff: 36.87ml
Epoch    43: reducing learning rate of group 0 to 5.0000e-04.

Epoch 43: current best loss = 9.45664, at epoch 31
Train batch 1/4 - 120.3ms/batch - loss: 11.00661 - diff: 28.41mlTrain batch 2/4 - 113.3ms/batch - loss: 9.14600 - diff: 25.63mlTrain batch 3/4 - 119.6ms/batch - loss: 8.68864 - diff: 25.07mlTrain batch 4/4 - 111.8ms/batch - loss: 8.08702 - diff: 23.88mlTrain batch 4/4 - 10.6s 111.8ms/batch - loss: 8.08702 - diff: 23.88ml
Test 0.6s: val_loss: 18.04833 - diff: 35.09ml

Epoch 44: current best loss = 9.45664, at epoch 31
Train batch 1/4 - 119.8ms/batch - loss: 6.78089 - diff: 21.82mlTrain batch 2/4 - 113.1ms/batch - loss: 6.28125 - diff: 21.94mlTrain batch 3/4 - 119.9ms/batch - loss: 6.38686 - diff: 21.98mlTrain batch 4/4 - 109.0ms/batch - loss: 6.51570 - diff: 21.99mlTrain batch 4/4 - 10.7s 109.0ms/batch - loss: 6.51570 - diff: 21.99ml
Test 0.6s: val_loss: 23.44371 - diff: 41.93ml

Epoch 45: current best loss = 9.45664, at epoch 31
Train batch 1/4 - 120.7ms/batch - loss: 6.70573 - diff: 21.91mlTrain batch 2/4 - 116.5ms/batch - loss: 6.37727 - diff: 21.31mlTrain batch 3/4 - 120.1ms/batch - loss: 6.25319 - diff: 21.24mlTrain batch 4/4 - 110.1ms/batch - loss: 6.95162 - diff: 21.69mlTrain batch 4/4 - 10.6s 110.1ms/batch - loss: 6.95162 - diff: 21.69ml
Test 0.6s: val_loss: 15.78408 - diff: 33.37ml

Epoch 46: current best loss = 9.45664, at epoch 31
Train batch 1/4 - 120.6ms/batch - loss: 6.86452 - diff: 21.05mlTrain batch 2/4 - 118.8ms/batch - loss: 6.96402 - diff: 22.65mlTrain batch 3/4 - 119.6ms/batch - loss: 6.81828 - diff: 22.58mlTrain batch 4/4 - 110.4ms/batch - loss: 6.60704 - diff: 22.18mlTrain batch 4/4 - 10.6s 110.4ms/batch - loss: 6.60704 - diff: 22.18ml
Test 0.6s: val_loss: 10.29128 - diff: 24.69ml

Epoch 47: current best loss = 9.45664, at epoch 31
Train batch 1/4 - 120.4ms/batch - loss: 5.72175 - diff: 20.46mlTrain batch 2/4 - 116.1ms/batch - loss: 6.15539 - diff: 21.62mlTrain batch 3/4 - 119.5ms/batch - loss: 6.21762 - diff: 21.62mlTrain batch 4/4 - 105.6ms/batch - loss: 6.72483 - diff: 21.78mlTrain batch 4/4 - 10.7s 105.6ms/batch - loss: 6.72483 - diff: 21.78ml
Test 0.6s: val_loss: 11.70988 - diff: 26.15ml

Epoch 48: current best loss = 9.45664, at epoch 31
Train batch 1/4 - 120.3ms/batch - loss: 9.27370 - diff: 24.67mlTrain batch 2/4 - 119.6ms/batch - loss: 7.47073 - diff: 22.68mlTrain batch 3/4 - 119.6ms/batch - loss: 7.42940 - diff: 23.13mlTrain batch 4/4 - 105.1ms/batch - loss: 7.59196 - diff: 23.06mlTrain batch 4/4 - 10.7s 105.1ms/batch - loss: 7.59196 - diff: 23.06ml
Test 0.6s: val_loss: 9.87387 - diff: 24.78ml

Epoch 49: current best loss = 9.45664, at epoch 31
Train batch 1/4 - 119.3ms/batch - loss: 6.10051 - diff: 21.76mlTrain batch 2/4 - 113.0ms/batch - loss: 6.92706 - diff: 22.08mlTrain batch 3/4 - 118.7ms/batch - loss: 6.92913 - diff: 22.33mlTrain batch 4/4 - 104.7ms/batch - loss: 6.94879 - diff: 22.36mlTrain batch 4/4 - 10.7s 104.7ms/batch - loss: 6.94879 - diff: 22.36ml
Test 0.6s: val_loss: 10.02257 - diff: 23.32ml

Epoch 50: current best loss = 9.45664, at epoch 31
Train batch 1/4 - 120.3ms/batch - loss: 7.80710 - diff: 22.49mlTrain batch 2/4 - 115.0ms/batch - loss: 6.98102 - diff: 21.98mlTrain batch 3/4 - 118.1ms/batch - loss: 7.09877 - diff: 22.63mlTrain batch 4/4 - 104.7ms/batch - loss: 6.97826 - diff: 22.41mlTrain batch 4/4 - 10.6s 104.7ms/batch - loss: 6.97826 - diff: 22.41ml
Test 0.6s: val_loss: 12.73538 - diff: 27.18ml

Epoch 51: current best loss = 9.45664, at epoch 31
Train batch 1/4 - 119.3ms/batch - loss: 7.17707 - diff: 23.09mlTrain batch 2/4 - 117.3ms/batch - loss: 6.11243 - diff: 21.09mlTrain batch 3/4 - 118.1ms/batch - loss: 6.45549 - diff: 21.49mlTrain batch 4/4 - 104.9ms/batch - loss: 6.83978 - diff: 21.88mlTrain batch 4/4 - 10.6s 104.9ms/batch - loss: 6.83978 - diff: 21.88ml
Test 0.6s: val_loss: 13.16832 - diff: 28.77ml

Epoch 52: current best loss = 9.45664, at epoch 31
Train batch 1/4 - 120.3ms/batch - loss: 6.22227 - diff: 21.67mlTrain batch 2/4 - 120.5ms/batch - loss: 6.61984 - diff: 21.94mlTrain batch 3/4 - 117.2ms/batch - loss: 5.96693 - diff: 21.23mlTrain batch 4/4 - 105.7ms/batch - loss: 7.01741 - diff: 22.49mlTrain batch 4/4 - 10.6s 105.7ms/batch - loss: 7.01741 - diff: 22.49ml
Test 0.6s: val_loss: 10.41008 - diff: 25.24ml

Epoch 53: current best loss = 9.45664, at epoch 31
Train batch 1/4 - 120.5ms/batch - loss: 6.23767 - diff: 21.53mlTrain batch 2/4 - 113.3ms/batch - loss: 6.34751 - diff: 22.09mlTrain batch 3/4 - 119.7ms/batch - loss: 6.38517 - diff: 21.92mlTrain batch 4/4 - 104.8ms/batch - loss: 7.13765 - diff: 22.06mlTrain batch 4/4 - 10.6s 104.8ms/batch - loss: 7.13765 - diff: 22.06ml
Test 0.6s: val_loss: 11.44241 - diff: 25.32ml
Epoch    54: reducing learning rate of group 0 to 2.5000e-04.

Epoch 54: current best loss = 9.45664, at epoch 31
Train batch 1/4 - 120.6ms/batch - loss: 5.90822 - diff: 20.95mlTrain batch 2/4 - 113.0ms/batch - loss: 6.56784 - diff: 21.85mlTrain batch 3/4 - 119.7ms/batch - loss: 6.25805 - diff: 21.40mlTrain batch 4/4 - 104.9ms/batch - loss: 6.24035 - diff: 21.28mlTrain batch 4/4 - 10.6s 104.9ms/batch - loss: 6.24035 - diff: 21.28ml
Test 0.6s: val_loss: 11.31993 - diff: 25.69ml

Epoch 55: current best loss = 9.45664, at epoch 31
Train batch 1/4 - 120.5ms/batch - loss: 4.89587 - diff: 19.76mlTrain batch 2/4 - 113.4ms/batch - loss: 5.65396 - diff: 21.04mlTrain batch 3/4 - 119.8ms/batch - loss: 6.10947 - diff: 22.09mlTrain batch 4/4 - 111.8ms/batch - loss: 6.05890 - diff: 21.52mlTrain batch 4/4 - 10.6s 111.8ms/batch - loss: 6.05890 - diff: 21.52ml
Test 0.6s: val_loss: 10.34812 - diff: 23.71ml

Epoch 56: current best loss = 9.45664, at epoch 31
Train batch 1/4 - 120.5ms/batch - loss: 5.42294 - diff: 20.47mlTrain batch 2/4 - 114.0ms/batch - loss: 5.73634 - diff: 21.19mlTrain batch 3/4 - 117.5ms/batch - loss: 6.00890 - diff: 21.77mlTrain batch 4/4 - 106.9ms/batch - loss: 6.41264 - diff: 21.74mlTrain batch 4/4 - 10.6s 106.9ms/batch - loss: 6.41264 - diff: 21.74ml
Test 0.6s: val_loss: 9.71219 - diff: 23.87ml

Epoch 57: current best loss = 9.45664, at epoch 31
Train batch 1/4 - 119.7ms/batch - loss: 5.02201 - diff: 19.36mlTrain batch 2/4 - 118.1ms/batch - loss: 5.99264 - diff: 20.86mlTrain batch 3/4 - 119.6ms/batch - loss: 6.15362 - diff: 20.88mlTrain batch 4/4 - 111.6ms/batch - loss: 6.39260 - diff: 21.33mlTrain batch 4/4 - 10.7s 111.6ms/batch - loss: 6.39260 - diff: 21.33ml
Test 0.6s: val_loss: 9.90077 - diff: 24.20ml

Epoch 58: current best loss = 9.45664, at epoch 31
Train batch 1/4 - 120.6ms/batch - loss: 5.01811 - diff: 19.91mlTrain batch 2/4 - 117.9ms/batch - loss: 6.42047 - diff: 22.00mlTrain batch 3/4 - 119.5ms/batch - loss: 6.27405 - diff: 21.88mlTrain batch 4/4 - 109.1ms/batch - loss: 6.26419 - diff: 21.69mlTrain batch 4/4 - 10.6s 109.1ms/batch - loss: 6.26419 - diff: 21.69ml
Test 0.6s: val_loss: 9.66512 - diff: 23.80ml

Epoch 59: current best loss = 9.45664, at epoch 31
Train batch 1/4 - 118.0ms/batch - loss: 4.59042 - diff: 18.23mlTrain batch 2/4 - 113.8ms/batch - loss: 6.80327 - diff: 21.35mlTrain batch 3/4 - 119.6ms/batch - loss: 5.86842 - diff: 19.96mlTrain batch 4/4 - 111.8ms/batch - loss: 6.38085 - diff: 20.71mlTrain batch 4/4 - 10.6s 111.8ms/batch - loss: 6.38085 - diff: 20.71ml
Test 0.6s: val_loss: 11.36173 - diff: 24.77ml

Epoch 60: current best loss = 9.45664, at epoch 31
Train batch 1/4 - 120.6ms/batch - loss: 5.41205 - diff: 20.03mlTrain batch 2/4 - 119.6ms/batch - loss: 6.07747 - diff: 21.31mlTrain batch 3/4 - 119.5ms/batch - loss: 5.80345 - diff: 20.96mlTrain batch 4/4 - 108.1ms/batch - loss: 5.78806 - diff: 20.85mlTrain batch 4/4 - 10.7s 108.1ms/batch - loss: 5.78806 - diff: 20.85ml
Test 0.6s: val_loss: 11.85341 - diff: 25.94ml

Epoch 61: current best loss = 9.45664, at epoch 31
Train batch 1/4 - 120.4ms/batch - loss: 5.47998 - diff: 20.28mlTrain batch 2/4 - 115.5ms/batch - loss: 5.49759 - diff: 20.40mlTrain batch 3/4 - 119.5ms/batch - loss: 5.40840 - diff: 20.28mlTrain batch 4/4 - 107.8ms/batch - loss: 5.41878 - diff: 19.79mlTrain batch 4/4 - 10.6s 107.8ms/batch - loss: 5.41878 - diff: 19.79ml
Test 0.6s: val_loss: 11.87524 - diff: 26.66ml

Epoch 62: current best loss = 9.45664, at epoch 31
Train batch 1/4 - 120.4ms/batch - loss: 7.62613 - diff: 23.93mlTrain batch 2/4 - 114.3ms/batch - loss: 6.15805 - diff: 21.45mlTrain batch 3/4 - 119.6ms/batch - loss: 6.10710 - diff: 21.64mlTrain batch 4/4 - 105.6ms/batch - loss: 6.50673 - diff: 21.74mlTrain batch 4/4 - 10.7s 105.6ms/batch - loss: 6.50673 - diff: 21.74ml
Test 0.6s: val_loss: 11.64204 - diff: 26.73ml

Epoch 63: current best loss = 9.45664, at epoch 31
Train batch 1/4 - 120.2ms/batch - loss: 6.72952 - diff: 23.93mlTrain batch 2/4 - 119.6ms/batch - loss: 6.19950 - diff: 22.29mlTrain batch 3/4 - 119.6ms/batch - loss: 6.25993 - diff: 21.84mlTrain batch 4/4 - 104.8ms/batch - loss: 6.75804 - diff: 21.84mlTrain batch 4/4 - 10.6s 104.8ms/batch - loss: 6.75804 - diff: 21.84ml
Test 0.6s: val_loss: 14.07745 - diff: 31.05ml

Epoch 64: current best loss = 9.45664, at epoch 31
Train batch 1/4 - 120.6ms/batch - loss: 4.26098 - diff: 18.24mlTrain batch 2/4 - 113.2ms/batch - loss: 4.87687 - diff: 19.40mlTrain batch 3/4 - 119.6ms/batch - loss: 5.80962 - diff: 20.35mlTrain batch 4/4 - 105.6ms/batch - loss: 5.88050 - diff: 20.40mlTrain batch 4/4 - 10.6s 105.6ms/batch - loss: 5.88050 - diff: 20.40ml
Test 0.6s: val_loss: 14.00142 - diff: 29.50ml
Epoch    65: reducing learning rate of group 0 to 1.2500e-04.

Epoch 65: current best loss = 9.45664, at epoch 31
Train batch 1/4 - 120.6ms/batch - loss: 4.98241 - diff: 19.29mlTrain batch 2/4 - 115.5ms/batch - loss: 5.26487 - diff: 19.46mlTrain batch 3/4 - 119.5ms/batch - loss: 5.69643 - diff: 20.60mlTrain batch 4/4 - 107.5ms/batch - loss: 5.90487 - diff: 20.91mlTrain batch 4/4 - 10.6s 107.5ms/batch - loss: 5.90487 - diff: 20.91ml
Test 0.6s: val_loss: 10.82881 - diff: 25.15ml

Epoch 66: current best loss = 9.45664, at epoch 31
Train batch 1/4 - 120.3ms/batch - loss: 7.92367 - diff: 24.60mlTrain batch 2/4 - 117.3ms/batch - loss: 6.50325 - diff: 22.39mlTrain batch 3/4 - 119.6ms/batch - loss: 6.11959 - diff: 21.19mlTrain batch 4/4 - 106.3ms/batch - loss: 6.43323 - diff: 21.61mlTrain batch 4/4 - 10.7s 106.3ms/batch - loss: 6.43323 - diff: 21.61ml
Test 0.6s: val_loss: 10.05915 - diff: 23.17ml

Epoch 67: current best loss = 9.45664, at epoch 31
Train batch 1/4 - 120.3ms/batch - loss: 6.81002 - diff: 22.64mlTrain batch 2/4 - 113.1ms/batch - loss: 6.69660 - diff: 21.84mlTrain batch 3/4 - 119.3ms/batch - loss: 6.37978 - diff: 21.50mlTrain batch 4/4 - 105.0ms/batch - loss: 6.43191 - diff: 21.33mlTrain batch 4/4 - 10.7s 105.0ms/batch - loss: 6.43191 - diff: 21.33ml
Test 0.6s: val_loss: 9.36170 - diff: 22.96ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_TimeAsDepth_1_Adam-0.001_MSE_DA3_best

Epoch 68: current best loss = 9.36170, at epoch 67
Train batch 1/4 - 120.2ms/batch - loss: 4.06825 - diff: 18.80mlTrain batch 2/4 - 116.7ms/batch - loss: 4.76535 - diff: 19.94mlTrain batch 3/4 - 117.5ms/batch - loss: 6.13097 - diff: 21.45mlTrain batch 4/4 - 104.8ms/batch - loss: 6.29844 - diff: 21.51mlTrain batch 4/4 - 10.6s 104.8ms/batch - loss: 6.29844 - diff: 21.51ml
Test 0.6s: val_loss: 9.73841 - diff: 22.96ml

Epoch 69: current best loss = 9.36170, at epoch 67
Train batch 1/4 - 120.8ms/batch - loss: 4.92543 - diff: 19.66mlTrain batch 2/4 - 118.4ms/batch - loss: 4.94217 - diff: 19.77mlTrain batch 3/4 - 119.5ms/batch - loss: 4.97454 - diff: 19.67mlTrain batch 4/4 - 104.8ms/batch - loss: 5.71962 - diff: 20.31mlTrain batch 4/4 - 10.6s 104.8ms/batch - loss: 5.71962 - diff: 20.31ml
Test 0.6s: val_loss: 9.01201 - diff: 22.97ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_TimeAsDepth_1_Adam-0.001_MSE_DA3_best

Epoch 70: current best loss = 9.01201, at epoch 69
Train batch 1/4 - 120.2ms/batch - loss: 6.07315 - diff: 20.71mlTrain batch 2/4 - 114.3ms/batch - loss: 6.17705 - diff: 21.15mlTrain batch 3/4 - 117.5ms/batch - loss: 5.94379 - diff: 20.97mlTrain batch 4/4 - 107.4ms/batch - loss: 5.72669 - diff: 20.52mlTrain batch 4/4 - 10.6s 107.4ms/batch - loss: 5.72669 - diff: 20.52ml
Test 0.6s: val_loss: 9.20149 - diff: 23.06ml

Epoch 71: current best loss = 9.01201, at epoch 69
Train batch 1/4 - 120.0ms/batch - loss: 6.79683 - diff: 23.19mlTrain batch 2/4 - 115.5ms/batch - loss: 6.66526 - diff: 22.61mlTrain batch 3/4 - 117.5ms/batch - loss: 6.33906 - diff: 21.66mlTrain batch 4/4 - 105.0ms/batch - loss: 6.35683 - diff: 21.68mlTrain batch 4/4 - 10.6s 105.0ms/batch - loss: 6.35683 - diff: 21.68ml
Test 0.6s: val_loss: 10.81752 - diff: 25.52ml

Epoch 72: current best loss = 9.01201, at epoch 69
Train batch 1/4 - 120.5ms/batch - loss: 7.12573 - diff: 23.19mlTrain batch 2/4 - 115.8ms/batch - loss: 6.26949 - diff: 21.61mlTrain batch 3/4 - 119.4ms/batch - loss: 5.85058 - diff: 20.86mlTrain batch 4/4 - 108.0ms/batch - loss: 5.72126 - diff: 20.38mlTrain batch 4/4 - 10.5s 108.0ms/batch - loss: 5.72126 - diff: 20.38ml
Test 0.6s: val_loss: 11.14393 - diff: 25.91ml

Epoch 73: current best loss = 9.01201, at epoch 69
Train batch 1/4 - 120.4ms/batch - loss: 4.38143 - diff: 18.15mlTrain batch 2/4 - 118.2ms/batch - loss: 4.99663 - diff: 19.58mlTrain batch 3/4 - 119.7ms/batch - loss: 5.14333 - diff: 19.96mlTrain batch 4/4 - 109.9ms/batch - loss: 5.81063 - diff: 20.45mlTrain batch 4/4 - 10.6s 109.9ms/batch - loss: 5.81063 - diff: 20.45ml
Test 0.6s: val_loss: 10.81470 - diff: 24.81ml

Epoch 74: current best loss = 9.01201, at epoch 69
Train batch 1/4 - 120.4ms/batch - loss: 7.82030 - diff: 22.67mlTrain batch 2/4 - 113.0ms/batch - loss: 6.63580 - diff: 21.92mlTrain batch 3/4 - 119.7ms/batch - loss: 6.05149 - diff: 21.34mlTrain batch 4/4 - 111.7ms/batch - loss: 6.03085 - diff: 20.98mlTrain batch 4/4 - 10.6s 111.7ms/batch - loss: 6.03085 - diff: 20.98ml
Test 0.6s: val_loss: 10.85055 - diff: 25.02ml

Epoch 75: current best loss = 9.01201, at epoch 69
Train batch 1/4 - 120.2ms/batch - loss: 5.79547 - diff: 21.27mlTrain batch 2/4 - 113.2ms/batch - loss: 5.70688 - diff: 20.64mlTrain batch 3/4 - 119.7ms/batch - loss: 5.26967 - diff: 20.10mlTrain batch 4/4 - 111.6ms/batch - loss: 5.43755 - diff: 19.62mlTrain batch 4/4 - 10.6s 111.6ms/batch - loss: 5.43755 - diff: 19.62ml
Test 0.6s: val_loss: 10.28165 - diff: 24.58ml

Epoch 76: current best loss = 9.01201, at epoch 69
Train batch 1/4 - 120.4ms/batch - loss: 7.03146 - diff: 22.98mlTrain batch 2/4 - 113.3ms/batch - loss: 6.48696 - diff: 21.39mlTrain batch 3/4 - 119.5ms/batch - loss: 6.04864 - diff: 20.68mlTrain batch 4/4 - 110.3ms/batch - loss: 6.17453 - diff: 20.80mlTrain batch 4/4 - 10.7s 110.3ms/batch - loss: 6.17453 - diff: 20.80ml
Test 0.6s: val_loss: 11.03103 - diff: 24.73ml

Epoch 77: current best loss = 9.01201, at epoch 69
Train batch 1/4 - 120.5ms/batch - loss: 5.59762 - diff: 20.46mlTrain batch 2/4 - 119.9ms/batch - loss: 5.15969 - diff: 20.09mlTrain batch 3/4 - 119.7ms/batch - loss: 5.39754 - diff: 20.35mlTrain batch 4/4 - 110.4ms/batch - loss: 5.87084 - diff: 20.38mlTrain batch 4/4 - 10.6s 110.4ms/batch - loss: 5.87084 - diff: 20.38ml
Test 0.6s: val_loss: 11.41795 - diff: 24.78ml

Epoch 78: current best loss = 9.01201, at epoch 69
Train batch 1/4 - 120.3ms/batch - loss: 5.91939 - diff: 20.71mlTrain batch 2/4 - 118.3ms/batch - loss: 5.70963 - diff: 21.23mlTrain batch 3/4 - 119.4ms/batch - loss: 5.59656 - diff: 20.84mlTrain batch 4/4 - 108.3ms/batch - loss: 5.76218 - diff: 20.72mlTrain batch 4/4 - 10.7s 108.3ms/batch - loss: 5.76218 - diff: 20.72ml
Test 0.6s: val_loss: 10.59682 - diff: 24.43ml

Epoch 79: current best loss = 9.01201, at epoch 69
Train batch 1/4 - 120.4ms/batch - loss: 5.62421 - diff: 20.66mlTrain batch 2/4 - 116.7ms/batch - loss: 5.79923 - diff: 21.10mlTrain batch 3/4 - 119.7ms/batch - loss: 5.84523 - diff: 20.98mlTrain batch 4/4 - 104.9ms/batch - loss: 5.53822 - diff: 20.24mlTrain batch 4/4 - 10.7s 104.9ms/batch - loss: 5.53822 - diff: 20.24ml
Test 0.6s: val_loss: 10.30348 - diff: 24.23ml

Epoch 80: current best loss = 9.01201, at epoch 69
Train batch 1/4 - 120.5ms/batch - loss: 5.26705 - diff: 20.44mlTrain batch 2/4 - 114.4ms/batch - loss: 5.17970 - diff: 20.86mlTrain batch 3/4 - 119.5ms/batch - loss: 5.23721 - diff: 20.65mlTrain batch 4/4 - 105.2ms/batch - loss: 6.19022 - diff: 21.03mlTrain batch 4/4 - 10.6s 105.2ms/batch - loss: 6.19022 - diff: 21.03ml
Test 0.6s: val_loss: 10.72546 - diff: 24.30ml
Epoch    81: reducing learning rate of group 0 to 6.2500e-05.

Epoch 81: current best loss = 9.01201, at epoch 69
Train batch 1/4 - 120.4ms/batch - loss: 7.65927 - diff: 23.08mlTrain batch 2/4 - 117.5ms/batch - loss: 6.57676 - diff: 22.26mlTrain batch 3/4 - 118.4ms/batch - loss: 6.08203 - diff: 21.53mlTrain batch 4/4 - 104.8ms/batch - loss: 6.12597 - diff: 21.39mlTrain batch 4/4 - 10.7s 104.8ms/batch - loss: 6.12597 - diff: 21.39ml
Test 0.6s: val_loss: 9.98613 - diff: 23.97ml

Epoch 82: current best loss = 9.01201, at epoch 69
Train batch 1/4 - 120.5ms/batch - loss: 4.49876 - diff: 18.91mlTrain batch 2/4 - 113.4ms/batch - loss: 5.11863 - diff: 19.89mlTrain batch 3/4 - 119.8ms/batch - loss: 4.64670 - diff: 18.99mlTrain batch 4/4 - 111.8ms/batch - loss: 5.53807 - diff: 19.80mlTrain batch 4/4 - 10.7s 111.8ms/batch - loss: 5.53807 - diff: 19.80ml
Test 0.6s: val_loss: 10.75127 - diff: 24.04ml

Epoch 83: current best loss = 9.01201, at epoch 69
Train batch 1/4 - 120.6ms/batch - loss: 5.23722 - diff: 20.04mlTrain batch 2/4 - 118.9ms/batch - loss: 5.19808 - diff: 20.01mlTrain batch 3/4 - 119.7ms/batch - loss: 5.21324 - diff: 19.76mlTrain batch 4/4 - 105.2ms/batch - loss: 4.96614 - diff: 19.22mlTrain batch 4/4 - 10.7s 105.2ms/batch - loss: 4.96614 - diff: 19.22ml
Test 0.6s: val_loss: 9.64296 - diff: 23.54ml

Epoch 84: current best loss = 9.01201, at epoch 69
Train batch 1/4 - 120.2ms/batch - loss: 5.62409 - diff: 20.04mlTrain batch 2/4 - 116.8ms/batch - loss: 5.37275 - diff: 19.52mlTrain batch 3/4 - 119.5ms/batch - loss: 5.39721 - diff: 19.85mlTrain batch 4/4 - 105.2ms/batch - loss: 5.54766 - diff: 20.18mlTrain batch 4/4 - 10.6s 105.2ms/batch - loss: 5.54766 - diff: 20.18ml
Test 0.6s: val_loss: 10.26734 - diff: 23.62ml

Epoch 85: current best loss = 9.01201, at epoch 69
Train batch 1/4 - 120.5ms/batch - loss: 4.23683 - diff: 18.17mlTrain batch 2/4 - 113.4ms/batch - loss: 4.58540 - diff: 19.25mlTrain batch 3/4 - 119.6ms/batch - loss: 4.62397 - diff: 18.67mlTrain batch 4/4 - 105.1ms/batch - loss: 4.96892 - diff: 19.20mlTrain batch 4/4 - 10.6s 105.1ms/batch - loss: 4.96892 - diff: 19.20ml
Test 0.6s: val_loss: 10.71736 - diff: 23.82ml

Epoch 86: current best loss = 9.01201, at epoch 69
Train batch 1/4 - 120.4ms/batch - loss: 4.98994 - diff: 18.81mlTrain batch 2/4 - 113.6ms/batch - loss: 5.24964 - diff: 19.34mlTrain batch 3/4 - 119.5ms/batch - loss: 5.66366 - diff: 20.34mlTrain batch 4/4 - 105.2ms/batch - loss: 5.40614 - diff: 19.76mlTrain batch 4/4 - 10.6s 105.2ms/batch - loss: 5.40614 - diff: 19.76ml
Test 0.6s: val_loss: 10.16780 - diff: 23.94ml

Epoch 87: current best loss = 9.01201, at epoch 69
Train batch 1/4 - 120.4ms/batch - loss: 3.79944 - diff: 17.53mlTrain batch 2/4 - 113.2ms/batch - loss: 4.96793 - diff: 19.58mlTrain batch 3/4 - 119.5ms/batch - loss: 4.84545 - diff: 19.49mlTrain batch 4/4 - 104.9ms/batch - loss: 5.07415 - diff: 19.73mlTrain batch 4/4 - 10.7s 104.9ms/batch - loss: 5.07415 - diff: 19.73ml
Test 0.6s: val_loss: 10.77680 - diff: 24.43ml

Epoch 88: current best loss = 9.01201, at epoch 69
Train batch 1/4 - 118.1ms/batch - loss: 4.27175 - diff: 18.89mlTrain batch 2/4 - 115.2ms/batch - loss: 4.83320 - diff: 19.47mlTrain batch 3/4 - 119.4ms/batch - loss: 5.88502 - diff: 20.41mlTrain batch 4/4 - 104.9ms/batch - loss: 5.61503 - diff: 19.83mlTrain batch 4/4 - 10.6s 104.9ms/batch - loss: 5.61503 - diff: 19.83ml
Test 0.6s: val_loss: 10.63329 - diff: 24.50ml

Epoch 89: current best loss = 9.01201, at epoch 69
Train batch 1/4 - 120.5ms/batch - loss: 5.77694 - diff: 20.59mlTrain batch 2/4 - 115.2ms/batch - loss: 6.03178 - diff: 20.48mlTrain batch 3/4 - 119.8ms/batch - loss: 5.63226 - diff: 20.08mlTrain batch 4/4 - 111.9ms/batch - loss: 5.92270 - diff: 20.55mlTrain batch 4/4 - 10.7s 111.9ms/batch - loss: 5.92270 - diff: 20.55ml
Test 0.6s: val_loss: 11.03743 - diff: 24.00ml

Epoch 90: current best loss = 9.01201, at epoch 69
Train batch 1/4 - 120.2ms/batch - loss: 6.46210 - diff: 21.55mlTrain batch 2/4 - 114.0ms/batch - loss: 6.17475 - diff: 21.15mlTrain batch 3/4 - 119.0ms/batch - loss: 5.80868 - diff: 20.34mlTrain batch 4/4 - 104.8ms/batch - loss: 5.91032 - diff: 20.46mlTrain batch 4/4 - 10.6s 104.8ms/batch - loss: 5.91032 - diff: 20.46ml
Test 0.6s: val_loss: 11.31511 - diff: 23.75ml

Epoch 91: current best loss = 9.01201, at epoch 69
Train batch 1/4 - 118.8ms/batch - loss: 5.36879 - diff: 19.49mlTrain batch 2/4 - 112.9ms/batch - loss: 5.11848 - diff: 19.28mlTrain batch 3/4 - 117.7ms/batch - loss: 5.60394 - diff: 20.46mlTrain batch 4/4 - 104.8ms/batch - loss: 5.40540 - diff: 20.07mlTrain batch 4/4 - 10.6s 104.8ms/batch - loss: 5.40540 - diff: 20.07ml
Test 0.6s: val_loss: 10.65098 - diff: 23.25ml
Epoch    92: reducing learning rate of group 0 to 3.1250e-05.

Epoch 92: current best loss = 9.01201, at epoch 69
Train batch 1/4 - 120.2ms/batch - loss: 4.69038 - diff: 18.59mlTrain batch 2/4 - 115.9ms/batch - loss: 5.22193 - diff: 19.61mlTrain batch 3/4 - 117.8ms/batch - loss: 5.42330 - diff: 20.01mlTrain batch 4/4 - 107.9ms/batch - loss: 5.34951 - diff: 19.72mlTrain batch 4/4 - 10.6s 107.9ms/batch - loss: 5.34951 - diff: 19.72ml
Test 0.6s: val_loss: 9.90878 - diff: 22.84ml

Epoch 93: current best loss = 9.01201, at epoch 69
Train batch 1/4 - 120.2ms/batch - loss: 5.23785 - diff: 19.93mlTrain batch 2/4 - 116.9ms/batch - loss: 5.88042 - diff: 21.50mlTrain batch 3/4 - 118.1ms/batch - loss: 6.66718 - diff: 21.79mlTrain batch 4/4 - 104.8ms/batch - loss: 6.49139 - diff: 21.29mlTrain batch 4/4 - 10.6s 104.8ms/batch - loss: 6.49139 - diff: 21.29ml
Test 0.6s: val_loss: 9.61936 - diff: 22.80ml

Epoch 94: current best loss = 9.01201, at epoch 69
Train batch 1/4 - 120.5ms/batch - loss: 7.61365 - diff: 23.10mlTrain batch 2/4 - 113.2ms/batch - loss: 6.06546 - diff: 20.72mlTrain batch 3/4 - 118.3ms/batch - loss: 5.42814 - diff: 20.27mlTrain batch 4/4 - 104.8ms/batch - loss: 5.59359 - diff: 20.65mlTrain batch 4/4 - 10.6s 104.8ms/batch - loss: 5.59359 - diff: 20.65ml
Test 0.6s: val_loss: 10.77706 - diff: 23.24ml

Epoch 95: current best loss = 9.01201, at epoch 69
Train batch 1/4 - 120.3ms/batch - loss: 6.41325 - diff: 22.00mlTrain batch 2/4 - 113.0ms/batch - loss: 6.62340 - diff: 22.01mlTrain batch 3/4 - 119.5ms/batch - loss: 6.13682 - diff: 21.17mlTrain batch 4/4 - 104.9ms/batch - loss: 6.01652 - diff: 20.89mlTrain batch 4/4 - 10.6s 104.9ms/batch - loss: 6.01652 - diff: 20.89ml
Test 0.6s: val_loss: 10.11024 - diff: 23.17ml

Epoch 96: current best loss = 9.01201, at epoch 69
Train batch 1/4 - 120.5ms/batch - loss: 5.85151 - diff: 21.01mlTrain batch 2/4 - 120.4ms/batch - loss: 5.64935 - diff: 20.71mlTrain batch 3/4 - 119.5ms/batch - loss: 5.29703 - diff: 20.08mlTrain batch 4/4 - 106.0ms/batch - loss: 5.65983 - diff: 20.45mlTrain batch 4/4 - 10.6s 106.0ms/batch - loss: 5.65983 - diff: 20.45ml
Test 0.6s: val_loss: 10.00594 - diff: 22.96ml

Epoch 97: current best loss = 9.01201, at epoch 69
Train batch 1/4 - 120.1ms/batch - loss: 4.65241 - diff: 18.59mlTrain batch 2/4 - 120.4ms/batch - loss: 4.84503 - diff: 19.43mlTrain batch 3/4 - 119.5ms/batch - loss: 4.87333 - diff: 19.36mlTrain batch 4/4 - 104.8ms/batch - loss: 4.88385 - diff: 19.22mlTrain batch 4/4 - 10.7s 104.8ms/batch - loss: 4.88385 - diff: 19.22ml
Test 0.6s: val_loss: 9.78733 - diff: 22.96ml

Epoch 98: current best loss = 9.01201, at epoch 69
Train batch 1/4 - 120.1ms/batch - loss: 5.61599 - diff: 21.37mlTrain batch 2/4 - 117.1ms/batch - loss: 6.66428 - diff: 22.24mlTrain batch 3/4 - 119.4ms/batch - loss: 6.03900 - diff: 21.43mlTrain batch 4/4 - 109.9ms/batch - loss: 5.98470 - diff: 21.31mlTrain batch 4/4 - 10.5s 109.9ms/batch - loss: 5.98470 - diff: 21.31ml
Test 0.6s: val_loss: 10.11364 - diff: 23.53ml

Epoch 99: current best loss = 9.01201, at epoch 69
Train batch 1/4 - 118.2ms/batch - loss: 4.98793 - diff: 19.82mlTrain batch 2/4 - 113.0ms/batch - loss: 5.65749 - diff: 20.42mlTrain batch 3/4 - 119.5ms/batch - loss: 5.27478 - diff: 19.73mlTrain batch 4/4 - 110.3ms/batch - loss: 5.10999 - diff: 19.23mlTrain batch 4/4 - 10.6s 110.3ms/batch - loss: 5.10999 - diff: 19.23ml
Test 0.6s: val_loss: 9.58892 - diff: 23.65ml

