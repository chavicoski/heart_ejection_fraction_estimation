nohup: ignoring input
Running experiment 2CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_WideResNet50_1_Adam-0.001_MSE_DA3
Going to train with the GPU in the slot 1 -> device model: GeForce RTX 2080
Model architecture:
 WideResNet50_1(
  (first_conv): Sequential(
    (0): Conv2d(30, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Dropout(p=0.4, inplace=False)
  )
  (pretrained_block): Sequential(
    (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): ReLU(inplace=True)
    (2): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (3): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (4): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (5): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (4): Bottleneck(
        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (5): Bottleneck(
        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
  )
  (reduction_block): Sequential(
    (0): AdaptiveAvgPool2d(output_size=(1, 1))
    (1): Flatten()
  )
  (dense_block): Sequential(
    (0): Linear(in_features=1024, out_features=512, bias=True)
    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Dropout(p=0.4, inplace=False)
    (4): Linear(in_features=512, out_features=1, bias=True)
  )
) 


############################
# TRAIN PHASE:  150 epochs #
############################

Epoch 0: 
Train batch 1/32 - 206.6ms/batch - loss: 2823.60596 - diff: 193.49mlTrain batch 2/32 - 189.8ms/batch - loss: 2282.15186 - diff: 177.39mlTrain batch 3/32 - 181.8ms/batch - loss: 2044.16862 - diff: 169.63mlTrain batch 4/32 - 171.9ms/batch - loss: 2074.17004 - diff: 171.73mlTrain batch 5/32 - 172.3ms/batch - loss: 2066.80312 - diff: 171.08mlTrain batch 6/32 - 172.0ms/batch - loss: 2039.48716 - diff: 171.19mlTrain batch 7/32 - 171.4ms/batch - loss: 2050.49841 - diff: 172.02mlTrain batch 8/32 - 172.4ms/batch - loss: 2029.15698 - diff: 171.65mlTrain batch 9/32 - 172.4ms/batch - loss: 1998.43106 - diff: 170.00mlTrain batch 10/32 - 172.4ms/batch - loss: 1963.01107 - diff: 168.94mlTrain batch 11/32 - 172.4ms/batch - loss: 2046.74495 - diff: 170.62mlTrain batch 12/32 - 172.3ms/batch - loss: 2005.38365 - diff: 168.80mlTrain batch 13/32 - 172.4ms/batch - loss: 2001.53964 - diff: 167.94mlTrain batch 14/32 - 172.3ms/batch - loss: 1997.16936 - diff: 168.08mlTrain batch 15/32 - 172.3ms/batch - loss: 2021.53979 - diff: 169.38mlTrain batch 16/32 - 172.6ms/batch - loss: 1976.33278 - diff: 167.10mlTrain batch 17/32 - 172.4ms/batch - loss: 1977.11157 - diff: 167.21mlTrain batch 18/32 - 172.3ms/batch - loss: 1971.33790 - diff: 167.03mlTrain batch 19/32 - 172.5ms/batch - loss: 1951.00199 - diff: 166.29mlTrain batch 20/32 - 172.3ms/batch - loss: 1918.20438 - diff: 164.77mlTrain batch 21/32 - 172.5ms/batch - loss: 1925.44430 - diff: 164.98mlTrain batch 22/32 - 172.3ms/batch - loss: 1894.67824 - diff: 163.49mlTrain batch 23/32 - 172.5ms/batch - loss: 1875.61260 - diff: 162.88mlTrain batch 24/32 - 172.4ms/batch - loss: 1885.69528 - diff: 163.32mlTrain batch 25/32 - 172.4ms/batch - loss: 1908.82097 - diff: 164.34mlTrain batch 26/32 - 172.6ms/batch - loss: 1911.96288 - diff: 164.39mlTrain batch 27/32 - 172.5ms/batch - loss: 1918.49138 - diff: 164.62mlTrain batch 28/32 - 172.3ms/batch - loss: 1919.93790 - diff: 164.73mlTrain batch 29/32 - 172.6ms/batch - loss: 1911.05550 - diff: 164.53mlTrain batch 30/32 - 172.5ms/batch - loss: 1900.86395 - diff: 164.10mlTrain batch 31/32 - 172.4ms/batch - loss: 1881.71250 - diff: 163.24mlTrain batch 32/32 - 52.5ms/batch - loss: 1913.01545 - diff: 163.14mlTrain batch 32/32 - 11.8s 52.5ms/batch - loss: 1913.01545 - diff: 163.14ml
Test 1.0s: val_loss: 1834.38035 - diff: 156.78ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_WideResNet50_1_Adam-0.001_MSE_DA3_best

Epoch 1: current best loss = 1834.38035, at epoch 0
Train batch 1/32 - 172.6ms/batch - loss: 1784.33350 - diff: 163.93mlTrain batch 2/32 - 172.9ms/batch - loss: 1881.52124 - diff: 165.25mlTrain batch 3/32 - 172.4ms/batch - loss: 1806.63310 - diff: 162.95mlTrain batch 4/32 - 172.6ms/batch - loss: 1779.56143 - diff: 161.12mlTrain batch 5/32 - 172.4ms/batch - loss: 1819.29734 - diff: 163.27mlTrain batch 6/32 - 172.0ms/batch - loss: 1729.20823 - diff: 159.05mlTrain batch 7/32 - 172.1ms/batch - loss: 1739.89237 - diff: 159.64mlTrain batch 8/32 - 172.0ms/batch - loss: 1753.10283 - diff: 160.51mlTrain batch 9/32 - 172.4ms/batch - loss: 1699.36407 - diff: 157.60mlTrain batch 10/32 - 172.3ms/batch - loss: 1681.82288 - diff: 156.39mlTrain batch 11/32 - 172.7ms/batch - loss: 1648.08641 - diff: 154.97mlTrain batch 12/32 - 172.8ms/batch - loss: 1645.82611 - diff: 154.29mlTrain batch 13/32 - 172.7ms/batch - loss: 1679.46152 - diff: 155.09mlTrain batch 14/32 - 172.8ms/batch - loss: 1682.06226 - diff: 155.52mlTrain batch 15/32 - 172.5ms/batch - loss: 1706.55669 - diff: 156.73mlTrain batch 16/32 - 172.8ms/batch - loss: 1696.66365 - diff: 156.19mlTrain batch 17/32 - 172.8ms/batch - loss: 1691.11928 - diff: 156.12mlTrain batch 18/32 - 172.7ms/batch - loss: 1682.46175 - diff: 155.73mlTrain batch 19/32 - 172.7ms/batch - loss: 1683.63981 - diff: 156.00mlTrain batch 20/32 - 173.1ms/batch - loss: 1675.28201 - diff: 155.37mlTrain batch 21/32 - 172.8ms/batch - loss: 1646.60671 - diff: 154.01mlTrain batch 22/32 - 172.4ms/batch - loss: 1678.97067 - diff: 154.97mlTrain batch 23/32 - 172.8ms/batch - loss: 1670.48756 - diff: 154.69mlTrain batch 24/32 - 173.2ms/batch - loss: 1659.28932 - diff: 154.39mlTrain batch 25/32 - 172.8ms/batch - loss: 1669.67390 - diff: 154.85mlTrain batch 26/32 - 172.4ms/batch - loss: 1644.57793 - diff: 153.64mlTrain batch 27/32 - 172.7ms/batch - loss: 1633.22954 - diff: 153.05mlTrain batch 28/32 - 172.9ms/batch - loss: 1702.53922 - diff: 155.17mlTrain batch 29/32 - 172.5ms/batch - loss: 1693.76690 - diff: 154.82mlTrain batch 30/32 - 173.1ms/batch - loss: 1713.41694 - diff: 155.84mlTrain batch 31/32 - 173.3ms/batch - loss: 1724.83400 - diff: 156.39mlTrain batch 32/32 - 52.9ms/batch - loss: 1757.14618 - diff: 156.29mlTrain batch 32/32 - 10.5s 52.9ms/batch - loss: 1757.14618 - diff: 156.29ml
Test 1.1s: val_loss: 1409.91072 - diff: 135.65ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_WideResNet50_1_Adam-0.001_MSE_DA3_best

Epoch 2: current best loss = 1409.91072, at epoch 1
Train batch 1/32 - 172.8ms/batch - loss: 1555.97986 - diff: 147.27mlTrain batch 2/32 - 173.3ms/batch - loss: 1882.51508 - diff: 163.35mlTrain batch 3/32 - 172.9ms/batch - loss: 1902.67289 - diff: 165.14mlTrain batch 4/32 - 173.5ms/batch - loss: 1864.27948 - diff: 164.62mlTrain batch 5/32 - 173.1ms/batch - loss: 2126.75679 - diff: 171.56mlTrain batch 6/32 - 173.1ms/batch - loss: 2063.37585 - diff: 169.71mlTrain batch 7/32 - 172.9ms/batch - loss: 1977.44741 - diff: 166.54mlTrain batch 8/32 - 180.3ms/batch - loss: 1878.88968 - diff: 162.30mlTrain batch 9/32 - 173.2ms/batch - loss: 1872.61778 - diff: 162.63mlTrain batch 10/32 - 173.1ms/batch - loss: 1803.95940 - diff: 159.26mlTrain batch 11/32 - 173.0ms/batch - loss: 1794.03612 - diff: 159.23mlTrain batch 12/32 - 172.7ms/batch - loss: 1756.20440 - diff: 157.92mlTrain batch 13/32 - 172.7ms/batch - loss: 1773.66080 - diff: 158.86mlTrain batch 14/32 - 173.3ms/batch - loss: 1757.26601 - diff: 158.06mlTrain batch 15/32 - 173.2ms/batch - loss: 1697.70165 - diff: 155.04mlTrain batch 16/32 - 173.4ms/batch - loss: 1660.77337 - diff: 153.19mlTrain batch 17/32 - 173.5ms/batch - loss: 1650.81405 - diff: 152.32mlTrain batch 18/32 - 173.1ms/batch - loss: 1614.27958 - diff: 150.66mlTrain batch 19/32 - 172.9ms/batch - loss: 1604.48588 - diff: 150.37mlTrain batch 20/32 - 173.1ms/batch - loss: 1591.54573 - diff: 149.96mlTrain batch 21/32 - 173.1ms/batch - loss: 1588.82342 - diff: 150.00mlTrain batch 22/32 - 173.5ms/batch - loss: 1584.04757 - diff: 149.75mlTrain batch 23/32 - 173.2ms/batch - loss: 1569.28389 - diff: 149.00mlTrain batch 24/32 - 173.4ms/batch - loss: 1551.04876 - diff: 148.19mlTrain batch 25/32 - 173.4ms/batch - loss: 1560.20363 - diff: 148.62mlTrain batch 26/32 - 173.4ms/batch - loss: 1552.15807 - diff: 148.22mlTrain batch 27/32 - 173.5ms/batch - loss: 1538.96917 - diff: 147.70mlTrain batch 28/32 - 173.4ms/batch - loss: 1547.08109 - diff: 147.95mlTrain batch 29/32 - 173.3ms/batch - loss: 1533.51406 - diff: 147.37mlTrain batch 30/32 - 173.2ms/batch - loss: 1545.48119 - diff: 147.97mlTrain batch 31/32 - 173.1ms/batch - loss: 1553.89068 - diff: 148.40mlTrain batch 32/32 - 53.0ms/batch - loss: 1572.08353 - diff: 148.17mlTrain batch 32/32 - 10.6s 53.0ms/batch - loss: 1572.08353 - diff: 148.17ml
Test 1.1s: val_loss: 991.62199 - diff: 114.76ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_WideResNet50_1_Adam-0.001_MSE_DA3_best

Epoch 3: current best loss = 991.62199, at epoch 2
Train batch 1/32 - 173.2ms/batch - loss: 1210.30957 - diff: 133.99mlTrain batch 2/32 - 173.4ms/batch - loss: 1536.19006 - diff: 148.12mlTrain batch 3/32 - 173.4ms/batch - loss: 1714.40153 - diff: 148.54mlTrain batch 4/32 - 173.2ms/batch - loss: 1664.11969 - diff: 148.12mlTrain batch 5/32 - 173.0ms/batch - loss: 1577.23193 - diff: 144.87mlTrain batch 6/32 - 172.9ms/batch - loss: 1513.35242 - diff: 143.03mlTrain batch 7/32 - 173.3ms/batch - loss: 1436.31477 - diff: 139.46mlTrain batch 8/32 - 173.6ms/batch - loss: 1388.72464 - diff: 137.55mlTrain batch 9/32 - 173.3ms/batch - loss: 1413.69322 - diff: 139.10mlTrain batch 10/32 - 173.5ms/batch - loss: 1387.76027 - diff: 138.46mlTrain batch 11/32 - 173.8ms/batch - loss: 1424.81148 - diff: 140.45mlTrain batch 12/32 - 174.0ms/batch - loss: 1415.68772 - diff: 140.25mlTrain batch 13/32 - 173.7ms/batch - loss: 1423.74934 - diff: 141.08mlTrain batch 14/32 - 173.0ms/batch - loss: 1426.87942 - diff: 141.71mlTrain batch 15/32 - 173.5ms/batch - loss: 1405.77397 - diff: 140.62mlTrain batch 16/32 - 173.6ms/batch - loss: 1424.31899 - diff: 141.71mlTrain batch 17/32 - 173.8ms/batch - loss: 1425.21061 - diff: 142.04mlTrain batch 18/32 - 173.5ms/batch - loss: 1431.47560 - diff: 142.62mlTrain batch 19/32 - 173.8ms/batch - loss: 1414.13361 - diff: 141.75mlTrain batch 20/32 - 173.4ms/batch - loss: 1420.05867 - diff: 142.26mlTrain batch 21/32 - 173.7ms/batch - loss: 1411.01143 - diff: 141.91mlTrain batch 22/32 - 173.8ms/batch - loss: 1395.98495 - diff: 141.23mlTrain batch 23/32 - 173.5ms/batch - loss: 1373.38604 - diff: 140.03mlTrain batch 24/32 - 173.9ms/batch - loss: 1364.88215 - diff: 139.62mlTrain batch 25/32 - 173.7ms/batch - loss: 1358.65566 - diff: 139.37mlTrain batch 26/32 - 173.8ms/batch - loss: 1345.22042 - diff: 138.78mlTrain batch 27/32 - 173.5ms/batch - loss: 1344.90781 - diff: 138.81mlTrain batch 28/32 - 173.9ms/batch - loss: 1363.03253 - diff: 139.53mlTrain batch 29/32 - 173.4ms/batch - loss: 1349.62268 - diff: 138.81mlTrain batch 30/32 - 173.8ms/batch - loss: 1339.54064 - diff: 138.21mlTrain batch 31/32 - 173.4ms/batch - loss: 1350.26750 - diff: 138.81mlTrain batch 32/32 - 53.0ms/batch - loss: 1368.54677 - diff: 138.66mlTrain batch 32/32 - 10.9s 53.0ms/batch - loss: 1368.54677 - diff: 138.66ml
Test 1.1s: val_loss: 413.67186 - diff: 68.13ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_WideResNet50_1_Adam-0.001_MSE_DA3_best

Epoch 4: current best loss = 413.67186, at epoch 3
Train batch 1/32 - 173.5ms/batch - loss: 1152.82690 - diff: 133.11mlTrain batch 2/32 - 173.9ms/batch - loss: 1168.84662 - diff: 132.86mlTrain batch 3/32 - 173.7ms/batch - loss: 1185.32589 - diff: 133.84mlTrain batch 4/32 - 174.0ms/batch - loss: 1184.00650 - diff: 133.47mlTrain batch 5/32 - 173.7ms/batch - loss: 1187.65071 - diff: 133.58mlTrain batch 6/32 - 173.9ms/batch - loss: 1209.83081 - diff: 133.69mlTrain batch 7/32 - 173.7ms/batch - loss: 1170.71433 - diff: 131.02mlTrain batch 8/32 - 173.9ms/batch - loss: 1149.28855 - diff: 129.90mlTrain batch 9/32 - 173.7ms/batch - loss: 1190.65539 - diff: 132.25mlTrain batch 10/32 - 173.9ms/batch - loss: 1166.39058 - diff: 131.00mlTrain batch 11/32 - 173.8ms/batch - loss: 1152.33691 - diff: 130.33mlTrain batch 12/32 - 173.7ms/batch - loss: 1145.52638 - diff: 129.93mlTrain batch 13/32 - 173.8ms/batch - loss: 1106.35893 - diff: 127.34mlTrain batch 14/32 - 174.0ms/batch - loss: 1113.38703 - diff: 127.63mlTrain batch 15/32 - 173.9ms/batch - loss: 1080.43629 - diff: 125.59mlTrain batch 16/32 - 174.0ms/batch - loss: 1092.17612 - diff: 126.41mlTrain batch 17/32 - 173.7ms/batch - loss: 1108.18581 - diff: 127.42mlTrain batch 18/32 - 173.8ms/batch - loss: 1099.98512 - diff: 126.95mlTrain batch 19/32 - 173.8ms/batch - loss: 1109.14676 - diff: 127.60mlTrain batch 20/32 - 173.9ms/batch - loss: 1103.20653 - diff: 127.09mlTrain batch 21/32 - 173.8ms/batch - loss: 1097.23698 - diff: 126.62mlTrain batch 22/32 - 174.0ms/batch - loss: 1106.62001 - diff: 127.16mlTrain batch 23/32 - 173.9ms/batch - loss: 1099.38388 - diff: 126.77mlTrain batch 24/32 - 173.8ms/batch - loss: 1094.27354 - diff: 126.52mlTrain batch 25/32 - 173.7ms/batch - loss: 1124.09070 - diff: 127.93mlTrain batch 26/32 - 173.9ms/batch - loss: 1139.47860 - diff: 128.86mlTrain batch 27/32 - 173.9ms/batch - loss: 1166.80481 - diff: 129.49mlTrain batch 28/32 - 173.8ms/batch - loss: 1157.36689 - diff: 128.87mlTrain batch 29/32 - 174.1ms/batch - loss: 1157.60299 - diff: 128.89mlTrain batch 30/32 - 173.9ms/batch - loss: 1147.78642 - diff: 128.38mlTrain batch 31/32 - 174.0ms/batch - loss: 1133.50377 - diff: 127.37mlTrain batch 32/32 - 53.2ms/batch - loss: 1181.83002 - diff: 127.62mlTrain batch 32/32 - 11.2s 53.2ms/batch - loss: 1181.83002 - diff: 127.62ml
Test 1.1s: val_loss: 434.84099 - diff: 71.55ml

Epoch 5: current best loss = 413.67186, at epoch 3
Train batch 1/32 - 173.8ms/batch - loss: 883.83203 - diff: 114.03mlTrain batch 2/32 - 174.2ms/batch - loss: 937.52606 - diff: 115.16mlTrain batch 3/32 - 173.7ms/batch - loss: 921.65951 - diff: 114.33mlTrain batch 4/32 - 174.3ms/batch - loss: 1009.71011 - diff: 119.38mlTrain batch 5/32 - 174.1ms/batch - loss: 1042.72620 - diff: 121.97mlTrain batch 6/32 - 174.2ms/batch - loss: 1209.75639 - diff: 128.14mlTrain batch 7/32 - 173.9ms/batch - loss: 1181.17327 - diff: 127.19mlTrain batch 8/32 - 173.9ms/batch - loss: 1142.87958 - diff: 125.45mlTrain batch 9/32 - 174.0ms/batch - loss: 1116.75308 - diff: 124.47mlTrain batch 10/32 - 174.1ms/batch - loss: 1066.28881 - diff: 121.22mlTrain batch 11/32 - 174.0ms/batch - loss: 1083.48934 - diff: 122.60mlTrain batch 12/32 - 174.7ms/batch - loss: 1070.59527 - diff: 122.07mlTrain batch 13/32 - 173.9ms/batch - loss: 1093.02031 - diff: 123.62mlTrain batch 14/32 - 173.7ms/batch - loss: 1090.55571 - diff: 123.60mlTrain batch 15/32 - 174.1ms/batch - loss: 1078.41714 - diff: 122.91mlTrain batch 16/32 - 174.1ms/batch - loss: 1086.11307 - diff: 123.49mlTrain batch 17/32 - 174.2ms/batch - loss: 1056.66831 - diff: 121.34mlTrain batch 18/32 - 174.4ms/batch - loss: 1036.17567 - diff: 120.29mlTrain batch 19/32 - 174.2ms/batch - loss: 1019.98086 - diff: 119.37mlTrain batch 20/32 - 174.2ms/batch - loss: 1004.24887 - diff: 118.55mlTrain batch 21/32 - 174.5ms/batch - loss: 999.32756 - diff: 118.31mlTrain batch 22/32 - 174.5ms/batch - loss: 1005.99861 - diff: 118.75mlTrain batch 23/32 - 174.1ms/batch - loss: 995.37722 - diff: 118.29mlTrain batch 24/32 - 174.3ms/batch - loss: 994.85576 - diff: 118.24mlTrain batch 25/32 - 174.2ms/batch - loss: 980.61682 - diff: 117.43mlTrain batch 26/32 - 174.4ms/batch - loss: 973.07495 - diff: 116.92mlTrain batch 27/32 - 174.2ms/batch - loss: 968.31864 - diff: 116.68mlTrain batch 28/32 - 174.1ms/batch - loss: 960.99177 - diff: 116.13mlTrain batch 29/32 - 174.3ms/batch - loss: 966.42804 - diff: 116.30mlTrain batch 30/32 - 174.3ms/batch - loss: 953.53081 - diff: 115.45mlTrain batch 31/32 - 174.0ms/batch - loss: 954.52494 - diff: 115.64mlTrain batch 32/32 - 53.6ms/batch - loss: 966.64879 - diff: 115.50mlTrain batch 32/32 - 10.7s 53.6ms/batch - loss: 966.64879 - diff: 115.50ml
Test 1.1s: val_loss: 107.72883 - diff: 31.38ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_WideResNet50_1_Adam-0.001_MSE_DA3_best

Epoch 6: current best loss = 107.72883, at epoch 5
Train batch 1/32 - 174.3ms/batch - loss: 967.12469 - diff: 118.48mlTrain batch 2/32 - 174.0ms/batch - loss: 920.13892 - diff: 115.32mlTrain batch 3/32 - 174.5ms/batch - loss: 910.76298 - diff: 114.34mlTrain batch 4/32 - 174.5ms/batch - loss: 819.80077 - diff: 107.72mlTrain batch 5/32 - 174.4ms/batch - loss: 766.37865 - diff: 103.46mlTrain batch 6/32 - 174.5ms/batch - loss: 751.10150 - diff: 102.66mlTrain batch 7/32 - 174.4ms/batch - loss: 799.44088 - diff: 106.09mlTrain batch 8/32 - 174.3ms/batch - loss: 812.29527 - diff: 106.81mlTrain batch 9/32 - 174.2ms/batch - loss: 811.71111 - diff: 107.31mlTrain batch 10/32 - 174.6ms/batch - loss: 828.94263 - diff: 108.69mlTrain batch 11/32 - 174.4ms/batch - loss: 836.16110 - diff: 108.28mlTrain batch 12/32 - 173.9ms/batch - loss: 831.45186 - diff: 107.94mlTrain batch 13/32 - 174.2ms/batch - loss: 830.09484 - diff: 108.08mlTrain batch 14/32 - 174.5ms/batch - loss: 814.49946 - diff: 106.95mlTrain batch 15/32 - 174.2ms/batch - loss: 813.87627 - diff: 106.87mlTrain batch 16/32 - 174.4ms/batch - loss: 811.53102 - diff: 106.91mlTrain batch 17/32 - 174.3ms/batch - loss: 815.50465 - diff: 107.22mlTrain batch 18/32 - 174.5ms/batch - loss: 811.96851 - diff: 107.09mlTrain batch 19/32 - 174.3ms/batch - loss: 808.57334 - diff: 106.93mlTrain batch 20/32 - 174.7ms/batch - loss: 793.00627 - diff: 105.83mlTrain batch 21/32 - 174.3ms/batch - loss: 789.35880 - diff: 105.68mlTrain batch 22/32 - 174.5ms/batch - loss: 785.70676 - diff: 105.55mlTrain batch 23/32 - 174.2ms/batch - loss: 815.60972 - diff: 106.70mlTrain batch 24/32 - 174.6ms/batch - loss: 808.53586 - diff: 106.26mlTrain batch 25/32 - 174.3ms/batch - loss: 792.67419 - diff: 104.69mlTrain batch 26/32 - 174.8ms/batch - loss: 785.39865 - diff: 104.23mlTrain batch 27/32 - 174.4ms/batch - loss: 787.40433 - diff: 104.46mlTrain batch 28/32 - 174.3ms/batch - loss: 784.36995 - diff: 104.22mlTrain batch 29/32 - 174.3ms/batch - loss: 770.52855 - diff: 103.17mlTrain batch 30/32 - 174.9ms/batch - loss: 769.23626 - diff: 103.13mlTrain batch 31/32 - 174.3ms/batch - loss: 762.73352 - diff: 102.79mlTrain batch 32/32 - 53.3ms/batch - loss: 767.69340 - diff: 102.50mlTrain batch 32/32 - 11.1s 53.3ms/batch - loss: 767.69340 - diff: 102.50ml
Test 1.1s: val_loss: 101.53151 - diff: 29.64ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_WideResNet50_1_Adam-0.001_MSE_DA3_best

Epoch 7: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 174.4ms/batch - loss: 364.22729 - diff: 73.37mlTrain batch 2/32 - 174.6ms/batch - loss: 522.82602 - diff: 87.27mlTrain batch 3/32 - 174.4ms/batch - loss: 546.12915 - diff: 88.18mlTrain batch 4/32 - 174.2ms/batch - loss: 531.28920 - diff: 86.83mlTrain batch 5/32 - 174.5ms/batch - loss: 554.96801 - diff: 89.05mlTrain batch 6/32 - 174.5ms/batch - loss: 576.54721 - diff: 91.14mlTrain batch 7/32 - 174.3ms/batch - loss: 617.04676 - diff: 93.85mlTrain batch 8/32 - 174.6ms/batch - loss: 623.66209 - diff: 94.69mlTrain batch 9/32 - 174.2ms/batch - loss: 667.64505 - diff: 97.67mlTrain batch 10/32 - 174.9ms/batch - loss: 638.69026 - diff: 94.93mlTrain batch 11/32 - 174.5ms/batch - loss: 630.23349 - diff: 93.90mlTrain batch 12/32 - 174.7ms/batch - loss: 634.91084 - diff: 93.84mlTrain batch 13/32 - 174.3ms/batch - loss: 690.68443 - diff: 97.06mlTrain batch 14/32 - 174.4ms/batch - loss: 686.90704 - diff: 96.84mlTrain batch 15/32 - 174.2ms/batch - loss: 707.92206 - diff: 98.14mlTrain batch 16/32 - 174.5ms/batch - loss: 703.22733 - diff: 97.71mlTrain batch 17/32 - 174.3ms/batch - loss: 694.71230 - diff: 97.17mlTrain batch 18/32 - 173.8ms/batch - loss: 695.58698 - diff: 97.43mlTrain batch 19/32 - 174.4ms/batch - loss: 687.09478 - diff: 96.94mlTrain batch 20/32 - 174.8ms/batch - loss: 671.34671 - diff: 95.52mlTrain batch 21/32 - 174.3ms/batch - loss: 655.07998 - diff: 94.07mlTrain batch 22/32 - 174.6ms/batch - loss: 642.56671 - diff: 92.99mlTrain batch 23/32 - 174.6ms/batch - loss: 638.75252 - diff: 92.88mlTrain batch 24/32 - 173.7ms/batch - loss: 639.16847 - diff: 93.06mlTrain batch 25/32 - 174.7ms/batch - loss: 637.42109 - diff: 93.17mlTrain batch 26/32 - 174.6ms/batch - loss: 634.12976 - diff: 92.80mlTrain batch 27/32 - 174.5ms/batch - loss: 628.48870 - diff: 92.35mlTrain batch 28/32 - 175.2ms/batch - loss: 631.50031 - diff: 92.71mlTrain batch 29/32 - 174.3ms/batch - loss: 626.43320 - diff: 92.33mlTrain batch 30/32 - 174.7ms/batch - loss: 615.29028 - diff: 91.29mlTrain batch 31/32 - 174.1ms/batch - loss: 607.02349 - diff: 90.64mlTrain batch 32/32 - 53.2ms/batch - loss: 604.22001 - diff: 90.15mlTrain batch 32/32 - 11.7s 53.2ms/batch - loss: 604.22001 - diff: 90.15ml
Test 1.1s: val_loss: 131.58738 - diff: 36.78ml

Epoch 8: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 174.5ms/batch - loss: 505.39569 - diff: 83.38mlTrain batch 2/32 - 174.7ms/batch - loss: 701.67319 - diff: 96.70mlTrain batch 3/32 - 174.5ms/batch - loss: 577.61528 - diff: 86.50mlTrain batch 4/32 - 174.5ms/batch - loss: 586.59828 - diff: 88.17mlTrain batch 5/32 - 174.4ms/batch - loss: 564.75208 - diff: 87.11mlTrain batch 6/32 - 174.4ms/batch - loss: 560.73559 - diff: 87.48mlTrain batch 7/32 - 174.5ms/batch - loss: 574.12579 - diff: 87.07mlTrain batch 8/32 - 174.6ms/batch - loss: 557.66031 - diff: 85.81mlTrain batch 9/32 - 174.3ms/batch - loss: 551.77930 - diff: 85.45mlTrain batch 10/32 - 175.0ms/batch - loss: 531.88708 - diff: 83.88mlTrain batch 11/32 - 174.3ms/batch - loss: 510.43373 - diff: 82.20mlTrain batch 12/32 - 175.1ms/batch - loss: 521.31677 - diff: 83.31mlTrain batch 13/32 - 174.5ms/batch - loss: 525.02207 - diff: 83.92mlTrain batch 14/32 - 173.8ms/batch - loss: 512.95963 - diff: 82.70mlTrain batch 15/32 - 174.6ms/batch - loss: 522.39203 - diff: 83.49mlTrain batch 16/32 - 174.5ms/batch - loss: 519.71552 - diff: 83.45mlTrain batch 17/32 - 174.5ms/batch - loss: 517.66577 - diff: 83.21mlTrain batch 18/32 - 174.7ms/batch - loss: 511.00308 - diff: 82.70mlTrain batch 19/32 - 174.5ms/batch - loss: 503.79918 - diff: 82.00mlTrain batch 20/32 - 174.6ms/batch - loss: 493.64229 - diff: 81.14mlTrain batch 21/32 - 174.5ms/batch - loss: 481.23165 - diff: 79.73mlTrain batch 22/32 - 175.1ms/batch - loss: 495.52760 - diff: 80.43mlTrain batch 23/32 - 174.6ms/batch - loss: 492.09725 - diff: 79.94mlTrain batch 24/32 - 175.1ms/batch - loss: 488.35352 - diff: 79.63mlTrain batch 25/32 - 174.7ms/batch - loss: 478.67801 - diff: 78.81mlTrain batch 26/32 - 174.9ms/batch - loss: 478.03124 - diff: 78.77mlTrain batch 27/32 - 174.5ms/batch - loss: 478.78708 - diff: 78.99mlTrain batch 28/32 - 174.8ms/batch - loss: 472.40357 - diff: 78.16mlTrain batch 29/32 - 174.2ms/batch - loss: 473.67403 - diff: 78.25mlTrain batch 30/32 - 174.5ms/batch - loss: 465.38228 - diff: 77.44mlTrain batch 31/32 - 174.7ms/batch - loss: 463.79037 - diff: 77.35mlTrain batch 32/32 - 53.4ms/batch - loss: 464.11626 - diff: 77.03mlTrain batch 32/32 - 11.7s 53.4ms/batch - loss: 464.11626 - diff: 77.03ml
Test 1.1s: val_loss: 114.17972 - diff: 34.16ml

Epoch 9: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 175.2ms/batch - loss: 297.56470 - diff: 62.61mlTrain batch 2/32 - 175.0ms/batch - loss: 383.99889 - diff: 66.81mlTrain batch 3/32 - 174.9ms/batch - loss: 504.40203 - diff: 73.48mlTrain batch 4/32 - 174.9ms/batch - loss: 460.27395 - diff: 71.25mlTrain batch 5/32 - 174.7ms/batch - loss: 455.48881 - diff: 72.16mlTrain batch 6/32 - 175.1ms/batch - loss: 451.22864 - diff: 72.73mlTrain batch 7/32 - 174.8ms/batch - loss: 413.50861 - diff: 69.28mlTrain batch 8/32 - 175.0ms/batch - loss: 387.11368 - diff: 66.73mlTrain batch 9/32 - 175.0ms/batch - loss: 381.06505 - diff: 66.54mlTrain batch 10/32 - 175.2ms/batch - loss: 380.79061 - diff: 66.22mlTrain batch 11/32 - 174.9ms/batch - loss: 391.70137 - diff: 67.73mlTrain batch 12/32 - 175.1ms/batch - loss: 406.46648 - diff: 69.32mlTrain batch 13/32 - 175.0ms/batch - loss: 413.89218 - diff: 70.14mlTrain batch 14/32 - 175.1ms/batch - loss: 416.59977 - diff: 70.93mlTrain batch 15/32 - 174.8ms/batch - loss: 421.13815 - diff: 71.69mlTrain batch 16/32 - 175.2ms/batch - loss: 407.53878 - diff: 70.41mlTrain batch 17/32 - 174.8ms/batch - loss: 401.18110 - diff: 69.71mlTrain batch 18/32 - 175.1ms/batch - loss: 394.29111 - diff: 69.13mlTrain batch 19/32 - 175.1ms/batch - loss: 392.16817 - diff: 68.98mlTrain batch 20/32 - 175.0ms/batch - loss: 381.95890 - diff: 68.05mlTrain batch 21/32 - 175.0ms/batch - loss: 376.50093 - diff: 67.62mlTrain batch 22/32 - 175.3ms/batch - loss: 387.28175 - diff: 68.77mlTrain batch 23/32 - 175.0ms/batch - loss: 383.14635 - diff: 68.54mlTrain batch 24/32 - 175.1ms/batch - loss: 377.66277 - diff: 68.04mlTrain batch 25/32 - 174.7ms/batch - loss: 382.92747 - diff: 68.61mlTrain batch 26/32 - 175.2ms/batch - loss: 379.31706 - diff: 68.11mlTrain batch 27/32 - 175.0ms/batch - loss: 374.58678 - diff: 67.52mlTrain batch 28/32 - 175.2ms/batch - loss: 373.36529 - diff: 67.56mlTrain batch 29/32 - 174.8ms/batch - loss: 369.03679 - diff: 67.01mlTrain batch 30/32 - 175.1ms/batch - loss: 361.50056 - diff: 66.07mlTrain batch 31/32 - 174.8ms/batch - loss: 353.23067 - diff: 65.03mlTrain batch 32/32 - 53.6ms/batch - loss: 354.00844 - diff: 64.84mlTrain batch 32/32 - 10.6s 53.6ms/batch - loss: 354.00844 - diff: 64.84ml
Test 1.1s: val_loss: 178.03540 - diff: 44.57ml

Epoch 10: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 175.2ms/batch - loss: 437.99512 - diff: 69.68mlTrain batch 2/32 - 175.4ms/batch - loss: 354.12415 - diff: 63.32mlTrain batch 3/32 - 175.1ms/batch - loss: 363.43892 - diff: 64.71mlTrain batch 4/32 - 175.3ms/batch - loss: 326.55194 - diff: 60.99mlTrain batch 5/32 - 175.1ms/batch - loss: 287.58617 - diff: 56.18mlTrain batch 6/32 - 175.0ms/batch - loss: 286.55789 - diff: 56.85mlTrain batch 7/32 - 175.1ms/batch - loss: 280.98459 - diff: 55.56mlTrain batch 8/32 - 175.1ms/batch - loss: 313.27727 - diff: 59.05mlTrain batch 9/32 - 175.0ms/batch - loss: 299.57486 - diff: 57.80mlTrain batch 10/32 - 175.3ms/batch - loss: 294.66795 - diff: 57.35mlTrain batch 11/32 - 175.0ms/batch - loss: 292.57993 - diff: 57.40mlTrain batch 12/32 - 175.0ms/batch - loss: 285.13126 - diff: 56.75mlTrain batch 13/32 - 175.1ms/batch - loss: 279.53312 - diff: 56.26mlTrain batch 14/32 - 174.9ms/batch - loss: 270.73665 - diff: 55.25mlTrain batch 15/32 - 174.9ms/batch - loss: 313.53009 - diff: 58.04mlTrain batch 16/32 - 174.9ms/batch - loss: 307.93472 - diff: 57.39mlTrain batch 17/32 - 174.9ms/batch - loss: 304.91963 - diff: 57.36mlTrain batch 18/32 - 175.2ms/batch - loss: 313.52833 - diff: 58.46mlTrain batch 19/32 - 174.9ms/batch - loss: 316.67035 - diff: 59.02mlTrain batch 20/32 - 175.1ms/batch - loss: 321.05391 - diff: 59.64mlTrain batch 21/32 - 175.1ms/batch - loss: 314.98540 - diff: 59.14mlTrain batch 22/32 - 175.4ms/batch - loss: 304.68628 - diff: 57.88mlTrain batch 23/32 - 175.0ms/batch - loss: 298.16297 - diff: 57.20mlTrain batch 24/32 - 175.6ms/batch - loss: 294.54295 - diff: 56.93mlTrain batch 25/32 - 175.0ms/batch - loss: 288.51836 - diff: 56.17mlTrain batch 26/32 - 175.3ms/batch - loss: 283.81473 - diff: 55.51mlTrain batch 27/32 - 175.0ms/batch - loss: 278.31254 - diff: 54.84mlTrain batch 28/32 - 175.1ms/batch - loss: 272.12580 - diff: 54.01mlTrain batch 29/32 - 175.0ms/batch - loss: 270.02409 - diff: 53.78mlTrain batch 30/32 - 175.0ms/batch - loss: 273.37429 - diff: 54.34mlTrain batch 31/32 - 175.0ms/batch - loss: 275.46010 - diff: 54.72mlTrain batch 32/32 - 53.7ms/batch - loss: 280.54149 - diff: 54.69mlTrain batch 32/32 - 11.5s 53.7ms/batch - loss: 280.54149 - diff: 54.69ml
Test 1.1s: val_loss: 511.57233 - diff: 79.57ml

Epoch 11: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 175.2ms/batch - loss: 254.85390 - diff: 57.26mlTrain batch 2/32 - 175.3ms/batch - loss: 382.58610 - diff: 68.25mlTrain batch 3/32 - 175.2ms/batch - loss: 353.20285 - diff: 66.12mlTrain batch 4/32 - 175.0ms/batch - loss: 331.62905 - diff: 63.85mlTrain batch 5/32 - 175.1ms/batch - loss: 293.31134 - diff: 58.67mlTrain batch 6/32 - 175.2ms/batch - loss: 281.53072 - diff: 57.41mlTrain batch 7/32 - 175.1ms/batch - loss: 335.47575 - diff: 60.70mlTrain batch 8/32 - 175.2ms/batch - loss: 305.83620 - diff: 57.52mlTrain batch 9/32 - 175.1ms/batch - loss: 295.06605 - diff: 56.15mlTrain batch 10/32 - 175.3ms/batch - loss: 279.94365 - diff: 54.77mlTrain batch 11/32 - 175.1ms/batch - loss: 278.05097 - diff: 54.51mlTrain batch 12/32 - 175.3ms/batch - loss: 263.45089 - diff: 52.61mlTrain batch 13/32 - 175.2ms/batch - loss: 259.31793 - diff: 52.34mlTrain batch 14/32 - 175.2ms/batch - loss: 251.76550 - diff: 51.80mlTrain batch 15/32 - 175.0ms/batch - loss: 240.70643 - diff: 50.37mlTrain batch 16/32 - 175.3ms/batch - loss: 234.91274 - diff: 49.94mlTrain batch 17/32 - 175.1ms/batch - loss: 227.96750 - diff: 49.15mlTrain batch 18/32 - 175.4ms/batch - loss: 232.83421 - diff: 49.48mlTrain batch 19/32 - 175.0ms/batch - loss: 228.35717 - diff: 48.97mlTrain batch 20/32 - 175.0ms/batch - loss: 227.40995 - diff: 48.81mlTrain batch 21/32 - 175.0ms/batch - loss: 222.62319 - diff: 48.14mlTrain batch 22/32 - 175.3ms/batch - loss: 217.06406 - diff: 47.36mlTrain batch 23/32 - 175.1ms/batch - loss: 212.78383 - diff: 46.83mlTrain batch 24/32 - 175.1ms/batch - loss: 215.75255 - diff: 47.20mlTrain batch 25/32 - 175.4ms/batch - loss: 212.38927 - diff: 46.81mlTrain batch 26/32 - 175.5ms/batch - loss: 210.23086 - diff: 46.73mlTrain batch 27/32 - 175.2ms/batch - loss: 214.29537 - diff: 47.46mlTrain batch 28/32 - 175.2ms/batch - loss: 215.64849 - diff: 47.75mlTrain batch 29/32 - 175.2ms/batch - loss: 209.57308 - diff: 46.85mlTrain batch 30/32 - 175.3ms/batch - loss: 206.24953 - diff: 46.37mlTrain batch 31/32 - 175.0ms/batch - loss: 204.52136 - diff: 46.29mlTrain batch 32/32 - 53.6ms/batch - loss: 204.80931 - diff: 46.14mlTrain batch 32/32 - 11.2s 53.6ms/batch - loss: 204.80931 - diff: 46.14ml
Test 1.1s: val_loss: 776.40831 - diff: 101.34ml

Epoch 12: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 175.3ms/batch - loss: 105.69923 - diff: 32.65mlTrain batch 2/32 - 175.2ms/batch - loss: 335.88211 - diff: 49.60mlTrain batch 3/32 - 175.2ms/batch - loss: 277.26107 - diff: 46.75mlTrain batch 4/32 - 175.5ms/batch - loss: 263.72254 - diff: 48.22mlTrain batch 5/32 - 175.1ms/batch - loss: 237.57469 - diff: 46.49mlTrain batch 6/32 - 175.5ms/batch - loss: 256.20578 - diff: 49.43mlTrain batch 7/32 - 175.1ms/batch - loss: 257.36369 - diff: 50.28mlTrain batch 8/32 - 174.9ms/batch - loss: 242.56223 - diff: 49.15mlTrain batch 9/32 - 174.8ms/batch - loss: 235.37169 - diff: 48.46mlTrain batch 10/32 - 175.2ms/batch - loss: 235.06849 - diff: 49.11mlTrain batch 11/32 - 175.2ms/batch - loss: 227.99364 - diff: 48.43mlTrain batch 12/32 - 175.0ms/batch - loss: 219.55406 - diff: 47.73mlTrain batch 13/32 - 175.3ms/batch - loss: 212.37347 - diff: 46.70mlTrain batch 14/32 - 175.3ms/batch - loss: 216.36329 - diff: 47.62mlTrain batch 15/32 - 175.1ms/batch - loss: 211.88344 - diff: 46.89mlTrain batch 16/32 - 174.9ms/batch - loss: 202.89015 - diff: 45.58mlTrain batch 17/32 - 175.0ms/batch - loss: 198.95409 - diff: 45.46mlTrain batch 18/32 - 175.4ms/batch - loss: 191.35512 - diff: 44.28mlTrain batch 19/32 - 175.3ms/batch - loss: 188.81826 - diff: 44.07mlTrain batch 20/32 - 175.0ms/batch - loss: 183.57901 - diff: 43.31mlTrain batch 21/32 - 175.0ms/batch - loss: 184.26775 - diff: 42.69mlTrain batch 22/32 - 175.0ms/batch - loss: 181.25956 - diff: 42.21mlTrain batch 23/32 - 175.1ms/batch - loss: 178.65071 - diff: 42.00mlTrain batch 24/32 - 175.5ms/batch - loss: 177.03068 - diff: 41.69mlTrain batch 25/32 - 175.3ms/batch - loss: 176.15278 - diff: 41.81mlTrain batch 26/32 - 175.0ms/batch - loss: 171.57619 - diff: 41.18mlTrain batch 27/32 - 174.8ms/batch - loss: 170.46961 - diff: 41.15mlTrain batch 28/32 - 175.4ms/batch - loss: 167.00573 - diff: 40.71mlTrain batch 29/32 - 175.0ms/batch - loss: 163.91756 - diff: 40.30mlTrain batch 30/32 - 175.1ms/batch - loss: 161.73469 - diff: 40.01mlTrain batch 31/32 - 175.0ms/batch - loss: 160.12617 - diff: 39.85mlTrain batch 32/32 - 53.6ms/batch - loss: 162.78392 - diff: 39.83mlTrain batch 32/32 - 11.0s 53.6ms/batch - loss: 162.78392 - diff: 39.83ml
Test 1.1s: val_loss: 292.28453 - diff: 59.79ml

Epoch 13: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 175.3ms/batch - loss: 69.79048 - diff: 26.07mlTrain batch 2/32 - 175.8ms/batch - loss: 213.91509 - diff: 45.07mlTrain batch 3/32 - 175.0ms/batch - loss: 186.49354 - diff: 43.31mlTrain batch 4/32 - 175.6ms/batch - loss: 149.46741 - diff: 37.32mlTrain batch 5/32 - 175.3ms/batch - loss: 135.67514 - diff: 35.23mlTrain batch 6/32 - 175.4ms/batch - loss: 139.58610 - diff: 36.28mlTrain batch 7/32 - 175.2ms/batch - loss: 156.94650 - diff: 38.92mlTrain batch 8/32 - 175.4ms/batch - loss: 145.45004 - diff: 37.47mlTrain batch 9/32 - 175.3ms/batch - loss: 136.44205 - diff: 36.44mlTrain batch 10/32 - 175.2ms/batch - loss: 128.54782 - diff: 35.36mlTrain batch 11/32 - 175.2ms/batch - loss: 125.17096 - diff: 35.00mlTrain batch 12/32 - 175.6ms/batch - loss: 120.75928 - diff: 34.37mlTrain batch 13/32 - 175.1ms/batch - loss: 116.19815 - diff: 33.81mlTrain batch 14/32 - 175.6ms/batch - loss: 115.18202 - diff: 33.72mlTrain batch 15/32 - 175.5ms/batch - loss: 117.12842 - diff: 34.21mlTrain batch 16/32 - 175.9ms/batch - loss: 123.63545 - diff: 35.06mlTrain batch 17/32 - 175.4ms/batch - loss: 124.92983 - diff: 35.43mlTrain batch 18/32 - 174.6ms/batch - loss: 122.76845 - diff: 35.04mlTrain batch 19/32 - 175.0ms/batch - loss: 121.26145 - diff: 34.90mlTrain batch 20/32 - 174.7ms/batch - loss: 124.93855 - diff: 34.99mlTrain batch 21/32 - 175.2ms/batch - loss: 124.09744 - diff: 35.04mlTrain batch 22/32 - 175.5ms/batch - loss: 120.79786 - diff: 34.53mlTrain batch 23/32 - 175.1ms/batch - loss: 118.20290 - diff: 34.09mlTrain batch 24/32 - 175.5ms/batch - loss: 128.24219 - diff: 34.70mlTrain batch 25/32 - 175.0ms/batch - loss: 128.33869 - diff: 34.81mlTrain batch 26/32 - 174.6ms/batch - loss: 125.57392 - diff: 34.43mlTrain batch 27/32 - 175.2ms/batch - loss: 124.43755 - diff: 34.29mlTrain batch 28/32 - 175.2ms/batch - loss: 122.51193 - diff: 34.17mlTrain batch 29/32 - 175.1ms/batch - loss: 123.56620 - diff: 34.46mlTrain batch 30/32 - 175.2ms/batch - loss: 121.69671 - diff: 34.08mlTrain batch 31/32 - 175.0ms/batch - loss: 119.76259 - diff: 33.73mlTrain batch 32/32 - 53.6ms/batch - loss: 120.40738 - diff: 33.67mlTrain batch 32/32 - 11.9s 53.6ms/batch - loss: 120.40738 - diff: 33.67ml
Test 1.1s: val_loss: 293.91190 - diff: 59.97ml

Epoch 14: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 175.2ms/batch - loss: 132.72906 - diff: 35.38mlTrain batch 2/32 - 175.6ms/batch - loss: 128.42873 - diff: 34.60mlTrain batch 3/32 - 175.4ms/batch - loss: 142.22694 - diff: 37.05mlTrain batch 4/32 - 175.2ms/batch - loss: 117.28663 - diff: 33.25mlTrain batch 5/32 - 175.6ms/batch - loss: 107.71620 - diff: 31.78mlTrain batch 6/32 - 175.5ms/batch - loss: 96.88942 - diff: 29.85mlTrain batch 7/32 - 174.8ms/batch - loss: 111.56293 - diff: 32.19mlTrain batch 8/32 - 175.2ms/batch - loss: 120.76197 - diff: 32.67mlTrain batch 9/32 - 175.1ms/batch - loss: 129.97062 - diff: 34.53mlTrain batch 10/32 - 175.8ms/batch - loss: 134.13583 - diff: 35.61mlTrain batch 11/32 - 175.5ms/batch - loss: 127.57263 - diff: 34.89mlTrain batch 12/32 - 175.3ms/batch - loss: 121.74268 - diff: 33.87mlTrain batch 13/32 - 175.4ms/batch - loss: 119.94171 - diff: 33.78mlTrain batch 14/32 - 175.2ms/batch - loss: 114.96316 - diff: 32.75mlTrain batch 15/32 - 175.4ms/batch - loss: 111.04454 - diff: 32.15mlTrain batch 16/32 - 175.6ms/batch - loss: 112.13011 - diff: 32.44mlTrain batch 17/32 - 175.2ms/batch - loss: 110.29941 - diff: 32.36mlTrain batch 18/32 - 175.8ms/batch - loss: 108.45999 - diff: 32.26mlTrain batch 19/32 - 175.4ms/batch - loss: 106.83902 - diff: 32.10mlTrain batch 20/32 - 175.7ms/batch - loss: 117.89607 - diff: 32.78mlTrain batch 21/32 - 175.5ms/batch - loss: 119.70179 - diff: 33.19mlTrain batch 22/32 - 175.3ms/batch - loss: 116.84414 - diff: 32.84mlTrain batch 23/32 - 175.2ms/batch - loss: 116.21676 - diff: 32.77mlTrain batch 24/32 - 175.5ms/batch - loss: 116.34878 - diff: 32.96mlTrain batch 25/32 - 175.7ms/batch - loss: 115.65507 - diff: 32.71mlTrain batch 26/32 - 175.2ms/batch - loss: 114.91829 - diff: 32.66mlTrain batch 27/32 - 175.8ms/batch - loss: 114.91628 - diff: 32.63mlTrain batch 28/32 - 175.6ms/batch - loss: 112.10619 - diff: 32.12mlTrain batch 29/32 - 175.5ms/batch - loss: 111.27706 - diff: 32.11mlTrain batch 30/32 - 175.1ms/batch - loss: 113.46962 - diff: 32.44mlTrain batch 31/32 - 175.3ms/batch - loss: 111.01038 - diff: 32.03mlTrain batch 32/32 - 53.6ms/batch - loss: 113.40347 - diff: 32.03mlTrain batch 32/32 - 11.2s 53.6ms/batch - loss: 113.40347 - diff: 32.03ml
Test 1.1s: val_loss: 1199.82887 - diff: 128.11ml

Epoch 15: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 175.5ms/batch - loss: 71.06928 - diff: 26.72mlTrain batch 2/32 - 175.7ms/batch - loss: 93.66914 - diff: 27.29mlTrain batch 3/32 - 175.3ms/batch - loss: 115.82661 - diff: 32.84mlTrain batch 4/32 - 175.3ms/batch - loss: 109.01147 - diff: 31.19mlTrain batch 5/32 - 175.6ms/batch - loss: 169.01317 - diff: 35.96mlTrain batch 6/32 - 175.6ms/batch - loss: 160.33407 - diff: 36.19mlTrain batch 7/32 - 175.2ms/batch - loss: 157.57597 - diff: 37.03mlTrain batch 8/32 - 175.5ms/batch - loss: 145.25754 - diff: 35.34mlTrain batch 9/32 - 175.4ms/batch - loss: 139.15187 - diff: 34.96mlTrain batch 10/32 - 175.7ms/batch - loss: 134.68323 - diff: 34.68mlTrain batch 11/32 - 175.4ms/batch - loss: 125.69726 - diff: 33.40mlTrain batch 12/32 - 175.6ms/batch - loss: 124.74599 - diff: 33.50mlTrain batch 13/32 - 175.4ms/batch - loss: 123.71535 - diff: 33.51mlTrain batch 14/32 - 175.4ms/batch - loss: 118.61860 - diff: 32.84mlTrain batch 15/32 - 175.2ms/batch - loss: 117.13597 - diff: 32.69mlTrain batch 16/32 - 175.2ms/batch - loss: 118.08773 - diff: 32.88mlTrain batch 17/32 - 175.4ms/batch - loss: 117.59115 - diff: 32.59mlTrain batch 18/32 - 175.4ms/batch - loss: 113.99383 - diff: 31.99mlTrain batch 19/32 - 175.6ms/batch - loss: 111.77685 - diff: 31.70mlTrain batch 20/32 - 175.2ms/batch - loss: 111.21489 - diff: 31.70mlTrain batch 21/32 - 175.7ms/batch - loss: 110.68950 - diff: 31.82mlTrain batch 22/32 - 175.3ms/batch - loss: 110.90775 - diff: 31.95mlTrain batch 23/32 - 175.7ms/batch - loss: 108.23229 - diff: 31.55mlTrain batch 24/32 - 175.4ms/batch - loss: 106.55528 - diff: 31.36mlTrain batch 25/32 - 175.6ms/batch - loss: 105.76763 - diff: 31.33mlTrain batch 26/32 - 175.6ms/batch - loss: 104.77600 - diff: 31.18mlTrain batch 27/32 - 175.5ms/batch - loss: 103.47971 - diff: 30.89mlTrain batch 28/32 - 175.3ms/batch - loss: 103.63912 - diff: 30.95mlTrain batch 29/32 - 175.5ms/batch - loss: 102.85758 - diff: 30.92mlTrain batch 30/32 - 175.5ms/batch - loss: 101.93987 - diff: 30.77mlTrain batch 31/32 - 175.5ms/batch - loss: 101.15339 - diff: 30.75mlTrain batch 32/32 - 53.8ms/batch - loss: 100.92764 - diff: 30.62mlTrain batch 32/32 - 11.6s 53.8ms/batch - loss: 100.92764 - diff: 30.62ml
Test 1.1s: val_loss: 604.17499 - diff: 87.63ml

Epoch 16: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 175.1ms/batch - loss: 83.47498 - diff: 30.41mlTrain batch 2/32 - 182.0ms/batch - loss: 90.81470 - diff: 31.61mlTrain batch 3/32 - 175.8ms/batch - loss: 74.09284 - diff: 27.78mlTrain batch 4/32 - 175.9ms/batch - loss: 82.71604 - diff: 28.63mlTrain batch 5/32 - 175.7ms/batch - loss: 83.01046 - diff: 28.55mlTrain batch 6/32 - 176.1ms/batch - loss: 81.90328 - diff: 28.65mlTrain batch 7/32 - 175.8ms/batch - loss: 75.24163 - diff: 27.59mlTrain batch 8/32 - 176.0ms/batch - loss: 71.58849 - diff: 26.77mlTrain batch 9/32 - 175.6ms/batch - loss: 77.08380 - diff: 27.30mlTrain batch 10/32 - 176.1ms/batch - loss: 74.37640 - diff: 26.92mlTrain batch 11/32 - 175.8ms/batch - loss: 73.94982 - diff: 26.76mlTrain batch 12/32 - 175.9ms/batch - loss: 73.72283 - diff: 26.87mlTrain batch 13/32 - 176.0ms/batch - loss: 76.48906 - diff: 27.45mlTrain batch 14/32 - 175.9ms/batch - loss: 77.85588 - diff: 28.03mlTrain batch 15/32 - 175.8ms/batch - loss: 78.58954 - diff: 28.25mlTrain batch 16/32 - 175.9ms/batch - loss: 77.50722 - diff: 27.91mlTrain batch 17/32 - 176.1ms/batch - loss: 80.16084 - diff: 28.34mlTrain batch 18/32 - 175.9ms/batch - loss: 82.01269 - diff: 28.42mlTrain batch 19/32 - 176.0ms/batch - loss: 80.89038 - diff: 28.31mlTrain batch 20/32 - 175.9ms/batch - loss: 79.57416 - diff: 28.07mlTrain batch 21/32 - 176.0ms/batch - loss: 78.68182 - diff: 28.02mlTrain batch 22/32 - 175.6ms/batch - loss: 77.28074 - diff: 27.80mlTrain batch 23/32 - 176.1ms/batch - loss: 76.14050 - diff: 27.64mlTrain batch 24/32 - 175.7ms/batch - loss: 74.17244 - diff: 27.26mlTrain batch 25/32 - 176.0ms/batch - loss: 75.60367 - diff: 27.41mlTrain batch 26/32 - 175.7ms/batch - loss: 77.00125 - diff: 27.64mlTrain batch 27/32 - 175.8ms/batch - loss: 80.12820 - diff: 27.98mlTrain batch 28/32 - 175.8ms/batch - loss: 79.46534 - diff: 27.90mlTrain batch 29/32 - 176.1ms/batch - loss: 77.68716 - diff: 27.44mlTrain batch 30/32 - 176.0ms/batch - loss: 77.75047 - diff: 27.49mlTrain batch 31/32 - 175.9ms/batch - loss: 86.30249 - diff: 28.16mlTrain batch 32/32 - 54.1ms/batch - loss: 88.16944 - diff: 28.14mlTrain batch 32/32 - 11.0s 54.1ms/batch - loss: 88.16944 - diff: 28.14ml
Test 1.1s: val_loss: 576.73405 - diff: 87.63ml

Epoch 17: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 178.8ms/batch - loss: 120.41934 - diff: 38.17mlTrain batch 2/32 - 175.9ms/batch - loss: 101.91288 - diff: 35.37mlTrain batch 3/32 - 175.6ms/batch - loss: 118.36552 - diff: 37.13mlTrain batch 4/32 - 176.1ms/batch - loss: 112.43183 - diff: 35.26mlTrain batch 5/32 - 175.8ms/batch - loss: 107.73966 - diff: 34.20mlTrain batch 6/32 - 175.9ms/batch - loss: 113.53414 - diff: 34.77mlTrain batch 7/32 - 175.7ms/batch - loss: 107.62217 - diff: 34.09mlTrain batch 8/32 - 175.8ms/batch - loss: 101.75175 - diff: 32.93mlTrain batch 9/32 - 175.8ms/batch - loss: 96.45557 - diff: 31.93mlTrain batch 10/32 - 176.0ms/batch - loss: 100.67418 - diff: 32.59mlTrain batch 11/32 - 175.6ms/batch - loss: 104.29195 - diff: 32.89mlTrain batch 12/32 - 175.9ms/batch - loss: 98.50175 - diff: 31.53mlTrain batch 13/32 - 175.7ms/batch - loss: 96.90182 - diff: 31.37mlTrain batch 14/32 - 176.2ms/batch - loss: 95.19668 - diff: 30.99mlTrain batch 15/32 - 175.5ms/batch - loss: 93.05266 - diff: 30.56mlTrain batch 16/32 - 176.0ms/batch - loss: 89.06133 - diff: 29.80mlTrain batch 17/32 - 175.7ms/batch - loss: 85.69832 - diff: 29.16mlTrain batch 18/32 - 176.2ms/batch - loss: 83.57458 - diff: 28.88mlTrain batch 19/32 - 175.9ms/batch - loss: 89.28910 - diff: 29.86mlTrain batch 20/32 - 175.9ms/batch - loss: 87.52096 - diff: 29.51mlTrain batch 21/32 - 176.0ms/batch - loss: 93.27922 - diff: 29.88mlTrain batch 22/32 - 176.1ms/batch - loss: 91.38303 - diff: 29.67mlTrain batch 23/32 - 175.8ms/batch - loss: 93.31365 - diff: 29.79mlTrain batch 24/32 - 175.9ms/batch - loss: 92.06288 - diff: 29.53mlTrain batch 25/32 - 175.5ms/batch - loss: 92.69150 - diff: 29.45mlTrain batch 26/32 - 176.1ms/batch - loss: 92.10695 - diff: 29.45mlTrain batch 27/32 - 175.8ms/batch - loss: 91.62065 - diff: 29.39mlTrain batch 28/32 - 175.9ms/batch - loss: 90.07310 - diff: 29.17mlTrain batch 29/32 - 175.8ms/batch - loss: 91.23647 - diff: 29.33mlTrain batch 30/32 - 176.0ms/batch - loss: 89.73234 - diff: 29.00mlTrain batch 31/32 - 175.9ms/batch - loss: 89.22748 - diff: 28.93mlTrain batch 32/32 - 54.1ms/batch - loss: 89.99864 - diff: 28.88mlTrain batch 32/32 - 10.8s 54.1ms/batch - loss: 89.99864 - diff: 28.88ml
Test 1.1s: val_loss: 308.04734 - diff: 60.55ml
Epoch    18: reducing learning rate of group 0 to 5.0000e-04.

Epoch 18: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 175.8ms/batch - loss: 39.16809 - diff: 19.78mlTrain batch 2/32 - 175.9ms/batch - loss: 64.48928 - diff: 24.49mlTrain batch 3/32 - 175.9ms/batch - loss: 64.54620 - diff: 25.37mlTrain batch 4/32 - 176.1ms/batch - loss: 62.45590 - diff: 25.19mlTrain batch 5/32 - 176.1ms/batch - loss: 72.02165 - diff: 27.96mlTrain batch 6/32 - 176.1ms/batch - loss: 69.91564 - diff: 27.05mlTrain batch 7/32 - 175.6ms/batch - loss: 66.56309 - diff: 26.45mlTrain batch 8/32 - 175.8ms/batch - loss: 63.11503 - diff: 25.67mlTrain batch 9/32 - 175.8ms/batch - loss: 63.81554 - diff: 25.88mlTrain batch 10/32 - 176.0ms/batch - loss: 62.97798 - diff: 25.87mlTrain batch 11/32 - 175.8ms/batch - loss: 59.85190 - diff: 25.07mlTrain batch 12/32 - 176.0ms/batch - loss: 61.83083 - diff: 25.56mlTrain batch 13/32 - 175.8ms/batch - loss: 63.73565 - diff: 25.78mlTrain batch 14/32 - 176.2ms/batch - loss: 67.06534 - diff: 26.05mlTrain batch 15/32 - 176.0ms/batch - loss: 67.99329 - diff: 26.11mlTrain batch 16/32 - 176.0ms/batch - loss: 67.50640 - diff: 26.17mlTrain batch 17/32 - 175.7ms/batch - loss: 64.95354 - diff: 25.58mlTrain batch 18/32 - 175.9ms/batch - loss: 66.13643 - diff: 25.77mlTrain batch 19/32 - 176.1ms/batch - loss: 66.40753 - diff: 25.78mlTrain batch 20/32 - 176.1ms/batch - loss: 70.38684 - diff: 26.43mlTrain batch 21/32 - 175.9ms/batch - loss: 71.88035 - diff: 26.72mlTrain batch 22/32 - 175.9ms/batch - loss: 73.41486 - diff: 27.06mlTrain batch 23/32 - 176.0ms/batch - loss: 73.56727 - diff: 27.16mlTrain batch 24/32 - 176.2ms/batch - loss: 73.15658 - diff: 27.04mlTrain batch 25/32 - 176.0ms/batch - loss: 72.58520 - diff: 26.78mlTrain batch 26/32 - 176.2ms/batch - loss: 74.28258 - diff: 27.11mlTrain batch 27/32 - 176.0ms/batch - loss: 74.59566 - diff: 27.19mlTrain batch 28/32 - 176.2ms/batch - loss: 73.75184 - diff: 27.01mlTrain batch 29/32 - 175.9ms/batch - loss: 73.08079 - diff: 26.92mlTrain batch 30/32 - 176.1ms/batch - loss: 72.10458 - diff: 26.78mlTrain batch 31/32 - 176.2ms/batch - loss: 76.16769 - diff: 27.29mlTrain batch 32/32 - 54.1ms/batch - loss: 79.42891 - diff: 27.34mlTrain batch 32/32 - 10.7s 54.1ms/batch - loss: 79.42891 - diff: 27.34ml
Test 1.1s: val_loss: 602.59681 - diff: 89.45ml

Epoch 19: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 176.0ms/batch - loss: 43.89929 - diff: 23.44mlTrain batch 2/32 - 175.7ms/batch - loss: 38.44862 - diff: 21.27mlTrain batch 3/32 - 176.0ms/batch - loss: 50.87240 - diff: 24.08mlTrain batch 4/32 - 176.1ms/batch - loss: 59.97708 - diff: 24.91mlTrain batch 5/32 - 175.8ms/batch - loss: 54.31307 - diff: 23.71mlTrain batch 6/32 - 176.2ms/batch - loss: 50.50599 - diff: 22.69mlTrain batch 7/32 - 175.7ms/batch - loss: 47.89869 - diff: 22.13mlTrain batch 8/32 - 176.0ms/batch - loss: 49.96047 - diff: 22.76mlTrain batch 9/32 - 175.8ms/batch - loss: 50.69326 - diff: 23.40mlTrain batch 10/32 - 176.0ms/batch - loss: 50.14047 - diff: 23.25mlTrain batch 11/32 - 175.7ms/batch - loss: 53.65165 - diff: 23.84mlTrain batch 12/32 - 176.1ms/batch - loss: 54.97128 - diff: 24.15mlTrain batch 13/32 - 175.6ms/batch - loss: 57.40492 - diff: 24.71mlTrain batch 14/32 - 176.2ms/batch - loss: 82.65160 - diff: 27.50mlTrain batch 15/32 - 175.8ms/batch - loss: 81.65121 - diff: 27.45mlTrain batch 16/32 - 176.0ms/batch - loss: 82.17358 - diff: 27.41mlTrain batch 17/32 - 175.7ms/batch - loss: 81.83660 - diff: 27.41mlTrain batch 18/32 - 176.2ms/batch - loss: 81.19401 - diff: 27.45mlTrain batch 19/32 - 175.8ms/batch - loss: 79.26945 - diff: 27.09mlTrain batch 20/32 - 176.2ms/batch - loss: 77.47371 - diff: 26.78mlTrain batch 21/32 - 175.7ms/batch - loss: 75.96382 - diff: 26.54mlTrain batch 22/32 - 176.1ms/batch - loss: 75.72884 - diff: 26.48mlTrain batch 23/32 - 175.5ms/batch - loss: 75.14594 - diff: 26.51mlTrain batch 24/32 - 176.4ms/batch - loss: 74.44349 - diff: 26.47mlTrain batch 25/32 - 176.0ms/batch - loss: 73.27163 - diff: 26.31mlTrain batch 26/32 - 176.2ms/batch - loss: 73.11591 - diff: 26.32mlTrain batch 27/32 - 175.9ms/batch - loss: 74.14988 - diff: 26.65mlTrain batch 28/32 - 176.1ms/batch - loss: 73.99000 - diff: 26.63mlTrain batch 29/32 - 175.7ms/batch - loss: 72.54915 - diff: 26.36mlTrain batch 30/32 - 176.1ms/batch - loss: 71.81794 - diff: 26.30mlTrain batch 31/32 - 176.1ms/batch - loss: 71.45640 - diff: 26.13mlTrain batch 32/32 - 54.0ms/batch - loss: 75.29301 - diff: 26.28mlTrain batch 32/32 - 11.1s 54.0ms/batch - loss: 75.29301 - diff: 26.28ml
Test 1.1s: val_loss: 729.28964 - diff: 98.71ml

Epoch 20: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 176.0ms/batch - loss: 55.87843 - diff: 22.07mlTrain batch 2/32 - 175.9ms/batch - loss: 77.37374 - diff: 26.51mlTrain batch 3/32 - 175.8ms/batch - loss: 69.94269 - diff: 24.88mlTrain batch 4/32 - 175.8ms/batch - loss: 66.12957 - diff: 24.55mlTrain batch 5/32 - 176.0ms/batch - loss: 59.50120 - diff: 23.28mlTrain batch 6/32 - 175.8ms/batch - loss: 59.07627 - diff: 23.67mlTrain batch 7/32 - 175.8ms/batch - loss: 58.30337 - diff: 23.93mlTrain batch 8/32 - 175.8ms/batch - loss: 56.61765 - diff: 23.88mlTrain batch 9/32 - 176.1ms/batch - loss: 58.43890 - diff: 24.27mlTrain batch 10/32 - 176.0ms/batch - loss: 59.16087 - diff: 24.40mlTrain batch 11/32 - 176.1ms/batch - loss: 60.41216 - diff: 24.66mlTrain batch 12/32 - 175.8ms/batch - loss: 59.72867 - diff: 24.60mlTrain batch 13/32 - 176.1ms/batch - loss: 58.02204 - diff: 24.27mlTrain batch 14/32 - 175.6ms/batch - loss: 61.14302 - diff: 24.72mlTrain batch 15/32 - 176.0ms/batch - loss: 82.27361 - diff: 26.80mlTrain batch 16/32 - 175.9ms/batch - loss: 79.39445 - diff: 26.39mlTrain batch 17/32 - 176.1ms/batch - loss: 78.41946 - diff: 26.34mlTrain batch 18/32 - 176.0ms/batch - loss: 77.27097 - diff: 26.33mlTrain batch 19/32 - 176.1ms/batch - loss: 75.12793 - diff: 26.02mlTrain batch 20/32 - 175.8ms/batch - loss: 73.48493 - diff: 25.76mlTrain batch 21/32 - 176.1ms/batch - loss: 73.21190 - diff: 25.57mlTrain batch 22/32 - 176.1ms/batch - loss: 73.81726 - diff: 25.72mlTrain batch 23/32 - 176.1ms/batch - loss: 74.33139 - diff: 25.91mlTrain batch 24/32 - 175.7ms/batch - loss: 76.29737 - diff: 26.28mlTrain batch 25/32 - 176.0ms/batch - loss: 80.89592 - diff: 27.09mlTrain batch 26/32 - 176.1ms/batch - loss: 80.33171 - diff: 26.93mlTrain batch 27/32 - 176.1ms/batch - loss: 81.70146 - diff: 27.14mlTrain batch 28/32 - 176.1ms/batch - loss: 81.11910 - diff: 27.07mlTrain batch 29/32 - 176.0ms/batch - loss: 79.73665 - diff: 26.87mlTrain batch 30/32 - 175.9ms/batch - loss: 79.58346 - diff: 26.84mlTrain batch 31/32 - 176.1ms/batch - loss: 78.48360 - diff: 26.68mlTrain batch 32/32 - 54.1ms/batch - loss: 81.58538 - diff: 26.80mlTrain batch 32/32 - 11.3s 54.1ms/batch - loss: 81.58538 - diff: 26.80ml
Test 1.1s: val_loss: 966.08129 - diff: 115.85ml

Epoch 21: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 176.2ms/batch - loss: 418.76752 - diff: 60.10mlTrain batch 2/32 - 176.1ms/batch - loss: 224.86994 - diff: 38.91mlTrain batch 3/32 - 175.9ms/batch - loss: 162.26360 - diff: 33.37mlTrain batch 4/32 - 176.0ms/batch - loss: 143.14936 - diff: 32.45mlTrain batch 5/32 - 176.0ms/batch - loss: 121.41778 - diff: 30.02mlTrain batch 6/32 - 175.9ms/batch - loss: 111.57736 - diff: 28.53mlTrain batch 7/32 - 176.0ms/batch - loss: 99.08779 - diff: 26.68mlTrain batch 8/32 - 175.9ms/batch - loss: 96.55593 - diff: 27.09mlTrain batch 9/32 - 175.9ms/batch - loss: 96.91189 - diff: 27.68mlTrain batch 10/32 - 175.6ms/batch - loss: 92.85180 - diff: 27.10mlTrain batch 11/32 - 175.9ms/batch - loss: 88.03949 - diff: 26.23mlTrain batch 12/32 - 176.1ms/batch - loss: 86.43845 - diff: 26.11mlTrain batch 13/32 - 176.1ms/batch - loss: 81.73206 - diff: 25.20mlTrain batch 14/32 - 175.8ms/batch - loss: 82.41600 - diff: 25.45mlTrain batch 15/32 - 175.6ms/batch - loss: 81.88427 - diff: 25.60mlTrain batch 16/32 - 175.8ms/batch - loss: 80.31328 - diff: 25.65mlTrain batch 17/32 - 176.0ms/batch - loss: 79.18873 - diff: 25.68mlTrain batch 18/32 - 175.5ms/batch - loss: 77.56130 - diff: 25.55mlTrain batch 19/32 - 176.2ms/batch - loss: 76.59866 - diff: 25.46mlTrain batch 20/32 - 175.5ms/batch - loss: 75.34980 - diff: 25.31mlTrain batch 21/32 - 176.2ms/batch - loss: 74.50480 - diff: 25.27mlTrain batch 22/32 - 175.6ms/batch - loss: 74.96344 - diff: 25.44mlTrain batch 23/32 - 176.1ms/batch - loss: 72.77367 - diff: 25.08mlTrain batch 24/32 - 176.1ms/batch - loss: 72.02749 - diff: 24.98mlTrain batch 25/32 - 176.2ms/batch - loss: 75.08086 - diff: 25.39mlTrain batch 26/32 - 175.6ms/batch - loss: 75.00681 - diff: 25.42mlTrain batch 27/32 - 176.1ms/batch - loss: 73.15049 - diff: 25.05mlTrain batch 28/32 - 175.7ms/batch - loss: 74.04314 - diff: 25.26mlTrain batch 29/32 - 176.1ms/batch - loss: 73.89177 - diff: 25.36mlTrain batch 30/32 - 175.8ms/batch - loss: 72.91561 - diff: 25.27mlTrain batch 31/32 - 176.0ms/batch - loss: 71.44316 - diff: 24.94mlTrain batch 32/32 - 54.1ms/batch - loss: 72.81101 - diff: 24.98mlTrain batch 32/32 - 12.1s 54.1ms/batch - loss: 72.81101 - diff: 24.98ml
Test 1.1s: val_loss: 1123.53632 - diff: 125.69ml

Epoch 22: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 176.1ms/batch - loss: 53.77037 - diff: 23.55mlTrain batch 2/32 - 176.2ms/batch - loss: 103.96479 - diff: 32.27mlTrain batch 3/32 - 176.1ms/batch - loss: 83.73910 - diff: 28.04mlTrain batch 4/32 - 176.1ms/batch - loss: 83.51856 - diff: 27.88mlTrain batch 5/32 - 175.6ms/batch - loss: 88.09029 - diff: 29.07mlTrain batch 6/32 - 175.8ms/batch - loss: 88.62319 - diff: 29.86mlTrain batch 7/32 - 175.8ms/batch - loss: 88.87291 - diff: 29.95mlTrain batch 8/32 - 176.2ms/batch - loss: 88.59082 - diff: 29.79mlTrain batch 9/32 - 175.7ms/batch - loss: 82.29313 - diff: 28.52mlTrain batch 10/32 - 175.9ms/batch - loss: 81.85557 - diff: 28.55mlTrain batch 11/32 - 175.9ms/batch - loss: 83.34061 - diff: 29.04mlTrain batch 12/32 - 176.1ms/batch - loss: 85.99684 - diff: 29.70mlTrain batch 13/32 - 175.8ms/batch - loss: 86.74614 - diff: 29.92mlTrain batch 14/32 - 176.0ms/batch - loss: 83.84018 - diff: 29.30mlTrain batch 15/32 - 175.8ms/batch - loss: 103.30881 - diff: 30.65mlTrain batch 16/32 - 176.0ms/batch - loss: 100.37268 - diff: 30.24mlTrain batch 17/32 - 175.9ms/batch - loss: 97.34681 - diff: 29.88mlTrain batch 18/32 - 176.1ms/batch - loss: 97.19415 - diff: 29.87mlTrain batch 19/32 - 175.8ms/batch - loss: 95.91411 - diff: 29.64mlTrain batch 20/32 - 176.0ms/batch - loss: 94.11255 - diff: 29.47mlTrain batch 21/32 - 176.0ms/batch - loss: 92.14721 - diff: 29.17mlTrain batch 22/32 - 175.9ms/batch - loss: 91.30941 - diff: 29.15mlTrain batch 23/32 - 176.0ms/batch - loss: 92.21728 - diff: 29.27mlTrain batch 24/32 - 176.0ms/batch - loss: 90.81017 - diff: 29.14mlTrain batch 25/32 - 175.8ms/batch - loss: 88.99953 - diff: 28.98mlTrain batch 26/32 - 176.1ms/batch - loss: 87.11898 - diff: 28.73mlTrain batch 27/32 - 175.9ms/batch - loss: 87.23000 - diff: 28.65mlTrain batch 28/32 - 176.0ms/batch - loss: 86.17272 - diff: 28.49mlTrain batch 29/32 - 176.2ms/batch - loss: 85.00920 - diff: 28.30mlTrain batch 30/32 - 175.9ms/batch - loss: 84.39977 - diff: 28.15mlTrain batch 31/32 - 175.9ms/batch - loss: 84.13037 - diff: 28.09mlTrain batch 32/32 - 54.0ms/batch - loss: 87.76219 - diff: 28.17mlTrain batch 32/32 - 10.8s 54.0ms/batch - loss: 87.76219 - diff: 28.17ml
Test 1.1s: val_loss: 920.37750 - diff: 112.88ml

Epoch 23: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 176.0ms/batch - loss: 63.70716 - diff: 21.03mlTrain batch 2/32 - 176.2ms/batch - loss: 59.22926 - diff: 22.44mlTrain batch 3/32 - 176.0ms/batch - loss: 57.94235 - diff: 22.49mlTrain batch 4/32 - 175.9ms/batch - loss: 56.51872 - diff: 22.84mlTrain batch 5/32 - 176.0ms/batch - loss: 74.77248 - diff: 26.34mlTrain batch 6/32 - 176.0ms/batch - loss: 71.16603 - diff: 25.96mlTrain batch 7/32 - 176.0ms/batch - loss: 69.05501 - diff: 26.03mlTrain batch 8/32 - 175.9ms/batch - loss: 71.32196 - diff: 26.26mlTrain batch 9/32 - 176.1ms/batch - loss: 69.77686 - diff: 25.97mlTrain batch 10/32 - 176.0ms/batch - loss: 70.61649 - diff: 26.22mlTrain batch 11/32 - 176.0ms/batch - loss: 70.57066 - diff: 26.48mlTrain batch 12/32 - 175.8ms/batch - loss: 68.91832 - diff: 26.16mlTrain batch 13/32 - 176.0ms/batch - loss: 70.42267 - diff: 26.48mlTrain batch 14/32 - 176.1ms/batch - loss: 69.27635 - diff: 26.42mlTrain batch 15/32 - 176.0ms/batch - loss: 69.75566 - diff: 26.44mlTrain batch 16/32 - 175.9ms/batch - loss: 69.01029 - diff: 26.27mlTrain batch 17/32 - 175.9ms/batch - loss: 73.15864 - diff: 27.13mlTrain batch 18/32 - 176.0ms/batch - loss: 71.12313 - diff: 26.60mlTrain batch 19/32 - 176.2ms/batch - loss: 74.76995 - diff: 27.05mlTrain batch 20/32 - 175.9ms/batch - loss: 73.37080 - diff: 26.73mlTrain batch 21/32 - 176.3ms/batch - loss: 73.66388 - diff: 26.83mlTrain batch 22/32 - 176.1ms/batch - loss: 72.69864 - diff: 26.61mlTrain batch 23/32 - 176.0ms/batch - loss: 73.74683 - diff: 26.93mlTrain batch 24/32 - 176.0ms/batch - loss: 72.75226 - diff: 26.72mlTrain batch 25/32 - 176.3ms/batch - loss: 72.32380 - diff: 26.68mlTrain batch 26/32 - 175.8ms/batch - loss: 71.72871 - diff: 26.58mlTrain batch 27/32 - 176.1ms/batch - loss: 72.23298 - diff: 26.61mlTrain batch 28/32 - 176.1ms/batch - loss: 71.21145 - diff: 26.37mlTrain batch 29/32 - 176.1ms/batch - loss: 77.84498 - diff: 26.90mlTrain batch 30/32 - 176.2ms/batch - loss: 78.03460 - diff: 26.84mlTrain batch 31/32 - 176.0ms/batch - loss: 79.28473 - diff: 27.17mlTrain batch 32/32 - 54.1ms/batch - loss: 79.74429 - diff: 27.11mlTrain batch 32/32 - 11.0s 54.1ms/batch - loss: 79.74429 - diff: 27.11ml
Test 1.1s: val_loss: 1253.64604 - diff: 132.81ml

Epoch 24: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 175.9ms/batch - loss: 30.42014 - diff: 18.29mlTrain batch 2/32 - 176.1ms/batch - loss: 29.31691 - diff: 17.31mlTrain batch 3/32 - 176.0ms/batch - loss: 33.50475 - diff: 18.29mlTrain batch 4/32 - 176.1ms/batch - loss: 43.84488 - diff: 21.31mlTrain batch 5/32 - 175.8ms/batch - loss: 65.90980 - diff: 23.86mlTrain batch 6/32 - 176.1ms/batch - loss: 66.94218 - diff: 24.60mlTrain batch 7/32 - 176.0ms/batch - loss: 70.66001 - diff: 25.29mlTrain batch 8/32 - 175.9ms/batch - loss: 71.58950 - diff: 25.63mlTrain batch 9/32 - 176.2ms/batch - loss: 70.93432 - diff: 25.31mlTrain batch 10/32 - 176.2ms/batch - loss: 66.34321 - diff: 24.38mlTrain batch 11/32 - 176.1ms/batch - loss: 66.54274 - diff: 24.79mlTrain batch 12/32 - 176.1ms/batch - loss: 74.47535 - diff: 25.96mlTrain batch 13/32 - 175.9ms/batch - loss: 72.43657 - diff: 25.69mlTrain batch 14/32 - 176.2ms/batch - loss: 78.39653 - diff: 26.98mlTrain batch 15/32 - 176.0ms/batch - loss: 76.26623 - diff: 26.41mlTrain batch 16/32 - 176.0ms/batch - loss: 76.14844 - diff: 26.72mlTrain batch 17/32 - 176.1ms/batch - loss: 76.40173 - diff: 26.83mlTrain batch 18/32 - 176.1ms/batch - loss: 76.06118 - diff: 27.03mlTrain batch 19/32 - 176.0ms/batch - loss: 74.44938 - diff: 26.77mlTrain batch 20/32 - 176.0ms/batch - loss: 75.09288 - diff: 26.93mlTrain batch 21/32 - 176.0ms/batch - loss: 75.96491 - diff: 27.12mlTrain batch 22/32 - 176.3ms/batch - loss: 76.70008 - diff: 27.24mlTrain batch 23/32 - 175.8ms/batch - loss: 77.54046 - diff: 27.52mlTrain batch 24/32 - 176.3ms/batch - loss: 76.07539 - diff: 27.24mlTrain batch 25/32 - 176.0ms/batch - loss: 76.10525 - diff: 27.36mlTrain batch 26/32 - 176.3ms/batch - loss: 76.03232 - diff: 27.33mlTrain batch 27/32 - 176.0ms/batch - loss: 75.47679 - diff: 27.24mlTrain batch 28/32 - 175.9ms/batch - loss: 86.07421 - diff: 28.46mlTrain batch 29/32 - 176.0ms/batch - loss: 84.47733 - diff: 28.16mlTrain batch 30/32 - 175.9ms/batch - loss: 83.34621 - diff: 27.92mlTrain batch 31/32 - 175.8ms/batch - loss: 81.88549 - diff: 27.63mlTrain batch 32/32 - 53.9ms/batch - loss: 81.27357 - diff: 27.44mlTrain batch 32/32 - 10.8s 53.9ms/batch - loss: 81.27357 - diff: 27.44ml
Test 1.1s: val_loss: 1137.44498 - diff: 126.04ml

Epoch 25: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 176.0ms/batch - loss: 51.58098 - diff: 21.69mlTrain batch 2/32 - 176.1ms/batch - loss: 35.55522 - diff: 18.23mlTrain batch 3/32 - 175.9ms/batch - loss: 46.63293 - diff: 21.40mlTrain batch 4/32 - 176.2ms/batch - loss: 44.70262 - diff: 20.15mlTrain batch 5/32 - 175.9ms/batch - loss: 41.92657 - diff: 20.01mlTrain batch 6/32 - 176.1ms/batch - loss: 45.74073 - diff: 21.36mlTrain batch 7/32 - 176.0ms/batch - loss: 51.86386 - diff: 22.32mlTrain batch 8/32 - 176.2ms/batch - loss: 49.72433 - diff: 21.76mlTrain batch 9/32 - 176.1ms/batch - loss: 48.86770 - diff: 21.77mlTrain batch 10/32 - 176.3ms/batch - loss: 60.46750 - diff: 23.03mlTrain batch 11/32 - 175.9ms/batch - loss: 63.83464 - diff: 23.85mlTrain batch 12/32 - 176.2ms/batch - loss: 63.98076 - diff: 24.02mlTrain batch 13/32 - 176.0ms/batch - loss: 63.18282 - diff: 23.81mlTrain batch 14/32 - 176.4ms/batch - loss: 65.04978 - diff: 24.10mlTrain batch 15/32 - 176.0ms/batch - loss: 64.33985 - diff: 24.03mlTrain batch 16/32 - 176.2ms/batch - loss: 62.23637 - diff: 23.67mlTrain batch 17/32 - 176.1ms/batch - loss: 62.65027 - diff: 23.80mlTrain batch 18/32 - 176.2ms/batch - loss: 61.81328 - diff: 23.74mlTrain batch 19/32 - 175.9ms/batch - loss: 63.08858 - diff: 24.20mlTrain batch 20/32 - 176.1ms/batch - loss: 62.33585 - diff: 24.15mlTrain batch 21/32 - 176.0ms/batch - loss: 62.42368 - diff: 24.16mlTrain batch 22/32 - 176.4ms/batch - loss: 63.50250 - diff: 24.40mlTrain batch 23/32 - 176.1ms/batch - loss: 63.28559 - diff: 24.46mlTrain batch 24/32 - 176.1ms/batch - loss: 65.04460 - diff: 24.50mlTrain batch 25/32 - 176.1ms/batch - loss: 65.21875 - diff: 24.59mlTrain batch 26/32 - 176.3ms/batch - loss: 64.26702 - diff: 24.40mlTrain batch 27/32 - 176.0ms/batch - loss: 63.61324 - diff: 24.38mlTrain batch 28/32 - 176.2ms/batch - loss: 63.49813 - diff: 24.28mlTrain batch 29/32 - 176.1ms/batch - loss: 63.54121 - diff: 24.32mlTrain batch 30/32 - 176.1ms/batch - loss: 63.15625 - diff: 24.32mlTrain batch 31/32 - 175.9ms/batch - loss: 62.77142 - diff: 24.23mlTrain batch 32/32 - 54.1ms/batch - loss: 63.23781 - diff: 24.19mlTrain batch 32/32 - 11.4s 54.1ms/batch - loss: 63.23781 - diff: 24.19ml
Test 1.1s: val_loss: 1158.85980 - diff: 128.00ml

Epoch 26: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 176.2ms/batch - loss: 34.27824 - diff: 19.59mlTrain batch 2/32 - 176.3ms/batch - loss: 42.12743 - diff: 21.72mlTrain batch 3/32 - 175.8ms/batch - loss: 45.12979 - diff: 22.84mlTrain batch 4/32 - 176.1ms/batch - loss: 51.18571 - diff: 24.39mlTrain batch 5/32 - 176.1ms/batch - loss: 49.12897 - diff: 23.81mlTrain batch 6/32 - 176.2ms/batch - loss: 49.44414 - diff: 23.61mlTrain batch 7/32 - 176.1ms/batch - loss: 52.82818 - diff: 24.05mlTrain batch 8/32 - 176.1ms/batch - loss: 50.10907 - diff: 23.38mlTrain batch 9/32 - 176.0ms/batch - loss: 50.79413 - diff: 23.51mlTrain batch 10/32 - 176.2ms/batch - loss: 51.80415 - diff: 23.50mlTrain batch 11/32 - 176.1ms/batch - loss: 52.47086 - diff: 23.54mlTrain batch 12/32 - 176.4ms/batch - loss: 55.38692 - diff: 24.27mlTrain batch 13/32 - 176.0ms/batch - loss: 58.44315 - diff: 24.88mlTrain batch 14/32 - 176.0ms/batch - loss: 58.43491 - diff: 24.54mlTrain batch 15/32 - 176.0ms/batch - loss: 57.09938 - diff: 24.18mlTrain batch 16/32 - 176.1ms/batch - loss: 57.46536 - diff: 24.35mlTrain batch 17/32 - 176.1ms/batch - loss: 58.98532 - diff: 24.65mlTrain batch 18/32 - 176.2ms/batch - loss: 60.80931 - diff: 25.08mlTrain batch 19/32 - 175.9ms/batch - loss: 59.61616 - diff: 24.77mlTrain batch 20/32 - 176.0ms/batch - loss: 59.99876 - diff: 24.79mlTrain batch 21/32 - 176.1ms/batch - loss: 60.56740 - diff: 24.96mlTrain batch 22/32 - 176.2ms/batch - loss: 59.68532 - diff: 24.69mlTrain batch 23/32 - 175.9ms/batch - loss: 61.60832 - diff: 25.17mlTrain batch 24/32 - 176.4ms/batch - loss: 62.86926 - diff: 25.31mlTrain batch 25/32 - 176.1ms/batch - loss: 63.11797 - diff: 25.49mlTrain batch 26/32 - 176.3ms/batch - loss: 63.39907 - diff: 25.62mlTrain batch 27/32 - 176.1ms/batch - loss: 64.37833 - diff: 25.75mlTrain batch 28/32 - 176.5ms/batch - loss: 68.66582 - diff: 26.34mlTrain batch 29/32 - 175.9ms/batch - loss: 72.71343 - diff: 26.99mlTrain batch 30/32 - 176.2ms/batch - loss: 71.50473 - diff: 26.75mlTrain batch 31/32 - 175.9ms/batch - loss: 72.14946 - diff: 26.85mlTrain batch 32/32 - 53.9ms/batch - loss: 74.25980 - diff: 26.87mlTrain batch 32/32 - 11.4s 53.9ms/batch - loss: 74.25980 - diff: 26.87ml
Test 1.1s: val_loss: 952.92449 - diff: 115.89ml

Epoch 27: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 176.2ms/batch - loss: 38.76098 - diff: 20.36mlTrain batch 2/32 - 176.2ms/batch - loss: 35.48583 - diff: 18.97mlTrain batch 3/32 - 176.0ms/batch - loss: 49.52306 - diff: 23.26mlTrain batch 4/32 - 176.0ms/batch - loss: 52.30263 - diff: 23.26mlTrain batch 5/32 - 176.0ms/batch - loss: 51.86553 - diff: 22.93mlTrain batch 6/32 - 176.1ms/batch - loss: 52.83448 - diff: 23.49mlTrain batch 7/32 - 175.9ms/batch - loss: 49.58871 - diff: 22.48mlTrain batch 8/32 - 176.1ms/batch - loss: 52.60233 - diff: 23.11mlTrain batch 9/32 - 176.1ms/batch - loss: 60.69157 - diff: 24.53mlTrain batch 10/32 - 176.2ms/batch - loss: 60.99643 - diff: 24.41mlTrain batch 11/32 - 176.0ms/batch - loss: 59.70478 - diff: 24.30mlTrain batch 12/32 - 176.1ms/batch - loss: 59.34196 - diff: 24.29mlTrain batch 13/32 - 176.1ms/batch - loss: 63.28336 - diff: 24.53mlTrain batch 14/32 - 176.0ms/batch - loss: 61.90329 - diff: 24.27mlTrain batch 15/32 - 176.0ms/batch - loss: 60.27578 - diff: 23.84mlTrain batch 16/32 - 176.0ms/batch - loss: 59.98345 - diff: 23.83mlTrain batch 17/32 - 176.0ms/batch - loss: 58.71717 - diff: 23.67mlTrain batch 18/32 - 176.0ms/batch - loss: 57.41917 - diff: 23.35mlTrain batch 19/32 - 176.2ms/batch - loss: 57.55180 - diff: 23.48mlTrain batch 20/32 - 176.1ms/batch - loss: 57.25021 - diff: 23.51mlTrain batch 21/32 - 176.1ms/batch - loss: 59.86073 - diff: 24.15mlTrain batch 22/32 - 176.0ms/batch - loss: 60.09881 - diff: 24.18mlTrain batch 23/32 - 176.0ms/batch - loss: 59.67042 - diff: 24.00mlTrain batch 24/32 - 176.0ms/batch - loss: 59.22676 - diff: 23.85mlTrain batch 25/32 - 176.3ms/batch - loss: 60.19711 - diff: 24.16mlTrain batch 26/32 - 176.0ms/batch - loss: 60.75744 - diff: 24.31mlTrain batch 27/32 - 176.2ms/batch - loss: 60.80419 - diff: 24.38mlTrain batch 28/32 - 175.9ms/batch - loss: 62.69051 - diff: 24.69mlTrain batch 29/32 - 176.1ms/batch - loss: 66.29913 - diff: 25.02mlTrain batch 30/32 - 175.9ms/batch - loss: 65.09739 - diff: 24.80mlTrain batch 31/32 - 176.1ms/batch - loss: 63.93008 - diff: 24.58mlTrain batch 32/32 - 54.1ms/batch - loss: 65.09273 - diff: 24.57mlTrain batch 32/32 - 10.7s 54.1ms/batch - loss: 65.09273 - diff: 24.57ml
Test 1.1s: val_loss: 1268.17074 - diff: 133.76ml

Epoch 28: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 176.2ms/batch - loss: 75.50750 - diff: 27.82mlTrain batch 2/32 - 176.1ms/batch - loss: 75.73377 - diff: 27.19mlTrain batch 3/32 - 176.1ms/batch - loss: 65.54515 - diff: 26.04mlTrain batch 4/32 - 176.1ms/batch - loss: 60.48040 - diff: 24.93mlTrain batch 5/32 - 176.1ms/batch - loss: 52.72730 - diff: 23.12mlTrain batch 6/32 - 176.2ms/batch - loss: 52.01649 - diff: 22.95mlTrain batch 7/32 - 176.0ms/batch - loss: 50.67125 - diff: 22.53mlTrain batch 8/32 - 176.1ms/batch - loss: 51.13301 - diff: 22.86mlTrain batch 9/32 - 176.0ms/batch - loss: 52.33636 - diff: 22.91mlTrain batch 10/32 - 176.0ms/batch - loss: 53.61559 - diff: 23.44mlTrain batch 11/32 - 176.0ms/batch - loss: 54.80878 - diff: 23.43mlTrain batch 12/32 - 176.2ms/batch - loss: 57.88735 - diff: 24.15mlTrain batch 13/32 - 176.0ms/batch - loss: 59.78958 - diff: 24.60mlTrain batch 14/32 - 176.2ms/batch - loss: 66.06124 - diff: 25.29mlTrain batch 15/32 - 176.0ms/batch - loss: 63.42613 - diff: 24.78mlTrain batch 16/32 - 176.3ms/batch - loss: 64.60661 - diff: 25.09mlTrain batch 17/32 - 175.9ms/batch - loss: 68.33717 - diff: 25.72mlTrain batch 18/32 - 176.4ms/batch - loss: 69.29629 - diff: 25.86mlTrain batch 19/32 - 176.2ms/batch - loss: 68.03794 - diff: 25.70mlTrain batch 20/32 - 176.2ms/batch - loss: 69.72414 - diff: 26.08mlTrain batch 21/32 - 176.0ms/batch - loss: 72.58915 - diff: 26.05mlTrain batch 22/32 - 176.1ms/batch - loss: 70.93945 - diff: 25.73mlTrain batch 23/32 - 176.0ms/batch - loss: 71.56628 - diff: 26.07mlTrain batch 24/32 - 176.2ms/batch - loss: 70.94322 - diff: 25.99mlTrain batch 25/32 - 175.9ms/batch - loss: 69.23761 - diff: 25.70mlTrain batch 26/32 - 176.3ms/batch - loss: 69.55110 - diff: 25.83mlTrain batch 27/32 - 176.0ms/batch - loss: 70.73629 - diff: 25.99mlTrain batch 28/32 - 176.2ms/batch - loss: 70.94816 - diff: 26.00mlTrain batch 29/32 - 176.1ms/batch - loss: 70.66104 - diff: 26.01mlTrain batch 30/32 - 176.1ms/batch - loss: 69.59999 - diff: 25.73mlTrain batch 31/32 - 176.1ms/batch - loss: 68.28170 - diff: 25.38mlTrain batch 32/32 - 54.1ms/batch - loss: 70.95079 - diff: 25.44mlTrain batch 32/32 - 10.9s 54.1ms/batch - loss: 70.95079 - diff: 25.44ml
Test 1.1s: val_loss: 951.40380 - diff: 113.21ml
Epoch    29: reducing learning rate of group 0 to 2.5000e-04.

Epoch 29: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 176.0ms/batch - loss: 56.70780 - diff: 25.91mlTrain batch 2/32 - 176.2ms/batch - loss: 67.80621 - diff: 23.80mlTrain batch 3/32 - 175.9ms/batch - loss: 52.67277 - diff: 21.09mlTrain batch 4/32 - 176.1ms/batch - loss: 67.45525 - diff: 23.26mlTrain batch 5/32 - 176.1ms/batch - loss: 78.23780 - diff: 26.16mlTrain batch 6/32 - 176.4ms/batch - loss: 71.14689 - diff: 25.12mlTrain batch 7/32 - 176.2ms/batch - loss: 68.41458 - diff: 24.93mlTrain batch 8/32 - 176.4ms/batch - loss: 73.58637 - diff: 25.95mlTrain batch 9/32 - 175.9ms/batch - loss: 70.30598 - diff: 25.74mlTrain batch 10/32 - 176.2ms/batch - loss: 67.95027 - diff: 25.11mlTrain batch 11/32 - 176.1ms/batch - loss: 68.28024 - diff: 25.15mlTrain batch 12/32 - 176.3ms/batch - loss: 73.54656 - diff: 26.28mlTrain batch 13/32 - 176.0ms/batch - loss: 73.33420 - diff: 26.44mlTrain batch 14/32 - 176.6ms/batch - loss: 72.04409 - diff: 26.13mlTrain batch 15/32 - 176.0ms/batch - loss: 69.94876 - diff: 25.67mlTrain batch 16/32 - 176.3ms/batch - loss: 72.43593 - diff: 26.20mlTrain batch 17/32 - 176.2ms/batch - loss: 72.44155 - diff: 26.19mlTrain batch 18/32 - 176.1ms/batch - loss: 73.78838 - diff: 26.49mlTrain batch 19/32 - 176.1ms/batch - loss: 71.88360 - diff: 26.14mlTrain batch 20/32 - 176.4ms/batch - loss: 71.05466 - diff: 26.10mlTrain batch 21/32 - 176.0ms/batch - loss: 69.33875 - diff: 25.74mlTrain batch 22/32 - 176.4ms/batch - loss: 70.16242 - diff: 26.04mlTrain batch 23/32 - 176.0ms/batch - loss: 68.51797 - diff: 25.73mlTrain batch 24/32 - 176.3ms/batch - loss: 67.79914 - diff: 25.64mlTrain batch 25/32 - 176.1ms/batch - loss: 66.96958 - diff: 25.48mlTrain batch 26/32 - 176.2ms/batch - loss: 66.39701 - diff: 25.46mlTrain batch 27/32 - 175.9ms/batch - loss: 66.17624 - diff: 25.49mlTrain batch 28/32 - 176.2ms/batch - loss: 67.34351 - diff: 25.55mlTrain batch 29/32 - 176.2ms/batch - loss: 67.41578 - diff: 25.57mlTrain batch 30/32 - 176.1ms/batch - loss: 66.34528 - diff: 25.39mlTrain batch 31/32 - 176.1ms/batch - loss: 66.99475 - diff: 25.43mlTrain batch 32/32 - 54.1ms/batch - loss: 66.76250 - diff: 25.31mlTrain batch 32/32 - 11.0s 54.1ms/batch - loss: 66.76250 - diff: 25.31ml
Test 1.1s: val_loss: 1054.31369 - diff: 121.16ml

Epoch 30: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 176.2ms/batch - loss: 55.30385 - diff: 24.96mlTrain batch 2/32 - 176.4ms/batch - loss: 46.90903 - diff: 21.55mlTrain batch 3/32 - 176.0ms/batch - loss: 65.44150 - diff: 25.19mlTrain batch 4/32 - 176.3ms/batch - loss: 84.61703 - diff: 27.48mlTrain batch 5/32 - 175.9ms/batch - loss: 83.72593 - diff: 27.74mlTrain batch 6/32 - 176.2ms/batch - loss: 77.63489 - diff: 26.67mlTrain batch 7/32 - 176.1ms/batch - loss: 77.49615 - diff: 27.32mlTrain batch 8/32 - 176.2ms/batch - loss: 78.85706 - diff: 27.81mlTrain batch 9/32 - 175.8ms/batch - loss: 73.89093 - diff: 26.91mlTrain batch 10/32 - 176.1ms/batch - loss: 73.46277 - diff: 26.97mlTrain batch 11/32 - 176.1ms/batch - loss: 68.68226 - diff: 25.79mlTrain batch 12/32 - 176.1ms/batch - loss: 67.38594 - diff: 25.43mlTrain batch 13/32 - 176.1ms/batch - loss: 68.24628 - diff: 25.48mlTrain batch 14/32 - 176.4ms/batch - loss: 68.09990 - diff: 25.58mlTrain batch 15/32 - 175.8ms/batch - loss: 69.18833 - diff: 25.85mlTrain batch 16/32 - 176.3ms/batch - loss: 68.98238 - diff: 25.97mlTrain batch 17/32 - 176.1ms/batch - loss: 67.99412 - diff: 26.04mlTrain batch 18/32 - 176.1ms/batch - loss: 68.94405 - diff: 26.08mlTrain batch 19/32 - 176.1ms/batch - loss: 68.03919 - diff: 26.04mlTrain batch 20/32 - 176.3ms/batch - loss: 66.20810 - diff: 25.64mlTrain batch 21/32 - 176.2ms/batch - loss: 64.13541 - diff: 25.14mlTrain batch 22/32 - 176.3ms/batch - loss: 63.53450 - diff: 25.11mlTrain batch 23/32 - 176.1ms/batch - loss: 63.07059 - diff: 25.20mlTrain batch 24/32 - 176.4ms/batch - loss: 63.22710 - diff: 25.22mlTrain batch 25/32 - 176.0ms/batch - loss: 61.87227 - diff: 24.97mlTrain batch 26/32 - 176.3ms/batch - loss: 62.94594 - diff: 25.14mlTrain batch 27/32 - 175.9ms/batch - loss: 62.54543 - diff: 25.02mlTrain batch 28/32 - 176.2ms/batch - loss: 63.02260 - diff: 25.19mlTrain batch 29/32 - 176.2ms/batch - loss: 63.80532 - diff: 25.33mlTrain batch 30/32 - 176.1ms/batch - loss: 63.28772 - diff: 25.17mlTrain batch 31/32 - 176.0ms/batch - loss: 64.12350 - diff: 25.33mlTrain batch 32/32 - 54.1ms/batch - loss: 64.82738 - diff: 25.27mlTrain batch 32/32 - 10.8s 54.1ms/batch - loss: 64.82738 - diff: 25.27ml
Test 1.1s: val_loss: 1126.77806 - diff: 125.15ml

Epoch 31: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 176.2ms/batch - loss: 69.97187 - diff: 29.84mlTrain batch 2/32 - 176.5ms/batch - loss: 57.13304 - diff: 24.61mlTrain batch 3/32 - 176.1ms/batch - loss: 77.91739 - diff: 27.66mlTrain batch 4/32 - 176.2ms/batch - loss: 84.11004 - diff: 28.64mlTrain batch 5/32 - 176.0ms/batch - loss: 75.58095 - diff: 27.35mlTrain batch 6/32 - 175.6ms/batch - loss: 70.75014 - diff: 26.25mlTrain batch 7/32 - 176.0ms/batch - loss: 66.01816 - diff: 25.31mlTrain batch 8/32 - 176.3ms/batch - loss: 74.67027 - diff: 26.26mlTrain batch 9/32 - 175.8ms/batch - loss: 78.65588 - diff: 26.85mlTrain batch 10/32 - 175.6ms/batch - loss: 73.91060 - diff: 25.99mlTrain batch 11/32 - 176.1ms/batch - loss: 71.50080 - diff: 25.62mlTrain batch 12/32 - 176.2ms/batch - loss: 70.88053 - diff: 25.64mlTrain batch 13/32 - 176.1ms/batch - loss: 69.19541 - diff: 25.36mlTrain batch 14/32 - 176.2ms/batch - loss: 66.47879 - diff: 24.91mlTrain batch 15/32 - 176.1ms/batch - loss: 63.22740 - diff: 24.03mlTrain batch 16/32 - 176.1ms/batch - loss: 61.89863 - diff: 23.83mlTrain batch 17/32 - 176.0ms/batch - loss: 62.82898 - diff: 23.97mlTrain batch 18/32 - 176.1ms/batch - loss: 61.47876 - diff: 23.76mlTrain batch 19/32 - 176.1ms/batch - loss: 61.77550 - diff: 23.81mlTrain batch 20/32 - 175.8ms/batch - loss: 59.62006 - diff: 23.34mlTrain batch 21/32 - 176.3ms/batch - loss: 60.13724 - diff: 23.50mlTrain batch 22/32 - 176.2ms/batch - loss: 59.92431 - diff: 23.45mlTrain batch 23/32 - 175.2ms/batch - loss: 59.36791 - diff: 23.34mlTrain batch 24/32 - 176.0ms/batch - loss: 61.10104 - diff: 23.80mlTrain batch 25/32 - 176.3ms/batch - loss: 60.53450 - diff: 23.71mlTrain batch 26/32 - 175.9ms/batch - loss: 59.37927 - diff: 23.49mlTrain batch 27/32 - 176.4ms/batch - loss: 58.51794 - diff: 23.29mlTrain batch 28/32 - 175.9ms/batch - loss: 63.57475 - diff: 23.97mlTrain batch 29/32 - 176.6ms/batch - loss: 63.60470 - diff: 24.04mlTrain batch 30/32 - 176.1ms/batch - loss: 62.28846 - diff: 23.72mlTrain batch 31/32 - 176.1ms/batch - loss: 62.18870 - diff: 23.74mlTrain batch 32/32 - 53.9ms/batch - loss: 63.00208 - diff: 23.75mlTrain batch 32/32 - 12.2s 53.9ms/batch - loss: 63.00208 - diff: 23.75ml
Test 1.1s: val_loss: 1200.95139 - diff: 129.29ml

Epoch 32: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 176.0ms/batch - loss: 77.14935 - diff: 25.31mlTrain batch 2/32 - 176.2ms/batch - loss: 74.27584 - diff: 26.51mlTrain batch 3/32 - 176.1ms/batch - loss: 80.78199 - diff: 27.93mlTrain batch 4/32 - 176.3ms/batch - loss: 76.61560 - diff: 26.83mlTrain batch 5/32 - 176.0ms/batch - loss: 69.34273 - diff: 25.49mlTrain batch 6/32 - 175.7ms/batch - loss: 86.80063 - diff: 27.90mlTrain batch 7/32 - 176.1ms/batch - loss: 84.64626 - diff: 27.72mlTrain batch 8/32 - 176.2ms/batch - loss: 81.39078 - diff: 27.32mlTrain batch 9/32 - 176.0ms/batch - loss: 79.45276 - diff: 27.19mlTrain batch 10/32 - 176.2ms/batch - loss: 79.36622 - diff: 27.39mlTrain batch 11/32 - 176.0ms/batch - loss: 75.43406 - diff: 26.45mlTrain batch 12/32 - 174.9ms/batch - loss: 70.93011 - diff: 25.56mlTrain batch 13/32 - 175.9ms/batch - loss: 69.95723 - diff: 25.64mlTrain batch 14/32 - 176.2ms/batch - loss: 71.01520 - diff: 25.99mlTrain batch 15/32 - 176.0ms/batch - loss: 71.95429 - diff: 26.14mlTrain batch 16/32 - 176.0ms/batch - loss: 70.03836 - diff: 25.90mlTrain batch 17/32 - 178.0ms/batch - loss: 69.95882 - diff: 26.00mlTrain batch 18/32 - 176.3ms/batch - loss: 68.61497 - diff: 25.76mlTrain batch 19/32 - 175.8ms/batch - loss: 69.00168 - diff: 25.70mlTrain batch 20/32 - 176.7ms/batch - loss: 67.45403 - diff: 25.49mlTrain batch 21/32 - 176.1ms/batch - loss: 66.81734 - diff: 25.43mlTrain batch 22/32 - 176.3ms/batch - loss: 65.55899 - diff: 25.18mlTrain batch 23/32 - 176.0ms/batch - loss: 64.17393 - diff: 24.72mlTrain batch 24/32 - 176.3ms/batch - loss: 64.44937 - diff: 24.93mlTrain batch 25/32 - 176.3ms/batch - loss: 64.55593 - diff: 24.95mlTrain batch 26/32 - 176.2ms/batch - loss: 64.67579 - diff: 25.04mlTrain batch 27/32 - 176.1ms/batch - loss: 63.89419 - diff: 24.91mlTrain batch 28/32 - 176.2ms/batch - loss: 64.06655 - diff: 25.01mlTrain batch 29/32 - 175.9ms/batch - loss: 64.09017 - diff: 25.18mlTrain batch 30/32 - 176.1ms/batch - loss: 65.09791 - diff: 25.34mlTrain batch 31/32 - 175.9ms/batch - loss: 65.26538 - diff: 25.47mlTrain batch 32/32 - 53.9ms/batch - loss: 69.10739 - diff: 25.62mlTrain batch 32/32 - 12.1s 53.9ms/batch - loss: 69.10739 - diff: 25.62ml
Test 1.1s: val_loss: 1352.98571 - diff: 138.82ml

Epoch 33: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 176.1ms/batch - loss: 78.49057 - diff: 28.47mlTrain batch 2/32 - 176.2ms/batch - loss: 61.20646 - diff: 25.16mlTrain batch 3/32 - 176.3ms/batch - loss: 69.90272 - diff: 27.81mlTrain batch 4/32 - 175.3ms/batch - loss: 79.11835 - diff: 29.56mlTrain batch 5/32 - 176.1ms/batch - loss: 76.25679 - diff: 28.35mlTrain batch 6/32 - 176.1ms/batch - loss: 75.76678 - diff: 28.30mlTrain batch 7/32 - 175.9ms/batch - loss: 81.75721 - diff: 29.23mlTrain batch 8/32 - 176.0ms/batch - loss: 94.72567 - diff: 31.34mlTrain batch 9/32 - 176.0ms/batch - loss: 91.46993 - diff: 30.73mlTrain batch 10/32 - 176.1ms/batch - loss: 90.46882 - diff: 30.46mlTrain batch 11/32 - 176.1ms/batch - loss: 88.82328 - diff: 30.14mlTrain batch 12/32 - 176.2ms/batch - loss: 86.93398 - diff: 29.80mlTrain batch 13/32 - 176.2ms/batch - loss: 84.88651 - diff: 29.55mlTrain batch 14/32 - 176.3ms/batch - loss: 82.23226 - diff: 29.06mlTrain batch 15/32 - 176.0ms/batch - loss: 79.85558 - diff: 28.46mlTrain batch 16/32 - 176.2ms/batch - loss: 76.15465 - diff: 27.54mlTrain batch 17/32 - 175.8ms/batch - loss: 75.20153 - diff: 27.30mlTrain batch 18/32 - 176.3ms/batch - loss: 73.84284 - diff: 27.17mlTrain batch 19/32 - 176.0ms/batch - loss: 74.33095 - diff: 27.26mlTrain batch 20/32 - 176.3ms/batch - loss: 75.14563 - diff: 27.23mlTrain batch 21/32 - 176.2ms/batch - loss: 74.25373 - diff: 27.05mlTrain batch 22/32 - 176.3ms/batch - loss: 71.85893 - diff: 26.50mlTrain batch 23/32 - 176.0ms/batch - loss: 70.19727 - diff: 26.21mlTrain batch 24/32 - 176.5ms/batch - loss: 72.37531 - diff: 26.49mlTrain batch 25/32 - 176.1ms/batch - loss: 72.49658 - diff: 26.62mlTrain batch 26/32 - 176.5ms/batch - loss: 71.97222 - diff: 26.50mlTrain batch 27/32 - 176.1ms/batch - loss: 71.86031 - diff: 26.54mlTrain batch 28/32 - 176.4ms/batch - loss: 71.18926 - diff: 26.39mlTrain batch 29/32 - 176.1ms/batch - loss: 69.74826 - diff: 26.11mlTrain batch 30/32 - 176.2ms/batch - loss: 68.82230 - diff: 25.93mlTrain batch 31/32 - 176.2ms/batch - loss: 67.32325 - diff: 25.56mlTrain batch 32/32 - 54.1ms/batch - loss: 68.56709 - diff: 25.54mlTrain batch 32/32 - 11.5s 54.1ms/batch - loss: 68.56709 - diff: 25.54ml
Test 1.1s: val_loss: 1257.93545 - diff: 133.13ml

Epoch 34: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 176.2ms/batch - loss: 49.73446 - diff: 22.11mlTrain batch 2/32 - 176.3ms/batch - loss: 48.65453 - diff: 21.93mlTrain batch 3/32 - 176.0ms/batch - loss: 49.95370 - diff: 22.84mlTrain batch 4/32 - 176.7ms/batch - loss: 54.15948 - diff: 23.38mlTrain batch 5/32 - 175.9ms/batch - loss: 56.03174 - diff: 23.80mlTrain batch 6/32 - 176.3ms/batch - loss: 61.33551 - diff: 24.78mlTrain batch 7/32 - 176.1ms/batch - loss: 58.53794 - diff: 24.18mlTrain batch 8/32 - 175.7ms/batch - loss: 59.25036 - diff: 24.14mlTrain batch 9/32 - 175.9ms/batch - loss: 56.70269 - diff: 23.54mlTrain batch 10/32 - 176.4ms/batch - loss: 58.93621 - diff: 24.01mlTrain batch 11/32 - 175.8ms/batch - loss: 59.80720 - diff: 24.13mlTrain batch 12/32 - 176.5ms/batch - loss: 59.38272 - diff: 24.03mlTrain batch 13/32 - 176.1ms/batch - loss: 56.28522 - diff: 23.28mlTrain batch 14/32 - 176.7ms/batch - loss: 55.60183 - diff: 23.33mlTrain batch 15/32 - 175.9ms/batch - loss: 53.49154 - diff: 22.87mlTrain batch 16/32 - 176.4ms/batch - loss: 53.52611 - diff: 22.94mlTrain batch 17/32 - 176.1ms/batch - loss: 52.81093 - diff: 22.79mlTrain batch 18/32 - 176.3ms/batch - loss: 53.87783 - diff: 22.97mlTrain batch 19/32 - 176.0ms/batch - loss: 52.46283 - diff: 22.69mlTrain batch 20/32 - 176.4ms/batch - loss: 52.61947 - diff: 22.70mlTrain batch 21/32 - 176.1ms/batch - loss: 53.15607 - diff: 22.78mlTrain batch 22/32 - 175.1ms/batch - loss: 52.80523 - diff: 22.77mlTrain batch 23/32 - 175.6ms/batch - loss: 52.82984 - diff: 22.88mlTrain batch 24/32 - 175.9ms/batch - loss: 54.80616 - diff: 23.21mlTrain batch 25/32 - 176.0ms/batch - loss: 54.04267 - diff: 23.09mlTrain batch 26/32 - 176.1ms/batch - loss: 53.61608 - diff: 23.00mlTrain batch 27/32 - 176.1ms/batch - loss: 57.65094 - diff: 23.62mlTrain batch 28/32 - 176.1ms/batch - loss: 56.86763 - diff: 23.50mlTrain batch 29/32 - 176.1ms/batch - loss: 55.99209 - diff: 23.35mlTrain batch 30/32 - 176.5ms/batch - loss: 56.26937 - diff: 23.40mlTrain batch 31/32 - 176.1ms/batch - loss: 57.68177 - diff: 23.62mlTrain batch 32/32 - 54.1ms/batch - loss: 58.79064 - diff: 23.61mlTrain batch 32/32 - 11.7s 54.1ms/batch - loss: 58.79064 - diff: 23.61ml
Test 1.1s: val_loss: 1253.66720 - diff: 132.48ml

Epoch 35: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 176.0ms/batch - loss: 50.98606 - diff: 20.06mlTrain batch 2/32 - 175.6ms/batch - loss: 62.38519 - diff: 22.75mlTrain batch 3/32 - 176.2ms/batch - loss: 55.45827 - diff: 22.33mlTrain batch 4/32 - 176.3ms/batch - loss: 64.24844 - diff: 24.51mlTrain batch 5/32 - 176.0ms/batch - loss: 57.01110 - diff: 22.92mlTrain batch 6/32 - 176.6ms/batch - loss: 55.18290 - diff: 22.56mlTrain batch 7/32 - 175.9ms/batch - loss: 56.68451 - diff: 23.26mlTrain batch 8/32 - 176.5ms/batch - loss: 54.80665 - diff: 23.08mlTrain batch 9/32 - 176.0ms/batch - loss: 58.49754 - diff: 24.23mlTrain batch 10/32 - 176.1ms/batch - loss: 56.58430 - diff: 23.88mlTrain batch 11/32 - 176.4ms/batch - loss: 55.36654 - diff: 23.54mlTrain batch 12/32 - 176.4ms/batch - loss: 56.52695 - diff: 23.72mlTrain batch 13/32 - 175.9ms/batch - loss: 56.21888 - diff: 23.83mlTrain batch 14/32 - 176.4ms/batch - loss: 58.06092 - diff: 24.37mlTrain batch 15/32 - 175.9ms/batch - loss: 56.40884 - diff: 24.00mlTrain batch 16/32 - 176.4ms/batch - loss: 55.43292 - diff: 23.82mlTrain batch 17/32 - 176.1ms/batch - loss: 62.02808 - diff: 24.53mlTrain batch 18/32 - 176.5ms/batch - loss: 60.95322 - diff: 24.28mlTrain batch 19/32 - 175.9ms/batch - loss: 60.64616 - diff: 24.31mlTrain batch 20/32 - 176.1ms/batch - loss: 59.53101 - diff: 24.17mlTrain batch 21/32 - 176.1ms/batch - loss: 59.03006 - diff: 24.08mlTrain batch 22/32 - 175.9ms/batch - loss: 58.45511 - diff: 23.92mlTrain batch 23/32 - 176.4ms/batch - loss: 59.11558 - diff: 24.05mlTrain batch 24/32 - 175.9ms/batch - loss: 59.22784 - diff: 24.01mlTrain batch 25/32 - 176.5ms/batch - loss: 58.43515 - diff: 23.89mlTrain batch 26/32 - 176.2ms/batch - loss: 57.98176 - diff: 23.74mlTrain batch 27/32 - 176.4ms/batch - loss: 57.68582 - diff: 23.71mlTrain batch 28/32 - 175.9ms/batch - loss: 56.67650 - diff: 23.51mlTrain batch 29/32 - 176.3ms/batch - loss: 55.76504 - diff: 23.33mlTrain batch 30/32 - 175.9ms/batch - loss: 56.31727 - diff: 23.45mlTrain batch 31/32 - 175.4ms/batch - loss: 58.15970 - diff: 23.66mlTrain batch 32/32 - 54.1ms/batch - loss: 60.23612 - diff: 23.71mlTrain batch 32/32 - 11.3s 54.1ms/batch - loss: 60.23612 - diff: 23.71ml
Test 1.1s: val_loss: 1135.55206 - diff: 126.82ml

Epoch 36: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 176.0ms/batch - loss: 44.24754 - diff: 21.77mlTrain batch 2/32 - 175.8ms/batch - loss: 34.50728 - diff: 18.77mlTrain batch 3/32 - 175.9ms/batch - loss: 52.50870 - diff: 20.53mlTrain batch 4/32 - 176.5ms/batch - loss: 56.37971 - diff: 21.83mlTrain batch 5/32 - 175.9ms/batch - loss: 56.96209 - diff: 22.27mlTrain batch 6/32 - 176.2ms/batch - loss: 55.52423 - diff: 22.52mlTrain batch 7/32 - 176.1ms/batch - loss: 50.34744 - diff: 21.30mlTrain batch 8/32 - 176.6ms/batch - loss: 50.28400 - diff: 21.27mlTrain batch 9/32 - 176.1ms/batch - loss: 50.37653 - diff: 21.85mlTrain batch 10/32 - 176.3ms/batch - loss: 50.55656 - diff: 22.12mlTrain batch 11/32 - 176.1ms/batch - loss: 50.62776 - diff: 22.19mlTrain batch 12/32 - 176.5ms/batch - loss: 50.66741 - diff: 22.37mlTrain batch 13/32 - 176.3ms/batch - loss: 52.21233 - diff: 22.91mlTrain batch 14/32 - 176.3ms/batch - loss: 52.34093 - diff: 22.89mlTrain batch 15/32 - 176.0ms/batch - loss: 52.76948 - diff: 22.86mlTrain batch 16/32 - 176.5ms/batch - loss: 54.62290 - diff: 23.27mlTrain batch 17/32 - 176.2ms/batch - loss: 54.00583 - diff: 23.18mlTrain batch 18/32 - 176.3ms/batch - loss: 55.10143 - diff: 23.33mlTrain batch 19/32 - 176.0ms/batch - loss: 56.13606 - diff: 23.51mlTrain batch 20/32 - 176.4ms/batch - loss: 56.64791 - diff: 23.43mlTrain batch 21/32 - 176.0ms/batch - loss: 57.02893 - diff: 23.60mlTrain batch 22/32 - 176.2ms/batch - loss: 56.75437 - diff: 23.57mlTrain batch 23/32 - 176.0ms/batch - loss: 57.42632 - diff: 23.60mlTrain batch 24/32 - 176.2ms/batch - loss: 57.28796 - diff: 23.66mlTrain batch 25/32 - 176.1ms/batch - loss: 66.95964 - diff: 24.45mlTrain batch 26/32 - 176.3ms/batch - loss: 65.82090 - diff: 24.24mlTrain batch 27/32 - 176.0ms/batch - loss: 68.31063 - diff: 24.75mlTrain batch 28/32 - 176.5ms/batch - loss: 68.25957 - diff: 24.77mlTrain batch 29/32 - 176.0ms/batch - loss: 67.38083 - diff: 24.59mlTrain batch 30/32 - 176.2ms/batch - loss: 65.99191 - diff: 24.36mlTrain batch 31/32 - 176.4ms/batch - loss: 65.37602 - diff: 24.30mlTrain batch 32/32 - 54.1ms/batch - loss: 65.27962 - diff: 24.17mlTrain batch 32/32 - 11.5s 54.1ms/batch - loss: 65.27962 - diff: 24.17ml
Test 1.1s: val_loss: 1481.38783 - diff: 146.12ml

Epoch 37: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 176.1ms/batch - loss: 19.34222 - diff: 13.59mlTrain batch 2/32 - 176.5ms/batch - loss: 36.42649 - diff: 17.24mlTrain batch 3/32 - 175.9ms/batch - loss: 51.02853 - diff: 21.25mlTrain batch 4/32 - 176.2ms/batch - loss: 52.45904 - diff: 21.65mlTrain batch 5/32 - 175.9ms/batch - loss: 53.00412 - diff: 22.86mlTrain batch 6/32 - 176.3ms/batch - loss: 53.22960 - diff: 22.83mlTrain batch 7/32 - 176.0ms/batch - loss: 50.71941 - diff: 21.92mlTrain batch 8/32 - 176.3ms/batch - loss: 51.78355 - diff: 22.16mlTrain batch 9/32 - 176.2ms/batch - loss: 52.29633 - diff: 22.42mlTrain batch 10/32 - 176.1ms/batch - loss: 50.97156 - diff: 22.14mlTrain batch 11/32 - 176.1ms/batch - loss: 53.78588 - diff: 22.70mlTrain batch 12/32 - 176.3ms/batch - loss: 55.57828 - diff: 23.16mlTrain batch 13/32 - 176.1ms/batch - loss: 55.71711 - diff: 23.30mlTrain batch 14/32 - 176.1ms/batch - loss: 59.80786 - diff: 23.77mlTrain batch 15/32 - 176.1ms/batch - loss: 59.59213 - diff: 23.80mlTrain batch 16/32 - 176.3ms/batch - loss: 59.02137 - diff: 23.84mlTrain batch 17/32 - 176.0ms/batch - loss: 57.89705 - diff: 23.76mlTrain batch 18/32 - 176.2ms/batch - loss: 57.69252 - diff: 23.86mlTrain batch 19/32 - 176.0ms/batch - loss: 58.09234 - diff: 23.85mlTrain batch 20/32 - 176.4ms/batch - loss: 57.47735 - diff: 23.74mlTrain batch 21/32 - 176.1ms/batch - loss: 57.06910 - diff: 23.66mlTrain batch 22/32 - 176.2ms/batch - loss: 57.14658 - diff: 23.78mlTrain batch 23/32 - 176.0ms/batch - loss: 56.49168 - diff: 23.71mlTrain batch 24/32 - 176.1ms/batch - loss: 55.67435 - diff: 23.55mlTrain batch 25/32 - 176.3ms/batch - loss: 55.03842 - diff: 23.47mlTrain batch 26/32 - 176.1ms/batch - loss: 54.86564 - diff: 23.45mlTrain batch 27/32 - 176.5ms/batch - loss: 55.35675 - diff: 23.52mlTrain batch 28/32 - 176.2ms/batch - loss: 54.03749 - diff: 23.17mlTrain batch 29/32 - 176.3ms/batch - loss: 55.42824 - diff: 23.51mlTrain batch 30/32 - 175.8ms/batch - loss: 58.15767 - diff: 23.77mlTrain batch 31/32 - 176.3ms/batch - loss: 57.76378 - diff: 23.71mlTrain batch 32/32 - 54.1ms/batch - loss: 58.18004 - diff: 23.67mlTrain batch 32/32 - 11.3s 54.1ms/batch - loss: 58.18004 - diff: 23.67ml
Test 1.1s: val_loss: 1277.65741 - diff: 134.01ml

Epoch 38: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 176.3ms/batch - loss: 33.77702 - diff: 19.26mlTrain batch 2/32 - 176.5ms/batch - loss: 62.98309 - diff: 27.01mlTrain batch 3/32 - 176.2ms/batch - loss: 68.35271 - diff: 27.01mlTrain batch 4/32 - 176.2ms/batch - loss: 58.98911 - diff: 24.68mlTrain batch 5/32 - 176.0ms/batch - loss: 66.42048 - diff: 26.25mlTrain batch 6/32 - 176.4ms/batch - loss: 69.32142 - diff: 26.58mlTrain batch 7/32 - 176.1ms/batch - loss: 63.61841 - diff: 25.18mlTrain batch 8/32 - 176.4ms/batch - loss: 61.19193 - diff: 24.55mlTrain batch 9/32 - 176.1ms/batch - loss: 61.56621 - diff: 24.76mlTrain batch 10/32 - 176.2ms/batch - loss: 59.11216 - diff: 24.05mlTrain batch 11/32 - 176.0ms/batch - loss: 57.37916 - diff: 23.83mlTrain batch 12/32 - 176.2ms/batch - loss: 59.59350 - diff: 24.26mlTrain batch 13/32 - 176.3ms/batch - loss: 60.05823 - diff: 24.18mlTrain batch 14/32 - 176.3ms/batch - loss: 64.05564 - diff: 24.87mlTrain batch 15/32 - 175.7ms/batch - loss: 64.02593 - diff: 24.76mlTrain batch 16/32 - 176.3ms/batch - loss: 63.23561 - diff: 24.66mlTrain batch 17/32 - 176.1ms/batch - loss: 63.01842 - diff: 24.61mlTrain batch 18/32 - 176.3ms/batch - loss: 61.43322 - diff: 24.37mlTrain batch 19/32 - 176.0ms/batch - loss: 59.73057 - diff: 23.97mlTrain batch 20/32 - 176.0ms/batch - loss: 58.34250 - diff: 23.70mlTrain batch 21/32 - 175.3ms/batch - loss: 59.65365 - diff: 24.10mlTrain batch 22/32 - 176.0ms/batch - loss: 58.50921 - diff: 23.86mlTrain batch 23/32 - 175.6ms/batch - loss: 60.16939 - diff: 24.15mlTrain batch 24/32 - 176.0ms/batch - loss: 60.58488 - diff: 24.27mlTrain batch 25/32 - 176.4ms/batch - loss: 59.74155 - diff: 24.12mlTrain batch 26/32 - 176.2ms/batch - loss: 59.95964 - diff: 24.27mlTrain batch 27/32 - 175.0ms/batch - loss: 60.23314 - diff: 24.12mlTrain batch 28/32 - 175.9ms/batch - loss: 61.89026 - diff: 24.46mlTrain batch 29/32 - 176.2ms/batch - loss: 63.28283 - diff: 24.78mlTrain batch 30/32 - 176.0ms/batch - loss: 65.77787 - diff: 25.37mlTrain batch 31/32 - 174.8ms/batch - loss: 64.81757 - diff: 25.14mlTrain batch 32/32 - 54.3ms/batch - loss: 66.75712 - diff: 25.17mlTrain batch 32/32 - 11.5s 54.3ms/batch - loss: 66.75712 - diff: 25.17ml
Test 1.1s: val_loss: 1473.78778 - diff: 144.80ml

Epoch 39: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 176.3ms/batch - loss: 49.53020 - diff: 22.87mlTrain batch 2/32 - 176.2ms/batch - loss: 52.36694 - diff: 23.71mlTrain batch 3/32 - 176.1ms/batch - loss: 44.46422 - diff: 21.17mlTrain batch 4/32 - 176.4ms/batch - loss: 44.15611 - diff: 20.90mlTrain batch 5/32 - 176.1ms/batch - loss: 41.03036 - diff: 20.50mlTrain batch 6/32 - 176.3ms/batch - loss: 38.98131 - diff: 20.10mlTrain batch 7/32 - 176.1ms/batch - loss: 37.00928 - diff: 19.54mlTrain batch 8/32 - 176.5ms/batch - loss: 35.73699 - diff: 19.35mlTrain batch 9/32 - 175.8ms/batch - loss: 36.77885 - diff: 19.40mlTrain batch 10/32 - 175.4ms/batch - loss: 39.43486 - diff: 20.05mlTrain batch 11/32 - 176.1ms/batch - loss: 39.99280 - diff: 20.21mlTrain batch 12/32 - 176.2ms/batch - loss: 45.00937 - diff: 21.17mlTrain batch 13/32 - 176.3ms/batch - loss: 46.41297 - diff: 21.46mlTrain batch 14/32 - 176.4ms/batch - loss: 47.70022 - diff: 21.85mlTrain batch 15/32 - 176.2ms/batch - loss: 53.41790 - diff: 22.63mlTrain batch 16/32 - 176.2ms/batch - loss: 53.61377 - diff: 22.78mlTrain batch 17/32 - 176.4ms/batch - loss: 51.86637 - diff: 22.40mlTrain batch 18/32 - 176.0ms/batch - loss: 53.40218 - diff: 22.77mlTrain batch 19/32 - 175.4ms/batch - loss: 52.69606 - diff: 22.65mlTrain batch 20/32 - 176.0ms/batch - loss: 53.17923 - diff: 22.80mlTrain batch 21/32 - 176.1ms/batch - loss: 52.32211 - diff: 22.68mlTrain batch 22/32 - 176.0ms/batch - loss: 51.17882 - diff: 22.47mlTrain batch 23/32 - 176.4ms/batch - loss: 53.15062 - diff: 22.87mlTrain batch 24/32 - 176.2ms/batch - loss: 55.62469 - diff: 23.33mlTrain batch 25/32 - 176.3ms/batch - loss: 56.52390 - diff: 23.44mlTrain batch 26/32 - 175.9ms/batch - loss: 56.71895 - diff: 23.40mlTrain batch 27/32 - 176.3ms/batch - loss: 58.55456 - diff: 23.80mlTrain batch 28/32 - 175.8ms/batch - loss: 57.98616 - diff: 23.78mlTrain batch 29/32 - 176.5ms/batch - loss: 56.79408 - diff: 23.50mlTrain batch 30/32 - 176.0ms/batch - loss: 58.52871 - diff: 23.69mlTrain batch 31/32 - 176.4ms/batch - loss: 57.83934 - diff: 23.52mlTrain batch 32/32 - 54.2ms/batch - loss: 64.71546 - diff: 23.79mlTrain batch 32/32 - 11.8s 54.2ms/batch - loss: 64.71546 - diff: 23.79ml
Test 1.1s: val_loss: 1834.51537 - diff: 163.66ml
Epoch    40: reducing learning rate of group 0 to 1.2500e-04.

Epoch 40: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 176.0ms/batch - loss: 54.16023 - diff: 21.51mlTrain batch 2/32 - 176.4ms/batch - loss: 39.00520 - diff: 18.52mlTrain batch 3/32 - 176.1ms/batch - loss: 42.08309 - diff: 19.87mlTrain batch 4/32 - 176.2ms/batch - loss: 44.42665 - diff: 20.95mlTrain batch 5/32 - 176.0ms/batch - loss: 45.05119 - diff: 21.12mlTrain batch 6/32 - 176.0ms/batch - loss: 44.64475 - diff: 20.95mlTrain batch 7/32 - 176.2ms/batch - loss: 49.64032 - diff: 21.60mlTrain batch 8/32 - 176.1ms/batch - loss: 46.94747 - diff: 21.10mlTrain batch 9/32 - 176.1ms/batch - loss: 53.39201 - diff: 22.19mlTrain batch 10/32 - 176.1ms/batch - loss: 51.13070 - diff: 21.95mlTrain batch 11/32 - 176.2ms/batch - loss: 48.56656 - diff: 21.28mlTrain batch 12/32 - 176.2ms/batch - loss: 53.38023 - diff: 22.25mlTrain batch 13/32 - 176.0ms/batch - loss: 52.31756 - diff: 22.15mlTrain batch 14/32 - 176.2ms/batch - loss: 52.70951 - diff: 22.39mlTrain batch 15/32 - 176.2ms/batch - loss: 54.25000 - diff: 22.77mlTrain batch 16/32 - 176.2ms/batch - loss: 53.29965 - diff: 22.77mlTrain batch 17/32 - 175.8ms/batch - loss: 53.64933 - diff: 22.94mlTrain batch 18/32 - 176.3ms/batch - loss: 53.04167 - diff: 22.87mlTrain batch 19/32 - 176.3ms/batch - loss: 54.14555 - diff: 23.09mlTrain batch 20/32 - 176.3ms/batch - loss: 54.05588 - diff: 23.05mlTrain batch 21/32 - 176.1ms/batch - loss: 55.85170 - diff: 23.29mlTrain batch 22/32 - 176.3ms/batch - loss: 55.41917 - diff: 23.37mlTrain batch 23/32 - 176.5ms/batch - loss: 54.78301 - diff: 23.24mlTrain batch 24/32 - 176.3ms/batch - loss: 53.84613 - diff: 23.03mlTrain batch 25/32 - 176.2ms/batch - loss: 53.18650 - diff: 22.87mlTrain batch 26/32 - 176.5ms/batch - loss: 52.41639 - diff: 22.79mlTrain batch 27/32 - 176.1ms/batch - loss: 51.86003 - diff: 22.70mlTrain batch 28/32 - 176.5ms/batch - loss: 52.51533 - diff: 22.88mlTrain batch 29/32 - 176.1ms/batch - loss: 51.99093 - diff: 22.76mlTrain batch 30/32 - 176.5ms/batch - loss: 51.27740 - diff: 22.52mlTrain batch 31/32 - 176.1ms/batch - loss: 50.66861 - diff: 22.46mlTrain batch 32/32 - 54.1ms/batch - loss: 53.12527 - diff: 22.56mlTrain batch 32/32 - 11.6s 54.1ms/batch - loss: 53.12527 - diff: 22.56ml
Test 1.1s: val_loss: 1562.84416 - diff: 150.79ml

Epoch 41: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 176.2ms/batch - loss: 59.15151 - diff: 26.62mlTrain batch 2/32 - 176.3ms/batch - loss: 55.99148 - diff: 25.80mlTrain batch 3/32 - 176.1ms/batch - loss: 71.76473 - diff: 27.69mlTrain batch 4/32 - 176.2ms/batch - loss: 68.67450 - diff: 27.37mlTrain batch 5/32 - 176.0ms/batch - loss: 61.58589 - diff: 25.58mlTrain batch 6/32 - 176.2ms/batch - loss: 60.18887 - diff: 25.39mlTrain batch 7/32 - 176.2ms/batch - loss: 58.14798 - diff: 24.95mlTrain batch 8/32 - 176.2ms/batch - loss: 54.24858 - diff: 23.96mlTrain batch 9/32 - 176.0ms/batch - loss: 52.01602 - diff: 23.44mlTrain batch 10/32 - 176.2ms/batch - loss: 51.76122 - diff: 23.55mlTrain batch 11/32 - 176.1ms/batch - loss: 51.58106 - diff: 23.40mlTrain batch 12/32 - 176.2ms/batch - loss: 52.69168 - diff: 23.57mlTrain batch 13/32 - 176.1ms/batch - loss: 51.27741 - diff: 23.30mlTrain batch 14/32 - 176.1ms/batch - loss: 52.69583 - diff: 23.49mlTrain batch 15/32 - 176.1ms/batch - loss: 53.10864 - diff: 23.54mlTrain batch 16/32 - 176.2ms/batch - loss: 53.63448 - diff: 23.69mlTrain batch 17/32 - 176.1ms/batch - loss: 54.29438 - diff: 23.85mlTrain batch 18/32 - 176.1ms/batch - loss: 53.75975 - diff: 23.73mlTrain batch 19/32 - 176.1ms/batch - loss: 53.53102 - diff: 23.73mlTrain batch 20/32 - 176.2ms/batch - loss: 56.90261 - diff: 24.08mlTrain batch 21/32 - 176.2ms/batch - loss: 57.93595 - diff: 24.30mlTrain batch 22/32 - 176.2ms/batch - loss: 58.20953 - diff: 24.35mlTrain batch 23/32 - 176.0ms/batch - loss: 57.48644 - diff: 24.29mlTrain batch 24/32 - 176.1ms/batch - loss: 57.06086 - diff: 24.19mlTrain batch 25/32 - 176.0ms/batch - loss: 56.08869 - diff: 23.93mlTrain batch 26/32 - 176.2ms/batch - loss: 56.37697 - diff: 23.84mlTrain batch 27/32 - 176.2ms/batch - loss: 57.80476 - diff: 24.22mlTrain batch 28/32 - 176.4ms/batch - loss: 56.66000 - diff: 23.94mlTrain batch 29/32 - 176.0ms/batch - loss: 56.15162 - diff: 23.77mlTrain batch 30/32 - 176.4ms/batch - loss: 55.90411 - diff: 23.74mlTrain batch 31/32 - 176.1ms/batch - loss: 72.31929 - diff: 25.63mlTrain batch 32/32 - 54.2ms/batch - loss: 73.83858 - diff: 25.61mlTrain batch 32/32 - 11.0s 54.2ms/batch - loss: 73.83858 - diff: 25.61ml
Test 1.1s: val_loss: 1360.76682 - diff: 139.87ml

Epoch 42: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 176.2ms/batch - loss: 66.52040 - diff: 25.77mlTrain batch 2/32 - 176.5ms/batch - loss: 73.52661 - diff: 27.08mlTrain batch 3/32 - 176.3ms/batch - loss: 65.31996 - diff: 25.84mlTrain batch 4/32 - 176.6ms/batch - loss: 83.22254 - diff: 26.64mlTrain batch 5/32 - 176.1ms/batch - loss: 74.31477 - diff: 25.72mlTrain batch 6/32 - 176.3ms/batch - loss: 75.90487 - diff: 26.61mlTrain batch 7/32 - 176.0ms/batch - loss: 70.38320 - diff: 25.54mlTrain batch 8/32 - 176.2ms/batch - loss: 77.55180 - diff: 26.93mlTrain batch 9/32 - 176.1ms/batch - loss: 72.10045 - diff: 25.91mlTrain batch 10/32 - 176.4ms/batch - loss: 75.36877 - diff: 26.32mlTrain batch 11/32 - 176.1ms/batch - loss: 75.46065 - diff: 26.54mlTrain batch 12/32 - 176.4ms/batch - loss: 77.38730 - diff: 26.97mlTrain batch 13/32 - 176.4ms/batch - loss: 74.29709 - diff: 26.28mlTrain batch 14/32 - 176.8ms/batch - loss: 70.98928 - diff: 25.60mlTrain batch 15/32 - 176.3ms/batch - loss: 69.92648 - diff: 25.52mlTrain batch 16/32 - 176.5ms/batch - loss: 68.20316 - diff: 25.34mlTrain batch 17/32 - 176.2ms/batch - loss: 65.87265 - diff: 24.86mlTrain batch 18/32 - 176.6ms/batch - loss: 63.65095 - diff: 24.40mlTrain batch 19/32 - 176.3ms/batch - loss: 62.35655 - diff: 24.19mlTrain batch 20/32 - 176.4ms/batch - loss: 63.98743 - diff: 24.41mlTrain batch 21/32 - 176.4ms/batch - loss: 63.32827 - diff: 24.15mlTrain batch 22/32 - 176.3ms/batch - loss: 62.20994 - diff: 23.91mlTrain batch 23/32 - 176.2ms/batch - loss: 62.29998 - diff: 24.08mlTrain batch 24/32 - 176.4ms/batch - loss: 61.24403 - diff: 23.79mlTrain batch 25/32 - 176.2ms/batch - loss: 60.58868 - diff: 23.71mlTrain batch 26/32 - 176.4ms/batch - loss: 60.87752 - diff: 23.82mlTrain batch 27/32 - 176.3ms/batch - loss: 60.17841 - diff: 23.70mlTrain batch 28/32 - 176.4ms/batch - loss: 60.89705 - diff: 23.89mlTrain batch 29/32 - 176.1ms/batch - loss: 60.46858 - diff: 23.83mlTrain batch 30/32 - 176.3ms/batch - loss: 59.72598 - diff: 23.68mlTrain batch 31/32 - 176.2ms/batch - loss: 59.95715 - diff: 23.68mlTrain batch 32/32 - 54.1ms/batch - loss: 63.62182 - diff: 23.82mlTrain batch 32/32 - 10.6s 54.1ms/batch - loss: 63.62182 - diff: 23.82ml
Test 1.1s: val_loss: 1768.64599 - diff: 158.24ml

Epoch 43: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 176.4ms/batch - loss: 47.03027 - diff: 21.96mlTrain batch 2/32 - 176.8ms/batch - loss: 41.53722 - diff: 20.94mlTrain batch 3/32 - 176.2ms/batch - loss: 39.89616 - diff: 20.74mlTrain batch 4/32 - 176.5ms/batch - loss: 45.98938 - diff: 22.00mlTrain batch 5/32 - 176.2ms/batch - loss: 48.17030 - diff: 22.11mlTrain batch 6/32 - 176.2ms/batch - loss: 46.64772 - diff: 21.73mlTrain batch 7/32 - 176.2ms/batch - loss: 49.31544 - diff: 22.04mlTrain batch 8/32 - 176.2ms/batch - loss: 49.84552 - diff: 22.10mlTrain batch 9/32 - 176.1ms/batch - loss: 48.51721 - diff: 21.57mlTrain batch 10/32 - 176.3ms/batch - loss: 51.90869 - diff: 22.27mlTrain batch 11/32 - 176.1ms/batch - loss: 50.79547 - diff: 22.28mlTrain batch 12/32 - 176.3ms/batch - loss: 59.34923 - diff: 24.09mlTrain batch 13/32 - 176.2ms/batch - loss: 61.65038 - diff: 24.82mlTrain batch 14/32 - 176.5ms/batch - loss: 63.82297 - diff: 25.02mlTrain batch 15/32 - 176.5ms/batch - loss: 64.62566 - diff: 25.20mlTrain batch 16/32 - 176.4ms/batch - loss: 63.92854 - diff: 25.31mlTrain batch 17/32 - 176.0ms/batch - loss: 66.17768 - diff: 25.78mlTrain batch 18/32 - 176.5ms/batch - loss: 64.37552 - diff: 25.33mlTrain batch 19/32 - 176.3ms/batch - loss: 62.12386 - diff: 24.68mlTrain batch 20/32 - 176.4ms/batch - loss: 61.64884 - diff: 24.61mlTrain batch 21/32 - 176.0ms/batch - loss: 60.41557 - diff: 24.32mlTrain batch 22/32 - 176.1ms/batch - loss: 58.90639 - diff: 23.93mlTrain batch 23/32 - 176.0ms/batch - loss: 58.35527 - diff: 23.82mlTrain batch 24/32 - 176.2ms/batch - loss: 59.24842 - diff: 24.16mlTrain batch 25/32 - 176.2ms/batch - loss: 59.58857 - diff: 24.25mlTrain batch 26/32 - 176.6ms/batch - loss: 66.97917 - diff: 24.83mlTrain batch 27/32 - 176.3ms/batch - loss: 66.85500 - diff: 24.96mlTrain batch 28/32 - 176.5ms/batch - loss: 68.77121 - diff: 25.28mlTrain batch 29/32 - 176.1ms/batch - loss: 67.06140 - diff: 24.89mlTrain batch 30/32 - 176.2ms/batch - loss: 66.54492 - diff: 24.89mlTrain batch 31/32 - 176.2ms/batch - loss: 66.26393 - diff: 24.92mlTrain batch 32/32 - 53.9ms/batch - loss: 72.36743 - diff: 25.04mlTrain batch 32/32 - 10.8s 53.9ms/batch - loss: 72.36743 - diff: 25.04ml
Test 1.1s: val_loss: 1529.73214 - diff: 148.69ml

Epoch 44: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 176.4ms/batch - loss: 33.07380 - diff: 19.38mlTrain batch 2/32 - 176.3ms/batch - loss: 50.13783 - diff: 22.26mlTrain batch 3/32 - 176.1ms/batch - loss: 58.57631 - diff: 24.27mlTrain batch 4/32 - 176.5ms/batch - loss: 57.26003 - diff: 22.61mlTrain batch 5/32 - 176.2ms/batch - loss: 61.07000 - diff: 23.21mlTrain batch 6/32 - 176.3ms/batch - loss: 61.64151 - diff: 23.75mlTrain batch 7/32 - 176.4ms/batch - loss: 59.70838 - diff: 23.33mlTrain batch 8/32 - 175.7ms/batch - loss: 91.61132 - diff: 25.15mlTrain batch 9/32 - 176.2ms/batch - loss: 83.91159 - diff: 23.95mlTrain batch 10/32 - 176.4ms/batch - loss: 79.36172 - diff: 23.70mlTrain batch 11/32 - 176.2ms/batch - loss: 75.34495 - diff: 23.36mlTrain batch 12/32 - 176.4ms/batch - loss: 72.33463 - diff: 23.32mlTrain batch 13/32 - 176.1ms/batch - loss: 69.99491 - diff: 23.19mlTrain batch 14/32 - 176.6ms/batch - loss: 67.22897 - diff: 22.77mlTrain batch 15/32 - 175.9ms/batch - loss: 69.09472 - diff: 23.18mlTrain batch 16/32 - 176.3ms/batch - loss: 67.53330 - diff: 23.01mlTrain batch 17/32 - 176.2ms/batch - loss: 66.38727 - diff: 23.08mlTrain batch 18/32 - 176.3ms/batch - loss: 66.38521 - diff: 23.34mlTrain batch 19/32 - 176.3ms/batch - loss: 66.26917 - diff: 23.55mlTrain batch 20/32 - 176.3ms/batch - loss: 65.27896 - diff: 23.51mlTrain batch 21/32 - 176.1ms/batch - loss: 65.13213 - diff: 23.66mlTrain batch 22/32 - 176.4ms/batch - loss: 65.09392 - diff: 23.81mlTrain batch 23/32 - 176.2ms/batch - loss: 64.76828 - diff: 23.88mlTrain batch 24/32 - 176.6ms/batch - loss: 64.05743 - diff: 23.80mlTrain batch 25/32 - 176.1ms/batch - loss: 63.46618 - diff: 23.84mlTrain batch 26/32 - 176.3ms/batch - loss: 62.48561 - diff: 23.47mlTrain batch 27/32 - 176.4ms/batch - loss: 62.61619 - diff: 23.59mlTrain batch 28/32 - 176.2ms/batch - loss: 63.46335 - diff: 23.81mlTrain batch 29/32 - 176.2ms/batch - loss: 64.28486 - diff: 24.07mlTrain batch 30/32 - 176.2ms/batch - loss: 62.80612 - diff: 23.76mlTrain batch 31/32 - 176.1ms/batch - loss: 62.79826 - diff: 23.89mlTrain batch 32/32 - 54.1ms/batch - loss: 64.74647 - diff: 23.90mlTrain batch 32/32 - 10.7s 54.1ms/batch - loss: 64.74647 - diff: 23.90ml
Test 1.1s: val_loss: 1731.21862 - diff: 157.91ml

Epoch 45: current best loss = 101.53151, at epoch 6
Going to unfreeze the pretrained weights
Train batch 1/32 - 238.1ms/batch - loss: 74.53571 - diff: 30.34mlTrain batch 2/32 - 240.0ms/batch - loss: 131.97524 - diff: 37.99mlTrain batch 3/32 - 239.1ms/batch - loss: 116.02889 - diff: 34.53mlTrain batch 4/32 - 239.5ms/batch - loss: 109.55955 - diff: 33.98mlTrain batch 5/32 - 239.5ms/batch - loss: 102.14006 - diff: 32.77mlTrain batch 6/32 - 239.4ms/batch - loss: 108.57822 - diff: 34.40mlTrain batch 7/32 - 239.4ms/batch - loss: 114.97034 - diff: 35.46mlTrain batch 8/32 - 239.6ms/batch - loss: 108.68325 - diff: 34.17mlTrain batch 9/32 - 239.7ms/batch - loss: 111.79810 - diff: 34.78mlTrain batch 10/32 - 239.2ms/batch - loss: 114.69483 - diff: 35.04mlTrain batch 11/32 - 239.6ms/batch - loss: 115.35026 - diff: 34.95mlTrain batch 12/32 - 239.3ms/batch - loss: 114.10847 - diff: 34.54mlTrain batch 13/32 - 239.9ms/batch - loss: 133.57299 - diff: 35.54mlTrain batch 14/32 - 239.5ms/batch - loss: 132.97220 - diff: 35.53mlTrain batch 15/32 - 239.4ms/batch - loss: 129.28044 - diff: 34.95mlTrain batch 16/32 - 239.3ms/batch - loss: 136.83422 - diff: 35.90mlTrain batch 17/32 - 239.7ms/batch - loss: 135.92475 - diff: 36.00mlTrain batch 18/32 - 239.9ms/batch - loss: 132.15201 - diff: 35.64mlTrain batch 19/32 - 239.4ms/batch - loss: 128.83626 - diff: 35.28mlTrain batch 20/32 - 239.2ms/batch - loss: 126.17635 - diff: 34.89mlTrain batch 21/32 - 239.5ms/batch - loss: 126.74721 - diff: 35.11mlTrain batch 22/32 - 240.1ms/batch - loss: 124.89458 - diff: 34.88mlTrain batch 23/32 - 240.2ms/batch - loss: 123.30493 - diff: 34.54mlTrain batch 24/32 - 240.2ms/batch - loss: 126.92526 - diff: 34.93mlTrain batch 25/32 - 240.3ms/batch - loss: 124.04177 - diff: 34.53mlTrain batch 26/32 - 239.3ms/batch - loss: 122.23417 - diff: 34.32mlTrain batch 27/32 - 239.9ms/batch - loss: 124.02224 - diff: 34.39mlTrain batch 28/32 - 239.4ms/batch - loss: 125.37934 - diff: 34.31mlTrain batch 29/32 - 240.0ms/batch - loss: 124.25814 - diff: 34.16mlTrain batch 30/32 - 239.1ms/batch - loss: 125.44502 - diff: 34.48mlTrain batch 31/32 - 240.1ms/batch - loss: 127.03267 - diff: 34.52mlTrain batch 32/32 - 77.5ms/batch - loss: 128.33954 - diff: 34.49mlTrain batch 32/32 - 11.4s 77.5ms/batch - loss: 128.33954 - diff: 34.49ml
Test 1.1s: val_loss: 888.86925 - diff: 105.54ml

Epoch 46: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 239.7ms/batch - loss: 117.17723 - diff: 36.02mlTrain batch 2/32 - 239.8ms/batch - loss: 92.09068 - diff: 32.17mlTrain batch 3/32 - 239.1ms/batch - loss: 93.46800 - diff: 32.10mlTrain batch 4/32 - 240.1ms/batch - loss: 85.98599 - diff: 30.05mlTrain batch 5/32 - 239.5ms/batch - loss: 84.11315 - diff: 29.17mlTrain batch 6/32 - 239.5ms/batch - loss: 78.90878 - diff: 28.15mlTrain batch 7/32 - 239.7ms/batch - loss: 77.42308 - diff: 27.88mlTrain batch 8/32 - 240.1ms/batch - loss: 75.99823 - diff: 27.33mlTrain batch 9/32 - 240.3ms/batch - loss: 81.64187 - diff: 27.84mlTrain batch 10/32 - 240.2ms/batch - loss: 84.98442 - diff: 28.09mlTrain batch 11/32 - 240.3ms/batch - loss: 87.56430 - diff: 28.76mlTrain batch 12/32 - 240.1ms/batch - loss: 95.05289 - diff: 29.86mlTrain batch 13/32 - 240.6ms/batch - loss: 91.00035 - diff: 28.97mlTrain batch 14/32 - 240.3ms/batch - loss: 92.04277 - diff: 29.36mlTrain batch 15/32 - 240.4ms/batch - loss: 88.61824 - diff: 28.76mlTrain batch 16/32 - 239.8ms/batch - loss: 92.35895 - diff: 29.10mlTrain batch 17/32 - 240.1ms/batch - loss: 90.66122 - diff: 28.86mlTrain batch 18/32 - 240.1ms/batch - loss: 89.76633 - diff: 28.76mlTrain batch 19/32 - 240.1ms/batch - loss: 93.94681 - diff: 29.45mlTrain batch 20/32 - 240.3ms/batch - loss: 94.25618 - diff: 29.37mlTrain batch 21/32 - 239.9ms/batch - loss: 92.03778 - diff: 29.15mlTrain batch 22/32 - 240.4ms/batch - loss: 91.85524 - diff: 29.14mlTrain batch 23/32 - 240.4ms/batch - loss: 90.18342 - diff: 28.90mlTrain batch 24/32 - 240.8ms/batch - loss: 91.38704 - diff: 29.16mlTrain batch 25/32 - 240.1ms/batch - loss: 92.89990 - diff: 29.44mlTrain batch 26/32 - 240.0ms/batch - loss: 91.54189 - diff: 29.23mlTrain batch 27/32 - 240.0ms/batch - loss: 92.16735 - diff: 29.47mlTrain batch 28/32 - 240.3ms/batch - loss: 90.63074 - diff: 29.21mlTrain batch 29/32 - 239.9ms/batch - loss: 92.25524 - diff: 29.49mlTrain batch 30/32 - 240.0ms/batch - loss: 91.82520 - diff: 29.54mlTrain batch 31/32 - 240.2ms/batch - loss: 91.35507 - diff: 29.55mlTrain batch 32/32 - 78.3ms/batch - loss: 99.31248 - diff: 29.80mlTrain batch 32/32 - 11.5s 78.3ms/batch - loss: 99.31248 - diff: 29.80ml
Test 1.1s: val_loss: 1335.11085 - diff: 133.78ml

Epoch 47: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 239.6ms/batch - loss: 63.63132 - diff: 21.94mlTrain batch 2/32 - 240.3ms/batch - loss: 88.26502 - diff: 26.72mlTrain batch 3/32 - 239.2ms/batch - loss: 81.96156 - diff: 27.33mlTrain batch 4/32 - 240.0ms/batch - loss: 93.14950 - diff: 29.53mlTrain batch 5/32 - 239.6ms/batch - loss: 97.29207 - diff: 30.63mlTrain batch 6/32 - 240.1ms/batch - loss: 96.58328 - diff: 30.45mlTrain batch 7/32 - 240.4ms/batch - loss: 92.18338 - diff: 30.03mlTrain batch 8/32 - 240.1ms/batch - loss: 90.54346 - diff: 29.50mlTrain batch 9/32 - 240.2ms/batch - loss: 84.31604 - diff: 28.27mlTrain batch 10/32 - 240.1ms/batch - loss: 85.45827 - diff: 28.27mlTrain batch 11/32 - 240.1ms/batch - loss: 86.52092 - diff: 28.47mlTrain batch 12/32 - 240.8ms/batch - loss: 100.57878 - diff: 29.64mlTrain batch 13/32 - 244.0ms/batch - loss: 97.77392 - diff: 29.48mlTrain batch 14/32 - 240.3ms/batch - loss: 95.24309 - diff: 29.18mlTrain batch 15/32 - 240.0ms/batch - loss: 92.84405 - diff: 28.95mlTrain batch 16/32 - 240.3ms/batch - loss: 94.39680 - diff: 29.51mlTrain batch 17/32 - 239.8ms/batch - loss: 93.14405 - diff: 29.28mlTrain batch 18/32 - 240.5ms/batch - loss: 91.89530 - diff: 29.18mlTrain batch 19/32 - 240.2ms/batch - loss: 92.88125 - diff: 29.61mlTrain batch 20/32 - 240.9ms/batch - loss: 92.20013 - diff: 29.52mlTrain batch 21/32 - 240.1ms/batch - loss: 92.05736 - diff: 29.70mlTrain batch 22/32 - 240.2ms/batch - loss: 89.57338 - diff: 29.24mlTrain batch 23/32 - 240.1ms/batch - loss: 87.78482 - diff: 28.96mlTrain batch 24/32 - 240.3ms/batch - loss: 88.94289 - diff: 29.08mlTrain batch 25/32 - 240.1ms/batch - loss: 87.87195 - diff: 29.00mlTrain batch 26/32 - 240.2ms/batch - loss: 86.94392 - diff: 28.85mlTrain batch 27/32 - 240.1ms/batch - loss: 84.90064 - diff: 28.40mlTrain batch 28/32 - 240.2ms/batch - loss: 88.02866 - diff: 28.90mlTrain batch 29/32 - 240.2ms/batch - loss: 86.92923 - diff: 28.77mlTrain batch 30/32 - 240.1ms/batch - loss: 85.70232 - diff: 28.58mlTrain batch 31/32 - 240.1ms/batch - loss: 84.10241 - diff: 28.27mlTrain batch 32/32 - 78.1ms/batch - loss: 85.94807 - diff: 28.32mlTrain batch 32/32 - 12.6s 78.1ms/batch - loss: 85.94807 - diff: 28.32ml
Test 1.1s: val_loss: 994.77934 - diff: 108.42ml

Epoch 48: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 239.4ms/batch - loss: 65.60435 - diff: 25.18mlTrain batch 2/32 - 240.0ms/batch - loss: 49.54314 - diff: 22.15mlTrain batch 3/32 - 239.8ms/batch - loss: 53.25446 - diff: 22.93mlTrain batch 4/32 - 240.0ms/batch - loss: 72.12871 - diff: 25.35mlTrain batch 5/32 - 239.5ms/batch - loss: 71.22371 - diff: 25.56mlTrain batch 6/32 - 240.4ms/batch - loss: 78.09396 - diff: 26.24mlTrain batch 7/32 - 240.3ms/batch - loss: 92.16537 - diff: 28.74mlTrain batch 8/32 - 240.5ms/batch - loss: 84.05826 - diff: 27.25mlTrain batch 9/32 - 240.1ms/batch - loss: 82.87289 - diff: 26.82mlTrain batch 10/32 - 240.3ms/batch - loss: 87.34709 - diff: 27.70mlTrain batch 11/32 - 240.0ms/batch - loss: 88.57927 - diff: 28.23mlTrain batch 12/32 - 240.1ms/batch - loss: 89.79651 - diff: 28.64mlTrain batch 13/32 - 241.5ms/batch - loss: 86.88789 - diff: 28.24mlTrain batch 14/32 - 240.3ms/batch - loss: 85.00694 - diff: 28.01mlTrain batch 15/32 - 240.0ms/batch - loss: 81.55450 - diff: 27.39mlTrain batch 16/32 - 240.2ms/batch - loss: 81.48417 - diff: 27.55mlTrain batch 17/32 - 240.1ms/batch - loss: 82.99067 - diff: 28.06mlTrain batch 18/32 - 240.2ms/batch - loss: 82.21233 - diff: 27.71mlTrain batch 19/32 - 240.1ms/batch - loss: 80.37219 - diff: 27.42mlTrain batch 20/32 - 240.3ms/batch - loss: 78.34377 - diff: 27.05mlTrain batch 21/32 - 240.3ms/batch - loss: 77.34579 - diff: 26.94mlTrain batch 22/32 - 240.7ms/batch - loss: 76.47173 - diff: 26.71mlTrain batch 23/32 - 240.1ms/batch - loss: 76.71234 - diff: 26.86mlTrain batch 24/32 - 240.3ms/batch - loss: 76.58027 - diff: 27.03mlTrain batch 25/32 - 240.0ms/batch - loss: 78.54870 - diff: 27.46mlTrain batch 26/32 - 240.6ms/batch - loss: 79.02710 - diff: 27.74mlTrain batch 27/32 - 240.7ms/batch - loss: 77.69532 - diff: 27.52mlTrain batch 28/32 - 240.3ms/batch - loss: 81.32975 - diff: 27.86mlTrain batch 29/32 - 240.9ms/batch - loss: 80.11860 - diff: 27.65mlTrain batch 30/32 - 240.3ms/batch - loss: 79.46030 - diff: 27.59mlTrain batch 31/32 - 240.3ms/batch - loss: 79.01125 - diff: 27.45mlTrain batch 32/32 - 78.2ms/batch - loss: 80.64279 - diff: 27.45mlTrain batch 32/32 - 11.6s 78.2ms/batch - loss: 80.64279 - diff: 27.45ml
Test 1.1s: val_loss: 782.75857 - diff: 99.19ml

Epoch 49: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 239.6ms/batch - loss: 30.23613 - diff: 17.71mlTrain batch 2/32 - 240.5ms/batch - loss: 52.94475 - diff: 23.26mlTrain batch 3/32 - 240.1ms/batch - loss: 70.22990 - diff: 27.31mlTrain batch 4/32 - 240.4ms/batch - loss: 86.39341 - diff: 30.96mlTrain batch 5/32 - 240.0ms/batch - loss: 82.59829 - diff: 30.39mlTrain batch 6/32 - 240.3ms/batch - loss: 73.73776 - diff: 28.38mlTrain batch 7/32 - 240.5ms/batch - loss: 73.15047 - diff: 27.98mlTrain batch 8/32 - 240.7ms/batch - loss: 70.15762 - diff: 27.11mlTrain batch 9/32 - 240.4ms/batch - loss: 73.19384 - diff: 27.29mlTrain batch 10/32 - 240.9ms/batch - loss: 73.06309 - diff: 27.08mlTrain batch 11/32 - 240.6ms/batch - loss: 73.23018 - diff: 26.85mlTrain batch 12/32 - 241.0ms/batch - loss: 70.38313 - diff: 26.43mlTrain batch 13/32 - 240.2ms/batch - loss: 68.60820 - diff: 26.19mlTrain batch 14/32 - 240.5ms/batch - loss: 69.76710 - diff: 26.19mlTrain batch 15/32 - 240.2ms/batch - loss: 66.54076 - diff: 25.38mlTrain batch 16/32 - 240.4ms/batch - loss: 67.36166 - diff: 25.61mlTrain batch 17/32 - 240.7ms/batch - loss: 64.48666 - diff: 24.98mlTrain batch 18/32 - 240.8ms/batch - loss: 63.67684 - diff: 24.91mlTrain batch 19/32 - 240.3ms/batch - loss: 65.31876 - diff: 25.14mlTrain batch 20/32 - 240.9ms/batch - loss: 65.15399 - diff: 25.21mlTrain batch 21/32 - 240.2ms/batch - loss: 65.01170 - diff: 25.38mlTrain batch 22/32 - 241.0ms/batch - loss: 64.72781 - diff: 25.41mlTrain batch 23/32 - 240.3ms/batch - loss: 63.23961 - diff: 25.14mlTrain batch 24/32 - 241.2ms/batch - loss: 62.61689 - diff: 25.05mlTrain batch 25/32 - 240.3ms/batch - loss: 61.81872 - diff: 24.91mlTrain batch 26/32 - 240.1ms/batch - loss: 61.49413 - diff: 24.87mlTrain batch 27/32 - 240.5ms/batch - loss: 60.94078 - diff: 24.77mlTrain batch 28/32 - 240.7ms/batch - loss: 62.62225 - diff: 25.02mlTrain batch 29/32 - 241.1ms/batch - loss: 63.33708 - diff: 25.12mlTrain batch 30/32 - 240.3ms/batch - loss: 63.25223 - diff: 25.11mlTrain batch 31/32 - 240.8ms/batch - loss: 62.69655 - diff: 24.92mlTrain batch 32/32 - 78.0ms/batch - loss: 71.74484 - diff: 25.19mlTrain batch 32/32 - 11.3s 78.0ms/batch - loss: 71.74484 - diff: 25.19ml
Test 1.1s: val_loss: 320.85499 - diff: 58.22ml

Epoch 50: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 240.0ms/batch - loss: 117.85067 - diff: 34.65mlTrain batch 2/32 - 240.6ms/batch - loss: 77.64519 - diff: 27.00mlTrain batch 3/32 - 240.4ms/batch - loss: 79.40590 - diff: 27.25mlTrain batch 4/32 - 240.9ms/batch - loss: 75.50335 - diff: 27.33mlTrain batch 5/32 - 240.2ms/batch - loss: 71.91488 - diff: 26.92mlTrain batch 6/32 - 240.8ms/batch - loss: 98.96204 - diff: 30.67mlTrain batch 7/32 - 239.9ms/batch - loss: 89.69734 - diff: 28.99mlTrain batch 8/32 - 240.7ms/batch - loss: 82.59882 - diff: 27.69mlTrain batch 9/32 - 240.6ms/batch - loss: 79.36068 - diff: 27.07mlTrain batch 10/32 - 240.5ms/batch - loss: 77.85681 - diff: 27.14mlTrain batch 11/32 - 240.4ms/batch - loss: 73.40333 - diff: 26.19mlTrain batch 12/32 - 241.2ms/batch - loss: 73.81194 - diff: 26.54mlTrain batch 13/32 - 240.6ms/batch - loss: 71.55984 - diff: 26.17mlTrain batch 14/32 - 240.6ms/batch - loss: 70.50606 - diff: 26.06mlTrain batch 15/32 - 240.7ms/batch - loss: 70.94316 - diff: 26.11mlTrain batch 16/32 - 241.2ms/batch - loss: 72.14883 - diff: 26.52mlTrain batch 17/32 - 240.3ms/batch - loss: 71.75216 - diff: 26.34mlTrain batch 18/32 - 240.7ms/batch - loss: 71.51663 - diff: 26.31mlTrain batch 19/32 - 240.4ms/batch - loss: 70.14014 - diff: 25.99mlTrain batch 20/32 - 241.0ms/batch - loss: 72.87940 - diff: 26.70mlTrain batch 21/32 - 240.3ms/batch - loss: 77.21600 - diff: 27.30mlTrain batch 22/32 - 240.5ms/batch - loss: 76.95665 - diff: 27.31mlTrain batch 23/32 - 240.4ms/batch - loss: 77.35903 - diff: 27.50mlTrain batch 24/32 - 240.8ms/batch - loss: 76.00388 - diff: 27.28mlTrain batch 25/32 - 240.7ms/batch - loss: 76.59226 - diff: 27.25mlTrain batch 26/32 - 241.0ms/batch - loss: 76.39331 - diff: 27.22mlTrain batch 27/32 - 240.3ms/batch - loss: 82.62854 - diff: 28.18mlTrain batch 28/32 - 241.6ms/batch - loss: 81.45678 - diff: 28.03mlTrain batch 29/32 - 240.2ms/batch - loss: 81.42955 - diff: 28.13mlTrain batch 30/32 - 240.9ms/batch - loss: 80.97911 - diff: 28.06mlTrain batch 31/32 - 240.6ms/batch - loss: 80.81113 - diff: 28.05mlTrain batch 32/32 - 79.7ms/batch - loss: 83.57393 - diff: 28.14mlTrain batch 32/32 - 11.4s 79.7ms/batch - loss: 83.57393 - diff: 28.14ml
Test 1.1s: val_loss: 1919.45673 - diff: 167.04ml
Epoch    51: reducing learning rate of group 0 to 6.2500e-05.

Epoch 51: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 240.2ms/batch - loss: 83.92940 - diff: 25.78mlTrain batch 2/32 - 241.1ms/batch - loss: 66.16877 - diff: 24.60mlTrain batch 3/32 - 241.0ms/batch - loss: 68.53427 - diff: 25.76mlTrain batch 4/32 - 240.6ms/batch - loss: 62.25179 - diff: 25.06mlTrain batch 5/32 - 240.6ms/batch - loss: 77.26283 - diff: 27.82mlTrain batch 6/32 - 240.2ms/batch - loss: 69.84389 - diff: 26.18mlTrain batch 7/32 - 240.8ms/batch - loss: 69.74208 - diff: 26.13mlTrain batch 8/32 - 240.3ms/batch - loss: 77.04021 - diff: 25.91mlTrain batch 9/32 - 241.1ms/batch - loss: 73.95125 - diff: 25.46mlTrain batch 10/32 - 240.2ms/batch - loss: 76.59028 - diff: 26.28mlTrain batch 11/32 - 240.8ms/batch - loss: 75.16966 - diff: 26.08mlTrain batch 12/32 - 240.8ms/batch - loss: 71.04224 - diff: 25.16mlTrain batch 13/32 - 241.4ms/batch - loss: 68.72352 - diff: 24.85mlTrain batch 14/32 - 240.5ms/batch - loss: 71.10717 - diff: 25.25mlTrain batch 15/32 - 241.9ms/batch - loss: 72.96339 - diff: 25.71mlTrain batch 16/32 - 242.5ms/batch - loss: 69.79880 - diff: 25.17mlTrain batch 17/32 - 241.4ms/batch - loss: 66.51445 - diff: 24.40mlTrain batch 18/32 - 240.5ms/batch - loss: 63.89114 - diff: 23.92mlTrain batch 19/32 - 240.5ms/batch - loss: 63.66652 - diff: 24.05mlTrain batch 20/32 - 240.5ms/batch - loss: 62.88107 - diff: 23.88mlTrain batch 21/32 - 241.7ms/batch - loss: 61.55277 - diff: 23.68mlTrain batch 22/32 - 240.6ms/batch - loss: 60.98263 - diff: 23.65mlTrain batch 23/32 - 242.1ms/batch - loss: 59.77729 - diff: 23.44mlTrain batch 24/32 - 240.3ms/batch - loss: 60.19112 - diff: 23.61mlTrain batch 25/32 - 241.4ms/batch - loss: 60.55455 - diff: 23.78mlTrain batch 26/32 - 240.1ms/batch - loss: 59.10697 - diff: 23.41mlTrain batch 27/32 - 241.2ms/batch - loss: 59.07443 - diff: 23.24mlTrain batch 28/32 - 240.6ms/batch - loss: 58.08872 - diff: 23.04mlTrain batch 29/32 - 241.4ms/batch - loss: 57.58714 - diff: 22.98mlTrain batch 30/32 - 240.6ms/batch - loss: 57.04806 - diff: 22.90mlTrain batch 31/32 - 240.6ms/batch - loss: 55.75379 - diff: 22.59mlTrain batch 32/32 - 80.1ms/batch - loss: 56.74399 - diff: 22.60mlTrain batch 32/32 - 11.0s 80.1ms/batch - loss: 56.74399 - diff: 22.60ml
Test 1.1s: val_loss: 671.08787 - diff: 94.46ml

Epoch 52: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 240.5ms/batch - loss: 33.88277 - diff: 16.51mlTrain batch 2/32 - 241.4ms/batch - loss: 43.64020 - diff: 20.67mlTrain batch 3/32 - 240.4ms/batch - loss: 47.68510 - diff: 22.10mlTrain batch 4/32 - 240.8ms/batch - loss: 43.76626 - diff: 21.47mlTrain batch 5/32 - 240.4ms/batch - loss: 42.08226 - diff: 20.93mlTrain batch 6/32 - 241.5ms/batch - loss: 41.11341 - diff: 20.66mlTrain batch 7/32 - 240.5ms/batch - loss: 49.13561 - diff: 22.21mlTrain batch 8/32 - 241.5ms/batch - loss: 48.52170 - diff: 22.24mlTrain batch 9/32 - 240.8ms/batch - loss: 48.41143 - diff: 22.06mlTrain batch 10/32 - 241.4ms/batch - loss: 47.22234 - diff: 21.95mlTrain batch 11/32 - 240.4ms/batch - loss: 52.44188 - diff: 23.03mlTrain batch 12/32 - 241.2ms/batch - loss: 52.95731 - diff: 23.04mlTrain batch 13/32 - 240.3ms/batch - loss: 51.59061 - diff: 22.76mlTrain batch 14/32 - 240.0ms/batch - loss: 53.13315 - diff: 23.10mlTrain batch 15/32 - 240.3ms/batch - loss: 53.77496 - diff: 23.05mlTrain batch 16/32 - 240.8ms/batch - loss: 53.84511 - diff: 23.23mlTrain batch 17/32 - 241.0ms/batch - loss: 55.78912 - diff: 23.67mlTrain batch 18/32 - 240.3ms/batch - loss: 55.27778 - diff: 23.51mlTrain batch 19/32 - 240.9ms/batch - loss: 54.40279 - diff: 23.36mlTrain batch 20/32 - 240.5ms/batch - loss: 52.68383 - diff: 22.91mlTrain batch 21/32 - 240.8ms/batch - loss: 52.19577 - diff: 22.81mlTrain batch 22/32 - 240.7ms/batch - loss: 52.29738 - diff: 22.80mlTrain batch 23/32 - 241.4ms/batch - loss: 52.69223 - diff: 22.75mlTrain batch 24/32 - 240.5ms/batch - loss: 51.68046 - diff: 22.48mlTrain batch 25/32 - 241.8ms/batch - loss: 51.14068 - diff: 22.39mlTrain batch 26/32 - 240.3ms/batch - loss: 52.58580 - diff: 22.70mlTrain batch 27/32 - 240.7ms/batch - loss: 52.02591 - diff: 22.65mlTrain batch 28/32 - 240.3ms/batch - loss: 51.35251 - diff: 22.47mlTrain batch 29/32 - 240.8ms/batch - loss: 50.59904 - diff: 22.31mlTrain batch 30/32 - 240.2ms/batch - loss: 50.99020 - diff: 22.45mlTrain batch 31/32 - 240.5ms/batch - loss: 51.29558 - diff: 22.58mlTrain batch 32/32 - 78.3ms/batch - loss: 54.81132 - diff: 22.72mlTrain batch 32/32 - 12.7s 78.3ms/batch - loss: 54.81132 - diff: 22.72ml
Test 1.1s: val_loss: 993.42002 - diff: 114.70ml

Epoch 53: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 240.2ms/batch - loss: 31.09451 - diff: 18.30mlTrain batch 2/32 - 240.5ms/batch - loss: 26.95939 - diff: 16.92mlTrain batch 3/32 - 240.3ms/batch - loss: 47.67714 - diff: 22.57mlTrain batch 4/32 - 241.5ms/batch - loss: 49.21581 - diff: 22.61mlTrain batch 5/32 - 240.2ms/batch - loss: 50.65634 - diff: 23.08mlTrain batch 6/32 - 240.8ms/batch - loss: 47.27943 - diff: 22.29mlTrain batch 7/32 - 240.1ms/batch - loss: 50.93387 - diff: 23.34mlTrain batch 8/32 - 241.3ms/batch - loss: 55.20294 - diff: 23.87mlTrain batch 9/32 - 240.5ms/batch - loss: 51.62128 - diff: 22.91mlTrain batch 10/32 - 240.6ms/batch - loss: 49.90287 - diff: 22.28mlTrain batch 11/32 - 240.5ms/batch - loss: 48.94946 - diff: 22.20mlTrain batch 12/32 - 241.0ms/batch - loss: 48.20305 - diff: 22.00mlTrain batch 13/32 - 240.3ms/batch - loss: 47.69149 - diff: 21.95mlTrain batch 14/32 - 241.2ms/batch - loss: 46.17021 - diff: 21.65mlTrain batch 15/32 - 240.3ms/batch - loss: 44.80636 - diff: 21.35mlTrain batch 16/32 - 241.8ms/batch - loss: 43.76806 - diff: 21.16mlTrain batch 17/32 - 240.7ms/batch - loss: 42.26100 - diff: 20.71mlTrain batch 18/32 - 241.0ms/batch - loss: 41.80615 - diff: 20.61mlTrain batch 19/32 - 240.2ms/batch - loss: 40.66421 - diff: 20.32mlTrain batch 20/32 - 241.2ms/batch - loss: 39.62290 - diff: 19.94mlTrain batch 21/32 - 240.3ms/batch - loss: 38.97061 - diff: 19.79mlTrain batch 22/32 - 241.1ms/batch - loss: 38.48862 - diff: 19.74mlTrain batch 23/32 - 240.0ms/batch - loss: 38.14199 - diff: 19.60mlTrain batch 24/32 - 240.8ms/batch - loss: 37.98556 - diff: 19.57mlTrain batch 25/32 - 240.5ms/batch - loss: 37.27453 - diff: 19.38mlTrain batch 26/32 - 241.5ms/batch - loss: 39.45905 - diff: 19.89mlTrain batch 27/32 - 240.4ms/batch - loss: 39.53350 - diff: 19.99mlTrain batch 28/32 - 241.1ms/batch - loss: 38.91514 - diff: 19.75mlTrain batch 29/32 - 240.8ms/batch - loss: 41.38580 - diff: 20.27mlTrain batch 30/32 - 241.3ms/batch - loss: 41.10149 - diff: 20.22mlTrain batch 31/32 - 240.6ms/batch - loss: 40.72479 - diff: 20.17mlTrain batch 32/32 - 79.0ms/batch - loss: 42.01872 - diff: 20.23mlTrain batch 32/32 - 11.8s 79.0ms/batch - loss: 42.01872 - diff: 20.23ml
Test 1.1s: val_loss: 1306.46045 - diff: 136.74ml

Epoch 54: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 240.3ms/batch - loss: 124.16660 - diff: 37.44mlTrain batch 2/32 - 241.5ms/batch - loss: 79.27360 - diff: 28.16mlTrain batch 3/32 - 240.3ms/batch - loss: 67.91836 - diff: 25.84mlTrain batch 4/32 - 240.2ms/batch - loss: 57.61529 - diff: 22.80mlTrain batch 5/32 - 240.2ms/batch - loss: 51.21713 - diff: 21.62mlTrain batch 6/32 - 240.6ms/batch - loss: 53.59719 - diff: 22.22mlTrain batch 7/32 - 240.7ms/batch - loss: 52.83714 - diff: 22.25mlTrain batch 8/32 - 240.2ms/batch - loss: 49.38948 - diff: 21.39mlTrain batch 9/32 - 241.3ms/batch - loss: 46.17029 - diff: 20.67mlTrain batch 10/32 - 240.0ms/batch - loss: 44.99099 - diff: 20.55mlTrain batch 11/32 - 241.2ms/batch - loss: 43.94660 - diff: 20.53mlTrain batch 12/32 - 240.4ms/batch - loss: 41.68893 - diff: 19.90mlTrain batch 13/32 - 241.4ms/batch - loss: 40.99180 - diff: 19.76mlTrain batch 14/32 - 240.3ms/batch - loss: 41.59822 - diff: 19.55mlTrain batch 15/32 - 241.5ms/batch - loss: 42.33255 - diff: 19.95mlTrain batch 16/32 - 240.6ms/batch - loss: 45.42504 - diff: 20.73mlTrain batch 17/32 - 241.1ms/batch - loss: 44.84493 - diff: 20.70mlTrain batch 18/32 - 240.2ms/batch - loss: 44.50254 - diff: 20.55mlTrain batch 19/32 - 241.8ms/batch - loss: 53.26374 - diff: 22.01mlTrain batch 20/32 - 240.6ms/batch - loss: 52.29082 - diff: 21.88mlTrain batch 21/32 - 241.4ms/batch - loss: 54.00791 - diff: 22.28mlTrain batch 22/32 - 240.3ms/batch - loss: 52.62485 - diff: 22.02mlTrain batch 23/32 - 241.7ms/batch - loss: 51.27489 - diff: 21.65mlTrain batch 24/32 - 240.4ms/batch - loss: 50.07033 - diff: 21.45mlTrain batch 25/32 - 241.5ms/batch - loss: 49.67150 - diff: 21.46mlTrain batch 26/32 - 240.8ms/batch - loss: 49.06200 - diff: 21.34mlTrain batch 27/32 - 241.8ms/batch - loss: 48.01948 - diff: 21.09mlTrain batch 28/32 - 241.3ms/batch - loss: 48.34203 - diff: 21.19mlTrain batch 29/32 - 241.0ms/batch - loss: 47.63341 - diff: 21.01mlTrain batch 30/32 - 240.3ms/batch - loss: 48.43856 - diff: 21.22mlTrain batch 31/32 - 241.8ms/batch - loss: 48.01680 - diff: 21.17mlTrain batch 32/32 - 78.8ms/batch - loss: 48.52551 - diff: 21.16mlTrain batch 32/32 - 12.3s 78.8ms/batch - loss: 48.52551 - diff: 21.16ml
Test 1.1s: val_loss: 1539.72538 - diff: 148.15ml

Epoch 55: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 240.4ms/batch - loss: 26.88590 - diff: 16.85mlTrain batch 2/32 - 241.2ms/batch - loss: 36.80161 - diff: 19.85mlTrain batch 3/32 - 240.1ms/batch - loss: 38.64667 - diff: 20.92mlTrain batch 4/32 - 240.4ms/batch - loss: 35.12818 - diff: 19.34mlTrain batch 5/32 - 241.0ms/batch - loss: 38.26749 - diff: 20.06mlTrain batch 6/32 - 240.5ms/batch - loss: 40.67385 - diff: 20.78mlTrain batch 7/32 - 241.6ms/batch - loss: 43.37337 - diff: 21.36mlTrain batch 8/32 - 240.2ms/batch - loss: 47.63197 - diff: 22.47mlTrain batch 9/32 - 241.4ms/batch - loss: 49.48504 - diff: 22.75mlTrain batch 10/32 - 240.2ms/batch - loss: 49.13486 - diff: 22.77mlTrain batch 11/32 - 241.4ms/batch - loss: 47.75464 - diff: 22.33mlTrain batch 12/32 - 240.4ms/batch - loss: 46.26244 - diff: 22.03mlTrain batch 13/32 - 241.4ms/batch - loss: 58.17729 - diff: 23.10mlTrain batch 14/32 - 240.3ms/batch - loss: 55.72588 - diff: 22.51mlTrain batch 15/32 - 241.7ms/batch - loss: 54.28452 - diff: 22.30mlTrain batch 16/32 - 240.7ms/batch - loss: 53.03803 - diff: 22.08mlTrain batch 17/32 - 240.9ms/batch - loss: 52.35098 - diff: 22.01mlTrain batch 18/32 - 241.1ms/batch - loss: 50.76946 - diff: 21.63mlTrain batch 19/32 - 241.7ms/batch - loss: 49.36751 - diff: 21.38mlTrain batch 20/32 - 240.6ms/batch - loss: 48.41980 - diff: 21.12mlTrain batch 21/32 - 241.2ms/batch - loss: 47.54050 - diff: 20.99mlTrain batch 22/32 - 240.9ms/batch - loss: 47.73094 - diff: 21.04mlTrain batch 23/32 - 241.0ms/batch - loss: 46.39149 - diff: 20.77mlTrain batch 24/32 - 241.2ms/batch - loss: 45.40663 - diff: 20.49mlTrain batch 25/32 - 240.8ms/batch - loss: 44.64665 - diff: 20.35mlTrain batch 26/32 - 241.7ms/batch - loss: 44.85610 - diff: 20.38mlTrain batch 27/32 - 240.7ms/batch - loss: 44.55034 - diff: 20.31mlTrain batch 28/32 - 241.2ms/batch - loss: 44.25182 - diff: 20.27mlTrain batch 29/32 - 240.5ms/batch - loss: 43.36698 - diff: 20.07mlTrain batch 30/32 - 241.7ms/batch - loss: 43.60529 - diff: 20.21mlTrain batch 31/32 - 240.4ms/batch - loss: 44.53274 - diff: 20.34mlTrain batch 32/32 - 79.5ms/batch - loss: 53.74882 - diff: 20.57mlTrain batch 32/32 - 11.6s 79.5ms/batch - loss: 53.74882 - diff: 20.57ml
Test 1.1s: val_loss: 762.51750 - diff: 102.06ml

Epoch 56: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 240.5ms/batch - loss: 24.62336 - diff: 16.56mlTrain batch 2/32 - 241.0ms/batch - loss: 63.50870 - diff: 24.71mlTrain batch 3/32 - 240.4ms/batch - loss: 65.62157 - diff: 26.65mlTrain batch 4/32 - 240.7ms/batch - loss: 60.41364 - diff: 25.44mlTrain batch 5/32 - 240.2ms/batch - loss: 56.22830 - diff: 24.57mlTrain batch 6/32 - 241.6ms/batch - loss: 57.81416 - diff: 24.43mlTrain batch 7/32 - 240.8ms/batch - loss: 53.09264 - diff: 23.40mlTrain batch 8/32 - 241.8ms/batch - loss: 51.91530 - diff: 23.12mlTrain batch 9/32 - 240.4ms/batch - loss: 49.47751 - diff: 22.59mlTrain batch 10/32 - 240.8ms/batch - loss: 48.64546 - diff: 22.44mlTrain batch 11/32 - 241.0ms/batch - loss: 48.18035 - diff: 22.32mlTrain batch 12/32 - 241.5ms/batch - loss: 50.71609 - diff: 22.97mlTrain batch 13/32 - 240.5ms/batch - loss: 49.99896 - diff: 22.55mlTrain batch 14/32 - 241.6ms/batch - loss: 48.35344 - diff: 22.10mlTrain batch 15/32 - 240.8ms/batch - loss: 46.47827 - diff: 21.66mlTrain batch 16/32 - 241.4ms/batch - loss: 46.50948 - diff: 21.75mlTrain batch 17/32 - 240.5ms/batch - loss: 44.64879 - diff: 21.21mlTrain batch 18/32 - 241.4ms/batch - loss: 44.11367 - diff: 21.04mlTrain batch 19/32 - 241.1ms/batch - loss: 42.52530 - diff: 20.59mlTrain batch 20/32 - 241.1ms/batch - loss: 42.29984 - diff: 20.56mlTrain batch 21/32 - 240.7ms/batch - loss: 40.83807 - diff: 20.13mlTrain batch 22/32 - 241.2ms/batch - loss: 39.98985 - diff: 19.88mlTrain batch 23/32 - 240.9ms/batch - loss: 40.70460 - diff: 20.07mlTrain batch 24/32 - 241.5ms/batch - loss: 42.62159 - diff: 20.61mlTrain batch 25/32 - 240.9ms/batch - loss: 43.22507 - diff: 20.81mlTrain batch 26/32 - 242.1ms/batch - loss: 43.08267 - diff: 20.82mlTrain batch 27/32 - 241.0ms/batch - loss: 42.10048 - diff: 20.56mlTrain batch 28/32 - 241.3ms/batch - loss: 41.44307 - diff: 20.39mlTrain batch 29/32 - 240.6ms/batch - loss: 42.03154 - diff: 20.54mlTrain batch 30/32 - 241.8ms/batch - loss: 41.16421 - diff: 20.29mlTrain batch 31/32 - 241.2ms/batch - loss: 42.04590 - diff: 20.41mlTrain batch 32/32 - 79.7ms/batch - loss: 43.21290 - diff: 20.40mlTrain batch 32/32 - 11.2s 79.7ms/batch - loss: 43.21290 - diff: 20.40ml
Test 1.1s: val_loss: 624.25245 - diff: 89.45ml

Epoch 57: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 240.3ms/batch - loss: 28.45449 - diff: 19.27mlTrain batch 2/32 - 241.3ms/batch - loss: 30.52213 - diff: 19.49mlTrain batch 3/32 - 240.7ms/batch - loss: 28.69041 - diff: 18.61mlTrain batch 4/32 - 241.3ms/batch - loss: 26.10367 - diff: 17.55mlTrain batch 5/32 - 240.4ms/batch - loss: 25.00146 - diff: 16.78mlTrain batch 6/32 - 240.5ms/batch - loss: 25.63346 - diff: 16.68mlTrain batch 7/32 - 240.5ms/batch - loss: 26.01680 - diff: 16.93mlTrain batch 8/32 - 240.8ms/batch - loss: 29.24445 - diff: 17.51mlTrain batch 9/32 - 240.3ms/batch - loss: 30.31748 - diff: 17.90mlTrain batch 10/32 - 241.6ms/batch - loss: 29.66779 - diff: 17.78mlTrain batch 11/32 - 240.6ms/batch - loss: 36.16150 - diff: 19.25mlTrain batch 12/32 - 241.4ms/batch - loss: 36.30435 - diff: 19.18mlTrain batch 13/32 - 241.0ms/batch - loss: 35.65143 - diff: 19.06mlTrain batch 14/32 - 241.1ms/batch - loss: 41.17387 - diff: 19.60mlTrain batch 15/32 - 240.9ms/batch - loss: 41.79525 - diff: 19.92mlTrain batch 16/32 - 241.5ms/batch - loss: 41.27217 - diff: 19.91mlTrain batch 17/32 - 240.8ms/batch - loss: 40.88864 - diff: 19.99mlTrain batch 18/32 - 247.0ms/batch - loss: 41.79034 - diff: 20.26mlTrain batch 19/32 - 240.5ms/batch - loss: 40.46041 - diff: 19.96mlTrain batch 20/32 - 241.1ms/batch - loss: 41.27535 - diff: 20.15mlTrain batch 21/32 - 240.3ms/batch - loss: 40.99926 - diff: 20.08mlTrain batch 22/32 - 242.1ms/batch - loss: 41.22027 - diff: 20.20mlTrain batch 23/32 - 240.5ms/batch - loss: 43.11079 - diff: 20.69mlTrain batch 24/32 - 241.7ms/batch - loss: 42.58546 - diff: 20.64mlTrain batch 25/32 - 240.1ms/batch - loss: 43.77490 - diff: 20.95mlTrain batch 26/32 - 241.3ms/batch - loss: 44.94315 - diff: 21.30mlTrain batch 27/32 - 240.4ms/batch - loss: 44.05885 - diff: 21.07mlTrain batch 28/32 - 241.2ms/batch - loss: 43.40048 - diff: 20.90mlTrain batch 29/32 - 240.5ms/batch - loss: 43.74410 - diff: 21.11mlTrain batch 30/32 - 241.5ms/batch - loss: 42.96695 - diff: 20.89mlTrain batch 31/32 - 240.1ms/batch - loss: 42.62224 - diff: 20.87mlTrain batch 32/32 - 78.0ms/batch - loss: 44.29355 - diff: 20.94mlTrain batch 32/32 - 12.3s 78.0ms/batch - loss: 44.29355 - diff: 20.94ml
Test 1.1s: val_loss: 772.43854 - diff: 101.96ml

Epoch 58: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 240.3ms/batch - loss: 25.63242 - diff: 17.27mlTrain batch 2/32 - 241.5ms/batch - loss: 34.53400 - diff: 19.01mlTrain batch 3/32 - 241.0ms/batch - loss: 42.28045 - diff: 21.37mlTrain batch 4/32 - 240.8ms/batch - loss: 44.94672 - diff: 22.25mlTrain batch 5/32 - 241.2ms/batch - loss: 40.11119 - diff: 20.68mlTrain batch 6/32 - 240.7ms/batch - loss: 38.15224 - diff: 20.24mlTrain batch 7/32 - 241.8ms/batch - loss: 38.20866 - diff: 20.40mlTrain batch 8/32 - 240.7ms/batch - loss: 39.18904 - diff: 20.49mlTrain batch 9/32 - 241.5ms/batch - loss: 37.18282 - diff: 19.83mlTrain batch 10/32 - 240.7ms/batch - loss: 40.92927 - diff: 20.28mlTrain batch 11/32 - 241.5ms/batch - loss: 40.05254 - diff: 20.05mlTrain batch 12/32 - 239.8ms/batch - loss: 43.68255 - diff: 20.94mlTrain batch 13/32 - 241.2ms/batch - loss: 44.11745 - diff: 21.10mlTrain batch 14/32 - 240.4ms/batch - loss: 43.57289 - diff: 21.02mlTrain batch 15/32 - 241.6ms/batch - loss: 44.05798 - diff: 21.16mlTrain batch 16/32 - 240.7ms/batch - loss: 42.85151 - diff: 20.90mlTrain batch 17/32 - 241.4ms/batch - loss: 42.52822 - diff: 20.90mlTrain batch 18/32 - 240.7ms/batch - loss: 41.70249 - diff: 20.66mlTrain batch 19/32 - 241.3ms/batch - loss: 43.23123 - diff: 20.99mlTrain batch 20/32 - 240.6ms/batch - loss: 42.23086 - diff: 20.74mlTrain batch 21/32 - 241.2ms/batch - loss: 42.03243 - diff: 20.76mlTrain batch 22/32 - 240.9ms/batch - loss: 41.61761 - diff: 20.77mlTrain batch 23/32 - 241.7ms/batch - loss: 41.13195 - diff: 20.70mlTrain batch 24/32 - 241.1ms/batch - loss: 40.40552 - diff: 20.47mlTrain batch 25/32 - 240.9ms/batch - loss: 42.16652 - diff: 20.76mlTrain batch 26/32 - 240.8ms/batch - loss: 42.24114 - diff: 20.73mlTrain batch 27/32 - 240.8ms/batch - loss: 42.59659 - diff: 20.83mlTrain batch 28/32 - 241.3ms/batch - loss: 48.09017 - diff: 21.77mlTrain batch 29/32 - 240.4ms/batch - loss: 47.88177 - diff: 21.71mlTrain batch 30/32 - 241.4ms/batch - loss: 46.77839 - diff: 21.43mlTrain batch 31/32 - 240.4ms/batch - loss: 46.10829 - diff: 21.16mlTrain batch 32/32 - 78.2ms/batch - loss: 49.32474 - diff: 21.29mlTrain batch 32/32 - 11.3s 78.2ms/batch - loss: 49.32474 - diff: 21.29ml
Test 1.1s: val_loss: 1333.36259 - diff: 136.01ml

Epoch 59: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 240.4ms/batch - loss: 28.78554 - diff: 16.08mlTrain batch 2/32 - 241.7ms/batch - loss: 24.85551 - diff: 16.05mlTrain batch 3/32 - 240.4ms/batch - loss: 32.75280 - diff: 16.62mlTrain batch 4/32 - 241.4ms/batch - loss: 34.98176 - diff: 18.25mlTrain batch 5/32 - 240.4ms/batch - loss: 45.23709 - diff: 20.88mlTrain batch 6/32 - 241.4ms/batch - loss: 43.15461 - diff: 20.34mlTrain batch 7/32 - 240.3ms/batch - loss: 40.70445 - diff: 19.64mlTrain batch 8/32 - 241.4ms/batch - loss: 39.79846 - diff: 19.71mlTrain batch 9/32 - 240.7ms/batch - loss: 47.31926 - diff: 20.99mlTrain batch 10/32 - 241.4ms/batch - loss: 44.63969 - diff: 20.36mlTrain batch 11/32 - 241.5ms/batch - loss: 45.21368 - diff: 20.66mlTrain batch 12/32 - 240.9ms/batch - loss: 45.09205 - diff: 20.74mlTrain batch 13/32 - 240.5ms/batch - loss: 48.83749 - diff: 21.39mlTrain batch 14/32 - 241.6ms/batch - loss: 49.42070 - diff: 21.51mlTrain batch 15/32 - 243.0ms/batch - loss: 48.75502 - diff: 21.41mlTrain batch 16/32 - 240.9ms/batch - loss: 49.55531 - diff: 21.59mlTrain batch 17/32 - 240.8ms/batch - loss: 48.82726 - diff: 21.48mlTrain batch 18/32 - 240.3ms/batch - loss: 48.70949 - diff: 21.50mlTrain batch 19/32 - 241.4ms/batch - loss: 48.35873 - diff: 21.38mlTrain batch 20/32 - 240.4ms/batch - loss: 47.60369 - diff: 21.19mlTrain batch 21/32 - 241.9ms/batch - loss: 46.73744 - diff: 21.02mlTrain batch 22/32 - 240.5ms/batch - loss: 46.20842 - diff: 20.92mlTrain batch 23/32 - 241.2ms/batch - loss: 45.52198 - diff: 20.77mlTrain batch 24/32 - 240.7ms/batch - loss: 46.86657 - diff: 21.10mlTrain batch 25/32 - 241.5ms/batch - loss: 48.61427 - diff: 21.43mlTrain batch 26/32 - 240.5ms/batch - loss: 48.92137 - diff: 21.45mlTrain batch 27/32 - 241.2ms/batch - loss: 48.25525 - diff: 21.31mlTrain batch 28/32 - 240.6ms/batch - loss: 47.33734 - diff: 21.08mlTrain batch 29/32 - 240.7ms/batch - loss: 46.69693 - diff: 20.88mlTrain batch 30/32 - 240.3ms/batch - loss: 45.83391 - diff: 20.71mlTrain batch 31/32 - 241.5ms/batch - loss: 45.03764 - diff: 20.53mlTrain batch 32/32 - 79.3ms/batch - loss: 49.99416 - diff: 20.73mlTrain batch 32/32 - 12.6s 79.3ms/batch - loss: 49.99416 - diff: 20.73ml
Test 1.1s: val_loss: 1362.61418 - diff: 137.93ml

Epoch 60: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 240.4ms/batch - loss: 26.87990 - diff: 17.43mlTrain batch 2/32 - 240.6ms/batch - loss: 33.00074 - diff: 18.73mlTrain batch 3/32 - 240.3ms/batch - loss: 29.43233 - diff: 17.89mlTrain batch 4/32 - 241.0ms/batch - loss: 29.86666 - diff: 18.08mlTrain batch 5/32 - 240.5ms/batch - loss: 31.26076 - diff: 18.49mlTrain batch 6/32 - 241.2ms/batch - loss: 29.98696 - diff: 17.93mlTrain batch 7/32 - 240.3ms/batch - loss: 32.09471 - diff: 18.48mlTrain batch 8/32 - 241.4ms/batch - loss: 34.78340 - diff: 19.17mlTrain batch 9/32 - 241.2ms/batch - loss: 34.11834 - diff: 18.88mlTrain batch 10/32 - 241.5ms/batch - loss: 33.96577 - diff: 18.86mlTrain batch 11/32 - 240.6ms/batch - loss: 34.97963 - diff: 19.27mlTrain batch 12/32 - 241.7ms/batch - loss: 36.11658 - diff: 19.44mlTrain batch 13/32 - 240.6ms/batch - loss: 37.80951 - diff: 19.90mlTrain batch 14/32 - 241.4ms/batch - loss: 37.31583 - diff: 19.80mlTrain batch 15/32 - 240.6ms/batch - loss: 35.51915 - diff: 19.12mlTrain batch 16/32 - 241.2ms/batch - loss: 36.42261 - diff: 19.11mlTrain batch 17/32 - 240.5ms/batch - loss: 36.00768 - diff: 19.04mlTrain batch 18/32 - 241.3ms/batch - loss: 35.03387 - diff: 18.79mlTrain batch 19/32 - 240.6ms/batch - loss: 34.65018 - diff: 18.69mlTrain batch 20/32 - 241.3ms/batch - loss: 33.94708 - diff: 18.48mlTrain batch 21/32 - 240.9ms/batch - loss: 34.31102 - diff: 18.56mlTrain batch 22/32 - 241.6ms/batch - loss: 34.40800 - diff: 18.46mlTrain batch 23/32 - 240.6ms/batch - loss: 35.69827 - diff: 18.62mlTrain batch 24/32 - 241.4ms/batch - loss: 36.84144 - diff: 18.81mlTrain batch 25/32 - 240.8ms/batch - loss: 36.25935 - diff: 18.73mlTrain batch 26/32 - 241.3ms/batch - loss: 35.54815 - diff: 18.53mlTrain batch 27/32 - 240.2ms/batch - loss: 35.30277 - diff: 18.48mlTrain batch 28/32 - 240.9ms/batch - loss: 35.78151 - diff: 18.56mlTrain batch 29/32 - 240.9ms/batch - loss: 35.14378 - diff: 18.37mlTrain batch 30/32 - 241.4ms/batch - loss: 34.95384 - diff: 18.31mlTrain batch 31/32 - 240.5ms/batch - loss: 34.57277 - diff: 18.20mlTrain batch 32/32 - 78.1ms/batch - loss: 37.29916 - diff: 18.36mlTrain batch 32/32 - 11.7s 78.1ms/batch - loss: 37.29916 - diff: 18.36ml
Test 1.1s: val_loss: 855.02994 - diff: 107.60ml

Epoch 61: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 240.8ms/batch - loss: 26.21899 - diff: 15.77mlTrain batch 2/32 - 241.1ms/batch - loss: 25.47373 - diff: 14.70mlTrain batch 3/32 - 240.6ms/batch - loss: 21.34617 - diff: 13.90mlTrain batch 4/32 - 241.3ms/batch - loss: 21.47878 - diff: 14.23mlTrain batch 5/32 - 240.7ms/batch - loss: 22.55073 - diff: 14.49mlTrain batch 6/32 - 242.7ms/batch - loss: 22.50860 - diff: 14.53mlTrain batch 7/32 - 240.6ms/batch - loss: 22.58628 - diff: 14.61mlTrain batch 8/32 - 245.3ms/batch - loss: 28.81460 - diff: 16.33mlTrain batch 9/32 - 240.9ms/batch - loss: 30.49226 - diff: 17.01mlTrain batch 10/32 - 241.4ms/batch - loss: 30.57380 - diff: 17.21mlTrain batch 11/32 - 240.5ms/batch - loss: 32.32066 - diff: 17.40mlTrain batch 12/32 - 241.7ms/batch - loss: 32.66916 - diff: 17.48mlTrain batch 13/32 - 240.5ms/batch - loss: 31.54520 - diff: 17.19mlTrain batch 14/32 - 241.5ms/batch - loss: 31.40501 - diff: 17.25mlTrain batch 15/32 - 240.5ms/batch - loss: 30.76120 - diff: 17.20mlTrain batch 16/32 - 241.4ms/batch - loss: 30.51070 - diff: 17.28mlTrain batch 17/32 - 245.7ms/batch - loss: 31.79675 - diff: 17.49mlTrain batch 18/32 - 242.0ms/batch - loss: 31.27693 - diff: 17.30mlTrain batch 19/32 - 241.1ms/batch - loss: 31.70374 - diff: 17.48mlTrain batch 20/32 - 240.9ms/batch - loss: 31.19784 - diff: 17.31mlTrain batch 21/32 - 241.7ms/batch - loss: 30.16413 - diff: 16.96mlTrain batch 22/32 - 240.4ms/batch - loss: 29.84986 - diff: 16.97mlTrain batch 23/32 - 241.2ms/batch - loss: 29.76963 - diff: 17.06mlTrain batch 24/32 - 240.4ms/batch - loss: 30.30219 - diff: 17.33mlTrain batch 25/32 - 241.8ms/batch - loss: 30.77632 - diff: 17.45mlTrain batch 26/32 - 240.6ms/batch - loss: 31.19710 - diff: 17.65mlTrain batch 27/32 - 242.1ms/batch - loss: 31.16681 - diff: 17.68mlTrain batch 28/32 - 240.5ms/batch - loss: 31.53499 - diff: 17.79mlTrain batch 29/32 - 241.9ms/batch - loss: 30.76985 - diff: 17.51mlTrain batch 30/32 - 240.9ms/batch - loss: 31.05200 - diff: 17.54mlTrain batch 31/32 - 241.9ms/batch - loss: 30.87844 - diff: 17.46mlTrain batch 32/32 - 79.5ms/batch - loss: 30.87850 - diff: 17.39mlTrain batch 32/32 - 11.5s 79.5ms/batch - loss: 30.87850 - diff: 17.39ml
Test 1.1s: val_loss: 911.23474 - diff: 110.22ml
Epoch    62: reducing learning rate of group 0 to 3.1250e-05.

Epoch 62: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 240.4ms/batch - loss: 41.86824 - diff: 22.12mlTrain batch 2/32 - 241.3ms/batch - loss: 26.48036 - diff: 16.87mlTrain batch 3/32 - 240.2ms/batch - loss: 31.79499 - diff: 17.61mlTrain batch 4/32 - 241.4ms/batch - loss: 47.28671 - diff: 20.04mlTrain batch 5/32 - 240.6ms/batch - loss: 40.37646 - diff: 18.28mlTrain batch 6/32 - 241.7ms/batch - loss: 38.06998 - diff: 17.81mlTrain batch 7/32 - 240.6ms/batch - loss: 37.39329 - diff: 18.09mlTrain batch 8/32 - 241.5ms/batch - loss: 36.34154 - diff: 17.83mlTrain batch 9/32 - 241.0ms/batch - loss: 36.44028 - diff: 17.99mlTrain batch 10/32 - 242.0ms/batch - loss: 34.62795 - diff: 17.38mlTrain batch 11/32 - 240.8ms/batch - loss: 37.74434 - diff: 18.31mlTrain batch 12/32 - 241.5ms/batch - loss: 36.97285 - diff: 18.11mlTrain batch 13/32 - 240.7ms/batch - loss: 36.47827 - diff: 18.19mlTrain batch 14/32 - 241.1ms/batch - loss: 34.92021 - diff: 17.85mlTrain batch 15/32 - 240.6ms/batch - loss: 33.33565 - diff: 17.38mlTrain batch 16/32 - 241.2ms/batch - loss: 33.15817 - diff: 17.36mlTrain batch 17/32 - 240.5ms/batch - loss: 32.66313 - diff: 17.30mlTrain batch 18/32 - 241.2ms/batch - loss: 33.26232 - diff: 17.34mlTrain batch 19/32 - 241.0ms/batch - loss: 32.39221 - diff: 17.07mlTrain batch 20/32 - 241.6ms/batch - loss: 32.22845 - diff: 17.10mlTrain batch 21/32 - 241.1ms/batch - loss: 33.20274 - diff: 17.42mlTrain batch 22/32 - 241.3ms/batch - loss: 32.74808 - diff: 17.35mlTrain batch 23/32 - 241.0ms/batch - loss: 34.46814 - diff: 17.76mlTrain batch 24/32 - 241.4ms/batch - loss: 33.87693 - diff: 17.62mlTrain batch 25/32 - 241.1ms/batch - loss: 33.31227 - diff: 17.50mlTrain batch 26/32 - 241.3ms/batch - loss: 33.84848 - diff: 17.77mlTrain batch 27/32 - 240.6ms/batch - loss: 33.01092 - diff: 17.51mlTrain batch 28/32 - 241.1ms/batch - loss: 32.47317 - diff: 17.39mlTrain batch 29/32 - 240.8ms/batch - loss: 31.62831 - diff: 17.10mlTrain batch 30/32 - 241.7ms/batch - loss: 31.57921 - diff: 17.10mlTrain batch 31/32 - 241.0ms/batch - loss: 31.02385 - diff: 16.97mlTrain batch 32/32 - 79.2ms/batch - loss: 31.69898 - diff: 16.99mlTrain batch 32/32 - 11.6s 79.2ms/batch - loss: 31.69898 - diff: 16.99ml
Test 1.1s: val_loss: 820.43843 - diff: 106.69ml

Epoch 63: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 240.4ms/batch - loss: 52.73215 - diff: 20.87mlTrain batch 2/32 - 241.4ms/batch - loss: 38.09682 - diff: 17.57mlTrain batch 3/32 - 240.8ms/batch - loss: 33.40072 - diff: 17.27mlTrain batch 4/32 - 241.9ms/batch - loss: 31.93908 - diff: 17.21mlTrain batch 5/32 - 241.1ms/batch - loss: 35.05253 - diff: 18.16mlTrain batch 6/32 - 241.7ms/batch - loss: 31.10114 - diff: 17.10mlTrain batch 7/32 - 240.7ms/batch - loss: 29.28292 - diff: 16.53mlTrain batch 8/32 - 241.0ms/batch - loss: 30.13631 - diff: 16.94mlTrain batch 9/32 - 241.1ms/batch - loss: 32.71930 - diff: 17.45mlTrain batch 10/32 - 241.5ms/batch - loss: 32.48462 - diff: 17.43mlTrain batch 11/32 - 240.2ms/batch - loss: 31.53165 - diff: 17.13mlTrain batch 12/32 - 241.5ms/batch - loss: 30.26922 - diff: 16.74mlTrain batch 13/32 - 240.8ms/batch - loss: 29.52790 - diff: 16.60mlTrain batch 14/32 - 241.3ms/batch - loss: 29.91739 - diff: 16.66mlTrain batch 15/32 - 240.9ms/batch - loss: 30.07650 - diff: 16.86mlTrain batch 16/32 - 241.6ms/batch - loss: 31.77014 - diff: 17.47mlTrain batch 17/32 - 241.1ms/batch - loss: 30.91791 - diff: 17.25mlTrain batch 18/32 - 241.8ms/batch - loss: 30.50656 - diff: 17.19mlTrain batch 19/32 - 240.9ms/batch - loss: 29.79403 - diff: 17.07mlTrain batch 20/32 - 241.9ms/batch - loss: 29.32801 - diff: 16.96mlTrain batch 21/32 - 240.4ms/batch - loss: 29.45868 - diff: 16.89mlTrain batch 22/32 - 241.2ms/batch - loss: 29.32549 - diff: 16.89mlTrain batch 23/32 - 241.0ms/batch - loss: 29.26217 - diff: 16.91mlTrain batch 24/32 - 241.6ms/batch - loss: 30.15168 - diff: 17.12mlTrain batch 25/32 - 241.0ms/batch - loss: 30.97971 - diff: 17.35mlTrain batch 26/32 - 241.4ms/batch - loss: 30.36166 - diff: 17.20mlTrain batch 27/32 - 240.9ms/batch - loss: 34.32331 - diff: 18.11mlTrain batch 28/32 - 241.4ms/batch - loss: 33.86612 - diff: 18.02mlTrain batch 29/32 - 241.0ms/batch - loss: 33.44502 - diff: 17.95mlTrain batch 30/32 - 241.8ms/batch - loss: 34.54591 - diff: 18.27mlTrain batch 31/32 - 240.7ms/batch - loss: 34.75825 - diff: 18.40mlTrain batch 32/32 - 78.7ms/batch - loss: 34.98735 - diff: 18.38mlTrain batch 32/32 - 11.4s 78.7ms/batch - loss: 34.98735 - diff: 18.38ml
Test 1.1s: val_loss: 848.81500 - diff: 107.14ml

Epoch 64: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 240.7ms/batch - loss: 19.17861 - diff: 12.03mlTrain batch 2/32 - 241.4ms/batch - loss: 18.20962 - diff: 12.76mlTrain batch 3/32 - 240.8ms/batch - loss: 23.28395 - diff: 14.76mlTrain batch 4/32 - 241.6ms/batch - loss: 46.72242 - diff: 20.86mlTrain batch 5/32 - 240.8ms/batch - loss: 59.99175 - diff: 24.13mlTrain batch 6/32 - 241.5ms/batch - loss: 53.51679 - diff: 22.33mlTrain batch 7/32 - 240.8ms/batch - loss: 49.58830 - diff: 21.53mlTrain batch 8/32 - 241.4ms/batch - loss: 44.56978 - diff: 20.05mlTrain batch 9/32 - 240.3ms/batch - loss: 42.04126 - diff: 19.57mlTrain batch 10/32 - 241.3ms/batch - loss: 40.83455 - diff: 19.40mlTrain batch 11/32 - 240.4ms/batch - loss: 39.63599 - diff: 19.16mlTrain batch 12/32 - 241.6ms/batch - loss: 37.76688 - diff: 18.62mlTrain batch 13/32 - 240.9ms/batch - loss: 36.40276 - diff: 18.32mlTrain batch 14/32 - 242.0ms/batch - loss: 35.61242 - diff: 18.18mlTrain batch 15/32 - 240.4ms/batch - loss: 35.16872 - diff: 18.13mlTrain batch 16/32 - 242.0ms/batch - loss: 34.94724 - diff: 18.06mlTrain batch 17/32 - 240.4ms/batch - loss: 37.74959 - diff: 18.84mlTrain batch 18/32 - 241.4ms/batch - loss: 37.67241 - diff: 18.88mlTrain batch 19/32 - 241.1ms/batch - loss: 39.25366 - diff: 19.44mlTrain batch 20/32 - 241.9ms/batch - loss: 38.29977 - diff: 19.21mlTrain batch 21/32 - 241.1ms/batch - loss: 37.16245 - diff: 18.84mlTrain batch 22/32 - 241.5ms/batch - loss: 36.56998 - diff: 18.75mlTrain batch 23/32 - 241.2ms/batch - loss: 36.93077 - diff: 18.84mlTrain batch 24/32 - 241.6ms/batch - loss: 36.30982 - diff: 18.69mlTrain batch 25/32 - 241.1ms/batch - loss: 35.67392 - diff: 18.57mlTrain batch 26/32 - 241.7ms/batch - loss: 36.19861 - diff: 18.78mlTrain batch 27/32 - 240.5ms/batch - loss: 35.69525 - diff: 18.58mlTrain batch 28/32 - 240.7ms/batch - loss: 35.07845 - diff: 18.40mlTrain batch 29/32 - 241.2ms/batch - loss: 35.15797 - diff: 18.38mlTrain batch 30/32 - 240.4ms/batch - loss: 34.50551 - diff: 18.18mlTrain batch 31/32 - 241.2ms/batch - loss: 34.63186 - diff: 18.25mlTrain batch 32/32 - 79.0ms/batch - loss: 37.25944 - diff: 18.33mlTrain batch 32/32 - 11.6s 79.0ms/batch - loss: 37.25944 - diff: 18.33ml
Test 1.2s: val_loss: 856.27400 - diff: 108.39ml

Epoch 65: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 240.8ms/batch - loss: 60.27018 - diff: 26.02mlTrain batch 2/32 - 241.3ms/batch - loss: 41.79861 - diff: 20.41mlTrain batch 3/32 - 240.6ms/batch - loss: 32.31300 - diff: 17.50mlTrain batch 4/32 - 241.6ms/batch - loss: 37.40526 - diff: 19.51mlTrain batch 5/32 - 240.3ms/batch - loss: 34.78935 - diff: 18.89mlTrain batch 6/32 - 241.7ms/batch - loss: 40.35523 - diff: 20.61mlTrain batch 7/32 - 240.4ms/batch - loss: 39.94075 - diff: 20.61mlTrain batch 8/32 - 241.3ms/batch - loss: 38.15787 - diff: 19.71mlTrain batch 9/32 - 240.5ms/batch - loss: 39.52048 - diff: 20.23mlTrain batch 10/32 - 241.5ms/batch - loss: 39.06275 - diff: 20.13mlTrain batch 11/32 - 240.9ms/batch - loss: 40.48336 - diff: 20.44mlTrain batch 12/32 - 241.7ms/batch - loss: 38.22193 - diff: 19.77mlTrain batch 13/32 - 241.0ms/batch - loss: 36.92448 - diff: 19.29mlTrain batch 14/32 - 241.9ms/batch - loss: 35.36423 - diff: 18.88mlTrain batch 15/32 - 241.5ms/batch - loss: 35.56532 - diff: 18.99mlTrain batch 16/32 - 241.9ms/batch - loss: 35.02053 - diff: 18.89mlTrain batch 17/32 - 240.7ms/batch - loss: 37.48521 - diff: 19.37mlTrain batch 18/32 - 242.1ms/batch - loss: 36.13523 - diff: 18.97mlTrain batch 19/32 - 241.1ms/batch - loss: 37.59909 - diff: 19.35mlTrain batch 20/32 - 242.1ms/batch - loss: 36.24577 - diff: 18.92mlTrain batch 21/32 - 241.2ms/batch - loss: 36.18874 - diff: 18.97mlTrain batch 22/32 - 242.0ms/batch - loss: 36.58455 - diff: 19.03mlTrain batch 23/32 - 240.5ms/batch - loss: 36.11638 - diff: 18.88mlTrain batch 24/32 - 241.1ms/batch - loss: 36.23021 - diff: 18.99mlTrain batch 25/32 - 240.6ms/batch - loss: 36.09824 - diff: 18.88mlTrain batch 26/32 - 241.7ms/batch - loss: 35.32945 - diff: 18.63mlTrain batch 27/32 - 241.1ms/batch - loss: 34.95318 - diff: 18.47mlTrain batch 28/32 - 241.6ms/batch - loss: 35.42401 - diff: 18.70mlTrain batch 29/32 - 241.0ms/batch - loss: 34.98752 - diff: 18.53mlTrain batch 30/32 - 241.6ms/batch - loss: 35.57424 - diff: 18.53mlTrain batch 31/32 - 240.4ms/batch - loss: 36.11655 - diff: 18.71mlTrain batch 32/32 - 78.0ms/batch - loss: 36.42473 - diff: 18.68mlTrain batch 32/32 - 11.9s 78.0ms/batch - loss: 36.42473 - diff: 18.68ml
Test 1.1s: val_loss: 984.24671 - diff: 117.22ml

Epoch 66: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 240.5ms/batch - loss: 19.78004 - diff: 13.51mlTrain batch 2/32 - 241.3ms/batch - loss: 38.97886 - diff: 19.84mlTrain batch 3/32 - 240.5ms/batch - loss: 57.48567 - diff: 25.51mlTrain batch 4/32 - 242.0ms/batch - loss: 47.76820 - diff: 22.64mlTrain batch 5/32 - 240.6ms/batch - loss: 43.12917 - diff: 21.21mlTrain batch 6/32 - 241.9ms/batch - loss: 38.24289 - diff: 19.68mlTrain batch 7/32 - 240.8ms/batch - loss: 36.46870 - diff: 19.30mlTrain batch 8/32 - 241.7ms/batch - loss: 34.32113 - diff: 18.59mlTrain batch 9/32 - 240.5ms/batch - loss: 32.63876 - diff: 18.12mlTrain batch 10/32 - 241.8ms/batch - loss: 31.56477 - diff: 17.78mlTrain batch 11/32 - 240.5ms/batch - loss: 30.45426 - diff: 17.59mlTrain batch 12/32 - 241.6ms/batch - loss: 31.19276 - diff: 18.01mlTrain batch 13/32 - 240.9ms/batch - loss: 30.64788 - diff: 17.93mlTrain batch 14/32 - 241.4ms/batch - loss: 30.90597 - diff: 17.97mlTrain batch 15/32 - 240.2ms/batch - loss: 30.47541 - diff: 17.89mlTrain batch 16/32 - 241.7ms/batch - loss: 29.27024 - diff: 17.40mlTrain batch 17/32 - 240.6ms/batch - loss: 30.34720 - diff: 17.59mlTrain batch 18/32 - 241.7ms/batch - loss: 29.56933 - diff: 17.34mlTrain batch 19/32 - 244.4ms/batch - loss: 28.83488 - diff: 17.11mlTrain batch 20/32 - 241.8ms/batch - loss: 27.77209 - diff: 16.74mlTrain batch 21/32 - 244.3ms/batch - loss: 28.06368 - diff: 16.85mlTrain batch 22/32 - 241.8ms/batch - loss: 27.70332 - diff: 16.79mlTrain batch 23/32 - 241.1ms/batch - loss: 27.41407 - diff: 16.66mlTrain batch 24/32 - 241.8ms/batch - loss: 27.05992 - diff: 16.56mlTrain batch 25/32 - 240.5ms/batch - loss: 26.86452 - diff: 16.47mlTrain batch 26/32 - 242.0ms/batch - loss: 26.49577 - diff: 16.31mlTrain batch 27/32 - 240.8ms/batch - loss: 27.53699 - diff: 16.66mlTrain batch 28/32 - 241.0ms/batch - loss: 26.89690 - diff: 16.44mlTrain batch 29/32 - 240.4ms/batch - loss: 26.96059 - diff: 16.45mlTrain batch 30/32 - 241.2ms/batch - loss: 26.73395 - diff: 16.40mlTrain batch 31/32 - 240.8ms/batch - loss: 27.27111 - diff: 16.62mlTrain batch 32/32 - 79.0ms/batch - loss: 28.88087 - diff: 16.67mlTrain batch 32/32 - 11.9s 79.0ms/batch - loss: 28.88087 - diff: 16.67ml
Test 1.1s: val_loss: 1093.42538 - diff: 123.57ml

Epoch 67: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 240.5ms/batch - loss: 29.20772 - diff: 16.53mlTrain batch 2/32 - 241.1ms/batch - loss: 24.58614 - diff: 15.14mlTrain batch 3/32 - 240.3ms/batch - loss: 26.14699 - diff: 16.19mlTrain batch 4/32 - 241.3ms/batch - loss: 22.87017 - diff: 15.10mlTrain batch 5/32 - 240.6ms/batch - loss: 26.38391 - diff: 16.28mlTrain batch 6/32 - 240.9ms/batch - loss: 26.34926 - diff: 16.10mlTrain batch 7/32 - 240.8ms/batch - loss: 26.19614 - diff: 16.04mlTrain batch 8/32 - 240.7ms/batch - loss: 23.79563 - diff: 14.93mlTrain batch 9/32 - 241.1ms/batch - loss: 22.84369 - diff: 14.63mlTrain batch 10/32 - 241.0ms/batch - loss: 22.53529 - diff: 14.62mlTrain batch 11/32 - 241.7ms/batch - loss: 22.69259 - diff: 14.84mlTrain batch 12/32 - 240.7ms/batch - loss: 22.67322 - diff: 14.86mlTrain batch 13/32 - 241.5ms/batch - loss: 24.74895 - diff: 15.56mlTrain batch 14/32 - 241.4ms/batch - loss: 25.96909 - diff: 15.89mlTrain batch 15/32 - 242.4ms/batch - loss: 27.20957 - diff: 16.31mlTrain batch 16/32 - 240.4ms/batch - loss: 27.25428 - diff: 16.53mlTrain batch 17/32 - 241.8ms/batch - loss: 26.89820 - diff: 16.43mlTrain batch 18/32 - 240.7ms/batch - loss: 30.74514 - diff: 17.23mlTrain batch 19/32 - 241.7ms/batch - loss: 31.25752 - diff: 17.42mlTrain batch 20/32 - 240.5ms/batch - loss: 30.38941 - diff: 17.19mlTrain batch 21/32 - 240.6ms/batch - loss: 30.22758 - diff: 17.21mlTrain batch 22/32 - 241.5ms/batch - loss: 29.65550 - diff: 17.07mlTrain batch 23/32 - 240.8ms/batch - loss: 29.49912 - diff: 17.11mlTrain batch 24/32 - 241.4ms/batch - loss: 29.94220 - diff: 17.25mlTrain batch 25/32 - 240.4ms/batch - loss: 32.35011 - diff: 17.92mlTrain batch 26/32 - 241.7ms/batch - loss: 32.97901 - diff: 18.04mlTrain batch 27/32 - 240.8ms/batch - loss: 33.37909 - diff: 18.18mlTrain batch 28/32 - 241.2ms/batch - loss: 33.05177 - diff: 18.13mlTrain batch 29/32 - 241.5ms/batch - loss: 32.78195 - diff: 18.04mlTrain batch 30/32 - 240.5ms/batch - loss: 32.69728 - diff: 18.04mlTrain batch 31/32 - 241.3ms/batch - loss: 32.86467 - diff: 18.10mlTrain batch 32/32 - 79.3ms/batch - loss: 33.01641 - diff: 18.06mlTrain batch 32/32 - 11.8s 79.3ms/batch - loss: 33.01641 - diff: 18.06ml
Test 1.1s: val_loss: 708.29711 - diff: 96.09ml

Epoch 68: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 240.4ms/batch - loss: 8.80615 - diff: 9.57mlTrain batch 2/32 - 241.3ms/batch - loss: 37.91740 - diff: 18.88mlTrain batch 3/32 - 240.5ms/batch - loss: 43.97767 - diff: 20.99mlTrain batch 4/32 - 241.4ms/batch - loss: 36.81399 - diff: 18.78mlTrain batch 5/32 - 240.6ms/batch - loss: 31.97197 - diff: 17.23mlTrain batch 6/32 - 241.3ms/batch - loss: 29.51201 - diff: 16.52mlTrain batch 7/32 - 240.4ms/batch - loss: 28.64519 - diff: 16.44mlTrain batch 8/32 - 241.7ms/batch - loss: 27.39146 - diff: 16.14mlTrain batch 9/32 - 240.8ms/batch - loss: 27.76514 - diff: 16.31mlTrain batch 10/32 - 241.8ms/batch - loss: 31.41829 - diff: 17.33mlTrain batch 11/32 - 240.8ms/batch - loss: 32.18807 - diff: 17.70mlTrain batch 12/32 - 241.4ms/batch - loss: 34.43178 - diff: 18.32mlTrain batch 13/32 - 240.4ms/batch - loss: 32.82671 - diff: 17.68mlTrain batch 14/32 - 241.1ms/batch - loss: 34.83671 - diff: 17.98mlTrain batch 15/32 - 240.7ms/batch - loss: 33.69869 - diff: 17.62mlTrain batch 16/32 - 241.5ms/batch - loss: 32.49431 - diff: 17.27mlTrain batch 17/32 - 240.4ms/batch - loss: 31.64217 - diff: 17.07mlTrain batch 18/32 - 241.4ms/batch - loss: 31.09010 - diff: 16.89mlTrain batch 19/32 - 240.3ms/batch - loss: 30.09748 - diff: 16.59mlTrain batch 20/32 - 241.8ms/batch - loss: 31.00228 - diff: 16.90mlTrain batch 21/32 - 240.3ms/batch - loss: 30.26594 - diff: 16.69mlTrain batch 22/32 - 241.5ms/batch - loss: 29.93878 - diff: 16.64mlTrain batch 23/32 - 240.4ms/batch - loss: 29.53167 - diff: 16.56mlTrain batch 24/32 - 241.6ms/batch - loss: 29.04154 - diff: 16.46mlTrain batch 25/32 - 240.6ms/batch - loss: 28.33007 - diff: 16.27mlTrain batch 26/32 - 241.4ms/batch - loss: 27.72961 - diff: 16.02mlTrain batch 27/32 - 240.8ms/batch - loss: 27.21674 - diff: 15.88mlTrain batch 28/32 - 242.0ms/batch - loss: 30.10033 - diff: 16.62mlTrain batch 29/32 - 240.9ms/batch - loss: 29.79028 - diff: 16.62mlTrain batch 30/32 - 241.7ms/batch - loss: 29.46876 - diff: 16.61mlTrain batch 31/32 - 241.0ms/batch - loss: 29.47373 - diff: 16.65mlTrain batch 32/32 - 79.5ms/batch - loss: 30.80462 - diff: 16.68mlTrain batch 32/32 - 11.5s 79.5ms/batch - loss: 30.80462 - diff: 16.68ml
Test 1.1s: val_loss: 933.95060 - diff: 114.01ml

Epoch 69: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 240.3ms/batch - loss: 23.60852 - diff: 14.82mlTrain batch 2/32 - 241.4ms/batch - loss: 19.43532 - diff: 13.63mlTrain batch 3/32 - 240.7ms/batch - loss: 21.18512 - diff: 14.66mlTrain batch 4/32 - 241.4ms/batch - loss: 29.86845 - diff: 17.05mlTrain batch 5/32 - 240.3ms/batch - loss: 30.64122 - diff: 17.52mlTrain batch 6/32 - 241.6ms/batch - loss: 34.07768 - diff: 18.33mlTrain batch 7/32 - 241.0ms/batch - loss: 38.61376 - diff: 19.44mlTrain batch 8/32 - 241.7ms/batch - loss: 36.93677 - diff: 19.19mlTrain batch 9/32 - 240.3ms/batch - loss: 38.75341 - diff: 19.62mlTrain batch 10/32 - 241.4ms/batch - loss: 36.37261 - diff: 19.00mlTrain batch 11/32 - 240.5ms/batch - loss: 35.71975 - diff: 18.88mlTrain batch 12/32 - 241.5ms/batch - loss: 37.00525 - diff: 19.16mlTrain batch 13/32 - 240.3ms/batch - loss: 35.46876 - diff: 18.57mlTrain batch 14/32 - 241.9ms/batch - loss: 35.98534 - diff: 18.84mlTrain batch 15/32 - 240.8ms/batch - loss: 34.20813 - diff: 18.27mlTrain batch 16/32 - 241.5ms/batch - loss: 33.25563 - diff: 17.93mlTrain batch 17/32 - 240.8ms/batch - loss: 33.85311 - diff: 18.11mlTrain batch 18/32 - 241.7ms/batch - loss: 32.90078 - diff: 17.84mlTrain batch 19/32 - 241.0ms/batch - loss: 31.97703 - diff: 17.65mlTrain batch 20/32 - 241.6ms/batch - loss: 32.08783 - diff: 17.76mlTrain batch 21/32 - 240.2ms/batch - loss: 30.89003 - diff: 17.32mlTrain batch 22/32 - 241.1ms/batch - loss: 30.37669 - diff: 17.15mlTrain batch 23/32 - 240.9ms/batch - loss: 30.44865 - diff: 17.13mlTrain batch 24/32 - 241.7ms/batch - loss: 30.12299 - diff: 17.13mlTrain batch 25/32 - 240.6ms/batch - loss: 29.80320 - diff: 17.07mlTrain batch 26/32 - 241.7ms/batch - loss: 29.65781 - diff: 17.09mlTrain batch 27/32 - 241.0ms/batch - loss: 30.97656 - diff: 17.48mlTrain batch 28/32 - 240.7ms/batch - loss: 30.52664 - diff: 17.38mlTrain batch 29/32 - 241.6ms/batch - loss: 30.78023 - diff: 17.45mlTrain batch 30/32 - 242.4ms/batch - loss: 30.28386 - diff: 17.31mlTrain batch 31/32 - 240.8ms/batch - loss: 29.84204 - diff: 17.20mlTrain batch 32/32 - 80.0ms/batch - loss: 29.98189 - diff: 17.15mlTrain batch 32/32 - 11.2s 80.0ms/batch - loss: 29.98189 - diff: 17.15ml
Test 1.1s: val_loss: 589.08872 - diff: 86.91ml

Epoch 70: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 240.4ms/batch - loss: 35.35486 - diff: 18.78mlTrain batch 2/32 - 241.2ms/batch - loss: 23.78215 - diff: 15.24mlTrain batch 3/32 - 240.3ms/batch - loss: 19.64300 - diff: 13.88mlTrain batch 4/32 - 241.5ms/batch - loss: 21.16806 - diff: 14.29mlTrain batch 5/32 - 241.7ms/batch - loss: 22.94399 - diff: 15.03mlTrain batch 6/32 - 240.9ms/batch - loss: 23.28277 - diff: 15.07mlTrain batch 7/32 - 241.1ms/batch - loss: 22.69110 - diff: 14.97mlTrain batch 8/32 - 240.3ms/batch - loss: 26.20339 - diff: 16.30mlTrain batch 9/32 - 241.5ms/batch - loss: 24.85249 - diff: 15.85mlTrain batch 10/32 - 240.9ms/batch - loss: 24.85673 - diff: 15.88mlTrain batch 11/32 - 241.5ms/batch - loss: 24.24870 - diff: 15.79mlTrain batch 12/32 - 240.5ms/batch - loss: 24.20054 - diff: 15.80mlTrain batch 13/32 - 241.7ms/batch - loss: 26.13039 - diff: 16.44mlTrain batch 14/32 - 240.5ms/batch - loss: 25.75825 - diff: 16.37mlTrain batch 15/32 - 241.1ms/batch - loss: 28.23211 - diff: 17.04mlTrain batch 16/32 - 240.4ms/batch - loss: 27.82268 - diff: 16.96mlTrain batch 17/32 - 241.0ms/batch - loss: 27.35385 - diff: 16.85mlTrain batch 18/32 - 241.1ms/batch - loss: 29.46454 - diff: 17.53mlTrain batch 19/32 - 241.5ms/batch - loss: 29.03078 - diff: 17.46mlTrain batch 20/32 - 241.3ms/batch - loss: 28.67671 - diff: 17.41mlTrain batch 21/32 - 241.6ms/batch - loss: 28.57152 - diff: 17.39mlTrain batch 22/32 - 241.3ms/batch - loss: 28.80018 - diff: 17.42mlTrain batch 23/32 - 241.7ms/batch - loss: 29.62050 - diff: 17.75mlTrain batch 24/32 - 241.0ms/batch - loss: 33.73345 - diff: 18.68mlTrain batch 25/32 - 241.5ms/batch - loss: 32.87520 - diff: 18.38mlTrain batch 26/32 - 240.8ms/batch - loss: 32.56005 - diff: 18.25mlTrain batch 27/32 - 240.4ms/batch - loss: 33.39114 - diff: 18.41mlTrain batch 28/32 - 242.1ms/batch - loss: 32.74980 - diff: 18.22mlTrain batch 29/32 - 241.1ms/batch - loss: 32.29016 - diff: 18.10mlTrain batch 30/32 - 241.8ms/batch - loss: 32.34769 - diff: 18.13mlTrain batch 31/32 - 240.8ms/batch - loss: 31.70247 - diff: 17.93mlTrain batch 32/32 - 79.4ms/batch - loss: 33.43935 - diff: 18.01mlTrain batch 32/32 - 11.5s 79.4ms/batch - loss: 33.43935 - diff: 18.01ml
Test 1.1s: val_loss: 576.43587 - diff: 86.10ml

Epoch 71: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 240.8ms/batch - loss: 19.49398 - diff: 12.95mlTrain batch 2/32 - 241.3ms/batch - loss: 25.65047 - diff: 15.39mlTrain batch 3/32 - 241.1ms/batch - loss: 29.49428 - diff: 16.92mlTrain batch 4/32 - 241.5ms/batch - loss: 28.51974 - diff: 16.64mlTrain batch 5/32 - 240.8ms/batch - loss: 37.64080 - diff: 18.93mlTrain batch 6/32 - 241.8ms/batch - loss: 33.85968 - diff: 17.94mlTrain batch 7/32 - 240.7ms/batch - loss: 33.05278 - diff: 17.84mlTrain batch 8/32 - 241.2ms/batch - loss: 32.47628 - diff: 17.90mlTrain batch 9/32 - 240.9ms/batch - loss: 29.94292 - diff: 17.01mlTrain batch 10/32 - 241.5ms/batch - loss: 30.23895 - diff: 17.25mlTrain batch 11/32 - 241.4ms/batch - loss: 33.48509 - diff: 17.88mlTrain batch 12/32 - 241.4ms/batch - loss: 31.25818 - diff: 17.08mlTrain batch 13/32 - 240.9ms/batch - loss: 32.33360 - diff: 17.43mlTrain batch 14/32 - 241.2ms/batch - loss: 30.92508 - diff: 17.07mlTrain batch 15/32 - 241.1ms/batch - loss: 30.52189 - diff: 17.03mlTrain batch 16/32 - 241.9ms/batch - loss: 29.74801 - diff: 16.82mlTrain batch 17/32 - 241.3ms/batch - loss: 29.64746 - diff: 16.88mlTrain batch 18/32 - 241.6ms/batch - loss: 29.03674 - diff: 16.76mlTrain batch 19/32 - 241.8ms/batch - loss: 29.21381 - diff: 16.89mlTrain batch 20/32 - 241.7ms/batch - loss: 29.96328 - diff: 17.08mlTrain batch 21/32 - 241.3ms/batch - loss: 29.48950 - diff: 16.90mlTrain batch 22/32 - 240.9ms/batch - loss: 29.41262 - diff: 16.89mlTrain batch 23/32 - 241.5ms/batch - loss: 29.32487 - diff: 16.99mlTrain batch 24/32 - 241.0ms/batch - loss: 29.34897 - diff: 17.08mlTrain batch 25/32 - 241.3ms/batch - loss: 28.87196 - diff: 16.97mlTrain batch 26/32 - 241.4ms/batch - loss: 28.76948 - diff: 16.91mlTrain batch 27/32 - 240.8ms/batch - loss: 28.73870 - diff: 16.85mlTrain batch 28/32 - 241.8ms/batch - loss: 28.93932 - diff: 16.93mlTrain batch 29/32 - 240.5ms/batch - loss: 28.80034 - diff: 16.88mlTrain batch 30/32 - 241.5ms/batch - loss: 29.34111 - diff: 17.00mlTrain batch 31/32 - 240.8ms/batch - loss: 29.45405 - diff: 17.04mlTrain batch 32/32 - 79.3ms/batch - loss: 31.33003 - diff: 17.16mlTrain batch 32/32 - 11.6s 79.3ms/batch - loss: 31.33003 - diff: 17.16ml
Test 1.1s: val_loss: 860.63809 - diff: 108.14ml

Epoch 72: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 241.1ms/batch - loss: 19.00824 - diff: 14.40mlTrain batch 2/32 - 241.8ms/batch - loss: 27.36508 - diff: 17.70mlTrain batch 3/32 - 240.9ms/batch - loss: 31.39683 - diff: 18.05mlTrain batch 4/32 - 241.8ms/batch - loss: 29.88512 - diff: 17.72mlTrain batch 5/32 - 240.6ms/batch - loss: 31.52069 - diff: 18.02mlTrain batch 6/32 - 241.1ms/batch - loss: 29.54830 - diff: 17.60mlTrain batch 7/32 - 240.6ms/batch - loss: 29.22896 - diff: 17.47mlTrain batch 8/32 - 241.6ms/batch - loss: 28.01344 - diff: 17.13mlTrain batch 9/32 - 240.5ms/batch - loss: 27.82033 - diff: 17.12mlTrain batch 10/32 - 241.6ms/batch - loss: 27.81517 - diff: 16.93mlTrain batch 11/32 - 240.7ms/batch - loss: 27.80666 - diff: 16.85mlTrain batch 12/32 - 241.1ms/batch - loss: 27.10680 - diff: 16.71mlTrain batch 13/32 - 240.3ms/batch - loss: 25.95210 - diff: 16.33mlTrain batch 14/32 - 241.6ms/batch - loss: 25.07697 - diff: 16.03mlTrain batch 15/32 - 241.0ms/batch - loss: 24.59091 - diff: 15.88mlTrain batch 16/32 - 241.8ms/batch - loss: 25.87385 - diff: 16.32mlTrain batch 17/32 - 240.5ms/batch - loss: 25.50628 - diff: 16.27mlTrain batch 18/32 - 241.8ms/batch - loss: 25.96389 - diff: 16.27mlTrain batch 19/32 - 241.1ms/batch - loss: 25.17133 - diff: 15.92mlTrain batch 20/32 - 241.6ms/batch - loss: 25.58899 - diff: 16.09mlTrain batch 21/32 - 240.9ms/batch - loss: 25.86346 - diff: 16.13mlTrain batch 22/32 - 242.2ms/batch - loss: 25.98974 - diff: 16.05mlTrain batch 23/32 - 240.9ms/batch - loss: 25.86583 - diff: 16.09mlTrain batch 24/32 - 241.8ms/batch - loss: 25.57880 - diff: 15.97mlTrain batch 25/32 - 241.3ms/batch - loss: 25.97826 - diff: 16.16mlTrain batch 26/32 - 241.7ms/batch - loss: 25.53268 - diff: 15.97mlTrain batch 27/32 - 240.9ms/batch - loss: 25.25245 - diff: 15.89mlTrain batch 28/32 - 241.8ms/batch - loss: 25.31355 - diff: 15.93mlTrain batch 29/32 - 241.2ms/batch - loss: 28.75772 - diff: 16.71mlTrain batch 30/32 - 241.1ms/batch - loss: 29.59307 - diff: 16.98mlTrain batch 31/32 - 240.9ms/batch - loss: 29.20818 - diff: 16.85mlTrain batch 32/32 - 79.2ms/batch - loss: 29.61463 - diff: 16.86mlTrain batch 32/32 - 11.9s 79.2ms/batch - loss: 29.61463 - diff: 16.86ml
Test 1.1s: val_loss: 736.01461 - diff: 99.14ml
Epoch    73: reducing learning rate of group 0 to 1.5625e-05.

Epoch 73: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 240.5ms/batch - loss: 17.46712 - diff: 12.74mlTrain batch 2/32 - 241.9ms/batch - loss: 23.05165 - diff: 15.94mlTrain batch 3/32 - 240.5ms/batch - loss: 21.23244 - diff: 14.96mlTrain batch 4/32 - 241.7ms/batch - loss: 21.61349 - diff: 14.93mlTrain batch 5/32 - 240.8ms/batch - loss: 19.44319 - diff: 13.83mlTrain batch 6/32 - 242.0ms/batch - loss: 19.70119 - diff: 13.88mlTrain batch 7/32 - 240.8ms/batch - loss: 24.34987 - diff: 15.57mlTrain batch 8/32 - 242.0ms/batch - loss: 24.70264 - diff: 15.81mlTrain batch 9/32 - 240.5ms/batch - loss: 26.39079 - diff: 16.06mlTrain batch 10/32 - 241.6ms/batch - loss: 29.36252 - diff: 16.98mlTrain batch 11/32 - 240.9ms/batch - loss: 29.34917 - diff: 16.97mlTrain batch 12/32 - 244.6ms/batch - loss: 29.59810 - diff: 17.12mlTrain batch 13/32 - 240.3ms/batch - loss: 29.37910 - diff: 17.16mlTrain batch 14/32 - 241.7ms/batch - loss: 30.27651 - diff: 17.42mlTrain batch 15/32 - 241.0ms/batch - loss: 31.15067 - diff: 17.82mlTrain batch 16/32 - 241.3ms/batch - loss: 31.86515 - diff: 18.03mlTrain batch 17/32 - 241.0ms/batch - loss: 30.97623 - diff: 17.77mlTrain batch 18/32 - 241.7ms/batch - loss: 33.32307 - diff: 18.39mlTrain batch 19/32 - 240.6ms/batch - loss: 32.99124 - diff: 18.33mlTrain batch 20/32 - 241.8ms/batch - loss: 32.95506 - diff: 18.37mlTrain batch 21/32 - 241.2ms/batch - loss: 32.56990 - diff: 18.22mlTrain batch 22/32 - 241.7ms/batch - loss: 32.31188 - diff: 18.11mlTrain batch 23/32 - 241.1ms/batch - loss: 31.95977 - diff: 18.03mlTrain batch 24/32 - 241.7ms/batch - loss: 32.14204 - diff: 18.11mlTrain batch 25/32 - 241.0ms/batch - loss: 32.67891 - diff: 18.28mlTrain batch 26/32 - 241.4ms/batch - loss: 32.00010 - diff: 18.01mlTrain batch 27/32 - 241.4ms/batch - loss: 31.40113 - diff: 17.86mlTrain batch 28/32 - 241.9ms/batch - loss: 31.00489 - diff: 17.76mlTrain batch 29/32 - 243.2ms/batch - loss: 30.48903 - diff: 17.64mlTrain batch 30/32 - 242.0ms/batch - loss: 30.20083 - diff: 17.45mlTrain batch 31/32 - 240.2ms/batch - loss: 29.41656 - diff: 17.14mlTrain batch 32/32 - 78.1ms/batch - loss: 29.83461 - diff: 17.12mlTrain batch 32/32 - 11.8s 78.1ms/batch - loss: 29.83461 - diff: 17.12ml
Test 1.1s: val_loss: 795.55888 - diff: 103.98ml

Epoch 74: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 240.4ms/batch - loss: 18.95668 - diff: 13.39mlTrain batch 2/32 - 241.7ms/batch - loss: 16.45953 - diff: 12.52mlTrain batch 3/32 - 240.5ms/batch - loss: 13.15403 - diff: 10.95mlTrain batch 4/32 - 241.4ms/batch - loss: 17.65992 - diff: 12.06mlTrain batch 5/32 - 240.2ms/batch - loss: 22.52603 - diff: 14.10mlTrain batch 6/32 - 241.7ms/batch - loss: 20.71383 - diff: 13.42mlTrain batch 7/32 - 240.2ms/batch - loss: 19.56868 - diff: 13.16mlTrain batch 8/32 - 241.3ms/batch - loss: 18.90290 - diff: 12.96mlTrain batch 9/32 - 241.1ms/batch - loss: 20.69798 - diff: 13.56mlTrain batch 10/32 - 241.4ms/batch - loss: 20.46061 - diff: 13.59mlTrain batch 11/32 - 241.0ms/batch - loss: 21.45343 - diff: 13.85mlTrain batch 12/32 - 241.9ms/batch - loss: 21.71675 - diff: 14.02mlTrain batch 13/32 - 240.3ms/batch - loss: 21.92007 - diff: 14.25mlTrain batch 14/32 - 241.5ms/batch - loss: 21.82116 - diff: 14.16mlTrain batch 15/32 - 240.8ms/batch - loss: 23.92218 - diff: 15.02mlTrain batch 16/32 - 241.7ms/batch - loss: 24.25886 - diff: 15.27mlTrain batch 17/32 - 240.5ms/batch - loss: 23.78033 - diff: 15.18mlTrain batch 18/32 - 241.4ms/batch - loss: 24.54311 - diff: 15.50mlTrain batch 19/32 - 240.5ms/batch - loss: 24.67593 - diff: 15.64mlTrain batch 20/32 - 241.9ms/batch - loss: 25.24165 - diff: 15.82mlTrain batch 21/32 - 241.3ms/batch - loss: 26.48604 - diff: 16.30mlTrain batch 22/32 - 242.1ms/batch - loss: 26.45836 - diff: 16.38mlTrain batch 23/32 - 240.7ms/batch - loss: 28.36709 - diff: 16.97mlTrain batch 24/32 - 241.3ms/batch - loss: 28.16412 - diff: 16.86mlTrain batch 25/32 - 240.2ms/batch - loss: 27.35388 - diff: 16.55mlTrain batch 26/32 - 241.6ms/batch - loss: 27.57197 - diff: 16.66mlTrain batch 27/32 - 240.7ms/batch - loss: 27.27822 - diff: 16.51mlTrain batch 28/32 - 241.7ms/batch - loss: 27.16246 - diff: 16.52mlTrain batch 29/32 - 240.9ms/batch - loss: 27.11340 - diff: 16.53mlTrain batch 30/32 - 241.1ms/batch - loss: 27.56524 - diff: 16.72mlTrain batch 31/32 - 240.9ms/batch - loss: 27.77869 - diff: 16.81mlTrain batch 32/32 - 79.1ms/batch - loss: 29.79262 - diff: 16.91mlTrain batch 32/32 - 12.2s 79.1ms/batch - loss: 29.79262 - diff: 16.91ml
Test 1.1s: val_loss: 782.70863 - diff: 102.47ml

Epoch 75: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 241.0ms/batch - loss: 31.04847 - diff: 18.32mlTrain batch 2/32 - 241.7ms/batch - loss: 110.19896 - diff: 35.12mlTrain batch 3/32 - 240.4ms/batch - loss: 106.33965 - diff: 34.64mlTrain batch 4/32 - 241.0ms/batch - loss: 81.95597 - diff: 28.28mlTrain batch 5/32 - 240.9ms/batch - loss: 70.27134 - diff: 25.71mlTrain batch 6/32 - 240.7ms/batch - loss: 63.58609 - diff: 24.41mlTrain batch 7/32 - 241.3ms/batch - loss: 58.04412 - diff: 22.98mlTrain batch 8/32 - 241.2ms/batch - loss: 56.90536 - diff: 23.36mlTrain batch 9/32 - 241.1ms/batch - loss: 56.93420 - diff: 23.42mlTrain batch 10/32 - 240.4ms/batch - loss: 52.66249 - diff: 22.29mlTrain batch 11/32 - 241.5ms/batch - loss: 49.72506 - diff: 21.70mlTrain batch 12/32 - 240.6ms/batch - loss: 47.34440 - diff: 21.08mlTrain batch 13/32 - 241.6ms/batch - loss: 47.36073 - diff: 21.37mlTrain batch 14/32 - 240.4ms/batch - loss: 45.40703 - diff: 20.83mlTrain batch 15/32 - 241.3ms/batch - loss: 45.89898 - diff: 21.13mlTrain batch 16/32 - 240.7ms/batch - loss: 44.01767 - diff: 20.62mlTrain batch 17/32 - 241.7ms/batch - loss: 42.35191 - diff: 20.10mlTrain batch 18/32 - 240.9ms/batch - loss: 46.03889 - diff: 21.10mlTrain batch 19/32 - 241.4ms/batch - loss: 45.08484 - diff: 20.93mlTrain batch 20/32 - 240.8ms/batch - loss: 44.39262 - diff: 20.77mlTrain batch 21/32 - 241.2ms/batch - loss: 43.01451 - diff: 20.35mlTrain batch 22/32 - 241.2ms/batch - loss: 41.77178 - diff: 19.98mlTrain batch 23/32 - 243.7ms/batch - loss: 41.35522 - diff: 19.93mlTrain batch 24/32 - 240.7ms/batch - loss: 42.53806 - diff: 20.41mlTrain batch 25/32 - 241.6ms/batch - loss: 42.06405 - diff: 20.32mlTrain batch 26/32 - 240.3ms/batch - loss: 40.85343 - diff: 19.97mlTrain batch 27/32 - 241.8ms/batch - loss: 40.04324 - diff: 19.77mlTrain batch 28/32 - 240.6ms/batch - loss: 39.21538 - diff: 19.59mlTrain batch 29/32 - 241.5ms/batch - loss: 38.27289 - diff: 19.32mlTrain batch 30/32 - 240.1ms/batch - loss: 38.10104 - diff: 19.22mlTrain batch 31/32 - 241.7ms/batch - loss: 37.05366 - diff: 18.85mlTrain batch 32/32 - 79.4ms/batch - loss: 38.75395 - diff: 18.93mlTrain batch 32/32 - 11.3s 79.4ms/batch - loss: 38.75395 - diff: 18.93ml
Test 1.1s: val_loss: 877.77771 - diff: 108.01ml

Epoch 76: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 240.9ms/batch - loss: 18.63688 - diff: 13.08mlTrain batch 2/32 - 241.0ms/batch - loss: 20.23152 - diff: 14.22mlTrain batch 3/32 - 240.6ms/batch - loss: 23.83965 - diff: 16.02mlTrain batch 4/32 - 241.4ms/batch - loss: 20.90333 - diff: 14.88mlTrain batch 5/32 - 240.6ms/batch - loss: 27.24058 - diff: 16.99mlTrain batch 6/32 - 241.5ms/batch - loss: 24.29934 - diff: 15.77mlTrain batch 7/32 - 240.8ms/batch - loss: 23.49046 - diff: 15.43mlTrain batch 8/32 - 241.4ms/batch - loss: 23.00802 - diff: 15.15mlTrain batch 9/32 - 240.4ms/batch - loss: 22.17907 - diff: 14.95mlTrain batch 10/32 - 241.2ms/batch - loss: 24.19379 - diff: 15.51mlTrain batch 11/32 - 240.5ms/batch - loss: 23.13592 - diff: 15.04mlTrain batch 12/32 - 241.1ms/batch - loss: 21.95562 - diff: 14.61mlTrain batch 13/32 - 240.5ms/batch - loss: 29.09103 - diff: 16.48mlTrain batch 14/32 - 241.1ms/batch - loss: 27.86654 - diff: 15.96mlTrain batch 15/32 - 240.7ms/batch - loss: 30.04086 - diff: 16.79mlTrain batch 16/32 - 241.7ms/batch - loss: 28.92568 - diff: 16.45mlTrain batch 17/32 - 241.4ms/batch - loss: 28.69804 - diff: 16.51mlTrain batch 18/32 - 241.8ms/batch - loss: 27.69069 - diff: 16.18mlTrain batch 19/32 - 241.3ms/batch - loss: 28.61471 - diff: 16.51mlTrain batch 20/32 - 242.2ms/batch - loss: 27.76972 - diff: 16.21mlTrain batch 21/32 - 241.0ms/batch - loss: 26.94960 - diff: 15.86mlTrain batch 22/32 - 241.6ms/batch - loss: 26.43808 - diff: 15.75mlTrain batch 23/32 - 241.2ms/batch - loss: 25.81790 - diff: 15.50mlTrain batch 24/32 - 243.1ms/batch - loss: 25.40807 - diff: 15.42mlTrain batch 25/32 - 241.4ms/batch - loss: 26.34749 - diff: 15.75mlTrain batch 26/32 - 240.2ms/batch - loss: 26.78862 - diff: 15.89mlTrain batch 27/32 - 241.8ms/batch - loss: 26.64261 - diff: 15.85mlTrain batch 28/32 - 241.1ms/batch - loss: 26.28075 - diff: 15.75mlTrain batch 29/32 - 241.6ms/batch - loss: 25.74458 - diff: 15.55mlTrain batch 30/32 - 240.1ms/batch - loss: 25.37600 - diff: 15.49mlTrain batch 31/32 - 241.7ms/batch - loss: 25.72333 - diff: 15.57mlTrain batch 32/32 - 79.7ms/batch - loss: 26.84343 - diff: 15.63mlTrain batch 32/32 - 11.5s 79.7ms/batch - loss: 26.84343 - diff: 15.63ml
Test 1.1s: val_loss: 669.00229 - diff: 94.19ml

Epoch 77: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 240.6ms/batch - loss: 71.80759 - diff: 29.36mlTrain batch 2/32 - 242.5ms/batch - loss: 45.51152 - diff: 22.36mlTrain batch 3/32 - 240.4ms/batch - loss: 34.48743 - diff: 18.65mlTrain batch 4/32 - 241.6ms/batch - loss: 32.14612 - diff: 18.27mlTrain batch 5/32 - 241.1ms/batch - loss: 29.72603 - diff: 17.66mlTrain batch 6/32 - 241.5ms/batch - loss: 26.65775 - diff: 16.67mlTrain batch 7/32 - 241.3ms/batch - loss: 24.60707 - diff: 16.01mlTrain batch 8/32 - 241.7ms/batch - loss: 23.04108 - diff: 15.61mlTrain batch 9/32 - 240.7ms/batch - loss: 22.63756 - diff: 15.65mlTrain batch 10/32 - 241.3ms/batch - loss: 22.73389 - diff: 15.69mlTrain batch 11/32 - 241.4ms/batch - loss: 21.69902 - diff: 15.28mlTrain batch 12/32 - 241.4ms/batch - loss: 20.36044 - diff: 14.67mlTrain batch 13/32 - 240.9ms/batch - loss: 19.54761 - diff: 14.27mlTrain batch 14/32 - 241.4ms/batch - loss: 18.87029 - diff: 13.92mlTrain batch 15/32 - 241.3ms/batch - loss: 18.98058 - diff: 13.90mlTrain batch 16/32 - 241.2ms/batch - loss: 20.15987 - diff: 14.33mlTrain batch 17/32 - 241.2ms/batch - loss: 19.93560 - diff: 14.24mlTrain batch 18/32 - 241.3ms/batch - loss: 20.37706 - diff: 14.41mlTrain batch 19/32 - 241.7ms/batch - loss: 21.44062 - diff: 14.80mlTrain batch 20/32 - 241.2ms/batch - loss: 21.73241 - diff: 14.99mlTrain batch 21/32 - 241.4ms/batch - loss: 21.79655 - diff: 15.05mlTrain batch 22/32 - 241.6ms/batch - loss: 22.46432 - diff: 15.21mlTrain batch 23/32 - 240.9ms/batch - loss: 23.69358 - diff: 15.63mlTrain batch 24/32 - 241.6ms/batch - loss: 24.16843 - diff: 15.86mlTrain batch 25/32 - 240.5ms/batch - loss: 24.04786 - diff: 15.81mlTrain batch 26/32 - 241.7ms/batch - loss: 24.13883 - diff: 15.84mlTrain batch 27/32 - 241.0ms/batch - loss: 24.29136 - diff: 15.90mlTrain batch 28/32 - 241.6ms/batch - loss: 24.15316 - diff: 15.82mlTrain batch 29/32 - 241.4ms/batch - loss: 24.91326 - diff: 16.10mlTrain batch 30/32 - 241.5ms/batch - loss: 25.55107 - diff: 16.32mlTrain batch 31/32 - 240.7ms/batch - loss: 25.29734 - diff: 16.20mlTrain batch 32/32 - 79.3ms/batch - loss: 25.96299 - diff: 16.22mlTrain batch 32/32 - 11.1s 79.3ms/batch - loss: 25.96299 - diff: 16.22ml
Test 1.1s: val_loss: 730.49994 - diff: 98.68ml

Epoch 78: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 240.9ms/batch - loss: 46.53513 - diff: 22.96mlTrain batch 2/32 - 242.1ms/batch - loss: 32.10300 - diff: 18.34mlTrain batch 3/32 - 241.0ms/batch - loss: 31.84442 - diff: 18.31mlTrain batch 4/32 - 241.7ms/batch - loss: 26.14642 - diff: 16.01mlTrain batch 5/32 - 240.4ms/batch - loss: 24.52619 - diff: 14.95mlTrain batch 6/32 - 242.0ms/batch - loss: 23.95616 - diff: 15.17mlTrain batch 7/32 - 240.8ms/batch - loss: 22.26309 - diff: 14.74mlTrain batch 8/32 - 241.6ms/batch - loss: 21.73545 - diff: 14.68mlTrain batch 9/32 - 240.7ms/batch - loss: 22.76116 - diff: 15.11mlTrain batch 10/32 - 241.4ms/batch - loss: 21.36561 - diff: 14.63mlTrain batch 11/32 - 243.8ms/batch - loss: 22.11486 - diff: 15.00mlTrain batch 12/32 - 241.8ms/batch - loss: 21.69257 - diff: 14.78mlTrain batch 13/32 - 240.7ms/batch - loss: 21.19345 - diff: 14.47mlTrain batch 14/32 - 241.5ms/batch - loss: 20.39617 - diff: 14.22mlTrain batch 15/32 - 241.0ms/batch - loss: 19.93276 - diff: 14.06mlTrain batch 16/32 - 242.1ms/batch - loss: 19.46107 - diff: 13.85mlTrain batch 17/32 - 240.9ms/batch - loss: 20.22027 - diff: 14.13mlTrain batch 18/32 - 241.4ms/batch - loss: 21.01487 - diff: 14.39mlTrain batch 19/32 - 240.9ms/batch - loss: 20.69141 - diff: 14.22mlTrain batch 20/32 - 241.7ms/batch - loss: 20.39631 - diff: 14.15mlTrain batch 21/32 - 240.9ms/batch - loss: 20.71736 - diff: 14.31mlTrain batch 22/32 - 241.4ms/batch - loss: 20.92985 - diff: 14.44mlTrain batch 23/32 - 241.5ms/batch - loss: 20.81764 - diff: 14.32mlTrain batch 24/32 - 241.4ms/batch - loss: 22.64223 - diff: 14.97mlTrain batch 25/32 - 241.3ms/batch - loss: 23.11761 - diff: 15.12mlTrain batch 26/32 - 241.5ms/batch - loss: 23.04009 - diff: 15.14mlTrain batch 27/32 - 240.8ms/batch - loss: 22.86970 - diff: 15.11mlTrain batch 28/32 - 242.1ms/batch - loss: 22.52623 - diff: 15.01mlTrain batch 29/32 - 240.5ms/batch - loss: 23.25648 - diff: 15.18mlTrain batch 30/32 - 240.9ms/batch - loss: 26.15237 - diff: 15.95mlTrain batch 31/32 - 240.7ms/batch - loss: 25.86327 - diff: 15.86mlTrain batch 32/32 - 79.1ms/batch - loss: 27.65739 - diff: 15.97mlTrain batch 32/32 - 11.9s 79.1ms/batch - loss: 27.65739 - diff: 15.97ml
Test 1.1s: val_loss: 800.05920 - diff: 104.23ml

Epoch 79: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 240.9ms/batch - loss: 14.58456 - diff: 10.47mlTrain batch 2/32 - 241.7ms/batch - loss: 20.47996 - diff: 13.43mlTrain batch 3/32 - 241.2ms/batch - loss: 17.03313 - diff: 12.46mlTrain batch 4/32 - 241.7ms/batch - loss: 18.00075 - diff: 13.00mlTrain batch 5/32 - 240.4ms/batch - loss: 19.02107 - diff: 13.28mlTrain batch 6/32 - 241.2ms/batch - loss: 19.92109 - diff: 13.91mlTrain batch 7/32 - 240.4ms/batch - loss: 28.83289 - diff: 16.71mlTrain batch 8/32 - 241.5ms/batch - loss: 37.55848 - diff: 18.91mlTrain batch 9/32 - 240.5ms/batch - loss: 36.06981 - diff: 18.44mlTrain batch 10/32 - 241.7ms/batch - loss: 34.29580 - diff: 18.04mlTrain batch 11/32 - 241.0ms/batch - loss: 33.64189 - diff: 17.88mlTrain batch 12/32 - 241.8ms/batch - loss: 33.03775 - diff: 17.79mlTrain batch 13/32 - 240.7ms/batch - loss: 32.18676 - diff: 17.61mlTrain batch 14/32 - 241.1ms/batch - loss: 31.43095 - diff: 17.40mlTrain batch 15/32 - 241.2ms/batch - loss: 30.87091 - diff: 17.22mlTrain batch 16/32 - 241.5ms/batch - loss: 30.77489 - diff: 17.31mlTrain batch 17/32 - 240.6ms/batch - loss: 30.44982 - diff: 17.30mlTrain batch 18/32 - 242.0ms/batch - loss: 29.68082 - diff: 17.07mlTrain batch 19/32 - 240.2ms/batch - loss: 30.51595 - diff: 17.44mlTrain batch 20/32 - 241.4ms/batch - loss: 32.58779 - diff: 17.89mlTrain batch 21/32 - 240.6ms/batch - loss: 32.26135 - diff: 17.89mlTrain batch 22/32 - 241.4ms/batch - loss: 33.11712 - diff: 18.20mlTrain batch 23/32 - 240.3ms/batch - loss: 32.97249 - diff: 18.23mlTrain batch 24/32 - 241.3ms/batch - loss: 34.44809 - diff: 18.74mlTrain batch 25/32 - 241.0ms/batch - loss: 33.57697 - diff: 18.44mlTrain batch 26/32 - 241.3ms/batch - loss: 32.77788 - diff: 18.21mlTrain batch 27/32 - 240.8ms/batch - loss: 32.17990 - diff: 18.03mlTrain batch 28/32 - 242.0ms/batch - loss: 31.95897 - diff: 18.01mlTrain batch 29/32 - 241.0ms/batch - loss: 31.89035 - diff: 17.97mlTrain batch 30/32 - 240.5ms/batch - loss: 32.15028 - diff: 18.09mlTrain batch 31/32 - 241.5ms/batch - loss: 33.36490 - diff: 18.42mlTrain batch 32/32 - 79.7ms/batch - loss: 35.84416 - diff: 18.55mlTrain batch 32/32 - 11.9s 79.7ms/batch - loss: 35.84416 - diff: 18.55ml
Test 1.1s: val_loss: 635.57427 - diff: 92.48ml

Epoch 80: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 240.2ms/batch - loss: 94.39966 - diff: 34.63mlTrain batch 2/32 - 241.1ms/batch - loss: 52.24967 - diff: 22.99mlTrain batch 3/32 - 240.8ms/batch - loss: 38.81403 - diff: 18.97mlTrain batch 4/32 - 241.5ms/batch - loss: 44.63898 - diff: 20.73mlTrain batch 5/32 - 240.6ms/batch - loss: 50.43049 - diff: 22.90mlTrain batch 6/32 - 241.6ms/batch - loss: 46.42838 - diff: 22.12mlTrain batch 7/32 - 240.2ms/batch - loss: 41.48059 - diff: 20.64mlTrain batch 8/32 - 241.4ms/batch - loss: 49.19026 - diff: 22.39mlTrain batch 9/32 - 240.4ms/batch - loss: 50.51472 - diff: 22.97mlTrain batch 10/32 - 242.1ms/batch - loss: 46.35298 - diff: 21.60mlTrain batch 11/32 - 240.7ms/batch - loss: 45.46182 - diff: 21.46mlTrain batch 12/32 - 241.5ms/batch - loss: 42.90015 - diff: 20.71mlTrain batch 13/32 - 240.6ms/batch - loss: 41.44919 - diff: 20.28mlTrain batch 14/32 - 241.6ms/batch - loss: 39.56588 - diff: 19.81mlTrain batch 15/32 - 240.2ms/batch - loss: 37.91571 - diff: 19.34mlTrain batch 16/32 - 241.3ms/batch - loss: 36.88688 - diff: 19.03mlTrain batch 17/32 - 240.7ms/batch - loss: 35.28623 - diff: 18.49mlTrain batch 18/32 - 241.5ms/batch - loss: 35.14310 - diff: 18.60mlTrain batch 19/32 - 240.7ms/batch - loss: 34.58338 - diff: 18.46mlTrain batch 20/32 - 241.6ms/batch - loss: 33.23349 - diff: 17.97mlTrain batch 21/32 - 240.9ms/batch - loss: 32.75198 - diff: 17.72mlTrain batch 22/32 - 241.4ms/batch - loss: 32.12359 - diff: 17.61mlTrain batch 23/32 - 240.8ms/batch - loss: 31.46626 - diff: 17.45mlTrain batch 24/32 - 240.5ms/batch - loss: 31.54223 - diff: 17.57mlTrain batch 25/32 - 241.8ms/batch - loss: 31.00309 - diff: 17.42mlTrain batch 26/32 - 240.6ms/batch - loss: 30.60289 - diff: 17.37mlTrain batch 27/32 - 241.6ms/batch - loss: 30.59487 - diff: 17.38mlTrain batch 28/32 - 240.2ms/batch - loss: 30.10022 - diff: 17.25mlTrain batch 29/32 - 241.7ms/batch - loss: 29.31957 - diff: 16.95mlTrain batch 30/32 - 240.2ms/batch - loss: 28.90370 - diff: 16.78mlTrain batch 31/32 - 241.7ms/batch - loss: 29.36134 - diff: 16.93mlTrain batch 32/32 - 79.5ms/batch - loss: 30.63840 - diff: 16.95mlTrain batch 32/32 - 12.7s 79.5ms/batch - loss: 30.63840 - diff: 16.95ml
Test 1.1s: val_loss: 787.00772 - diff: 103.91ml

Epoch 81: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 240.3ms/batch - loss: 13.32168 - diff: 12.02mlTrain batch 2/32 - 241.1ms/batch - loss: 25.22077 - diff: 15.94mlTrain batch 3/32 - 240.2ms/batch - loss: 26.92012 - diff: 17.11mlTrain batch 4/32 - 241.2ms/batch - loss: 29.70233 - diff: 18.13mlTrain batch 5/32 - 240.5ms/batch - loss: 26.67498 - diff: 16.87mlTrain batch 6/32 - 241.8ms/batch - loss: 32.85874 - diff: 18.13mlTrain batch 7/32 - 241.1ms/batch - loss: 30.70089 - diff: 17.53mlTrain batch 8/32 - 241.5ms/batch - loss: 30.68424 - diff: 17.72mlTrain batch 9/32 - 247.3ms/batch - loss: 28.69279 - diff: 17.13mlTrain batch 10/32 - 241.7ms/batch - loss: 28.66331 - diff: 17.15mlTrain batch 11/32 - 240.5ms/batch - loss: 27.86498 - diff: 17.05mlTrain batch 12/32 - 241.4ms/batch - loss: 26.26126 - diff: 16.38mlTrain batch 13/32 - 241.0ms/batch - loss: 25.21477 - diff: 16.07mlTrain batch 14/32 - 241.6ms/batch - loss: 24.62516 - diff: 16.00mlTrain batch 15/32 - 241.1ms/batch - loss: 31.16456 - diff: 17.71mlTrain batch 16/32 - 241.9ms/batch - loss: 32.96415 - diff: 18.33mlTrain batch 17/32 - 241.2ms/batch - loss: 33.45937 - diff: 18.47mlTrain batch 18/32 - 241.9ms/batch - loss: 34.44495 - diff: 18.95mlTrain batch 19/32 - 240.7ms/batch - loss: 33.15268 - diff: 18.49mlTrain batch 20/32 - 241.5ms/batch - loss: 32.93462 - diff: 18.46mlTrain batch 21/32 - 240.2ms/batch - loss: 33.30778 - diff: 18.57mlTrain batch 22/32 - 241.6ms/batch - loss: 33.26161 - diff: 18.52mlTrain batch 23/32 - 240.8ms/batch - loss: 33.60383 - diff: 18.59mlTrain batch 24/32 - 241.5ms/batch - loss: 32.86383 - diff: 18.32mlTrain batch 25/32 - 240.5ms/batch - loss: 32.36755 - diff: 18.15mlTrain batch 26/32 - 241.2ms/batch - loss: 31.83321 - diff: 17.94mlTrain batch 27/32 - 241.1ms/batch - loss: 32.13825 - diff: 18.00mlTrain batch 28/32 - 242.2ms/batch - loss: 31.89129 - diff: 17.95mlTrain batch 29/32 - 240.9ms/batch - loss: 31.36350 - diff: 17.76mlTrain batch 30/32 - 241.3ms/batch - loss: 30.92051 - diff: 17.65mlTrain batch 31/32 - 240.8ms/batch - loss: 31.27060 - diff: 17.79mlTrain batch 32/32 - 78.3ms/batch - loss: 31.33663 - diff: 17.72mlTrain batch 32/32 - 11.5s 78.3ms/batch - loss: 31.33663 - diff: 17.72ml
Test 1.2s: val_loss: 667.33758 - diff: 94.64ml

Epoch 82: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 241.0ms/batch - loss: 20.79218 - diff: 12.12mlTrain batch 2/32 - 241.8ms/batch - loss: 19.52971 - diff: 13.28mlTrain batch 3/32 - 240.5ms/batch - loss: 20.03138 - diff: 13.63mlTrain batch 4/32 - 241.4ms/batch - loss: 19.81449 - diff: 14.08mlTrain batch 5/32 - 240.7ms/batch - loss: 18.78336 - diff: 13.77mlTrain batch 6/32 - 241.7ms/batch - loss: 19.38630 - diff: 14.10mlTrain batch 7/32 - 240.8ms/batch - loss: 20.27710 - diff: 14.38mlTrain batch 8/32 - 241.1ms/batch - loss: 19.27332 - diff: 13.96mlTrain batch 9/32 - 240.6ms/batch - loss: 19.44220 - diff: 14.00mlTrain batch 10/32 - 241.8ms/batch - loss: 19.76124 - diff: 14.02mlTrain batch 11/32 - 240.4ms/batch - loss: 21.27688 - diff: 14.62mlTrain batch 12/32 - 241.6ms/batch - loss: 20.15843 - diff: 14.13mlTrain batch 13/32 - 240.5ms/batch - loss: 20.43257 - diff: 14.27mlTrain batch 14/32 - 241.3ms/batch - loss: 20.20513 - diff: 14.32mlTrain batch 15/32 - 240.4ms/batch - loss: 21.38770 - diff: 14.68mlTrain batch 16/32 - 241.4ms/batch - loss: 22.81025 - diff: 15.14mlTrain batch 17/32 - 241.0ms/batch - loss: 22.99727 - diff: 15.24mlTrain batch 18/32 - 241.6ms/batch - loss: 22.53910 - diff: 15.01mlTrain batch 19/32 - 240.7ms/batch - loss: 25.99604 - diff: 16.03mlTrain batch 20/32 - 241.2ms/batch - loss: 25.39117 - diff: 15.85mlTrain batch 21/32 - 240.9ms/batch - loss: 25.27232 - diff: 15.87mlTrain batch 22/32 - 240.7ms/batch - loss: 25.05934 - diff: 15.79mlTrain batch 23/32 - 241.2ms/batch - loss: 26.39830 - diff: 16.26mlTrain batch 24/32 - 241.0ms/batch - loss: 26.23455 - diff: 16.19mlTrain batch 25/32 - 241.5ms/batch - loss: 26.92866 - diff: 16.49mlTrain batch 26/32 - 241.3ms/batch - loss: 26.76541 - diff: 16.38mlTrain batch 27/32 - 240.9ms/batch - loss: 26.22132 - diff: 16.13mlTrain batch 28/32 - 241.3ms/batch - loss: 26.36248 - diff: 16.23mlTrain batch 29/32 - 241.0ms/batch - loss: 25.94611 - diff: 16.09mlTrain batch 30/32 - 243.0ms/batch - loss: 25.66301 - diff: 16.03mlTrain batch 31/32 - 241.5ms/batch - loss: 25.90537 - diff: 16.12mlTrain batch 32/32 - 79.5ms/batch - loss: 27.15499 - diff: 16.19mlTrain batch 32/32 - 11.2s 79.5ms/batch - loss: 27.15499 - diff: 16.19ml
Test 1.1s: val_loss: 573.90299 - diff: 87.80ml

Epoch 83: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 240.6ms/batch - loss: 16.10128 - diff: 13.86mlTrain batch 2/32 - 241.2ms/batch - loss: 15.99348 - diff: 12.80mlTrain batch 3/32 - 240.3ms/batch - loss: 22.35088 - diff: 15.01mlTrain batch 4/32 - 241.8ms/batch - loss: 21.83161 - diff: 14.84mlTrain batch 5/32 - 240.4ms/batch - loss: 20.26950 - diff: 14.44mlTrain batch 6/32 - 241.2ms/batch - loss: 22.17140 - diff: 15.06mlTrain batch 7/32 - 241.2ms/batch - loss: 21.43883 - diff: 15.08mlTrain batch 8/32 - 241.0ms/batch - loss: 27.01707 - diff: 16.71mlTrain batch 9/32 - 241.3ms/batch - loss: 28.00662 - diff: 17.18mlTrain batch 10/32 - 240.7ms/batch - loss: 26.71208 - diff: 16.65mlTrain batch 11/32 - 241.6ms/batch - loss: 25.76311 - diff: 16.29mlTrain batch 12/32 - 241.2ms/batch - loss: 25.90582 - diff: 16.35mlTrain batch 13/32 - 241.8ms/batch - loss: 24.93615 - diff: 15.94mlTrain batch 14/32 - 240.4ms/batch - loss: 24.00698 - diff: 15.64mlTrain batch 15/32 - 241.2ms/batch - loss: 24.53642 - diff: 15.89mlTrain batch 16/32 - 240.7ms/batch - loss: 23.94179 - diff: 15.63mlTrain batch 17/32 - 242.0ms/batch - loss: 23.08685 - diff: 15.27mlTrain batch 18/32 - 240.9ms/batch - loss: 22.76669 - diff: 15.19mlTrain batch 19/32 - 242.4ms/batch - loss: 24.23911 - diff: 15.53mlTrain batch 20/32 - 240.6ms/batch - loss: 32.27335 - diff: 16.98mlTrain batch 21/32 - 241.9ms/batch - loss: 31.85903 - diff: 16.98mlTrain batch 22/32 - 240.7ms/batch - loss: 31.21407 - diff: 16.86mlTrain batch 23/32 - 241.9ms/batch - loss: 30.52795 - diff: 16.68mlTrain batch 24/32 - 240.8ms/batch - loss: 30.78064 - diff: 16.75mlTrain batch 25/32 - 241.6ms/batch - loss: 30.62265 - diff: 16.74mlTrain batch 26/32 - 240.6ms/batch - loss: 30.27586 - diff: 16.61mlTrain batch 27/32 - 241.5ms/batch - loss: 30.28354 - diff: 16.73mlTrain batch 28/32 - 241.0ms/batch - loss: 29.70445 - diff: 16.58mlTrain batch 29/32 - 241.7ms/batch - loss: 29.25455 - diff: 16.47mlTrain batch 30/32 - 240.7ms/batch - loss: 28.75907 - diff: 16.31mlTrain batch 31/32 - 242.1ms/batch - loss: 28.59783 - diff: 16.32mlTrain batch 32/32 - 79.6ms/batch - loss: 34.05164 - diff: 16.59mlTrain batch 32/32 - 11.8s 79.6ms/batch - loss: 34.05164 - diff: 16.59ml
Test 1.1s: val_loss: 857.66917 - diff: 107.40ml
Epoch    84: reducing learning rate of group 0 to 7.8125e-06.

Epoch 84: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 240.5ms/batch - loss: 50.04733 - diff: 25.30mlTrain batch 2/32 - 241.3ms/batch - loss: 43.40900 - diff: 23.65mlTrain batch 3/32 - 240.3ms/batch - loss: 34.83159 - diff: 20.14mlTrain batch 4/32 - 241.6ms/batch - loss: 36.57995 - diff: 20.69mlTrain batch 5/32 - 240.5ms/batch - loss: 33.40070 - diff: 18.72mlTrain batch 6/32 - 241.5ms/batch - loss: 29.48877 - diff: 17.48mlTrain batch 7/32 - 240.5ms/batch - loss: 27.43569 - diff: 16.92mlTrain batch 8/32 - 241.4ms/batch - loss: 26.60617 - diff: 16.70mlTrain batch 9/32 - 241.1ms/batch - loss: 31.38354 - diff: 18.23mlTrain batch 10/32 - 241.4ms/batch - loss: 33.37371 - diff: 18.88mlTrain batch 11/32 - 240.7ms/batch - loss: 33.81474 - diff: 19.02mlTrain batch 12/32 - 241.3ms/batch - loss: 32.22691 - diff: 18.39mlTrain batch 13/32 - 240.4ms/batch - loss: 30.39758 - diff: 17.71mlTrain batch 14/32 - 241.7ms/batch - loss: 29.32305 - diff: 17.39mlTrain batch 15/32 - 240.4ms/batch - loss: 28.31608 - diff: 17.13mlTrain batch 16/32 - 241.5ms/batch - loss: 27.64724 - diff: 16.96mlTrain batch 17/32 - 240.9ms/batch - loss: 27.12154 - diff: 16.75mlTrain batch 18/32 - 241.1ms/batch - loss: 28.62791 - diff: 17.26mlTrain batch 19/32 - 240.8ms/batch - loss: 28.78006 - diff: 17.42mlTrain batch 20/32 - 246.4ms/batch - loss: 27.93182 - diff: 17.11mlTrain batch 21/32 - 241.1ms/batch - loss: 27.62320 - diff: 16.98mlTrain batch 22/32 - 244.3ms/batch - loss: 26.75267 - diff: 16.59mlTrain batch 23/32 - 240.8ms/batch - loss: 26.11898 - diff: 16.38mlTrain batch 24/32 - 241.6ms/batch - loss: 25.65036 - diff: 16.23mlTrain batch 25/32 - 240.6ms/batch - loss: 25.25302 - diff: 16.00mlTrain batch 26/32 - 241.1ms/batch - loss: 27.01528 - diff: 16.51mlTrain batch 27/32 - 240.8ms/batch - loss: 26.44759 - diff: 16.30mlTrain batch 28/32 - 241.0ms/batch - loss: 25.93051 - diff: 16.12mlTrain batch 29/32 - 240.9ms/batch - loss: 25.36734 - diff: 15.92mlTrain batch 30/32 - 241.0ms/batch - loss: 26.64135 - diff: 16.29mlTrain batch 31/32 - 241.1ms/batch - loss: 26.43595 - diff: 16.25mlTrain batch 32/32 - 79.2ms/batch - loss: 37.94681 - diff: 16.72mlTrain batch 32/32 - 11.8s 79.2ms/batch - loss: 37.94681 - diff: 16.72ml
Test 1.1s: val_loss: 986.56571 - diff: 117.18ml

Epoch 85: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 240.8ms/batch - loss: 13.24016 - diff: 12.43mlTrain batch 2/32 - 241.3ms/batch - loss: 25.17851 - diff: 16.88mlTrain batch 3/32 - 240.5ms/batch - loss: 28.81337 - diff: 17.62mlTrain batch 4/32 - 241.7ms/batch - loss: 23.42176 - diff: 15.35mlTrain batch 5/32 - 240.7ms/batch - loss: 26.04791 - diff: 16.49mlTrain batch 6/32 - 241.5ms/batch - loss: 23.07305 - diff: 15.35mlTrain batch 7/32 - 240.8ms/batch - loss: 21.44638 - diff: 14.62mlTrain batch 8/32 - 241.6ms/batch - loss: 23.40951 - diff: 15.28mlTrain batch 9/32 - 240.7ms/batch - loss: 24.95940 - diff: 15.28mlTrain batch 10/32 - 242.0ms/batch - loss: 24.76465 - diff: 15.36mlTrain batch 11/32 - 240.3ms/batch - loss: 23.30273 - diff: 14.83mlTrain batch 12/32 - 241.0ms/batch - loss: 22.27303 - diff: 14.45mlTrain batch 13/32 - 241.1ms/batch - loss: 22.85301 - diff: 14.75mlTrain batch 14/32 - 241.7ms/batch - loss: 23.16512 - diff: 14.79mlTrain batch 15/32 - 241.0ms/batch - loss: 22.59266 - diff: 14.61mlTrain batch 16/32 - 241.9ms/batch - loss: 22.03840 - diff: 14.52mlTrain batch 17/32 - 240.6ms/batch - loss: 21.69424 - diff: 14.47mlTrain batch 18/32 - 241.1ms/batch - loss: 20.97299 - diff: 14.20mlTrain batch 19/32 - 240.8ms/batch - loss: 20.89417 - diff: 14.22mlTrain batch 20/32 - 242.4ms/batch - loss: 21.35623 - diff: 14.40mlTrain batch 21/32 - 240.6ms/batch - loss: 21.48693 - diff: 14.40mlTrain batch 22/32 - 241.5ms/batch - loss: 21.83477 - diff: 14.48mlTrain batch 23/32 - 240.4ms/batch - loss: 21.45391 - diff: 14.42mlTrain batch 24/32 - 241.8ms/batch - loss: 20.89471 - diff: 14.20mlTrain batch 25/32 - 240.8ms/batch - loss: 20.77488 - diff: 14.21mlTrain batch 26/32 - 241.9ms/batch - loss: 20.60401 - diff: 14.08mlTrain batch 27/32 - 240.3ms/batch - loss: 20.54004 - diff: 14.05mlTrain batch 28/32 - 241.1ms/batch - loss: 21.48138 - diff: 14.44mlTrain batch 29/32 - 240.4ms/batch - loss: 21.19490 - diff: 14.31mlTrain batch 30/32 - 242.2ms/batch - loss: 20.79972 - diff: 14.18mlTrain batch 31/32 - 240.6ms/batch - loss: 21.36390 - diff: 14.38mlTrain batch 32/32 - 79.0ms/batch - loss: 21.67292 - diff: 14.37mlTrain batch 32/32 - 11.8s 79.0ms/batch - loss: 21.67292 - diff: 14.37ml
Test 1.1s: val_loss: 869.97919 - diff: 109.96ml

Epoch 86: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 240.9ms/batch - loss: 28.66674 - diff: 17.84mlTrain batch 2/32 - 241.7ms/batch - loss: 23.15333 - diff: 15.95mlTrain batch 3/32 - 240.5ms/batch - loss: 25.18534 - diff: 16.58mlTrain batch 4/32 - 241.5ms/batch - loss: 21.05557 - diff: 15.08mlTrain batch 5/32 - 240.6ms/batch - loss: 19.48991 - diff: 14.67mlTrain batch 6/32 - 241.8ms/batch - loss: 18.77060 - diff: 14.49mlTrain batch 7/32 - 241.2ms/batch - loss: 19.09299 - diff: 14.56mlTrain batch 8/32 - 242.0ms/batch - loss: 18.17258 - diff: 14.01mlTrain batch 9/32 - 240.8ms/batch - loss: 19.21917 - diff: 14.36mlTrain batch 10/32 - 241.7ms/batch - loss: 18.69387 - diff: 14.11mlTrain batch 11/32 - 241.1ms/batch - loss: 19.25645 - diff: 14.45mlTrain batch 12/32 - 241.4ms/batch - loss: 18.28221 - diff: 13.94mlTrain batch 13/32 - 240.4ms/batch - loss: 19.67788 - diff: 14.06mlTrain batch 14/32 - 241.0ms/batch - loss: 30.13769 - diff: 16.42mlTrain batch 15/32 - 240.8ms/batch - loss: 30.09117 - diff: 16.44mlTrain batch 16/32 - 241.5ms/batch - loss: 28.99051 - diff: 16.18mlTrain batch 17/32 - 240.3ms/batch - loss: 27.68292 - diff: 15.74mlTrain batch 18/32 - 241.6ms/batch - loss: 26.87173 - diff: 15.53mlTrain batch 19/32 - 240.5ms/batch - loss: 26.46329 - diff: 15.43mlTrain batch 20/32 - 241.0ms/batch - loss: 26.67241 - diff: 15.42mlTrain batch 21/32 - 241.1ms/batch - loss: 26.68377 - diff: 15.51mlTrain batch 22/32 - 241.0ms/batch - loss: 26.66706 - diff: 15.53mlTrain batch 23/32 - 241.3ms/batch - loss: 26.46569 - diff: 15.50mlTrain batch 24/32 - 241.0ms/batch - loss: 26.11138 - diff: 15.46mlTrain batch 25/32 - 241.7ms/batch - loss: 25.86409 - diff: 15.44mlTrain batch 26/32 - 241.1ms/batch - loss: 25.43701 - diff: 15.27mlTrain batch 27/32 - 241.7ms/batch - loss: 25.01528 - diff: 15.15mlTrain batch 28/32 - 241.0ms/batch - loss: 24.96886 - diff: 15.20mlTrain batch 29/32 - 240.9ms/batch - loss: 24.57653 - diff: 15.04mlTrain batch 30/32 - 240.7ms/batch - loss: 24.30298 - diff: 15.00mlTrain batch 31/32 - 241.8ms/batch - loss: 24.41457 - diff: 15.08mlTrain batch 32/32 - 79.6ms/batch - loss: 25.93084 - diff: 15.16mlTrain batch 32/32 - 11.1s 79.6ms/batch - loss: 25.93084 - diff: 15.16ml
Test 1.1s: val_loss: 765.05111 - diff: 101.07ml

Epoch 87: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 240.5ms/batch - loss: 9.38266 - diff: 8.44mlTrain batch 2/32 - 241.6ms/batch - loss: 9.74991 - diff: 9.58mlTrain batch 3/32 - 240.5ms/batch - loss: 23.07521 - diff: 13.56mlTrain batch 4/32 - 240.8ms/batch - loss: 22.58053 - diff: 13.94mlTrain batch 5/32 - 241.1ms/batch - loss: 19.74070 - diff: 13.02mlTrain batch 6/32 - 241.0ms/batch - loss: 18.83878 - diff: 12.89mlTrain batch 7/32 - 241.0ms/batch - loss: 19.05958 - diff: 12.96mlTrain batch 8/32 - 240.4ms/batch - loss: 19.09474 - diff: 13.15mlTrain batch 9/32 - 241.5ms/batch - loss: 19.50363 - diff: 13.49mlTrain batch 10/32 - 240.5ms/batch - loss: 18.52831 - diff: 13.08mlTrain batch 11/32 - 241.9ms/batch - loss: 18.61024 - diff: 13.18mlTrain batch 12/32 - 241.2ms/batch - loss: 20.42583 - diff: 13.79mlTrain batch 13/32 - 242.0ms/batch - loss: 20.25495 - diff: 13.74mlTrain batch 14/32 - 240.9ms/batch - loss: 20.49908 - diff: 13.81mlTrain batch 15/32 - 241.7ms/batch - loss: 20.44927 - diff: 13.89mlTrain batch 16/32 - 240.9ms/batch - loss: 19.56921 - diff: 13.52mlTrain batch 17/32 - 241.0ms/batch - loss: 21.92309 - diff: 14.35mlTrain batch 18/32 - 240.9ms/batch - loss: 22.75716 - diff: 14.66mlTrain batch 19/32 - 241.9ms/batch - loss: 23.41800 - diff: 14.94mlTrain batch 20/32 - 240.8ms/batch - loss: 22.85709 - diff: 14.82mlTrain batch 21/32 - 241.3ms/batch - loss: 23.23697 - diff: 15.01mlTrain batch 22/32 - 240.2ms/batch - loss: 22.54261 - diff: 14.74mlTrain batch 23/32 - 241.6ms/batch - loss: 22.47308 - diff: 14.72mlTrain batch 24/32 - 240.8ms/batch - loss: 22.31666 - diff: 14.69mlTrain batch 25/32 - 241.5ms/batch - loss: 22.30664 - diff: 14.72mlTrain batch 26/32 - 241.0ms/batch - loss: 22.13421 - diff: 14.62mlTrain batch 27/32 - 241.6ms/batch - loss: 23.44258 - diff: 15.00mlTrain batch 28/32 - 240.8ms/batch - loss: 23.79032 - diff: 15.20mlTrain batch 29/32 - 241.6ms/batch - loss: 23.33936 - diff: 15.04mlTrain batch 30/32 - 241.2ms/batch - loss: 23.10606 - diff: 14.97mlTrain batch 31/32 - 242.1ms/batch - loss: 24.02576 - diff: 15.22mlTrain batch 32/32 - 79.6ms/batch - loss: 24.31901 - diff: 15.22mlTrain batch 32/32 - 11.4s 79.6ms/batch - loss: 24.31901 - diff: 15.22ml
Test 1.1s: val_loss: 565.51191 - diff: 86.20ml

Epoch 88: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 240.4ms/batch - loss: 15.09714 - diff: 11.52mlTrain batch 2/32 - 241.5ms/batch - loss: 18.06534 - diff: 13.68mlTrain batch 3/32 - 240.8ms/batch - loss: 27.41466 - diff: 16.66mlTrain batch 4/32 - 241.7ms/batch - loss: 24.59297 - diff: 15.79mlTrain batch 5/32 - 241.1ms/batch - loss: 21.96226 - diff: 14.84mlTrain batch 6/32 - 241.7ms/batch - loss: 21.72402 - diff: 14.74mlTrain batch 7/32 - 241.0ms/batch - loss: 21.00310 - diff: 14.66mlTrain batch 8/32 - 241.9ms/batch - loss: 22.52502 - diff: 15.22mlTrain batch 9/32 - 241.1ms/batch - loss: 21.22362 - diff: 14.67mlTrain batch 10/32 - 241.3ms/batch - loss: 24.91477 - diff: 15.77mlTrain batch 11/32 - 240.8ms/batch - loss: 26.97411 - diff: 16.05mlTrain batch 12/32 - 241.9ms/batch - loss: 28.02410 - diff: 16.37mlTrain batch 13/32 - 241.0ms/batch - loss: 27.08261 - diff: 16.16mlTrain batch 14/32 - 241.1ms/batch - loss: 28.04733 - diff: 16.59mlTrain batch 15/32 - 241.3ms/batch - loss: 28.12838 - diff: 16.66mlTrain batch 16/32 - 242.4ms/batch - loss: 27.39584 - diff: 16.48mlTrain batch 17/32 - 240.6ms/batch - loss: 26.34019 - diff: 16.11mlTrain batch 18/32 - 241.5ms/batch - loss: 25.34797 - diff: 15.74mlTrain batch 19/32 - 240.2ms/batch - loss: 24.81051 - diff: 15.56mlTrain batch 20/32 - 241.4ms/batch - loss: 25.68589 - diff: 15.78mlTrain batch 21/32 - 240.8ms/batch - loss: 25.13093 - diff: 15.58mlTrain batch 22/32 - 241.6ms/batch - loss: 25.78148 - diff: 15.80mlTrain batch 23/32 - 240.7ms/batch - loss: 28.53005 - diff: 16.64mlTrain batch 24/32 - 241.0ms/batch - loss: 28.98350 - diff: 16.81mlTrain batch 25/32 - 240.6ms/batch - loss: 31.61983 - diff: 17.51mlTrain batch 26/32 - 241.3ms/batch - loss: 31.50041 - diff: 17.58mlTrain batch 27/32 - 240.3ms/batch - loss: 31.04039 - diff: 17.43mlTrain batch 28/32 - 241.7ms/batch - loss: 30.27705 - diff: 17.17mlTrain batch 29/32 - 240.8ms/batch - loss: 29.87510 - diff: 17.09mlTrain batch 30/32 - 241.1ms/batch - loss: 29.59883 - diff: 17.02mlTrain batch 31/32 - 240.4ms/batch - loss: 30.25924 - diff: 17.12mlTrain batch 32/32 - 79.2ms/batch - loss: 30.35709 - diff: 17.07mlTrain batch 32/32 - 12.0s 79.2ms/batch - loss: 30.35709 - diff: 17.07ml
Test 1.1s: val_loss: 782.00118 - diff: 101.91ml

Epoch 89: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 240.2ms/batch - loss: 17.88165 - diff: 14.52mlTrain batch 2/32 - 241.8ms/batch - loss: 15.94933 - diff: 13.14mlTrain batch 3/32 - 240.9ms/batch - loss: 16.02585 - diff: 12.82mlTrain batch 4/32 - 241.3ms/batch - loss: 16.14379 - diff: 13.18mlTrain batch 5/32 - 240.5ms/batch - loss: 26.52802 - diff: 16.26mlTrain batch 6/32 - 241.6ms/batch - loss: 28.30797 - diff: 16.69mlTrain batch 7/32 - 240.4ms/batch - loss: 28.12789 - diff: 16.80mlTrain batch 8/32 - 241.4ms/batch - loss: 28.43589 - diff: 16.77mlTrain batch 9/32 - 240.4ms/batch - loss: 27.35048 - diff: 16.60mlTrain batch 10/32 - 241.1ms/batch - loss: 26.84090 - diff: 16.55mlTrain batch 11/32 - 240.9ms/batch - loss: 25.28151 - diff: 16.00mlTrain batch 12/32 - 242.0ms/batch - loss: 24.50944 - diff: 15.66mlTrain batch 13/32 - 240.7ms/batch - loss: 24.19098 - diff: 15.55mlTrain batch 14/32 - 241.3ms/batch - loss: 26.28517 - diff: 16.32mlTrain batch 15/32 - 240.3ms/batch - loss: 31.03198 - diff: 17.70mlTrain batch 16/32 - 241.7ms/batch - loss: 32.35832 - diff: 18.19mlTrain batch 17/32 - 241.0ms/batch - loss: 32.26080 - diff: 18.22mlTrain batch 18/32 - 242.0ms/batch - loss: 31.44737 - diff: 17.92mlTrain batch 19/32 - 240.5ms/batch - loss: 30.10545 - diff: 17.38mlTrain batch 20/32 - 241.7ms/batch - loss: 29.85859 - diff: 17.33mlTrain batch 21/32 - 241.0ms/batch - loss: 29.67223 - diff: 17.30mlTrain batch 22/32 - 242.0ms/batch - loss: 35.33952 - diff: 18.63mlTrain batch 23/32 - 241.1ms/batch - loss: 34.37594 - diff: 18.25mlTrain batch 24/32 - 241.7ms/batch - loss: 33.61635 - diff: 17.97mlTrain batch 25/32 - 240.6ms/batch - loss: 34.51459 - diff: 18.20mlTrain batch 26/32 - 241.5ms/batch - loss: 34.83317 - diff: 18.34mlTrain batch 27/32 - 240.3ms/batch - loss: 34.23700 - diff: 18.15mlTrain batch 28/32 - 241.8ms/batch - loss: 33.58463 - diff: 18.00mlTrain batch 29/32 - 240.8ms/batch - loss: 33.08418 - diff: 17.89mlTrain batch 30/32 - 241.8ms/batch - loss: 33.41695 - diff: 18.09mlTrain batch 31/32 - 240.5ms/batch - loss: 33.44948 - diff: 18.19mlTrain batch 32/32 - 78.9ms/batch - loss: 36.64995 - diff: 18.35mlTrain batch 32/32 - 11.5s 78.9ms/batch - loss: 36.64995 - diff: 18.35ml
Test 1.2s: val_loss: 787.00909 - diff: 103.70ml

Epoch 90: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 240.3ms/batch - loss: 9.56975 - diff: 10.15mlTrain batch 2/32 - 241.3ms/batch - loss: 15.04892 - diff: 12.44mlTrain batch 3/32 - 240.6ms/batch - loss: 16.21148 - diff: 13.18mlTrain batch 4/32 - 241.4ms/batch - loss: 14.63066 - diff: 12.27mlTrain batch 5/32 - 240.5ms/batch - loss: 20.61287 - diff: 14.14mlTrain batch 6/32 - 241.1ms/batch - loss: 21.69766 - diff: 14.86mlTrain batch 7/32 - 240.3ms/batch - loss: 29.77196 - diff: 16.48mlTrain batch 8/32 - 240.4ms/batch - loss: 27.46418 - diff: 15.69mlTrain batch 9/32 - 241.3ms/batch - loss: 25.83603 - diff: 15.08mlTrain batch 10/32 - 241.1ms/batch - loss: 25.75110 - diff: 15.39mlTrain batch 11/32 - 241.5ms/batch - loss: 27.83453 - diff: 16.10mlTrain batch 12/32 - 240.4ms/batch - loss: 27.69251 - diff: 16.16mlTrain batch 13/32 - 241.1ms/batch - loss: 27.12665 - diff: 16.01mlTrain batch 14/32 - 240.5ms/batch - loss: 26.00888 - diff: 15.71mlTrain batch 15/32 - 240.8ms/batch - loss: 28.36508 - diff: 16.39mlTrain batch 16/32 - 240.5ms/batch - loss: 35.02372 - diff: 17.75mlTrain batch 17/32 - 241.4ms/batch - loss: 33.66886 - diff: 17.43mlTrain batch 18/32 - 242.9ms/batch - loss: 32.29079 - diff: 16.98mlTrain batch 19/32 - 241.5ms/batch - loss: 31.53626 - diff: 16.80mlTrain batch 20/32 - 241.0ms/batch - loss: 30.80429 - diff: 16.64mlTrain batch 21/32 - 241.9ms/batch - loss: 31.41847 - diff: 16.80mlTrain batch 22/32 - 245.6ms/batch - loss: 31.44349 - diff: 16.88mlTrain batch 23/32 - 241.8ms/batch - loss: 30.74332 - diff: 16.65mlTrain batch 24/32 - 240.9ms/batch - loss: 30.21527 - diff: 16.52mlTrain batch 25/32 - 241.6ms/batch - loss: 29.25002 - diff: 16.14mlTrain batch 26/32 - 241.4ms/batch - loss: 28.87707 - diff: 16.00mlTrain batch 27/32 - 242.0ms/batch - loss: 29.70266 - diff: 16.32mlTrain batch 28/32 - 240.9ms/batch - loss: 29.00648 - diff: 16.15mlTrain batch 29/32 - 241.5ms/batch - loss: 28.40817 - diff: 15.97mlTrain batch 30/32 - 240.9ms/batch - loss: 27.75889 - diff: 15.78mlTrain batch 31/32 - 241.3ms/batch - loss: 27.54016 - diff: 15.81mlTrain batch 32/32 - 79.2ms/batch - loss: 27.41893 - diff: 15.73mlTrain batch 32/32 - 11.2s 79.2ms/batch - loss: 27.41893 - diff: 15.73ml
Test 1.1s: val_loss: 767.59292 - diff: 102.64ml

Epoch 91: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 240.5ms/batch - loss: 15.59748 - diff: 12.51mlTrain batch 2/32 - 241.7ms/batch - loss: 12.87718 - diff: 11.60mlTrain batch 3/32 - 240.3ms/batch - loss: 12.81341 - diff: 11.55mlTrain batch 4/32 - 241.3ms/batch - loss: 16.28226 - diff: 12.81mlTrain batch 5/32 - 241.0ms/batch - loss: 15.30699 - diff: 12.64mlTrain batch 6/32 - 241.1ms/batch - loss: 15.09405 - diff: 12.60mlTrain batch 7/32 - 240.8ms/batch - loss: 14.73005 - diff: 12.47mlTrain batch 8/32 - 240.5ms/batch - loss: 14.39030 - diff: 12.38mlTrain batch 9/32 - 241.4ms/batch - loss: 15.32240 - diff: 12.80mlTrain batch 10/32 - 240.8ms/batch - loss: 20.49425 - diff: 14.33mlTrain batch 11/32 - 241.0ms/batch - loss: 19.97082 - diff: 14.19mlTrain batch 12/32 - 241.0ms/batch - loss: 20.03557 - diff: 14.25mlTrain batch 13/32 - 242.0ms/batch - loss: 22.66079 - diff: 14.94mlTrain batch 14/32 - 240.6ms/batch - loss: 22.23509 - diff: 14.66mlTrain batch 15/32 - 241.1ms/batch - loss: 21.10622 - diff: 14.12mlTrain batch 16/32 - 240.9ms/batch - loss: 20.78214 - diff: 14.11mlTrain batch 17/32 - 241.3ms/batch - loss: 20.35930 - diff: 14.01mlTrain batch 18/32 - 240.9ms/batch - loss: 19.69608 - diff: 13.73mlTrain batch 19/32 - 241.6ms/batch - loss: 19.19952 - diff: 13.51mlTrain batch 20/32 - 241.5ms/batch - loss: 19.94900 - diff: 13.86mlTrain batch 21/32 - 241.6ms/batch - loss: 20.79357 - diff: 14.19mlTrain batch 22/32 - 241.0ms/batch - loss: 21.19353 - diff: 14.37mlTrain batch 23/32 - 241.2ms/batch - loss: 21.02993 - diff: 14.31mlTrain batch 24/32 - 240.9ms/batch - loss: 22.90012 - diff: 14.95mlTrain batch 25/32 - 241.7ms/batch - loss: 22.38121 - diff: 14.78mlTrain batch 26/32 - 241.1ms/batch - loss: 22.23219 - diff: 14.68mlTrain batch 27/32 - 241.7ms/batch - loss: 21.62348 - diff: 14.42mlTrain batch 28/32 - 241.4ms/batch - loss: 21.47604 - diff: 14.42mlTrain batch 29/32 - 241.1ms/batch - loss: 21.58819 - diff: 14.46mlTrain batch 30/32 - 241.4ms/batch - loss: 21.40408 - diff: 14.40mlTrain batch 31/32 - 241.0ms/batch - loss: 21.03005 - diff: 14.25mlTrain batch 32/32 - 79.2ms/batch - loss: 21.61509 - diff: 14.25mlTrain batch 32/32 - 11.3s 79.2ms/batch - loss: 21.61509 - diff: 14.25ml
Test 1.1s: val_loss: 679.74514 - diff: 95.41ml

Epoch 92: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 240.6ms/batch - loss: 34.44579 - diff: 17.44mlTrain batch 2/32 - 242.0ms/batch - loss: 26.71785 - diff: 15.31mlTrain batch 3/32 - 240.5ms/batch - loss: 21.33060 - diff: 13.93mlTrain batch 4/32 - 241.1ms/batch - loss: 20.17042 - diff: 13.85mlTrain batch 5/32 - 240.7ms/batch - loss: 29.17818 - diff: 16.88mlTrain batch 6/32 - 241.4ms/batch - loss: 28.88392 - diff: 16.87mlTrain batch 7/32 - 240.9ms/batch - loss: 27.06403 - diff: 16.42mlTrain batch 8/32 - 241.7ms/batch - loss: 29.87852 - diff: 17.14mlTrain batch 9/32 - 240.6ms/batch - loss: 28.21351 - diff: 16.67mlTrain batch 10/32 - 241.4ms/batch - loss: 26.56604 - diff: 16.08mlTrain batch 11/32 - 240.9ms/batch - loss: 25.18156 - diff: 15.71mlTrain batch 12/32 - 241.4ms/batch - loss: 26.60673 - diff: 16.35mlTrain batch 13/32 - 240.5ms/batch - loss: 26.86885 - diff: 16.47mlTrain batch 14/32 - 241.2ms/batch - loss: 26.60324 - diff: 16.29mlTrain batch 15/32 - 240.4ms/batch - loss: 42.56720 - diff: 19.33mlTrain batch 16/32 - 241.2ms/batch - loss: 41.42448 - diff: 18.98mlTrain batch 17/32 - 240.8ms/batch - loss: 41.15671 - diff: 19.10mlTrain batch 18/32 - 246.0ms/batch - loss: 40.14162 - diff: 18.84mlTrain batch 19/32 - 240.9ms/batch - loss: 39.29981 - diff: 18.60mlTrain batch 20/32 - 241.9ms/batch - loss: 37.76565 - diff: 18.18mlTrain batch 21/32 - 240.5ms/batch - loss: 38.48022 - diff: 18.56mlTrain batch 22/32 - 241.6ms/batch - loss: 37.75537 - diff: 18.39mlTrain batch 23/32 - 240.7ms/batch - loss: 36.68290 - diff: 18.09mlTrain batch 24/32 - 241.8ms/batch - loss: 35.41364 - diff: 17.68mlTrain batch 25/32 - 241.0ms/batch - loss: 34.50355 - diff: 17.46mlTrain batch 26/32 - 241.6ms/batch - loss: 34.17411 - diff: 17.45mlTrain batch 27/32 - 241.3ms/batch - loss: 34.02009 - diff: 17.40mlTrain batch 28/32 - 242.2ms/batch - loss: 33.26579 - diff: 17.17mlTrain batch 29/32 - 241.2ms/batch - loss: 32.81161 - diff: 17.08mlTrain batch 30/32 - 241.4ms/batch - loss: 32.64097 - diff: 17.05mlTrain batch 31/32 - 240.8ms/batch - loss: 32.17703 - diff: 16.97mlTrain batch 32/32 - 79.1ms/batch - loss: 32.57765 - diff: 16.94mlTrain batch 32/32 - 11.7s 79.1ms/batch - loss: 32.57765 - diff: 16.94ml
Test 1.1s: val_loss: 659.58692 - diff: 94.64ml

Epoch 93: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 240.8ms/batch - loss: 18.06719 - diff: 13.24mlTrain batch 2/32 - 242.0ms/batch - loss: 12.12304 - diff: 10.43mlTrain batch 3/32 - 240.9ms/batch - loss: 24.38601 - diff: 15.26mlTrain batch 4/32 - 241.7ms/batch - loss: 21.28366 - diff: 14.45mlTrain batch 5/32 - 240.9ms/batch - loss: 23.89673 - diff: 15.51mlTrain batch 6/32 - 241.7ms/batch - loss: 22.00816 - diff: 14.86mlTrain batch 7/32 - 240.8ms/batch - loss: 24.67463 - diff: 15.75mlTrain batch 8/32 - 241.2ms/batch - loss: 22.75480 - diff: 15.00mlTrain batch 9/32 - 240.8ms/batch - loss: 21.63824 - diff: 14.71mlTrain batch 10/32 - 241.5ms/batch - loss: 21.11126 - diff: 14.56mlTrain batch 11/32 - 240.4ms/batch - loss: 21.05888 - diff: 14.73mlTrain batch 12/32 - 241.3ms/batch - loss: 21.58277 - diff: 14.86mlTrain batch 13/32 - 240.4ms/batch - loss: 20.97462 - diff: 14.75mlTrain batch 14/32 - 241.8ms/batch - loss: 21.80496 - diff: 15.16mlTrain batch 15/32 - 240.7ms/batch - loss: 22.32430 - diff: 15.43mlTrain batch 16/32 - 242.0ms/batch - loss: 21.70881 - diff: 15.20mlTrain batch 17/32 - 240.6ms/batch - loss: 21.83025 - diff: 15.33mlTrain batch 18/32 - 241.5ms/batch - loss: 21.58159 - diff: 15.27mlTrain batch 19/32 - 240.9ms/batch - loss: 21.30912 - diff: 15.18mlTrain batch 20/32 - 241.6ms/batch - loss: 21.64714 - diff: 15.30mlTrain batch 21/32 - 241.1ms/batch - loss: 21.39982 - diff: 15.10mlTrain batch 22/32 - 241.3ms/batch - loss: 22.15415 - diff: 15.31mlTrain batch 23/32 - 241.2ms/batch - loss: 21.62316 - diff: 15.01mlTrain batch 24/32 - 240.8ms/batch - loss: 21.19360 - diff: 14.82mlTrain batch 25/32 - 240.9ms/batch - loss: 21.23762 - diff: 14.82mlTrain batch 26/32 - 241.0ms/batch - loss: 21.44196 - diff: 14.94mlTrain batch 27/32 - 241.8ms/batch - loss: 24.29989 - diff: 15.72mlTrain batch 28/32 - 240.3ms/batch - loss: 24.18766 - diff: 15.66mlTrain batch 29/32 - 241.2ms/batch - loss: 23.91588 - diff: 15.55mlTrain batch 30/32 - 240.7ms/batch - loss: 23.56978 - diff: 15.45mlTrain batch 31/32 - 241.9ms/batch - loss: 23.28599 - diff: 15.37mlTrain batch 32/32 - 79.6ms/batch - loss: 27.51636 - diff: 15.61mlTrain batch 32/32 - 11.3s 79.6ms/batch - loss: 27.51636 - diff: 15.61ml
Test 1.2s: val_loss: 842.89787 - diff: 107.54ml

Epoch 94: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 240.6ms/batch - loss: 75.05515 - diff: 30.91mlTrain batch 2/32 - 241.0ms/batch - loss: 43.22725 - diff: 21.24mlTrain batch 3/32 - 240.2ms/batch - loss: 32.41666 - diff: 17.97mlTrain batch 4/32 - 241.6ms/batch - loss: 35.85926 - diff: 19.47mlTrain batch 5/32 - 240.3ms/batch - loss: 31.67428 - diff: 18.12mlTrain batch 6/32 - 241.6ms/batch - loss: 32.33591 - diff: 18.50mlTrain batch 7/32 - 240.6ms/batch - loss: 38.70114 - diff: 20.48mlTrain batch 8/32 - 242.1ms/batch - loss: 37.58039 - diff: 20.02mlTrain batch 9/32 - 240.7ms/batch - loss: 39.81460 - diff: 20.87mlTrain batch 10/32 - 241.8ms/batch - loss: 37.74526 - diff: 20.13mlTrain batch 11/32 - 240.6ms/batch - loss: 37.34686 - diff: 20.09mlTrain batch 12/32 - 241.2ms/batch - loss: 35.05903 - diff: 19.16mlTrain batch 13/32 - 241.0ms/batch - loss: 34.26186 - diff: 19.04mlTrain batch 14/32 - 242.0ms/batch - loss: 32.57451 - diff: 18.32mlTrain batch 15/32 - 240.4ms/batch - loss: 33.25953 - diff: 18.15mlTrain batch 16/32 - 241.1ms/batch - loss: 31.64998 - diff: 17.60mlTrain batch 17/32 - 240.1ms/batch - loss: 31.29982 - diff: 17.53mlTrain batch 18/32 - 241.3ms/batch - loss: 31.38407 - diff: 17.69mlTrain batch 19/32 - 241.2ms/batch - loss: 30.38029 - diff: 17.37mlTrain batch 20/32 - 242.1ms/batch - loss: 31.50376 - diff: 17.63mlTrain batch 21/32 - 240.7ms/batch - loss: 30.59836 - diff: 17.36mlTrain batch 22/32 - 241.4ms/batch - loss: 29.93107 - diff: 17.21mlTrain batch 23/32 - 240.9ms/batch - loss: 29.20252 - diff: 16.96mlTrain batch 24/32 - 241.8ms/batch - loss: 28.26504 - diff: 16.60mlTrain batch 25/32 - 240.9ms/batch - loss: 27.49565 - diff: 16.34mlTrain batch 26/32 - 241.7ms/batch - loss: 26.95649 - diff: 16.18mlTrain batch 27/32 - 240.3ms/batch - loss: 26.73510 - diff: 16.14mlTrain batch 28/32 - 241.7ms/batch - loss: 26.68716 - diff: 16.14mlTrain batch 29/32 - 240.7ms/batch - loss: 27.70190 - diff: 16.51mlTrain batch 30/32 - 241.4ms/batch - loss: 36.61660 - diff: 18.08mlTrain batch 31/32 - 240.9ms/batch - loss: 36.16608 - diff: 18.02mlTrain batch 32/32 - 79.8ms/batch - loss: 36.49529 - diff: 17.99mlTrain batch 32/32 - 11.5s 79.8ms/batch - loss: 36.49529 - diff: 17.99ml
Test 1.2s: val_loss: 615.09887 - diff: 90.17ml
Epoch    95: reducing learning rate of group 0 to 3.9063e-06.

Epoch 95: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 240.6ms/batch - loss: 14.11918 - diff: 12.77mlTrain batch 2/32 - 241.8ms/batch - loss: 18.42785 - diff: 14.76mlTrain batch 3/32 - 240.2ms/batch - loss: 21.95966 - diff: 16.41mlTrain batch 4/32 - 241.5ms/batch - loss: 19.62210 - diff: 15.30mlTrain batch 5/32 - 240.4ms/batch - loss: 18.71096 - diff: 14.70mlTrain batch 6/32 - 241.1ms/batch - loss: 17.39467 - diff: 13.98mlTrain batch 7/32 - 240.8ms/batch - loss: 16.95298 - diff: 13.66mlTrain batch 8/32 - 241.4ms/batch - loss: 17.10309 - diff: 13.90mlTrain batch 9/32 - 240.2ms/batch - loss: 16.38542 - diff: 13.53mlTrain batch 10/32 - 241.6ms/batch - loss: 16.31514 - diff: 13.36mlTrain batch 11/32 - 241.0ms/batch - loss: 24.27179 - diff: 15.66mlTrain batch 12/32 - 241.5ms/batch - loss: 24.04603 - diff: 15.59mlTrain batch 13/32 - 240.8ms/batch - loss: 23.18531 - diff: 15.31mlTrain batch 14/32 - 241.0ms/batch - loss: 25.39901 - diff: 16.02mlTrain batch 15/32 - 240.7ms/batch - loss: 24.21313 - diff: 15.54mlTrain batch 16/32 - 241.3ms/batch - loss: 23.39051 - diff: 15.17mlTrain batch 17/32 - 240.9ms/batch - loss: 22.85230 - diff: 15.00mlTrain batch 18/32 - 241.6ms/batch - loss: 23.11608 - diff: 15.19mlTrain batch 19/32 - 240.4ms/batch - loss: 22.36359 - diff: 14.87mlTrain batch 20/32 - 241.4ms/batch - loss: 24.14879 - diff: 15.14mlTrain batch 21/32 - 241.0ms/batch - loss: 24.39941 - diff: 15.17mlTrain batch 22/32 - 241.8ms/batch - loss: 23.72476 - diff: 14.94mlTrain batch 23/32 - 240.2ms/batch - loss: 23.31924 - diff: 14.85mlTrain batch 24/32 - 241.8ms/batch - loss: 22.82490 - diff: 14.70mlTrain batch 25/32 - 240.4ms/batch - loss: 22.89828 - diff: 14.72mlTrain batch 26/32 - 241.1ms/batch - loss: 22.44787 - diff: 14.58mlTrain batch 27/32 - 240.4ms/batch - loss: 21.84561 - diff: 14.34mlTrain batch 28/32 - 242.4ms/batch - loss: 22.66953 - diff: 14.66mlTrain batch 29/32 - 240.7ms/batch - loss: 23.67760 - diff: 15.02mlTrain batch 30/32 - 241.8ms/batch - loss: 24.00184 - diff: 15.14mlTrain batch 31/32 - 241.0ms/batch - loss: 23.92929 - diff: 15.14mlTrain batch 32/32 - 78.5ms/batch - loss: 26.12175 - diff: 15.24mlTrain batch 32/32 - 11.9s 78.5ms/batch - loss: 26.12175 - diff: 15.24ml
Test 1.1s: val_loss: 845.91136 - diff: 107.59ml

Epoch 96: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 240.7ms/batch - loss: 10.89032 - diff: 10.41mlTrain batch 2/32 - 241.2ms/batch - loss: 15.28727 - diff: 12.47mlTrain batch 3/32 - 240.9ms/batch - loss: 32.60936 - diff: 17.39mlTrain batch 4/32 - 241.8ms/batch - loss: 27.45151 - diff: 15.49mlTrain batch 5/32 - 240.4ms/batch - loss: 28.59654 - diff: 16.40mlTrain batch 6/32 - 240.9ms/batch - loss: 26.16625 - diff: 15.86mlTrain batch 7/32 - 240.6ms/batch - loss: 24.14716 - diff: 15.38mlTrain batch 8/32 - 240.8ms/batch - loss: 23.29741 - diff: 14.87mlTrain batch 9/32 - 241.1ms/batch - loss: 21.52437 - diff: 14.21mlTrain batch 10/32 - 240.6ms/batch - loss: 22.22977 - diff: 14.57mlTrain batch 11/32 - 240.2ms/batch - loss: 21.82017 - diff: 14.54mlTrain batch 12/32 - 240.7ms/batch - loss: 21.40007 - diff: 14.37mlTrain batch 13/32 - 240.9ms/batch - loss: 20.81670 - diff: 14.22mlTrain batch 14/32 - 241.2ms/batch - loss: 21.59557 - diff: 14.60mlTrain batch 15/32 - 241.0ms/batch - loss: 20.65984 - diff: 14.21mlTrain batch 16/32 - 240.8ms/batch - loss: 20.18699 - diff: 14.14mlTrain batch 17/32 - 241.5ms/batch - loss: 31.94690 - diff: 16.63mlTrain batch 18/32 - 240.7ms/batch - loss: 30.78038 - diff: 16.33mlTrain batch 19/32 - 241.9ms/batch - loss: 30.16444 - diff: 16.21mlTrain batch 20/32 - 240.6ms/batch - loss: 29.29915 - diff: 15.86mlTrain batch 21/32 - 242.1ms/batch - loss: 29.20426 - diff: 15.88mlTrain batch 22/32 - 240.5ms/batch - loss: 29.53616 - diff: 16.09mlTrain batch 23/32 - 241.5ms/batch - loss: 30.22240 - diff: 16.34mlTrain batch 24/32 - 240.7ms/batch - loss: 29.55591 - diff: 16.17mlTrain batch 25/32 - 241.6ms/batch - loss: 29.06232 - diff: 16.11mlTrain batch 26/32 - 240.7ms/batch - loss: 28.72133 - diff: 15.97mlTrain batch 27/32 - 241.7ms/batch - loss: 30.08364 - diff: 16.34mlTrain batch 28/32 - 240.7ms/batch - loss: 29.73204 - diff: 16.31mlTrain batch 29/32 - 241.3ms/batch - loss: 29.61376 - diff: 16.43mlTrain batch 30/32 - 240.4ms/batch - loss: 28.95654 - diff: 16.25mlTrain batch 31/32 - 241.5ms/batch - loss: 29.12376 - diff: 16.36mlTrain batch 32/32 - 78.8ms/batch - loss: 30.27702 - diff: 16.41mlTrain batch 32/32 - 11.3s 78.8ms/batch - loss: 30.27702 - diff: 16.41ml
Test 1.1s: val_loss: 671.61293 - diff: 95.51ml

Epoch 97: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 240.7ms/batch - loss: 11.99437 - diff: 11.60mlTrain batch 2/32 - 241.8ms/batch - loss: 15.82609 - diff: 12.86mlTrain batch 3/32 - 240.3ms/batch - loss: 14.54469 - diff: 12.21mlTrain batch 4/32 - 241.8ms/batch - loss: 12.50230 - diff: 10.89mlTrain batch 5/32 - 240.6ms/batch - loss: 16.97237 - diff: 12.78mlTrain batch 6/32 - 241.7ms/batch - loss: 15.48078 - diff: 12.16mlTrain batch 7/32 - 240.5ms/batch - loss: 19.64356 - diff: 13.59mlTrain batch 8/32 - 241.6ms/batch - loss: 19.78614 - diff: 13.74mlTrain batch 9/32 - 240.8ms/batch - loss: 19.47698 - diff: 13.71mlTrain batch 10/32 - 241.8ms/batch - loss: 21.51464 - diff: 14.43mlTrain batch 11/32 - 240.5ms/batch - loss: 20.67595 - diff: 14.04mlTrain batch 12/32 - 241.0ms/batch - loss: 20.32350 - diff: 13.91mlTrain batch 13/32 - 241.0ms/batch - loss: 20.05059 - diff: 13.87mlTrain batch 14/32 - 241.5ms/batch - loss: 19.60159 - diff: 13.77mlTrain batch 15/32 - 240.7ms/batch - loss: 23.16488 - diff: 14.94mlTrain batch 16/32 - 241.6ms/batch - loss: 22.97898 - diff: 14.94mlTrain batch 17/32 - 240.6ms/batch - loss: 22.61785 - diff: 14.88mlTrain batch 18/32 - 241.2ms/batch - loss: 22.19011 - diff: 14.79mlTrain batch 19/32 - 241.0ms/batch - loss: 22.97744 - diff: 15.12mlTrain batch 20/32 - 241.4ms/batch - loss: 22.46888 - diff: 14.99mlTrain batch 21/32 - 241.2ms/batch - loss: 22.20800 - diff: 14.96mlTrain batch 22/32 - 242.3ms/batch - loss: 27.90608 - diff: 16.17mlTrain batch 23/32 - 240.9ms/batch - loss: 27.03225 - diff: 15.87mlTrain batch 24/32 - 241.0ms/batch - loss: 26.40073 - diff: 15.72mlTrain batch 25/32 - 241.0ms/batch - loss: 25.98166 - diff: 15.58mlTrain batch 26/32 - 241.9ms/batch - loss: 25.72760 - diff: 15.50mlTrain batch 27/32 - 240.7ms/batch - loss: 26.68046 - diff: 15.83mlTrain batch 28/32 - 241.2ms/batch - loss: 26.29185 - diff: 15.74mlTrain batch 29/32 - 240.9ms/batch - loss: 26.50414 - diff: 15.80mlTrain batch 30/32 - 241.7ms/batch - loss: 26.45632 - diff: 15.70mlTrain batch 31/32 - 241.0ms/batch - loss: 25.96332 - diff: 15.58mlTrain batch 32/32 - 79.7ms/batch - loss: 26.61884 - diff: 15.59mlTrain batch 32/32 - 11.2s 79.7ms/batch - loss: 26.61884 - diff: 15.59ml
Test 1.2s: val_loss: 675.66564 - diff: 96.10ml

Epoch 98: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 240.7ms/batch - loss: 8.37714 - diff: 7.81mlTrain batch 2/32 - 241.7ms/batch - loss: 12.84705 - diff: 10.55mlTrain batch 3/32 - 240.8ms/batch - loss: 11.56231 - diff: 9.59mlTrain batch 4/32 - 241.9ms/batch - loss: 13.05311 - diff: 10.17mlTrain batch 5/32 - 240.8ms/batch - loss: 13.91853 - diff: 11.01mlTrain batch 6/32 - 241.6ms/batch - loss: 15.85545 - diff: 12.14mlTrain batch 7/32 - 240.6ms/batch - loss: 18.51597 - diff: 13.12mlTrain batch 8/32 - 241.7ms/batch - loss: 18.01728 - diff: 12.99mlTrain batch 9/32 - 240.5ms/batch - loss: 20.95229 - diff: 14.27mlTrain batch 10/32 - 241.0ms/batch - loss: 25.34381 - diff: 15.67mlTrain batch 11/32 - 240.6ms/batch - loss: 27.03045 - diff: 16.29mlTrain batch 12/32 - 241.2ms/batch - loss: 25.81292 - diff: 16.00mlTrain batch 13/32 - 240.1ms/batch - loss: 36.85409 - diff: 18.51mlTrain batch 14/32 - 241.7ms/batch - loss: 37.18799 - diff: 18.79mlTrain batch 15/32 - 240.8ms/batch - loss: 35.54461 - diff: 18.33mlTrain batch 16/32 - 241.7ms/batch - loss: 33.72705 - diff: 17.74mlTrain batch 17/32 - 240.8ms/batch - loss: 32.44076 - diff: 17.39mlTrain batch 18/32 - 241.7ms/batch - loss: 31.05583 - diff: 16.87mlTrain batch 19/32 - 241.1ms/batch - loss: 29.74585 - diff: 16.41mlTrain batch 20/32 - 241.5ms/batch - loss: 29.52362 - diff: 16.46mlTrain batch 21/32 - 240.5ms/batch - loss: 28.71255 - diff: 16.22mlTrain batch 22/32 - 241.7ms/batch - loss: 28.14144 - diff: 16.09mlTrain batch 23/32 - 240.9ms/batch - loss: 27.37898 - diff: 15.79mlTrain batch 24/32 - 242.1ms/batch - loss: 26.78277 - diff: 15.62mlTrain batch 25/32 - 240.8ms/batch - loss: 26.02716 - diff: 15.35mlTrain batch 26/32 - 242.1ms/batch - loss: 27.34373 - diff: 15.81mlTrain batch 27/32 - 240.5ms/batch - loss: 26.93166 - diff: 15.66mlTrain batch 28/32 - 241.5ms/batch - loss: 26.25127 - diff: 15.43mlTrain batch 29/32 - 240.6ms/batch - loss: 26.52873 - diff: 15.68mlTrain batch 30/32 - 241.2ms/batch - loss: 26.66757 - diff: 15.75mlTrain batch 31/32 - 240.2ms/batch - loss: 26.13521 - diff: 15.54mlTrain batch 32/32 - 79.0ms/batch - loss: 26.29536 - diff: 15.49mlTrain batch 32/32 - 11.6s 79.0ms/batch - loss: 26.29536 - diff: 15.49ml
Test 1.2s: val_loss: 844.10493 - diff: 107.55ml

Epoch 99: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 240.5ms/batch - loss: 13.17941 - diff: 12.24mlTrain batch 2/32 - 240.7ms/batch - loss: 10.98877 - diff: 11.00mlTrain batch 3/32 - 240.5ms/batch - loss: 13.38638 - diff: 12.36mlTrain batch 4/32 - 240.9ms/batch - loss: 13.23366 - diff: 11.89mlTrain batch 5/32 - 241.0ms/batch - loss: 14.56287 - diff: 12.46mlTrain batch 6/32 - 242.1ms/batch - loss: 13.75156 - diff: 12.09mlTrain batch 7/32 - 240.5ms/batch - loss: 16.58207 - diff: 13.26mlTrain batch 8/32 - 241.7ms/batch - loss: 19.82906 - diff: 14.38mlTrain batch 9/32 - 240.6ms/batch - loss: 19.66078 - diff: 14.30mlTrain batch 10/32 - 241.2ms/batch - loss: 21.17817 - diff: 15.08mlTrain batch 11/32 - 240.4ms/batch - loss: 22.03477 - diff: 15.38mlTrain batch 12/32 - 241.1ms/batch - loss: 21.11642 - diff: 14.96mlTrain batch 13/32 - 240.3ms/batch - loss: 20.40454 - diff: 14.71mlTrain batch 14/32 - 243.8ms/batch - loss: 19.79737 - diff: 14.46mlTrain batch 15/32 - 240.8ms/batch - loss: 21.60657 - diff: 15.18mlTrain batch 16/32 - 241.4ms/batch - loss: 21.34984 - diff: 15.12mlTrain batch 17/32 - 240.4ms/batch - loss: 21.89241 - diff: 15.17mlTrain batch 18/32 - 241.2ms/batch - loss: 21.49467 - diff: 14.94mlTrain batch 19/32 - 241.0ms/batch - loss: 20.86332 - diff: 14.67mlTrain batch 20/32 - 242.1ms/batch - loss: 21.31597 - diff: 14.94mlTrain batch 21/32 - 241.0ms/batch - loss: 21.99200 - diff: 15.12mlTrain batch 22/32 - 241.9ms/batch - loss: 22.06974 - diff: 15.15mlTrain batch 23/32 - 240.9ms/batch - loss: 25.30527 - diff: 16.03mlTrain batch 24/32 - 241.0ms/batch - loss: 24.74678 - diff: 15.80mlTrain batch 25/32 - 240.7ms/batch - loss: 24.03003 - diff: 15.49mlTrain batch 26/32 - 240.6ms/batch - loss: 23.80709 - diff: 15.46mlTrain batch 27/32 - 240.5ms/batch - loss: 23.25065 - diff: 15.25mlTrain batch 28/32 - 240.4ms/batch - loss: 23.27212 - diff: 15.26mlTrain batch 29/32 - 241.5ms/batch - loss: 24.11466 - diff: 15.63mlTrain batch 30/32 - 240.8ms/batch - loss: 24.81461 - diff: 15.92mlTrain batch 31/32 - 241.7ms/batch - loss: 24.49334 - diff: 15.79mlTrain batch 32/32 - 79.5ms/batch - loss: 26.68316 - diff: 15.93mlTrain batch 32/32 - 12.2s 79.5ms/batch - loss: 26.68316 - diff: 15.93ml
Test 1.1s: val_loss: 654.15947 - diff: 93.99ml

Epoch 100: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 240.2ms/batch - loss: 6.26658 - diff: 8.69mlTrain batch 2/32 - 241.3ms/batch - loss: 9.26901 - diff: 9.35mlTrain batch 3/32 - 240.3ms/batch - loss: 17.27046 - diff: 13.39mlTrain batch 4/32 - 241.5ms/batch - loss: 16.76398 - diff: 13.25mlTrain batch 5/32 - 240.6ms/batch - loss: 15.35182 - diff: 12.66mlTrain batch 6/32 - 241.9ms/batch - loss: 17.92196 - diff: 13.95mlTrain batch 7/32 - 240.8ms/batch - loss: 19.13269 - diff: 14.65mlTrain batch 8/32 - 241.6ms/batch - loss: 19.52127 - diff: 14.74mlTrain batch 9/32 - 240.5ms/batch - loss: 19.76789 - diff: 14.81mlTrain batch 10/32 - 241.1ms/batch - loss: 18.93317 - diff: 14.48mlTrain batch 11/32 - 240.5ms/batch - loss: 17.86042 - diff: 13.97mlTrain batch 12/32 - 241.4ms/batch - loss: 18.11738 - diff: 14.04mlTrain batch 13/32 - 240.8ms/batch - loss: 17.97068 - diff: 14.03mlTrain batch 14/32 - 241.3ms/batch - loss: 27.68745 - diff: 15.83mlTrain batch 15/32 - 240.6ms/batch - loss: 27.17420 - diff: 15.82mlTrain batch 16/32 - 241.8ms/batch - loss: 26.46280 - diff: 15.70mlTrain batch 17/32 - 240.6ms/batch - loss: 27.09435 - diff: 16.04mlTrain batch 18/32 - 241.4ms/batch - loss: 26.85914 - diff: 16.02mlTrain batch 19/32 - 240.4ms/batch - loss: 26.38396 - diff: 15.92mlTrain batch 20/32 - 241.4ms/batch - loss: 29.52485 - diff: 16.88mlTrain batch 21/32 - 240.7ms/batch - loss: 29.07342 - diff: 16.74mlTrain batch 22/32 - 241.8ms/batch - loss: 29.66283 - diff: 16.95mlTrain batch 23/32 - 241.0ms/batch - loss: 29.29541 - diff: 16.95mlTrain batch 24/32 - 241.5ms/batch - loss: 28.27935 - diff: 16.55mlTrain batch 25/32 - 242.1ms/batch - loss: 29.72164 - diff: 17.04mlTrain batch 26/32 - 241.4ms/batch - loss: 29.22767 - diff: 16.90mlTrain batch 27/32 - 240.9ms/batch - loss: 28.80788 - diff: 16.81mlTrain batch 28/32 - 240.3ms/batch - loss: 28.81455 - diff: 16.83mlTrain batch 29/32 - 241.5ms/batch - loss: 28.52309 - diff: 16.78mlTrain batch 30/32 - 240.4ms/batch - loss: 29.49451 - diff: 17.13mlTrain batch 31/32 - 241.2ms/batch - loss: 28.96344 - diff: 16.91mlTrain batch 32/32 - 80.4ms/batch - loss: 29.89434 - diff: 16.91mlTrain batch 32/32 - 11.8s 80.4ms/batch - loss: 29.89434 - diff: 16.91ml
Test 1.1s: val_loss: 816.18166 - diff: 106.15ml

Epoch 101: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 240.5ms/batch - loss: 11.32734 - diff: 10.89mlTrain batch 2/32 - 241.1ms/batch - loss: 11.20809 - diff: 10.55mlTrain batch 3/32 - 240.6ms/batch - loss: 12.84532 - diff: 11.31mlTrain batch 4/32 - 241.0ms/batch - loss: 15.57894 - diff: 12.73mlTrain batch 5/32 - 240.4ms/batch - loss: 15.09367 - diff: 12.67mlTrain batch 6/32 - 241.5ms/batch - loss: 14.55743 - diff: 12.59mlTrain batch 7/32 - 240.7ms/batch - loss: 14.55884 - diff: 12.66mlTrain batch 8/32 - 242.0ms/batch - loss: 14.99077 - diff: 12.85mlTrain batch 9/32 - 240.4ms/batch - loss: 17.82528 - diff: 13.96mlTrain batch 10/32 - 241.6ms/batch - loss: 17.02406 - diff: 13.54mlTrain batch 11/32 - 240.6ms/batch - loss: 16.80909 - diff: 13.37mlTrain batch 12/32 - 241.4ms/batch - loss: 19.66327 - diff: 14.29mlTrain batch 13/32 - 241.0ms/batch - loss: 19.11955 - diff: 14.11mlTrain batch 14/32 - 241.9ms/batch - loss: 20.63009 - diff: 14.58mlTrain batch 15/32 - 240.3ms/batch - loss: 20.26895 - diff: 14.37mlTrain batch 16/32 - 241.5ms/batch - loss: 19.70384 - diff: 14.19mlTrain batch 17/32 - 241.3ms/batch - loss: 19.06285 - diff: 13.97mlTrain batch 18/32 - 242.0ms/batch - loss: 19.95973 - diff: 14.32mlTrain batch 19/32 - 241.1ms/batch - loss: 19.90431 - diff: 14.33mlTrain batch 20/32 - 241.8ms/batch - loss: 19.62150 - diff: 14.25mlTrain batch 21/32 - 240.3ms/batch - loss: 20.46379 - diff: 14.50mlTrain batch 22/32 - 242.0ms/batch - loss: 19.83659 - diff: 14.22mlTrain batch 23/32 - 240.9ms/batch - loss: 30.04082 - diff: 16.28mlTrain batch 24/32 - 241.1ms/batch - loss: 30.43402 - diff: 16.49mlTrain batch 25/32 - 240.7ms/batch - loss: 30.28421 - diff: 16.51mlTrain batch 26/32 - 241.4ms/batch - loss: 30.15207 - diff: 16.52mlTrain batch 27/32 - 241.0ms/batch - loss: 30.00934 - diff: 16.51mlTrain batch 28/32 - 241.6ms/batch - loss: 29.39369 - diff: 16.32mlTrain batch 29/32 - 240.6ms/batch - loss: 28.71265 - diff: 16.08mlTrain batch 30/32 - 240.3ms/batch - loss: 27.98042 - diff: 15.85mlTrain batch 31/32 - 240.9ms/batch - loss: 29.42492 - diff: 16.23mlTrain batch 32/32 - 78.6ms/batch - loss: 33.42384 - diff: 16.46mlTrain batch 32/32 - 11.9s 78.6ms/batch - loss: 33.42384 - diff: 16.46ml
Test 1.1s: val_loss: 892.03913 - diff: 111.40ml

Epoch 102: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 240.8ms/batch - loss: 17.33252 - diff: 14.22mlTrain batch 2/32 - 241.6ms/batch - loss: 14.90626 - diff: 12.60mlTrain batch 3/32 - 240.4ms/batch - loss: 13.34709 - diff: 11.73mlTrain batch 4/32 - 241.7ms/batch - loss: 11.29365 - diff: 10.66mlTrain batch 5/32 - 241.0ms/batch - loss: 11.94491 - diff: 11.09mlTrain batch 6/32 - 242.0ms/batch - loss: 12.76096 - diff: 11.21mlTrain batch 7/32 - 240.5ms/batch - loss: 12.83751 - diff: 11.30mlTrain batch 8/32 - 241.7ms/batch - loss: 12.91529 - diff: 11.42mlTrain batch 9/32 - 240.2ms/batch - loss: 16.70532 - diff: 12.91mlTrain batch 10/32 - 241.8ms/batch - loss: 15.90841 - diff: 12.57mlTrain batch 11/32 - 240.9ms/batch - loss: 18.03740 - diff: 13.46mlTrain batch 12/32 - 241.5ms/batch - loss: 17.97520 - diff: 13.60mlTrain batch 13/32 - 240.5ms/batch - loss: 19.23882 - diff: 14.13mlTrain batch 14/32 - 242.0ms/batch - loss: 19.99838 - diff: 14.42mlTrain batch 15/32 - 241.1ms/batch - loss: 19.82409 - diff: 14.41mlTrain batch 16/32 - 241.3ms/batch - loss: 19.31057 - diff: 14.19mlTrain batch 17/32 - 240.8ms/batch - loss: 19.43960 - diff: 14.24mlTrain batch 18/32 - 241.8ms/batch - loss: 19.13939 - diff: 14.06mlTrain batch 19/32 - 240.6ms/batch - loss: 18.62516 - diff: 13.87mlTrain batch 20/32 - 241.5ms/batch - loss: 19.24297 - diff: 14.11mlTrain batch 21/32 - 240.8ms/batch - loss: 18.65659 - diff: 13.85mlTrain batch 22/32 - 241.9ms/batch - loss: 18.19492 - diff: 13.68mlTrain batch 23/32 - 241.2ms/batch - loss: 18.36217 - diff: 13.73mlTrain batch 24/32 - 241.8ms/batch - loss: 17.94696 - diff: 13.53mlTrain batch 25/32 - 240.4ms/batch - loss: 18.11404 - diff: 13.66mlTrain batch 26/32 - 241.6ms/batch - loss: 18.24735 - diff: 13.68mlTrain batch 27/32 - 240.6ms/batch - loss: 18.05796 - diff: 13.54mlTrain batch 28/32 - 241.1ms/batch - loss: 17.71751 - diff: 13.40mlTrain batch 29/32 - 241.2ms/batch - loss: 17.45549 - diff: 13.28mlTrain batch 30/32 - 242.1ms/batch - loss: 17.33875 - diff: 13.25mlTrain batch 31/32 - 241.1ms/batch - loss: 18.51135 - diff: 13.53mlTrain batch 32/32 - 78.8ms/batch - loss: 20.42245 - diff: 13.65mlTrain batch 32/32 - 11.1s 78.8ms/batch - loss: 20.42245 - diff: 13.65ml
Test 1.1s: val_loss: 713.42757 - diff: 98.84ml

Epoch 103: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 240.5ms/batch - loss: 37.02515 - diff: 21.55mlTrain batch 2/32 - 241.6ms/batch - loss: 26.87840 - diff: 17.50mlTrain batch 3/32 - 240.8ms/batch - loss: 34.37806 - diff: 19.91mlTrain batch 4/32 - 241.4ms/batch - loss: 31.94513 - diff: 19.33mlTrain batch 5/32 - 240.5ms/batch - loss: 30.38306 - diff: 18.77mlTrain batch 6/32 - 241.8ms/batch - loss: 28.29754 - diff: 18.02mlTrain batch 7/32 - 241.1ms/batch - loss: 26.69437 - diff: 17.42mlTrain batch 8/32 - 241.5ms/batch - loss: 25.56087 - diff: 16.92mlTrain batch 9/32 - 241.2ms/batch - loss: 24.38620 - diff: 16.24mlTrain batch 10/32 - 241.4ms/batch - loss: 23.32915 - diff: 15.94mlTrain batch 11/32 - 240.7ms/batch - loss: 22.06736 - diff: 15.24mlTrain batch 12/32 - 241.6ms/batch - loss: 22.21589 - diff: 15.17mlTrain batch 13/32 - 240.4ms/batch - loss: 22.29662 - diff: 14.97mlTrain batch 14/32 - 241.6ms/batch - loss: 22.36282 - diff: 15.05mlTrain batch 15/32 - 240.8ms/batch - loss: 22.88842 - diff: 15.24mlTrain batch 16/32 - 241.5ms/batch - loss: 22.38985 - diff: 15.12mlTrain batch 17/32 - 240.8ms/batch - loss: 23.32790 - diff: 15.49mlTrain batch 18/32 - 241.8ms/batch - loss: 23.50039 - diff: 15.53mlTrain batch 19/32 - 240.5ms/batch - loss: 23.64666 - diff: 15.54mlTrain batch 20/32 - 241.3ms/batch - loss: 22.95420 - diff: 15.32mlTrain batch 21/32 - 240.5ms/batch - loss: 22.23256 - diff: 15.02mlTrain batch 22/32 - 241.5ms/batch - loss: 21.66687 - diff: 14.80mlTrain batch 23/32 - 241.1ms/batch - loss: 21.28726 - diff: 14.68mlTrain batch 24/32 - 241.4ms/batch - loss: 21.94070 - diff: 15.02mlTrain batch 25/32 - 240.9ms/batch - loss: 21.49051 - diff: 14.82mlTrain batch 26/32 - 241.5ms/batch - loss: 21.92354 - diff: 14.94mlTrain batch 27/32 - 240.6ms/batch - loss: 21.57217 - diff: 14.78mlTrain batch 28/32 - 241.1ms/batch - loss: 21.46439 - diff: 14.81mlTrain batch 29/32 - 240.3ms/batch - loss: 20.95384 - diff: 14.60mlTrain batch 30/32 - 241.5ms/batch - loss: 20.93665 - diff: 14.65mlTrain batch 31/32 - 241.0ms/batch - loss: 23.08535 - diff: 15.19mlTrain batch 32/32 - 78.7ms/batch - loss: 29.63629 - diff: 15.50mlTrain batch 32/32 - 12.2s 78.7ms/batch - loss: 29.63629 - diff: 15.50ml
Test 1.1s: val_loss: 719.88924 - diff: 99.23ml

Epoch 104: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 240.8ms/batch - loss: 34.85875 - diff: 19.67mlTrain batch 2/32 - 241.7ms/batch - loss: 26.06206 - diff: 16.76mlTrain batch 3/32 - 240.2ms/batch - loss: 35.26666 - diff: 19.99mlTrain batch 4/32 - 241.5ms/batch - loss: 31.13288 - diff: 18.95mlTrain batch 5/32 - 240.3ms/batch - loss: 29.39394 - diff: 18.38mlTrain batch 6/32 - 241.6ms/batch - loss: 28.59371 - diff: 18.15mlTrain batch 7/32 - 240.4ms/batch - loss: 27.33738 - diff: 17.55mlTrain batch 8/32 - 241.1ms/batch - loss: 35.91582 - diff: 19.41mlTrain batch 9/32 - 240.3ms/batch - loss: 36.96633 - diff: 19.85mlTrain batch 10/32 - 241.2ms/batch - loss: 34.12226 - diff: 18.84mlTrain batch 11/32 - 240.6ms/batch - loss: 32.77093 - diff: 18.47mlTrain batch 12/32 - 241.3ms/batch - loss: 31.10957 - diff: 17.95mlTrain batch 13/32 - 240.6ms/batch - loss: 29.43895 - diff: 17.33mlTrain batch 14/32 - 241.3ms/batch - loss: 30.95369 - diff: 17.93mlTrain batch 15/32 - 240.3ms/batch - loss: 31.15353 - diff: 18.13mlTrain batch 16/32 - 241.7ms/batch - loss: 30.03593 - diff: 17.76mlTrain batch 17/32 - 240.7ms/batch - loss: 29.25160 - diff: 17.52mlTrain batch 18/32 - 241.4ms/batch - loss: 29.38861 - diff: 17.63mlTrain batch 19/32 - 240.8ms/batch - loss: 29.01230 - diff: 17.52mlTrain batch 20/32 - 241.9ms/batch - loss: 28.39711 - diff: 17.27mlTrain batch 21/32 - 240.3ms/batch - loss: 29.55746 - diff: 17.69mlTrain batch 22/32 - 241.3ms/batch - loss: 28.75660 - diff: 17.36mlTrain batch 23/32 - 240.2ms/batch - loss: 28.21575 - diff: 17.20mlTrain batch 24/32 - 241.4ms/batch - loss: 27.52904 - diff: 16.96mlTrain batch 25/32 - 240.4ms/batch - loss: 26.91597 - diff: 16.72mlTrain batch 26/32 - 240.7ms/batch - loss: 26.40991 - diff: 16.53mlTrain batch 27/32 - 240.7ms/batch - loss: 25.85919 - diff: 16.32mlTrain batch 28/32 - 241.6ms/batch - loss: 25.86000 - diff: 16.32mlTrain batch 29/32 - 240.3ms/batch - loss: 25.47979 - diff: 16.20mlTrain batch 30/32 - 241.6ms/batch - loss: 25.16233 - diff: 16.07mlTrain batch 31/32 - 240.7ms/batch - loss: 24.61084 - diff: 15.86mlTrain batch 32/32 - 79.0ms/batch - loss: 24.84113 - diff: 15.83mlTrain batch 32/32 - 12.1s 79.0ms/batch - loss: 24.84113 - diff: 15.83ml
Test 1.1s: val_loss: 764.75873 - diff: 102.51ml

Epoch 105: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 240.0ms/batch - loss: 5.48158 - diff: 7.13mlTrain batch 2/32 - 241.0ms/batch - loss: 6.42866 - diff: 7.84mlTrain batch 3/32 - 240.5ms/batch - loss: 9.03333 - diff: 9.02mlTrain batch 4/32 - 241.6ms/batch - loss: 27.30240 - diff: 15.03mlTrain batch 5/32 - 240.1ms/batch - loss: 27.44930 - diff: 15.65mlTrain batch 6/32 - 241.4ms/batch - loss: 30.83894 - diff: 17.07mlTrain batch 7/32 - 240.6ms/batch - loss: 27.54570 - diff: 15.86mlTrain batch 8/32 - 241.7ms/batch - loss: 25.47193 - diff: 15.29mlTrain batch 9/32 - 240.7ms/batch - loss: 24.47306 - diff: 14.95mlTrain batch 10/32 - 241.4ms/batch - loss: 23.21216 - diff: 14.50mlTrain batch 11/32 - 240.7ms/batch - loss: 22.34600 - diff: 14.15mlTrain batch 12/32 - 241.9ms/batch - loss: 22.29491 - diff: 14.33mlTrain batch 13/32 - 240.8ms/batch - loss: 25.52594 - diff: 15.34mlTrain batch 14/32 - 244.7ms/batch - loss: 25.35651 - diff: 15.34mlTrain batch 15/32 - 240.8ms/batch - loss: 25.67212 - diff: 15.48mlTrain batch 16/32 - 241.6ms/batch - loss: 24.65189 - diff: 15.16mlTrain batch 17/32 - 240.7ms/batch - loss: 24.56664 - diff: 15.19mlTrain batch 18/32 - 242.2ms/batch - loss: 25.46833 - diff: 15.58mlTrain batch 19/32 - 240.4ms/batch - loss: 24.94923 - diff: 15.47mlTrain batch 20/32 - 241.4ms/batch - loss: 24.32401 - diff: 15.21mlTrain batch 21/32 - 240.2ms/batch - loss: 24.49678 - diff: 15.27mlTrain batch 22/32 - 241.4ms/batch - loss: 25.02707 - diff: 15.45mlTrain batch 23/32 - 240.6ms/batch - loss: 27.22296 - diff: 16.22mlTrain batch 24/32 - 241.3ms/batch - loss: 26.64028 - diff: 16.03mlTrain batch 25/32 - 240.3ms/batch - loss: 25.94752 - diff: 15.74mlTrain batch 26/32 - 242.0ms/batch - loss: 25.37365 - diff: 15.58mlTrain batch 27/32 - 240.9ms/batch - loss: 25.58873 - diff: 15.74mlTrain batch 28/32 - 241.5ms/batch - loss: 25.74277 - diff: 15.90mlTrain batch 29/32 - 240.9ms/batch - loss: 25.68807 - diff: 15.92mlTrain batch 30/32 - 241.6ms/batch - loss: 25.88598 - diff: 16.06mlTrain batch 31/32 - 240.3ms/batch - loss: 25.35144 - diff: 15.87mlTrain batch 32/32 - 79.5ms/batch - loss: 25.92034 - diff: 15.87mlTrain batch 32/32 - 11.3s 79.5ms/batch - loss: 25.92034 - diff: 15.87ml
Test 1.1s: val_loss: 720.91745 - diff: 99.04ml
Epoch   106: reducing learning rate of group 0 to 1.9531e-06.

Epoch 106: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 240.7ms/batch - loss: 6.91547 - diff: 8.59mlTrain batch 2/32 - 241.6ms/batch - loss: 8.69404 - diff: 9.36mlTrain batch 3/32 - 240.6ms/batch - loss: 43.24993 - diff: 17.46mlTrain batch 4/32 - 241.1ms/batch - loss: 37.26346 - diff: 16.79mlTrain batch 5/32 - 240.2ms/batch - loss: 39.31352 - diff: 18.17mlTrain batch 6/32 - 241.6ms/batch - loss: 35.86338 - diff: 17.55mlTrain batch 7/32 - 241.0ms/batch - loss: 34.42551 - diff: 17.42mlTrain batch 8/32 - 241.9ms/batch - loss: 31.84900 - diff: 16.74mlTrain batch 9/32 - 241.1ms/batch - loss: 32.58351 - diff: 17.28mlTrain batch 10/32 - 240.7ms/batch - loss: 30.88965 - diff: 16.87mlTrain batch 11/32 - 240.7ms/batch - loss: 31.02463 - diff: 17.16mlTrain batch 12/32 - 240.6ms/batch - loss: 30.35806 - diff: 16.97mlTrain batch 13/32 - 241.4ms/batch - loss: 33.45920 - diff: 18.03mlTrain batch 14/32 - 240.6ms/batch - loss: 33.22852 - diff: 17.86mlTrain batch 15/32 - 241.2ms/batch - loss: 36.33568 - diff: 18.70mlTrain batch 16/32 - 240.5ms/batch - loss: 34.80374 - diff: 18.30mlTrain batch 17/32 - 241.6ms/batch - loss: 34.46777 - diff: 18.29mlTrain batch 18/32 - 241.7ms/batch - loss: 33.45539 - diff: 17.97mlTrain batch 19/32 - 241.5ms/batch - loss: 32.44606 - diff: 17.66mlTrain batch 20/32 - 241.5ms/batch - loss: 31.45580 - diff: 17.41mlTrain batch 21/32 - 241.2ms/batch - loss: 31.41188 - diff: 17.45mlTrain batch 22/32 - 241.4ms/batch - loss: 30.89405 - diff: 17.36mlTrain batch 23/32 - 240.8ms/batch - loss: 30.15650 - diff: 17.07mlTrain batch 24/32 - 241.2ms/batch - loss: 30.21380 - diff: 17.16mlTrain batch 25/32 - 240.5ms/batch - loss: 30.01419 - diff: 17.11mlTrain batch 26/32 - 240.2ms/batch - loss: 32.29996 - diff: 17.74mlTrain batch 27/32 - 240.5ms/batch - loss: 32.36717 - diff: 17.77mlTrain batch 28/32 - 241.2ms/batch - loss: 32.10338 - diff: 17.71mlTrain batch 29/32 - 241.0ms/batch - loss: 32.86231 - diff: 17.92mlTrain batch 30/32 - 241.4ms/batch - loss: 32.03715 - diff: 17.63mlTrain batch 31/32 - 241.1ms/batch - loss: 32.50863 - diff: 17.81mlTrain batch 32/32 - 79.7ms/batch - loss: 33.68803 - diff: 17.88mlTrain batch 32/32 - 11.4s 79.7ms/batch - loss: 33.68803 - diff: 17.88ml
Test 1.2s: val_loss: 870.11895 - diff: 109.21ml

Epoch 107: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 240.6ms/batch - loss: 21.43363 - diff: 13.36mlTrain batch 2/32 - 241.9ms/batch - loss: 23.57358 - diff: 14.84mlTrain batch 3/32 - 240.8ms/batch - loss: 21.81853 - diff: 14.44mlTrain batch 4/32 - 241.4ms/batch - loss: 25.78854 - diff: 16.42mlTrain batch 5/32 - 240.6ms/batch - loss: 25.55315 - diff: 16.15mlTrain batch 6/32 - 241.0ms/batch - loss: 23.68389 - diff: 15.30mlTrain batch 7/32 - 240.8ms/batch - loss: 24.44352 - diff: 15.60mlTrain batch 8/32 - 241.1ms/batch - loss: 22.93800 - diff: 15.06mlTrain batch 9/32 - 240.8ms/batch - loss: 22.68442 - diff: 15.03mlTrain batch 10/32 - 241.9ms/batch - loss: 22.12591 - diff: 14.73mlTrain batch 11/32 - 240.6ms/batch - loss: 21.80724 - diff: 14.59mlTrain batch 12/32 - 241.0ms/batch - loss: 22.32903 - diff: 14.70mlTrain batch 13/32 - 241.0ms/batch - loss: 23.89900 - diff: 15.37mlTrain batch 14/32 - 241.6ms/batch - loss: 23.04454 - diff: 15.02mlTrain batch 15/32 - 240.5ms/batch - loss: 22.78307 - diff: 14.84mlTrain batch 16/32 - 241.4ms/batch - loss: 23.76412 - diff: 15.19mlTrain batch 17/32 - 240.7ms/batch - loss: 24.69574 - diff: 15.53mlTrain batch 18/32 - 241.5ms/batch - loss: 24.66712 - diff: 15.60mlTrain batch 19/32 - 240.6ms/batch - loss: 25.41001 - diff: 15.90mlTrain batch 20/32 - 241.4ms/batch - loss: 24.61690 - diff: 15.59mlTrain batch 21/32 - 240.9ms/batch - loss: 26.41349 - diff: 16.15mlTrain batch 22/32 - 242.2ms/batch - loss: 25.93129 - diff: 15.99mlTrain batch 23/32 - 241.1ms/batch - loss: 28.99058 - diff: 16.89mlTrain batch 24/32 - 241.7ms/batch - loss: 28.86314 - diff: 16.89mlTrain batch 25/32 - 240.8ms/batch - loss: 28.45801 - diff: 16.82mlTrain batch 26/32 - 241.8ms/batch - loss: 28.43807 - diff: 16.90mlTrain batch 27/32 - 240.5ms/batch - loss: 27.86813 - diff: 16.69mlTrain batch 28/32 - 241.9ms/batch - loss: 27.19720 - diff: 16.44mlTrain batch 29/32 - 241.1ms/batch - loss: 28.72670 - diff: 16.88mlTrain batch 30/32 - 241.5ms/batch - loss: 28.10357 - diff: 16.64mlTrain batch 31/32 - 240.6ms/batch - loss: 28.01669 - diff: 16.61mlTrain batch 32/32 - 79.6ms/batch - loss: 31.48088 - diff: 16.76mlTrain batch 32/32 - 11.9s 79.6ms/batch - loss: 31.48088 - diff: 16.76ml
Test 1.2s: val_loss: 703.38912 - diff: 97.56ml

Epoch 108: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 240.6ms/batch - loss: 20.16649 - diff: 15.38mlTrain batch 2/32 - 241.5ms/batch - loss: 15.22351 - diff: 13.29mlTrain batch 3/32 - 240.6ms/batch - loss: 15.31141 - diff: 12.91mlTrain batch 4/32 - 241.4ms/batch - loss: 23.49146 - diff: 14.90mlTrain batch 5/32 - 240.3ms/batch - loss: 21.66700 - diff: 14.39mlTrain batch 6/32 - 241.5ms/batch - loss: 20.00144 - diff: 13.91mlTrain batch 7/32 - 240.5ms/batch - loss: 23.59829 - diff: 15.28mlTrain batch 8/32 - 241.5ms/batch - loss: 24.53491 - diff: 15.59mlTrain batch 9/32 - 240.1ms/batch - loss: 23.19760 - diff: 15.18mlTrain batch 10/32 - 241.6ms/batch - loss: 32.39239 - diff: 17.79mlTrain batch 11/32 - 240.5ms/batch - loss: 30.34825 - diff: 17.09mlTrain batch 12/32 - 241.4ms/batch - loss: 31.83888 - diff: 17.54mlTrain batch 13/32 - 240.3ms/batch - loss: 30.33904 - diff: 17.11mlTrain batch 14/32 - 241.8ms/batch - loss: 31.51477 - diff: 17.18mlTrain batch 15/32 - 240.5ms/batch - loss: 29.82464 - diff: 16.56mlTrain batch 16/32 - 241.3ms/batch - loss: 30.47505 - diff: 16.89mlTrain batch 17/32 - 240.3ms/batch - loss: 29.40073 - diff: 16.51mlTrain batch 18/32 - 241.8ms/batch - loss: 29.05878 - diff: 16.38mlTrain batch 19/32 - 240.6ms/batch - loss: 28.26497 - diff: 16.08mlTrain batch 20/32 - 241.4ms/batch - loss: 27.67678 - diff: 15.97mlTrain batch 21/32 - 240.5ms/batch - loss: 27.22397 - diff: 15.88mlTrain batch 22/32 - 241.1ms/batch - loss: 26.36542 - diff: 15.58mlTrain batch 23/32 - 240.5ms/batch - loss: 26.12689 - diff: 15.60mlTrain batch 24/32 - 241.6ms/batch - loss: 25.67264 - diff: 15.50mlTrain batch 25/32 - 240.9ms/batch - loss: 26.30847 - diff: 15.80mlTrain batch 26/32 - 241.9ms/batch - loss: 25.71938 - diff: 15.58mlTrain batch 27/32 - 241.1ms/batch - loss: 26.54178 - diff: 15.95mlTrain batch 28/32 - 241.7ms/batch - loss: 27.43378 - diff: 16.30mlTrain batch 29/32 - 241.0ms/batch - loss: 27.16914 - diff: 16.17mlTrain batch 30/32 - 241.6ms/batch - loss: 26.79197 - diff: 16.06mlTrain batch 31/32 - 241.0ms/batch - loss: 28.13288 - diff: 16.53mlTrain batch 32/32 - 78.1ms/batch - loss: 28.35548 - diff: 16.51mlTrain batch 32/32 - 11.6s 78.1ms/batch - loss: 28.35548 - diff: 16.51ml
Test 1.1s: val_loss: 935.31554 - diff: 113.61ml

Epoch 109: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 240.6ms/batch - loss: 13.18785 - diff: 12.08mlTrain batch 2/32 - 241.3ms/batch - loss: 14.46167 - diff: 13.11mlTrain batch 3/32 - 240.6ms/batch - loss: 15.00015 - diff: 12.98mlTrain batch 4/32 - 241.7ms/batch - loss: 16.40982 - diff: 13.46mlTrain batch 5/32 - 240.4ms/batch - loss: 20.83412 - diff: 14.97mlTrain batch 6/32 - 241.5ms/batch - loss: 21.15135 - diff: 14.86mlTrain batch 7/32 - 240.5ms/batch - loss: 21.60498 - diff: 15.04mlTrain batch 8/32 - 241.5ms/batch - loss: 23.40820 - diff: 15.71mlTrain batch 9/32 - 240.6ms/batch - loss: 21.93259 - diff: 15.05mlTrain batch 10/32 - 241.0ms/batch - loss: 20.72763 - diff: 14.54mlTrain batch 11/32 - 241.9ms/batch - loss: 19.78619 - diff: 14.15mlTrain batch 12/32 - 241.6ms/batch - loss: 21.54037 - diff: 14.49mlTrain batch 13/32 - 240.5ms/batch - loss: 20.78880 - diff: 14.22mlTrain batch 14/32 - 241.5ms/batch - loss: 22.92731 - diff: 14.81mlTrain batch 15/32 - 240.4ms/batch - loss: 23.72841 - diff: 15.16mlTrain batch 16/32 - 242.0ms/batch - loss: 24.99142 - diff: 15.69mlTrain batch 17/32 - 240.5ms/batch - loss: 24.67574 - diff: 15.55mlTrain batch 18/32 - 241.9ms/batch - loss: 23.73019 - diff: 15.17mlTrain batch 19/32 - 241.1ms/batch - loss: 23.69689 - diff: 15.26mlTrain batch 20/32 - 241.8ms/batch - loss: 22.79136 - diff: 14.83mlTrain batch 21/32 - 240.7ms/batch - loss: 23.10018 - diff: 14.99mlTrain batch 22/32 - 241.8ms/batch - loss: 22.56489 - diff: 14.71mlTrain batch 23/32 - 241.1ms/batch - loss: 22.20842 - diff: 14.60mlTrain batch 24/32 - 241.8ms/batch - loss: 22.36628 - diff: 14.76mlTrain batch 25/32 - 240.8ms/batch - loss: 22.52369 - diff: 14.83mlTrain batch 26/32 - 241.7ms/batch - loss: 23.21035 - diff: 15.02mlTrain batch 27/32 - 241.6ms/batch - loss: 22.64206 - diff: 14.78mlTrain batch 28/32 - 241.2ms/batch - loss: 23.83909 - diff: 15.24mlTrain batch 29/32 - 241.3ms/batch - loss: 23.67324 - diff: 15.21mlTrain batch 30/32 - 241.6ms/batch - loss: 23.41560 - diff: 15.09mlTrain batch 31/32 - 240.9ms/batch - loss: 23.63751 - diff: 15.25mlTrain batch 32/32 - 79.1ms/batch - loss: 25.36575 - diff: 15.36mlTrain batch 32/32 - 11.4s 79.1ms/batch - loss: 25.36575 - diff: 15.36ml
Test 1.1s: val_loss: 829.31156 - diff: 105.47ml

Epoch 110: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 240.4ms/batch - loss: 46.91689 - diff: 24.06mlTrain batch 2/32 - 241.8ms/batch - loss: 25.58300 - diff: 15.72mlTrain batch 3/32 - 240.5ms/batch - loss: 30.87333 - diff: 15.85mlTrain batch 4/32 - 241.7ms/batch - loss: 31.43107 - diff: 16.44mlTrain batch 5/32 - 240.5ms/batch - loss: 28.59880 - diff: 16.07mlTrain batch 6/32 - 241.2ms/batch - loss: 26.31141 - diff: 15.61mlTrain batch 7/32 - 240.5ms/batch - loss: 24.39157 - diff: 15.03mlTrain batch 8/32 - 241.8ms/batch - loss: 26.39483 - diff: 15.79mlTrain batch 9/32 - 240.7ms/batch - loss: 26.84894 - diff: 16.13mlTrain batch 10/32 - 241.7ms/batch - loss: 27.58693 - diff: 16.17mlTrain batch 11/32 - 240.8ms/batch - loss: 26.41382 - diff: 15.87mlTrain batch 12/32 - 241.1ms/batch - loss: 25.27480 - diff: 15.58mlTrain batch 13/32 - 240.4ms/batch - loss: 24.53233 - diff: 15.45mlTrain batch 14/32 - 241.1ms/batch - loss: 24.89349 - diff: 15.51mlTrain batch 15/32 - 241.2ms/batch - loss: 24.61079 - diff: 15.45mlTrain batch 16/32 - 241.4ms/batch - loss: 23.77287 - diff: 15.14mlTrain batch 17/32 - 240.8ms/batch - loss: 23.17204 - diff: 14.95mlTrain batch 18/32 - 241.4ms/batch - loss: 23.61804 - diff: 15.14mlTrain batch 19/32 - 241.0ms/batch - loss: 23.01076 - diff: 14.96mlTrain batch 20/32 - 241.6ms/batch - loss: 22.27604 - diff: 14.71mlTrain batch 21/32 - 241.3ms/batch - loss: 22.16172 - diff: 14.71mlTrain batch 22/32 - 241.7ms/batch - loss: 21.79425 - diff: 14.61mlTrain batch 23/32 - 240.8ms/batch - loss: 21.51958 - diff: 14.54mlTrain batch 24/32 - 241.9ms/batch - loss: 20.99263 - diff: 14.31mlTrain batch 25/32 - 241.0ms/batch - loss: 21.27565 - diff: 14.44mlTrain batch 26/32 - 241.8ms/batch - loss: 21.67473 - diff: 14.68mlTrain batch 27/32 - 240.5ms/batch - loss: 21.45799 - diff: 14.63mlTrain batch 28/32 - 241.8ms/batch - loss: 21.25114 - diff: 14.56mlTrain batch 29/32 - 240.6ms/batch - loss: 21.18093 - diff: 14.56mlTrain batch 30/32 - 241.2ms/batch - loss: 21.31877 - diff: 14.60mlTrain batch 31/32 - 240.7ms/batch - loss: 21.20191 - diff: 14.53mlTrain batch 32/32 - 78.1ms/batch - loss: 22.50236 - diff: 14.57mlTrain batch 32/32 - 11.5s 78.1ms/batch - loss: 22.50236 - diff: 14.57ml
Test 1.1s: val_loss: 758.96555 - diff: 101.09ml

Epoch 111: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 240.6ms/batch - loss: 19.82436 - diff: 14.85mlTrain batch 2/32 - 241.4ms/batch - loss: 35.53250 - diff: 20.52mlTrain batch 3/32 - 240.7ms/batch - loss: 26.09769 - diff: 16.70mlTrain batch 4/32 - 241.9ms/batch - loss: 29.96639 - diff: 17.19mlTrain batch 5/32 - 240.9ms/batch - loss: 32.81281 - diff: 18.81mlTrain batch 6/32 - 242.0ms/batch - loss: 33.43855 - diff: 18.33mlTrain batch 7/32 - 241.2ms/batch - loss: 31.98875 - diff: 17.98mlTrain batch 8/32 - 241.7ms/batch - loss: 31.53162 - diff: 17.92mlTrain batch 9/32 - 240.6ms/batch - loss: 29.35751 - diff: 17.06mlTrain batch 10/32 - 241.7ms/batch - loss: 27.50116 - diff: 16.40mlTrain batch 11/32 - 240.7ms/batch - loss: 26.47132 - diff: 16.01mlTrain batch 12/32 - 241.7ms/batch - loss: 33.24818 - diff: 18.00mlTrain batch 13/32 - 240.4ms/batch - loss: 34.79706 - diff: 18.47mlTrain batch 14/32 - 241.8ms/batch - loss: 35.24469 - diff: 18.71mlTrain batch 15/32 - 240.5ms/batch - loss: 37.34761 - diff: 19.50mlTrain batch 16/32 - 241.7ms/batch - loss: 35.68193 - diff: 18.92mlTrain batch 17/32 - 241.1ms/batch - loss: 36.68063 - diff: 19.38mlTrain batch 18/32 - 241.8ms/batch - loss: 35.76787 - diff: 19.06mlTrain batch 19/32 - 241.1ms/batch - loss: 37.89553 - diff: 19.67mlTrain batch 20/32 - 241.8ms/batch - loss: 37.12177 - diff: 19.45mlTrain batch 21/32 - 240.7ms/batch - loss: 35.98279 - diff: 19.12mlTrain batch 22/32 - 241.3ms/batch - loss: 36.24479 - diff: 19.29mlTrain batch 23/32 - 240.9ms/batch - loss: 35.43079 - diff: 19.05mlTrain batch 24/32 - 241.5ms/batch - loss: 35.05363 - diff: 18.92mlTrain batch 25/32 - 240.7ms/batch - loss: 33.90331 - diff: 18.51mlTrain batch 26/32 - 241.8ms/batch - loss: 33.36925 - diff: 18.38mlTrain batch 27/32 - 241.1ms/batch - loss: 32.35229 - diff: 18.00mlTrain batch 28/32 - 242.0ms/batch - loss: 31.37910 - diff: 17.60mlTrain batch 29/32 - 240.9ms/batch - loss: 31.25188 - diff: 17.57mlTrain batch 30/32 - 241.1ms/batch - loss: 30.92976 - diff: 17.41mlTrain batch 31/32 - 241.0ms/batch - loss: 30.36897 - diff: 17.24mlTrain batch 32/32 - 79.6ms/batch - loss: 33.13362 - diff: 17.38mlTrain batch 32/32 - 11.9s 79.6ms/batch - loss: 33.13362 - diff: 17.38ml
Test 1.2s: val_loss: 829.40115 - diff: 106.12ml

Epoch 112: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 240.5ms/batch - loss: 32.39245 - diff: 20.26mlTrain batch 2/32 - 241.6ms/batch - loss: 56.93000 - diff: 25.98mlTrain batch 3/32 - 240.4ms/batch - loss: 53.16067 - diff: 24.73mlTrain batch 4/32 - 241.3ms/batch - loss: 45.30408 - diff: 22.40mlTrain batch 5/32 - 240.6ms/batch - loss: 39.68334 - diff: 20.14mlTrain batch 6/32 - 241.7ms/batch - loss: 35.62676 - diff: 18.75mlTrain batch 7/32 - 240.6ms/batch - loss: 39.22154 - diff: 19.97mlTrain batch 8/32 - 243.0ms/batch - loss: 36.88258 - diff: 19.15mlTrain batch 9/32 - 240.5ms/batch - loss: 35.97609 - diff: 19.02mlTrain batch 10/32 - 241.6ms/batch - loss: 37.92420 - diff: 19.92mlTrain batch 11/32 - 240.6ms/batch - loss: 37.00663 - diff: 19.71mlTrain batch 12/32 - 241.8ms/batch - loss: 34.60350 - diff: 18.80mlTrain batch 13/32 - 240.4ms/batch - loss: 35.33814 - diff: 19.07mlTrain batch 14/32 - 241.4ms/batch - loss: 34.61661 - diff: 18.83mlTrain batch 15/32 - 241.0ms/batch - loss: 33.41690 - diff: 18.53mlTrain batch 16/32 - 241.5ms/batch - loss: 33.46046 - diff: 18.65mlTrain batch 17/32 - 241.3ms/batch - loss: 32.43971 - diff: 18.31mlTrain batch 18/32 - 241.9ms/batch - loss: 32.64778 - diff: 18.39mlTrain batch 19/32 - 241.0ms/batch - loss: 31.33091 - diff: 17.84mlTrain batch 20/32 - 241.8ms/batch - loss: 32.77379 - diff: 18.38mlTrain batch 21/32 - 240.6ms/batch - loss: 31.88656 - diff: 18.13mlTrain batch 22/32 - 241.4ms/batch - loss: 30.96049 - diff: 17.83mlTrain batch 23/32 - 240.7ms/batch - loss: 30.09544 - diff: 17.56mlTrain batch 24/32 - 241.9ms/batch - loss: 32.43387 - diff: 18.23mlTrain batch 25/32 - 240.9ms/batch - loss: 31.71451 - diff: 17.98mlTrain batch 26/32 - 241.8ms/batch - loss: 35.49299 - diff: 18.90mlTrain batch 27/32 - 240.8ms/batch - loss: 34.67010 - diff: 18.63mlTrain batch 28/32 - 241.5ms/batch - loss: 34.36530 - diff: 18.54mlTrain batch 29/32 - 240.8ms/batch - loss: 33.46846 - diff: 18.25mlTrain batch 30/32 - 241.5ms/batch - loss: 33.11836 - diff: 18.04mlTrain batch 31/32 - 240.9ms/batch - loss: 33.41061 - diff: 18.19mlTrain batch 32/32 - 79.3ms/batch - loss: 33.59258 - diff: 18.15mlTrain batch 32/32 - 11.4s 79.3ms/batch - loss: 33.59258 - diff: 18.15ml
Test 1.1s: val_loss: 848.27263 - diff: 107.59ml

Epoch 113: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 240.8ms/batch - loss: 30.94160 - diff: 18.35mlTrain batch 2/32 - 241.8ms/batch - loss: 38.31259 - diff: 20.89mlTrain batch 3/32 - 240.4ms/batch - loss: 28.66969 - diff: 16.81mlTrain batch 4/32 - 241.3ms/batch - loss: 24.27964 - diff: 14.94mlTrain batch 5/32 - 240.7ms/batch - loss: 22.68536 - diff: 14.62mlTrain batch 6/32 - 243.1ms/batch - loss: 25.52270 - diff: 15.85mlTrain batch 7/32 - 240.6ms/batch - loss: 25.29168 - diff: 15.64mlTrain batch 8/32 - 240.8ms/batch - loss: 25.55500 - diff: 15.97mlTrain batch 9/32 - 240.8ms/batch - loss: 24.75342 - diff: 15.83mlTrain batch 10/32 - 241.4ms/batch - loss: 23.24931 - diff: 15.28mlTrain batch 11/32 - 241.1ms/batch - loss: 23.27781 - diff: 15.32mlTrain batch 12/32 - 241.9ms/batch - loss: 22.20564 - diff: 14.88mlTrain batch 13/32 - 240.4ms/batch - loss: 25.90743 - diff: 16.06mlTrain batch 14/32 - 241.3ms/batch - loss: 24.93514 - diff: 15.73mlTrain batch 15/32 - 240.6ms/batch - loss: 25.39424 - diff: 15.90mlTrain batch 16/32 - 242.0ms/batch - loss: 29.67425 - diff: 17.00mlTrain batch 17/32 - 240.9ms/batch - loss: 29.16034 - diff: 16.89mlTrain batch 18/32 - 244.0ms/batch - loss: 28.38942 - diff: 16.47mlTrain batch 19/32 - 240.6ms/batch - loss: 28.43990 - diff: 16.48mlTrain batch 20/32 - 241.3ms/batch - loss: 27.58544 - diff: 16.21mlTrain batch 21/32 - 240.9ms/batch - loss: 26.99007 - diff: 16.04mlTrain batch 22/32 - 242.1ms/batch - loss: 26.33279 - diff: 15.88mlTrain batch 23/32 - 241.1ms/batch - loss: 25.72492 - diff: 15.63mlTrain batch 24/32 - 241.7ms/batch - loss: 25.13482 - diff: 15.44mlTrain batch 25/32 - 241.1ms/batch - loss: 25.71718 - diff: 15.76mlTrain batch 26/32 - 241.5ms/batch - loss: 25.31031 - diff: 15.69mlTrain batch 27/32 - 241.0ms/batch - loss: 24.97327 - diff: 15.60mlTrain batch 28/32 - 241.9ms/batch - loss: 25.83265 - diff: 15.93mlTrain batch 29/32 - 240.7ms/batch - loss: 25.32414 - diff: 15.76mlTrain batch 30/32 - 241.7ms/batch - loss: 24.90715 - diff: 15.64mlTrain batch 31/32 - 240.9ms/batch - loss: 24.54356 - diff: 15.53mlTrain batch 32/32 - 78.4ms/batch - loss: 24.91348 - diff: 15.54mlTrain batch 32/32 - 12.0s 78.4ms/batch - loss: 24.91348 - diff: 15.54ml
Test 1.1s: val_loss: 748.95072 - diff: 100.45ml

Epoch 114: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 240.6ms/batch - loss: 26.50725 - diff: 18.45mlTrain batch 2/32 - 241.8ms/batch - loss: 24.20396 - diff: 17.14mlTrain batch 3/32 - 240.9ms/batch - loss: 27.05010 - diff: 18.01mlTrain batch 4/32 - 241.5ms/batch - loss: 22.25356 - diff: 15.74mlTrain batch 5/32 - 240.8ms/batch - loss: 18.95653 - diff: 14.14mlTrain batch 6/32 - 241.2ms/batch - loss: 24.47490 - diff: 15.84mlTrain batch 7/32 - 240.8ms/batch - loss: 25.03448 - diff: 16.22mlTrain batch 8/32 - 241.9ms/batch - loss: 23.28127 - diff: 15.53mlTrain batch 9/32 - 240.8ms/batch - loss: 22.06268 - diff: 15.01mlTrain batch 10/32 - 242.1ms/batch - loss: 21.60292 - diff: 14.96mlTrain batch 11/32 - 241.1ms/batch - loss: 25.04526 - diff: 16.08mlTrain batch 12/32 - 241.7ms/batch - loss: 30.38342 - diff: 17.67mlTrain batch 13/32 - 240.9ms/batch - loss: 29.98980 - diff: 17.63mlTrain batch 14/32 - 240.8ms/batch - loss: 30.08797 - diff: 17.83mlTrain batch 15/32 - 241.4ms/batch - loss: 28.86881 - diff: 17.35mlTrain batch 16/32 - 241.0ms/batch - loss: 27.85718 - diff: 16.97mlTrain batch 17/32 - 241.1ms/batch - loss: 26.53697 - diff: 16.43mlTrain batch 18/32 - 240.2ms/batch - loss: 26.41523 - diff: 16.42mlTrain batch 19/32 - 241.7ms/batch - loss: 26.14512 - diff: 16.41mlTrain batch 20/32 - 240.8ms/batch - loss: 25.36493 - diff: 16.16mlTrain batch 21/32 - 241.7ms/batch - loss: 27.15444 - diff: 16.71mlTrain batch 22/32 - 240.6ms/batch - loss: 26.52095 - diff: 16.49mlTrain batch 23/32 - 241.6ms/batch - loss: 25.84656 - diff: 16.24mlTrain batch 24/32 - 240.6ms/batch - loss: 25.00415 - diff: 15.87mlTrain batch 25/32 - 241.9ms/batch - loss: 24.85067 - diff: 15.77mlTrain batch 26/32 - 240.7ms/batch - loss: 24.07417 - diff: 15.45mlTrain batch 27/32 - 241.5ms/batch - loss: 23.62165 - diff: 15.28mlTrain batch 28/32 - 240.6ms/batch - loss: 23.66002 - diff: 15.32mlTrain batch 29/32 - 241.8ms/batch - loss: 23.93171 - diff: 15.38mlTrain batch 30/32 - 240.8ms/batch - loss: 24.33729 - diff: 15.54mlTrain batch 31/32 - 242.5ms/batch - loss: 24.27088 - diff: 15.58mlTrain batch 32/32 - 79.5ms/batch - loss: 25.62979 - diff: 15.65mlTrain batch 32/32 - 11.5s 79.5ms/batch - loss: 25.62979 - diff: 15.65ml
Test 1.1s: val_loss: 749.04104 - diff: 100.91ml

Epoch 115: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 240.8ms/batch - loss: 52.80348 - diff: 25.03mlTrain batch 2/32 - 241.8ms/batch - loss: 30.30120 - diff: 17.21mlTrain batch 3/32 - 241.0ms/batch - loss: 24.30063 - diff: 15.14mlTrain batch 4/32 - 242.2ms/batch - loss: 26.76772 - diff: 16.43mlTrain batch 5/32 - 240.5ms/batch - loss: 24.78508 - diff: 15.82mlTrain batch 6/32 - 240.8ms/batch - loss: 24.62068 - diff: 15.72mlTrain batch 7/32 - 241.1ms/batch - loss: 26.04497 - diff: 16.32mlTrain batch 8/32 - 241.8ms/batch - loss: 26.23866 - diff: 16.52mlTrain batch 9/32 - 240.6ms/batch - loss: 25.83418 - diff: 16.41mlTrain batch 10/32 - 241.5ms/batch - loss: 24.41792 - diff: 15.98mlTrain batch 11/32 - 241.1ms/batch - loss: 23.87793 - diff: 15.81mlTrain batch 12/32 - 241.9ms/batch - loss: 23.55916 - diff: 15.75mlTrain batch 13/32 - 240.7ms/batch - loss: 23.30898 - diff: 15.62mlTrain batch 14/32 - 241.4ms/batch - loss: 22.23997 - diff: 15.17mlTrain batch 15/32 - 240.8ms/batch - loss: 22.08727 - diff: 15.14mlTrain batch 16/32 - 241.7ms/batch - loss: 23.19487 - diff: 15.60mlTrain batch 17/32 - 241.3ms/batch - loss: 22.95779 - diff: 15.53mlTrain batch 18/32 - 241.1ms/batch - loss: 24.01545 - diff: 15.99mlTrain batch 19/32 - 240.6ms/batch - loss: 23.91244 - diff: 15.88mlTrain batch 20/32 - 242.4ms/batch - loss: 23.24024 - diff: 15.63mlTrain batch 21/32 - 240.8ms/batch - loss: 22.87303 - diff: 15.49mlTrain batch 22/32 - 241.6ms/batch - loss: 22.67975 - diff: 15.35mlTrain batch 23/32 - 240.7ms/batch - loss: 22.25501 - diff: 15.22mlTrain batch 24/32 - 242.1ms/batch - loss: 21.93341 - diff: 15.11mlTrain batch 25/32 - 240.7ms/batch - loss: 22.63803 - diff: 15.37mlTrain batch 26/32 - 241.6ms/batch - loss: 22.33123 - diff: 15.25mlTrain batch 27/32 - 240.8ms/batch - loss: 21.63309 - diff: 14.92mlTrain batch 28/32 - 241.0ms/batch - loss: 21.32717 - diff: 14.83mlTrain batch 29/32 - 241.1ms/batch - loss: 21.36113 - diff: 14.88mlTrain batch 30/32 - 241.8ms/batch - loss: 21.70291 - diff: 15.00mlTrain batch 31/32 - 240.8ms/batch - loss: 21.63605 - diff: 14.96mlTrain batch 32/32 - 79.1ms/batch - loss: 24.90233 - diff: 15.14mlTrain batch 32/32 - 12.1s 79.1ms/batch - loss: 24.90233 - diff: 15.14ml
Test 1.1s: val_loss: 602.09085 - diff: 89.58ml

Epoch 116: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 241.9ms/batch - loss: 114.99544 - diff: 38.53mlTrain batch 2/32 - 241.5ms/batch - loss: 70.89707 - diff: 28.77mlTrain batch 3/32 - 240.5ms/batch - loss: 50.50147 - diff: 22.41mlTrain batch 4/32 - 240.7ms/batch - loss: 41.91889 - diff: 20.41mlTrain batch 5/32 - 241.6ms/batch - loss: 38.59280 - diff: 19.71mlTrain batch 6/32 - 240.7ms/batch - loss: 42.14608 - diff: 20.86mlTrain batch 7/32 - 241.4ms/batch - loss: 40.05588 - diff: 20.16mlTrain batch 8/32 - 240.5ms/batch - loss: 36.65403 - diff: 19.16mlTrain batch 9/32 - 241.2ms/batch - loss: 34.83812 - diff: 18.65mlTrain batch 10/32 - 241.0ms/batch - loss: 32.32329 - diff: 17.70mlTrain batch 11/32 - 240.6ms/batch - loss: 31.69113 - diff: 17.71mlTrain batch 12/32 - 241.3ms/batch - loss: 29.84947 - diff: 17.10mlTrain batch 13/32 - 240.5ms/batch - loss: 32.92771 - diff: 18.23mlTrain batch 14/32 - 241.8ms/batch - loss: 32.45870 - diff: 17.98mlTrain batch 15/32 - 240.5ms/batch - loss: 31.43894 - diff: 17.58mlTrain batch 16/32 - 241.6ms/batch - loss: 32.58295 - diff: 18.02mlTrain batch 17/32 - 240.9ms/batch - loss: 31.39026 - diff: 17.64mlTrain batch 18/32 - 241.3ms/batch - loss: 31.90543 - diff: 17.84mlTrain batch 19/32 - 241.1ms/batch - loss: 31.90389 - diff: 17.82mlTrain batch 20/32 - 242.0ms/batch - loss: 31.47951 - diff: 17.73mlTrain batch 21/32 - 240.7ms/batch - loss: 30.95930 - diff: 17.59mlTrain batch 22/32 - 241.6ms/batch - loss: 30.73889 - diff: 17.57mlTrain batch 23/32 - 240.8ms/batch - loss: 31.00374 - diff: 17.72mlTrain batch 24/32 - 241.7ms/batch - loss: 30.82604 - diff: 17.69mlTrain batch 25/32 - 240.8ms/batch - loss: 30.44133 - diff: 17.64mlTrain batch 26/32 - 242.1ms/batch - loss: 30.07832 - diff: 17.56mlTrain batch 27/32 - 240.6ms/batch - loss: 29.87743 - diff: 17.58mlTrain batch 28/32 - 241.5ms/batch - loss: 29.24494 - diff: 17.35mlTrain batch 29/32 - 240.4ms/batch - loss: 29.18336 - diff: 17.25mlTrain batch 30/32 - 241.3ms/batch - loss: 28.56441 - diff: 17.03mlTrain batch 31/32 - 241.2ms/batch - loss: 28.64460 - diff: 17.07mlTrain batch 32/32 - 79.6ms/batch - loss: 30.71798 - diff: 17.18mlTrain batch 32/32 - 12.2s 79.6ms/batch - loss: 30.71798 - diff: 17.18ml
Test 1.2s: val_loss: 767.79251 - diff: 101.65ml
Epoch   117: reducing learning rate of group 0 to 9.7656e-07.

Epoch 117: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 240.6ms/batch - loss: 13.25410 - diff: 11.97mlTrain batch 2/32 - 241.2ms/batch - loss: 18.40757 - diff: 13.54mlTrain batch 3/32 - 240.3ms/batch - loss: 24.23337 - diff: 15.78mlTrain batch 4/32 - 241.6ms/batch - loss: 22.36986 - diff: 15.09mlTrain batch 5/32 - 240.4ms/batch - loss: 20.99783 - diff: 14.39mlTrain batch 6/32 - 241.7ms/batch - loss: 20.93369 - diff: 14.37mlTrain batch 7/32 - 240.8ms/batch - loss: 20.49354 - diff: 14.46mlTrain batch 8/32 - 241.7ms/batch - loss: 20.05163 - diff: 14.31mlTrain batch 9/32 - 241.0ms/batch - loss: 22.43922 - diff: 15.22mlTrain batch 10/32 - 241.4ms/batch - loss: 21.81949 - diff: 14.87mlTrain batch 11/32 - 240.9ms/batch - loss: 20.52762 - diff: 14.35mlTrain batch 12/32 - 241.3ms/batch - loss: 20.51962 - diff: 14.46mlTrain batch 13/32 - 240.8ms/batch - loss: 19.85216 - diff: 14.18mlTrain batch 14/32 - 241.1ms/batch - loss: 19.60799 - diff: 14.22mlTrain batch 15/32 - 241.2ms/batch - loss: 18.79447 - diff: 13.88mlTrain batch 16/32 - 241.0ms/batch - loss: 18.62924 - diff: 13.74mlTrain batch 17/32 - 241.4ms/batch - loss: 19.58019 - diff: 14.07mlTrain batch 18/32 - 240.2ms/batch - loss: 20.09015 - diff: 14.36mlTrain batch 19/32 - 241.3ms/batch - loss: 20.14365 - diff: 14.38mlTrain batch 20/32 - 240.5ms/batch - loss: 19.63616 - diff: 14.15mlTrain batch 21/32 - 240.8ms/batch - loss: 21.29275 - diff: 14.71mlTrain batch 22/32 - 241.4ms/batch - loss: 20.83468 - diff: 14.48mlTrain batch 23/32 - 241.0ms/batch - loss: 20.42162 - diff: 14.32mlTrain batch 24/32 - 241.7ms/batch - loss: 19.82556 - diff: 14.09mlTrain batch 25/32 - 240.3ms/batch - loss: 20.94403 - diff: 14.54mlTrain batch 26/32 - 241.7ms/batch - loss: 20.67814 - diff: 14.45mlTrain batch 27/32 - 240.9ms/batch - loss: 20.03375 - diff: 14.13mlTrain batch 28/32 - 241.3ms/batch - loss: 20.26400 - diff: 14.21mlTrain batch 29/32 - 240.4ms/batch - loss: 20.11560 - diff: 14.12mlTrain batch 30/32 - 241.4ms/batch - loss: 22.18943 - diff: 14.77mlTrain batch 31/32 - 240.3ms/batch - loss: 22.29997 - diff: 14.82mlTrain batch 32/32 - 78.5ms/batch - loss: 23.59526 - diff: 14.88mlTrain batch 32/32 - 12.4s 78.5ms/batch - loss: 23.59526 - diff: 14.88ml
Test 1.1s: val_loss: 877.71032 - diff: 108.88ml

Epoch 118: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 240.3ms/batch - loss: 59.79455 - diff: 27.85mlTrain batch 2/32 - 241.5ms/batch - loss: 34.15689 - diff: 18.64mlTrain batch 3/32 - 240.5ms/batch - loss: 32.11988 - diff: 18.46mlTrain batch 4/32 - 241.7ms/batch - loss: 27.37338 - diff: 16.75mlTrain batch 5/32 - 240.2ms/batch - loss: 24.70228 - diff: 15.73mlTrain batch 6/32 - 241.8ms/batch - loss: 22.02242 - diff: 14.79mlTrain batch 7/32 - 240.6ms/batch - loss: 20.54409 - diff: 14.14mlTrain batch 8/32 - 241.7ms/batch - loss: 19.43290 - diff: 13.59mlTrain batch 9/32 - 240.7ms/batch - loss: 19.87561 - diff: 13.91mlTrain batch 10/32 - 241.5ms/batch - loss: 19.80627 - diff: 13.98mlTrain batch 11/32 - 240.9ms/batch - loss: 21.10116 - diff: 14.55mlTrain batch 12/32 - 241.6ms/batch - loss: 20.49410 - diff: 14.32mlTrain batch 13/32 - 240.6ms/batch - loss: 19.95681 - diff: 14.09mlTrain batch 14/32 - 241.7ms/batch - loss: 28.53182 - diff: 16.16mlTrain batch 15/32 - 240.8ms/batch - loss: 33.01039 - diff: 17.47mlTrain batch 16/32 - 241.0ms/batch - loss: 32.04687 - diff: 17.22mlTrain batch 17/32 - 240.3ms/batch - loss: 33.08031 - diff: 17.58mlTrain batch 18/32 - 241.6ms/batch - loss: 32.73461 - diff: 17.56mlTrain batch 19/32 - 240.4ms/batch - loss: 31.24593 - diff: 16.98mlTrain batch 20/32 - 241.0ms/batch - loss: 31.91548 - diff: 17.30mlTrain batch 21/32 - 241.2ms/batch - loss: 32.08774 - diff: 17.40mlTrain batch 22/32 - 240.4ms/batch - loss: 31.57877 - diff: 17.31mlTrain batch 23/32 - 241.0ms/batch - loss: 30.80054 - diff: 17.05mlTrain batch 24/32 - 240.7ms/batch - loss: 29.87167 - diff: 16.74mlTrain batch 25/32 - 242.0ms/batch - loss: 29.63797 - diff: 16.60mlTrain batch 26/32 - 241.0ms/batch - loss: 30.98553 - diff: 17.03mlTrain batch 27/32 - 240.8ms/batch - loss: 30.44007 - diff: 16.88mlTrain batch 28/32 - 240.9ms/batch - loss: 29.93982 - diff: 16.76mlTrain batch 29/32 - 240.8ms/batch - loss: 29.74901 - diff: 16.76mlTrain batch 30/32 - 241.7ms/batch - loss: 29.83708 - diff: 16.86mlTrain batch 31/32 - 240.5ms/batch - loss: 29.18402 - diff: 16.65mlTrain batch 32/32 - 79.6ms/batch - loss: 32.37622 - diff: 16.82mlTrain batch 32/32 - 12.1s 79.6ms/batch - loss: 32.37622 - diff: 16.82ml
Test 1.1s: val_loss: 719.63389 - diff: 98.46ml

Epoch 119: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 240.5ms/batch - loss: 30.73675 - diff: 17.63mlTrain batch 2/32 - 241.4ms/batch - loss: 28.95551 - diff: 17.62mlTrain batch 3/32 - 240.2ms/batch - loss: 25.02384 - diff: 16.28mlTrain batch 4/32 - 241.4ms/batch - loss: 21.33125 - diff: 14.63mlTrain batch 5/32 - 240.8ms/batch - loss: 18.11661 - diff: 13.24mlTrain batch 6/32 - 241.5ms/batch - loss: 27.33203 - diff: 16.21mlTrain batch 7/32 - 240.6ms/batch - loss: 25.17790 - diff: 15.57mlTrain batch 8/32 - 241.5ms/batch - loss: 24.20993 - diff: 15.12mlTrain batch 9/32 - 240.3ms/batch - loss: 26.20422 - diff: 16.09mlTrain batch 10/32 - 241.7ms/batch - loss: 24.78011 - diff: 15.59mlTrain batch 11/32 - 240.8ms/batch - loss: 23.25677 - diff: 15.07mlTrain batch 12/32 - 241.0ms/batch - loss: 25.30708 - diff: 15.93mlTrain batch 13/32 - 240.7ms/batch - loss: 23.72753 - diff: 15.27mlTrain batch 14/32 - 240.9ms/batch - loss: 22.97724 - diff: 15.02mlTrain batch 15/32 - 241.0ms/batch - loss: 23.39088 - diff: 15.07mlTrain batch 16/32 - 241.5ms/batch - loss: 23.16155 - diff: 15.08mlTrain batch 17/32 - 241.3ms/batch - loss: 23.06283 - diff: 15.10mlTrain batch 18/32 - 241.9ms/batch - loss: 23.20206 - diff: 14.97mlTrain batch 19/32 - 240.3ms/batch - loss: 22.55607 - diff: 14.76mlTrain batch 20/32 - 241.6ms/batch - loss: 23.46597 - diff: 15.13mlTrain batch 21/32 - 240.9ms/batch - loss: 23.38407 - diff: 15.05mlTrain batch 22/32 - 241.5ms/batch - loss: 22.89513 - diff: 14.92mlTrain batch 23/32 - 241.2ms/batch - loss: 22.81212 - diff: 14.95mlTrain batch 24/32 - 241.9ms/batch - loss: 22.42889 - diff: 14.75mlTrain batch 25/32 - 240.6ms/batch - loss: 23.07939 - diff: 14.97mlTrain batch 26/32 - 241.4ms/batch - loss: 22.78218 - diff: 14.84mlTrain batch 27/32 - 241.1ms/batch - loss: 23.33108 - diff: 15.09mlTrain batch 28/32 - 241.4ms/batch - loss: 23.01319 - diff: 14.97mlTrain batch 29/32 - 240.8ms/batch - loss: 22.39359 - diff: 14.68mlTrain batch 30/32 - 241.1ms/batch - loss: 22.22067 - diff: 14.61mlTrain batch 31/32 - 241.0ms/batch - loss: 21.93669 - diff: 14.49mlTrain batch 32/32 - 79.1ms/batch - loss: 24.30470 - diff: 14.62mlTrain batch 32/32 - 11.2s 79.1ms/batch - loss: 24.30470 - diff: 14.62ml
Test 1.1s: val_loss: 766.58655 - diff: 102.62ml

Epoch 120: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 240.6ms/batch - loss: 22.85853 - diff: 14.55mlTrain batch 2/32 - 241.5ms/batch - loss: 17.96190 - diff: 13.39mlTrain batch 3/32 - 240.8ms/batch - loss: 16.37994 - diff: 13.19mlTrain batch 4/32 - 242.0ms/batch - loss: 13.78876 - diff: 11.86mlTrain batch 5/32 - 240.9ms/batch - loss: 14.13836 - diff: 11.82mlTrain batch 6/32 - 241.0ms/batch - loss: 16.74161 - diff: 13.16mlTrain batch 7/32 - 241.1ms/batch - loss: 16.39312 - diff: 12.98mlTrain batch 8/32 - 240.6ms/batch - loss: 16.73696 - diff: 13.09mlTrain batch 9/32 - 241.9ms/batch - loss: 19.27024 - diff: 14.14mlTrain batch 10/32 - 240.7ms/batch - loss: 23.55290 - diff: 15.52mlTrain batch 11/32 - 241.3ms/batch - loss: 22.48097 - diff: 15.14mlTrain batch 12/32 - 240.4ms/batch - loss: 22.73709 - diff: 15.31mlTrain batch 13/32 - 241.7ms/batch - loss: 22.96262 - diff: 15.33mlTrain batch 14/32 - 240.7ms/batch - loss: 21.84929 - diff: 14.76mlTrain batch 15/32 - 242.2ms/batch - loss: 21.46893 - diff: 14.58mlTrain batch 16/32 - 241.2ms/batch - loss: 20.57322 - diff: 14.20mlTrain batch 17/32 - 241.9ms/batch - loss: 21.07185 - diff: 14.49mlTrain batch 18/32 - 240.5ms/batch - loss: 20.98981 - diff: 14.45mlTrain batch 19/32 - 243.6ms/batch - loss: 21.59961 - diff: 14.73mlTrain batch 20/32 - 240.8ms/batch - loss: 23.15872 - diff: 15.25mlTrain batch 21/32 - 241.4ms/batch - loss: 22.96077 - diff: 15.15mlTrain batch 22/32 - 240.9ms/batch - loss: 23.18274 - diff: 15.32mlTrain batch 23/32 - 241.8ms/batch - loss: 23.67498 - diff: 15.47mlTrain batch 24/32 - 241.2ms/batch - loss: 22.97469 - diff: 15.18mlTrain batch 25/32 - 241.8ms/batch - loss: 22.97584 - diff: 15.18mlTrain batch 26/32 - 240.9ms/batch - loss: 22.84178 - diff: 15.16mlTrain batch 27/32 - 244.6ms/batch - loss: 24.07734 - diff: 15.56mlTrain batch 28/32 - 240.8ms/batch - loss: 23.81394 - diff: 15.40mlTrain batch 29/32 - 242.2ms/batch - loss: 25.85967 - diff: 16.05mlTrain batch 30/32 - 240.8ms/batch - loss: 25.34314 - diff: 15.89mlTrain batch 31/32 - 242.0ms/batch - loss: 26.72417 - diff: 16.34mlTrain batch 32/32 - 78.7ms/batch - loss: 31.12630 - diff: 16.58mlTrain batch 32/32 - 11.9s 78.7ms/batch - loss: 31.12630 - diff: 16.58ml
Test 1.1s: val_loss: 643.69523 - diff: 92.46ml

Epoch 121: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 240.9ms/batch - loss: 14.15709 - diff: 12.58mlTrain batch 2/32 - 242.2ms/batch - loss: 27.99068 - diff: 15.19mlTrain batch 3/32 - 240.3ms/batch - loss: 20.28218 - diff: 12.51mlTrain batch 4/32 - 241.8ms/batch - loss: 27.50532 - diff: 15.47mlTrain batch 5/32 - 241.4ms/batch - loss: 26.25953 - diff: 15.60mlTrain batch 6/32 - 241.6ms/batch - loss: 23.73680 - diff: 14.93mlTrain batch 7/32 - 240.3ms/batch - loss: 22.39391 - diff: 14.62mlTrain batch 8/32 - 241.7ms/batch - loss: 31.05082 - diff: 17.32mlTrain batch 9/32 - 240.2ms/batch - loss: 29.90280 - diff: 16.99mlTrain batch 10/32 - 241.5ms/batch - loss: 30.84246 - diff: 17.57mlTrain batch 11/32 - 240.7ms/batch - loss: 28.63110 - diff: 16.72mlTrain batch 12/32 - 241.5ms/batch - loss: 30.72431 - diff: 17.34mlTrain batch 13/32 - 240.6ms/batch - loss: 29.51327 - diff: 17.00mlTrain batch 14/32 - 241.8ms/batch - loss: 28.69461 - diff: 16.75mlTrain batch 15/32 - 240.7ms/batch - loss: 28.03754 - diff: 16.56mlTrain batch 16/32 - 241.5ms/batch - loss: 28.93060 - diff: 17.00mlTrain batch 17/32 - 240.8ms/batch - loss: 29.57766 - diff: 17.11mlTrain batch 18/32 - 241.7ms/batch - loss: 29.01868 - diff: 16.98mlTrain batch 19/32 - 240.1ms/batch - loss: 28.00366 - diff: 16.62mlTrain batch 20/32 - 241.2ms/batch - loss: 27.26610 - diff: 16.39mlTrain batch 21/32 - 240.7ms/batch - loss: 26.57989 - diff: 16.19mlTrain batch 22/32 - 241.5ms/batch - loss: 26.22332 - diff: 16.11mlTrain batch 23/32 - 240.9ms/batch - loss: 27.49950 - diff: 16.56mlTrain batch 24/32 - 241.6ms/batch - loss: 26.95966 - diff: 16.34mlTrain batch 25/32 - 241.2ms/batch - loss: 27.04896 - diff: 16.46mlTrain batch 26/32 - 241.9ms/batch - loss: 26.50772 - diff: 16.26mlTrain batch 27/32 - 241.1ms/batch - loss: 28.69091 - diff: 16.86mlTrain batch 28/32 - 241.9ms/batch - loss: 28.91388 - diff: 17.00mlTrain batch 29/32 - 240.6ms/batch - loss: 28.51996 - diff: 16.89mlTrain batch 30/32 - 241.4ms/batch - loss: 28.62636 - diff: 17.01mlTrain batch 31/32 - 240.8ms/batch - loss: 28.75938 - diff: 17.10mlTrain batch 32/32 - 79.0ms/batch - loss: 29.19573 - diff: 17.08mlTrain batch 32/32 - 11.8s 79.0ms/batch - loss: 29.19573 - diff: 17.08ml
Test 1.1s: val_loss: 774.83842 - diff: 103.08ml

Epoch 122: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 240.7ms/batch - loss: 13.90788 - diff: 13.16mlTrain batch 2/32 - 241.4ms/batch - loss: 17.99492 - diff: 13.20mlTrain batch 3/32 - 240.5ms/batch - loss: 23.41312 - diff: 15.17mlTrain batch 4/32 - 241.0ms/batch - loss: 28.24255 - diff: 16.86mlTrain batch 5/32 - 241.4ms/batch - loss: 25.05598 - diff: 15.50mlTrain batch 6/32 - 240.4ms/batch - loss: 22.73472 - diff: 14.82mlTrain batch 7/32 - 240.9ms/batch - loss: 23.32199 - diff: 15.19mlTrain batch 8/32 - 240.3ms/batch - loss: 24.95600 - diff: 15.95mlTrain batch 9/32 - 241.8ms/batch - loss: 24.61538 - diff: 15.92mlTrain batch 10/32 - 240.6ms/batch - loss: 23.19785 - diff: 15.28mlTrain batch 11/32 - 241.7ms/batch - loss: 23.12166 - diff: 15.40mlTrain batch 12/32 - 240.4ms/batch - loss: 23.53330 - diff: 15.64mlTrain batch 13/32 - 241.3ms/batch - loss: 22.97973 - diff: 15.47mlTrain batch 14/32 - 240.8ms/batch - loss: 22.69251 - diff: 15.38mlTrain batch 15/32 - 241.8ms/batch - loss: 21.93188 - diff: 15.16mlTrain batch 16/32 - 240.8ms/batch - loss: 22.15016 - diff: 15.24mlTrain batch 17/32 - 241.9ms/batch - loss: 22.60987 - diff: 15.38mlTrain batch 18/32 - 240.8ms/batch - loss: 23.76952 - diff: 15.78mlTrain batch 19/32 - 241.4ms/batch - loss: 24.98936 - diff: 16.26mlTrain batch 20/32 - 241.1ms/batch - loss: 24.73274 - diff: 16.14mlTrain batch 21/32 - 241.4ms/batch - loss: 26.61004 - diff: 16.80mlTrain batch 22/32 - 240.4ms/batch - loss: 25.83448 - diff: 16.47mlTrain batch 23/32 - 241.5ms/batch - loss: 25.21282 - diff: 16.23mlTrain batch 24/32 - 240.7ms/batch - loss: 24.60750 - diff: 16.01mlTrain batch 25/32 - 241.8ms/batch - loss: 23.82933 - diff: 15.67mlTrain batch 26/32 - 240.9ms/batch - loss: 23.27785 - diff: 15.43mlTrain batch 27/32 - 241.8ms/batch - loss: 23.28454 - diff: 15.42mlTrain batch 28/32 - 240.6ms/batch - loss: 22.85921 - diff: 15.19mlTrain batch 29/32 - 240.8ms/batch - loss: 22.77504 - diff: 15.15mlTrain batch 30/32 - 240.6ms/batch - loss: 23.35089 - diff: 15.38mlTrain batch 31/32 - 241.0ms/batch - loss: 24.15151 - diff: 15.71mlTrain batch 32/32 - 79.1ms/batch - loss: 40.64322 - diff: 16.28mlTrain batch 32/32 - 12.1s 79.1ms/batch - loss: 40.64322 - diff: 16.28ml
Test 1.2s: val_loss: 1023.33181 - diff: 119.33ml

Epoch 123: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 240.0ms/batch - loss: 26.73402 - diff: 14.01mlTrain batch 2/32 - 241.5ms/batch - loss: 76.13907 - diff: 27.31mlTrain batch 3/32 - 241.1ms/batch - loss: 60.13083 - diff: 24.63mlTrain batch 4/32 - 241.8ms/batch - loss: 51.36864 - diff: 22.25mlTrain batch 5/32 - 240.8ms/batch - loss: 44.08958 - diff: 20.30mlTrain batch 6/32 - 241.5ms/batch - loss: 39.47894 - diff: 19.21mlTrain batch 7/32 - 241.0ms/batch - loss: 62.94761 - diff: 24.35mlTrain batch 8/32 - 241.6ms/batch - loss: 56.98766 - diff: 23.00mlTrain batch 9/32 - 240.8ms/batch - loss: 51.66092 - diff: 21.53mlTrain batch 10/32 - 241.8ms/batch - loss: 48.29463 - diff: 20.77mlTrain batch 11/32 - 240.9ms/batch - loss: 45.72206 - diff: 20.14mlTrain batch 12/32 - 241.8ms/batch - loss: 45.10559 - diff: 20.02mlTrain batch 13/32 - 240.3ms/batch - loss: 43.39738 - diff: 19.72mlTrain batch 14/32 - 242.1ms/batch - loss: 42.73753 - diff: 19.65mlTrain batch 15/32 - 240.4ms/batch - loss: 40.15489 - diff: 18.79mlTrain batch 16/32 - 241.9ms/batch - loss: 38.12273 - diff: 18.23mlTrain batch 17/32 - 240.8ms/batch - loss: 36.57187 - diff: 17.83mlTrain batch 18/32 - 241.9ms/batch - loss: 35.98522 - diff: 17.78mlTrain batch 19/32 - 240.3ms/batch - loss: 35.20431 - diff: 17.71mlTrain batch 20/32 - 241.2ms/batch - loss: 34.24787 - diff: 17.50mlTrain batch 21/32 - 240.2ms/batch - loss: 34.39297 - diff: 17.68mlTrain batch 22/32 - 241.3ms/batch - loss: 35.14809 - diff: 18.00mlTrain batch 23/32 - 241.0ms/batch - loss: 34.00440 - diff: 17.63mlTrain batch 24/32 - 241.5ms/batch - loss: 34.01985 - diff: 17.77mlTrain batch 25/32 - 240.5ms/batch - loss: 33.50904 - diff: 17.63mlTrain batch 26/32 - 241.6ms/batch - loss: 32.97889 - diff: 17.49mlTrain batch 27/32 - 241.0ms/batch - loss: 32.20180 - diff: 17.28mlTrain batch 28/32 - 242.0ms/batch - loss: 31.76331 - diff: 17.17mlTrain batch 29/32 - 240.9ms/batch - loss: 31.61936 - diff: 17.21mlTrain batch 30/32 - 241.6ms/batch - loss: 31.17469 - diff: 17.14mlTrain batch 31/32 - 240.5ms/batch - loss: 30.48855 - diff: 16.90mlTrain batch 32/32 - 79.1ms/batch - loss: 31.01569 - diff: 16.92mlTrain batch 32/32 - 12.0s 79.1ms/batch - loss: 31.01569 - diff: 16.92ml
Test 1.1s: val_loss: 982.42776 - diff: 114.83ml

Epoch 124: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 240.5ms/batch - loss: 6.62513 - diff: 8.74mlTrain batch 2/32 - 241.7ms/batch - loss: 13.62726 - diff: 12.08mlTrain batch 3/32 - 240.9ms/batch - loss: 13.01571 - diff: 11.73mlTrain batch 4/32 - 241.2ms/batch - loss: 13.60315 - diff: 12.01mlTrain batch 5/32 - 240.9ms/batch - loss: 11.97033 - diff: 11.20mlTrain batch 6/32 - 242.0ms/batch - loss: 13.75997 - diff: 12.12mlTrain batch 7/32 - 241.4ms/batch - loss: 23.83872 - diff: 15.19mlTrain batch 8/32 - 241.8ms/batch - loss: 22.60021 - diff: 14.67mlTrain batch 9/32 - 240.5ms/batch - loss: 26.12949 - diff: 15.92mlTrain batch 10/32 - 241.2ms/batch - loss: 27.21020 - diff: 16.50mlTrain batch 11/32 - 240.5ms/batch - loss: 26.76802 - diff: 16.44mlTrain batch 12/32 - 241.9ms/batch - loss: 26.54282 - diff: 16.45mlTrain batch 13/32 - 240.6ms/batch - loss: 26.95059 - diff: 16.70mlTrain batch 14/32 - 241.8ms/batch - loss: 27.06172 - diff: 16.80mlTrain batch 15/32 - 240.6ms/batch - loss: 25.99134 - diff: 16.40mlTrain batch 16/32 - 241.8ms/batch - loss: 25.02644 - diff: 16.09mlTrain batch 17/32 - 240.9ms/batch - loss: 24.19314 - diff: 15.72mlTrain batch 18/32 - 241.1ms/batch - loss: 26.03120 - diff: 16.38mlTrain batch 19/32 - 240.4ms/batch - loss: 25.45081 - diff: 16.21mlTrain batch 20/32 - 241.5ms/batch - loss: 24.61236 - diff: 15.86mlTrain batch 21/32 - 241.0ms/batch - loss: 29.10416 - diff: 16.95mlTrain batch 22/32 - 241.1ms/batch - loss: 32.78757 - diff: 17.91mlTrain batch 23/32 - 240.8ms/batch - loss: 32.90629 - diff: 18.00mlTrain batch 24/32 - 242.0ms/batch - loss: 35.09955 - diff: 18.71mlTrain batch 25/32 - 241.0ms/batch - loss: 34.34240 - diff: 18.48mlTrain batch 26/32 - 242.0ms/batch - loss: 33.92648 - diff: 18.31mlTrain batch 27/32 - 241.2ms/batch - loss: 34.66037 - diff: 18.62mlTrain batch 28/32 - 242.4ms/batch - loss: 34.46659 - diff: 18.57mlTrain batch 29/32 - 240.8ms/batch - loss: 33.84438 - diff: 18.34mlTrain batch 30/32 - 241.5ms/batch - loss: 34.36518 - diff: 18.59mlTrain batch 31/32 - 240.7ms/batch - loss: 34.25361 - diff: 18.66mlTrain batch 32/32 - 78.0ms/batch - loss: 36.68369 - diff: 18.78mlTrain batch 32/32 - 11.2s 78.0ms/batch - loss: 36.68369 - diff: 18.78ml
Test 1.2s: val_loss: 837.96564 - diff: 107.88ml

Epoch 125: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 240.8ms/batch - loss: 19.92429 - diff: 13.85mlTrain batch 2/32 - 241.3ms/batch - loss: 15.91722 - diff: 12.37mlTrain batch 3/32 - 240.2ms/batch - loss: 16.62541 - diff: 12.84mlTrain batch 4/32 - 241.8ms/batch - loss: 15.13560 - diff: 12.46mlTrain batch 5/32 - 240.6ms/batch - loss: 24.65516 - diff: 15.72mlTrain batch 6/32 - 241.1ms/batch - loss: 22.50150 - diff: 15.09mlTrain batch 7/32 - 240.3ms/batch - loss: 33.51424 - diff: 17.75mlTrain batch 8/32 - 241.1ms/batch - loss: 35.13201 - diff: 18.50mlTrain batch 9/32 - 240.8ms/batch - loss: 34.27171 - diff: 18.27mlTrain batch 10/32 - 241.9ms/batch - loss: 32.71218 - diff: 17.81mlTrain batch 11/32 - 240.4ms/batch - loss: 30.73306 - diff: 16.96mlTrain batch 12/32 - 241.5ms/batch - loss: 31.68692 - diff: 17.49mlTrain batch 13/32 - 240.5ms/batch - loss: 30.80012 - diff: 17.28mlTrain batch 14/32 - 241.6ms/batch - loss: 30.94820 - diff: 17.41mlTrain batch 15/32 - 240.8ms/batch - loss: 29.74785 - diff: 17.01mlTrain batch 16/32 - 241.8ms/batch - loss: 28.65110 - diff: 16.61mlTrain batch 17/32 - 240.9ms/batch - loss: 28.94207 - diff: 16.77mlTrain batch 18/32 - 241.4ms/batch - loss: 27.79948 - diff: 16.35mlTrain batch 19/32 - 240.6ms/batch - loss: 27.54808 - diff: 16.37mlTrain batch 20/32 - 242.1ms/batch - loss: 26.87478 - diff: 16.14mlTrain batch 21/32 - 240.6ms/batch - loss: 27.46499 - diff: 16.27mlTrain batch 22/32 - 242.0ms/batch - loss: 26.96400 - diff: 16.13mlTrain batch 23/32 - 240.4ms/batch - loss: 28.57897 - diff: 16.68mlTrain batch 24/32 - 246.5ms/batch - loss: 28.18452 - diff: 16.55mlTrain batch 25/32 - 240.8ms/batch - loss: 27.60761 - diff: 16.33mlTrain batch 26/32 - 245.9ms/batch - loss: 27.86267 - diff: 16.46mlTrain batch 27/32 - 240.2ms/batch - loss: 27.57114 - diff: 16.42mlTrain batch 28/32 - 241.4ms/batch - loss: 27.34344 - diff: 16.34mlTrain batch 29/32 - 240.1ms/batch - loss: 27.43276 - diff: 16.28mlTrain batch 30/32 - 241.5ms/batch - loss: 26.83349 - diff: 16.08mlTrain batch 31/32 - 240.6ms/batch - loss: 26.42842 - diff: 15.98mlTrain batch 32/32 - 79.3ms/batch - loss: 26.91253 - diff: 15.98mlTrain batch 32/32 - 13.1s 79.3ms/batch - loss: 26.91253 - diff: 15.98ml
Test 1.1s: val_loss: 682.90429 - diff: 95.85ml

Epoch 126: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 240.0ms/batch - loss: 33.21614 - diff: 15.60mlTrain batch 2/32 - 241.5ms/batch - loss: 35.13249 - diff: 16.77mlTrain batch 3/32 - 240.8ms/batch - loss: 31.27037 - diff: 15.71mlTrain batch 4/32 - 241.7ms/batch - loss: 27.08445 - diff: 14.73mlTrain batch 5/32 - 240.5ms/batch - loss: 25.95430 - diff: 14.54mlTrain batch 6/32 - 241.7ms/batch - loss: 34.65707 - diff: 17.07mlTrain batch 7/32 - 240.5ms/batch - loss: 31.26959 - diff: 15.92mlTrain batch 8/32 - 241.6ms/batch - loss: 29.92726 - diff: 16.00mlTrain batch 9/32 - 240.6ms/batch - loss: 27.80566 - diff: 15.38mlTrain batch 10/32 - 241.5ms/batch - loss: 27.31698 - diff: 15.41mlTrain batch 11/32 - 240.7ms/batch - loss: 25.59272 - diff: 14.92mlTrain batch 12/32 - 241.7ms/batch - loss: 25.34421 - diff: 14.68mlTrain batch 13/32 - 240.9ms/batch - loss: 24.91181 - diff: 14.67mlTrain batch 14/32 - 242.0ms/batch - loss: 24.73153 - diff: 14.81mlTrain batch 15/32 - 240.8ms/batch - loss: 24.53580 - diff: 14.73mlTrain batch 16/32 - 241.7ms/batch - loss: 23.99137 - diff: 14.62mlTrain batch 17/32 - 240.6ms/batch - loss: 23.39113 - diff: 14.42mlTrain batch 18/32 - 241.3ms/batch - loss: 24.18083 - diff: 14.63mlTrain batch 19/32 - 240.8ms/batch - loss: 24.55440 - diff: 14.76mlTrain batch 20/32 - 241.7ms/batch - loss: 25.19713 - diff: 15.17mlTrain batch 21/32 - 241.0ms/batch - loss: 24.77609 - diff: 15.09mlTrain batch 22/32 - 240.8ms/batch - loss: 24.91124 - diff: 15.18mlTrain batch 23/32 - 240.7ms/batch - loss: 26.50908 - diff: 15.76mlTrain batch 24/32 - 241.4ms/batch - loss: 26.94914 - diff: 15.83mlTrain batch 25/32 - 240.6ms/batch - loss: 26.33683 - diff: 15.65mlTrain batch 26/32 - 240.8ms/batch - loss: 27.29864 - diff: 16.12mlTrain batch 27/32 - 240.3ms/batch - loss: 26.85534 - diff: 15.97mlTrain batch 28/32 - 240.4ms/batch - loss: 27.10022 - diff: 16.16mlTrain batch 29/32 - 241.6ms/batch - loss: 26.93601 - diff: 16.16mlTrain batch 30/32 - 240.3ms/batch - loss: 26.32143 - diff: 15.95mlTrain batch 31/32 - 241.7ms/batch - loss: 25.93329 - diff: 15.83mlTrain batch 32/32 - 79.9ms/batch - loss: 26.42943 - diff: 15.85mlTrain batch 32/32 - 11.5s 79.9ms/batch - loss: 26.42943 - diff: 15.85ml
Test 1.1s: val_loss: 748.94276 - diff: 100.69ml

Epoch 127: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 240.2ms/batch - loss: 12.78044 - diff: 11.13mlTrain batch 2/32 - 241.3ms/batch - loss: 30.35426 - diff: 18.32mlTrain batch 3/32 - 240.5ms/batch - loss: 28.10977 - diff: 17.33mlTrain batch 4/32 - 241.6ms/batch - loss: 26.87630 - diff: 16.64mlTrain batch 5/32 - 240.3ms/batch - loss: 50.26901 - diff: 21.61mlTrain batch 6/32 - 241.2ms/batch - loss: 42.97493 - diff: 19.33mlTrain batch 7/32 - 240.4ms/batch - loss: 40.78264 - diff: 19.08mlTrain batch 8/32 - 241.4ms/batch - loss: 36.54548 - diff: 17.75mlTrain batch 9/32 - 240.3ms/batch - loss: 35.18877 - diff: 17.69mlTrain batch 10/32 - 241.8ms/batch - loss: 33.08584 - diff: 17.15mlTrain batch 11/32 - 240.6ms/batch - loss: 30.85866 - diff: 16.50mlTrain batch 12/32 - 241.5ms/batch - loss: 31.22756 - diff: 16.71mlTrain batch 13/32 - 240.3ms/batch - loss: 32.22659 - diff: 17.05mlTrain batch 14/32 - 241.6ms/batch - loss: 30.54103 - diff: 16.57mlTrain batch 15/32 - 240.4ms/batch - loss: 28.88080 - diff: 15.95mlTrain batch 16/32 - 241.3ms/batch - loss: 29.23741 - diff: 16.24mlTrain batch 17/32 - 240.3ms/batch - loss: 29.62758 - diff: 16.31mlTrain batch 18/32 - 241.6ms/batch - loss: 28.89820 - diff: 16.12mlTrain batch 19/32 - 240.4ms/batch - loss: 28.71530 - diff: 16.22mlTrain batch 20/32 - 241.7ms/batch - loss: 27.82784 - diff: 15.96mlTrain batch 21/32 - 241.0ms/batch - loss: 27.30011 - diff: 15.85mlTrain batch 22/32 - 242.0ms/batch - loss: 26.96293 - diff: 15.80mlTrain batch 23/32 - 241.0ms/batch - loss: 26.28412 - diff: 15.61mlTrain batch 24/32 - 241.9ms/batch - loss: 25.91919 - diff: 15.50mlTrain batch 25/32 - 240.4ms/batch - loss: 25.68997 - diff: 15.47mlTrain batch 26/32 - 240.9ms/batch - loss: 25.29994 - diff: 15.40mlTrain batch 27/32 - 240.7ms/batch - loss: 24.85425 - diff: 15.27mlTrain batch 28/32 - 241.6ms/batch - loss: 24.59129 - diff: 15.27mlTrain batch 29/32 - 240.6ms/batch - loss: 25.22031 - diff: 15.51mlTrain batch 30/32 - 241.8ms/batch - loss: 25.31489 - diff: 15.55mlTrain batch 31/32 - 240.6ms/batch - loss: 24.76909 - diff: 15.31mlTrain batch 32/32 - 79.0ms/batch - loss: 25.03354 - diff: 15.28mlTrain batch 32/32 - 11.7s 79.0ms/batch - loss: 25.03354 - diff: 15.28ml
Test 1.1s: val_loss: 782.80625 - diff: 102.40ml
Epoch   128: reducing learning rate of group 0 to 4.8828e-07.

Epoch 128: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 240.3ms/batch - loss: 39.64552 - diff: 21.86mlTrain batch 2/32 - 240.7ms/batch - loss: 34.00403 - diff: 19.80mlTrain batch 3/32 - 240.3ms/batch - loss: 25.62565 - diff: 16.24mlTrain batch 4/32 - 241.8ms/batch - loss: 26.18152 - diff: 16.58mlTrain batch 5/32 - 240.4ms/batch - loss: 27.64931 - diff: 16.57mlTrain batch 6/32 - 241.6ms/batch - loss: 26.41517 - diff: 16.36mlTrain batch 7/32 - 240.6ms/batch - loss: 24.53859 - diff: 15.66mlTrain batch 8/32 - 241.5ms/batch - loss: 24.75884 - diff: 15.94mlTrain batch 9/32 - 240.5ms/batch - loss: 23.34575 - diff: 15.51mlTrain batch 10/32 - 241.4ms/batch - loss: 21.51362 - diff: 14.71mlTrain batch 11/32 - 240.8ms/batch - loss: 22.54005 - diff: 15.08mlTrain batch 12/32 - 241.6ms/batch - loss: 24.13043 - diff: 15.61mlTrain batch 13/32 - 240.6ms/batch - loss: 29.76562 - diff: 17.18mlTrain batch 14/32 - 241.0ms/batch - loss: 29.20014 - diff: 17.01mlTrain batch 15/32 - 241.0ms/batch - loss: 28.12880 - diff: 16.68mlTrain batch 16/32 - 241.2ms/batch - loss: 28.61677 - diff: 16.98mlTrain batch 17/32 - 241.1ms/batch - loss: 28.27856 - diff: 16.86mlTrain batch 18/32 - 240.9ms/batch - loss: 27.47373 - diff: 16.56mlTrain batch 19/32 - 241.2ms/batch - loss: 27.85330 - diff: 16.75mlTrain batch 20/32 - 241.2ms/batch - loss: 26.94210 - diff: 16.44mlTrain batch 21/32 - 241.5ms/batch - loss: 26.75574 - diff: 16.38mlTrain batch 22/32 - 241.4ms/batch - loss: 26.23374 - diff: 16.22mlTrain batch 23/32 - 241.4ms/batch - loss: 25.55883 - diff: 15.97mlTrain batch 24/32 - 241.2ms/batch - loss: 25.07649 - diff: 15.77mlTrain batch 25/32 - 241.2ms/batch - loss: 25.02356 - diff: 15.76mlTrain batch 26/32 - 240.9ms/batch - loss: 24.38060 - diff: 15.52mlTrain batch 27/32 - 241.4ms/batch - loss: 24.54138 - diff: 15.61mlTrain batch 28/32 - 240.3ms/batch - loss: 23.85347 - diff: 15.33mlTrain batch 29/32 - 241.1ms/batch - loss: 25.12579 - diff: 15.76mlTrain batch 30/32 - 241.0ms/batch - loss: 24.52574 - diff: 15.53mlTrain batch 31/32 - 241.1ms/batch - loss: 24.39881 - diff: 15.54mlTrain batch 32/32 - 79.1ms/batch - loss: 32.58799 - diff: 15.87mlTrain batch 32/32 - 11.7s 79.1ms/batch - loss: 32.58799 - diff: 15.87ml
Test 1.1s: val_loss: 574.92700 - diff: 87.24ml

Epoch 129: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 240.5ms/batch - loss: 16.32079 - diff: 13.58mlTrain batch 2/32 - 241.2ms/batch - loss: 16.87161 - diff: 13.59mlTrain batch 3/32 - 241.1ms/batch - loss: 19.24580 - diff: 13.83mlTrain batch 4/32 - 240.8ms/batch - loss: 16.30426 - diff: 12.69mlTrain batch 5/32 - 241.1ms/batch - loss: 17.40902 - diff: 12.97mlTrain batch 6/32 - 241.1ms/batch - loss: 20.04187 - diff: 14.30mlTrain batch 7/32 - 241.8ms/batch - loss: 27.85946 - diff: 16.37mlTrain batch 8/32 - 240.4ms/batch - loss: 34.49013 - diff: 18.18mlTrain batch 9/32 - 241.6ms/batch - loss: 31.51722 - diff: 17.20mlTrain batch 10/32 - 240.6ms/batch - loss: 29.16104 - diff: 16.32mlTrain batch 11/32 - 241.4ms/batch - loss: 27.17373 - diff: 15.65mlTrain batch 12/32 - 240.8ms/batch - loss: 26.20710 - diff: 15.36mlTrain batch 13/32 - 241.4ms/batch - loss: 25.49421 - diff: 15.34mlTrain batch 14/32 - 240.4ms/batch - loss: 26.61374 - diff: 15.78mlTrain batch 15/32 - 241.0ms/batch - loss: 25.90475 - diff: 15.50mlTrain batch 16/32 - 240.3ms/batch - loss: 26.51097 - diff: 15.81mlTrain batch 17/32 - 241.6ms/batch - loss: 27.19295 - diff: 16.22mlTrain batch 18/32 - 240.7ms/batch - loss: 26.13409 - diff: 15.87mlTrain batch 19/32 - 241.4ms/batch - loss: 25.95310 - diff: 15.83mlTrain batch 20/32 - 241.1ms/batch - loss: 25.31237 - diff: 15.61mlTrain batch 21/32 - 241.8ms/batch - loss: 25.63780 - diff: 15.83mlTrain batch 22/32 - 240.9ms/batch - loss: 27.84827 - diff: 16.51mlTrain batch 23/32 - 241.8ms/batch - loss: 28.27418 - diff: 16.66mlTrain batch 24/32 - 240.8ms/batch - loss: 27.66097 - diff: 16.46mlTrain batch 25/32 - 240.5ms/batch - loss: 26.85905 - diff: 16.16mlTrain batch 26/32 - 241.8ms/batch - loss: 26.32483 - diff: 15.97mlTrain batch 27/32 - 240.7ms/batch - loss: 25.97726 - diff: 15.89mlTrain batch 28/32 - 241.4ms/batch - loss: 25.58284 - diff: 15.73mlTrain batch 29/32 - 240.1ms/batch - loss: 25.21699 - diff: 15.59mlTrain batch 30/32 - 241.7ms/batch - loss: 25.78051 - diff: 15.81mlTrain batch 31/32 - 240.2ms/batch - loss: 26.12115 - diff: 15.90mlTrain batch 32/32 - 78.9ms/batch - loss: 27.48409 - diff: 15.92mlTrain batch 32/32 - 12.1s 78.9ms/batch - loss: 27.48409 - diff: 15.92ml
Test 1.1s: val_loss: 611.39285 - diff: 90.04ml

Epoch 130: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 240.4ms/batch - loss: 16.06962 - diff: 13.63mlTrain batch 2/32 - 241.3ms/batch - loss: 15.10108 - diff: 12.87mlTrain batch 3/32 - 240.4ms/batch - loss: 30.14233 - diff: 17.40mlTrain batch 4/32 - 241.1ms/batch - loss: 25.75691 - diff: 15.79mlTrain batch 5/32 - 240.4ms/batch - loss: 24.58678 - diff: 15.57mlTrain batch 6/32 - 241.3ms/batch - loss: 22.95486 - diff: 15.00mlTrain batch 7/32 - 240.4ms/batch - loss: 21.39050 - diff: 14.46mlTrain batch 8/32 - 241.8ms/batch - loss: 21.54760 - diff: 14.67mlTrain batch 9/32 - 240.4ms/batch - loss: 23.30748 - diff: 15.42mlTrain batch 10/32 - 241.7ms/batch - loss: 25.54764 - diff: 16.13mlTrain batch 11/32 - 241.0ms/batch - loss: 24.01064 - diff: 15.47mlTrain batch 12/32 - 241.9ms/batch - loss: 22.96810 - diff: 15.17mlTrain batch 13/32 - 240.5ms/batch - loss: 23.24367 - diff: 15.32mlTrain batch 14/32 - 242.0ms/batch - loss: 21.98564 - diff: 14.78mlTrain batch 15/32 - 240.2ms/batch - loss: 21.10559 - diff: 14.31mlTrain batch 16/32 - 241.7ms/batch - loss: 20.99957 - diff: 14.36mlTrain batch 17/32 - 240.7ms/batch - loss: 21.92898 - diff: 14.67mlTrain batch 18/32 - 241.8ms/batch - loss: 21.59779 - diff: 14.60mlTrain batch 19/32 - 240.5ms/batch - loss: 21.67984 - diff: 14.72mlTrain batch 20/32 - 241.8ms/batch - loss: 21.53330 - diff: 14.56mlTrain batch 21/32 - 240.7ms/batch - loss: 21.87674 - diff: 14.68mlTrain batch 22/32 - 241.5ms/batch - loss: 21.80367 - diff: 14.65mlTrain batch 23/32 - 240.9ms/batch - loss: 21.92968 - diff: 14.75mlTrain batch 24/32 - 241.5ms/batch - loss: 21.36576 - diff: 14.50mlTrain batch 25/32 - 240.9ms/batch - loss: 20.90629 - diff: 14.34mlTrain batch 26/32 - 241.5ms/batch - loss: 22.59362 - diff: 14.91mlTrain batch 27/32 - 241.0ms/batch - loss: 26.20191 - diff: 15.80mlTrain batch 28/32 - 241.5ms/batch - loss: 25.79775 - diff: 15.66mlTrain batch 29/32 - 240.3ms/batch - loss: 25.31100 - diff: 15.50mlTrain batch 30/32 - 241.5ms/batch - loss: 25.50949 - diff: 15.65mlTrain batch 31/32 - 240.7ms/batch - loss: 24.94020 - diff: 15.42mlTrain batch 32/32 - 79.0ms/batch - loss: 26.36365 - diff: 15.48mlTrain batch 32/32 - 11.9s 79.0ms/batch - loss: 26.36365 - diff: 15.48ml
Test 1.1s: val_loss: 705.36686 - diff: 97.49ml

Epoch 131: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 240.5ms/batch - loss: 12.34411 - diff: 9.95mlTrain batch 2/32 - 241.3ms/batch - loss: 14.80759 - diff: 11.74mlTrain batch 3/32 - 240.7ms/batch - loss: 15.85141 - diff: 12.34mlTrain batch 4/32 - 242.0ms/batch - loss: 15.84629 - diff: 12.64mlTrain batch 5/32 - 240.3ms/batch - loss: 22.75149 - diff: 15.08mlTrain batch 6/32 - 241.9ms/batch - loss: 20.18960 - diff: 14.06mlTrain batch 7/32 - 240.9ms/batch - loss: 20.16170 - diff: 14.33mlTrain batch 8/32 - 241.4ms/batch - loss: 19.95938 - diff: 14.20mlTrain batch 9/32 - 240.6ms/batch - loss: 20.85844 - diff: 14.63mlTrain batch 10/32 - 241.0ms/batch - loss: 23.82805 - diff: 15.79mlTrain batch 11/32 - 241.2ms/batch - loss: 22.93166 - diff: 15.41mlTrain batch 12/32 - 240.6ms/batch - loss: 31.34202 - diff: 17.48mlTrain batch 13/32 - 241.4ms/batch - loss: 36.58464 - diff: 18.98mlTrain batch 14/32 - 241.0ms/batch - loss: 34.79400 - diff: 18.45mlTrain batch 15/32 - 246.0ms/batch - loss: 35.56595 - diff: 18.76mlTrain batch 16/32 - 241.6ms/batch - loss: 34.47844 - diff: 18.51mlTrain batch 17/32 - 240.9ms/batch - loss: 33.18853 - diff: 18.11mlTrain batch 18/32 - 241.5ms/batch - loss: 34.84618 - diff: 18.73mlTrain batch 19/32 - 240.6ms/batch - loss: 33.85058 - diff: 18.48mlTrain batch 20/32 - 240.2ms/batch - loss: 33.03807 - diff: 18.26mlTrain batch 21/32 - 241.7ms/batch - loss: 32.48165 - diff: 18.04mlTrain batch 22/32 - 240.6ms/batch - loss: 31.96287 - diff: 17.88mlTrain batch 23/32 - 241.4ms/batch - loss: 31.07712 - diff: 17.55mlTrain batch 24/32 - 240.5ms/batch - loss: 30.28174 - diff: 17.31mlTrain batch 25/32 - 241.0ms/batch - loss: 29.35466 - diff: 16.99mlTrain batch 26/32 - 240.7ms/batch - loss: 30.03919 - diff: 17.18mlTrain batch 27/32 - 241.6ms/batch - loss: 30.50166 - diff: 17.36mlTrain batch 28/32 - 241.1ms/batch - loss: 29.69829 - diff: 17.10mlTrain batch 29/32 - 241.6ms/batch - loss: 29.23672 - diff: 16.99mlTrain batch 30/32 - 240.7ms/batch - loss: 28.50300 - diff: 16.72mlTrain batch 31/32 - 241.5ms/batch - loss: 28.00229 - diff: 16.61mlTrain batch 32/32 - 79.1ms/batch - loss: 29.19350 - diff: 16.69mlTrain batch 32/32 - 11.6s 79.1ms/batch - loss: 29.19350 - diff: 16.69ml
Test 1.1s: val_loss: 969.28750 - diff: 115.56ml

Epoch 132: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 240.6ms/batch - loss: 10.05386 - diff: 11.51mlTrain batch 2/32 - 240.8ms/batch - loss: 23.84077 - diff: 15.50mlTrain batch 3/32 - 241.0ms/batch - loss: 22.94817 - diff: 14.62mlTrain batch 4/32 - 241.5ms/batch - loss: 20.33885 - diff: 13.71mlTrain batch 5/32 - 240.7ms/batch - loss: 26.60389 - diff: 16.06mlTrain batch 6/32 - 242.1ms/batch - loss: 24.27554 - diff: 15.45mlTrain batch 7/32 - 240.3ms/batch - loss: 21.98476 - diff: 14.61mlTrain batch 8/32 - 241.4ms/batch - loss: 21.51127 - diff: 14.60mlTrain batch 9/32 - 240.4ms/batch - loss: 22.47015 - diff: 15.18mlTrain batch 10/32 - 241.5ms/batch - loss: 25.38533 - diff: 16.16mlTrain batch 11/32 - 240.5ms/batch - loss: 23.76196 - diff: 15.50mlTrain batch 12/32 - 241.3ms/batch - loss: 35.19111 - diff: 18.00mlTrain batch 13/32 - 245.9ms/batch - loss: 33.14710 - diff: 17.40mlTrain batch 14/32 - 241.6ms/batch - loss: 31.87177 - diff: 17.06mlTrain batch 15/32 - 240.9ms/batch - loss: 34.12580 - diff: 17.75mlTrain batch 16/32 - 241.6ms/batch - loss: 33.10149 - diff: 17.44mlTrain batch 17/32 - 240.5ms/batch - loss: 32.54644 - diff: 17.40mlTrain batch 18/32 - 241.9ms/batch - loss: 31.32536 - diff: 16.93mlTrain batch 19/32 - 241.2ms/batch - loss: 30.00440 - diff: 16.44mlTrain batch 20/32 - 241.6ms/batch - loss: 31.60825 - diff: 16.99mlTrain batch 21/32 - 240.7ms/batch - loss: 30.84050 - diff: 16.83mlTrain batch 22/32 - 241.7ms/batch - loss: 29.84898 - diff: 16.54mlTrain batch 23/32 - 240.9ms/batch - loss: 29.23634 - diff: 16.41mlTrain batch 24/32 - 242.0ms/batch - loss: 29.04056 - diff: 16.45mlTrain batch 25/32 - 240.4ms/batch - loss: 28.60283 - diff: 16.32mlTrain batch 26/32 - 241.2ms/batch - loss: 27.68160 - diff: 15.96mlTrain batch 27/32 - 240.9ms/batch - loss: 26.97846 - diff: 15.71mlTrain batch 28/32 - 241.5ms/batch - loss: 27.11921 - diff: 15.85mlTrain batch 29/32 - 240.3ms/batch - loss: 26.89027 - diff: 15.82mlTrain batch 30/32 - 241.9ms/batch - loss: 28.77832 - diff: 16.43mlTrain batch 31/32 - 240.4ms/batch - loss: 28.34527 - diff: 16.35mlTrain batch 32/32 - 78.2ms/batch - loss: 28.47111 - diff: 16.31mlTrain batch 32/32 - 11.6s 78.2ms/batch - loss: 28.47111 - diff: 16.31ml
Test 1.1s: val_loss: 809.20542 - diff: 104.82ml

Epoch 133: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 240.1ms/batch - loss: 25.25949 - diff: 17.10mlTrain batch 2/32 - 241.2ms/batch - loss: 36.11318 - diff: 20.81mlTrain batch 3/32 - 240.4ms/batch - loss: 26.70788 - diff: 16.68mlTrain batch 4/32 - 241.8ms/batch - loss: 29.29136 - diff: 17.87mlTrain batch 5/32 - 243.6ms/batch - loss: 25.32734 - diff: 16.27mlTrain batch 6/32 - 241.7ms/batch - loss: 26.12550 - diff: 16.71mlTrain batch 7/32 - 240.4ms/batch - loss: 23.32616 - diff: 15.58mlTrain batch 8/32 - 241.4ms/batch - loss: 23.05760 - diff: 15.62mlTrain batch 9/32 - 240.9ms/batch - loss: 21.95569 - diff: 15.21mlTrain batch 10/32 - 241.6ms/batch - loss: 22.00252 - diff: 15.22mlTrain batch 11/32 - 240.9ms/batch - loss: 21.68441 - diff: 15.11mlTrain batch 12/32 - 241.2ms/batch - loss: 20.44240 - diff: 14.48mlTrain batch 13/32 - 240.4ms/batch - loss: 19.99478 - diff: 14.37mlTrain batch 14/32 - 241.8ms/batch - loss: 19.60968 - diff: 14.31mlTrain batch 15/32 - 241.0ms/batch - loss: 19.81178 - diff: 14.38mlTrain batch 16/32 - 241.6ms/batch - loss: 19.33712 - diff: 14.19mlTrain batch 17/32 - 240.7ms/batch - loss: 23.09371 - diff: 15.36mlTrain batch 18/32 - 241.1ms/batch - loss: 22.68602 - diff: 15.24mlTrain batch 19/32 - 240.8ms/batch - loss: 22.27283 - diff: 15.12mlTrain batch 20/32 - 241.2ms/batch - loss: 26.37176 - diff: 16.18mlTrain batch 21/32 - 240.7ms/batch - loss: 28.28262 - diff: 16.83mlTrain batch 22/32 - 241.6ms/batch - loss: 27.43544 - diff: 16.53mlTrain batch 23/32 - 240.4ms/batch - loss: 27.24319 - diff: 16.61mlTrain batch 24/32 - 242.0ms/batch - loss: 29.16802 - diff: 17.21mlTrain batch 25/32 - 240.8ms/batch - loss: 29.27276 - diff: 17.29mlTrain batch 26/32 - 241.9ms/batch - loss: 29.26562 - diff: 17.27mlTrain batch 27/32 - 241.2ms/batch - loss: 29.85068 - diff: 17.47mlTrain batch 28/32 - 241.5ms/batch - loss: 29.43013 - diff: 17.36mlTrain batch 29/32 - 240.9ms/batch - loss: 29.01533 - diff: 17.25mlTrain batch 30/32 - 241.7ms/batch - loss: 28.33350 - diff: 17.00mlTrain batch 31/32 - 241.0ms/batch - loss: 28.28440 - diff: 17.09mlTrain batch 32/32 - 79.2ms/batch - loss: 34.45114 - diff: 17.36mlTrain batch 32/32 - 11.3s 79.2ms/batch - loss: 34.45114 - diff: 17.36ml
Test 1.2s: val_loss: 865.92500 - diff: 109.04ml

Epoch 134: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 240.7ms/batch - loss: 14.28651 - diff: 12.00mlTrain batch 2/32 - 241.3ms/batch - loss: 22.12167 - diff: 14.42mlTrain batch 3/32 - 240.9ms/batch - loss: 20.85231 - diff: 14.65mlTrain batch 4/32 - 241.6ms/batch - loss: 27.49014 - diff: 17.16mlTrain batch 5/32 - 240.4ms/batch - loss: 23.81328 - diff: 15.58mlTrain batch 6/32 - 241.4ms/batch - loss: 35.23728 - diff: 18.94mlTrain batch 7/32 - 240.3ms/batch - loss: 31.65724 - diff: 17.80mlTrain batch 8/32 - 241.2ms/batch - loss: 28.86935 - diff: 16.75mlTrain batch 9/32 - 240.4ms/batch - loss: 26.12248 - diff: 15.66mlTrain batch 10/32 - 241.4ms/batch - loss: 24.63517 - diff: 15.17mlTrain batch 11/32 - 240.5ms/batch - loss: 22.98127 - diff: 14.49mlTrain batch 12/32 - 241.3ms/batch - loss: 21.84775 - diff: 14.12mlTrain batch 13/32 - 240.9ms/batch - loss: 20.76379 - diff: 13.71mlTrain batch 14/32 - 241.5ms/batch - loss: 20.25951 - diff: 13.66mlTrain batch 15/32 - 240.9ms/batch - loss: 24.06782 - diff: 14.50mlTrain batch 16/32 - 241.8ms/batch - loss: 22.94801 - diff: 14.08mlTrain batch 17/32 - 240.9ms/batch - loss: 23.08905 - diff: 14.26mlTrain batch 18/32 - 242.1ms/batch - loss: 22.85334 - diff: 14.21mlTrain batch 19/32 - 240.5ms/batch - loss: 23.41661 - diff: 14.51mlTrain batch 20/32 - 241.2ms/batch - loss: 23.04850 - diff: 14.43mlTrain batch 21/32 - 240.8ms/batch - loss: 22.78114 - diff: 14.38mlTrain batch 22/32 - 241.9ms/batch - loss: 23.57340 - diff: 14.58mlTrain batch 23/32 - 240.6ms/batch - loss: 24.29630 - diff: 14.87mlTrain batch 24/32 - 241.9ms/batch - loss: 23.65910 - diff: 14.67mlTrain batch 25/32 - 240.5ms/batch - loss: 23.20076 - diff: 14.57mlTrain batch 26/32 - 241.4ms/batch - loss: 22.49037 - diff: 14.28mlTrain batch 27/32 - 240.4ms/batch - loss: 22.51497 - diff: 14.25mlTrain batch 28/32 - 241.2ms/batch - loss: 22.50437 - diff: 14.27mlTrain batch 29/32 - 240.7ms/batch - loss: 22.16491 - diff: 14.21mlTrain batch 30/32 - 241.9ms/batch - loss: 21.96387 - diff: 14.10mlTrain batch 31/32 - 240.6ms/batch - loss: 22.04763 - diff: 14.14mlTrain batch 32/32 - 78.0ms/batch - loss: 22.59594 - diff: 14.16mlTrain batch 32/32 - 12.2s 78.0ms/batch - loss: 22.59594 - diff: 14.16ml
Test 1.1s: val_loss: 905.66514 - diff: 112.50ml

Epoch 135: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 240.6ms/batch - loss: 10.82737 - diff: 11.64mlTrain batch 2/32 - 241.0ms/batch - loss: 15.67150 - diff: 13.35mlTrain batch 3/32 - 240.6ms/batch - loss: 35.63549 - diff: 19.52mlTrain batch 4/32 - 240.3ms/batch - loss: 30.36938 - diff: 17.84mlTrain batch 5/32 - 240.8ms/batch - loss: 26.84656 - diff: 16.29mlTrain batch 6/32 - 240.5ms/batch - loss: 23.48366 - diff: 15.00mlTrain batch 7/32 - 241.0ms/batch - loss: 24.37085 - diff: 15.53mlTrain batch 8/32 - 240.5ms/batch - loss: 25.36493 - diff: 16.12mlTrain batch 9/32 - 241.4ms/batch - loss: 27.74349 - diff: 17.07mlTrain batch 10/32 - 240.6ms/batch - loss: 26.59265 - diff: 16.77mlTrain batch 11/32 - 241.5ms/batch - loss: 26.93175 - diff: 16.93mlTrain batch 12/32 - 240.4ms/batch - loss: 26.03535 - diff: 16.65mlTrain batch 13/32 - 241.5ms/batch - loss: 26.78206 - diff: 16.92mlTrain batch 14/32 - 240.3ms/batch - loss: 26.92001 - diff: 17.12mlTrain batch 15/32 - 241.1ms/batch - loss: 25.71039 - diff: 16.58mlTrain batch 16/32 - 240.8ms/batch - loss: 28.60287 - diff: 17.48mlTrain batch 17/32 - 241.9ms/batch - loss: 27.58758 - diff: 17.00mlTrain batch 18/32 - 240.9ms/batch - loss: 26.90145 - diff: 16.78mlTrain batch 19/32 - 241.4ms/batch - loss: 26.31435 - diff: 16.54mlTrain batch 20/32 - 240.4ms/batch - loss: 25.28355 - diff: 16.08mlTrain batch 21/32 - 241.8ms/batch - loss: 25.85253 - diff: 16.33mlTrain batch 22/32 - 240.4ms/batch - loss: 27.19427 - diff: 16.75mlTrain batch 23/32 - 241.4ms/batch - loss: 27.70928 - diff: 16.99mlTrain batch 24/32 - 240.4ms/batch - loss: 27.10181 - diff: 16.75mlTrain batch 25/32 - 241.7ms/batch - loss: 27.45827 - diff: 16.94mlTrain batch 26/32 - 241.6ms/batch - loss: 27.40409 - diff: 16.98mlTrain batch 27/32 - 241.1ms/batch - loss: 30.91170 - diff: 17.70mlTrain batch 28/32 - 241.0ms/batch - loss: 30.23321 - diff: 17.49mlTrain batch 29/32 - 240.4ms/batch - loss: 29.50758 - diff: 17.23mlTrain batch 30/32 - 240.7ms/batch - loss: 29.05435 - diff: 17.07mlTrain batch 31/32 - 241.9ms/batch - loss: 28.37114 - diff: 16.81mlTrain batch 32/32 - 80.4ms/batch - loss: 28.72317 - diff: 16.79mlTrain batch 32/32 - 11.7s 80.4ms/batch - loss: 28.72317 - diff: 16.79ml
Test 1.2s: val_loss: 730.97866 - diff: 99.77ml

Epoch 136: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 240.7ms/batch - loss: 9.81308 - diff: 9.65mlTrain batch 2/32 - 241.5ms/batch - loss: 33.52409 - diff: 18.21mlTrain batch 3/32 - 240.7ms/batch - loss: 25.81785 - diff: 15.20mlTrain batch 4/32 - 241.8ms/batch - loss: 29.96616 - diff: 16.31mlTrain batch 5/32 - 240.3ms/batch - loss: 26.32087 - diff: 15.21mlTrain batch 6/32 - 241.6ms/batch - loss: 29.37621 - diff: 16.39mlTrain batch 7/32 - 240.6ms/batch - loss: 27.52570 - diff: 15.78mlTrain batch 8/32 - 241.6ms/batch - loss: 25.26950 - diff: 15.07mlTrain batch 9/32 - 240.2ms/batch - loss: 24.53411 - diff: 14.97mlTrain batch 10/32 - 241.3ms/batch - loss: 23.47390 - diff: 14.73mlTrain batch 11/32 - 241.0ms/batch - loss: 22.32046 - diff: 14.40mlTrain batch 12/32 - 241.5ms/batch - loss: 24.30334 - diff: 15.19mlTrain batch 13/32 - 240.6ms/batch - loss: 23.34216 - diff: 14.85mlTrain batch 14/32 - 241.2ms/batch - loss: 22.38805 - diff: 14.47mlTrain batch 15/32 - 240.7ms/batch - loss: 22.26294 - diff: 14.51mlTrain batch 16/32 - 241.5ms/batch - loss: 24.33781 - diff: 15.28mlTrain batch 17/32 - 241.0ms/batch - loss: 24.94187 - diff: 15.44mlTrain batch 18/32 - 241.8ms/batch - loss: 25.32600 - diff: 15.59mlTrain batch 19/32 - 240.6ms/batch - loss: 24.66629 - diff: 15.37mlTrain batch 20/32 - 241.7ms/batch - loss: 24.50716 - diff: 15.25mlTrain batch 21/32 - 240.5ms/batch - loss: 24.70960 - diff: 15.40mlTrain batch 22/32 - 241.4ms/batch - loss: 24.42840 - diff: 15.36mlTrain batch 23/32 - 241.4ms/batch - loss: 25.94200 - diff: 15.86mlTrain batch 24/32 - 241.6ms/batch - loss: 25.26360 - diff: 15.63mlTrain batch 25/32 - 240.5ms/batch - loss: 24.87235 - diff: 15.52mlTrain batch 26/32 - 241.9ms/batch - loss: 25.07735 - diff: 15.68mlTrain batch 27/32 - 241.0ms/batch - loss: 24.74419 - diff: 15.60mlTrain batch 28/32 - 241.6ms/batch - loss: 24.69357 - diff: 15.65mlTrain batch 29/32 - 242.4ms/batch - loss: 25.97387 - diff: 16.07mlTrain batch 30/32 - 241.4ms/batch - loss: 25.51348 - diff: 15.90mlTrain batch 31/32 - 240.9ms/batch - loss: 25.00444 - diff: 15.70mlTrain batch 32/32 - 78.4ms/batch - loss: 24.92901 - diff: 15.62mlTrain batch 32/32 - 12.0s 78.4ms/batch - loss: 24.92901 - diff: 15.62ml
Test 1.1s: val_loss: 924.61773 - diff: 112.86ml

Epoch 137: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 240.8ms/batch - loss: 21.45251 - diff: 15.98mlTrain batch 2/32 - 241.7ms/batch - loss: 14.25212 - diff: 12.32mlTrain batch 3/32 - 241.0ms/batch - loss: 12.31800 - diff: 11.51mlTrain batch 4/32 - 241.9ms/batch - loss: 11.76483 - diff: 10.99mlTrain batch 5/32 - 240.8ms/batch - loss: 12.00716 - diff: 11.06mlTrain batch 6/32 - 241.3ms/batch - loss: 13.54351 - diff: 11.58mlTrain batch 7/32 - 240.9ms/batch - loss: 13.53666 - diff: 11.65mlTrain batch 8/32 - 241.2ms/batch - loss: 14.41819 - diff: 11.83mlTrain batch 9/32 - 240.7ms/batch - loss: 15.33056 - diff: 12.53mlTrain batch 10/32 - 241.9ms/batch - loss: 14.24102 - diff: 11.95mlTrain batch 11/32 - 240.8ms/batch - loss: 17.16971 - diff: 13.02mlTrain batch 12/32 - 241.5ms/batch - loss: 16.96951 - diff: 13.03mlTrain batch 13/32 - 240.8ms/batch - loss: 17.36221 - diff: 13.28mlTrain batch 14/32 - 241.8ms/batch - loss: 16.58124 - diff: 12.91mlTrain batch 15/32 - 241.1ms/batch - loss: 19.47767 - diff: 13.85mlTrain batch 16/32 - 241.6ms/batch - loss: 20.00909 - diff: 14.13mlTrain batch 17/32 - 240.1ms/batch - loss: 20.21807 - diff: 14.11mlTrain batch 18/32 - 241.6ms/batch - loss: 19.87353 - diff: 13.93mlTrain batch 19/32 - 240.9ms/batch - loss: 19.19887 - diff: 13.69mlTrain batch 20/32 - 241.1ms/batch - loss: 19.49295 - diff: 13.92mlTrain batch 21/32 - 240.8ms/batch - loss: 18.83831 - diff: 13.65mlTrain batch 22/32 - 241.6ms/batch - loss: 19.68475 - diff: 14.01mlTrain batch 23/32 - 241.2ms/batch - loss: 21.35390 - diff: 14.56mlTrain batch 24/32 - 242.2ms/batch - loss: 20.87094 - diff: 14.37mlTrain batch 25/32 - 240.3ms/batch - loss: 20.95938 - diff: 14.45mlTrain batch 26/32 - 241.5ms/batch - loss: 21.94304 - diff: 14.80mlTrain batch 27/32 - 240.8ms/batch - loss: 25.14147 - diff: 15.67mlTrain batch 28/32 - 241.1ms/batch - loss: 25.28309 - diff: 15.71mlTrain batch 29/32 - 240.5ms/batch - loss: 25.08467 - diff: 15.71mlTrain batch 30/32 - 241.4ms/batch - loss: 25.13391 - diff: 15.77mlTrain batch 31/32 - 240.5ms/batch - loss: 24.65908 - diff: 15.62mlTrain batch 32/32 - 79.6ms/batch - loss: 25.08279 - diff: 15.63mlTrain batch 32/32 - 11.7s 79.6ms/batch - loss: 25.08279 - diff: 15.63ml
Test 1.1s: val_loss: 776.19738 - diff: 102.64ml

Epoch 138: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 240.4ms/batch - loss: 48.34895 - diff: 24.67mlTrain batch 2/32 - 241.1ms/batch - loss: 34.99383 - diff: 20.65mlTrain batch 3/32 - 240.2ms/batch - loss: 29.26082 - diff: 18.21mlTrain batch 4/32 - 241.5ms/batch - loss: 24.45490 - diff: 16.29mlTrain batch 5/32 - 240.5ms/batch - loss: 21.66072 - diff: 15.20mlTrain batch 6/32 - 241.4ms/batch - loss: 20.23997 - diff: 14.54mlTrain batch 7/32 - 240.2ms/batch - loss: 18.86646 - diff: 14.03mlTrain batch 8/32 - 241.4ms/batch - loss: 31.59107 - diff: 17.22mlTrain batch 9/32 - 240.7ms/batch - loss: 28.96027 - diff: 16.35mlTrain batch 10/32 - 241.3ms/batch - loss: 29.06034 - diff: 16.35mlTrain batch 11/32 - 240.3ms/batch - loss: 28.31165 - diff: 16.23mlTrain batch 12/32 - 241.6ms/batch - loss: 26.75792 - diff: 15.73mlTrain batch 13/32 - 240.7ms/batch - loss: 27.45480 - diff: 16.08mlTrain batch 14/32 - 241.4ms/batch - loss: 26.23780 - diff: 15.71mlTrain batch 15/32 - 240.8ms/batch - loss: 26.18024 - diff: 15.81mlTrain batch 16/32 - 241.7ms/batch - loss: 25.45329 - diff: 15.68mlTrain batch 17/32 - 240.4ms/batch - loss: 24.81465 - diff: 15.50mlTrain batch 18/32 - 241.0ms/batch - loss: 25.63433 - diff: 15.89mlTrain batch 19/32 - 240.7ms/batch - loss: 28.47218 - diff: 16.69mlTrain batch 20/32 - 241.3ms/batch - loss: 28.27256 - diff: 16.57mlTrain batch 21/32 - 240.8ms/batch - loss: 30.64426 - diff: 17.31mlTrain batch 22/32 - 241.3ms/batch - loss: 31.18818 - diff: 17.52mlTrain batch 23/32 - 240.7ms/batch - loss: 32.52684 - diff: 18.01mlTrain batch 24/32 - 241.9ms/batch - loss: 31.65779 - diff: 17.67mlTrain batch 25/32 - 240.3ms/batch - loss: 32.52640 - diff: 17.99mlTrain batch 26/32 - 241.7ms/batch - loss: 32.92551 - diff: 18.21mlTrain batch 27/32 - 240.9ms/batch - loss: 32.04310 - diff: 17.90mlTrain batch 28/32 - 241.7ms/batch - loss: 32.06063 - diff: 17.91mlTrain batch 29/32 - 240.9ms/batch - loss: 31.39375 - diff: 17.69mlTrain batch 30/32 - 241.8ms/batch - loss: 30.67111 - diff: 17.48mlTrain batch 31/32 - 240.3ms/batch - loss: 30.95511 - diff: 17.60mlTrain batch 32/32 - 78.6ms/batch - loss: 31.26671 - diff: 17.59mlTrain batch 32/32 - 12.5s 78.6ms/batch - loss: 31.26671 - diff: 17.59ml
Test 1.2s: val_loss: 685.50895 - diff: 95.95ml
Epoch   139: reducing learning rate of group 0 to 2.4414e-07.

Epoch 139: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 240.3ms/batch - loss: 11.64894 - diff: 10.42mlTrain batch 2/32 - 241.5ms/batch - loss: 18.43220 - diff: 13.65mlTrain batch 3/32 - 240.2ms/batch - loss: 16.12500 - diff: 12.67mlTrain batch 4/32 - 241.7ms/batch - loss: 26.56774 - diff: 15.90mlTrain batch 5/32 - 241.0ms/batch - loss: 28.89981 - diff: 17.03mlTrain batch 6/32 - 241.8ms/batch - loss: 32.49619 - diff: 18.19mlTrain batch 7/32 - 240.1ms/batch - loss: 29.20827 - diff: 17.00mlTrain batch 8/32 - 241.4ms/batch - loss: 27.08815 - diff: 16.33mlTrain batch 9/32 - 240.6ms/batch - loss: 40.14706 - diff: 19.63mlTrain batch 10/32 - 242.1ms/batch - loss: 38.92541 - diff: 19.50mlTrain batch 11/32 - 240.8ms/batch - loss: 37.48136 - diff: 18.95mlTrain batch 12/32 - 241.4ms/batch - loss: 36.81968 - diff: 18.92mlTrain batch 13/32 - 240.4ms/batch - loss: 35.42467 - diff: 18.49mlTrain batch 14/32 - 241.2ms/batch - loss: 35.67781 - diff: 18.78mlTrain batch 15/32 - 240.5ms/batch - loss: 35.27717 - diff: 18.68mlTrain batch 16/32 - 241.5ms/batch - loss: 34.03374 - diff: 18.33mlTrain batch 17/32 - 240.4ms/batch - loss: 33.72308 - diff: 18.31mlTrain batch 18/32 - 241.8ms/batch - loss: 32.30846 - diff: 17.83mlTrain batch 19/32 - 240.5ms/batch - loss: 31.07903 - diff: 17.41mlTrain batch 20/32 - 241.6ms/batch - loss: 34.85417 - diff: 18.54mlTrain batch 21/32 - 240.6ms/batch - loss: 33.96117 - diff: 18.19mlTrain batch 22/32 - 241.7ms/batch - loss: 33.09836 - diff: 17.87mlTrain batch 23/32 - 240.6ms/batch - loss: 32.08111 - diff: 17.55mlTrain batch 24/32 - 241.5ms/batch - loss: 31.46966 - diff: 17.39mlTrain batch 25/32 - 240.4ms/batch - loss: 31.96078 - diff: 17.61mlTrain batch 26/32 - 241.4ms/batch - loss: 31.49516 - diff: 17.41mlTrain batch 27/32 - 240.3ms/batch - loss: 30.92213 - diff: 17.24mlTrain batch 28/32 - 241.4ms/batch - loss: 30.37339 - diff: 17.03mlTrain batch 29/32 - 240.6ms/batch - loss: 30.09272 - diff: 17.00mlTrain batch 30/32 - 241.5ms/batch - loss: 30.12211 - diff: 17.06mlTrain batch 31/32 - 241.0ms/batch - loss: 30.31626 - diff: 17.13mlTrain batch 32/32 - 79.5ms/batch - loss: 30.49626 - diff: 17.10mlTrain batch 32/32 - 12.2s 79.5ms/batch - loss: 30.49626 - diff: 17.10ml
Test 1.1s: val_loss: 792.65229 - diff: 104.60ml

Epoch 140: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 240.7ms/batch - loss: 8.29137 - diff: 10.32mlTrain batch 2/32 - 241.5ms/batch - loss: 9.87052 - diff: 10.78mlTrain batch 3/32 - 240.3ms/batch - loss: 12.07544 - diff: 11.38mlTrain batch 4/32 - 241.2ms/batch - loss: 19.71570 - diff: 14.15mlTrain batch 5/32 - 240.4ms/batch - loss: 17.85192 - diff: 13.61mlTrain batch 6/32 - 241.6ms/batch - loss: 19.49051 - diff: 13.99mlTrain batch 7/32 - 241.0ms/batch - loss: 24.06750 - diff: 15.75mlTrain batch 8/32 - 241.9ms/batch - loss: 24.15155 - diff: 15.74mlTrain batch 9/32 - 240.7ms/batch - loss: 23.33507 - diff: 15.27mlTrain batch 10/32 - 241.8ms/batch - loss: 22.27001 - diff: 14.91mlTrain batch 11/32 - 240.4ms/batch - loss: 21.87118 - diff: 14.97mlTrain batch 12/32 - 241.2ms/batch - loss: 20.96855 - diff: 14.59mlTrain batch 13/32 - 240.1ms/batch - loss: 20.89754 - diff: 14.60mlTrain batch 14/32 - 241.7ms/batch - loss: 20.17247 - diff: 14.30mlTrain batch 15/32 - 240.7ms/batch - loss: 19.87146 - diff: 14.21mlTrain batch 16/32 - 243.4ms/batch - loss: 24.72371 - diff: 15.68mlTrain batch 17/32 - 240.8ms/batch - loss: 24.43432 - diff: 15.58mlTrain batch 18/32 - 241.5ms/batch - loss: 23.83672 - diff: 15.46mlTrain batch 19/32 - 240.5ms/batch - loss: 23.49811 - diff: 15.40mlTrain batch 20/32 - 241.5ms/batch - loss: 22.82747 - diff: 15.12mlTrain batch 21/32 - 240.7ms/batch - loss: 23.11157 - diff: 15.10mlTrain batch 22/32 - 241.3ms/batch - loss: 22.41376 - diff: 14.84mlTrain batch 23/32 - 240.7ms/batch - loss: 21.89360 - diff: 14.66mlTrain batch 24/32 - 241.6ms/batch - loss: 21.15882 - diff: 14.32mlTrain batch 25/32 - 241.0ms/batch - loss: 20.71527 - diff: 14.20mlTrain batch 26/32 - 241.5ms/batch - loss: 21.34211 - diff: 14.47mlTrain batch 27/32 - 240.7ms/batch - loss: 23.63141 - diff: 15.12mlTrain batch 28/32 - 241.6ms/batch - loss: 23.33793 - diff: 15.06mlTrain batch 29/32 - 240.8ms/batch - loss: 23.05675 - diff: 14.98mlTrain batch 30/32 - 240.7ms/batch - loss: 22.95411 - diff: 15.00mlTrain batch 31/32 - 241.5ms/batch - loss: 24.38150 - diff: 15.46mlTrain batch 32/32 - 79.3ms/batch - loss: 26.70745 - diff: 15.62mlTrain batch 32/32 - 11.6s 79.3ms/batch - loss: 26.70745 - diff: 15.62ml
Test 1.1s: val_loss: 706.41782 - diff: 98.04ml

Epoch 141: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 240.3ms/batch - loss: 29.08737 - diff: 15.95mlTrain batch 2/32 - 241.9ms/batch - loss: 19.27661 - diff: 12.93mlTrain batch 3/32 - 240.7ms/batch - loss: 16.02521 - diff: 11.87mlTrain batch 4/32 - 241.8ms/batch - loss: 16.96167 - diff: 12.84mlTrain batch 5/32 - 240.8ms/batch - loss: 16.11340 - diff: 12.33mlTrain batch 6/32 - 242.0ms/batch - loss: 15.73335 - diff: 12.06mlTrain batch 7/32 - 241.2ms/batch - loss: 15.42096 - diff: 11.91mlTrain batch 8/32 - 241.3ms/batch - loss: 16.05716 - diff: 12.31mlTrain batch 9/32 - 241.1ms/batch - loss: 17.41131 - diff: 12.98mlTrain batch 10/32 - 241.1ms/batch - loss: 17.24463 - diff: 12.89mlTrain batch 11/32 - 241.3ms/batch - loss: 17.38056 - diff: 13.03mlTrain batch 12/32 - 241.2ms/batch - loss: 17.31919 - diff: 13.05mlTrain batch 13/32 - 240.2ms/batch - loss: 17.06020 - diff: 12.99mlTrain batch 14/32 - 241.4ms/batch - loss: 16.77896 - diff: 12.87mlTrain batch 15/32 - 241.2ms/batch - loss: 17.18735 - diff: 13.02mlTrain batch 16/32 - 241.7ms/batch - loss: 18.71942 - diff: 13.64mlTrain batch 17/32 - 240.7ms/batch - loss: 19.42900 - diff: 13.92mlTrain batch 18/32 - 241.2ms/batch - loss: 19.73335 - diff: 14.10mlTrain batch 19/32 - 241.0ms/batch - loss: 19.24197 - diff: 13.85mlTrain batch 20/32 - 240.8ms/batch - loss: 18.93494 - diff: 13.72mlTrain batch 21/32 - 241.5ms/batch - loss: 22.52400 - diff: 14.68mlTrain batch 22/32 - 240.8ms/batch - loss: 23.43510 - diff: 15.06mlTrain batch 23/32 - 241.5ms/batch - loss: 24.40867 - diff: 15.44mlTrain batch 24/32 - 240.5ms/batch - loss: 23.65801 - diff: 15.15mlTrain batch 25/32 - 241.0ms/batch - loss: 23.24454 - diff: 15.04mlTrain batch 26/32 - 240.8ms/batch - loss: 22.54729 - diff: 14.77mlTrain batch 27/32 - 241.9ms/batch - loss: 25.44072 - diff: 15.60mlTrain batch 28/32 - 240.7ms/batch - loss: 24.79838 - diff: 15.38mlTrain batch 29/32 - 241.1ms/batch - loss: 26.57860 - diff: 15.85mlTrain batch 30/32 - 240.3ms/batch - loss: 26.38569 - diff: 15.87mlTrain batch 31/32 - 240.9ms/batch - loss: 26.91146 - diff: 16.09mlTrain batch 32/32 - 78.8ms/batch - loss: 38.47419 - diff: 16.56mlTrain batch 32/32 - 11.5s 78.8ms/batch - loss: 38.47419 - diff: 16.56ml
Test 1.1s: val_loss: 532.96257 - diff: 84.02ml

Epoch 142: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 240.3ms/batch - loss: 21.20237 - diff: 13.89mlTrain batch 2/32 - 241.4ms/batch - loss: 13.02416 - diff: 10.26mlTrain batch 3/32 - 240.8ms/batch - loss: 17.29246 - diff: 11.85mlTrain batch 4/32 - 241.2ms/batch - loss: 19.15970 - diff: 13.00mlTrain batch 5/32 - 240.6ms/batch - loss: 20.97365 - diff: 14.13mlTrain batch 6/32 - 241.7ms/batch - loss: 21.01046 - diff: 14.26mlTrain batch 7/32 - 241.0ms/batch - loss: 29.79819 - diff: 16.88mlTrain batch 8/32 - 241.4ms/batch - loss: 27.49515 - diff: 16.04mlTrain batch 9/32 - 240.8ms/batch - loss: 26.44190 - diff: 15.70mlTrain batch 10/32 - 241.8ms/batch - loss: 24.74951 - diff: 15.16mlTrain batch 11/32 - 240.4ms/batch - loss: 23.72005 - diff: 14.96mlTrain batch 12/32 - 241.3ms/batch - loss: 22.96891 - diff: 14.82mlTrain batch 13/32 - 240.6ms/batch - loss: 24.47328 - diff: 15.49mlTrain batch 14/32 - 241.6ms/batch - loss: 25.40003 - diff: 15.86mlTrain batch 15/32 - 241.4ms/batch - loss: 31.74163 - diff: 17.42mlTrain batch 16/32 - 242.0ms/batch - loss: 31.04519 - diff: 17.19mlTrain batch 17/32 - 240.3ms/batch - loss: 29.55451 - diff: 16.59mlTrain batch 18/32 - 241.7ms/batch - loss: 30.50571 - diff: 17.05mlTrain batch 19/32 - 241.4ms/batch - loss: 30.20391 - diff: 17.00mlTrain batch 20/32 - 242.0ms/batch - loss: 29.06610 - diff: 16.60mlTrain batch 21/32 - 240.5ms/batch - loss: 27.96709 - diff: 16.17mlTrain batch 22/32 - 241.2ms/batch - loss: 29.11689 - diff: 16.62mlTrain batch 23/32 - 241.0ms/batch - loss: 28.69368 - diff: 16.53mlTrain batch 24/32 - 241.7ms/batch - loss: 28.79555 - diff: 16.54mlTrain batch 25/32 - 240.9ms/batch - loss: 28.41604 - diff: 16.43mlTrain batch 26/32 - 241.3ms/batch - loss: 27.56045 - diff: 16.11mlTrain batch 27/32 - 241.0ms/batch - loss: 28.64300 - diff: 16.56mlTrain batch 28/32 - 241.8ms/batch - loss: 28.87929 - diff: 16.75mlTrain batch 29/32 - 240.7ms/batch - loss: 28.34852 - diff: 16.59mlTrain batch 30/32 - 241.4ms/batch - loss: 27.96094 - diff: 16.52mlTrain batch 31/32 - 240.9ms/batch - loss: 27.43356 - diff: 16.34mlTrain batch 32/32 - 79.3ms/batch - loss: 35.99227 - diff: 16.71mlTrain batch 32/32 - 11.1s 79.3ms/batch - loss: 35.99227 - diff: 16.71ml
Test 1.1s: val_loss: 800.30347 - diff: 103.58ml

Epoch 143: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 241.2ms/batch - loss: 10.28638 - diff: 9.85mlTrain batch 2/32 - 242.1ms/batch - loss: 14.67227 - diff: 12.78mlTrain batch 3/32 - 240.9ms/batch - loss: 16.73996 - diff: 13.22mlTrain batch 4/32 - 242.0ms/batch - loss: 18.47637 - diff: 14.18mlTrain batch 5/32 - 241.1ms/batch - loss: 18.70866 - diff: 14.27mlTrain batch 6/32 - 241.8ms/batch - loss: 18.63427 - diff: 13.83mlTrain batch 7/32 - 241.1ms/batch - loss: 22.35990 - diff: 15.14mlTrain batch 8/32 - 241.4ms/batch - loss: 20.92258 - diff: 14.62mlTrain batch 9/32 - 240.7ms/batch - loss: 21.64228 - diff: 14.67mlTrain batch 10/32 - 241.8ms/batch - loss: 20.26556 - diff: 14.04mlTrain batch 11/32 - 240.5ms/batch - loss: 20.68224 - diff: 14.20mlTrain batch 12/32 - 241.8ms/batch - loss: 20.37486 - diff: 14.18mlTrain batch 13/32 - 240.7ms/batch - loss: 19.34401 - diff: 13.73mlTrain batch 14/32 - 241.2ms/batch - loss: 19.19628 - diff: 13.62mlTrain batch 15/32 - 240.8ms/batch - loss: 18.83869 - diff: 13.57mlTrain batch 16/32 - 241.7ms/batch - loss: 18.66403 - diff: 13.56mlTrain batch 17/32 - 241.0ms/batch - loss: 18.21654 - diff: 13.37mlTrain batch 18/32 - 241.3ms/batch - loss: 18.77546 - diff: 13.65mlTrain batch 19/32 - 240.5ms/batch - loss: 18.45382 - diff: 13.57mlTrain batch 20/32 - 241.3ms/batch - loss: 19.40039 - diff: 13.96mlTrain batch 21/32 - 240.6ms/batch - loss: 19.37206 - diff: 14.02mlTrain batch 22/32 - 241.4ms/batch - loss: 19.02788 - diff: 13.89mlTrain batch 23/32 - 241.0ms/batch - loss: 18.75948 - diff: 13.81mlTrain batch 24/32 - 241.4ms/batch - loss: 18.26333 - diff: 13.59mlTrain batch 25/32 - 241.0ms/batch - loss: 17.86778 - diff: 13.42mlTrain batch 26/32 - 241.4ms/batch - loss: 18.18283 - diff: 13.60mlTrain batch 27/32 - 241.0ms/batch - loss: 18.25092 - diff: 13.67mlTrain batch 28/32 - 241.5ms/batch - loss: 18.30736 - diff: 13.72mlTrain batch 29/32 - 241.0ms/batch - loss: 18.39825 - diff: 13.79mlTrain batch 30/32 - 242.2ms/batch - loss: 18.44179 - diff: 13.81mlTrain batch 31/32 - 241.0ms/batch - loss: 19.24608 - diff: 14.08mlTrain batch 32/32 - 79.7ms/batch - loss: 21.97303 - diff: 14.27mlTrain batch 32/32 - 11.2s 79.7ms/batch - loss: 21.97303 - diff: 14.27ml
Test 1.2s: val_loss: 874.52132 - diff: 110.09ml

Epoch 144: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 240.8ms/batch - loss: 7.05229 - diff: 9.29mlTrain batch 2/32 - 241.6ms/batch - loss: 7.42472 - diff: 9.31mlTrain batch 3/32 - 240.8ms/batch - loss: 8.23748 - diff: 9.47mlTrain batch 4/32 - 241.0ms/batch - loss: 10.31388 - diff: 9.87mlTrain batch 5/32 - 241.7ms/batch - loss: 11.23808 - diff: 10.10mlTrain batch 6/32 - 241.0ms/batch - loss: 45.94323 - diff: 17.64mlTrain batch 7/32 - 241.2ms/batch - loss: 40.06407 - diff: 16.06mlTrain batch 8/32 - 240.2ms/batch - loss: 36.57684 - diff: 15.35mlTrain batch 9/32 - 240.8ms/batch - loss: 36.51948 - diff: 15.78mlTrain batch 10/32 - 240.4ms/batch - loss: 33.51514 - diff: 15.08mlTrain batch 11/32 - 240.8ms/batch - loss: 33.20954 - diff: 15.34mlTrain batch 12/32 - 240.5ms/batch - loss: 31.28864 - diff: 14.98mlTrain batch 13/32 - 241.2ms/batch - loss: 29.89478 - diff: 14.74mlTrain batch 14/32 - 240.7ms/batch - loss: 31.97440 - diff: 15.65mlTrain batch 15/32 - 246.4ms/batch - loss: 30.47335 - diff: 15.27mlTrain batch 16/32 - 242.0ms/batch - loss: 29.08878 - diff: 14.96mlTrain batch 17/32 - 240.8ms/batch - loss: 28.80154 - diff: 15.03mlTrain batch 18/32 - 241.8ms/batch - loss: 27.84738 - diff: 14.79mlTrain batch 19/32 - 240.8ms/batch - loss: 27.79638 - diff: 14.89mlTrain batch 20/32 - 241.6ms/batch - loss: 27.14952 - diff: 14.82mlTrain batch 21/32 - 240.6ms/batch - loss: 26.67515 - diff: 14.75mlTrain batch 22/32 - 241.6ms/batch - loss: 25.72974 - diff: 14.38mlTrain batch 23/32 - 240.3ms/batch - loss: 25.24600 - diff: 14.33mlTrain batch 24/32 - 241.3ms/batch - loss: 24.85537 - diff: 14.27mlTrain batch 25/32 - 241.1ms/batch - loss: 24.61620 - diff: 14.23mlTrain batch 26/32 - 241.8ms/batch - loss: 24.35810 - diff: 14.26mlTrain batch 27/32 - 241.0ms/batch - loss: 24.05493 - diff: 14.25mlTrain batch 28/32 - 241.9ms/batch - loss: 23.27608 - diff: 13.92mlTrain batch 29/32 - 241.2ms/batch - loss: 24.14060 - diff: 14.26mlTrain batch 30/32 - 241.9ms/batch - loss: 23.86147 - diff: 14.21mlTrain batch 31/32 - 240.8ms/batch - loss: 23.41037 - diff: 14.04mlTrain batch 32/32 - 78.9ms/batch - loss: 23.54769 - diff: 14.01mlTrain batch 32/32 - 11.8s 78.9ms/batch - loss: 23.54769 - diff: 14.01ml
Test 1.1s: val_loss: 739.94992 - diff: 100.26ml

Epoch 145: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 240.6ms/batch - loss: 12.20610 - diff: 9.47mlTrain batch 2/32 - 240.9ms/batch - loss: 12.03777 - diff: 10.12mlTrain batch 3/32 - 240.4ms/batch - loss: 12.69133 - diff: 11.00mlTrain batch 4/32 - 241.3ms/batch - loss: 18.08119 - diff: 12.95mlTrain batch 5/32 - 240.4ms/batch - loss: 17.28381 - diff: 12.83mlTrain batch 6/32 - 241.1ms/batch - loss: 18.72227 - diff: 13.40mlTrain batch 7/32 - 240.5ms/batch - loss: 18.49722 - diff: 13.42mlTrain batch 8/32 - 245.7ms/batch - loss: 18.71063 - diff: 13.71mlTrain batch 9/32 - 240.7ms/batch - loss: 27.81814 - diff: 16.33mlTrain batch 10/32 - 241.5ms/batch - loss: 26.31929 - diff: 15.77mlTrain batch 11/32 - 240.4ms/batch - loss: 25.66534 - diff: 15.61mlTrain batch 12/32 - 241.4ms/batch - loss: 24.98573 - diff: 15.46mlTrain batch 13/32 - 240.8ms/batch - loss: 24.93762 - diff: 15.50mlTrain batch 14/32 - 241.0ms/batch - loss: 23.94889 - diff: 15.18mlTrain batch 15/32 - 241.0ms/batch - loss: 24.11725 - diff: 15.23mlTrain batch 16/32 - 241.8ms/batch - loss: 24.22527 - diff: 15.34mlTrain batch 17/32 - 240.9ms/batch - loss: 25.00607 - diff: 15.72mlTrain batch 18/32 - 242.2ms/batch - loss: 24.43964 - diff: 15.49mlTrain batch 19/32 - 240.6ms/batch - loss: 23.46993 - diff: 15.12mlTrain batch 20/32 - 241.6ms/batch - loss: 24.09497 - diff: 15.44mlTrain batch 21/32 - 241.0ms/batch - loss: 23.39284 - diff: 15.16mlTrain batch 22/32 - 241.7ms/batch - loss: 22.90285 - diff: 14.95mlTrain batch 23/32 - 241.0ms/batch - loss: 22.40806 - diff: 14.76mlTrain batch 24/32 - 241.7ms/batch - loss: 22.17503 - diff: 14.66mlTrain batch 25/32 - 240.6ms/batch - loss: 21.63378 - diff: 14.50mlTrain batch 26/32 - 241.6ms/batch - loss: 22.40432 - diff: 14.70mlTrain batch 27/32 - 240.3ms/batch - loss: 22.52281 - diff: 14.76mlTrain batch 28/32 - 241.8ms/batch - loss: 24.31977 - diff: 15.34mlTrain batch 29/32 - 240.7ms/batch - loss: 23.87071 - diff: 15.16mlTrain batch 30/32 - 241.5ms/batch - loss: 23.59563 - diff: 15.03mlTrain batch 31/32 - 240.9ms/batch - loss: 23.12269 - diff: 14.85mlTrain batch 32/32 - 79.8ms/batch - loss: 25.17872 - diff: 14.97mlTrain batch 32/32 - 11.8s 79.8ms/batch - loss: 25.17872 - diff: 14.97ml
Test 1.1s: val_loss: 643.81378 - diff: 92.70ml

Epoch 146: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 240.6ms/batch - loss: 20.66003 - diff: 15.72mlTrain batch 2/32 - 241.6ms/batch - loss: 14.12319 - diff: 12.50mlTrain batch 3/32 - 240.3ms/batch - loss: 16.71508 - diff: 13.57mlTrain batch 4/32 - 241.7ms/batch - loss: 17.84891 - diff: 13.96mlTrain batch 5/32 - 240.9ms/batch - loss: 31.07078 - diff: 17.75mlTrain batch 6/32 - 241.9ms/batch - loss: 29.67127 - diff: 17.37mlTrain batch 7/32 - 240.6ms/batch - loss: 28.46453 - diff: 17.06mlTrain batch 8/32 - 241.6ms/batch - loss: 26.93763 - diff: 16.47mlTrain batch 9/32 - 240.8ms/batch - loss: 28.66117 - diff: 17.12mlTrain batch 10/32 - 241.7ms/batch - loss: 27.40710 - diff: 16.64mlTrain batch 11/32 - 240.8ms/batch - loss: 25.93006 - diff: 16.02mlTrain batch 12/32 - 241.8ms/batch - loss: 24.78047 - diff: 15.69mlTrain batch 13/32 - 240.1ms/batch - loss: 24.06902 - diff: 15.46mlTrain batch 14/32 - 241.4ms/batch - loss: 23.44875 - diff: 15.33mlTrain batch 15/32 - 241.0ms/batch - loss: 23.06915 - diff: 15.26mlTrain batch 16/32 - 241.9ms/batch - loss: 21.80826 - diff: 14.64mlTrain batch 17/32 - 241.1ms/batch - loss: 21.38734 - diff: 14.58mlTrain batch 18/32 - 242.1ms/batch - loss: 20.83001 - diff: 14.29mlTrain batch 19/32 - 241.0ms/batch - loss: 20.26726 - diff: 14.06mlTrain batch 20/32 - 242.1ms/batch - loss: 20.79466 - diff: 14.22mlTrain batch 21/32 - 240.3ms/batch - loss: 20.48894 - diff: 14.15mlTrain batch 22/32 - 241.6ms/batch - loss: 24.41272 - diff: 15.18mlTrain batch 23/32 - 240.8ms/batch - loss: 23.88246 - diff: 14.99mlTrain batch 24/32 - 241.6ms/batch - loss: 23.25797 - diff: 14.75mlTrain batch 25/32 - 240.6ms/batch - loss: 23.55918 - diff: 14.85mlTrain batch 26/32 - 241.7ms/batch - loss: 23.13712 - diff: 14.73mlTrain batch 27/32 - 241.0ms/batch - loss: 24.19615 - diff: 15.19mlTrain batch 28/32 - 240.9ms/batch - loss: 24.64191 - diff: 15.42mlTrain batch 29/32 - 240.5ms/batch - loss: 24.22365 - diff: 15.27mlTrain batch 30/32 - 241.4ms/batch - loss: 23.67140 - diff: 15.03mlTrain batch 31/32 - 240.3ms/batch - loss: 23.84547 - diff: 15.16mlTrain batch 32/32 - 79.3ms/batch - loss: 26.27960 - diff: 15.32mlTrain batch 32/32 - 12.0s 79.3ms/batch - loss: 26.27960 - diff: 15.32ml
Test 1.1s: val_loss: 749.71990 - diff: 101.74ml

Epoch 147: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 240.6ms/batch - loss: 48.26765 - diff: 23.00mlTrain batch 2/32 - 241.6ms/batch - loss: 44.26491 - diff: 22.83mlTrain batch 3/32 - 241.0ms/batch - loss: 46.41448 - diff: 22.85mlTrain batch 4/32 - 241.6ms/batch - loss: 36.76868 - diff: 19.39mlTrain batch 5/32 - 240.5ms/batch - loss: 32.79987 - diff: 18.23mlTrain batch 6/32 - 241.1ms/batch - loss: 31.40572 - diff: 17.75mlTrain batch 7/32 - 240.5ms/batch - loss: 27.64504 - diff: 16.24mlTrain batch 8/32 - 241.4ms/batch - loss: 27.31385 - diff: 16.23mlTrain batch 9/32 - 240.7ms/batch - loss: 27.88741 - diff: 16.34mlTrain batch 10/32 - 241.4ms/batch - loss: 28.91147 - diff: 16.63mlTrain batch 11/32 - 240.5ms/batch - loss: 31.62557 - diff: 17.58mlTrain batch 12/32 - 241.1ms/batch - loss: 29.78435 - diff: 16.94mlTrain batch 13/32 - 240.6ms/batch - loss: 29.95145 - diff: 17.11mlTrain batch 14/32 - 241.2ms/batch - loss: 29.62344 - diff: 17.07mlTrain batch 15/32 - 240.4ms/batch - loss: 30.22635 - diff: 17.29mlTrain batch 16/32 - 241.0ms/batch - loss: 29.29402 - diff: 16.98mlTrain batch 17/32 - 240.8ms/batch - loss: 29.17214 - diff: 16.92mlTrain batch 18/32 - 241.4ms/batch - loss: 28.54587 - diff: 16.76mlTrain batch 19/32 - 240.4ms/batch - loss: 28.17559 - diff: 16.74mlTrain batch 20/32 - 241.6ms/batch - loss: 27.06856 - diff: 16.34mlTrain batch 21/32 - 240.5ms/batch - loss: 27.66711 - diff: 16.61mlTrain batch 22/32 - 241.4ms/batch - loss: 26.81378 - diff: 16.29mlTrain batch 23/32 - 241.1ms/batch - loss: 26.45398 - diff: 16.19mlTrain batch 24/32 - 241.7ms/batch - loss: 26.04575 - diff: 16.11mlTrain batch 25/32 - 240.6ms/batch - loss: 25.51390 - diff: 15.99mlTrain batch 26/32 - 242.1ms/batch - loss: 24.91829 - diff: 15.80mlTrain batch 27/32 - 240.6ms/batch - loss: 24.39102 - diff: 15.62mlTrain batch 28/32 - 240.7ms/batch - loss: 29.36513 - diff: 16.77mlTrain batch 29/32 - 240.5ms/batch - loss: 29.22610 - diff: 16.78mlTrain batch 30/32 - 241.7ms/batch - loss: 28.77773 - diff: 16.63mlTrain batch 31/32 - 240.6ms/batch - loss: 29.00206 - diff: 16.70mlTrain batch 32/32 - 78.7ms/batch - loss: 31.39838 - diff: 16.81mlTrain batch 32/32 - 12.4s 78.7ms/batch - loss: 31.39838 - diff: 16.81ml
Test 1.2s: val_loss: 635.01606 - diff: 91.68ml

Epoch 148: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 240.3ms/batch - loss: 2.79124 - diff: 5.09mlTrain batch 2/32 - 241.7ms/batch - loss: 21.57296 - diff: 11.94mlTrain batch 3/32 - 240.4ms/batch - loss: 20.20467 - diff: 12.47mlTrain batch 4/32 - 241.5ms/batch - loss: 19.78773 - diff: 12.83mlTrain batch 5/32 - 240.6ms/batch - loss: 26.46849 - diff: 15.51mlTrain batch 6/32 - 241.7ms/batch - loss: 30.34123 - diff: 16.93mlTrain batch 7/32 - 240.5ms/batch - loss: 30.18969 - diff: 17.14mlTrain batch 8/32 - 241.4ms/batch - loss: 29.61135 - diff: 17.21mlTrain batch 9/32 - 240.5ms/batch - loss: 30.78560 - diff: 17.77mlTrain batch 10/32 - 241.7ms/batch - loss: 29.41358 - diff: 17.41mlTrain batch 11/32 - 241.2ms/batch - loss: 28.34679 - diff: 17.08mlTrain batch 12/32 - 241.6ms/batch - loss: 26.80411 - diff: 16.55mlTrain batch 13/32 - 240.9ms/batch - loss: 26.34907 - diff: 16.35mlTrain batch 14/32 - 241.2ms/batch - loss: 26.25730 - diff: 16.22mlTrain batch 15/32 - 240.9ms/batch - loss: 26.23849 - diff: 16.24mlTrain batch 16/32 - 241.7ms/batch - loss: 25.81418 - diff: 16.02mlTrain batch 17/32 - 240.7ms/batch - loss: 25.00622 - diff: 15.76mlTrain batch 18/32 - 241.8ms/batch - loss: 24.62936 - diff: 15.67mlTrain batch 19/32 - 240.4ms/batch - loss: 24.26945 - diff: 15.54mlTrain batch 20/32 - 240.9ms/batch - loss: 23.71726 - diff: 15.39mlTrain batch 21/32 - 241.1ms/batch - loss: 23.24703 - diff: 15.24mlTrain batch 22/32 - 241.9ms/batch - loss: 22.78782 - diff: 15.02mlTrain batch 23/32 - 240.9ms/batch - loss: 22.25999 - diff: 14.84mlTrain batch 24/32 - 241.9ms/batch - loss: 21.65105 - diff: 14.61mlTrain batch 25/32 - 240.4ms/batch - loss: 22.19180 - diff: 14.83mlTrain batch 26/32 - 241.6ms/batch - loss: 21.76422 - diff: 14.70mlTrain batch 27/32 - 240.3ms/batch - loss: 21.09036 - diff: 14.40mlTrain batch 28/32 - 241.4ms/batch - loss: 20.67764 - diff: 14.24mlTrain batch 29/32 - 240.9ms/batch - loss: 21.30134 - diff: 14.47mlTrain batch 30/32 - 242.0ms/batch - loss: 21.22778 - diff: 14.39mlTrain batch 31/32 - 241.0ms/batch - loss: 20.95262 - diff: 14.34mlTrain batch 32/32 - 79.5ms/batch - loss: 20.89821 - diff: 14.28mlTrain batch 32/32 - 11.7s 79.5ms/batch - loss: 20.89821 - diff: 14.28ml
Test 1.2s: val_loss: 747.76816 - diff: 101.07ml

Epoch 149: current best loss = 101.53151, at epoch 6
Train batch 1/32 - 240.9ms/batch - loss: 40.30270 - diff: 20.71mlTrain batch 2/32 - 241.5ms/batch - loss: 55.08982 - diff: 25.54mlTrain batch 3/32 - 240.6ms/batch - loss: 41.25057 - diff: 20.90mlTrain batch 4/32 - 240.9ms/batch - loss: 42.09344 - diff: 21.47mlTrain batch 5/32 - 240.6ms/batch - loss: 40.30128 - diff: 21.17mlTrain batch 6/32 - 241.3ms/batch - loss: 35.42184 - diff: 19.26mlTrain batch 7/32 - 240.7ms/batch - loss: 32.79850 - diff: 18.38mlTrain batch 8/32 - 240.9ms/batch - loss: 34.68325 - diff: 19.22mlTrain batch 9/32 - 241.0ms/batch - loss: 38.23806 - diff: 20.39mlTrain batch 10/32 - 241.7ms/batch - loss: 36.75101 - diff: 19.99mlTrain batch 11/32 - 240.7ms/batch - loss: 35.59479 - diff: 19.80mlTrain batch 12/32 - 241.5ms/batch - loss: 33.64327 - diff: 19.06mlTrain batch 13/32 - 240.8ms/batch - loss: 32.34926 - diff: 18.66mlTrain batch 14/32 - 241.4ms/batch - loss: 31.22780 - diff: 18.24mlTrain batch 15/32 - 240.8ms/batch - loss: 30.00537 - diff: 17.73mlTrain batch 16/32 - 241.8ms/batch - loss: 30.77646 - diff: 18.06mlTrain batch 17/32 - 240.8ms/batch - loss: 29.58812 - diff: 17.64mlTrain batch 18/32 - 241.5ms/batch - loss: 29.44143 - diff: 17.72mlTrain batch 19/32 - 240.9ms/batch - loss: 28.52032 - diff: 17.37mlTrain batch 20/32 - 241.8ms/batch - loss: 27.67289 - diff: 17.08mlTrain batch 21/32 - 240.7ms/batch - loss: 26.81589 - diff: 16.72mlTrain batch 22/32 - 241.9ms/batch - loss: 25.93529 - diff: 16.37mlTrain batch 23/32 - 240.9ms/batch - loss: 25.44923 - diff: 16.17mlTrain batch 24/32 - 241.7ms/batch - loss: 25.94351 - diff: 16.27mlTrain batch 25/32 - 241.4ms/batch - loss: 25.91704 - diff: 16.24mlTrain batch 26/32 - 241.5ms/batch - loss: 27.38761 - diff: 16.77mlTrain batch 27/32 - 240.4ms/batch - loss: 26.76122 - diff: 16.54mlTrain batch 28/32 - 241.0ms/batch - loss: 26.16959 - diff: 16.32mlTrain batch 29/32 - 240.9ms/batch - loss: 25.73582 - diff: 16.14mlTrain batch 30/32 - 241.5ms/batch - loss: 25.13151 - diff: 15.91mlTrain batch 31/32 - 240.5ms/batch - loss: 29.29368 - diff: 16.94mlTrain batch 32/32 - 79.4ms/batch - loss: 29.71385 - diff: 16.92mlTrain batch 32/32 - 12.2s 79.4ms/batch - loss: 29.71385 - diff: 16.92ml
Test 1.2s: val_loss: 765.43859 - diff: 101.33ml
Epoch   150: reducing learning rate of group 0 to 1.2207e-07.

Traceback (most recent call last):
  File "train.py", line 266, in <module>
    plot_results(train_losses, test_losses, title=f"Loss {target_label}", save_as=exp_name + "_loss")
  File "/home/allochi/tfm/workspace/lib/utils.py", line 393, in plot_results
    plt.plot(train_values, "r", label="train")
  File "/home/allochi/.conda/envs/DL_env/lib/python3.8/site-packages/matplotlib/pyplot.py", line 2824, in plot
    return gca().plot(
  File "/home/allochi/.conda/envs/DL_env/lib/python3.8/site-packages/matplotlib/pyplot.py", line 2352, in gca
    return gcf().gca(**kwargs)
  File "/home/allochi/.conda/envs/DL_env/lib/python3.8/site-packages/matplotlib/pyplot.py", line 731, in gcf
    return figure()
  File "/home/allochi/.conda/envs/DL_env/lib/python3.8/site-packages/matplotlib/pyplot.py", line 671, in figure
    figManager = new_figure_manager(num, figsize=figsize,
  File "/home/allochi/.conda/envs/DL_env/lib/python3.8/site-packages/matplotlib/pyplot.py", line 299, in new_figure_manager
    return _backend_mod.new_figure_manager(*args, **kwargs)
  File "/home/allochi/.conda/envs/DL_env/lib/python3.8/site-packages/matplotlib/backend_bases.py", line 3494, in new_figure_manager
    return cls.new_figure_manager_given_figure(num, fig)
  File "/home/allochi/.conda/envs/DL_env/lib/python3.8/site-packages/matplotlib/backends/_backend_tk.py", line 868, in new_figure_manager_given_figure
    window = tk.Tk(className="matplotlib")
  File "/home/allochi/.conda/envs/DL_env/lib/python3.8/tkinter/__init__.py", line 2261, in __init__
    self.tk = _tkinter.create(screenName, baseName, className, interactive, wantobjects, useTk, sync, use)
_tkinter.TclError: couldn't connect to display "localhost:10.0"
