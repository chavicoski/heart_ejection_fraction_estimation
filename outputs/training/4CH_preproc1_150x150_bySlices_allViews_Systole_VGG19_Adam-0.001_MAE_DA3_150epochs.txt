nohup: ignoring input
2020-09-02 10:49:50.744967: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/allochi/protobuf_install/lib:/home/allochi/protobuf_install/lib:/usr/local/cuda-10.1/lib64/:/usr/local/cudnn/cuda10.1/dnn7.6.5/lib64/:/usr/local/cuda-10.0/lib64/:/usr/local/cudnn/cuda10/dnn7.6.5/lib64/
2020-09-02 10:49:50.745656: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/allochi/protobuf_install/lib:/home/allochi/protobuf_install/lib:/usr/local/cuda-10.1/lib64/:/usr/local/cudnn/cuda10.1/dnn7.6.5/lib64/:/usr/local/cuda-10.0/lib64/:/usr/local/cudnn/cuda10/dnn7.6.5/lib64/
2020-09-02 10:49:50.745710: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
Running experiment 4CH_preproc1_150x150_bySlices_dataset_allViews_Systole_VGG19_Adam-0.001_MAE_DA3
Going to train with the GPU in the slot 0 -> device model: GeForce GTX 1080
Model architecture:
 VGG19(
  (first_conv): Sequential(
    (0): Conv2d(30, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU()
    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (pretrained_block): Sequential(
    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU(inplace=True)
    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): ReLU(inplace=True)
    (5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (6): ReLU(inplace=True)
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (9): ReLU(inplace=True)
    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): ReLU(inplace=True)
    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (13): ReLU(inplace=True)
    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (15): ReLU(inplace=True)
    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (18): ReLU(inplace=True)
    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (20): ReLU(inplace=True)
    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (22): ReLU(inplace=True)
    (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (24): ReLU(inplace=True)
    (25): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (27): ReLU(inplace=True)
    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (29): ReLU(inplace=True)
    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (31): ReLU(inplace=True)
    (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (33): ReLU(inplace=True)
    (34): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (reduction_block): Sequential(
    (0): AdaptiveAvgPool2d(output_size=(1, 1))
    (1): Flatten()
  )
  (dense_block): Sequential(
    (0): Linear(in_features=512, out_features=512, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.4, inplace=False)
    (3): Linear(in_features=512, out_features=1, bias=True)
  )
) 


############################
# TRAIN PHASE:  150 epochs #
############################

Epoch 0: 
Train batch 1/7 - 990.7ms/batch - loss: 0.88834 - diff: 71.07mlTrain batch 2/7 - 460.2ms/batch - loss: 0.90841 - diff: 72.67mlTrain batch 3/7 - 461.4ms/batch - loss: 0.90280 - diff: 72.22mlTrain batch 4/7 - 460.6ms/batch - loss: 0.89553 - diff: 71.64mlTrain batch 5/7 - 460.2ms/batch - loss: 0.87502 - diff: 70.00mlTrain batch 6/7 - 463.1ms/batch - loss: 0.86384 - diff: 69.11mlTrain batch 7/7 - 48.4ms/batch - loss: 0.94089 - diff: 68.74mlTrain batch 7/7 - 21.0s 48.4ms/batch - loss: 0.94089 - diff: 68.74ml
Test 7.0s: val_loss: 0.99690 - diff: 65.70ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Systole_VGG19_Adam-0.001_MAE_DA3_best

Epoch 1: current best loss = 0.99690, at epoch 0
Train batch 1/7 - 462.5ms/batch - loss: 0.68845 - diff: 55.08mlTrain batch 2/7 - 465.9ms/batch - loss: 0.72360 - diff: 57.89mlTrain batch 3/7 - 470.3ms/batch - loss: 0.73863 - diff: 59.09mlTrain batch 4/7 - 461.5ms/batch - loss: 0.72536 - diff: 58.03mlTrain batch 5/7 - 470.4ms/batch - loss: 0.73051 - diff: 58.44mlTrain batch 6/7 - 461.2ms/batch - loss: 0.70865 - diff: 56.69mlTrain batch 7/7 - 48.2ms/batch - loss: 0.77476 - diff: 56.41mlTrain batch 7/7 - 10.0s 48.2ms/batch - loss: 0.77476 - diff: 56.41ml
Test 0.9s: val_loss: 0.91378 - diff: 59.57ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Systole_VGG19_Adam-0.001_MAE_DA3_best

Epoch 2: current best loss = 0.91378, at epoch 1
Train batch 1/7 - 466.9ms/batch - loss: 0.56694 - diff: 45.36mlTrain batch 2/7 - 463.6ms/batch - loss: 0.54988 - diff: 43.99mlTrain batch 3/7 - 461.0ms/batch - loss: 0.52200 - diff: 41.76mlTrain batch 4/7 - 461.5ms/batch - loss: 0.49518 - diff: 39.61mlTrain batch 5/7 - 460.7ms/batch - loss: 0.47619 - diff: 38.10mlTrain batch 6/7 - 464.2ms/batch - loss: 0.45829 - diff: 36.66mlTrain batch 7/7 - 48.4ms/batch - loss: 0.49427 - diff: 36.43mlTrain batch 7/7 - 10.0s 48.4ms/batch - loss: 0.49427 - diff: 36.43ml
Test 1.0s: val_loss: 0.77150 - diff: 49.26ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Systole_VGG19_Adam-0.001_MAE_DA3_best

Epoch 3: current best loss = 0.77150, at epoch 2
Train batch 1/7 - 468.7ms/batch - loss: 0.38925 - diff: 31.14mlTrain batch 2/7 - 465.2ms/batch - loss: 0.37695 - diff: 30.16mlTrain batch 3/7 - 480.1ms/batch - loss: 0.36720 - diff: 29.38mlTrain batch 4/7 - 470.0ms/batch - loss: 0.36058 - diff: 28.85mlTrain batch 5/7 - 470.4ms/batch - loss: 0.36817 - diff: 29.45mlTrain batch 6/7 - 466.4ms/batch - loss: 0.36612 - diff: 29.29mlTrain batch 7/7 - 48.4ms/batch - loss: 0.46197 - diff: 29.58mlTrain batch 7/7 - 10.7s 48.4ms/batch - loss: 0.46197 - diff: 29.58ml
Test 1.0s: val_loss: 0.65753 - diff: 43.21ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Systole_VGG19_Adam-0.001_MAE_DA3_best

Epoch 4: current best loss = 0.65753, at epoch 3
Train batch 1/7 - 464.7ms/batch - loss: 0.34908 - diff: 27.93mlTrain batch 2/7 - 464.4ms/batch - loss: 0.33352 - diff: 26.68mlTrain batch 3/7 - 464.3ms/batch - loss: 0.36891 - diff: 29.51mlTrain batch 4/7 - 465.7ms/batch - loss: 0.37609 - diff: 30.09mlTrain batch 5/7 - 460.6ms/batch - loss: 0.37041 - diff: 29.63mlTrain batch 6/7 - 469.2ms/batch - loss: 0.36016 - diff: 28.81mlTrain batch 7/7 - 48.6ms/batch - loss: 0.40687 - diff: 28.76mlTrain batch 7/7 - 10.5s 48.6ms/batch - loss: 0.40687 - diff: 28.76ml
Test 1.0s: val_loss: 0.60247 - diff: 39.29ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Systole_VGG19_Adam-0.001_MAE_DA3_best

Epoch 5: current best loss = 0.60247, at epoch 4
Train batch 1/7 - 463.9ms/batch - loss: 0.35427 - diff: 28.34mlTrain batch 2/7 - 464.0ms/batch - loss: 0.36939 - diff: 29.55mlTrain batch 3/7 - 463.3ms/batch - loss: 0.36782 - diff: 29.43mlTrain batch 4/7 - 465.1ms/batch - loss: 0.35312 - diff: 28.25mlTrain batch 5/7 - 463.0ms/batch - loss: 0.35473 - diff: 28.38mlTrain batch 6/7 - 467.7ms/batch - loss: 0.35080 - diff: 28.06mlTrain batch 7/7 - 48.6ms/batch - loss: 0.40121 - diff: 28.05mlTrain batch 7/7 - 10.3s 48.6ms/batch - loss: 0.40121 - diff: 28.05ml
Test 1.0s: val_loss: 0.53688 - diff: 35.63ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Systole_VGG19_Adam-0.001_MAE_DA3_best

Epoch 6: current best loss = 0.53688, at epoch 5
Train batch 1/7 - 477.5ms/batch - loss: 0.35849 - diff: 28.68mlTrain batch 2/7 - 464.9ms/batch - loss: 0.38379 - diff: 30.70mlTrain batch 3/7 - 472.7ms/batch - loss: 0.36858 - diff: 29.49mlTrain batch 4/7 - 468.0ms/batch - loss: 0.36833 - diff: 29.47mlTrain batch 5/7 - 464.9ms/batch - loss: 0.34772 - diff: 27.82mlTrain batch 6/7 - 469.3ms/batch - loss: 0.35372 - diff: 28.30mlTrain batch 7/7 - 48.7ms/batch - loss: 0.39964 - diff: 28.25mlTrain batch 7/7 - 10.4s 48.7ms/batch - loss: 0.39964 - diff: 28.25ml
Test 1.0s: val_loss: 0.53918 - diff: 34.28ml

Epoch 7: current best loss = 0.53688, at epoch 5
Train batch 1/7 - 479.3ms/batch - loss: 0.32234 - diff: 25.79mlTrain batch 2/7 - 463.1ms/batch - loss: 0.35824 - diff: 28.66mlTrain batch 3/7 - 466.6ms/batch - loss: 0.33360 - diff: 26.69mlTrain batch 4/7 - 464.3ms/batch - loss: 0.35517 - diff: 28.41mlTrain batch 5/7 - 463.7ms/batch - loss: 0.34818 - diff: 27.85mlTrain batch 6/7 - 469.6ms/batch - loss: 0.35135 - diff: 28.11mlTrain batch 7/7 - 48.4ms/batch - loss: 0.38995 - diff: 28.01mlTrain batch 7/7 - 10.4s 48.4ms/batch - loss: 0.38995 - diff: 28.01ml
Test 1.0s: val_loss: 0.52211 - diff: 33.71ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Systole_VGG19_Adam-0.001_MAE_DA3_best

Epoch 8: current best loss = 0.52211, at epoch 7
Train batch 1/7 - 469.6ms/batch - loss: 0.33674 - diff: 26.94mlTrain batch 2/7 - 474.1ms/batch - loss: 0.35381 - diff: 28.30mlTrain batch 3/7 - 476.4ms/batch - loss: 0.36593 - diff: 29.27mlTrain batch 4/7 - 465.2ms/batch - loss: 0.35306 - diff: 28.24mlTrain batch 5/7 - 475.8ms/batch - loss: 0.34840 - diff: 27.87mlTrain batch 6/7 - 463.0ms/batch - loss: 0.35333 - diff: 28.27mlTrain batch 7/7 - 48.5ms/batch - loss: 0.39399 - diff: 28.18mlTrain batch 7/7 - 10.3s 48.5ms/batch - loss: 0.39399 - diff: 28.18ml
Test 1.0s: val_loss: 0.46837 - diff: 32.42ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Systole_VGG19_Adam-0.001_MAE_DA3_best

Epoch 9: current best loss = 0.46837, at epoch 8
Train batch 1/7 - 478.1ms/batch - loss: 0.43504 - diff: 34.80mlTrain batch 2/7 - 463.5ms/batch - loss: 0.40541 - diff: 32.43mlTrain batch 3/7 - 474.5ms/batch - loss: 0.39261 - diff: 31.41mlTrain batch 4/7 - 463.8ms/batch - loss: 0.38408 - diff: 30.73mlTrain batch 5/7 - 464.1ms/batch - loss: 0.35984 - diff: 28.79mlTrain batch 6/7 - 469.3ms/batch - loss: 0.35562 - diff: 28.45mlTrain batch 7/7 - 48.6ms/batch - loss: 0.38017 - diff: 28.25mlTrain batch 7/7 - 10.4s 48.6ms/batch - loss: 0.38017 - diff: 28.25ml
Test 1.0s: val_loss: 0.47295 - diff: 31.37ml

Epoch 10: current best loss = 0.46837, at epoch 8
Train batch 1/7 - 481.8ms/batch - loss: 0.34260 - diff: 27.41mlTrain batch 2/7 - 463.1ms/batch - loss: 0.33674 - diff: 26.94mlTrain batch 3/7 - 464.3ms/batch - loss: 0.34214 - diff: 27.37mlTrain batch 4/7 - 464.1ms/batch - loss: 0.33486 - diff: 26.79mlTrain batch 5/7 - 465.0ms/batch - loss: 0.33826 - diff: 27.06mlTrain batch 6/7 - 466.1ms/batch - loss: 0.34887 - diff: 27.91mlTrain batch 7/7 - 48.6ms/batch - loss: 0.41840 - diff: 28.03mlTrain batch 7/7 - 10.5s 48.6ms/batch - loss: 0.41840 - diff: 28.03ml
Test 1.0s: val_loss: 0.46167 - diff: 29.47ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Systole_VGG19_Adam-0.001_MAE_DA3_best

Epoch 11: current best loss = 0.46167, at epoch 10
Train batch 1/7 - 473.8ms/batch - loss: 0.30516 - diff: 24.41mlTrain batch 2/7 - 464.0ms/batch - loss: 0.33982 - diff: 27.19mlTrain batch 3/7 - 464.6ms/batch - loss: 0.34564 - diff: 27.65mlTrain batch 4/7 - 466.0ms/batch - loss: 0.32992 - diff: 26.39mlTrain batch 5/7 - 465.1ms/batch - loss: 0.35370 - diff: 28.30mlTrain batch 6/7 - 466.7ms/batch - loss: 0.34782 - diff: 27.83mlTrain batch 7/7 - 48.8ms/batch - loss: 0.46136 - diff: 28.26mlTrain batch 7/7 - 10.5s 48.8ms/batch - loss: 0.46136 - diff: 28.26ml
Test 1.0s: val_loss: 0.39961 - diff: 25.79ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Systole_VGG19_Adam-0.001_MAE_DA3_best

Epoch 12: current best loss = 0.39961, at epoch 11
Train batch 1/7 - 482.1ms/batch - loss: 0.30005 - diff: 24.00mlTrain batch 2/7 - 463.7ms/batch - loss: 0.32819 - diff: 26.25mlTrain batch 3/7 - 474.1ms/batch - loss: 0.37052 - diff: 29.64mlTrain batch 4/7 - 466.1ms/batch - loss: 0.36459 - diff: 29.17mlTrain batch 5/7 - 466.2ms/batch - loss: 0.35832 - diff: 28.67mlTrain batch 6/7 - 469.2ms/batch - loss: 0.34705 - diff: 27.76mlTrain batch 7/7 - 48.6ms/batch - loss: 0.40475 - diff: 27.80mlTrain batch 7/7 - 10.5s 48.6ms/batch - loss: 0.40475 - diff: 27.80ml
Test 1.0s: val_loss: 0.38932 - diff: 25.35ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Systole_VGG19_Adam-0.001_MAE_DA3_best

Epoch 13: current best loss = 0.38932, at epoch 12
Train batch 1/7 - 478.9ms/batch - loss: 0.33685 - diff: 26.95mlTrain batch 2/7 - 462.8ms/batch - loss: 0.42158 - diff: 33.73mlTrain batch 3/7 - 464.6ms/batch - loss: 0.38835 - diff: 31.07mlTrain batch 4/7 - 465.7ms/batch - loss: 0.36648 - diff: 29.32mlTrain batch 5/7 - 463.4ms/batch - loss: 0.35140 - diff: 28.11mlTrain batch 6/7 - 469.2ms/batch - loss: 0.34491 - diff: 27.59mlTrain batch 7/7 - 48.6ms/batch - loss: 0.35870 - diff: 27.33mlTrain batch 7/7 - 10.5s 48.6ms/batch - loss: 0.35870 - diff: 27.33ml
Test 1.0s: val_loss: 0.39406 - diff: 24.95ml

Epoch 14: current best loss = 0.38932, at epoch 12
Train batch 1/7 - 467.9ms/batch - loss: 0.35348 - diff: 28.28mlTrain batch 2/7 - 463.0ms/batch - loss: 0.30064 - diff: 24.05mlTrain batch 3/7 - 464.1ms/batch - loss: 0.34480 - diff: 27.58mlTrain batch 4/7 - 465.3ms/batch - loss: 0.33703 - diff: 26.96mlTrain batch 5/7 - 468.8ms/batch - loss: 0.34812 - diff: 27.85mlTrain batch 6/7 - 470.4ms/batch - loss: 0.33590 - diff: 26.87mlTrain batch 7/7 - 48.6ms/batch - loss: 0.37568 - diff: 26.80mlTrain batch 7/7 - 10.5s 48.6ms/batch - loss: 0.37568 - diff: 26.80ml
Test 1.0s: val_loss: 0.37420 - diff: 25.63ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Systole_VGG19_Adam-0.001_MAE_DA3_best

Epoch 15: current best loss = 0.37420, at epoch 14
Train batch 1/7 - 472.6ms/batch - loss: 0.40633 - diff: 32.51mlTrain batch 2/7 - 479.3ms/batch - loss: 0.36135 - diff: 28.91mlTrain batch 3/7 - 474.1ms/batch - loss: 0.34379 - diff: 27.50mlTrain batch 4/7 - 463.1ms/batch - loss: 0.33971 - diff: 27.18mlTrain batch 5/7 - 464.3ms/batch - loss: 0.33511 - diff: 26.81mlTrain batch 6/7 - 483.4ms/batch - loss: 0.32875 - diff: 26.30mlTrain batch 7/7 - 49.0ms/batch - loss: 0.35225 - diff: 26.12mlTrain batch 7/7 - 10.4s 49.0ms/batch - loss: 0.35225 - diff: 26.12ml
Test 0.9s: val_loss: 0.44699 - diff: 28.52ml

Epoch 16: current best loss = 0.37420, at epoch 14
Train batch 1/7 - 464.2ms/batch - loss: 0.38900 - diff: 31.12mlTrain batch 2/7 - 464.7ms/batch - loss: 0.32837 - diff: 26.27mlTrain batch 3/7 - 479.0ms/batch - loss: 0.34650 - diff: 27.72mlTrain batch 4/7 - 464.0ms/batch - loss: 0.33421 - diff: 26.74mlTrain batch 5/7 - 472.2ms/batch - loss: 0.34491 - diff: 27.59mlTrain batch 6/7 - 465.5ms/batch - loss: 0.33385 - diff: 26.71mlTrain batch 7/7 - 48.6ms/batch - loss: 0.37148 - diff: 26.62mlTrain batch 7/7 - 10.3s 48.6ms/batch - loss: 0.37148 - diff: 26.62ml
Test 1.1s: val_loss: 0.46296 - diff: 29.70ml

Epoch 17: current best loss = 0.37420, at epoch 14
Train batch 1/7 - 470.2ms/batch - loss: 0.36469 - diff: 29.18mlTrain batch 2/7 - 464.9ms/batch - loss: 0.28358 - diff: 22.69mlTrain batch 3/7 - 471.3ms/batch - loss: 0.32409 - diff: 25.93mlTrain batch 4/7 - 470.1ms/batch - loss: 0.32248 - diff: 25.80mlTrain batch 5/7 - 473.5ms/batch - loss: 0.32951 - diff: 26.36mlTrain batch 6/7 - 465.6ms/batch - loss: 0.33087 - diff: 26.47mlTrain batch 7/7 - 48.7ms/batch - loss: 0.38205 - diff: 26.48mlTrain batch 7/7 - 10.4s 48.7ms/batch - loss: 0.38205 - diff: 26.48ml
Test 1.0s: val_loss: 0.41322 - diff: 27.69ml

Epoch 18: current best loss = 0.37420, at epoch 14
Train batch 1/7 - 473.1ms/batch - loss: 0.34543 - diff: 27.63mlTrain batch 2/7 - 465.3ms/batch - loss: 0.34969 - diff: 27.98mlTrain batch 3/7 - 465.4ms/batch - loss: 0.36836 - diff: 29.47mlTrain batch 4/7 - 464.3ms/batch - loss: 0.35411 - diff: 28.33mlTrain batch 5/7 - 463.6ms/batch - loss: 0.34818 - diff: 27.85mlTrain batch 6/7 - 470.2ms/batch - loss: 0.33656 - diff: 26.92mlTrain batch 7/7 - 48.6ms/batch - loss: 0.34752 - diff: 26.65mlTrain batch 7/7 - 10.4s 48.6ms/batch - loss: 0.34752 - diff: 26.65ml
Test 1.0s: val_loss: 0.36172 - diff: 24.26ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Systole_VGG19_Adam-0.001_MAE_DA3_best

Epoch 19: current best loss = 0.36172, at epoch 18
Train batch 1/7 - 464.2ms/batch - loss: 0.38642 - diff: 30.91mlTrain batch 2/7 - 465.2ms/batch - loss: 0.34000 - diff: 27.20mlTrain batch 3/7 - 465.5ms/batch - loss: 0.30971 - diff: 24.78mlTrain batch 4/7 - 470.4ms/batch - loss: 0.31241 - diff: 24.99mlTrain batch 5/7 - 464.2ms/batch - loss: 0.30686 - diff: 24.55mlTrain batch 6/7 - 467.3ms/batch - loss: 0.32258 - diff: 25.81mlTrain batch 7/7 - 48.5ms/batch - loss: 0.35170 - diff: 25.67mlTrain batch 7/7 - 10.4s 48.5ms/batch - loss: 0.35170 - diff: 25.67ml
Test 1.0s: val_loss: 0.36512 - diff: 24.53ml

Epoch 20: current best loss = 0.36172, at epoch 18
Train batch 1/7 - 475.3ms/batch - loss: 0.28721 - diff: 22.98mlTrain batch 2/7 - 466.7ms/batch - loss: 0.30014 - diff: 24.01mlTrain batch 3/7 - 478.5ms/batch - loss: 0.32730 - diff: 26.18mlTrain batch 4/7 - 463.5ms/batch - loss: 0.32570 - diff: 26.06mlTrain batch 5/7 - 464.3ms/batch - loss: 0.32222 - diff: 25.78mlTrain batch 6/7 - 467.2ms/batch - loss: 0.32626 - diff: 26.10mlTrain batch 7/7 - 48.7ms/batch - loss: 0.38375 - diff: 26.16mlTrain batch 7/7 - 10.5s 48.7ms/batch - loss: 0.38375 - diff: 26.16ml
Test 1.0s: val_loss: 0.37355 - diff: 24.74ml

Epoch 21: current best loss = 0.36172, at epoch 18
Train batch 1/7 - 467.3ms/batch - loss: 0.32753 - diff: 26.20mlTrain batch 2/7 - 467.7ms/batch - loss: 0.31083 - diff: 24.87mlTrain batch 3/7 - 465.1ms/batch - loss: 0.31240 - diff: 24.99mlTrain batch 4/7 - 465.8ms/batch - loss: 0.31475 - diff: 25.18mlTrain batch 5/7 - 464.5ms/batch - loss: 0.32599 - diff: 26.08mlTrain batch 6/7 - 468.6ms/batch - loss: 0.32606 - diff: 26.08mlTrain batch 7/7 - 48.7ms/batch - loss: 0.35956 - diff: 25.98mlTrain batch 7/7 - 10.4s 48.7ms/batch - loss: 0.35956 - diff: 25.98ml
Test 1.0s: val_loss: 0.38063 - diff: 25.33ml

Epoch 22: current best loss = 0.36172, at epoch 18
Train batch 1/7 - 482.7ms/batch - loss: 0.32409 - diff: 25.93mlTrain batch 2/7 - 464.3ms/batch - loss: 0.35201 - diff: 28.16mlTrain batch 3/7 - 474.5ms/batch - loss: 0.34352 - diff: 27.48mlTrain batch 4/7 - 463.7ms/batch - loss: 0.33615 - diff: 26.89mlTrain batch 5/7 - 463.9ms/batch - loss: 0.33357 - diff: 26.69mlTrain batch 6/7 - 467.5ms/batch - loss: 0.32524 - diff: 26.02mlTrain batch 7/7 - 48.9ms/batch - loss: 0.34888 - diff: 25.84mlTrain batch 7/7 - 10.5s 48.9ms/batch - loss: 0.34888 - diff: 25.84ml
Test 1.0s: val_loss: 0.39724 - diff: 24.55ml

Epoch 23: current best loss = 0.36172, at epoch 18
Train batch 1/7 - 465.6ms/batch - loss: 0.38062 - diff: 30.45mlTrain batch 2/7 - 463.8ms/batch - loss: 0.35645 - diff: 28.52mlTrain batch 3/7 - 466.7ms/batch - loss: 0.34500 - diff: 27.60mlTrain batch 4/7 - 465.2ms/batch - loss: 0.33261 - diff: 26.61mlTrain batch 5/7 - 473.4ms/batch - loss: 0.32937 - diff: 26.35mlTrain batch 6/7 - 463.1ms/batch - loss: 0.32654 - diff: 26.12mlTrain batch 7/7 - 48.6ms/batch - loss: 0.39943 - diff: 26.29mlTrain batch 7/7 - 10.5s 48.6ms/batch - loss: 0.39943 - diff: 26.29ml
Test 1.0s: val_loss: 0.35409 - diff: 23.38ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Systole_VGG19_Adam-0.001_MAE_DA3_best

Epoch 24: current best loss = 0.35409, at epoch 23
Train batch 1/7 - 476.0ms/batch - loss: 0.32006 - diff: 25.60mlTrain batch 2/7 - 468.0ms/batch - loss: 0.34916 - diff: 27.93mlTrain batch 3/7 - 467.1ms/batch - loss: 0.32213 - diff: 25.77mlTrain batch 4/7 - 465.4ms/batch - loss: 0.30741 - diff: 24.59mlTrain batch 5/7 - 464.1ms/batch - loss: 0.32242 - diff: 25.79mlTrain batch 6/7 - 465.9ms/batch - loss: 0.32596 - diff: 26.08mlTrain batch 7/7 - 49.4ms/batch - loss: 0.34029 - diff: 25.84mlTrain batch 7/7 - 10.4s 49.4ms/batch - loss: 0.34029 - diff: 25.84ml
Test 1.0s: val_loss: 0.34558 - diff: 23.44ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Systole_VGG19_Adam-0.001_MAE_DA3_best

Epoch 25: current best loss = 0.34558, at epoch 24
Train batch 1/7 - 478.3ms/batch - loss: 0.27611 - diff: 22.09mlTrain batch 2/7 - 465.6ms/batch - loss: 0.30606 - diff: 24.48mlTrain batch 3/7 - 465.3ms/batch - loss: 0.32594 - diff: 26.08mlTrain batch 4/7 - 466.3ms/batch - loss: 0.32817 - diff: 26.25mlTrain batch 5/7 - 471.2ms/batch - loss: 0.32281 - diff: 25.83mlTrain batch 6/7 - 466.7ms/batch - loss: 0.31502 - diff: 25.20mlTrain batch 7/7 - 50.1ms/batch - loss: 0.38952 - diff: 25.39mlTrain batch 7/7 - 10.4s 50.1ms/batch - loss: 0.38952 - diff: 25.39ml
Test 1.0s: val_loss: 0.35550 - diff: 22.90ml

Epoch 26: current best loss = 0.34558, at epoch 24
Train batch 1/7 - 473.8ms/batch - loss: 0.28195 - diff: 22.56mlTrain batch 2/7 - 464.7ms/batch - loss: 0.35518 - diff: 28.41mlTrain batch 3/7 - 471.2ms/batch - loss: 0.33542 - diff: 26.83mlTrain batch 4/7 - 466.7ms/batch - loss: 0.33023 - diff: 26.42mlTrain batch 5/7 - 471.4ms/batch - loss: 0.32896 - diff: 26.32mlTrain batch 6/7 - 462.5ms/batch - loss: 0.32218 - diff: 25.77mlTrain batch 7/7 - 48.7ms/batch - loss: 0.33533 - diff: 25.53mlTrain batch 7/7 - 10.3s 48.7ms/batch - loss: 0.33533 - diff: 25.53ml
Test 1.0s: val_loss: 0.33094 - diff: 22.39ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Systole_VGG19_Adam-0.001_MAE_DA3_best

Epoch 27: current best loss = 0.33094, at epoch 26
Train batch 1/7 - 467.8ms/batch - loss: 0.32057 - diff: 25.65mlTrain batch 2/7 - 465.8ms/batch - loss: 0.31840 - diff: 25.47mlTrain batch 3/7 - 465.8ms/batch - loss: 0.30462 - diff: 24.37mlTrain batch 4/7 - 464.1ms/batch - loss: 0.32895 - diff: 26.32mlTrain batch 5/7 - 463.6ms/batch - loss: 0.32810 - diff: 26.25mlTrain batch 6/7 - 468.4ms/batch - loss: 0.31719 - diff: 25.38mlTrain batch 7/7 - 48.5ms/batch - loss: 0.37107 - diff: 25.42mlTrain batch 7/7 - 10.4s 48.5ms/batch - loss: 0.37107 - diff: 25.42ml
Test 1.0s: val_loss: 0.32158 - diff: 22.35ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Systole_VGG19_Adam-0.001_MAE_DA3_best

Epoch 28: current best loss = 0.32158, at epoch 27
Train batch 1/7 - 465.7ms/batch - loss: 0.36160 - diff: 28.93mlTrain batch 2/7 - 477.6ms/batch - loss: 0.31916 - diff: 25.53mlTrain batch 3/7 - 466.1ms/batch - loss: 0.31016 - diff: 24.81mlTrain batch 4/7 - 476.9ms/batch - loss: 0.32698 - diff: 26.16mlTrain batch 5/7 - 465.9ms/batch - loss: 0.32570 - diff: 26.06mlTrain batch 6/7 - 469.7ms/batch - loss: 0.31682 - diff: 25.35mlTrain batch 7/7 - 48.7ms/batch - loss: 0.37020 - diff: 25.39mlTrain batch 7/7 - 10.5s 48.7ms/batch - loss: 0.37020 - diff: 25.39ml
Test 1.0s: val_loss: 0.33850 - diff: 22.64ml

Epoch 29: current best loss = 0.32158, at epoch 27
Train batch 1/7 - 465.5ms/batch - loss: 0.27580 - diff: 22.06mlTrain batch 2/7 - 464.5ms/batch - loss: 0.30497 - diff: 24.40mlTrain batch 3/7 - 465.9ms/batch - loss: 0.28952 - diff: 23.16mlTrain batch 4/7 - 464.2ms/batch - loss: 0.30901 - diff: 24.72mlTrain batch 5/7 - 466.5ms/batch - loss: 0.30135 - diff: 24.11mlTrain batch 6/7 - 468.9ms/batch - loss: 0.30479 - diff: 24.38mlTrain batch 7/7 - 48.9ms/batch - loss: 0.34860 - diff: 24.37mlTrain batch 7/7 - 10.5s 48.9ms/batch - loss: 0.34860 - diff: 24.37ml
Test 1.0s: val_loss: 0.36742 - diff: 24.76ml

Epoch 30: current best loss = 0.32158, at epoch 27
Train batch 1/7 - 478.8ms/batch - loss: 0.36076 - diff: 28.86mlTrain batch 2/7 - 464.5ms/batch - loss: 0.34411 - diff: 27.53mlTrain batch 3/7 - 464.3ms/batch - loss: 0.34616 - diff: 27.69mlTrain batch 4/7 - 466.1ms/batch - loss: 0.33867 - diff: 27.09mlTrain batch 5/7 - 463.2ms/batch - loss: 0.32226 - diff: 25.78mlTrain batch 6/7 - 469.6ms/batch - loss: 0.31294 - diff: 25.04mlTrain batch 7/7 - 48.7ms/batch - loss: 0.33916 - diff: 24.89mlTrain batch 7/7 - 10.4s 48.7ms/batch - loss: 0.33916 - diff: 24.89ml
Test 1.0s: val_loss: 0.39453 - diff: 24.70ml

Epoch 31: current best loss = 0.32158, at epoch 27
Train batch 1/7 - 465.9ms/batch - loss: 0.27792 - diff: 22.23mlTrain batch 2/7 - 467.8ms/batch - loss: 0.30027 - diff: 24.02mlTrain batch 3/7 - 466.9ms/batch - loss: 0.31564 - diff: 25.25mlTrain batch 4/7 - 464.1ms/batch - loss: 0.32062 - diff: 25.65mlTrain batch 5/7 - 463.5ms/batch - loss: 0.32518 - diff: 26.01mlTrain batch 6/7 - 467.8ms/batch - loss: 0.31508 - diff: 25.21mlTrain batch 7/7 - 48.7ms/batch - loss: 0.32538 - diff: 24.95mlTrain batch 7/7 - 10.5s 48.7ms/batch - loss: 0.32538 - diff: 24.95ml
Test 1.0s: val_loss: 0.40481 - diff: 26.02ml

Epoch 32: current best loss = 0.32158, at epoch 27
Train batch 1/7 - 463.5ms/batch - loss: 0.31031 - diff: 24.83mlTrain batch 2/7 - 466.0ms/batch - loss: 0.31321 - diff: 25.06mlTrain batch 3/7 - 466.4ms/batch - loss: 0.33284 - diff: 26.63mlTrain batch 4/7 - 464.8ms/batch - loss: 0.33171 - diff: 26.54mlTrain batch 5/7 - 468.2ms/batch - loss: 0.32115 - diff: 25.69mlTrain batch 6/7 - 469.1ms/batch - loss: 0.31253 - diff: 25.00mlTrain batch 7/7 - 48.8ms/batch - loss: 0.38502 - diff: 25.18mlTrain batch 7/7 - 10.4s 48.8ms/batch - loss: 0.38502 - diff: 25.18ml
Test 1.0s: val_loss: 0.37291 - diff: 23.25ml

Epoch 33: current best loss = 0.32158, at epoch 27
Train batch 1/7 - 464.4ms/batch - loss: 0.35267 - diff: 28.21mlTrain batch 2/7 - 466.2ms/batch - loss: 0.32942 - diff: 26.35mlTrain batch 3/7 - 480.9ms/batch - loss: 0.30485 - diff: 24.39mlTrain batch 4/7 - 466.4ms/batch - loss: 0.30965 - diff: 24.77mlTrain batch 5/7 - 469.6ms/batch - loss: 0.29463 - diff: 23.57mlTrain batch 6/7 - 467.2ms/batch - loss: 0.30614 - diff: 24.49mlTrain batch 7/7 - 48.7ms/batch - loss: 0.33989 - diff: 24.41mlTrain batch 7/7 - 10.4s 48.7ms/batch - loss: 0.33989 - diff: 24.41ml
Test 1.0s: val_loss: 0.31293 - diff: 21.40ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Systole_VGG19_Adam-0.001_MAE_DA3_best

Epoch 34: current best loss = 0.31293, at epoch 33
Train batch 1/7 - 466.9ms/batch - loss: 0.32968 - diff: 26.37mlTrain batch 2/7 - 466.2ms/batch - loss: 0.30007 - diff: 24.01mlTrain batch 3/7 - 463.4ms/batch - loss: 0.29824 - diff: 23.86mlTrain batch 4/7 - 465.8ms/batch - loss: 0.29884 - diff: 23.91mlTrain batch 5/7 - 471.5ms/batch - loss: 0.29689 - diff: 23.75mlTrain batch 6/7 - 462.7ms/batch - loss: 0.29639 - diff: 23.71mlTrain batch 7/7 - 49.3ms/batch - loss: 0.44247 - diff: 24.42mlTrain batch 7/7 - 10.3s 49.3ms/batch - loss: 0.44247 - diff: 24.42ml
Test 1.1s: val_loss: 0.32712 - diff: 21.55ml

Epoch 35: current best loss = 0.31293, at epoch 33
Train batch 1/7 - 482.1ms/batch - loss: 0.24043 - diff: 19.23mlTrain batch 2/7 - 464.0ms/batch - loss: 0.26575 - diff: 21.26mlTrain batch 3/7 - 466.8ms/batch - loss: 0.29931 - diff: 23.94mlTrain batch 4/7 - 467.7ms/batch - loss: 0.29654 - diff: 23.72mlTrain batch 5/7 - 466.6ms/batch - loss: 0.29730 - diff: 23.78mlTrain batch 6/7 - 466.9ms/batch - loss: 0.30338 - diff: 24.27mlTrain batch 7/7 - 48.7ms/batch - loss: 0.34569 - diff: 24.25mlTrain batch 7/7 - 10.5s 48.7ms/batch - loss: 0.34569 - diff: 24.25ml
Test 1.2s: val_loss: 0.38588 - diff: 23.51ml

Epoch 36: current best loss = 0.31293, at epoch 33
Train batch 1/7 - 477.6ms/batch - loss: 0.26390 - diff: 21.11mlTrain batch 2/7 - 464.6ms/batch - loss: 0.26738 - diff: 21.39mlTrain batch 3/7 - 477.7ms/batch - loss: 0.27800 - diff: 22.24mlTrain batch 4/7 - 463.5ms/batch - loss: 0.30289 - diff: 24.23mlTrain batch 5/7 - 466.8ms/batch - loss: 0.30412 - diff: 24.33mlTrain batch 6/7 - 467.1ms/batch - loss: 0.29912 - diff: 23.93mlTrain batch 7/7 - 48.5ms/batch - loss: 0.32713 - diff: 23.81mlTrain batch 7/7 - 10.6s 48.5ms/batch - loss: 0.32713 - diff: 23.81ml
Test 1.1s: val_loss: 0.35334 - diff: 25.06ml

Epoch 37: current best loss = 0.31293, at epoch 33
Train batch 1/7 - 474.4ms/batch - loss: 0.29923 - diff: 23.94mlTrain batch 2/7 - 465.8ms/batch - loss: 0.29663 - diff: 23.73mlTrain batch 3/7 - 474.7ms/batch - loss: 0.31653 - diff: 25.32mlTrain batch 4/7 - 473.6ms/batch - loss: 0.31737 - diff: 25.39mlTrain batch 5/7 - 463.9ms/batch - loss: 0.31666 - diff: 25.33mlTrain batch 6/7 - 466.9ms/batch - loss: 0.31341 - diff: 25.07mlTrain batch 7/7 - 48.5ms/batch - loss: 0.33166 - diff: 24.87mlTrain batch 7/7 - 10.4s 48.5ms/batch - loss: 0.33166 - diff: 24.87ml
Test 1.0s: val_loss: 0.32031 - diff: 21.28ml

Epoch 38: current best loss = 0.31293, at epoch 33
Train batch 1/7 - 469.2ms/batch - loss: 0.33342 - diff: 26.67mlTrain batch 2/7 - 468.4ms/batch - loss: 0.32453 - diff: 25.96mlTrain batch 3/7 - 475.7ms/batch - loss: 0.33030 - diff: 26.42mlTrain batch 4/7 - 470.0ms/batch - loss: 0.31540 - diff: 25.23mlTrain batch 5/7 - 464.4ms/batch - loss: 0.31186 - diff: 24.95mlTrain batch 6/7 - 479.0ms/batch - loss: 0.30243 - diff: 24.19mlTrain batch 7/7 - 48.5ms/batch - loss: 0.34662 - diff: 24.19mlTrain batch 7/7 - 10.4s 48.5ms/batch - loss: 0.34662 - diff: 24.19ml
Test 1.0s: val_loss: 0.32046 - diff: 21.18ml

Epoch 39: current best loss = 0.31293, at epoch 33
Train batch 1/7 - 465.9ms/batch - loss: 0.28518 - diff: 22.81mlTrain batch 2/7 - 466.0ms/batch - loss: 0.30212 - diff: 24.17mlTrain batch 3/7 - 466.6ms/batch - loss: 0.29784 - diff: 23.83mlTrain batch 4/7 - 465.5ms/batch - loss: 0.28692 - diff: 22.95mlTrain batch 5/7 - 465.4ms/batch - loss: 0.29580 - diff: 23.66mlTrain batch 6/7 - 470.3ms/batch - loss: 0.29822 - diff: 23.86mlTrain batch 7/7 - 48.9ms/batch - loss: 0.35794 - diff: 23.96mlTrain batch 7/7 - 10.4s 48.9ms/batch - loss: 0.35794 - diff: 23.96ml
Test 1.0s: val_loss: 0.35479 - diff: 21.06ml

Epoch 40: current best loss = 0.31293, at epoch 33
Train batch 1/7 - 476.1ms/batch - loss: 0.35120 - diff: 28.10mlTrain batch 2/7 - 469.2ms/batch - loss: 0.31870 - diff: 25.50mlTrain batch 3/7 - 474.1ms/batch - loss: 0.33081 - diff: 26.46mlTrain batch 4/7 - 466.3ms/batch - loss: 0.32842 - diff: 26.27mlTrain batch 5/7 - 467.1ms/batch - loss: 0.32603 - diff: 26.08mlTrain batch 6/7 - 468.0ms/batch - loss: 0.31113 - diff: 24.89mlTrain batch 7/7 - 48.7ms/batch - loss: 0.34044 - diff: 24.77mlTrain batch 7/7 - 10.4s 48.7ms/batch - loss: 0.34044 - diff: 24.77ml
Test 1.1s: val_loss: 0.36938 - diff: 22.97ml

Epoch 41: current best loss = 0.31293, at epoch 33
Train batch 1/7 - 477.1ms/batch - loss: 0.25052 - diff: 20.04mlTrain batch 2/7 - 465.4ms/batch - loss: 0.28180 - diff: 22.54mlTrain batch 3/7 - 465.6ms/batch - loss: 0.27346 - diff: 21.88mlTrain batch 4/7 - 464.8ms/batch - loss: 0.30012 - diff: 24.01mlTrain batch 5/7 - 465.6ms/batch - loss: 0.29324 - diff: 23.46mlTrain batch 6/7 - 467.5ms/batch - loss: 0.29402 - diff: 23.52mlTrain batch 7/7 - 48.6ms/batch - loss: 0.32858 - diff: 23.45mlTrain batch 7/7 - 10.4s 48.6ms/batch - loss: 0.32858 - diff: 23.45ml
Test 1.1s: val_loss: 0.37039 - diff: 23.33ml

Epoch 42: current best loss = 0.31293, at epoch 33
Train batch 1/7 - 475.8ms/batch - loss: 0.25575 - diff: 20.46mlTrain batch 2/7 - 465.2ms/batch - loss: 0.27255 - diff: 21.80mlTrain batch 3/7 - 477.1ms/batch - loss: 0.28108 - diff: 22.49mlTrain batch 4/7 - 465.4ms/batch - loss: 0.27187 - diff: 21.75mlTrain batch 5/7 - 472.9ms/batch - loss: 0.27753 - diff: 22.20mlTrain batch 6/7 - 465.2ms/batch - loss: 0.29808 - diff: 23.85mlTrain batch 7/7 - 48.7ms/batch - loss: 0.31767 - diff: 23.67mlTrain batch 7/7 - 10.3s 48.7ms/batch - loss: 0.31767 - diff: 23.67ml
Test 1.0s: val_loss: 0.38483 - diff: 24.43ml

Epoch 43: current best loss = 0.31293, at epoch 33
Train batch 1/7 - 466.8ms/batch - loss: 0.25890 - diff: 20.71mlTrain batch 2/7 - 466.8ms/batch - loss: 0.30370 - diff: 24.30mlTrain batch 3/7 - 475.5ms/batch - loss: 0.30886 - diff: 24.71mlTrain batch 4/7 - 466.3ms/batch - loss: 0.30902 - diff: 24.72mlTrain batch 5/7 - 473.6ms/batch - loss: 0.29299 - diff: 23.44mlTrain batch 6/7 - 463.4ms/batch - loss: 0.29798 - diff: 23.84mlTrain batch 7/7 - 48.7ms/batch - loss: 0.36204 - diff: 23.97mlTrain batch 7/7 - 10.4s 48.7ms/batch - loss: 0.36204 - diff: 23.97ml
Test 1.0s: val_loss: 0.35557 - diff: 24.38ml

Epoch 44: current best loss = 0.31293, at epoch 33
Train batch 1/7 - 470.8ms/batch - loss: 0.20959 - diff: 16.77mlTrain batch 2/7 - 463.8ms/batch - loss: 0.24066 - diff: 19.25mlTrain batch 3/7 - 464.8ms/batch - loss: 0.26020 - diff: 20.82mlTrain batch 4/7 - 466.8ms/batch - loss: 0.28364 - diff: 22.69mlTrain batch 5/7 - 474.6ms/batch - loss: 0.30323 - diff: 24.26mlTrain batch 6/7 - 463.6ms/batch - loss: 0.30705 - diff: 24.56mlTrain batch 7/7 - 48.9ms/batch - loss: 0.33520 - diff: 24.44mlTrain batch 7/7 - 10.4s 48.9ms/batch - loss: 0.33520 - diff: 24.44ml
Test 1.0s: val_loss: 0.34324 - diff: 22.95ml
Epoch    45: reducing learning rate of group 0 to 5.0000e-04.

Epoch 45: current best loss = 0.31293, at epoch 33
Going to unfreeze the pretrained weights
Train batch 1/7 - 671.4ms/batch - loss: 0.30358 - diff: 24.29mlTrain batch 2/7 - 752.0ms/batch - loss: 15.23834 - diff: 1219.07mlTrain batch 3/7 - 596.6ms/batch - loss: 10.37819 - diff: 830.26mlTrain batch 4/7 - 599.6ms/batch - loss: 7.87557 - diff: 630.05mlTrain batch 5/7 - 596.9ms/batch - loss: 6.50260 - diff: 520.21mlTrain batch 6/7 - 601.7ms/batch - loss: 5.52401 - diff: 441.92mlTrain batch 7/7 - 71.5ms/batch - loss: 5.49966 - diff: 435.95mlTrain batch 7/7 - 10.7s 71.5ms/batch - loss: 5.49966 - diff: 435.95ml
Test 1.0s: val_loss: 0.79466 - diff: 51.40ml

Epoch 46: current best loss = 0.31293, at epoch 33
Train batch 1/7 - 608.8ms/batch - loss: 0.60655 - diff: 48.52mlTrain batch 2/7 - 596.1ms/batch - loss: 0.45881 - diff: 36.71mlTrain batch 3/7 - 598.5ms/batch - loss: 0.46792 - diff: 37.43mlTrain batch 4/7 - 597.1ms/batch - loss: 0.46089 - diff: 36.87mlTrain batch 5/7 - 611.2ms/batch - loss: 0.44759 - diff: 35.81mlTrain batch 6/7 - 595.8ms/batch - loss: 0.45439 - diff: 36.35mlTrain batch 7/7 - 71.1ms/batch - loss: 0.53940 - diff: 36.47mlTrain batch 7/7 - 10.7s 71.1ms/batch - loss: 0.53940 - diff: 36.47ml
Test 1.0s: val_loss: 0.45190 - diff: 29.62ml

Epoch 47: current best loss = 0.31293, at epoch 33
Train batch 1/7 - 598.3ms/batch - loss: 0.43898 - diff: 35.12mlTrain batch 2/7 - 598.2ms/batch - loss: 0.39515 - diff: 31.61mlTrain batch 3/7 - 601.5ms/batch - loss: 0.38756 - diff: 31.00mlTrain batch 4/7 - 598.0ms/batch - loss: 0.39390 - diff: 31.51mlTrain batch 5/7 - 600.3ms/batch - loss: 0.37716 - diff: 30.17mlTrain batch 6/7 - 599.7ms/batch - loss: 0.38852 - diff: 31.08mlTrain batch 7/7 - 70.5ms/batch - loss: 0.41692 - diff: 30.87mlTrain batch 7/7 - 10.7s 70.5ms/batch - loss: 0.41692 - diff: 30.87ml
Test 1.0s: val_loss: 0.49401 - diff: 32.88ml

Epoch 48: current best loss = 0.31293, at epoch 33
Train batch 1/7 - 598.8ms/batch - loss: 0.41150 - diff: 32.92mlTrain batch 2/7 - 599.9ms/batch - loss: 0.37192 - diff: 29.75mlTrain batch 3/7 - 598.3ms/batch - loss: 0.39358 - diff: 31.49mlTrain batch 4/7 - 596.0ms/batch - loss: 0.41337 - diff: 33.07mlTrain batch 5/7 - 598.3ms/batch - loss: 0.41629 - diff: 33.30mlTrain batch 6/7 - 601.8ms/batch - loss: 0.40828 - diff: 32.66mlTrain batch 7/7 - 70.8ms/batch - loss: 0.45465 - diff: 32.56mlTrain batch 7/7 - 10.8s 70.8ms/batch - loss: 0.45465 - diff: 32.56ml
Test 1.1s: val_loss: 0.39938 - diff: 25.38ml

Epoch 49: current best loss = 0.31293, at epoch 33
Train batch 1/7 - 597.7ms/batch - loss: 0.38961 - diff: 31.17mlTrain batch 2/7 - 599.4ms/batch - loss: 0.36545 - diff: 29.24mlTrain batch 3/7 - 596.8ms/batch - loss: 0.41423 - diff: 33.14mlTrain batch 4/7 - 595.8ms/batch - loss: 0.37078 - diff: 29.66mlTrain batch 5/7 - 610.8ms/batch - loss: 0.38443 - diff: 30.75mlTrain batch 6/7 - 598.5ms/batch - loss: 0.37440 - diff: 29.95mlTrain batch 7/7 - 70.8ms/batch - loss: 0.41391 - diff: 29.84mlTrain batch 7/7 - 10.6s 70.8ms/batch - loss: 0.41391 - diff: 29.84ml
Test 1.0s: val_loss: 0.42245 - diff: 28.31ml

Epoch 50: current best loss = 0.31293, at epoch 33
Train batch 1/7 - 600.4ms/batch - loss: 0.35572 - diff: 28.46mlTrain batch 2/7 - 596.7ms/batch - loss: 0.35551 - diff: 28.44mlTrain batch 3/7 - 597.4ms/batch - loss: 0.35661 - diff: 28.53mlTrain batch 4/7 - 597.7ms/batch - loss: 0.37401 - diff: 29.92mlTrain batch 5/7 - 602.7ms/batch - loss: 0.37073 - diff: 29.66mlTrain batch 6/7 - 598.2ms/batch - loss: 0.35978 - diff: 28.78mlTrain batch 7/7 - 71.5ms/batch - loss: 0.40609 - diff: 28.73mlTrain batch 7/7 - 10.7s 71.5ms/batch - loss: 0.40609 - diff: 28.73ml
Test 1.0s: val_loss: 0.69018 - diff: 44.84ml

Epoch 51: current best loss = 0.31293, at epoch 33
Train batch 1/7 - 599.4ms/batch - loss: 0.55750 - diff: 44.60mlTrain batch 2/7 - 598.3ms/batch - loss: 0.57570 - diff: 46.06mlTrain batch 3/7 - 602.0ms/batch - loss: 0.48539 - diff: 38.83mlTrain batch 4/7 - 600.7ms/batch - loss: 0.45093 - diff: 36.07mlTrain batch 5/7 - 609.8ms/batch - loss: 0.45912 - diff: 36.73mlTrain batch 6/7 - 599.3ms/batch - loss: 0.46709 - diff: 37.37mlTrain batch 7/7 - 71.8ms/batch - loss: 0.54662 - diff: 37.43mlTrain batch 7/7 - 10.8s 71.8ms/batch - loss: 0.54662 - diff: 37.43ml
Test 1.0s: val_loss: 0.39133 - diff: 25.70ml

Epoch 52: current best loss = 0.31293, at epoch 33
Train batch 1/7 - 597.4ms/batch - loss: 0.39107 - diff: 31.29mlTrain batch 2/7 - 595.9ms/batch - loss: 0.38008 - diff: 30.41mlTrain batch 3/7 - 602.1ms/batch - loss: 0.41675 - diff: 33.34mlTrain batch 4/7 - 597.0ms/batch - loss: 0.39643 - diff: 31.71mlTrain batch 5/7 - 596.7ms/batch - loss: 0.40243 - diff: 32.19mlTrain batch 6/7 - 600.5ms/batch - loss: 0.39599 - diff: 31.68mlTrain batch 7/7 - 70.9ms/batch - loss: 0.43098 - diff: 31.51mlTrain batch 7/7 - 10.6s 70.9ms/batch - loss: 0.43098 - diff: 31.51ml
Test 0.9s: val_loss: 0.41637 - diff: 25.74ml

Epoch 53: current best loss = 0.31293, at epoch 33
Train batch 1/7 - 595.8ms/batch - loss: 0.28777 - diff: 23.02mlTrain batch 2/7 - 597.1ms/batch - loss: 0.34295 - diff: 27.44mlTrain batch 3/7 - 595.9ms/batch - loss: 0.35947 - diff: 28.76mlTrain batch 4/7 - 599.4ms/batch - loss: 0.38849 - diff: 31.08mlTrain batch 5/7 - 594.2ms/batch - loss: 0.37058 - diff: 29.65mlTrain batch 6/7 - 599.0ms/batch - loss: 0.36345 - diff: 29.08mlTrain batch 7/7 - 71.4ms/batch - loss: 0.39052 - diff: 28.88mlTrain batch 7/7 - 10.6s 71.4ms/batch - loss: 0.39052 - diff: 28.88ml
Test 0.9s: val_loss: 0.48477 - diff: 30.76ml

Epoch 54: current best loss = 0.31293, at epoch 33
Train batch 1/7 - 610.4ms/batch - loss: 0.39508 - diff: 31.61mlTrain batch 2/7 - 595.4ms/batch - loss: 0.39497 - diff: 31.60mlTrain batch 3/7 - 607.0ms/batch - loss: 0.39766 - diff: 31.81mlTrain batch 4/7 - 597.6ms/batch - loss: 0.38182 - diff: 30.55mlTrain batch 5/7 - 604.7ms/batch - loss: 0.38607 - diff: 30.89mlTrain batch 6/7 - 594.7ms/batch - loss: 0.38515 - diff: 30.81mlTrain batch 7/7 - 70.8ms/batch - loss: 0.40980 - diff: 30.58mlTrain batch 7/7 - 10.6s 70.8ms/batch - loss: 0.40980 - diff: 30.58ml
Test 1.1s: val_loss: 0.40611 - diff: 28.14ml

Epoch 55: current best loss = 0.31293, at epoch 33
Train batch 1/7 - 605.2ms/batch - loss: 0.41925 - diff: 33.54mlTrain batch 2/7 - 608.3ms/batch - loss: 0.44984 - diff: 35.99mlTrain batch 3/7 - 605.4ms/batch - loss: 0.44118 - diff: 35.29mlTrain batch 4/7 - 601.7ms/batch - loss: 0.43645 - diff: 34.92mlTrain batch 5/7 - 606.7ms/batch - loss: 0.40807 - diff: 32.65mlTrain batch 6/7 - 593.5ms/batch - loss: 0.39286 - diff: 31.43mlTrain batch 7/7 - 71.5ms/batch - loss: 0.44068 - diff: 31.35mlTrain batch 7/7 - 10.7s 71.5ms/batch - loss: 0.44068 - diff: 31.35ml
Test 1.1s: val_loss: 0.38243 - diff: 24.75ml
Epoch    56: reducing learning rate of group 0 to 2.5000e-04.

Epoch 56: current best loss = 0.31293, at epoch 33
Train batch 1/7 - 595.0ms/batch - loss: 0.35875 - diff: 28.70mlTrain batch 2/7 - 602.2ms/batch - loss: 0.32295 - diff: 25.84mlTrain batch 3/7 - 598.0ms/batch - loss: 0.33624 - diff: 26.90mlTrain batch 4/7 - 600.2ms/batch - loss: 0.35045 - diff: 28.04mlTrain batch 5/7 - 598.5ms/batch - loss: 0.35644 - diff: 28.51mlTrain batch 6/7 - 600.5ms/batch - loss: 0.35304 - diff: 28.24mlTrain batch 7/7 - 71.4ms/batch - loss: 0.38899 - diff: 28.12mlTrain batch 7/7 - 10.6s 71.4ms/batch - loss: 0.38899 - diff: 28.12ml
Test 1.0s: val_loss: 0.37002 - diff: 24.57ml

Epoch 57: current best loss = 0.31293, at epoch 33
Train batch 1/7 - 607.2ms/batch - loss: 0.43678 - diff: 34.94mlTrain batch 2/7 - 594.8ms/batch - loss: 0.38126 - diff: 30.50mlTrain batch 3/7 - 608.5ms/batch - loss: 0.37307 - diff: 29.85mlTrain batch 4/7 - 597.6ms/batch - loss: 0.36900 - diff: 29.52mlTrain batch 5/7 - 607.7ms/batch - loss: 0.35310 - diff: 28.25mlTrain batch 6/7 - 597.3ms/batch - loss: 0.34743 - diff: 27.79mlTrain batch 7/7 - 70.9ms/batch - loss: 0.40852 - diff: 27.86mlTrain batch 7/7 - 10.6s 70.9ms/batch - loss: 0.40852 - diff: 27.86ml
Test 1.0s: val_loss: 0.38446 - diff: 24.46ml

Epoch 58: current best loss = 0.31293, at epoch 33
Train batch 1/7 - 611.2ms/batch - loss: 0.34831 - diff: 27.86mlTrain batch 2/7 - 596.7ms/batch - loss: 0.32032 - diff: 25.63mlTrain batch 3/7 - 607.2ms/batch - loss: 0.34326 - diff: 27.46mlTrain batch 4/7 - 597.6ms/batch - loss: 0.33808 - diff: 27.05mlTrain batch 5/7 - 607.1ms/batch - loss: 0.32821 - diff: 26.26mlTrain batch 6/7 - 596.8ms/batch - loss: 0.33701 - diff: 26.96mlTrain batch 7/7 - 70.7ms/batch - loss: 0.40691 - diff: 27.10mlTrain batch 7/7 - 10.7s 70.7ms/batch - loss: 0.40691 - diff: 27.10ml
Test 0.9s: val_loss: 0.36244 - diff: 24.18ml

Epoch 59: current best loss = 0.31293, at epoch 33
Train batch 1/7 - 605.6ms/batch - loss: 0.33627 - diff: 26.90mlTrain batch 2/7 - 599.4ms/batch - loss: 0.33036 - diff: 26.43mlTrain batch 3/7 - 597.1ms/batch - loss: 0.32305 - diff: 25.84mlTrain batch 4/7 - 597.2ms/batch - loss: 0.34606 - diff: 27.68mlTrain batch 5/7 - 596.3ms/batch - loss: 0.33786 - diff: 27.03mlTrain batch 6/7 - 599.6ms/batch - loss: 0.33664 - diff: 26.93mlTrain batch 7/7 - 71.4ms/batch - loss: 0.43662 - diff: 27.28mlTrain batch 7/7 - 10.8s 71.4ms/batch - loss: 0.43662 - diff: 27.28ml
Test 1.0s: val_loss: 0.35891 - diff: 24.35ml

Epoch 60: current best loss = 0.31293, at epoch 33
Train batch 1/7 - 600.7ms/batch - loss: 0.29950 - diff: 23.96mlTrain batch 2/7 - 596.7ms/batch - loss: 0.36780 - diff: 29.42mlTrain batch 3/7 - 606.6ms/batch - loss: 0.35564 - diff: 28.45mlTrain batch 4/7 - 598.3ms/batch - loss: 0.35083 - diff: 28.07mlTrain batch 5/7 - 607.1ms/batch - loss: 0.35474 - diff: 28.38mlTrain batch 6/7 - 593.9ms/batch - loss: 0.33885 - diff: 27.11mlTrain batch 7/7 - 71.8ms/batch - loss: 0.38044 - diff: 27.04mlTrain batch 7/7 - 10.6s 71.8ms/batch - loss: 0.38044 - diff: 27.04ml
Test 0.9s: val_loss: 0.39864 - diff: 25.99ml

Epoch 61: current best loss = 0.31293, at epoch 33
Train batch 1/7 - 599.2ms/batch - loss: 0.46544 - diff: 37.24mlTrain batch 2/7 - 598.5ms/batch - loss: 0.42519 - diff: 34.01mlTrain batch 3/7 - 597.9ms/batch - loss: 0.42133 - diff: 33.71mlTrain batch 4/7 - 600.8ms/batch - loss: 0.38572 - diff: 30.86mlTrain batch 5/7 - 598.4ms/batch - loss: 0.36745 - diff: 29.40mlTrain batch 6/7 - 615.3ms/batch - loss: 0.35889 - diff: 28.71mlTrain batch 7/7 - 70.7ms/batch - loss: 0.40128 - diff: 28.63mlTrain batch 7/7 - 10.7s 70.7ms/batch - loss: 0.40128 - diff: 28.63ml
Test 1.0s: val_loss: 0.35780 - diff: 24.19ml

Epoch 62: current best loss = 0.31293, at epoch 33
Train batch 1/7 - 601.0ms/batch - loss: 0.30467 - diff: 24.37mlTrain batch 2/7 - 598.6ms/batch - loss: 0.30286 - diff: 24.23mlTrain batch 3/7 - 602.4ms/batch - loss: 0.30668 - diff: 24.53mlTrain batch 4/7 - 595.0ms/batch - loss: 0.31868 - diff: 25.49mlTrain batch 5/7 - 596.7ms/batch - loss: 0.32574 - diff: 26.06mlTrain batch 6/7 - 599.3ms/batch - loss: 0.33318 - diff: 26.65mlTrain batch 7/7 - 71.7ms/batch - loss: 0.41226 - diff: 26.86mlTrain batch 7/7 - 10.7s 71.7ms/batch - loss: 0.41226 - diff: 26.86ml
Test 1.0s: val_loss: 0.36407 - diff: 23.67ml

Epoch 63: current best loss = 0.31293, at epoch 33
Train batch 1/7 - 598.1ms/batch - loss: 0.30822 - diff: 24.66mlTrain batch 2/7 - 596.1ms/batch - loss: 0.34777 - diff: 27.82mlTrain batch 3/7 - 600.8ms/batch - loss: 0.34759 - diff: 27.81mlTrain batch 4/7 - 597.7ms/batch - loss: 0.34247 - diff: 27.40mlTrain batch 5/7 - 594.9ms/batch - loss: 0.33460 - diff: 26.77mlTrain batch 6/7 - 601.2ms/batch - loss: 0.35245 - diff: 28.20mlTrain batch 7/7 - 70.9ms/batch - loss: 0.37874 - diff: 28.01mlTrain batch 7/7 - 10.6s 70.9ms/batch - loss: 0.37874 - diff: 28.01ml
Test 1.0s: val_loss: 0.43361 - diff: 28.63ml

Epoch 64: current best loss = 0.31293, at epoch 33
Train batch 1/7 - 599.8ms/batch - loss: 0.33027 - diff: 26.42mlTrain batch 2/7 - 598.2ms/batch - loss: 0.35987 - diff: 28.79mlTrain batch 3/7 - 595.5ms/batch - loss: 0.34510 - diff: 27.61mlTrain batch 4/7 - 601.4ms/batch - loss: 0.34864 - diff: 27.89mlTrain batch 5/7 - 596.8ms/batch - loss: 0.33882 - diff: 27.11mlTrain batch 6/7 - 599.5ms/batch - loss: 0.33647 - diff: 26.92mlTrain batch 7/7 - 71.0ms/batch - loss: 0.45007 - diff: 27.36mlTrain batch 7/7 - 10.7s 71.0ms/batch - loss: 0.45007 - diff: 27.36ml
Test 1.0s: val_loss: 0.43478 - diff: 28.97ml

Epoch 65: current best loss = 0.31293, at epoch 33
Train batch 1/7 - 601.5ms/batch - loss: 0.36728 - diff: 29.38mlTrain batch 2/7 - 600.8ms/batch - loss: 0.36397 - diff: 29.12mlTrain batch 3/7 - 593.5ms/batch - loss: 0.35983 - diff: 28.79mlTrain batch 4/7 - 598.8ms/batch - loss: 0.33499 - diff: 26.80mlTrain batch 5/7 - 595.6ms/batch - loss: 0.33682 - diff: 26.95mlTrain batch 6/7 - 601.3ms/batch - loss: 0.35665 - diff: 28.53mlTrain batch 7/7 - 71.3ms/batch - loss: 0.41919 - diff: 28.60mlTrain batch 7/7 - 10.7s 71.3ms/batch - loss: 0.41919 - diff: 28.60ml
Test 1.0s: val_loss: 0.41410 - diff: 27.71ml

Epoch 66: current best loss = 0.31293, at epoch 33
Train batch 1/7 - 618.7ms/batch - loss: 0.29697 - diff: 23.76mlTrain batch 2/7 - 602.6ms/batch - loss: 0.28488 - diff: 22.79mlTrain batch 3/7 - 596.4ms/batch - loss: 0.29958 - diff: 23.97mlTrain batch 4/7 - 598.5ms/batch - loss: 0.34087 - diff: 27.27mlTrain batch 5/7 - 599.4ms/batch - loss: 0.34421 - diff: 27.54mlTrain batch 6/7 - 599.9ms/batch - loss: 0.34428 - diff: 27.54mlTrain batch 7/7 - 70.7ms/batch - loss: 0.40617 - diff: 27.61mlTrain batch 7/7 - 10.8s 70.7ms/batch - loss: 0.40617 - diff: 27.61ml
Test 1.0s: val_loss: 0.37818 - diff: 23.36ml
Epoch    67: reducing learning rate of group 0 to 1.2500e-04.

Epoch 67: current best loss = 0.31293, at epoch 33
Train batch 1/7 - 603.6ms/batch - loss: 0.32500 - diff: 26.00mlTrain batch 2/7 - 596.7ms/batch - loss: 0.30538 - diff: 24.43mlTrain batch 3/7 - 606.1ms/batch - loss: 0.30662 - diff: 24.53mlTrain batch 4/7 - 599.3ms/batch - loss: 0.30901 - diff: 24.72mlTrain batch 5/7 - 605.3ms/batch - loss: 0.30364 - diff: 24.29mlTrain batch 6/7 - 597.0ms/batch - loss: 0.33291 - diff: 26.63mlTrain batch 7/7 - 71.0ms/batch - loss: 0.36662 - diff: 26.52mlTrain batch 7/7 - 10.6s 71.0ms/batch - loss: 0.36662 - diff: 26.52ml
Test 1.0s: val_loss: 0.36013 - diff: 23.51ml

Epoch 68: current best loss = 0.31293, at epoch 33
Train batch 1/7 - 598.1ms/batch - loss: 0.25536 - diff: 20.43mlTrain batch 2/7 - 598.9ms/batch - loss: 0.26106 - diff: 20.89mlTrain batch 3/7 - 600.5ms/batch - loss: 0.28195 - diff: 22.56mlTrain batch 4/7 - 596.2ms/batch - loss: 0.30535 - diff: 24.43mlTrain batch 5/7 - 598.4ms/batch - loss: 0.34038 - diff: 27.23mlTrain batch 6/7 - 607.7ms/batch - loss: 0.33691 - diff: 26.95mlTrain batch 7/7 - 70.7ms/batch - loss: 0.35583 - diff: 26.73mlTrain batch 7/7 - 10.8s 70.7ms/batch - loss: 0.35583 - diff: 26.73ml
Test 1.0s: val_loss: 0.36171 - diff: 23.43ml

Epoch 69: current best loss = 0.31293, at epoch 33
Train batch 1/7 - 600.3ms/batch - loss: 0.32624 - diff: 26.10mlTrain batch 2/7 - 603.6ms/batch - loss: 0.34271 - diff: 27.42mlTrain batch 3/7 - 599.8ms/batch - loss: 0.34035 - diff: 27.23mlTrain batch 4/7 - 599.5ms/batch - loss: 0.32225 - diff: 25.78mlTrain batch 5/7 - 604.7ms/batch - loss: 0.32496 - diff: 26.00mlTrain batch 6/7 - 606.6ms/batch - loss: 0.32870 - diff: 26.30mlTrain batch 7/7 - 71.7ms/batch - loss: 0.37956 - diff: 26.31mlTrain batch 7/7 - 10.6s 71.7ms/batch - loss: 0.37956 - diff: 26.31ml
Test 1.0s: val_loss: 0.34945 - diff: 23.52ml

Epoch 70: current best loss = 0.31293, at epoch 33
Train batch 1/7 - 599.5ms/batch - loss: 0.23835 - diff: 19.07mlTrain batch 2/7 - 596.0ms/batch - loss: 0.25899 - diff: 20.72mlTrain batch 3/7 - 597.1ms/batch - loss: 0.32440 - diff: 25.95mlTrain batch 4/7 - 595.2ms/batch - loss: 0.33009 - diff: 26.41mlTrain batch 5/7 - 595.4ms/batch - loss: 0.32933 - diff: 26.35mlTrain batch 6/7 - 607.1ms/batch - loss: 0.33362 - diff: 26.69mlTrain batch 7/7 - 70.8ms/batch - loss: 0.37676 - diff: 26.64mlTrain batch 7/7 - 10.6s 70.8ms/batch - loss: 0.37676 - diff: 26.64ml
Test 1.0s: val_loss: 0.35142 - diff: 22.97ml

Epoch 71: current best loss = 0.31293, at epoch 33
Train batch 1/7 - 605.5ms/batch - loss: 0.39441 - diff: 31.55mlTrain batch 2/7 - 597.7ms/batch - loss: 0.34787 - diff: 27.83mlTrain batch 3/7 - 598.1ms/batch - loss: 0.33359 - diff: 26.69mlTrain batch 4/7 - 600.2ms/batch - loss: 0.32300 - diff: 25.84mlTrain batch 5/7 - 596.4ms/batch - loss: 0.32112 - diff: 25.69mlTrain batch 6/7 - 601.1ms/batch - loss: 0.32244 - diff: 25.80mlTrain batch 7/7 - 71.7ms/batch - loss: 0.39515 - diff: 25.97mlTrain batch 7/7 - 10.9s 71.7ms/batch - loss: 0.39515 - diff: 25.97ml
Test 1.2s: val_loss: 0.36132 - diff: 23.36ml

Epoch 72: current best loss = 0.31293, at epoch 33
Train batch 1/7 - 612.8ms/batch - loss: 0.30569 - diff: 24.46mlTrain batch 2/7 - 602.9ms/batch - loss: 0.27892 - diff: 22.31mlTrain batch 3/7 - 606.1ms/batch - loss: 0.32688 - diff: 26.15mlTrain batch 4/7 - 596.6ms/batch - loss: 0.32836 - diff: 26.27mlTrain batch 5/7 - 601.9ms/batch - loss: 0.33149 - diff: 26.52mlTrain batch 6/7 - 597.4ms/batch - loss: 0.32586 - diff: 26.07mlTrain batch 7/7 - 70.5ms/batch - loss: 0.36614 - diff: 26.01mlTrain batch 7/7 - 10.7s 70.5ms/batch - loss: 0.36614 - diff: 26.01ml
Test 1.0s: val_loss: 0.36955 - diff: 23.26ml

Epoch 73: current best loss = 0.31293, at epoch 33
Train batch 1/7 - 605.8ms/batch - loss: 0.24652 - diff: 19.72mlTrain batch 2/7 - 605.7ms/batch - loss: 0.28042 - diff: 22.43mlTrain batch 3/7 - 607.2ms/batch - loss: 0.33470 - diff: 26.78mlTrain batch 4/7 - 606.9ms/batch - loss: 0.34322 - diff: 27.46mlTrain batch 5/7 - 597.2ms/batch - loss: 0.34649 - diff: 27.72mlTrain batch 6/7 - 606.1ms/batch - loss: 0.33201 - diff: 26.56mlTrain batch 7/7 - 70.7ms/batch - loss: 0.49167 - diff: 27.33mlTrain batch 7/7 - 10.7s 70.7ms/batch - loss: 0.49167 - diff: 27.33ml
Test 0.9s: val_loss: 0.35644 - diff: 23.50ml

Epoch 74: current best loss = 0.31293, at epoch 33
Train batch 1/7 - 609.2ms/batch - loss: 0.35832 - diff: 28.67mlTrain batch 2/7 - 596.7ms/batch - loss: 0.34749 - diff: 27.80mlTrain batch 3/7 - 605.1ms/batch - loss: 0.35699 - diff: 28.56mlTrain batch 4/7 - 598.3ms/batch - loss: 0.34588 - diff: 27.67mlTrain batch 5/7 - 607.8ms/batch - loss: 0.34765 - diff: 27.81mlTrain batch 6/7 - 596.5ms/batch - loss: 0.34383 - diff: 27.51mlTrain batch 7/7 - 71.7ms/batch - loss: 0.43612 - diff: 27.79mlTrain batch 7/7 - 10.6s 71.7ms/batch - loss: 0.43612 - diff: 27.79ml
Test 1.0s: val_loss: 0.36331 - diff: 24.06ml

Epoch 75: current best loss = 0.31293, at epoch 33
Train batch 1/7 - 608.0ms/batch - loss: 0.35312 - diff: 28.25mlTrain batch 2/7 - 600.3ms/batch - loss: 0.34815 - diff: 27.85mlTrain batch 3/7 - 606.6ms/batch - loss: 0.32326 - diff: 25.86mlTrain batch 4/7 - 600.6ms/batch - loss: 0.32217 - diff: 25.77mlTrain batch 5/7 - 606.0ms/batch - loss: 0.33091 - diff: 26.47mlTrain batch 6/7 - 597.4ms/batch - loss: 0.32540 - diff: 26.03mlTrain batch 7/7 - 70.7ms/batch - loss: 0.38247 - diff: 26.09mlTrain batch 7/7 - 10.6s 70.7ms/batch - loss: 0.38247 - diff: 26.09ml
Test 1.1s: val_loss: 0.42520 - diff: 28.89ml

Epoch 76: current best loss = 0.31293, at epoch 33
Train batch 1/7 - 597.6ms/batch - loss: 0.44859 - diff: 35.89mlTrain batch 2/7 - 597.7ms/batch - loss: 0.44075 - diff: 35.26mlTrain batch 3/7 - 599.2ms/batch - loss: 0.43970 - diff: 35.18mlTrain batch 4/7 - 601.6ms/batch - loss: 0.42861 - diff: 34.29mlTrain batch 5/7 - 594.9ms/batch - loss: 0.39408 - diff: 31.53mlTrain batch 6/7 - 600.8ms/batch - loss: 0.38580 - diff: 30.86mlTrain batch 7/7 - 71.6ms/batch - loss: 0.44793 - diff: 30.89mlTrain batch 7/7 - 10.7s 71.6ms/batch - loss: 0.44793 - diff: 30.89ml
Test 1.0s: val_loss: 0.44873 - diff: 29.73ml

Epoch 77: current best loss = 0.31293, at epoch 33
Train batch 1/7 - 609.6ms/batch - loss: 0.42562 - diff: 34.05mlTrain batch 2/7 - 597.6ms/batch - loss: 0.43850 - diff: 35.08mlTrain batch 3/7 - 598.3ms/batch - loss: 0.40975 - diff: 32.78mlTrain batch 4/7 - 599.6ms/batch - loss: 0.38884 - diff: 31.11mlTrain batch 5/7 - 596.0ms/batch - loss: 0.37314 - diff: 29.85mlTrain batch 6/7 - 598.9ms/batch - loss: 0.36153 - diff: 28.92mlTrain batch 7/7 - 71.1ms/batch - loss: 0.41953 - diff: 28.95mlTrain batch 7/7 - 10.7s 71.1ms/batch - loss: 0.41953 - diff: 28.95ml
Test 1.0s: val_loss: 0.33597 - diff: 22.99ml
Epoch    78: reducing learning rate of group 0 to 6.2500e-05.

Epoch 78: current best loss = 0.31293, at epoch 33
Train batch 1/7 - 604.9ms/batch - loss: 0.36059 - diff: 28.85mlTrain batch 2/7 - 595.2ms/batch - loss: 0.30853 - diff: 24.68mlTrain batch 3/7 - 595.2ms/batch - loss: 0.32906 - diff: 26.32mlTrain batch 4/7 - 598.9ms/batch - loss: 0.33178 - diff: 26.54mlTrain batch 5/7 - 598.2ms/batch - loss: 0.33578 - diff: 26.86mlTrain batch 6/7 - 600.2ms/batch - loss: 0.32708 - diff: 26.17mlTrain batch 7/7 - 71.4ms/batch - loss: 0.35625 - diff: 26.03mlTrain batch 7/7 - 10.7s 71.4ms/batch - loss: 0.35625 - diff: 26.03ml
Test 1.0s: val_loss: 0.33733 - diff: 22.64ml

Epoch 79: current best loss = 0.31293, at epoch 33
Train batch 1/7 - 606.7ms/batch - loss: 0.36681 - diff: 29.34mlTrain batch 2/7 - 597.5ms/batch - loss: 0.33537 - diff: 26.83mlTrain batch 3/7 - 600.0ms/batch - loss: 0.33373 - diff: 26.70mlTrain batch 4/7 - 596.1ms/batch - loss: 0.32053 - diff: 25.64mlTrain batch 5/7 - 599.4ms/batch - loss: 0.32488 - diff: 25.99mlTrain batch 6/7 - 598.4ms/batch - loss: 0.32071 - diff: 25.66mlTrain batch 7/7 - 71.4ms/batch - loss: 0.36795 - diff: 25.65mlTrain batch 7/7 - 10.7s 71.4ms/batch - loss: 0.36795 - diff: 25.65ml
Test 1.0s: val_loss: 0.37386 - diff: 22.57ml

Epoch 80: current best loss = 0.31293, at epoch 33
Train batch 1/7 - 605.0ms/batch - loss: 0.33125 - diff: 26.50mlTrain batch 2/7 - 597.4ms/batch - loss: 0.31983 - diff: 25.59mlTrain batch 3/7 - 607.8ms/batch - loss: 0.29290 - diff: 23.43mlTrain batch 4/7 - 601.7ms/batch - loss: 0.31499 - diff: 25.20mlTrain batch 5/7 - 600.2ms/batch - loss: 0.30799 - diff: 24.64mlTrain batch 6/7 - 598.0ms/batch - loss: 0.31597 - diff: 25.28mlTrain batch 7/7 - 71.5ms/batch - loss: 0.42718 - diff: 25.72mlTrain batch 7/7 - 10.7s 71.5ms/batch - loss: 0.42718 - diff: 25.72ml
Test 1.0s: val_loss: 0.34241 - diff: 22.47ml

Epoch 81: current best loss = 0.31293, at epoch 33
Train batch 1/7 - 597.0ms/batch - loss: 0.32167 - diff: 25.73mlTrain batch 2/7 - 598.4ms/batch - loss: 0.31544 - diff: 25.23mlTrain batch 3/7 - 597.7ms/batch - loss: 0.32089 - diff: 25.67mlTrain batch 4/7 - 606.9ms/batch - loss: 0.32228 - diff: 25.78mlTrain batch 5/7 - 598.7ms/batch - loss: 0.31110 - diff: 24.89mlTrain batch 6/7 - 611.4ms/batch - loss: 0.30958 - diff: 24.77mlTrain batch 7/7 - 70.6ms/batch - loss: 0.41346 - diff: 25.17mlTrain batch 7/7 - 10.7s 70.6ms/batch - loss: 0.41346 - diff: 25.17ml
Test 1.0s: val_loss: 0.35397 - diff: 22.58ml

Epoch 82: current best loss = 0.31293, at epoch 33
Train batch 1/7 - 610.2ms/batch - loss: 0.33433 - diff: 26.75mlTrain batch 2/7 - 598.5ms/batch - loss: 0.34435 - diff: 27.55mlTrain batch 3/7 - 595.7ms/batch - loss: 0.31462 - diff: 25.17mlTrain batch 4/7 - 596.1ms/batch - loss: 0.31217 - diff: 24.97mlTrain batch 5/7 - 598.0ms/batch - loss: 0.32626 - diff: 26.10mlTrain batch 6/7 - 599.1ms/batch - loss: 0.31478 - diff: 25.18mlTrain batch 7/7 - 70.8ms/batch - loss: 0.37122 - diff: 25.25mlTrain batch 7/7 - 10.7s 70.8ms/batch - loss: 0.37122 - diff: 25.25ml
Test 1.0s: val_loss: 0.32279 - diff: 22.24ml

Epoch 83: current best loss = 0.31293, at epoch 33
Train batch 1/7 - 607.9ms/batch - loss: 0.34647 - diff: 27.72mlTrain batch 2/7 - 602.9ms/batch - loss: 0.32110 - diff: 25.69mlTrain batch 3/7 - 605.1ms/batch - loss: 0.31724 - diff: 25.38mlTrain batch 4/7 - 601.6ms/batch - loss: 0.31144 - diff: 24.92mlTrain batch 5/7 - 607.0ms/batch - loss: 0.31515 - diff: 25.21mlTrain batch 6/7 - 594.7ms/batch - loss: 0.31690 - diff: 25.35mlTrain batch 7/7 - 71.9ms/batch - loss: 0.36742 - diff: 25.37mlTrain batch 7/7 - 10.6s 71.9ms/batch - loss: 0.36742 - diff: 25.37ml
Test 1.0s: val_loss: 0.32986 - diff: 22.20ml

Epoch 84: current best loss = 0.31293, at epoch 33
Train batch 1/7 - 606.5ms/batch - loss: 0.29053 - diff: 23.24mlTrain batch 2/7 - 604.5ms/batch - loss: 0.33384 - diff: 26.71mlTrain batch 3/7 - 608.4ms/batch - loss: 0.31098 - diff: 24.88mlTrain batch 4/7 - 597.4ms/batch - loss: 0.31651 - diff: 25.32mlTrain batch 5/7 - 614.2ms/batch - loss: 0.31884 - diff: 25.51mlTrain batch 6/7 - 598.2ms/batch - loss: 0.31657 - diff: 25.33mlTrain batch 7/7 - 71.0ms/batch - loss: 0.35581 - diff: 25.27mlTrain batch 7/7 - 10.6s 71.0ms/batch - loss: 0.35581 - diff: 25.27ml
Test 1.0s: val_loss: 0.34155 - diff: 22.06ml

Epoch 85: current best loss = 0.31293, at epoch 33
Train batch 1/7 - 610.8ms/batch - loss: 0.31868 - diff: 25.49mlTrain batch 2/7 - 598.0ms/batch - loss: 0.33379 - diff: 26.70mlTrain batch 3/7 - 599.1ms/batch - loss: 0.30999 - diff: 24.80mlTrain batch 4/7 - 599.1ms/batch - loss: 0.31137 - diff: 24.91mlTrain batch 5/7 - 601.2ms/batch - loss: 0.32791 - diff: 26.23mlTrain batch 6/7 - 598.6ms/batch - loss: 0.32371 - diff: 25.90mlTrain batch 7/7 - 71.6ms/batch - loss: 0.35364 - diff: 25.77mlTrain batch 7/7 - 10.8s 71.6ms/batch - loss: 0.35364 - diff: 25.77ml
Test 1.0s: val_loss: 0.33196 - diff: 21.98ml

Epoch 86: current best loss = 0.31293, at epoch 33
Train batch 1/7 - 608.4ms/batch - loss: 0.40093 - diff: 32.07mlTrain batch 2/7 - 597.6ms/batch - loss: 0.33294 - diff: 26.64mlTrain batch 3/7 - 606.3ms/batch - loss: 0.31124 - diff: 24.90mlTrain batch 4/7 - 597.4ms/batch - loss: 0.30666 - diff: 24.53mlTrain batch 5/7 - 611.7ms/batch - loss: 0.32171 - diff: 25.74mlTrain batch 6/7 - 595.7ms/batch - loss: 0.31498 - diff: 25.20mlTrain batch 7/7 - 71.4ms/batch - loss: 0.37354 - diff: 25.28mlTrain batch 7/7 - 10.7s 71.4ms/batch - loss: 0.37354 - diff: 25.28ml
Test 1.0s: val_loss: 0.31988 - diff: 21.86ml

Epoch 87: current best loss = 0.31293, at epoch 33
Train batch 1/7 - 607.9ms/batch - loss: 0.34021 - diff: 27.22mlTrain batch 2/7 - 597.9ms/batch - loss: 0.29098 - diff: 23.28mlTrain batch 3/7 - 606.7ms/batch - loss: 0.30363 - diff: 24.29mlTrain batch 4/7 - 596.8ms/batch - loss: 0.31620 - diff: 25.30mlTrain batch 5/7 - 607.1ms/batch - loss: 0.30012 - diff: 24.01mlTrain batch 6/7 - 595.4ms/batch - loss: 0.31329 - diff: 25.06mlTrain batch 7/7 - 71.4ms/batch - loss: 0.36313 - diff: 25.08mlTrain batch 7/7 - 10.6s 71.4ms/batch - loss: 0.36313 - diff: 25.08ml
Test 0.9s: val_loss: 0.34904 - diff: 22.35ml

Epoch 88: current best loss = 0.31293, at epoch 33
Train batch 1/7 - 595.7ms/batch - loss: 0.37241 - diff: 29.79mlTrain batch 2/7 - 596.8ms/batch - loss: 0.35286 - diff: 28.23mlTrain batch 3/7 - 596.5ms/batch - loss: 0.33790 - diff: 27.03mlTrain batch 4/7 - 596.9ms/batch - loss: 0.32499 - diff: 26.00mlTrain batch 5/7 - 598.7ms/batch - loss: 0.33459 - diff: 26.77mlTrain batch 6/7 - 597.1ms/batch - loss: 0.32589 - diff: 26.07mlTrain batch 7/7 - 70.9ms/batch - loss: 0.37081 - diff: 26.04mlTrain batch 7/7 - 10.7s 70.9ms/batch - loss: 0.37081 - diff: 26.04ml
Test 1.0s: val_loss: 0.34161 - diff: 22.39ml
Epoch    89: reducing learning rate of group 0 to 3.1250e-05.

Epoch 89: current best loss = 0.31293, at epoch 33
Train batch 1/7 - 596.1ms/batch - loss: 0.33240 - diff: 26.59mlTrain batch 2/7 - 596.6ms/batch - loss: 0.31956 - diff: 25.57mlTrain batch 3/7 - 605.2ms/batch - loss: 0.30162 - diff: 24.13mlTrain batch 4/7 - 599.4ms/batch - loss: 0.31490 - diff: 25.19mlTrain batch 5/7 - 598.7ms/batch - loss: 0.32140 - diff: 25.71mlTrain batch 6/7 - 601.0ms/batch - loss: 0.31670 - diff: 25.34mlTrain batch 7/7 - 72.3ms/batch - loss: 0.33928 - diff: 25.16mlTrain batch 7/7 - 10.7s 72.3ms/batch - loss: 0.33928 - diff: 25.16ml
Test 1.0s: val_loss: 0.33174 - diff: 21.58ml

Epoch 90: current best loss = 0.31293, at epoch 33
Train batch 1/7 - 603.7ms/batch - loss: 0.23787 - diff: 19.03mlTrain batch 2/7 - 601.2ms/batch - loss: 0.27662 - diff: 22.13mlTrain batch 3/7 - 606.9ms/batch - loss: 0.29561 - diff: 23.65mlTrain batch 4/7 - 612.7ms/batch - loss: 0.28628 - diff: 22.90mlTrain batch 5/7 - 606.0ms/batch - loss: 0.30693 - diff: 24.55mlTrain batch 6/7 - 597.3ms/batch - loss: 0.31436 - diff: 25.15mlTrain batch 7/7 - 71.0ms/batch - loss: 0.35687 - diff: 25.12mlTrain batch 7/7 - 10.6s 71.0ms/batch - loss: 0.35687 - diff: 25.12ml
Test 1.1s: val_loss: 0.32105 - diff: 21.81ml

Epoch 91: current best loss = 0.31293, at epoch 33
Train batch 1/7 - 599.2ms/batch - loss: 0.32130 - diff: 25.70mlTrain batch 2/7 - 599.4ms/batch - loss: 0.31035 - diff: 24.83mlTrain batch 3/7 - 594.2ms/batch - loss: 0.33002 - diff: 26.40mlTrain batch 4/7 - 605.8ms/batch - loss: 0.32183 - diff: 25.75mlTrain batch 5/7 - 596.8ms/batch - loss: 0.31722 - diff: 25.38mlTrain batch 6/7 - 598.0ms/batch - loss: 0.31708 - diff: 25.37mlTrain batch 7/7 - 71.8ms/batch - loss: 0.33858 - diff: 25.18mlTrain batch 7/7 - 10.7s 71.8ms/batch - loss: 0.33858 - diff: 25.18ml
Test 1.1s: val_loss: 0.31756 - diff: 21.45ml

Epoch 92: current best loss = 0.31293, at epoch 33
Train batch 1/7 - 607.0ms/batch - loss: 0.30200 - diff: 24.16mlTrain batch 2/7 - 597.6ms/batch - loss: 0.30048 - diff: 24.04mlTrain batch 3/7 - 599.9ms/batch - loss: 0.31189 - diff: 24.95mlTrain batch 4/7 - 597.2ms/batch - loss: 0.31026 - diff: 24.82mlTrain batch 5/7 - 606.7ms/batch - loss: 0.30484 - diff: 24.39mlTrain batch 6/7 - 596.8ms/batch - loss: 0.31099 - diff: 24.88mlTrain batch 7/7 - 71.8ms/batch - loss: 0.35868 - diff: 24.89mlTrain batch 7/7 - 10.6s 71.8ms/batch - loss: 0.35868 - diff: 24.89ml
Test 1.0s: val_loss: 0.33382 - diff: 21.95ml

Epoch 93: current best loss = 0.31293, at epoch 33
Train batch 1/7 - 599.7ms/batch - loss: 0.27970 - diff: 22.38mlTrain batch 2/7 - 597.3ms/batch - loss: 0.30493 - diff: 24.39mlTrain batch 3/7 - 604.2ms/batch - loss: 0.31015 - diff: 24.81mlTrain batch 4/7 - 597.9ms/batch - loss: 0.30075 - diff: 24.06mlTrain batch 5/7 - 605.1ms/batch - loss: 0.31573 - diff: 25.26mlTrain batch 6/7 - 597.5ms/batch - loss: 0.31619 - diff: 25.30mlTrain batch 7/7 - 71.8ms/batch - loss: 0.36481 - diff: 25.30mlTrain batch 7/7 - 10.6s 71.8ms/batch - loss: 0.36481 - diff: 25.30ml
Test 1.0s: val_loss: 0.34728 - diff: 21.35ml

Epoch 94: current best loss = 0.31293, at epoch 33
Train batch 1/7 - 602.3ms/batch - loss: 0.30264 - diff: 24.21mlTrain batch 2/7 - 595.9ms/batch - loss: 0.32289 - diff: 25.83mlTrain batch 3/7 - 608.5ms/batch - loss: 0.31432 - diff: 25.15mlTrain batch 4/7 - 598.8ms/batch - loss: 0.31544 - diff: 25.23mlTrain batch 5/7 - 598.6ms/batch - loss: 0.32324 - diff: 25.86mlTrain batch 6/7 - 600.3ms/batch - loss: 0.31460 - diff: 25.17mlTrain batch 7/7 - 71.8ms/batch - loss: 0.34863 - diff: 25.08mlTrain batch 7/7 - 10.7s 71.8ms/batch - loss: 0.34863 - diff: 25.08ml
Test 1.0s: val_loss: 0.32056 - diff: 21.34ml

Epoch 95: current best loss = 0.31293, at epoch 33
Train batch 1/7 - 608.0ms/batch - loss: 0.27068 - diff: 21.65mlTrain batch 2/7 - 596.6ms/batch - loss: 0.27363 - diff: 21.89mlTrain batch 3/7 - 607.5ms/batch - loss: 0.29625 - diff: 23.70mlTrain batch 4/7 - 597.9ms/batch - loss: 0.31446 - diff: 25.16mlTrain batch 5/7 - 603.9ms/batch - loss: 0.31514 - diff: 25.21mlTrain batch 6/7 - 599.8ms/batch - loss: 0.30766 - diff: 24.61mlTrain batch 7/7 - 71.9ms/batch - loss: 0.39302 - diff: 24.89mlTrain batch 7/7 - 10.7s 71.9ms/batch - loss: 0.39302 - diff: 24.89ml
Test 1.0s: val_loss: 0.32565 - diff: 21.35ml

Epoch 96: current best loss = 0.31293, at epoch 33
Train batch 1/7 - 607.4ms/batch - loss: 0.32286 - diff: 25.83mlTrain batch 2/7 - 608.3ms/batch - loss: 0.30001 - diff: 24.00mlTrain batch 3/7 - 597.6ms/batch - loss: 0.29795 - diff: 23.84mlTrain batch 4/7 - 600.5ms/batch - loss: 0.30585 - diff: 24.47mlTrain batch 5/7 - 594.9ms/batch - loss: 0.31669 - diff: 25.34mlTrain batch 6/7 - 599.1ms/batch - loss: 0.31169 - diff: 24.94mlTrain batch 7/7 - 72.0ms/batch - loss: 0.34036 - diff: 24.81mlTrain batch 7/7 - 10.7s 72.0ms/batch - loss: 0.34036 - diff: 24.81ml
Test 1.0s: val_loss: 0.32820 - diff: 21.57ml

Epoch 97: current best loss = 0.31293, at epoch 33
Train batch 1/7 - 608.6ms/batch - loss: 0.28592 - diff: 22.87mlTrain batch 2/7 - 597.6ms/batch - loss: 0.32551 - diff: 26.04mlTrain batch 3/7 - 606.5ms/batch - loss: 0.33014 - diff: 26.41mlTrain batch 4/7 - 596.4ms/batch - loss: 0.32187 - diff: 25.75mlTrain batch 5/7 - 612.1ms/batch - loss: 0.32166 - diff: 25.73mlTrain batch 6/7 - 593.2ms/batch - loss: 0.31491 - diff: 25.19mlTrain batch 7/7 - 71.0ms/batch - loss: 0.35820 - diff: 25.17mlTrain batch 7/7 - 10.6s 71.0ms/batch - loss: 0.35820 - diff: 25.17ml
Test 1.0s: val_loss: 0.33481 - diff: 21.19ml

Epoch 98: current best loss = 0.31293, at epoch 33
Train batch 1/7 - 603.0ms/batch - loss: 0.35444 - diff: 28.36mlTrain batch 2/7 - 600.9ms/batch - loss: 0.33257 - diff: 26.61mlTrain batch 3/7 - 597.3ms/batch - loss: 0.32380 - diff: 25.90mlTrain batch 4/7 - 597.1ms/batch - loss: 0.31686 - diff: 25.35mlTrain batch 5/7 - 596.0ms/batch - loss: 0.31093 - diff: 24.87mlTrain batch 6/7 - 597.7ms/batch - loss: 0.30565 - diff: 24.45mlTrain batch 7/7 - 71.4ms/batch - loss: 0.43720 - diff: 25.05mlTrain batch 7/7 - 10.7s 71.4ms/batch - loss: 0.43720 - diff: 25.05ml
Test 0.9s: val_loss: 0.32854 - diff: 21.46ml

Epoch 99: current best loss = 0.31293, at epoch 33
Train batch 1/7 - 597.2ms/batch - loss: 0.26537 - diff: 21.23mlTrain batch 2/7 - 598.9ms/batch - loss: 0.33657 - diff: 26.93mlTrain batch 3/7 - 599.5ms/batch - loss: 0.32359 - diff: 25.89mlTrain batch 4/7 - 600.9ms/batch - loss: 0.31500 - diff: 25.20mlTrain batch 5/7 - 598.2ms/batch - loss: 0.31580 - diff: 25.26mlTrain batch 6/7 - 598.3ms/batch - loss: 0.30946 - diff: 24.76mlTrain batch 7/7 - 73.1ms/batch - loss: 0.34243 - diff: 24.66mlTrain batch 7/7 - 10.7s 73.1ms/batch - loss: 0.34243 - diff: 24.66ml
Test 1.0s: val_loss: 0.32670 - diff: 21.78ml
Epoch   100: reducing learning rate of group 0 to 1.5625e-05.

Epoch 100: current best loss = 0.31293, at epoch 33
Train batch 1/7 - 612.7ms/batch - loss: 0.26930 - diff: 21.54mlTrain batch 2/7 - 598.1ms/batch - loss: 0.29102 - diff: 23.28mlTrain batch 3/7 - 602.3ms/batch - loss: 0.29605 - diff: 23.68mlTrain batch 4/7 - 597.9ms/batch - loss: 0.31855 - diff: 25.48mlTrain batch 5/7 - 597.3ms/batch - loss: 0.31876 - diff: 25.50mlTrain batch 6/7 - 599.9ms/batch - loss: 0.30933 - diff: 24.75mlTrain batch 7/7 - 71.2ms/batch - loss: 0.33766 - diff: 24.62mlTrain batch 7/7 - 10.6s 71.2ms/batch - loss: 0.33766 - diff: 24.62ml
Test 1.0s: val_loss: 0.31435 - diff: 21.05ml

Epoch 101: current best loss = 0.31293, at epoch 33
Train batch 1/7 - 598.3ms/batch - loss: 0.33197 - diff: 26.56mlTrain batch 2/7 - 603.3ms/batch - loss: 0.31115 - diff: 24.89mlTrain batch 3/7 - 597.3ms/batch - loss: 0.33242 - diff: 26.59mlTrain batch 4/7 - 596.9ms/batch - loss: 0.31957 - diff: 25.57mlTrain batch 5/7 - 598.6ms/batch - loss: 0.31375 - diff: 25.10mlTrain batch 6/7 - 597.9ms/batch - loss: 0.30363 - diff: 24.29mlTrain batch 7/7 - 71.2ms/batch - loss: 0.35458 - diff: 24.33mlTrain batch 7/7 - 10.7s 71.2ms/batch - loss: 0.35458 - diff: 24.33ml
Test 1.0s: val_loss: 0.31291 - diff: 21.15ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Systole_VGG19_Adam-0.001_MAE_DA3_best

Epoch 102: current best loss = 0.31291, at epoch 101
Train batch 1/7 - 599.5ms/batch - loss: 0.32069 - diff: 25.66mlTrain batch 2/7 - 607.0ms/batch - loss: 0.35363 - diff: 28.29mlTrain batch 3/7 - 601.0ms/batch - loss: 0.32444 - diff: 25.95mlTrain batch 4/7 - 606.0ms/batch - loss: 0.31677 - diff: 25.34mlTrain batch 5/7 - 597.8ms/batch - loss: 0.31772 - diff: 25.42mlTrain batch 6/7 - 608.4ms/batch - loss: 0.31164 - diff: 24.93mlTrain batch 7/7 - 70.6ms/batch - loss: 0.35251 - diff: 24.89mlTrain batch 7/7 - 10.7s 70.6ms/batch - loss: 0.35251 - diff: 24.89ml
Test 1.0s: val_loss: 0.30757 - diff: 20.93ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Systole_VGG19_Adam-0.001_MAE_DA3_best

Epoch 103: current best loss = 0.30757, at epoch 102
Train batch 1/7 - 599.0ms/batch - loss: 0.26558 - diff: 21.25mlTrain batch 2/7 - 604.1ms/batch - loss: 0.28157 - diff: 22.53mlTrain batch 3/7 - 600.1ms/batch - loss: 0.29120 - diff: 23.30mlTrain batch 4/7 - 600.8ms/batch - loss: 0.29196 - diff: 23.36mlTrain batch 5/7 - 597.1ms/batch - loss: 0.30136 - diff: 24.11mlTrain batch 6/7 - 598.6ms/batch - loss: 0.30619 - diff: 24.50mlTrain batch 7/7 - 71.4ms/batch - loss: 0.35491 - diff: 24.51mlTrain batch 7/7 - 10.7s 71.4ms/batch - loss: 0.35491 - diff: 24.51ml
Test 0.9s: val_loss: 0.32098 - diff: 20.90ml

Epoch 104: current best loss = 0.30757, at epoch 102
Train batch 1/7 - 603.7ms/batch - loss: 0.29090 - diff: 23.27mlTrain batch 2/7 - 596.4ms/batch - loss: 0.27247 - diff: 21.80mlTrain batch 3/7 - 610.4ms/batch - loss: 0.30993 - diff: 24.79mlTrain batch 4/7 - 598.2ms/batch - loss: 0.29844 - diff: 23.88mlTrain batch 5/7 - 605.3ms/batch - loss: 0.30064 - diff: 24.05mlTrain batch 6/7 - 596.7ms/batch - loss: 0.30562 - diff: 24.45mlTrain batch 7/7 - 72.0ms/batch - loss: 0.40354 - diff: 24.81mlTrain batch 7/7 - 10.6s 72.0ms/batch - loss: 0.40354 - diff: 24.81ml
Test 1.0s: val_loss: 0.34176 - diff: 20.92ml

Epoch 105: current best loss = 0.30757, at epoch 102
Train batch 1/7 - 599.8ms/batch - loss: 0.30318 - diff: 24.25mlTrain batch 2/7 - 597.8ms/batch - loss: 0.29053 - diff: 23.24mlTrain batch 3/7 - 607.3ms/batch - loss: 0.28586 - diff: 22.87mlTrain batch 4/7 - 598.0ms/batch - loss: 0.30905 - diff: 24.72mlTrain batch 5/7 - 605.1ms/batch - loss: 0.30997 - diff: 24.80mlTrain batch 6/7 - 596.6ms/batch - loss: 0.30226 - diff: 24.18mlTrain batch 7/7 - 70.8ms/batch - loss: 0.33785 - diff: 24.11mlTrain batch 7/7 - 10.7s 70.8ms/batch - loss: 0.33785 - diff: 24.11ml
Test 1.1s: val_loss: 0.31161 - diff: 20.89ml

Epoch 106: current best loss = 0.30757, at epoch 102
Train batch 1/7 - 609.0ms/batch - loss: 0.27083 - diff: 21.67mlTrain batch 2/7 - 600.3ms/batch - loss: 0.29377 - diff: 23.50mlTrain batch 3/7 - 596.6ms/batch - loss: 0.30411 - diff: 24.33mlTrain batch 4/7 - 596.9ms/batch - loss: 0.30223 - diff: 24.18mlTrain batch 5/7 - 607.2ms/batch - loss: 0.29403 - diff: 23.52mlTrain batch 6/7 - 596.2ms/batch - loss: 0.30868 - diff: 24.69mlTrain batch 7/7 - 71.4ms/batch - loss: 0.35391 - diff: 24.69mlTrain batch 7/7 - 10.6s 71.4ms/batch - loss: 0.35391 - diff: 24.69ml
Test 1.0s: val_loss: 0.32433 - diff: 20.99ml

Epoch 107: current best loss = 0.30757, at epoch 102
Train batch 1/7 - 608.3ms/batch - loss: 0.27821 - diff: 22.26mlTrain batch 2/7 - 596.3ms/batch - loss: 0.27703 - diff: 22.16mlTrain batch 3/7 - 598.3ms/batch - loss: 0.29273 - diff: 23.42mlTrain batch 4/7 - 597.3ms/batch - loss: 0.31081 - diff: 24.87mlTrain batch 5/7 - 602.6ms/batch - loss: 0.30490 - diff: 24.39mlTrain batch 6/7 - 598.3ms/batch - loss: 0.30524 - diff: 24.42mlTrain batch 7/7 - 71.6ms/batch - loss: 0.33420 - diff: 24.30mlTrain batch 7/7 - 10.6s 71.6ms/batch - loss: 0.33420 - diff: 24.30ml
Test 1.0s: val_loss: 0.30752 - diff: 20.78ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Systole_VGG19_Adam-0.001_MAE_DA3_best

Epoch 108: current best loss = 0.30752, at epoch 107
Train batch 1/7 - 597.5ms/batch - loss: 0.28846 - diff: 23.08mlTrain batch 2/7 - 596.6ms/batch - loss: 0.30432 - diff: 24.35mlTrain batch 3/7 - 597.5ms/batch - loss: 0.29443 - diff: 23.55mlTrain batch 4/7 - 599.7ms/batch - loss: 0.29202 - diff: 23.36mlTrain batch 5/7 - 597.8ms/batch - loss: 0.29493 - diff: 23.59mlTrain batch 6/7 - 599.7ms/batch - loss: 0.30025 - diff: 24.02mlTrain batch 7/7 - 71.9ms/batch - loss: 0.36420 - diff: 24.15mlTrain batch 7/7 - 10.7s 71.9ms/batch - loss: 0.36420 - diff: 24.15ml
Test 1.0s: val_loss: 0.32206 - diff: 20.76ml

Epoch 109: current best loss = 0.30752, at epoch 107
Train batch 1/7 - 597.9ms/batch - loss: 0.25409 - diff: 20.33mlTrain batch 2/7 - 596.3ms/batch - loss: 0.27365 - diff: 21.89mlTrain batch 3/7 - 598.8ms/batch - loss: 0.29668 - diff: 23.73mlTrain batch 4/7 - 597.0ms/batch - loss: 0.30872 - diff: 24.70mlTrain batch 5/7 - 595.9ms/batch - loss: 0.30384 - diff: 24.31mlTrain batch 6/7 - 599.2ms/batch - loss: 0.30207 - diff: 24.17mlTrain batch 7/7 - 71.3ms/batch - loss: 0.33937 - diff: 24.11mlTrain batch 7/7 - 10.7s 71.3ms/batch - loss: 0.33937 - diff: 24.11ml
Test 1.0s: val_loss: 0.31414 - diff: 20.85ml

Epoch 110: current best loss = 0.30752, at epoch 107
Train batch 1/7 - 603.3ms/batch - loss: 0.26635 - diff: 21.31mlTrain batch 2/7 - 598.4ms/batch - loss: 0.26029 - diff: 20.82mlTrain batch 3/7 - 596.8ms/batch - loss: 0.26731 - diff: 21.38mlTrain batch 4/7 - 597.6ms/batch - loss: 0.27967 - diff: 22.37mlTrain batch 5/7 - 595.4ms/batch - loss: 0.29111 - diff: 23.29mlTrain batch 6/7 - 601.3ms/batch - loss: 0.30291 - diff: 24.23mlTrain batch 7/7 - 71.8ms/batch - loss: 0.33113 - diff: 24.11mlTrain batch 7/7 - 10.7s 71.8ms/batch - loss: 0.33113 - diff: 24.11ml
Test 1.0s: val_loss: 0.31181 - diff: 20.80ml

Epoch 111: current best loss = 0.30752, at epoch 107
Train batch 1/7 - 607.9ms/batch - loss: 0.31835 - diff: 25.47mlTrain batch 2/7 - 601.6ms/batch - loss: 0.29869 - diff: 23.89mlTrain batch 3/7 - 606.8ms/batch - loss: 0.30939 - diff: 24.75mlTrain batch 4/7 - 598.5ms/batch - loss: 0.29785 - diff: 23.83mlTrain batch 5/7 - 597.9ms/batch - loss: 0.31985 - diff: 25.59mlTrain batch 6/7 - 602.1ms/batch - loss: 0.30802 - diff: 24.64mlTrain batch 7/7 - 71.1ms/batch - loss: 0.34566 - diff: 24.58mlTrain batch 7/7 - 10.7s 71.1ms/batch - loss: 0.34566 - diff: 24.58ml
Test 1.0s: val_loss: 0.30437 - diff: 20.71ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Systole_VGG19_Adam-0.001_MAE_DA3_best

Epoch 112: current best loss = 0.30437, at epoch 111
Train batch 1/7 - 607.4ms/batch - loss: 0.22745 - diff: 18.20mlTrain batch 2/7 - 596.1ms/batch - loss: 0.29385 - diff: 23.51mlTrain batch 3/7 - 612.0ms/batch - loss: 0.30897 - diff: 24.72mlTrain batch 4/7 - 597.7ms/batch - loss: 0.31112 - diff: 24.89mlTrain batch 5/7 - 606.4ms/batch - loss: 0.30852 - diff: 24.68mlTrain batch 6/7 - 600.7ms/batch - loss: 0.31134 - diff: 24.91mlTrain batch 7/7 - 71.8ms/batch - loss: 0.32909 - diff: 24.71mlTrain batch 7/7 - 10.8s 71.8ms/batch - loss: 0.32909 - diff: 24.71ml
Test 1.0s: val_loss: 0.33858 - diff: 20.82ml

Epoch 113: current best loss = 0.30437, at epoch 111
Train batch 1/7 - 598.1ms/batch - loss: 0.28130 - diff: 22.50mlTrain batch 2/7 - 600.0ms/batch - loss: 0.28907 - diff: 23.13mlTrain batch 3/7 - 609.0ms/batch - loss: 0.30301 - diff: 24.24mlTrain batch 4/7 - 600.4ms/batch - loss: 0.30379 - diff: 24.30mlTrain batch 5/7 - 595.2ms/batch - loss: 0.31922 - diff: 25.54mlTrain batch 6/7 - 599.8ms/batch - loss: 0.31185 - diff: 24.95mlTrain batch 7/7 - 71.9ms/batch - loss: 0.36286 - diff: 24.98mlTrain batch 7/7 - 10.7s 71.9ms/batch - loss: 0.36286 - diff: 24.98ml
Test 1.0s: val_loss: 0.31385 - diff: 21.28ml

Epoch 114: current best loss = 0.30437, at epoch 111
Train batch 1/7 - 599.3ms/batch - loss: 0.33526 - diff: 26.82mlTrain batch 2/7 - 599.4ms/batch - loss: 0.29776 - diff: 23.82mlTrain batch 3/7 - 599.3ms/batch - loss: 0.29983 - diff: 23.99mlTrain batch 4/7 - 604.8ms/batch - loss: 0.29463 - diff: 23.57mlTrain batch 5/7 - 598.3ms/batch - loss: 0.28843 - diff: 23.07mlTrain batch 6/7 - 607.2ms/batch - loss: 0.30602 - diff: 24.48mlTrain batch 7/7 - 70.7ms/batch - loss: 0.38954 - diff: 24.75mlTrain batch 7/7 - 10.7s 70.7ms/batch - loss: 0.38954 - diff: 24.75ml
Test 1.0s: val_loss: 0.33180 - diff: 21.27ml

Epoch 115: current best loss = 0.30437, at epoch 111
Train batch 1/7 - 613.6ms/batch - loss: 0.25337 - diff: 20.27mlTrain batch 2/7 - 597.6ms/batch - loss: 0.27215 - diff: 21.77mlTrain batch 3/7 - 606.6ms/batch - loss: 0.29640 - diff: 23.71mlTrain batch 4/7 - 596.6ms/batch - loss: 0.28949 - diff: 23.16mlTrain batch 5/7 - 607.4ms/batch - loss: 0.30673 - diff: 24.54mlTrain batch 6/7 - 597.9ms/batch - loss: 0.30933 - diff: 24.75mlTrain batch 7/7 - 71.4ms/batch - loss: 0.34767 - diff: 24.69mlTrain batch 7/7 - 10.6s 71.4ms/batch - loss: 0.34767 - diff: 24.69ml
Test 1.0s: val_loss: 0.33129 - diff: 20.77ml

Epoch 116: current best loss = 0.30437, at epoch 111
Train batch 1/7 - 607.0ms/batch - loss: 0.40565 - diff: 32.45mlTrain batch 2/7 - 614.0ms/batch - loss: 0.36733 - diff: 29.39mlTrain batch 3/7 - 605.4ms/batch - loss: 0.31717 - diff: 25.37mlTrain batch 4/7 - 598.1ms/batch - loss: 0.31228 - diff: 24.98mlTrain batch 5/7 - 606.8ms/batch - loss: 0.30408 - diff: 24.33mlTrain batch 6/7 - 596.0ms/batch - loss: 0.31167 - diff: 24.93mlTrain batch 7/7 - 71.2ms/batch - loss: 0.34256 - diff: 24.82mlTrain batch 7/7 - 10.6s 71.2ms/batch - loss: 0.34256 - diff: 24.82ml
Test 1.1s: val_loss: 0.32878 - diff: 21.52ml

Epoch 117: current best loss = 0.30437, at epoch 111
Train batch 1/7 - 597.9ms/batch - loss: 0.23988 - diff: 19.19mlTrain batch 2/7 - 603.7ms/batch - loss: 0.24934 - diff: 19.95mlTrain batch 3/7 - 599.3ms/batch - loss: 0.26137 - diff: 20.91mlTrain batch 4/7 - 595.5ms/batch - loss: 0.28948 - diff: 23.16mlTrain batch 5/7 - 594.7ms/batch - loss: 0.30196 - diff: 24.16mlTrain batch 6/7 - 600.9ms/batch - loss: 0.30546 - diff: 24.44mlTrain batch 7/7 - 71.7ms/batch - loss: 0.36880 - diff: 24.56mlTrain batch 7/7 - 10.7s 71.7ms/batch - loss: 0.36880 - diff: 24.56ml
Test 1.1s: val_loss: 0.34372 - diff: 21.17ml

Epoch 118: current best loss = 0.30437, at epoch 111
Train batch 1/7 - 600.8ms/batch - loss: 0.33706 - diff: 26.96mlTrain batch 2/7 - 606.9ms/batch - loss: 0.35260 - diff: 28.21mlTrain batch 3/7 - 608.4ms/batch - loss: 0.32451 - diff: 25.96mlTrain batch 4/7 - 596.2ms/batch - loss: 0.32079 - diff: 25.66mlTrain batch 5/7 - 603.6ms/batch - loss: 0.31523 - diff: 25.22mlTrain batch 6/7 - 598.6ms/batch - loss: 0.31343 - diff: 25.07mlTrain batch 7/7 - 70.7ms/batch - loss: 0.36438 - diff: 25.10mlTrain batch 7/7 - 10.6s 70.7ms/batch - loss: 0.36438 - diff: 25.10ml
Test 1.0s: val_loss: 0.32574 - diff: 21.36ml

Epoch 119: current best loss = 0.30437, at epoch 111
Train batch 1/7 - 602.4ms/batch - loss: 0.37548 - diff: 30.04mlTrain batch 2/7 - 597.1ms/batch - loss: 0.32770 - diff: 26.22mlTrain batch 3/7 - 609.0ms/batch - loss: 0.32264 - diff: 25.81mlTrain batch 4/7 - 599.2ms/batch - loss: 0.30928 - diff: 24.74mlTrain batch 5/7 - 608.4ms/batch - loss: 0.31894 - diff: 25.52mlTrain batch 6/7 - 596.8ms/batch - loss: 0.30842 - diff: 24.67mlTrain batch 7/7 - 71.0ms/batch - loss: 0.33374 - diff: 24.53mlTrain batch 7/7 - 10.6s 71.0ms/batch - loss: 0.33374 - diff: 24.53ml
Test 1.0s: val_loss: 0.31303 - diff: 20.66ml

Epoch 120: current best loss = 0.30437, at epoch 111
Train batch 1/7 - 598.6ms/batch - loss: 0.32410 - diff: 25.93mlTrain batch 2/7 - 595.1ms/batch - loss: 0.30236 - diff: 24.19mlTrain batch 3/7 - 595.0ms/batch - loss: 0.30509 - diff: 24.41mlTrain batch 4/7 - 596.7ms/batch - loss: 0.29221 - diff: 23.38mlTrain batch 5/7 - 597.4ms/batch - loss: 0.29922 - diff: 23.94mlTrain batch 6/7 - 603.3ms/batch - loss: 0.30033 - diff: 24.03mlTrain batch 7/7 - 71.1ms/batch - loss: 0.32373 - diff: 23.88mlTrain batch 7/7 - 10.8s 71.1ms/batch - loss: 0.32373 - diff: 23.88ml
Test 1.0s: val_loss: 0.32178 - diff: 20.45ml

Epoch 121: current best loss = 0.30437, at epoch 111
Train batch 1/7 - 608.4ms/batch - loss: 0.26656 - diff: 21.32mlTrain batch 2/7 - 598.0ms/batch - loss: 0.29814 - diff: 23.85mlTrain batch 3/7 - 609.2ms/batch - loss: 0.30309 - diff: 24.25mlTrain batch 4/7 - 598.8ms/batch - loss: 0.30116 - diff: 24.09mlTrain batch 5/7 - 609.1ms/batch - loss: 0.30887 - diff: 24.71mlTrain batch 6/7 - 597.0ms/batch - loss: 0.29637 - diff: 23.71mlTrain batch 7/7 - 70.9ms/batch - loss: 0.34731 - diff: 23.76mlTrain batch 7/7 - 10.6s 70.9ms/batch - loss: 0.34731 - diff: 23.76ml
Test 1.0s: val_loss: 0.30288 - diff: 20.44ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Systole_VGG19_Adam-0.001_MAE_DA3_best

Epoch 122: current best loss = 0.30288, at epoch 121
Train batch 1/7 - 599.8ms/batch - loss: 0.22332 - diff: 17.87mlTrain batch 2/7 - 597.9ms/batch - loss: 0.22540 - diff: 18.03mlTrain batch 3/7 - 600.4ms/batch - loss: 0.25979 - diff: 20.78mlTrain batch 4/7 - 595.5ms/batch - loss: 0.29592 - diff: 23.67mlTrain batch 5/7 - 604.1ms/batch - loss: 0.30101 - diff: 24.08mlTrain batch 6/7 - 601.4ms/batch - loss: 0.30236 - diff: 24.19mlTrain batch 7/7 - 71.7ms/batch - loss: 0.36283 - diff: 24.29mlTrain batch 7/7 - 10.6s 71.7ms/batch - loss: 0.36283 - diff: 24.29ml
Test 1.0s: val_loss: 0.32678 - diff: 21.45ml

Epoch 123: current best loss = 0.30288, at epoch 121
Train batch 1/7 - 607.8ms/batch - loss: 0.32726 - diff: 26.18mlTrain batch 2/7 - 597.9ms/batch - loss: 0.30079 - diff: 24.06mlTrain batch 3/7 - 611.5ms/batch - loss: 0.28660 - diff: 22.93mlTrain batch 4/7 - 596.8ms/batch - loss: 0.29105 - diff: 23.28mlTrain batch 5/7 - 607.0ms/batch - loss: 0.31225 - diff: 24.98mlTrain batch 6/7 - 607.0ms/batch - loss: 0.30459 - diff: 24.37mlTrain batch 7/7 - 71.3ms/batch - loss: 0.34552 - diff: 24.33mlTrain batch 7/7 - 10.6s 71.3ms/batch - loss: 0.34552 - diff: 24.33ml
Test 1.0s: val_loss: 0.30478 - diff: 20.69ml

Epoch 124: current best loss = 0.30288, at epoch 121
Train batch 1/7 - 598.2ms/batch - loss: 0.38693 - diff: 30.95mlTrain batch 2/7 - 596.6ms/batch - loss: 0.34878 - diff: 27.90mlTrain batch 3/7 - 611.6ms/batch - loss: 0.30647 - diff: 24.52mlTrain batch 4/7 - 597.0ms/batch - loss: 0.30025 - diff: 24.02mlTrain batch 5/7 - 598.1ms/batch - loss: 0.30145 - diff: 24.12mlTrain batch 6/7 - 599.7ms/batch - loss: 0.29786 - diff: 23.83mlTrain batch 7/7 - 71.7ms/batch - loss: 0.39126 - diff: 24.17mlTrain batch 7/7 - 10.7s 71.7ms/batch - loss: 0.39126 - diff: 24.17ml
Test 1.0s: val_loss: 0.29613 - diff: 20.32ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Systole_VGG19_Adam-0.001_MAE_DA3_best

Epoch 125: current best loss = 0.29613, at epoch 124
Train batch 1/7 - 605.3ms/batch - loss: 0.35691 - diff: 28.55mlTrain batch 2/7 - 598.3ms/batch - loss: 0.36366 - diff: 29.09mlTrain batch 3/7 - 616.0ms/batch - loss: 0.32764 - diff: 26.21mlTrain batch 4/7 - 598.4ms/batch - loss: 0.32103 - diff: 25.68mlTrain batch 5/7 - 600.2ms/batch - loss: 0.30717 - diff: 24.57mlTrain batch 6/7 - 599.6ms/batch - loss: 0.29551 - diff: 23.64mlTrain batch 7/7 - 71.8ms/batch - loss: 0.37331 - diff: 23.88mlTrain batch 7/7 - 10.7s 71.8ms/batch - loss: 0.37331 - diff: 23.88ml
Test 1.0s: val_loss: 0.31022 - diff: 20.34ml

Epoch 126: current best loss = 0.29613, at epoch 124
Train batch 1/7 - 608.8ms/batch - loss: 0.25617 - diff: 20.49mlTrain batch 2/7 - 597.4ms/batch - loss: 0.27569 - diff: 22.06mlTrain batch 3/7 - 611.0ms/batch - loss: 0.26899 - diff: 21.52mlTrain batch 4/7 - 599.8ms/batch - loss: 0.27823 - diff: 22.26mlTrain batch 5/7 - 606.9ms/batch - loss: 0.27716 - diff: 22.17mlTrain batch 6/7 - 596.4ms/batch - loss: 0.29485 - diff: 23.59mlTrain batch 7/7 - 72.1ms/batch - loss: 0.36618 - diff: 23.78mlTrain batch 7/7 - 10.6s 72.1ms/batch - loss: 0.36618 - diff: 23.78ml
Test 1.0s: val_loss: 0.32845 - diff: 20.75ml

Epoch 127: current best loss = 0.29613, at epoch 124
Train batch 1/7 - 598.2ms/batch - loss: 0.22089 - diff: 17.67mlTrain batch 2/7 - 598.6ms/batch - loss: 0.26621 - diff: 21.30mlTrain batch 3/7 - 605.4ms/batch - loss: 0.26248 - diff: 21.00mlTrain batch 4/7 - 603.6ms/batch - loss: 0.27113 - diff: 21.69mlTrain batch 5/7 - 594.7ms/batch - loss: 0.28356 - diff: 22.68mlTrain batch 6/7 - 601.9ms/batch - loss: 0.29242 - diff: 23.39mlTrain batch 7/7 - 71.2ms/batch - loss: 0.33246 - diff: 23.37mlTrain batch 7/7 - 10.7s 71.2ms/batch - loss: 0.33246 - diff: 23.37ml
Test 1.1s: val_loss: 0.30994 - diff: 20.35ml

Epoch 128: current best loss = 0.29613, at epoch 124
Train batch 1/7 - 596.1ms/batch - loss: 0.33269 - diff: 26.62mlTrain batch 2/7 - 598.9ms/batch - loss: 0.33028 - diff: 26.42mlTrain batch 3/7 - 603.5ms/batch - loss: 0.31475 - diff: 25.18mlTrain batch 4/7 - 605.3ms/batch - loss: 0.30767 - diff: 24.61mlTrain batch 5/7 - 604.6ms/batch - loss: 0.30102 - diff: 24.08mlTrain batch 6/7 - 596.5ms/batch - loss: 0.30125 - diff: 24.10mlTrain batch 7/7 - 71.0ms/batch - loss: 0.36198 - diff: 24.21mlTrain batch 7/7 - 10.6s 71.0ms/batch - loss: 0.36198 - diff: 24.21ml
Test 1.0s: val_loss: 0.30615 - diff: 20.21ml

Epoch 129: current best loss = 0.29613, at epoch 124
Train batch 1/7 - 602.3ms/batch - loss: 0.29840 - diff: 23.87mlTrain batch 2/7 - 597.5ms/batch - loss: 0.28339 - diff: 22.67mlTrain batch 3/7 - 607.0ms/batch - loss: 0.29498 - diff: 23.60mlTrain batch 4/7 - 597.2ms/batch - loss: 0.30937 - diff: 24.75mlTrain batch 5/7 - 606.0ms/batch - loss: 0.29574 - diff: 23.66mlTrain batch 6/7 - 596.0ms/batch - loss: 0.29465 - diff: 23.57mlTrain batch 7/7 - 70.9ms/batch - loss: 0.34174 - diff: 23.59mlTrain batch 7/7 - 10.6s 70.9ms/batch - loss: 0.34174 - diff: 23.59ml
Test 1.0s: val_loss: 0.32876 - diff: 20.15ml

Epoch 130: current best loss = 0.29613, at epoch 124
Train batch 1/7 - 608.7ms/batch - loss: 0.30860 - diff: 24.69mlTrain batch 2/7 - 601.8ms/batch - loss: 0.27567 - diff: 22.05mlTrain batch 3/7 - 606.4ms/batch - loss: 0.30198 - diff: 24.16mlTrain batch 4/7 - 598.0ms/batch - loss: 0.29105 - diff: 23.28mlTrain batch 5/7 - 597.9ms/batch - loss: 0.30045 - diff: 24.04mlTrain batch 6/7 - 600.0ms/batch - loss: 0.29631 - diff: 23.70mlTrain batch 7/7 - 71.4ms/batch - loss: 0.32992 - diff: 23.63mlTrain batch 7/7 - 10.7s 71.4ms/batch - loss: 0.32992 - diff: 23.63ml
Test 1.0s: val_loss: 0.29582 - diff: 20.12ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Systole_VGG19_Adam-0.001_MAE_DA3_best

Epoch 131: current best loss = 0.29582, at epoch 130
Train batch 1/7 - 601.4ms/batch - loss: 0.29416 - diff: 23.53mlTrain batch 2/7 - 600.1ms/batch - loss: 0.28608 - diff: 22.89mlTrain batch 3/7 - 599.4ms/batch - loss: 0.28588 - diff: 22.87mlTrain batch 4/7 - 597.8ms/batch - loss: 0.30028 - diff: 24.02mlTrain batch 5/7 - 598.5ms/batch - loss: 0.29930 - diff: 23.94mlTrain batch 6/7 - 600.4ms/batch - loss: 0.29917 - diff: 23.93mlTrain batch 7/7 - 70.9ms/batch - loss: 0.32415 - diff: 23.79mlTrain batch 7/7 - 10.8s 70.9ms/batch - loss: 0.32415 - diff: 23.79ml
Test 1.0s: val_loss: 0.30529 - diff: 20.56ml

Epoch 132: current best loss = 0.29582, at epoch 130
Train batch 1/7 - 613.1ms/batch - loss: 0.30603 - diff: 24.48mlTrain batch 2/7 - 599.2ms/batch - loss: 0.30847 - diff: 24.68mlTrain batch 3/7 - 611.8ms/batch - loss: 0.30707 - diff: 24.57mlTrain batch 4/7 - 593.7ms/batch - loss: 0.29995 - diff: 24.00mlTrain batch 5/7 - 602.9ms/batch - loss: 0.31582 - diff: 25.27mlTrain batch 6/7 - 596.8ms/batch - loss: 0.30346 - diff: 24.28mlTrain batch 7/7 - 70.8ms/batch - loss: 0.33649 - diff: 24.19mlTrain batch 7/7 - 10.7s 70.8ms/batch - loss: 0.33649 - diff: 24.19ml
Test 1.0s: val_loss: 0.29914 - diff: 20.44ml

Epoch 133: current best loss = 0.29582, at epoch 130
Train batch 1/7 - 607.7ms/batch - loss: 0.30626 - diff: 24.50mlTrain batch 2/7 - 599.9ms/batch - loss: 0.33028 - diff: 26.42mlTrain batch 3/7 - 596.5ms/batch - loss: 0.32921 - diff: 26.34mlTrain batch 4/7 - 597.3ms/batch - loss: 0.31035 - diff: 24.83mlTrain batch 5/7 - 598.7ms/batch - loss: 0.29562 - diff: 23.65mlTrain batch 6/7 - 600.4ms/batch - loss: 0.30442 - diff: 24.35mlTrain batch 7/7 - 70.7ms/batch - loss: 0.32163 - diff: 24.15mlTrain batch 7/7 - 10.7s 70.7ms/batch - loss: 0.32163 - diff: 24.15ml
Test 1.0s: val_loss: 0.33617 - diff: 20.02ml

Epoch 134: current best loss = 0.29582, at epoch 130
Train batch 1/7 - 600.2ms/batch - loss: 0.30724 - diff: 24.58mlTrain batch 2/7 - 606.8ms/batch - loss: 0.28347 - diff: 22.68mlTrain batch 3/7 - 601.0ms/batch - loss: 0.28594 - diff: 22.88mlTrain batch 4/7 - 603.4ms/batch - loss: 0.29457 - diff: 23.57mlTrain batch 5/7 - 596.8ms/batch - loss: 0.30397 - diff: 24.32mlTrain batch 6/7 - 597.9ms/batch - loss: 0.30160 - diff: 24.13mlTrain batch 7/7 - 70.8ms/batch - loss: 0.34343 - diff: 24.10mlTrain batch 7/7 - 10.7s 70.8ms/batch - loss: 0.34343 - diff: 24.10ml
Test 1.0s: val_loss: 0.30976 - diff: 20.22ml

Epoch 135: current best loss = 0.29582, at epoch 130
Train batch 1/7 - 607.0ms/batch - loss: 0.29256 - diff: 23.40mlTrain batch 2/7 - 597.5ms/batch - loss: 0.27504 - diff: 22.00mlTrain batch 3/7 - 604.7ms/batch - loss: 0.30540 - diff: 24.43mlTrain batch 4/7 - 595.4ms/batch - loss: 0.30296 - diff: 24.24mlTrain batch 5/7 - 610.4ms/batch - loss: 0.29938 - diff: 23.95mlTrain batch 6/7 - 595.5ms/batch - loss: 0.29563 - diff: 23.65mlTrain batch 7/7 - 70.9ms/batch - loss: 0.33321 - diff: 23.60mlTrain batch 7/7 - 10.6s 70.9ms/batch - loss: 0.33321 - diff: 23.60ml
Test 1.0s: val_loss: 0.32646 - diff: 21.11ml

Epoch 136: current best loss = 0.29582, at epoch 130
Train batch 1/7 - 598.1ms/batch - loss: 0.31229 - diff: 24.98mlTrain batch 2/7 - 596.1ms/batch - loss: 0.29028 - diff: 23.22mlTrain batch 3/7 - 605.4ms/batch - loss: 0.28419 - diff: 22.73mlTrain batch 4/7 - 597.6ms/batch - loss: 0.29940 - diff: 23.95mlTrain batch 5/7 - 599.8ms/batch - loss: 0.30019 - diff: 24.01mlTrain batch 6/7 - 602.6ms/batch - loss: 0.29734 - diff: 23.79mlTrain batch 7/7 - 70.6ms/batch - loss: 0.35999 - diff: 23.91mlTrain batch 7/7 - 10.7s 70.6ms/batch - loss: 0.35999 - diff: 23.91ml
Test 1.0s: val_loss: 0.31560 - diff: 19.99ml

Epoch 137: current best loss = 0.29582, at epoch 130
Train batch 1/7 - 599.3ms/batch - loss: 0.24439 - diff: 19.55mlTrain batch 2/7 - 598.5ms/batch - loss: 0.26361 - diff: 21.09mlTrain batch 3/7 - 607.7ms/batch - loss: 0.28065 - diff: 22.45mlTrain batch 4/7 - 594.9ms/batch - loss: 0.29027 - diff: 23.22mlTrain batch 5/7 - 594.6ms/batch - loss: 0.29297 - diff: 23.44mlTrain batch 6/7 - 606.2ms/batch - loss: 0.29770 - diff: 23.82mlTrain batch 7/7 - 70.8ms/batch - loss: 0.37048 - diff: 24.01mlTrain batch 7/7 - 10.7s 70.8ms/batch - loss: 0.37048 - diff: 24.01ml
Test 1.0s: val_loss: 0.29742 - diff: 19.89ml

Epoch 138: current best loss = 0.29582, at epoch 130
Train batch 1/7 - 600.4ms/batch - loss: 0.30307 - diff: 24.25mlTrain batch 2/7 - 597.8ms/batch - loss: 0.32565 - diff: 26.05mlTrain batch 3/7 - 597.7ms/batch - loss: 0.31747 - diff: 25.40mlTrain batch 4/7 - 598.0ms/batch - loss: 0.31230 - diff: 24.98mlTrain batch 5/7 - 594.9ms/batch - loss: 0.30966 - diff: 24.77mlTrain batch 6/7 - 597.8ms/batch - loss: 0.30124 - diff: 24.10mlTrain batch 7/7 - 72.8ms/batch - loss: 0.31560 - diff: 23.88mlTrain batch 7/7 - 10.7s 72.8ms/batch - loss: 0.31560 - diff: 23.88ml
Test 1.0s: val_loss: 0.30527 - diff: 20.28ml

Epoch 139: current best loss = 0.29582, at epoch 130
Train batch 1/7 - 598.8ms/batch - loss: 0.28702 - diff: 22.96mlTrain batch 2/7 - 600.1ms/batch - loss: 0.28169 - diff: 22.54mlTrain batch 3/7 - 599.6ms/batch - loss: 0.28602 - diff: 22.88mlTrain batch 4/7 - 597.6ms/batch - loss: 0.30020 - diff: 24.02mlTrain batch 5/7 - 598.7ms/batch - loss: 0.29261 - diff: 23.41mlTrain batch 6/7 - 598.3ms/batch - loss: 0.29996 - diff: 24.00mlTrain batch 7/7 - 71.0ms/batch - loss: 0.30622 - diff: 23.73mlTrain batch 7/7 - 10.8s 71.0ms/batch - loss: 0.30622 - diff: 23.73ml
Test 1.2s: val_loss: 0.33551 - diff: 20.74ml

Epoch 140: current best loss = 0.29582, at epoch 130
Train batch 1/7 - 602.8ms/batch - loss: 0.27812 - diff: 22.25mlTrain batch 2/7 - 595.9ms/batch - loss: 0.27029 - diff: 21.62mlTrain batch 3/7 - 603.5ms/batch - loss: 0.31526 - diff: 25.22mlTrain batch 4/7 - 600.4ms/batch - loss: 0.30678 - diff: 24.54mlTrain batch 5/7 - 614.3ms/batch - loss: 0.29371 - diff: 23.50mlTrain batch 6/7 - 599.7ms/batch - loss: 0.29931 - diff: 23.94mlTrain batch 7/7 - 70.5ms/batch - loss: 0.34112 - diff: 23.92mlTrain batch 7/7 - 10.9s 70.5ms/batch - loss: 0.34112 - diff: 23.92ml
Test 1.1s: val_loss: 0.31754 - diff: 20.31ml

Epoch 141: current best loss = 0.29582, at epoch 130
Train batch 1/7 - 598.6ms/batch - loss: 0.25756 - diff: 20.60mlTrain batch 2/7 - 598.7ms/batch - loss: 0.26458 - diff: 21.17mlTrain batch 3/7 - 609.9ms/batch - loss: 0.29454 - diff: 23.56mlTrain batch 4/7 - 597.8ms/batch - loss: 0.28889 - diff: 23.11mlTrain batch 5/7 - 606.7ms/batch - loss: 0.29156 - diff: 23.32mlTrain batch 6/7 - 595.6ms/batch - loss: 0.29031 - diff: 23.22mlTrain batch 7/7 - 71.0ms/batch - loss: 0.37420 - diff: 23.51mlTrain batch 7/7 - 10.6s 71.0ms/batch - loss: 0.37420 - diff: 23.51ml
Test 1.0s: val_loss: 0.29829 - diff: 19.81ml
Epoch   142: reducing learning rate of group 0 to 7.8125e-06.

Epoch 142: current best loss = 0.29582, at epoch 130
Train batch 1/7 - 608.4ms/batch - loss: 0.29250 - diff: 23.40mlTrain batch 2/7 - 607.7ms/batch - loss: 0.30616 - diff: 24.49mlTrain batch 3/7 - 599.2ms/batch - loss: 0.29899 - diff: 23.92mlTrain batch 4/7 - 605.1ms/batch - loss: 0.29727 - diff: 23.78mlTrain batch 5/7 - 598.9ms/batch - loss: 0.29899 - diff: 23.92mlTrain batch 6/7 - 598.2ms/batch - loss: 0.29169 - diff: 23.34mlTrain batch 7/7 - 71.6ms/batch - loss: 0.37686 - diff: 23.63mlTrain batch 7/7 - 10.7s 71.6ms/batch - loss: 0.37686 - diff: 23.63ml
Test 1.0s: val_loss: 0.32553 - diff: 19.85ml

Epoch 143: current best loss = 0.29582, at epoch 130
Train batch 1/7 - 605.8ms/batch - loss: 0.35629 - diff: 28.50mlTrain batch 2/7 - 598.2ms/batch - loss: 0.33118 - diff: 26.49mlTrain batch 3/7 - 604.4ms/batch - loss: 0.29570 - diff: 23.66mlTrain batch 4/7 - 596.4ms/batch - loss: 0.29379 - diff: 23.50mlTrain batch 5/7 - 597.8ms/batch - loss: 0.29516 - diff: 23.61mlTrain batch 6/7 - 603.5ms/batch - loss: 0.29495 - diff: 23.60mlTrain batch 7/7 - 71.5ms/batch - loss: 0.33121 - diff: 23.54mlTrain batch 7/7 - 10.7s 71.5ms/batch - loss: 0.33121 - diff: 23.54ml
Test 1.0s: val_loss: 0.31152 - diff: 20.28ml

Epoch 144: current best loss = 0.29582, at epoch 130
Train batch 1/7 - 611.4ms/batch - loss: 0.31978 - diff: 25.58mlTrain batch 2/7 - 600.3ms/batch - loss: 0.28199 - diff: 22.56mlTrain batch 3/7 - 608.0ms/batch - loss: 0.30287 - diff: 24.23mlTrain batch 4/7 - 596.2ms/batch - loss: 0.29730 - diff: 23.78mlTrain batch 5/7 - 603.0ms/batch - loss: 0.29552 - diff: 23.64mlTrain batch 6/7 - 595.1ms/batch - loss: 0.29419 - diff: 23.53mlTrain batch 7/7 - 71.4ms/batch - loss: 0.33428 - diff: 23.51mlTrain batch 7/7 - 10.6s 71.4ms/batch - loss: 0.33428 - diff: 23.51ml
Test 1.0s: val_loss: 0.31235 - diff: 19.85ml

Epoch 145: current best loss = 0.29582, at epoch 130
Train batch 1/7 - 608.0ms/batch - loss: 0.26600 - diff: 21.28mlTrain batch 2/7 - 597.5ms/batch - loss: 0.27520 - diff: 22.02mlTrain batch 3/7 - 605.7ms/batch - loss: 0.27914 - diff: 22.33mlTrain batch 4/7 - 599.3ms/batch - loss: 0.28700 - diff: 22.96mlTrain batch 5/7 - 608.1ms/batch - loss: 0.28956 - diff: 23.16mlTrain batch 6/7 - 596.6ms/batch - loss: 0.30073 - diff: 24.06mlTrain batch 7/7 - 71.5ms/batch - loss: 0.34189 - diff: 24.03mlTrain batch 7/7 - 10.6s 71.5ms/batch - loss: 0.34189 - diff: 24.03ml
Test 1.1s: val_loss: 0.30000 - diff: 19.77ml

Epoch 146: current best loss = 0.29582, at epoch 130
Train batch 1/7 - 612.7ms/batch - loss: 0.27844 - diff: 22.28mlTrain batch 2/7 - 599.6ms/batch - loss: 0.30668 - diff: 24.53mlTrain batch 3/7 - 600.9ms/batch - loss: 0.32821 - diff: 26.26mlTrain batch 4/7 - 600.7ms/batch - loss: 0.30977 - diff: 24.78mlTrain batch 5/7 - 605.5ms/batch - loss: 0.29946 - diff: 23.96mlTrain batch 6/7 - 594.0ms/batch - loss: 0.29414 - diff: 23.53mlTrain batch 7/7 - 71.5ms/batch - loss: 0.35667 - diff: 23.66mlTrain batch 7/7 - 10.6s 71.5ms/batch - loss: 0.35667 - diff: 23.66ml
Test 1.0s: val_loss: 0.31283 - diff: 19.95ml

Epoch 147: current best loss = 0.29582, at epoch 130
Train batch 1/7 - 604.9ms/batch - loss: 0.28941 - diff: 23.15mlTrain batch 2/7 - 597.0ms/batch - loss: 0.27736 - diff: 22.19mlTrain batch 3/7 - 599.1ms/batch - loss: 0.29168 - diff: 23.33mlTrain batch 4/7 - 597.8ms/batch - loss: 0.29418 - diff: 23.53mlTrain batch 5/7 - 595.5ms/batch - loss: 0.30141 - diff: 24.11mlTrain batch 6/7 - 600.4ms/batch - loss: 0.30004 - diff: 24.00mlTrain batch 7/7 - 70.7ms/batch - loss: 0.34814 - diff: 24.02mlTrain batch 7/7 - 10.7s 70.7ms/batch - loss: 0.34814 - diff: 24.02ml
Test 1.0s: val_loss: 0.29604 - diff: 20.02ml

Epoch 148: current best loss = 0.29582, at epoch 130
Train batch 1/7 - 596.0ms/batch - loss: 0.27402 - diff: 21.92mlTrain batch 2/7 - 597.6ms/batch - loss: 0.34749 - diff: 27.80mlTrain batch 3/7 - 602.1ms/batch - loss: 0.32152 - diff: 25.72mlTrain batch 4/7 - 597.0ms/batch - loss: 0.31884 - diff: 25.51mlTrain batch 5/7 - 596.3ms/batch - loss: 0.30536 - diff: 24.43mlTrain batch 6/7 - 600.8ms/batch - loss: 0.29710 - diff: 23.77mlTrain batch 7/7 - 71.5ms/batch - loss: 0.33829 - diff: 23.74mlTrain batch 7/7 - 10.7s 71.5ms/batch - loss: 0.33829 - diff: 23.74ml
Test 1.0s: val_loss: 0.30981 - diff: 20.06ml

Epoch 149: current best loss = 0.29582, at epoch 130
Train batch 1/7 - 607.3ms/batch - loss: 0.26718 - diff: 21.37mlTrain batch 2/7 - 602.2ms/batch - loss: 0.31112 - diff: 24.89mlTrain batch 3/7 - 613.6ms/batch - loss: 0.30715 - diff: 24.57mlTrain batch 4/7 - 597.6ms/batch - loss: 0.29843 - diff: 23.87mlTrain batch 5/7 - 608.8ms/batch - loss: 0.29295 - diff: 23.44mlTrain batch 6/7 - 598.2ms/batch - loss: 0.29655 - diff: 23.72mlTrain batch 7/7 - 70.7ms/batch - loss: 0.32459 - diff: 23.61mlTrain batch 7/7 - 10.6s 70.7ms/batch - loss: 0.32459 - diff: 23.61ml
Test 1.0s: val_loss: 0.30335 - diff: 20.01ml

