nohup: ignoring input
Running experiment 4CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_VGG19_Adam-0.001_MSE_DA3
Going to train with the GPU in the slot 1 -> device model: GeForce RTX 2080
Model architecture:
 VGG19(
  (first_conv): Sequential(
    (0): Conv2d(30, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU()
    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (pretrained_block): Sequential(
    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU(inplace=True)
    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): ReLU(inplace=True)
    (5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (6): ReLU(inplace=True)
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (9): ReLU(inplace=True)
    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): ReLU(inplace=True)
    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (13): ReLU(inplace=True)
    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (15): ReLU(inplace=True)
    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (18): ReLU(inplace=True)
    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (20): ReLU(inplace=True)
    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (22): ReLU(inplace=True)
    (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (24): ReLU(inplace=True)
    (25): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (27): ReLU(inplace=True)
    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (29): ReLU(inplace=True)
    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (31): ReLU(inplace=True)
    (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (33): ReLU(inplace=True)
    (34): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (reduction_block): Sequential(
    (0): AdaptiveAvgPool2d(output_size=(1, 1))
    (1): Flatten()
  )
  (dense_block): Sequential(
    (0): Linear(in_features=512, out_features=512, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.4, inplace=False)
    (3): Linear(in_features=512, out_features=1, bias=True)
  )
) 


############################
# TRAIN PHASE:  150 epochs #
############################

Epoch 0: 
Train batch 1/16 - 144.0ms/batch - loss: 869.76257 - diff: 157.56mlTrain batch 2/16 - 128.5ms/batch - loss: 941.49377 - diff: 164.71mlTrain batch 3/16 - 141.2ms/batch - loss: 940.05493 - diff: 165.76mlTrain batch 4/16 - 151.6ms/batch - loss: 911.61319 - diff: 161.56mlTrain batch 5/16 - 114.9ms/batch - loss: 905.04641 - diff: 161.45mlTrain batch 6/16 - 115.1ms/batch - loss: 918.70759 - diff: 161.97mlTrain batch 7/16 - 128.1ms/batch - loss: 899.63169 - diff: 160.00mlTrain batch 8/16 - 121.6ms/batch - loss: 919.90540 - diff: 162.02mlTrain batch 9/16 - 128.7ms/batch - loss: 889.69863 - diff: 159.05mlTrain batch 10/16 - 128.4ms/batch - loss: 878.48553 - diff: 158.47mlTrain batch 11/16 - 128.7ms/batch - loss: 860.80691 - diff: 156.39mlTrain batch 12/16 - 117.6ms/batch - loss: 865.22144 - diff: 155.94mlTrain batch 13/16 - 128.7ms/batch - loss: 858.65757 - diff: 155.29mlTrain batch 14/16 - 127.1ms/batch - loss: 842.99170 - diff: 153.50mlTrain batch 15/16 - 128.7ms/batch - loss: 825.28414 - diff: 151.48mlTrain batch 16/16 - 44.3ms/batch - loss: 847.97501 - diff: 150.92mlTrain batch 16/16 - 33.8s 44.3ms/batch - loss: 847.97501 - diff: 150.92ml
Test 8.3s: val_loss: 879.99574 - diff: 149.32ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_VGG19_Adam-0.001_MSE_DA3_best

Epoch 1: current best loss = 879.99574, at epoch 0
Train batch 1/16 - 128.2ms/batch - loss: 547.80310 - diff: 123.94mlTrain batch 2/16 - 124.3ms/batch - loss: 481.30132 - diff: 111.58mlTrain batch 3/16 - 115.0ms/batch - loss: 458.87950 - diff: 110.22mlTrain batch 4/16 - 121.8ms/batch - loss: 451.61384 - diff: 108.33mlTrain batch 5/16 - 118.5ms/batch - loss: 414.02484 - diff: 102.94mlTrain batch 6/16 - 128.7ms/batch - loss: 403.40329 - diff: 100.64mlTrain batch 7/16 - 127.2ms/batch - loss: 414.49834 - diff: 99.69mlTrain batch 8/16 - 115.0ms/batch - loss: 385.72926 - diff: 94.85mlTrain batch 9/16 - 120.9ms/batch - loss: 360.17140 - diff: 90.75mlTrain batch 10/16 - 124.7ms/batch - loss: 345.27085 - diff: 88.31mlTrain batch 11/16 - 115.4ms/batch - loss: 333.58889 - diff: 85.07mlTrain batch 12/16 - 115.5ms/batch - loss: 318.30254 - diff: 82.18mlTrain batch 13/16 - 116.4ms/batch - loss: 306.62976 - diff: 79.81mlTrain batch 14/16 - 115.6ms/batch - loss: 292.88453 - diff: 77.64mlTrain batch 15/16 - 123.1ms/batch - loss: 278.65996 - diff: 75.08mlTrain batch 16/16 - 44.7ms/batch - loss: 279.62647 - diff: 74.56mlTrain batch 16/16 - 15.0s 44.7ms/batch - loss: 279.62647 - diff: 74.56ml
Test 1.2s: val_loss: 612.98853 - diff: 123.14ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_VGG19_Adam-0.001_MSE_DA3_best

Epoch 2: current best loss = 612.98853, at epoch 1
Train batch 1/16 - 127.5ms/batch - loss: 139.27594 - diff: 48.47mlTrain batch 2/16 - 115.4ms/batch - loss: 103.14716 - diff: 43.02mlTrain batch 3/16 - 115.4ms/batch - loss: 136.58098 - diff: 44.05mlTrain batch 4/16 - 116.0ms/batch - loss: 140.02881 - diff: 46.02mlTrain batch 5/16 - 115.6ms/batch - loss: 128.07580 - diff: 44.57mlTrain batch 6/16 - 115.6ms/batch - loss: 130.03637 - diff: 45.34mlTrain batch 7/16 - 115.5ms/batch - loss: 126.04820 - diff: 44.87mlTrain batch 8/16 - 115.4ms/batch - loss: 125.52727 - diff: 44.61mlTrain batch 9/16 - 115.5ms/batch - loss: 130.50909 - diff: 46.06mlTrain batch 10/16 - 115.4ms/batch - loss: 127.82468 - diff: 46.20mlTrain batch 11/16 - 115.8ms/batch - loss: 123.18446 - diff: 45.60mlTrain batch 12/16 - 122.0ms/batch - loss: 124.70786 - diff: 45.67mlTrain batch 13/16 - 121.9ms/batch - loss: 122.75577 - diff: 45.43mlTrain batch 14/16 - 115.5ms/batch - loss: 123.58217 - diff: 46.18mlTrain batch 15/16 - 115.4ms/batch - loss: 129.49656 - diff: 47.14mlTrain batch 16/16 - 39.1ms/batch - loss: 130.19109 - diff: 46.91mlTrain batch 16/16 - 16.2s 39.1ms/batch - loss: 130.19109 - diff: 46.91ml
Test 1.1s: val_loss: 436.09220 - diff: 98.47ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_VGG19_Adam-0.001_MSE_DA3_best

Epoch 3: current best loss = 436.09220, at epoch 2
Train batch 1/16 - 128.8ms/batch - loss: 144.19339 - diff: 53.83mlTrain batch 2/16 - 128.2ms/batch - loss: 154.79291 - diff: 55.81mlTrain batch 3/16 - 115.6ms/batch - loss: 134.62366 - diff: 49.86mlTrain batch 4/16 - 115.7ms/batch - loss: 147.02757 - diff: 50.34mlTrain batch 5/16 - 115.5ms/batch - loss: 144.02781 - diff: 50.17mlTrain batch 6/16 - 115.7ms/batch - loss: 136.15795 - diff: 49.51mlTrain batch 7/16 - 124.6ms/batch - loss: 150.67830 - diff: 49.81mlTrain batch 8/16 - 115.5ms/batch - loss: 145.05089 - diff: 49.11mlTrain batch 9/16 - 115.6ms/batch - loss: 139.53310 - diff: 48.71mlTrain batch 10/16 - 129.0ms/batch - loss: 136.89874 - diff: 48.49mlTrain batch 11/16 - 120.7ms/batch - loss: 131.09778 - diff: 47.54mlTrain batch 12/16 - 131.4ms/batch - loss: 128.72206 - diff: 47.49mlTrain batch 13/16 - 138.7ms/batch - loss: 131.73027 - diff: 47.96mlTrain batch 14/16 - 119.0ms/batch - loss: 128.73219 - diff: 47.63mlTrain batch 15/16 - 115.4ms/batch - loss: 125.89543 - diff: 47.27mlTrain batch 16/16 - 39.0ms/batch - loss: 128.63087 - diff: 47.12mlTrain batch 16/16 - 14.8s 39.0ms/batch - loss: 128.63087 - diff: 47.12ml
Test 1.1s: val_loss: 371.67703 - diff: 88.35ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_VGG19_Adam-0.001_MSE_DA3_best

Epoch 4: current best loss = 371.67703, at epoch 3
Train batch 1/16 - 128.8ms/batch - loss: 86.44191 - diff: 40.56mlTrain batch 2/16 - 127.4ms/batch - loss: 83.41069 - diff: 41.51mlTrain batch 3/16 - 129.5ms/batch - loss: 75.26353 - diff: 39.04mlTrain batch 4/16 - 120.9ms/batch - loss: 90.94612 - diff: 42.64mlTrain batch 5/16 - 115.5ms/batch - loss: 84.75922 - diff: 41.38mlTrain batch 6/16 - 115.5ms/batch - loss: 90.90082 - diff: 42.76mlTrain batch 7/16 - 121.7ms/batch - loss: 89.83477 - diff: 42.14mlTrain batch 8/16 - 115.6ms/batch - loss: 88.14409 - diff: 41.60mlTrain batch 9/16 - 115.6ms/batch - loss: 99.65134 - diff: 43.53mlTrain batch 10/16 - 115.7ms/batch - loss: 100.03329 - diff: 43.58mlTrain batch 11/16 - 119.9ms/batch - loss: 113.26417 - diff: 44.35mlTrain batch 12/16 - 115.9ms/batch - loss: 116.17728 - diff: 45.10mlTrain batch 13/16 - 116.1ms/batch - loss: 113.25458 - diff: 44.74mlTrain batch 14/16 - 123.9ms/batch - loss: 115.44467 - diff: 45.26mlTrain batch 15/16 - 129.4ms/batch - loss: 112.16517 - diff: 44.61mlTrain batch 16/16 - 45.0ms/batch - loss: 118.92456 - diff: 44.70mlTrain batch 16/16 - 15.1s 45.0ms/batch - loss: 118.92456 - diff: 44.70ml
Test 1.0s: val_loss: 223.20875 - diff: 57.17ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_VGG19_Adam-0.001_MSE_DA3_best

Epoch 5: current best loss = 223.20875, at epoch 4
Train batch 1/16 - 128.8ms/batch - loss: 45.29646 - diff: 31.05mlTrain batch 2/16 - 130.2ms/batch - loss: 64.39576 - diff: 34.72mlTrain batch 3/16 - 129.0ms/batch - loss: 66.65162 - diff: 35.92mlTrain batch 4/16 - 115.8ms/batch - loss: 63.59118 - diff: 35.47mlTrain batch 5/16 - 115.9ms/batch - loss: 82.75481 - diff: 39.64mlTrain batch 6/16 - 120.9ms/batch - loss: 91.30864 - diff: 41.06mlTrain batch 7/16 - 128.1ms/batch - loss: 96.92842 - diff: 42.26mlTrain batch 8/16 - 123.2ms/batch - loss: 109.98610 - diff: 44.10mlTrain batch 9/16 - 127.6ms/batch - loss: 106.79301 - diff: 43.83mlTrain batch 10/16 - 115.9ms/batch - loss: 116.84062 - diff: 44.13mlTrain batch 11/16 - 115.9ms/batch - loss: 115.80232 - diff: 44.32mlTrain batch 12/16 - 118.5ms/batch - loss: 114.19934 - diff: 44.42mlTrain batch 13/16 - 122.8ms/batch - loss: 111.05716 - diff: 43.82mlTrain batch 14/16 - 127.0ms/batch - loss: 109.41176 - diff: 43.67mlTrain batch 15/16 - 116.0ms/batch - loss: 107.23969 - diff: 43.31mlTrain batch 16/16 - 39.0ms/batch - loss: 108.16366 - diff: 43.04mlTrain batch 16/16 - 16.0s 39.0ms/batch - loss: 108.16366 - diff: 43.04ml
Test 1.2s: val_loss: 345.16779 - diff: 84.15ml

Epoch 6: current best loss = 223.20875, at epoch 4
Train batch 1/16 - 128.6ms/batch - loss: 113.89336 - diff: 44.54mlTrain batch 2/16 - 149.4ms/batch - loss: 125.14373 - diff: 44.44mlTrain batch 3/16 - 115.9ms/batch - loss: 136.06660 - diff: 46.25mlTrain batch 4/16 - 119.2ms/batch - loss: 118.95471 - diff: 44.02mlTrain batch 5/16 - 116.2ms/batch - loss: 109.90403 - diff: 42.46mlTrain batch 6/16 - 125.8ms/batch - loss: 107.53752 - diff: 43.09mlTrain batch 7/16 - 122.3ms/batch - loss: 104.59568 - diff: 42.82mlTrain batch 8/16 - 117.7ms/batch - loss: 103.14775 - diff: 42.96mlTrain batch 9/16 - 116.1ms/batch - loss: 107.19978 - diff: 43.90mlTrain batch 10/16 - 125.6ms/batch - loss: 103.26294 - diff: 43.28mlTrain batch 11/16 - 132.0ms/batch - loss: 98.30068 - diff: 42.13mlTrain batch 12/16 - 115.9ms/batch - loss: 101.53379 - diff: 42.68mlTrain batch 13/16 - 116.0ms/batch - loss: 112.61704 - diff: 43.51mlTrain batch 14/16 - 120.3ms/batch - loss: 108.84137 - diff: 42.90mlTrain batch 15/16 - 116.1ms/batch - loss: 106.44761 - diff: 42.29mlTrain batch 16/16 - 45.3ms/batch - loss: 109.46652 - diff: 42.32mlTrain batch 16/16 - 14.7s 45.3ms/batch - loss: 109.46652 - diff: 42.32ml
Test 1.1s: val_loss: 283.30311 - diff: 70.30ml

Epoch 7: current best loss = 223.20875, at epoch 4
Train batch 1/16 - 127.1ms/batch - loss: 148.07413 - diff: 52.05mlTrain batch 2/16 - 116.6ms/batch - loss: 116.54709 - diff: 46.04mlTrain batch 3/16 - 120.4ms/batch - loss: 106.46810 - diff: 44.63mlTrain batch 4/16 - 123.0ms/batch - loss: 93.82144 - diff: 41.62mlTrain batch 5/16 - 116.0ms/batch - loss: 95.88630 - diff: 41.47mlTrain batch 6/16 - 132.8ms/batch - loss: 112.62173 - diff: 43.98mlTrain batch 7/16 - 123.9ms/batch - loss: 131.27089 - diff: 45.29mlTrain batch 8/16 - 124.1ms/batch - loss: 124.46852 - diff: 44.55mlTrain batch 9/16 - 129.2ms/batch - loss: 118.60719 - diff: 43.42mlTrain batch 10/16 - 116.2ms/batch - loss: 111.45341 - diff: 42.25mlTrain batch 11/16 - 116.1ms/batch - loss: 105.37054 - diff: 41.01mlTrain batch 12/16 - 116.1ms/batch - loss: 104.41371 - diff: 41.43mlTrain batch 13/16 - 121.8ms/batch - loss: 101.08249 - diff: 40.96mlTrain batch 14/16 - 121.3ms/batch - loss: 101.05148 - diff: 41.43mlTrain batch 15/16 - 116.0ms/batch - loss: 102.36301 - diff: 41.67mlTrain batch 16/16 - 40.4ms/batch - loss: 109.45256 - diff: 41.91mlTrain batch 16/16 - 16.7s 40.4ms/batch - loss: 109.45256 - diff: 41.91ml
Test 1.1s: val_loss: 114.57225 - diff: 45.05ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_VGG19_Adam-0.001_MSE_DA3_best

Epoch 8: current best loss = 114.57225, at epoch 7
Train batch 1/16 - 129.1ms/batch - loss: 102.85095 - diff: 40.45mlTrain batch 2/16 - 146.6ms/batch - loss: 102.85424 - diff: 42.40mlTrain batch 3/16 - 115.9ms/batch - loss: 97.99293 - diff: 43.30mlTrain batch 4/16 - 124.2ms/batch - loss: 90.51284 - diff: 42.27mlTrain batch 5/16 - 129.1ms/batch - loss: 102.27617 - diff: 42.82mlTrain batch 6/16 - 125.7ms/batch - loss: 100.62878 - diff: 42.96mlTrain batch 7/16 - 116.1ms/batch - loss: 117.11527 - diff: 44.81mlTrain batch 8/16 - 123.1ms/batch - loss: 111.16241 - diff: 43.75mlTrain batch 9/16 - 129.7ms/batch - loss: 113.22918 - diff: 44.28mlTrain batch 10/16 - 124.1ms/batch - loss: 113.45612 - diff: 44.64mlTrain batch 11/16 - 129.0ms/batch - loss: 111.16982 - diff: 44.09mlTrain batch 12/16 - 119.8ms/batch - loss: 109.00054 - diff: 43.93mlTrain batch 13/16 - 116.1ms/batch - loss: 107.74752 - diff: 43.53mlTrain batch 14/16 - 116.3ms/batch - loss: 105.83003 - diff: 43.33mlTrain batch 15/16 - 116.0ms/batch - loss: 104.66488 - diff: 43.38mlTrain batch 16/16 - 39.3ms/batch - loss: 105.79449 - diff: 43.21mlTrain batch 16/16 - 17.4s 39.3ms/batch - loss: 105.79449 - diff: 43.21ml
Test 1.2s: val_loss: 151.64238 - diff: 54.02ml

Epoch 9: current best loss = 114.57225, at epoch 7
Train batch 1/16 - 130.7ms/batch - loss: 111.65382 - diff: 49.38mlTrain batch 2/16 - 126.9ms/batch - loss: 99.65471 - diff: 43.89mlTrain batch 3/16 - 128.7ms/batch - loss: 127.28584 - diff: 47.27mlTrain batch 4/16 - 126.9ms/batch - loss: 116.76019 - diff: 45.25mlTrain batch 5/16 - 130.2ms/batch - loss: 114.37663 - diff: 45.28mlTrain batch 6/16 - 116.2ms/batch - loss: 106.27091 - diff: 43.52mlTrain batch 7/16 - 120.2ms/batch - loss: 106.14313 - diff: 43.94mlTrain batch 8/16 - 115.0ms/batch - loss: 101.09304 - diff: 42.70mlTrain batch 9/16 - 115.9ms/batch - loss: 97.36416 - diff: 42.06mlTrain batch 10/16 - 126.7ms/batch - loss: 97.74826 - diff: 42.52mlTrain batch 11/16 - 122.8ms/batch - loss: 99.88086 - diff: 42.94mlTrain batch 12/16 - 119.9ms/batch - loss: 100.95293 - diff: 43.07mlTrain batch 13/16 - 152.0ms/batch - loss: 106.98849 - diff: 43.74mlTrain batch 14/16 - 130.5ms/batch - loss: 103.37624 - diff: 42.91mlTrain batch 15/16 - 115.9ms/batch - loss: 102.29510 - diff: 42.88mlTrain batch 16/16 - 39.1ms/batch - loss: 105.02117 - diff: 42.78mlTrain batch 16/16 - 16.0s 39.1ms/batch - loss: 105.02117 - diff: 42.78ml
Test 1.0s: val_loss: 231.65746 - diff: 57.49ml

Epoch 10: current best loss = 114.57225, at epoch 7
Train batch 1/16 - 131.3ms/batch - loss: 88.09804 - diff: 45.32mlTrain batch 2/16 - 116.5ms/batch - loss: 100.45705 - diff: 45.18mlTrain batch 3/16 - 122.2ms/batch - loss: 95.07770 - diff: 43.67mlTrain batch 4/16 - 124.4ms/batch - loss: 132.32101 - diff: 49.09mlTrain batch 5/16 - 129.7ms/batch - loss: 118.42478 - diff: 45.42mlTrain batch 6/16 - 116.1ms/batch - loss: 114.43937 - diff: 44.41mlTrain batch 7/16 - 129.5ms/batch - loss: 114.50156 - diff: 44.34mlTrain batch 8/16 - 133.0ms/batch - loss: 112.27047 - diff: 44.31mlTrain batch 9/16 - 133.5ms/batch - loss: 111.11225 - diff: 44.49mlTrain batch 10/16 - 116.8ms/batch - loss: 109.19876 - diff: 44.30mlTrain batch 11/16 - 114.4ms/batch - loss: 107.11818 - diff: 44.03mlTrain batch 12/16 - 140.2ms/batch - loss: 116.98345 - diff: 44.88mlTrain batch 13/16 - 116.2ms/batch - loss: 115.93834 - diff: 45.31mlTrain batch 14/16 - 123.2ms/batch - loss: 111.77874 - diff: 44.68mlTrain batch 15/16 - 117.1ms/batch - loss: 107.24702 - diff: 43.86mlTrain batch 16/16 - 41.1ms/batch - loss: 112.97949 - diff: 43.95mlTrain batch 16/16 - 17.2s 41.1ms/batch - loss: 112.97949 - diff: 43.95ml
Test 1.0s: val_loss: 210.38766 - diff: 63.08ml

Epoch 11: current best loss = 114.57225, at epoch 7
Train batch 1/16 - 136.9ms/batch - loss: 107.50956 - diff: 44.51mlTrain batch 2/16 - 119.4ms/batch - loss: 82.25732 - diff: 39.34mlTrain batch 3/16 - 127.3ms/batch - loss: 88.07409 - diff: 40.36mlTrain batch 4/16 - 120.1ms/batch - loss: 85.55691 - diff: 40.62mlTrain batch 5/16 - 129.4ms/batch - loss: 93.69381 - diff: 42.62mlTrain batch 6/16 - 116.3ms/batch - loss: 94.28782 - diff: 42.25mlTrain batch 7/16 - 116.4ms/batch - loss: 112.55828 - diff: 43.82mlTrain batch 8/16 - 124.0ms/batch - loss: 110.13896 - diff: 43.40mlTrain batch 9/16 - 116.3ms/batch - loss: 102.98793 - diff: 42.11mlTrain batch 10/16 - 124.8ms/batch - loss: 100.28439 - diff: 41.84mlTrain batch 11/16 - 120.9ms/batch - loss: 106.84593 - diff: 42.80mlTrain batch 12/16 - 116.3ms/batch - loss: 105.31445 - diff: 42.71mlTrain batch 13/16 - 116.0ms/batch - loss: 105.96915 - diff: 43.12mlTrain batch 14/16 - 121.9ms/batch - loss: 105.10890 - diff: 43.29mlTrain batch 15/16 - 116.0ms/batch - loss: 104.21742 - diff: 43.17mlTrain batch 16/16 - 39.3ms/batch - loss: 109.47847 - diff: 43.24mlTrain batch 16/16 - 17.0s 39.3ms/batch - loss: 109.47847 - diff: 43.24ml
Test 1.1s: val_loss: 180.93836 - diff: 53.58ml

Epoch 12: current best loss = 114.57225, at epoch 7
Train batch 1/16 - 129.7ms/batch - loss: 52.87344 - diff: 32.93mlTrain batch 2/16 - 127.8ms/batch - loss: 65.76431 - diff: 34.85mlTrain batch 3/16 - 145.1ms/batch - loss: 78.11708 - diff: 38.25mlTrain batch 4/16 - 127.8ms/batch - loss: 90.78696 - diff: 39.01mlTrain batch 5/16 - 116.4ms/batch - loss: 99.36125 - diff: 41.19mlTrain batch 6/16 - 115.9ms/batch - loss: 93.12376 - diff: 40.36mlTrain batch 7/16 - 129.6ms/batch - loss: 87.71363 - diff: 39.53mlTrain batch 8/16 - 116.0ms/batch - loss: 88.76631 - diff: 39.77mlTrain batch 9/16 - 130.5ms/batch - loss: 88.73473 - diff: 40.00mlTrain batch 10/16 - 124.3ms/batch - loss: 91.07224 - diff: 40.56mlTrain batch 11/16 - 116.1ms/batch - loss: 91.52948 - diff: 40.89mlTrain batch 12/16 - 129.0ms/batch - loss: 89.59429 - diff: 40.65mlTrain batch 13/16 - 115.8ms/batch - loss: 89.64617 - diff: 40.65mlTrain batch 14/16 - 116.1ms/batch - loss: 95.69229 - diff: 41.21mlTrain batch 15/16 - 115.9ms/batch - loss: 93.09432 - diff: 40.79mlTrain batch 16/16 - 39.2ms/batch - loss: 95.80474 - diff: 40.76mlTrain batch 16/16 - 16.1s 39.2ms/batch - loss: 95.80474 - diff: 40.76ml
Test 1.1s: val_loss: 210.25534 - diff: 66.32ml

Epoch 13: current best loss = 114.57225, at epoch 7
Train batch 1/16 - 128.8ms/batch - loss: 103.15480 - diff: 46.12mlTrain batch 2/16 - 116.0ms/batch - loss: 87.64486 - diff: 40.28mlTrain batch 3/16 - 116.7ms/batch - loss: 134.04595 - diff: 44.28mlTrain batch 4/16 - 118.9ms/batch - loss: 117.58329 - diff: 43.18mlTrain batch 5/16 - 126.1ms/batch - loss: 112.53398 - diff: 43.51mlTrain batch 6/16 - 123.0ms/batch - loss: 104.19079 - diff: 41.75mlTrain batch 7/16 - 166.3ms/batch - loss: 100.33942 - diff: 41.57mlTrain batch 8/16 - 116.2ms/batch - loss: 96.96887 - diff: 41.04mlTrain batch 9/16 - 144.0ms/batch - loss: 103.77594 - diff: 41.87mlTrain batch 10/16 - 116.2ms/batch - loss: 105.69974 - diff: 42.35mlTrain batch 11/16 - 133.7ms/batch - loss: 101.91245 - diff: 41.83mlTrain batch 12/16 - 128.1ms/batch - loss: 99.86484 - diff: 41.63mlTrain batch 13/16 - 130.3ms/batch - loss: 98.38774 - diff: 41.48mlTrain batch 14/16 - 128.3ms/batch - loss: 96.60228 - diff: 41.23mlTrain batch 15/16 - 115.9ms/batch - loss: 98.42107 - diff: 41.56mlTrain batch 16/16 - 39.2ms/batch - loss: 100.14670 - diff: 41.46mlTrain batch 16/16 - 16.9s 39.2ms/batch - loss: 100.14670 - diff: 41.46ml
Test 1.1s: val_loss: 147.74651 - diff: 47.44ml

Epoch 14: current best loss = 114.57225, at epoch 7
Train batch 1/16 - 128.7ms/batch - loss: 104.46240 - diff: 45.32mlTrain batch 2/16 - 118.0ms/batch - loss: 135.67689 - diff: 48.68mlTrain batch 3/16 - 130.3ms/batch - loss: 109.93714 - diff: 43.83mlTrain batch 4/16 - 116.4ms/batch - loss: 103.17099 - diff: 43.64mlTrain batch 5/16 - 129.3ms/batch - loss: 96.84091 - diff: 42.74mlTrain batch 6/16 - 117.7ms/batch - loss: 95.57197 - diff: 42.65mlTrain batch 7/16 - 128.2ms/batch - loss: 95.05484 - diff: 42.18mlTrain batch 8/16 - 131.4ms/batch - loss: 91.41122 - diff: 41.13mlTrain batch 9/16 - 119.6ms/batch - loss: 104.48113 - diff: 42.24mlTrain batch 10/16 - 116.2ms/batch - loss: 103.58764 - diff: 42.31mlTrain batch 11/16 - 116.2ms/batch - loss: 97.20966 - diff: 40.82mlTrain batch 12/16 - 121.8ms/batch - loss: 94.13564 - diff: 40.14mlTrain batch 13/16 - 115.8ms/batch - loss: 92.12590 - diff: 39.93mlTrain batch 14/16 - 123.6ms/batch - loss: 89.58255 - diff: 39.49mlTrain batch 15/16 - 116.2ms/batch - loss: 91.09125 - diff: 39.84mlTrain batch 16/16 - 39.2ms/batch - loss: 93.83849 - diff: 39.81mlTrain batch 16/16 - 16.5s 39.2ms/batch - loss: 93.83849 - diff: 39.81ml
Test 1.1s: val_loss: 151.35926 - diff: 48.90ml

Epoch 15: current best loss = 114.57225, at epoch 7
Train batch 1/16 - 128.2ms/batch - loss: 91.51918 - diff: 39.77mlTrain batch 2/16 - 130.7ms/batch - loss: 76.48516 - diff: 35.71mlTrain batch 3/16 - 116.3ms/batch - loss: 77.94052 - diff: 36.25mlTrain batch 4/16 - 116.7ms/batch - loss: 105.53573 - diff: 39.59mlTrain batch 5/16 - 135.1ms/batch - loss: 105.93440 - diff: 41.07mlTrain batch 6/16 - 126.7ms/batch - loss: 103.08011 - diff: 41.71mlTrain batch 7/16 - 128.9ms/batch - loss: 113.07067 - diff: 43.41mlTrain batch 8/16 - 128.8ms/batch - loss: 108.32374 - diff: 42.68mlTrain batch 9/16 - 133.2ms/batch - loss: 107.29176 - diff: 43.04mlTrain batch 10/16 - 116.5ms/batch - loss: 102.73951 - diff: 42.48mlTrain batch 11/16 - 132.3ms/batch - loss: 100.66556 - diff: 41.73mlTrain batch 12/16 - 116.5ms/batch - loss: 99.03228 - diff: 41.66mlTrain batch 13/16 - 136.7ms/batch - loss: 97.72417 - diff: 41.52mlTrain batch 14/16 - 117.7ms/batch - loss: 96.05163 - diff: 41.42mlTrain batch 15/16 - 116.3ms/batch - loss: 93.92606 - diff: 41.07mlTrain batch 16/16 - 46.8ms/batch - loss: 96.13966 - diff: 41.00mlTrain batch 16/16 - 17.8s 46.8ms/batch - loss: 96.13966 - diff: 41.00ml
Test 1.0s: val_loss: 185.46139 - diff: 56.73ml

Epoch 16: current best loss = 114.57225, at epoch 7
Train batch 1/16 - 126.4ms/batch - loss: 178.74094 - diff: 55.24mlTrain batch 2/16 - 117.9ms/batch - loss: 131.77946 - diff: 47.72mlTrain batch 3/16 - 133.6ms/batch - loss: 116.25124 - diff: 44.65mlTrain batch 4/16 - 116.7ms/batch - loss: 98.92950 - diff: 41.41mlTrain batch 5/16 - 128.8ms/batch - loss: 95.77413 - diff: 41.41mlTrain batch 6/16 - 123.7ms/batch - loss: 99.45618 - diff: 42.65mlTrain batch 7/16 - 116.3ms/batch - loss: 91.90108 - diff: 41.18mlTrain batch 8/16 - 126.9ms/batch - loss: 88.42292 - diff: 40.60mlTrain batch 9/16 - 116.1ms/batch - loss: 86.98854 - diff: 40.83mlTrain batch 10/16 - 116.1ms/batch - loss: 88.55598 - diff: 40.16mlTrain batch 11/16 - 116.4ms/batch - loss: 87.65202 - diff: 39.44mlTrain batch 12/16 - 115.9ms/batch - loss: 83.74566 - diff: 38.54mlTrain batch 13/16 - 116.2ms/batch - loss: 83.56382 - diff: 38.46mlTrain batch 14/16 - 132.0ms/batch - loss: 88.76124 - diff: 38.75mlTrain batch 15/16 - 116.2ms/batch - loss: 87.20409 - diff: 38.50mlTrain batch 16/16 - 47.3ms/batch - loss: 90.59669 - diff: 38.58mlTrain batch 16/16 - 16.6s 47.3ms/batch - loss: 90.59669 - diff: 38.58ml
Test 1.0s: val_loss: 106.08748 - diff: 43.86ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_VGG19_Adam-0.001_MSE_DA3_best

Epoch 17: current best loss = 106.08748, at epoch 16
Train batch 1/16 - 128.7ms/batch - loss: 60.48037 - diff: 34.73mlTrain batch 2/16 - 117.6ms/batch - loss: 67.41815 - diff: 37.00mlTrain batch 3/16 - 125.0ms/batch - loss: 63.47600 - diff: 36.25mlTrain batch 4/16 - 119.4ms/batch - loss: 60.51314 - diff: 35.47mlTrain batch 5/16 - 116.3ms/batch - loss: 57.87137 - diff: 34.52mlTrain batch 6/16 - 126.9ms/batch - loss: 62.60922 - diff: 35.49mlTrain batch 7/16 - 116.3ms/batch - loss: 63.61893 - diff: 36.16mlTrain batch 8/16 - 116.3ms/batch - loss: 68.77846 - diff: 36.59mlTrain batch 9/16 - 124.2ms/batch - loss: 66.34752 - diff: 36.18mlTrain batch 10/16 - 122.0ms/batch - loss: 81.75153 - diff: 37.81mlTrain batch 11/16 - 128.9ms/batch - loss: 85.84572 - diff: 38.37mlTrain batch 12/16 - 116.4ms/batch - loss: 84.86328 - diff: 38.34mlTrain batch 13/16 - 120.3ms/batch - loss: 85.75216 - diff: 38.67mlTrain batch 14/16 - 116.3ms/batch - loss: 85.44712 - diff: 38.61mlTrain batch 15/16 - 116.2ms/batch - loss: 84.02218 - diff: 38.51mlTrain batch 16/16 - 39.3ms/batch - loss: 86.65315 - diff: 38.53mlTrain batch 16/16 - 15.8s 39.3ms/batch - loss: 86.65315 - diff: 38.53ml
Test 1.2s: val_loss: 109.53827 - diff: 41.85ml

Epoch 18: current best loss = 106.08748, at epoch 16
Train batch 1/16 - 126.8ms/batch - loss: 92.47412 - diff: 41.95mlTrain batch 2/16 - 117.0ms/batch - loss: 72.16762 - diff: 37.18mlTrain batch 3/16 - 129.3ms/batch - loss: 85.05909 - diff: 39.97mlTrain batch 4/16 - 125.7ms/batch - loss: 77.43898 - diff: 38.77mlTrain batch 5/16 - 128.7ms/batch - loss: 70.20467 - diff: 36.97mlTrain batch 6/16 - 117.8ms/batch - loss: 67.42545 - diff: 36.49mlTrain batch 7/16 - 137.1ms/batch - loss: 75.14632 - diff: 37.48mlTrain batch 8/16 - 117.6ms/batch - loss: 74.07588 - diff: 37.48mlTrain batch 9/16 - 130.0ms/batch - loss: 73.04655 - diff: 37.35mlTrain batch 10/16 - 119.4ms/batch - loss: 74.88170 - diff: 37.90mlTrain batch 11/16 - 116.6ms/batch - loss: 75.44222 - diff: 38.04mlTrain batch 12/16 - 119.7ms/batch - loss: 75.93355 - diff: 38.26mlTrain batch 13/16 - 122.3ms/batch - loss: 76.10171 - diff: 38.33mlTrain batch 14/16 - 116.6ms/batch - loss: 75.66096 - diff: 38.33mlTrain batch 15/16 - 122.0ms/batch - loss: 81.60742 - diff: 38.49mlTrain batch 16/16 - 47.6ms/batch - loss: 83.77413 - diff: 38.45mlTrain batch 16/16 - 17.8s 47.6ms/batch - loss: 83.77413 - diff: 38.45ml
Test 1.2s: val_loss: 92.61132 - diff: 40.38ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_VGG19_Adam-0.001_MSE_DA3_best

Epoch 19: current best loss = 92.61132, at epoch 18
Train batch 1/16 - 127.0ms/batch - loss: 69.43693 - diff: 38.00mlTrain batch 2/16 - 116.7ms/batch - loss: 71.61589 - diff: 39.97mlTrain batch 3/16 - 136.6ms/batch - loss: 70.22133 - diff: 38.18mlTrain batch 4/16 - 120.6ms/batch - loss: 63.81704 - diff: 35.98mlTrain batch 5/16 - 127.3ms/batch - loss: 96.95531 - diff: 38.98mlTrain batch 6/16 - 126.0ms/batch - loss: 98.89208 - diff: 39.20mlTrain batch 7/16 - 116.2ms/batch - loss: 93.61317 - diff: 38.96mlTrain batch 8/16 - 116.5ms/batch - loss: 91.95763 - diff: 38.90mlTrain batch 9/16 - 118.2ms/batch - loss: 86.63104 - diff: 37.57mlTrain batch 10/16 - 120.9ms/batch - loss: 86.73955 - diff: 37.50mlTrain batch 11/16 - 119.3ms/batch - loss: 86.06427 - diff: 37.37mlTrain batch 12/16 - 116.1ms/batch - loss: 85.02564 - diff: 37.56mlTrain batch 13/16 - 116.0ms/batch - loss: 86.96728 - diff: 38.23mlTrain batch 14/16 - 116.6ms/batch - loss: 86.07942 - diff: 38.11mlTrain batch 15/16 - 122.1ms/batch - loss: 84.82434 - diff: 37.86mlTrain batch 16/16 - 39.2ms/batch - loss: 92.42647 - diff: 37.95mlTrain batch 16/16 - 16.3s 39.2ms/batch - loss: 92.42647 - diff: 37.95ml
Test 1.3s: val_loss: 83.39743 - diff: 37.31ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_VGG19_Adam-0.001_MSE_DA3_best

Epoch 20: current best loss = 83.39743, at epoch 19
Train batch 1/16 - 127.6ms/batch - loss: 68.73038 - diff: 40.19mlTrain batch 2/16 - 124.2ms/batch - loss: 58.36358 - diff: 35.52mlTrain batch 3/16 - 121.8ms/batch - loss: 62.97336 - diff: 36.66mlTrain batch 4/16 - 123.4ms/batch - loss: 69.35221 - diff: 37.47mlTrain batch 5/16 - 129.2ms/batch - loss: 102.04188 - diff: 39.92mlTrain batch 6/16 - 126.6ms/batch - loss: 98.69661 - diff: 40.24mlTrain batch 7/16 - 116.2ms/batch - loss: 93.43120 - diff: 39.58mlTrain batch 8/16 - 116.1ms/batch - loss: 88.48901 - diff: 39.07mlTrain batch 9/16 - 116.2ms/batch - loss: 87.24463 - diff: 38.91mlTrain batch 10/16 - 116.5ms/batch - loss: 90.90382 - diff: 40.28mlTrain batch 11/16 - 116.3ms/batch - loss: 87.84141 - diff: 39.51mlTrain batch 12/16 - 129.1ms/batch - loss: 87.31007 - diff: 39.42mlTrain batch 13/16 - 116.4ms/batch - loss: 84.90936 - diff: 38.99mlTrain batch 14/16 - 128.2ms/batch - loss: 83.21989 - diff: 38.70mlTrain batch 15/16 - 116.5ms/batch - loss: 83.91606 - diff: 38.74mlTrain batch 16/16 - 39.1ms/batch - loss: 85.79567 - diff: 38.70mlTrain batch 16/16 - 16.3s 39.1ms/batch - loss: 85.79567 - diff: 38.70ml
Test 1.2s: val_loss: 136.30914 - diff: 50.37ml

Epoch 21: current best loss = 83.39743, at epoch 19
Train batch 1/16 - 129.3ms/batch - loss: 48.98419 - diff: 30.04mlTrain batch 2/16 - 117.6ms/batch - loss: 74.57366 - diff: 35.73mlTrain batch 3/16 - 117.5ms/batch - loss: 67.94029 - diff: 34.23mlTrain batch 4/16 - 116.3ms/batch - loss: 67.63503 - diff: 34.60mlTrain batch 5/16 - 128.9ms/batch - loss: 67.12678 - diff: 34.90mlTrain batch 6/16 - 124.6ms/batch - loss: 67.78769 - diff: 35.34mlTrain batch 7/16 - 180.2ms/batch - loss: 65.97776 - diff: 35.08mlTrain batch 8/16 - 127.7ms/batch - loss: 74.54766 - diff: 36.42mlTrain batch 9/16 - 116.0ms/batch - loss: 73.86943 - diff: 36.69mlTrain batch 10/16 - 122.3ms/batch - loss: 71.44375 - diff: 36.25mlTrain batch 11/16 - 129.3ms/batch - loss: 71.41128 - diff: 36.39mlTrain batch 12/16 - 120.6ms/batch - loss: 69.37968 - diff: 36.06mlTrain batch 13/16 - 132.6ms/batch - loss: 74.12898 - diff: 36.39mlTrain batch 14/16 - 119.9ms/batch - loss: 75.60457 - diff: 36.84mlTrain batch 15/16 - 116.2ms/batch - loss: 77.42988 - diff: 37.11mlTrain batch 16/16 - 39.2ms/batch - loss: 84.35868 - diff: 37.33mlTrain batch 16/16 - 16.8s 39.2ms/batch - loss: 84.35868 - diff: 37.33ml
Test 1.2s: val_loss: 122.23332 - diff: 44.33ml

Epoch 22: current best loss = 83.39743, at epoch 19
Train batch 1/16 - 128.3ms/batch - loss: 62.57562 - diff: 35.43mlTrain batch 2/16 - 122.2ms/batch - loss: 85.76068 - diff: 39.03mlTrain batch 3/16 - 118.4ms/batch - loss: 77.13119 - diff: 38.30mlTrain batch 4/16 - 119.9ms/batch - loss: 82.40346 - diff: 39.74mlTrain batch 5/16 - 131.7ms/batch - loss: 76.07827 - diff: 37.86mlTrain batch 6/16 - 116.6ms/batch - loss: 81.71041 - diff: 38.74mlTrain batch 7/16 - 122.8ms/batch - loss: 78.63851 - diff: 37.71mlTrain batch 8/16 - 128.9ms/batch - loss: 79.26253 - diff: 37.88mlTrain batch 9/16 - 116.3ms/batch - loss: 78.17816 - diff: 37.65mlTrain batch 10/16 - 125.7ms/batch - loss: 77.62316 - diff: 37.71mlTrain batch 11/16 - 129.2ms/batch - loss: 76.05725 - diff: 37.54mlTrain batch 12/16 - 133.6ms/batch - loss: 74.90222 - diff: 37.39mlTrain batch 13/16 - 128.9ms/batch - loss: 78.23663 - diff: 37.67mlTrain batch 14/16 - 129.0ms/batch - loss: 76.21085 - diff: 37.32mlTrain batch 15/16 - 116.4ms/batch - loss: 83.00380 - diff: 38.09mlTrain batch 16/16 - 39.1ms/batch - loss: 86.21465 - diff: 38.12mlTrain batch 16/16 - 16.1s 39.1ms/batch - loss: 86.21465 - diff: 38.12ml
Test 0.7s: val_loss: 139.67238 - diff: 53.15ml

Epoch 23: current best loss = 83.39743, at epoch 19
Train batch 1/16 - 139.9ms/batch - loss: 65.17670 - diff: 32.24mlTrain batch 2/16 - 122.0ms/batch - loss: 73.22945 - diff: 35.90mlTrain batch 3/16 - 116.3ms/batch - loss: 106.36972 - diff: 37.55mlTrain batch 4/16 - 116.4ms/batch - loss: 97.82961 - diff: 37.24mlTrain batch 5/16 - 139.0ms/batch - loss: 96.01999 - diff: 37.22mlTrain batch 6/16 - 128.2ms/batch - loss: 91.98169 - diff: 37.65mlTrain batch 7/16 - 144.1ms/batch - loss: 86.41537 - diff: 37.23mlTrain batch 8/16 - 122.0ms/batch - loss: 86.43122 - diff: 37.94mlTrain batch 9/16 - 116.5ms/batch - loss: 85.80132 - diff: 38.10mlTrain batch 10/16 - 118.6ms/batch - loss: 83.31085 - diff: 37.92mlTrain batch 11/16 - 128.3ms/batch - loss: 85.15524 - diff: 38.03mlTrain batch 12/16 - 122.3ms/batch - loss: 84.26771 - diff: 38.18mlTrain batch 13/16 - 129.9ms/batch - loss: 83.27639 - diff: 38.18mlTrain batch 14/16 - 117.2ms/batch - loss: 83.41205 - diff: 38.66mlTrain batch 15/16 - 116.0ms/batch - loss: 82.02934 - diff: 38.20mlTrain batch 16/16 - 39.1ms/batch - loss: 85.16290 - diff: 38.08mlTrain batch 16/16 - 16.8s 39.1ms/batch - loss: 85.16290 - diff: 38.08ml
Test 1.1s: val_loss: 109.79736 - diff: 38.19ml

Epoch 24: current best loss = 83.39743, at epoch 19
Train batch 1/16 - 129.1ms/batch - loss: 143.33797 - diff: 49.56mlTrain batch 2/16 - 117.3ms/batch - loss: 105.72258 - diff: 45.29mlTrain batch 3/16 - 121.8ms/batch - loss: 90.82618 - diff: 41.95mlTrain batch 4/16 - 128.0ms/batch - loss: 88.05288 - diff: 39.99mlTrain batch 5/16 - 132.0ms/batch - loss: 89.25975 - diff: 40.23mlTrain batch 6/16 - 125.2ms/batch - loss: 89.17251 - diff: 39.78mlTrain batch 7/16 - 119.9ms/batch - loss: 101.60005 - diff: 39.97mlTrain batch 8/16 - 119.1ms/batch - loss: 95.10473 - diff: 38.85mlTrain batch 9/16 - 116.1ms/batch - loss: 89.32362 - diff: 37.82mlTrain batch 10/16 - 123.2ms/batch - loss: 88.74940 - diff: 37.84mlTrain batch 11/16 - 139.2ms/batch - loss: 85.47128 - diff: 37.46mlTrain batch 12/16 - 128.4ms/batch - loss: 84.97639 - diff: 37.75mlTrain batch 13/16 - 129.6ms/batch - loss: 82.26486 - diff: 37.34mlTrain batch 14/16 - 122.5ms/batch - loss: 80.39643 - diff: 37.12mlTrain batch 15/16 - 122.4ms/batch - loss: 79.04272 - diff: 36.84mlTrain batch 16/16 - 47.2ms/batch - loss: 79.77439 - diff: 36.66mlTrain batch 16/16 - 16.8s 47.2ms/batch - loss: 79.77439 - diff: 36.66ml
Test 1.2s: val_loss: 89.60048 - diff: 37.74ml

Epoch 25: current best loss = 83.39743, at epoch 19
Train batch 1/16 - 127.1ms/batch - loss: 67.37003 - diff: 34.37mlTrain batch 2/16 - 120.8ms/batch - loss: 76.47759 - diff: 36.06mlTrain batch 3/16 - 126.8ms/batch - loss: 77.71819 - diff: 37.17mlTrain batch 4/16 - 118.4ms/batch - loss: 66.80661 - diff: 34.72mlTrain batch 5/16 - 123.8ms/batch - loss: 66.18930 - diff: 35.43mlTrain batch 6/16 - 116.0ms/batch - loss: 61.35826 - diff: 34.05mlTrain batch 7/16 - 124.1ms/batch - loss: 61.97142 - diff: 34.38mlTrain batch 8/16 - 120.2ms/batch - loss: 66.52097 - diff: 34.83mlTrain batch 9/16 - 116.1ms/batch - loss: 74.76537 - diff: 36.52mlTrain batch 10/16 - 130.5ms/batch - loss: 76.20746 - diff: 36.68mlTrain batch 11/16 - 121.5ms/batch - loss: 83.55688 - diff: 36.93mlTrain batch 12/16 - 116.1ms/batch - loss: 81.06973 - diff: 36.61mlTrain batch 13/16 - 116.3ms/batch - loss: 82.07800 - diff: 37.22mlTrain batch 14/16 - 116.2ms/batch - loss: 80.49733 - diff: 37.17mlTrain batch 15/16 - 123.2ms/batch - loss: 79.05144 - diff: 37.00mlTrain batch 16/16 - 39.2ms/batch - loss: 84.45695 - diff: 37.12mlTrain batch 16/16 - 15.9s 39.2ms/batch - loss: 84.45695 - diff: 37.12ml
Test 1.1s: val_loss: 77.04502 - diff: 36.22ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_VGG19_Adam-0.001_MSE_DA3_best

Epoch 26: current best loss = 77.04502, at epoch 25
Train batch 1/16 - 139.6ms/batch - loss: 74.02979 - diff: 37.74mlTrain batch 2/16 - 125.7ms/batch - loss: 96.65199 - diff: 41.78mlTrain batch 3/16 - 120.1ms/batch - loss: 90.60907 - diff: 41.17mlTrain batch 4/16 - 116.3ms/batch - loss: 82.96472 - diff: 39.26mlTrain batch 5/16 - 116.4ms/batch - loss: 76.39881 - diff: 37.59mlTrain batch 6/16 - 116.1ms/batch - loss: 72.53760 - diff: 36.43mlTrain batch 7/16 - 116.7ms/batch - loss: 80.25785 - diff: 37.53mlTrain batch 8/16 - 116.3ms/batch - loss: 77.79675 - diff: 37.14mlTrain batch 9/16 - 116.3ms/batch - loss: 75.97486 - diff: 36.98mlTrain batch 10/16 - 116.3ms/batch - loss: 74.38940 - diff: 36.88mlTrain batch 11/16 - 122.4ms/batch - loss: 74.85856 - diff: 37.36mlTrain batch 12/16 - 125.3ms/batch - loss: 76.61232 - diff: 37.64mlTrain batch 13/16 - 122.1ms/batch - loss: 75.69629 - diff: 37.43mlTrain batch 14/16 - 122.0ms/batch - loss: 78.91085 - diff: 38.05mlTrain batch 15/16 - 122.2ms/batch - loss: 78.50987 - diff: 37.93mlTrain batch 16/16 - 39.2ms/batch - loss: 80.40025 - diff: 37.89mlTrain batch 16/16 - 15.8s 39.2ms/batch - loss: 80.40025 - diff: 37.89ml
Test 1.2s: val_loss: 132.10240 - diff: 41.03ml

Epoch 27: current best loss = 77.04502, at epoch 25
Train batch 1/16 - 128.8ms/batch - loss: 107.17680 - diff: 42.00mlTrain batch 2/16 - 120.2ms/batch - loss: 96.15488 - diff: 41.60mlTrain batch 3/16 - 129.1ms/batch - loss: 101.03046 - diff: 42.89mlTrain batch 4/16 - 117.2ms/batch - loss: 87.50341 - diff: 39.62mlTrain batch 5/16 - 116.1ms/batch - loss: 93.12123 - diff: 39.08mlTrain batch 6/16 - 116.6ms/batch - loss: 88.98339 - diff: 38.76mlTrain batch 7/16 - 122.2ms/batch - loss: 84.61837 - diff: 37.93mlTrain batch 8/16 - 116.2ms/batch - loss: 79.29296 - diff: 36.82mlTrain batch 9/16 - 129.0ms/batch - loss: 76.88611 - diff: 36.45mlTrain batch 10/16 - 121.1ms/batch - loss: 75.42680 - diff: 36.14mlTrain batch 11/16 - 130.4ms/batch - loss: 74.14873 - diff: 35.88mlTrain batch 12/16 - 127.2ms/batch - loss: 72.60220 - diff: 35.85mlTrain batch 13/16 - 128.9ms/batch - loss: 79.06622 - diff: 36.55mlTrain batch 14/16 - 123.1ms/batch - loss: 79.20344 - diff: 36.71mlTrain batch 15/16 - 116.3ms/batch - loss: 80.70353 - diff: 37.15mlTrain batch 16/16 - 51.5ms/batch - loss: 85.94911 - diff: 37.23mlTrain batch 16/16 - 16.8s 51.5ms/batch - loss: 85.94911 - diff: 37.23ml
Test 1.2s: val_loss: 79.19954 - diff: 37.38ml

Epoch 28: current best loss = 77.04502, at epoch 25
Train batch 1/16 - 134.6ms/batch - loss: 66.93741 - diff: 40.15mlTrain batch 2/16 - 129.6ms/batch - loss: 80.71261 - diff: 38.59mlTrain batch 3/16 - 116.3ms/batch - loss: 77.28515 - diff: 38.92mlTrain batch 4/16 - 129.4ms/batch - loss: 74.59137 - diff: 37.87mlTrain batch 5/16 - 116.2ms/batch - loss: 68.59087 - diff: 36.52mlTrain batch 6/16 - 122.6ms/batch - loss: 88.59432 - diff: 39.03mlTrain batch 7/16 - 116.2ms/batch - loss: 84.11530 - diff: 38.27mlTrain batch 8/16 - 118.2ms/batch - loss: 80.54541 - diff: 37.93mlTrain batch 9/16 - 116.4ms/batch - loss: 77.40158 - diff: 37.35mlTrain batch 10/16 - 124.8ms/batch - loss: 75.80729 - diff: 37.25mlTrain batch 11/16 - 124.2ms/batch - loss: 74.93104 - diff: 37.10mlTrain batch 12/16 - 116.1ms/batch - loss: 75.59870 - diff: 37.18mlTrain batch 13/16 - 116.3ms/batch - loss: 74.56953 - diff: 36.96mlTrain batch 14/16 - 116.0ms/batch - loss: 73.24119 - diff: 36.72mlTrain batch 15/16 - 122.0ms/batch - loss: 72.89728 - diff: 36.77mlTrain batch 16/16 - 44.9ms/batch - loss: 75.73930 - diff: 36.75mlTrain batch 16/16 - 15.4s 44.9ms/batch - loss: 75.73930 - diff: 36.75ml
Test 1.4s: val_loss: 113.33115 - diff: 44.32ml

Epoch 29: current best loss = 77.04502, at epoch 25
Train batch 1/16 - 135.8ms/batch - loss: 50.96893 - diff: 27.86mlTrain batch 2/16 - 117.5ms/batch - loss: 65.24241 - diff: 33.60mlTrain batch 3/16 - 125.3ms/batch - loss: 63.90282 - diff: 34.94mlTrain batch 4/16 - 131.4ms/batch - loss: 62.06353 - diff: 34.65mlTrain batch 5/16 - 124.3ms/batch - loss: 69.54025 - diff: 37.44mlTrain batch 6/16 - 124.9ms/batch - loss: 66.65666 - diff: 36.38mlTrain batch 7/16 - 116.0ms/batch - loss: 63.85846 - diff: 35.76mlTrain batch 8/16 - 116.5ms/batch - loss: 67.89901 - diff: 35.73mlTrain batch 9/16 - 116.2ms/batch - loss: 64.76308 - diff: 34.69mlTrain batch 10/16 - 116.3ms/batch - loss: 64.19956 - diff: 34.54mlTrain batch 11/16 - 184.1ms/batch - loss: 65.54150 - diff: 34.62mlTrain batch 12/16 - 127.4ms/batch - loss: 65.07681 - diff: 34.74mlTrain batch 13/16 - 118.5ms/batch - loss: 65.07865 - diff: 34.92mlTrain batch 14/16 - 132.2ms/batch - loss: 72.90917 - diff: 35.79mlTrain batch 15/16 - 116.0ms/batch - loss: 74.84426 - diff: 36.33mlTrain batch 16/16 - 39.3ms/batch - loss: 78.59036 - diff: 36.44mlTrain batch 16/16 - 16.3s 39.3ms/batch - loss: 78.59036 - diff: 36.44ml
Test 1.0s: val_loss: 78.39788 - diff: 35.12ml

Epoch 30: current best loss = 77.04502, at epoch 25
Train batch 1/16 - 128.8ms/batch - loss: 49.24627 - diff: 30.56mlTrain batch 2/16 - 134.6ms/batch - loss: 49.59317 - diff: 31.22mlTrain batch 3/16 - 132.9ms/batch - loss: 45.45439 - diff: 29.98mlTrain batch 4/16 - 116.3ms/batch - loss: 47.85752 - diff: 30.57mlTrain batch 5/16 - 116.2ms/batch - loss: 50.08517 - diff: 31.40mlTrain batch 6/16 - 130.7ms/batch - loss: 51.21907 - diff: 31.77mlTrain batch 7/16 - 116.3ms/batch - loss: 53.58730 - diff: 32.23mlTrain batch 8/16 - 123.6ms/batch - loss: 55.88253 - diff: 32.91mlTrain batch 9/16 - 116.1ms/batch - loss: 56.38892 - diff: 33.09mlTrain batch 10/16 - 116.1ms/batch - loss: 74.92531 - diff: 34.63mlTrain batch 11/16 - 122.8ms/batch - loss: 74.75004 - diff: 34.67mlTrain batch 12/16 - 116.2ms/batch - loss: 74.66065 - diff: 34.77mlTrain batch 13/16 - 116.2ms/batch - loss: 72.95088 - diff: 34.36mlTrain batch 14/16 - 116.1ms/batch - loss: 71.31045 - diff: 34.22mlTrain batch 15/16 - 122.3ms/batch - loss: 71.78290 - diff: 34.73mlTrain batch 16/16 - 39.2ms/batch - loss: 77.62754 - diff: 34.92mlTrain batch 16/16 - 16.0s 39.2ms/batch - loss: 77.62754 - diff: 34.92ml
Test 1.2s: val_loss: 128.67601 - diff: 47.68ml

Epoch 31: current best loss = 77.04502, at epoch 25
Train batch 1/16 - 128.7ms/batch - loss: 87.74473 - diff: 37.00mlTrain batch 2/16 - 128.5ms/batch - loss: 80.98712 - diff: 37.85mlTrain batch 3/16 - 116.1ms/batch - loss: 69.11832 - diff: 35.06mlTrain batch 4/16 - 125.0ms/batch - loss: 66.38651 - diff: 34.29mlTrain batch 5/16 - 127.4ms/batch - loss: 69.94904 - diff: 35.03mlTrain batch 6/16 - 125.9ms/batch - loss: 83.70058 - diff: 36.49mlTrain batch 7/16 - 118.1ms/batch - loss: 82.90634 - diff: 36.44mlTrain batch 8/16 - 118.6ms/batch - loss: 82.93921 - diff: 36.63mlTrain batch 9/16 - 116.1ms/batch - loss: 81.39932 - diff: 36.23mlTrain batch 10/16 - 122.0ms/batch - loss: 80.89316 - diff: 36.32mlTrain batch 11/16 - 116.3ms/batch - loss: 80.92337 - diff: 36.79mlTrain batch 12/16 - 116.3ms/batch - loss: 80.18714 - diff: 37.07mlTrain batch 13/16 - 129.3ms/batch - loss: 77.88712 - diff: 36.58mlTrain batch 14/16 - 125.9ms/batch - loss: 80.77523 - diff: 37.25mlTrain batch 15/16 - 117.6ms/batch - loss: 84.14652 - diff: 37.75mlTrain batch 16/16 - 39.4ms/batch - loss: 84.83776 - diff: 37.61mlTrain batch 16/16 - 16.0s 39.4ms/batch - loss: 84.83776 - diff: 37.61ml
Test 1.1s: val_loss: 117.49259 - diff: 43.99ml

Epoch 32: current best loss = 77.04502, at epoch 25
Train batch 1/16 - 150.1ms/batch - loss: 85.45671 - diff: 40.84mlTrain batch 2/16 - 124.0ms/batch - loss: 63.07690 - diff: 35.54mlTrain batch 3/16 - 116.3ms/batch - loss: 64.26747 - diff: 35.78mlTrain batch 4/16 - 116.3ms/batch - loss: 75.71392 - diff: 38.68mlTrain batch 5/16 - 116.1ms/batch - loss: 69.97459 - diff: 37.23mlTrain batch 6/16 - 116.5ms/batch - loss: 82.36642 - diff: 38.70mlTrain batch 7/16 - 123.1ms/batch - loss: 79.85946 - diff: 38.82mlTrain batch 8/16 - 121.9ms/batch - loss: 77.04087 - diff: 37.68mlTrain batch 9/16 - 120.1ms/batch - loss: 76.65615 - diff: 37.88mlTrain batch 10/16 - 116.3ms/batch - loss: 78.91629 - diff: 38.25mlTrain batch 11/16 - 116.6ms/batch - loss: 78.28621 - diff: 38.21mlTrain batch 12/16 - 116.2ms/batch - loss: 81.72110 - diff: 38.35mlTrain batch 13/16 - 115.9ms/batch - loss: 79.89605 - diff: 38.03mlTrain batch 14/16 - 126.3ms/batch - loss: 78.10360 - diff: 37.84mlTrain batch 15/16 - 124.1ms/batch - loss: 76.43812 - diff: 37.47mlTrain batch 16/16 - 46.5ms/batch - loss: 81.21482 - diff: 37.54mlTrain batch 16/16 - 14.8s 46.5ms/batch - loss: 81.21482 - diff: 37.54ml
Test 1.2s: val_loss: 146.74194 - diff: 53.13ml

Epoch 33: current best loss = 77.04502, at epoch 25
Train batch 1/16 - 128.8ms/batch - loss: 77.93584 - diff: 37.60mlTrain batch 2/16 - 116.1ms/batch - loss: 86.00852 - diff: 40.73mlTrain batch 3/16 - 128.9ms/batch - loss: 82.28933 - diff: 40.07mlTrain batch 4/16 - 116.8ms/batch - loss: 73.21627 - diff: 38.16mlTrain batch 5/16 - 122.4ms/batch - loss: 67.71448 - diff: 36.77mlTrain batch 6/16 - 128.9ms/batch - loss: 70.60429 - diff: 37.67mlTrain batch 7/16 - 116.3ms/batch - loss: 70.11446 - diff: 37.60mlTrain batch 8/16 - 117.3ms/batch - loss: 71.07650 - diff: 38.07mlTrain batch 9/16 - 119.7ms/batch - loss: 82.28417 - diff: 39.27mlTrain batch 10/16 - 127.9ms/batch - loss: 91.03703 - diff: 40.15mlTrain batch 11/16 - 123.7ms/batch - loss: 87.22109 - diff: 39.60mlTrain batch 12/16 - 116.0ms/batch - loss: 82.11784 - diff: 38.28mlTrain batch 13/16 - 116.2ms/batch - loss: 79.88101 - diff: 38.10mlTrain batch 14/16 - 116.3ms/batch - loss: 80.08765 - diff: 38.33mlTrain batch 15/16 - 116.2ms/batch - loss: 79.31260 - diff: 38.08mlTrain batch 16/16 - 39.2ms/batch - loss: 81.26823 - diff: 37.96mlTrain batch 16/16 - 16.1s 39.2ms/batch - loss: 81.26823 - diff: 37.96ml
Test 1.1s: val_loss: 104.95080 - diff: 41.79ml

Epoch 34: current best loss = 77.04502, at epoch 25
Train batch 1/16 - 128.9ms/batch - loss: 57.45577 - diff: 31.14mlTrain batch 2/16 - 125.6ms/batch - loss: 70.66557 - diff: 34.57mlTrain batch 3/16 - 116.2ms/batch - loss: 63.93761 - diff: 33.17mlTrain batch 4/16 - 120.1ms/batch - loss: 59.74897 - diff: 32.77mlTrain batch 5/16 - 116.1ms/batch - loss: 66.36084 - diff: 33.52mlTrain batch 6/16 - 116.2ms/batch - loss: 70.93433 - diff: 34.89mlTrain batch 7/16 - 128.9ms/batch - loss: 71.96115 - diff: 35.39mlTrain batch 8/16 - 126.5ms/batch - loss: 70.08019 - diff: 35.41mlTrain batch 9/16 - 125.1ms/batch - loss: 67.55414 - diff: 34.88mlTrain batch 10/16 - 127.1ms/batch - loss: 71.68411 - diff: 35.44mlTrain batch 11/16 - 116.0ms/batch - loss: 69.83157 - diff: 35.07mlTrain batch 12/16 - 132.1ms/batch - loss: 67.60047 - diff: 34.62mlTrain batch 13/16 - 116.2ms/batch - loss: 72.42629 - diff: 34.92mlTrain batch 14/16 - 116.3ms/batch - loss: 71.71965 - diff: 34.90mlTrain batch 15/16 - 116.2ms/batch - loss: 72.36358 - diff: 35.23mlTrain batch 16/16 - 39.2ms/batch - loss: 73.58344 - diff: 35.16mlTrain batch 16/16 - 16.6s 39.2ms/batch - loss: 73.58344 - diff: 35.16ml
Test 1.1s: val_loss: 113.88334 - diff: 42.82ml

Epoch 35: current best loss = 77.04502, at epoch 25
Train batch 1/16 - 126.7ms/batch - loss: 57.68807 - diff: 32.91mlTrain batch 2/16 - 116.2ms/batch - loss: 88.45733 - diff: 36.63mlTrain batch 3/16 - 125.0ms/batch - loss: 78.74436 - diff: 36.82mlTrain batch 4/16 - 135.0ms/batch - loss: 87.03033 - diff: 39.12mlTrain batch 5/16 - 128.9ms/batch - loss: 108.68430 - diff: 40.22mlTrain batch 6/16 - 117.4ms/batch - loss: 103.65405 - diff: 40.50mlTrain batch 7/16 - 116.1ms/batch - loss: 97.10000 - diff: 39.73mlTrain batch 8/16 - 117.0ms/batch - loss: 90.60327 - diff: 38.81mlTrain batch 9/16 - 128.8ms/batch - loss: 85.87524 - diff: 38.12mlTrain batch 10/16 - 117.3ms/batch - loss: 82.97002 - diff: 37.73mlTrain batch 11/16 - 125.3ms/batch - loss: 81.34148 - diff: 37.44mlTrain batch 12/16 - 116.7ms/batch - loss: 81.07507 - diff: 37.70mlTrain batch 13/16 - 123.2ms/batch - loss: 78.57437 - diff: 37.22mlTrain batch 14/16 - 116.6ms/batch - loss: 77.80033 - diff: 37.19mlTrain batch 15/16 - 116.4ms/batch - loss: 76.88354 - diff: 37.01mlTrain batch 16/16 - 39.2ms/batch - loss: 79.93355 - diff: 37.06mlTrain batch 16/16 - 15.9s 39.2ms/batch - loss: 79.93355 - diff: 37.06ml
Test 1.2s: val_loss: 82.02653 - diff: 36.80ml

Epoch 36: current best loss = 77.04502, at epoch 25
Train batch 1/16 - 127.7ms/batch - loss: 103.67097 - diff: 46.69mlTrain batch 2/16 - 116.6ms/batch - loss: 73.81190 - diff: 39.58mlTrain batch 3/16 - 123.1ms/batch - loss: 60.93403 - diff: 35.24mlTrain batch 4/16 - 128.4ms/batch - loss: 57.49608 - diff: 34.03mlTrain batch 5/16 - 126.3ms/batch - loss: 66.13949 - diff: 36.29mlTrain batch 6/16 - 126.7ms/batch - loss: 63.60316 - diff: 35.46mlTrain batch 7/16 - 121.0ms/batch - loss: 61.69156 - diff: 35.16mlTrain batch 8/16 - 116.7ms/batch - loss: 69.97224 - diff: 36.90mlTrain batch 9/16 - 124.5ms/batch - loss: 69.72089 - diff: 36.37mlTrain batch 10/16 - 116.3ms/batch - loss: 70.76004 - diff: 36.61mlTrain batch 11/16 - 116.2ms/batch - loss: 67.43439 - diff: 35.75mlTrain batch 12/16 - 126.8ms/batch - loss: 64.82059 - diff: 35.16mlTrain batch 13/16 - 124.8ms/batch - loss: 64.03443 - diff: 34.93mlTrain batch 14/16 - 116.3ms/batch - loss: 72.14699 - diff: 35.94mlTrain batch 15/16 - 116.2ms/batch - loss: 71.88669 - diff: 35.82mlTrain batch 16/16 - 39.1ms/batch - loss: 75.59635 - diff: 35.91mlTrain batch 16/16 - 15.9s 39.1ms/batch - loss: 75.59635 - diff: 35.91ml
Test 1.2s: val_loss: 88.24168 - diff: 37.24ml
Epoch    37: reducing learning rate of group 0 to 5.0000e-04.

Epoch 37: current best loss = 77.04502, at epoch 25
Train batch 1/16 - 130.9ms/batch - loss: 31.24178 - diff: 23.59mlTrain batch 2/16 - 127.5ms/batch - loss: 47.12368 - diff: 29.36mlTrain batch 3/16 - 122.2ms/batch - loss: 82.66591 - diff: 32.46mlTrain batch 4/16 - 122.2ms/batch - loss: 87.81508 - diff: 34.31mlTrain batch 5/16 - 138.3ms/batch - loss: 87.19066 - diff: 36.28mlTrain batch 6/16 - 122.2ms/batch - loss: 82.89305 - diff: 36.11mlTrain batch 7/16 - 123.0ms/batch - loss: 78.60128 - diff: 35.59mlTrain batch 8/16 - 137.8ms/batch - loss: 79.74549 - diff: 36.27mlTrain batch 9/16 - 119.3ms/batch - loss: 79.27057 - diff: 36.31mlTrain batch 10/16 - 116.0ms/batch - loss: 76.45627 - diff: 35.80mlTrain batch 11/16 - 119.0ms/batch - loss: 74.52421 - diff: 35.55mlTrain batch 12/16 - 126.7ms/batch - loss: 72.90412 - diff: 35.23mlTrain batch 13/16 - 118.9ms/batch - loss: 74.00723 - diff: 35.43mlTrain batch 14/16 - 124.1ms/batch - loss: 72.49531 - diff: 35.37mlTrain batch 15/16 - 129.2ms/batch - loss: 71.34411 - diff: 35.42mlTrain batch 16/16 - 50.4ms/batch - loss: 81.47901 - diff: 35.68mlTrain batch 16/16 - 17.2s 50.4ms/batch - loss: 81.47901 - diff: 35.68ml
Test 1.2s: val_loss: 100.75141 - diff: 38.31ml

Epoch 38: current best loss = 77.04502, at epoch 25
Train batch 1/16 - 129.7ms/batch - loss: 64.86849 - diff: 31.32mlTrain batch 2/16 - 127.3ms/batch - loss: 83.32669 - diff: 36.72mlTrain batch 3/16 - 126.9ms/batch - loss: 71.34746 - diff: 34.58mlTrain batch 4/16 - 116.4ms/batch - loss: 66.30533 - diff: 34.62mlTrain batch 5/16 - 128.9ms/batch - loss: 63.21415 - diff: 33.91mlTrain batch 6/16 - 116.2ms/batch - loss: 68.09205 - diff: 35.17mlTrain batch 7/16 - 157.7ms/batch - loss: 66.88953 - diff: 35.16mlTrain batch 8/16 - 126.4ms/batch - loss: 64.54030 - diff: 34.62mlTrain batch 9/16 - 117.0ms/batch - loss: 68.52857 - diff: 34.62mlTrain batch 10/16 - 127.8ms/batch - loss: 69.77075 - diff: 34.59mlTrain batch 11/16 - 129.5ms/batch - loss: 68.70354 - diff: 34.59mlTrain batch 12/16 - 123.6ms/batch - loss: 66.36646 - diff: 33.92mlTrain batch 13/16 - 138.6ms/batch - loss: 71.45828 - diff: 35.06mlTrain batch 14/16 - 121.0ms/batch - loss: 70.37720 - diff: 34.83mlTrain batch 15/16 - 129.2ms/batch - loss: 69.81968 - diff: 34.91mlTrain batch 16/16 - 44.3ms/batch - loss: 72.10300 - diff: 34.86mlTrain batch 16/16 - 17.9s 44.3ms/batch - loss: 72.10300 - diff: 34.86ml
Test 1.2s: val_loss: 77.16432 - diff: 36.46ml

Epoch 39: current best loss = 77.04502, at epoch 25
Train batch 1/16 - 126.7ms/batch - loss: 68.62167 - diff: 35.31mlTrain batch 2/16 - 121.5ms/batch - loss: 58.71630 - diff: 32.87mlTrain batch 3/16 - 124.2ms/batch - loss: 65.20244 - diff: 34.91mlTrain batch 4/16 - 124.3ms/batch - loss: 61.61525 - diff: 34.64mlTrain batch 5/16 - 116.1ms/batch - loss: 58.12544 - diff: 33.47mlTrain batch 6/16 - 116.3ms/batch - loss: 56.32017 - diff: 33.02mlTrain batch 7/16 - 116.6ms/batch - loss: 57.80301 - diff: 32.98mlTrain batch 8/16 - 116.3ms/batch - loss: 60.04829 - diff: 33.90mlTrain batch 9/16 - 121.5ms/batch - loss: 61.35212 - diff: 34.06mlTrain batch 10/16 - 130.1ms/batch - loss: 60.16025 - diff: 33.55mlTrain batch 11/16 - 127.4ms/batch - loss: 59.09730 - diff: 33.29mlTrain batch 12/16 - 116.3ms/batch - loss: 71.27925 - diff: 34.79mlTrain batch 13/16 - 126.3ms/batch - loss: 69.46422 - diff: 34.26mlTrain batch 14/16 - 129.0ms/batch - loss: 69.10228 - diff: 34.30mlTrain batch 15/16 - 123.2ms/batch - loss: 71.66411 - diff: 34.59mlTrain batch 16/16 - 46.9ms/batch - loss: 73.35641 - diff: 34.51mlTrain batch 16/16 - 16.6s 46.9ms/batch - loss: 73.35641 - diff: 34.51ml
Test 1.3s: val_loss: 72.45180 - diff: 36.64ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_VGG19_Adam-0.001_MSE_DA3_best

Epoch 40: current best loss = 72.45180, at epoch 39
Train batch 1/16 - 129.0ms/batch - loss: 48.10839 - diff: 28.18mlTrain batch 2/16 - 118.0ms/batch - loss: 61.26694 - diff: 33.43mlTrain batch 3/16 - 127.2ms/batch - loss: 63.35893 - diff: 35.23mlTrain batch 4/16 - 127.7ms/batch - loss: 88.66853 - diff: 37.66mlTrain batch 5/16 - 129.3ms/batch - loss: 75.10380 - diff: 34.36mlTrain batch 6/16 - 124.4ms/batch - loss: 68.75735 - diff: 33.25mlTrain batch 7/16 - 116.2ms/batch - loss: 71.62893 - diff: 33.98mlTrain batch 8/16 - 116.7ms/batch - loss: 70.56586 - diff: 34.45mlTrain batch 9/16 - 124.1ms/batch - loss: 68.76914 - diff: 34.52mlTrain batch 10/16 - 116.0ms/batch - loss: 72.71312 - diff: 34.66mlTrain batch 11/16 - 116.4ms/batch - loss: 69.42034 - diff: 34.04mlTrain batch 12/16 - 127.9ms/batch - loss: 68.60684 - diff: 34.05mlTrain batch 13/16 - 116.2ms/batch - loss: 68.39071 - diff: 34.20mlTrain batch 14/16 - 129.0ms/batch - loss: 67.45675 - diff: 34.24mlTrain batch 15/16 - 116.1ms/batch - loss: 67.73872 - diff: 34.41mlTrain batch 16/16 - 39.1ms/batch - loss: 69.57222 - diff: 34.33mlTrain batch 16/16 - 16.4s 39.1ms/batch - loss: 69.57222 - diff: 34.33ml
Test 1.2s: val_loss: 75.56286 - diff: 36.36ml

Epoch 41: current best loss = 72.45180, at epoch 39
Train batch 1/16 - 129.0ms/batch - loss: 63.47104 - diff: 33.38mlTrain batch 2/16 - 117.3ms/batch - loss: 53.93385 - diff: 31.58mlTrain batch 3/16 - 116.3ms/batch - loss: 55.21911 - diff: 30.73mlTrain batch 4/16 - 116.1ms/batch - loss: 52.59551 - diff: 30.49mlTrain batch 5/16 - 116.4ms/batch - loss: 50.38427 - diff: 30.00mlTrain batch 6/16 - 116.3ms/batch - loss: 65.17671 - diff: 32.35mlTrain batch 7/16 - 129.8ms/batch - loss: 64.66042 - diff: 32.72mlTrain batch 8/16 - 128.1ms/batch - loss: 64.04826 - diff: 32.97mlTrain batch 9/16 - 116.2ms/batch - loss: 64.50354 - diff: 33.58mlTrain batch 10/16 - 126.7ms/batch - loss: 63.74737 - diff: 33.26mlTrain batch 11/16 - 117.7ms/batch - loss: 64.67874 - diff: 33.55mlTrain batch 12/16 - 116.3ms/batch - loss: 65.27671 - diff: 33.88mlTrain batch 13/16 - 116.4ms/batch - loss: 69.55084 - diff: 34.17mlTrain batch 14/16 - 116.1ms/batch - loss: 69.06978 - diff: 33.97mlTrain batch 15/16 - 116.3ms/batch - loss: 67.38478 - diff: 33.55mlTrain batch 16/16 - 39.2ms/batch - loss: 68.46757 - diff: 33.39mlTrain batch 16/16 - 15.9s 39.2ms/batch - loss: 68.46757 - diff: 33.39ml
Test 1.3s: val_loss: 81.31627 - diff: 37.87ml

Epoch 42: current best loss = 72.45180, at epoch 39
Train batch 1/16 - 128.9ms/batch - loss: 60.07119 - diff: 36.00mlTrain batch 2/16 - 116.2ms/batch - loss: 67.96176 - diff: 36.51mlTrain batch 3/16 - 116.3ms/batch - loss: 63.81250 - diff: 35.32mlTrain batch 4/16 - 116.1ms/batch - loss: 59.14619 - diff: 33.07mlTrain batch 5/16 - 116.2ms/batch - loss: 56.95821 - diff: 32.44mlTrain batch 6/16 - 121.0ms/batch - loss: 58.77814 - diff: 33.18mlTrain batch 7/16 - 122.5ms/batch - loss: 65.59008 - diff: 34.27mlTrain batch 8/16 - 116.4ms/batch - loss: 66.90426 - diff: 35.09mlTrain batch 9/16 - 116.2ms/batch - loss: 63.01931 - diff: 34.18mlTrain batch 10/16 - 116.6ms/batch - loss: 63.27034 - diff: 34.09mlTrain batch 11/16 - 116.3ms/batch - loss: 63.25008 - diff: 34.00mlTrain batch 12/16 - 116.0ms/batch - loss: 62.54052 - diff: 34.00mlTrain batch 13/16 - 123.6ms/batch - loss: 62.71306 - diff: 34.24mlTrain batch 14/16 - 117.9ms/batch - loss: 67.09781 - diff: 34.45mlTrain batch 15/16 - 116.2ms/batch - loss: 67.76928 - diff: 34.70mlTrain batch 16/16 - 39.2ms/batch - loss: 75.06861 - diff: 34.82mlTrain batch 16/16 - 14.5s 39.2ms/batch - loss: 75.06861 - diff: 34.82ml
Test 1.1s: val_loss: 98.23023 - diff: 36.17ml

Epoch 43: current best loss = 72.45180, at epoch 39
Train batch 1/16 - 128.8ms/batch - loss: 62.62121 - diff: 33.78mlTrain batch 2/16 - 138.9ms/batch - loss: 87.45487 - diff: 39.46mlTrain batch 3/16 - 120.6ms/batch - loss: 79.37287 - diff: 38.62mlTrain batch 4/16 - 116.2ms/batch - loss: 77.03977 - diff: 38.25mlTrain batch 5/16 - 130.3ms/batch - loss: 83.46162 - diff: 39.46mlTrain batch 6/16 - 126.4ms/batch - loss: 78.13367 - diff: 37.89mlTrain batch 7/16 - 116.1ms/batch - loss: 72.58076 - diff: 36.57mlTrain batch 8/16 - 115.9ms/batch - loss: 69.19414 - diff: 35.55mlTrain batch 9/16 - 116.2ms/batch - loss: 71.41745 - diff: 35.93mlTrain batch 10/16 - 116.2ms/batch - loss: 71.69774 - diff: 36.39mlTrain batch 11/16 - 116.1ms/batch - loss: 71.52307 - diff: 36.56mlTrain batch 12/16 - 119.0ms/batch - loss: 71.12625 - diff: 36.62mlTrain batch 13/16 - 124.2ms/batch - loss: 68.79120 - diff: 36.01mlTrain batch 14/16 - 128.0ms/batch - loss: 66.12924 - diff: 35.30mlTrain batch 15/16 - 116.2ms/batch - loss: 67.41142 - diff: 35.43mlTrain batch 16/16 - 39.1ms/batch - loss: 70.38901 - diff: 35.49mlTrain batch 16/16 - 16.3s 39.1ms/batch - loss: 70.38901 - diff: 35.49ml
Test 1.2s: val_loss: 76.10720 - diff: 37.84ml

Epoch 44: current best loss = 72.45180, at epoch 39
Train batch 1/16 - 127.5ms/batch - loss: 53.33878 - diff: 29.30mlTrain batch 2/16 - 121.8ms/batch - loss: 72.26385 - diff: 36.45mlTrain batch 3/16 - 116.5ms/batch - loss: 62.88070 - diff: 34.75mlTrain batch 4/16 - 120.4ms/batch - loss: 72.34560 - diff: 37.20mlTrain batch 5/16 - 116.4ms/batch - loss: 68.37479 - diff: 35.99mlTrain batch 6/16 - 118.2ms/batch - loss: 86.55801 - diff: 38.24mlTrain batch 7/16 - 129.2ms/batch - loss: 80.74551 - diff: 37.16mlTrain batch 8/16 - 124.3ms/batch - loss: 75.93182 - diff: 35.96mlTrain batch 9/16 - 128.3ms/batch - loss: 73.46035 - diff: 35.57mlTrain batch 10/16 - 125.1ms/batch - loss: 70.51172 - diff: 34.82mlTrain batch 11/16 - 122.3ms/batch - loss: 75.02102 - diff: 35.77mlTrain batch 12/16 - 116.4ms/batch - loss: 71.43408 - diff: 35.09mlTrain batch 13/16 - 128.9ms/batch - loss: 70.30552 - diff: 34.87mlTrain batch 14/16 - 116.4ms/batch - loss: 71.43787 - diff: 34.70mlTrain batch 15/16 - 116.1ms/batch - loss: 69.20515 - diff: 34.42mlTrain batch 16/16 - 39.3ms/batch - loss: 70.08028 - diff: 34.27mlTrain batch 16/16 - 16.9s 39.3ms/batch - loss: 70.08028 - diff: 34.27ml
Test 1.2s: val_loss: 89.54368 - diff: 39.43ml

Epoch 45: current best loss = 72.45180, at epoch 39
Going to unfreeze the pretrained weights
Train batch 1/16 - 185.0ms/batch - loss: 73.31476 - diff: 34.43mlTrain batch 2/16 - 170.7ms/batch - loss: 165767.90738 - diff: 1620.17mlTrain batch 3/16 - 185.7ms/batch - loss: 110602.06380 - diff: 1105.56mlTrain batch 4/16 - 163.2ms/batch - loss: 82993.44934 - diff: 843.62mlTrain batch 5/16 - 162.7ms/batch - loss: 66695.91782 - diff: 717.45mlTrain batch 6/16 - 163.1ms/batch - loss: 55627.37496 - diff: 610.46mlTrain batch 7/16 - 171.5ms/batch - loss: 47730.24521 - diff: 536.32mlTrain batch 8/16 - 162.8ms/batch - loss: 41774.46043 - diff: 474.37mlTrain batch 9/16 - 163.0ms/batch - loss: 37204.74199 - diff: 436.24mlTrain batch 10/16 - 162.5ms/batch - loss: 33516.29581 - diff: 400.97mlTrain batch 11/16 - 169.8ms/batch - loss: 30476.05198 - diff: 367.93mlTrain batch 12/16 - 167.6ms/batch - loss: 27961.34974 - diff: 344.32mlTrain batch 13/16 - 192.3ms/batch - loss: 25823.47500 - diff: 322.37mlTrain batch 14/16 - 163.1ms/batch - loss: 23991.30738 - diff: 303.42mlTrain batch 15/16 - 162.5ms/batch - loss: 22418.11795 - diff: 288.66mlTrain batch 16/16 - 54.8ms/batch - loss: 22110.98092 - diff: 285.56mlTrain batch 16/16 - 15.4s 54.8ms/batch - loss: 22110.98092 - diff: 285.56ml
Test 1.2s: val_loss: 172.81942 - diff: 56.76ml

Epoch 46: current best loss = 72.45180, at epoch 39
Train batch 1/16 - 188.3ms/batch - loss: 142.56967 - diff: 57.22mlTrain batch 2/16 - 165.1ms/batch - loss: 165.14644 - diff: 59.06mlTrain batch 3/16 - 165.9ms/batch - loss: 156.57716 - diff: 56.24mlTrain batch 4/16 - 163.4ms/batch - loss: 218.23767 - diff: 59.67mlTrain batch 5/16 - 177.2ms/batch - loss: 212.13257 - diff: 60.08mlTrain batch 6/16 - 162.7ms/batch - loss: 204.04650 - diff: 59.39mlTrain batch 7/16 - 166.9ms/batch - loss: 196.31019 - diff: 58.30mlTrain batch 8/16 - 163.3ms/batch - loss: 180.24666 - diff: 55.63mlTrain batch 9/16 - 173.2ms/batch - loss: 180.20481 - diff: 55.45mlTrain batch 10/16 - 163.3ms/batch - loss: 179.11108 - diff: 55.14mlTrain batch 11/16 - 162.8ms/batch - loss: 173.41879 - diff: 54.62mlTrain batch 12/16 - 166.9ms/batch - loss: 167.79966 - diff: 53.83mlTrain batch 13/16 - 180.2ms/batch - loss: 163.58937 - diff: 53.51mlTrain batch 14/16 - 165.8ms/batch - loss: 159.69671 - diff: 53.09mlTrain batch 15/16 - 162.4ms/batch - loss: 158.44304 - diff: 53.03mlTrain batch 16/16 - 54.7ms/batch - loss: 161.16750 - diff: 52.86mlTrain batch 16/16 - 17.0s 54.7ms/batch - loss: 161.16750 - diff: 52.86ml
Test 1.1s: val_loss: 124.84444 - diff: 47.56ml

Epoch 47: current best loss = 72.45180, at epoch 39
Train batch 1/16 - 180.7ms/batch - loss: 93.14026 - diff: 39.11mlTrain batch 2/16 - 163.1ms/batch - loss: 109.34064 - diff: 44.10mlTrain batch 3/16 - 162.9ms/batch - loss: 101.51743 - diff: 42.91mlTrain batch 4/16 - 162.7ms/batch - loss: 153.85700 - diff: 48.43mlTrain batch 5/16 - 197.4ms/batch - loss: 146.39650 - diff: 48.02mlTrain batch 6/16 - 164.0ms/batch - loss: 156.80908 - diff: 50.55mlTrain batch 7/16 - 166.3ms/batch - loss: 148.07070 - diff: 49.78mlTrain batch 8/16 - 167.6ms/batch - loss: 150.08705 - diff: 50.39mlTrain batch 9/16 - 176.1ms/batch - loss: 142.84330 - diff: 49.48mlTrain batch 10/16 - 167.1ms/batch - loss: 145.65351 - diff: 49.80mlTrain batch 11/16 - 176.0ms/batch - loss: 140.60890 - diff: 48.99mlTrain batch 12/16 - 162.7ms/batch - loss: 137.84096 - diff: 48.48mlTrain batch 13/16 - 162.6ms/batch - loss: 139.05407 - diff: 48.87mlTrain batch 14/16 - 162.8ms/batch - loss: 137.15036 - diff: 48.62mlTrain batch 15/16 - 162.7ms/batch - loss: 144.90517 - diff: 50.14mlTrain batch 16/16 - 54.9ms/batch - loss: 153.69869 - diff: 50.32mlTrain batch 16/16 - 17.3s 54.9ms/batch - loss: 153.69869 - diff: 50.32ml
Test 1.2s: val_loss: 142.11920 - diff: 50.18ml

Epoch 48: current best loss = 72.45180, at epoch 39
Train batch 1/16 - 180.8ms/batch - loss: 133.28979 - diff: 46.92mlTrain batch 2/16 - 172.0ms/batch - loss: 181.56028 - diff: 56.12mlTrain batch 3/16 - 162.9ms/batch - loss: 221.71234 - diff: 65.53mlTrain batch 4/16 - 162.6ms/batch - loss: 200.45314 - diff: 62.88mlTrain batch 5/16 - 162.6ms/batch - loss: 197.26681 - diff: 62.29mlTrain batch 6/16 - 172.9ms/batch - loss: 199.18901 - diff: 63.84mlTrain batch 7/16 - 162.7ms/batch - loss: 186.92591 - diff: 61.74mlTrain batch 8/16 - 162.9ms/batch - loss: 178.37435 - diff: 60.26mlTrain batch 9/16 - 162.6ms/batch - loss: 177.14009 - diff: 59.35mlTrain batch 10/16 - 162.8ms/batch - loss: 172.04703 - diff: 58.44mlTrain batch 11/16 - 162.9ms/batch - loss: 164.24338 - diff: 57.19mlTrain batch 12/16 - 162.7ms/batch - loss: 157.10870 - diff: 55.83mlTrain batch 13/16 - 162.8ms/batch - loss: 158.79230 - diff: 55.89mlTrain batch 14/16 - 166.1ms/batch - loss: 166.35795 - diff: 56.05mlTrain batch 15/16 - 162.7ms/batch - loss: 163.78105 - diff: 55.93mlTrain batch 16/16 - 63.5ms/batch - loss: 176.35700 - diff: 56.18mlTrain batch 16/16 - 15.3s 63.5ms/batch - loss: 176.35700 - diff: 56.18ml
Test 1.2s: val_loss: 146.88192 - diff: 49.88ml

Epoch 49: current best loss = 72.45180, at epoch 39
Train batch 1/16 - 179.6ms/batch - loss: 72.91422 - diff: 37.71mlTrain batch 2/16 - 162.6ms/batch - loss: 109.07312 - diff: 45.82mlTrain batch 3/16 - 170.3ms/batch - loss: 123.13558 - diff: 50.26mlTrain batch 4/16 - 171.6ms/batch - loss: 132.51167 - diff: 52.62mlTrain batch 5/16 - 162.7ms/batch - loss: 130.76848 - diff: 51.36mlTrain batch 6/16 - 163.0ms/batch - loss: 133.70007 - diff: 52.37mlTrain batch 7/16 - 184.8ms/batch - loss: 138.25061 - diff: 53.34mlTrain batch 8/16 - 168.7ms/batch - loss: 156.11052 - diff: 54.44mlTrain batch 9/16 - 164.0ms/batch - loss: 149.98809 - diff: 53.29mlTrain batch 10/16 - 163.8ms/batch - loss: 151.73670 - diff: 53.82mlTrain batch 11/16 - 162.5ms/batch - loss: 146.70719 - diff: 52.91mlTrain batch 12/16 - 176.5ms/batch - loss: 149.25314 - diff: 52.64mlTrain batch 13/16 - 162.8ms/batch - loss: 146.08960 - diff: 52.01mlTrain batch 14/16 - 173.1ms/batch - loss: 151.39443 - diff: 52.93mlTrain batch 15/16 - 162.8ms/batch - loss: 147.95595 - diff: 52.52mlTrain batch 16/16 - 54.9ms/batch - loss: 154.15510 - diff: 52.49mlTrain batch 16/16 - 14.9s 54.9ms/batch - loss: 154.15510 - diff: 52.49ml
Test 1.2s: val_loss: 161.54612 - diff: 46.66ml

Epoch 50: current best loss = 72.45180, at epoch 39
Train batch 1/16 - 186.9ms/batch - loss: 165.87653 - diff: 61.89mlTrain batch 2/16 - 162.6ms/batch - loss: 165.70470 - diff: 60.14mlTrain batch 3/16 - 162.8ms/batch - loss: 161.82217 - diff: 57.78mlTrain batch 4/16 - 163.2ms/batch - loss: 152.96780 - diff: 55.14mlTrain batch 5/16 - 176.0ms/batch - loss: 139.99850 - diff: 51.88mlTrain batch 6/16 - 162.9ms/batch - loss: 130.47195 - diff: 50.40mlTrain batch 7/16 - 176.0ms/batch - loss: 152.00269 - diff: 51.19mlTrain batch 8/16 - 162.5ms/batch - loss: 146.35513 - diff: 50.29mlTrain batch 9/16 - 175.1ms/batch - loss: 135.38333 - diff: 48.19mlTrain batch 10/16 - 165.6ms/batch - loss: 135.08348 - diff: 48.76mlTrain batch 11/16 - 162.6ms/batch - loss: 130.54066 - diff: 47.89mlTrain batch 12/16 - 162.9ms/batch - loss: 129.15154 - diff: 47.75mlTrain batch 13/16 - 166.1ms/batch - loss: 131.44874 - diff: 48.53mlTrain batch 14/16 - 162.7ms/batch - loss: 132.84309 - diff: 48.77mlTrain batch 15/16 - 162.8ms/batch - loss: 131.69867 - diff: 48.47mlTrain batch 16/16 - 60.6ms/batch - loss: 148.32758 - diff: 48.84mlTrain batch 16/16 - 14.8s 60.6ms/batch - loss: 148.32758 - diff: 48.84ml
Test 1.1s: val_loss: 129.61852 - diff: 45.57ml
Epoch    51: reducing learning rate of group 0 to 2.5000e-04.

Epoch 51: current best loss = 72.45180, at epoch 39
Train batch 1/16 - 189.9ms/batch - loss: 160.33240 - diff: 48.11mlTrain batch 2/16 - 175.8ms/batch - loss: 143.84483 - diff: 49.24mlTrain batch 3/16 - 162.5ms/batch - loss: 139.35561 - diff: 49.87mlTrain batch 4/16 - 162.6ms/batch - loss: 139.73271 - diff: 49.71mlTrain batch 5/16 - 162.9ms/batch - loss: 133.91890 - diff: 48.94mlTrain batch 6/16 - 167.6ms/batch - loss: 129.77401 - diff: 48.52mlTrain batch 7/16 - 173.4ms/batch - loss: 126.65512 - diff: 48.29mlTrain batch 8/16 - 162.7ms/batch - loss: 120.85629 - diff: 47.02mlTrain batch 9/16 - 162.7ms/batch - loss: 125.68901 - diff: 47.91mlTrain batch 10/16 - 168.1ms/batch - loss: 141.24073 - diff: 49.06mlTrain batch 11/16 - 162.4ms/batch - loss: 135.70093 - diff: 48.62mlTrain batch 12/16 - 162.7ms/batch - loss: 131.58837 - diff: 48.13mlTrain batch 13/16 - 167.4ms/batch - loss: 130.99148 - diff: 48.14mlTrain batch 14/16 - 175.6ms/batch - loss: 128.68077 - diff: 47.43mlTrain batch 15/16 - 164.4ms/batch - loss: 124.14934 - diff: 46.65mlTrain batch 16/16 - 56.2ms/batch - loss: 130.31453 - diff: 46.76mlTrain batch 16/16 - 17.2s 56.2ms/batch - loss: 130.31453 - diff: 46.76ml
Test 1.3s: val_loss: 110.63775 - diff: 44.87ml

Epoch 52: current best loss = 72.45180, at epoch 39
Train batch 1/16 - 186.6ms/batch - loss: 69.02135 - diff: 37.29mlTrain batch 2/16 - 170.0ms/batch - loss: 83.77831 - diff: 40.88mlTrain batch 3/16 - 162.5ms/batch - loss: 93.78047 - diff: 42.07mlTrain batch 4/16 - 162.6ms/batch - loss: 96.40415 - diff: 43.49mlTrain batch 5/16 - 162.8ms/batch - loss: 95.14618 - diff: 43.23mlTrain batch 6/16 - 169.1ms/batch - loss: 89.95587 - diff: 42.08mlTrain batch 7/16 - 162.3ms/batch - loss: 90.67673 - diff: 42.24mlTrain batch 8/16 - 162.6ms/batch - loss: 102.24826 - diff: 43.59mlTrain batch 9/16 - 162.7ms/batch - loss: 105.82179 - diff: 44.03mlTrain batch 10/16 - 162.9ms/batch - loss: 105.65456 - diff: 44.17mlTrain batch 11/16 - 162.5ms/batch - loss: 119.73457 - diff: 44.73mlTrain batch 12/16 - 165.4ms/batch - loss: 117.17581 - diff: 44.54mlTrain batch 13/16 - 162.8ms/batch - loss: 115.44841 - diff: 43.96mlTrain batch 14/16 - 162.9ms/batch - loss: 116.83414 - diff: 44.35mlTrain batch 15/16 - 162.9ms/batch - loss: 118.65001 - diff: 44.96mlTrain batch 16/16 - 54.8ms/batch - loss: 127.13762 - diff: 45.13mlTrain batch 16/16 - 14.4s 54.8ms/batch - loss: 127.13762 - diff: 45.13ml
Test 1.3s: val_loss: 127.92019 - diff: 46.35ml

Epoch 53: current best loss = 72.45180, at epoch 39
Train batch 1/16 - 180.2ms/batch - loss: 230.03430 - diff: 56.05mlTrain batch 2/16 - 163.4ms/batch - loss: 183.90252 - diff: 55.57mlTrain batch 3/16 - 189.3ms/batch - loss: 179.52614 - diff: 55.92mlTrain batch 4/16 - 162.9ms/batch - loss: 155.02023 - diff: 52.36mlTrain batch 5/16 - 175.8ms/batch - loss: 154.34428 - diff: 51.57mlTrain batch 6/16 - 181.1ms/batch - loss: 138.58082 - diff: 48.55mlTrain batch 7/16 - 177.3ms/batch - loss: 128.50763 - diff: 47.32mlTrain batch 8/16 - 162.8ms/batch - loss: 122.28392 - diff: 46.42mlTrain batch 9/16 - 168.1ms/batch - loss: 132.73023 - diff: 48.39mlTrain batch 10/16 - 166.8ms/batch - loss: 135.34420 - diff: 48.87mlTrain batch 11/16 - 163.1ms/batch - loss: 132.63223 - diff: 48.80mlTrain batch 12/16 - 162.8ms/batch - loss: 129.49630 - diff: 48.08mlTrain batch 13/16 - 162.9ms/batch - loss: 136.25139 - diff: 49.48mlTrain batch 14/16 - 180.2ms/batch - loss: 135.15833 - diff: 49.55mlTrain batch 15/16 - 164.9ms/batch - loss: 135.61521 - diff: 49.83mlTrain batch 16/16 - 55.0ms/batch - loss: 138.15477 - diff: 49.63mlTrain batch 16/16 - 16.7s 55.0ms/batch - loss: 138.15477 - diff: 49.63ml
Test 1.1s: val_loss: 141.32363 - diff: 46.09ml

Epoch 54: current best loss = 72.45180, at epoch 39
Train batch 1/16 - 180.7ms/batch - loss: 85.03482 - diff: 41.52mlTrain batch 2/16 - 179.0ms/batch - loss: 82.14744 - diff: 40.39mlTrain batch 3/16 - 166.2ms/batch - loss: 90.94310 - diff: 42.00mlTrain batch 4/16 - 162.9ms/batch - loss: 93.73837 - diff: 43.65mlTrain batch 5/16 - 205.6ms/batch - loss: 106.45536 - diff: 46.30mlTrain batch 6/16 - 165.2ms/batch - loss: 131.55063 - diff: 50.31mlTrain batch 7/16 - 162.6ms/batch - loss: 139.42633 - diff: 52.20mlTrain batch 8/16 - 163.4ms/batch - loss: 132.74021 - diff: 50.95mlTrain batch 9/16 - 163.1ms/batch - loss: 132.00271 - diff: 50.61mlTrain batch 10/16 - 178.6ms/batch - loss: 133.59682 - diff: 50.97mlTrain batch 11/16 - 169.9ms/batch - loss: 134.88293 - diff: 51.60mlTrain batch 12/16 - 163.1ms/batch - loss: 143.68718 - diff: 52.12mlTrain batch 13/16 - 178.9ms/batch - loss: 136.81186 - diff: 50.66mlTrain batch 14/16 - 167.6ms/batch - loss: 135.35529 - diff: 50.39mlTrain batch 15/16 - 163.1ms/batch - loss: 143.62522 - diff: 51.17mlTrain batch 16/16 - 65.5ms/batch - loss: 149.53091 - diff: 51.13mlTrain batch 16/16 - 16.0s 65.5ms/batch - loss: 149.53091 - diff: 51.13ml
Test 1.1s: val_loss: 128.68201 - diff: 45.20ml

Epoch 55: current best loss = 72.45180, at epoch 39
Train batch 1/16 - 180.7ms/batch - loss: 76.02505 - diff: 41.47mlTrain batch 2/16 - 162.7ms/batch - loss: 112.19671 - diff: 47.48mlTrain batch 3/16 - 178.5ms/batch - loss: 121.76327 - diff: 48.50mlTrain batch 4/16 - 162.7ms/batch - loss: 146.83390 - diff: 49.84mlTrain batch 5/16 - 176.2ms/batch - loss: 142.68344 - diff: 50.19mlTrain batch 6/16 - 170.4ms/batch - loss: 136.13748 - diff: 49.40mlTrain batch 7/16 - 162.7ms/batch - loss: 126.49371 - diff: 48.00mlTrain batch 8/16 - 163.1ms/batch - loss: 125.66158 - diff: 47.69mlTrain batch 9/16 - 163.0ms/batch - loss: 118.74504 - diff: 46.40mlTrain batch 10/16 - 163.1ms/batch - loss: 116.16053 - diff: 45.94mlTrain batch 11/16 - 169.6ms/batch - loss: 120.69546 - diff: 46.57mlTrain batch 12/16 - 162.5ms/batch - loss: 121.45544 - diff: 47.28mlTrain batch 13/16 - 181.9ms/batch - loss: 119.67134 - diff: 46.79mlTrain batch 14/16 - 163.2ms/batch - loss: 118.44187 - diff: 46.86mlTrain batch 15/16 - 162.9ms/batch - loss: 121.55914 - diff: 46.98mlTrain batch 16/16 - 54.9ms/batch - loss: 123.24755 - diff: 46.79mlTrain batch 16/16 - 16.7s 54.9ms/batch - loss: 123.24755 - diff: 46.79ml
Test 1.3s: val_loss: 122.17227 - diff: 43.54ml

Epoch 56: current best loss = 72.45180, at epoch 39
Train batch 1/16 - 180.6ms/batch - loss: 102.70068 - diff: 42.58mlTrain batch 2/16 - 162.7ms/batch - loss: 163.20799 - diff: 51.34mlTrain batch 3/16 - 177.5ms/batch - loss: 143.15281 - diff: 47.70mlTrain batch 4/16 - 167.0ms/batch - loss: 123.01410 - diff: 45.00mlTrain batch 5/16 - 163.4ms/batch - loss: 118.37057 - diff: 44.94mlTrain batch 6/16 - 163.1ms/batch - loss: 114.67108 - diff: 44.86mlTrain batch 7/16 - 204.0ms/batch - loss: 119.33810 - diff: 45.76mlTrain batch 8/16 - 167.9ms/batch - loss: 121.49295 - diff: 46.28mlTrain batch 9/16 - 180.9ms/batch - loss: 116.00999 - diff: 45.12mlTrain batch 10/16 - 169.5ms/batch - loss: 130.76229 - diff: 45.84mlTrain batch 11/16 - 169.0ms/batch - loss: 125.13668 - diff: 44.99mlTrain batch 12/16 - 168.3ms/batch - loss: 121.08604 - diff: 44.49mlTrain batch 13/16 - 163.1ms/batch - loss: 120.59104 - diff: 44.74mlTrain batch 14/16 - 172.7ms/batch - loss: 120.19758 - diff: 44.95mlTrain batch 15/16 - 162.6ms/batch - loss: 116.57031 - diff: 44.45mlTrain batch 16/16 - 55.0ms/batch - loss: 123.64589 - diff: 44.57mlTrain batch 16/16 - 16.1s 55.0ms/batch - loss: 123.64589 - diff: 44.57ml
Test 1.3s: val_loss: 128.96502 - diff: 44.99ml

Epoch 57: current best loss = 72.45180, at epoch 39
Train batch 1/16 - 180.6ms/batch - loss: 108.35210 - diff: 39.96mlTrain batch 2/16 - 168.5ms/batch - loss: 151.19992 - diff: 49.07mlTrain batch 3/16 - 169.0ms/batch - loss: 139.47933 - diff: 48.38mlTrain batch 4/16 - 162.1ms/batch - loss: 140.01733 - diff: 49.07mlTrain batch 5/16 - 163.0ms/batch - loss: 134.38057 - diff: 48.22mlTrain batch 6/16 - 162.9ms/batch - loss: 153.68362 - diff: 49.35mlTrain batch 7/16 - 163.0ms/batch - loss: 139.23118 - diff: 46.86mlTrain batch 8/16 - 164.6ms/batch - loss: 136.35539 - diff: 46.90mlTrain batch 9/16 - 162.9ms/batch - loss: 128.21496 - diff: 45.87mlTrain batch 10/16 - 164.1ms/batch - loss: 124.43748 - diff: 45.58mlTrain batch 11/16 - 163.0ms/batch - loss: 121.84711 - diff: 45.37mlTrain batch 12/16 - 174.2ms/batch - loss: 117.57632 - diff: 44.73mlTrain batch 13/16 - 162.9ms/batch - loss: 120.62344 - diff: 45.02mlTrain batch 14/16 - 163.2ms/batch - loss: 120.95053 - diff: 45.26mlTrain batch 15/16 - 162.8ms/batch - loss: 121.58183 - diff: 45.61mlTrain batch 16/16 - 67.6ms/batch - loss: 132.02687 - diff: 45.75mlTrain batch 16/16 - 16.5s 67.6ms/batch - loss: 132.02687 - diff: 45.75ml
Test 1.2s: val_loss: 111.06260 - diff: 42.75ml

Epoch 58: current best loss = 72.45180, at epoch 39
Train batch 1/16 - 180.8ms/batch - loss: 106.20557 - diff: 46.90mlTrain batch 2/16 - 174.2ms/batch - loss: 123.08624 - diff: 50.24mlTrain batch 3/16 - 162.8ms/batch - loss: 119.51011 - diff: 50.24mlTrain batch 4/16 - 168.9ms/batch - loss: 144.27795 - diff: 50.69mlTrain batch 5/16 - 181.0ms/batch - loss: 144.07992 - diff: 50.93mlTrain batch 6/16 - 168.3ms/batch - loss: 139.81415 - diff: 50.69mlTrain batch 7/16 - 162.7ms/batch - loss: 134.72366 - diff: 50.26mlTrain batch 8/16 - 196.1ms/batch - loss: 136.40398 - diff: 50.20mlTrain batch 9/16 - 175.9ms/batch - loss: 130.13722 - diff: 48.86mlTrain batch 10/16 - 167.7ms/batch - loss: 121.20186 - diff: 46.82mlTrain batch 11/16 - 162.8ms/batch - loss: 117.99555 - diff: 46.27mlTrain batch 12/16 - 170.8ms/batch - loss: 112.88451 - diff: 45.33mlTrain batch 13/16 - 163.1ms/batch - loss: 113.85797 - diff: 45.37mlTrain batch 14/16 - 163.2ms/batch - loss: 114.20841 - diff: 45.43mlTrain batch 15/16 - 162.7ms/batch - loss: 112.77981 - diff: 45.26mlTrain batch 16/16 - 54.8ms/batch - loss: 114.45686 - diff: 45.11mlTrain batch 16/16 - 16.5s 54.8ms/batch - loss: 114.45686 - diff: 45.11ml
Test 1.1s: val_loss: 107.75752 - diff: 42.72ml

Epoch 59: current best loss = 72.45180, at epoch 39
Train batch 1/16 - 180.9ms/batch - loss: 156.21577 - diff: 52.59mlTrain batch 2/16 - 162.8ms/batch - loss: 131.06992 - diff: 51.44mlTrain batch 3/16 - 162.8ms/batch - loss: 117.86210 - diff: 48.47mlTrain batch 4/16 - 162.7ms/batch - loss: 114.83319 - diff: 46.32mlTrain batch 5/16 - 175.3ms/batch - loss: 111.25455 - diff: 45.26mlTrain batch 6/16 - 162.8ms/batch - loss: 109.01668 - diff: 44.71mlTrain batch 7/16 - 162.7ms/batch - loss: 124.50260 - diff: 44.40mlTrain batch 8/16 - 162.8ms/batch - loss: 121.28347 - diff: 44.60mlTrain batch 9/16 - 162.8ms/batch - loss: 121.28805 - diff: 44.82mlTrain batch 10/16 - 162.9ms/batch - loss: 118.39107 - diff: 44.76mlTrain batch 11/16 - 162.7ms/batch - loss: 121.41956 - diff: 44.70mlTrain batch 12/16 - 162.8ms/batch - loss: 119.10888 - diff: 44.40mlTrain batch 13/16 - 171.6ms/batch - loss: 118.71358 - diff: 44.83mlTrain batch 14/16 - 184.9ms/batch - loss: 116.95642 - diff: 44.47mlTrain batch 15/16 - 168.9ms/batch - loss: 114.60179 - diff: 44.06mlTrain batch 16/16 - 61.4ms/batch - loss: 115.82745 - diff: 43.84mlTrain batch 16/16 - 15.7s 61.4ms/batch - loss: 115.82745 - diff: 43.84ml
Test 1.2s: val_loss: 98.10149 - diff: 41.32ml

Epoch 60: current best loss = 72.45180, at epoch 39
Train batch 1/16 - 180.7ms/batch - loss: 122.22814 - diff: 48.61mlTrain batch 2/16 - 162.8ms/batch - loss: 133.74578 - diff: 51.03mlTrain batch 3/16 - 162.8ms/batch - loss: 129.87430 - diff: 50.89mlTrain batch 4/16 - 162.7ms/batch - loss: 128.29572 - diff: 49.34mlTrain batch 5/16 - 163.1ms/batch - loss: 120.46320 - diff: 48.19mlTrain batch 6/16 - 164.9ms/batch - loss: 120.78736 - diff: 47.74mlTrain batch 7/16 - 179.2ms/batch - loss: 139.83980 - diff: 48.31mlTrain batch 8/16 - 163.1ms/batch - loss: 128.63135 - diff: 46.18mlTrain batch 9/16 - 162.9ms/batch - loss: 121.61157 - diff: 45.04mlTrain batch 10/16 - 162.8ms/batch - loss: 124.50419 - diff: 46.22mlTrain batch 11/16 - 165.7ms/batch - loss: 119.71982 - diff: 45.28mlTrain batch 12/16 - 162.9ms/batch - loss: 116.44398 - diff: 44.87mlTrain batch 13/16 - 162.9ms/batch - loss: 111.31048 - diff: 43.95mlTrain batch 14/16 - 168.1ms/batch - loss: 111.47090 - diff: 43.86mlTrain batch 15/16 - 180.0ms/batch - loss: 110.75794 - diff: 43.80mlTrain batch 16/16 - 60.4ms/batch - loss: 115.76951 - diff: 43.74mlTrain batch 16/16 - 17.4s 60.4ms/batch - loss: 115.76951 - diff: 43.74ml
Test 1.2s: val_loss: 124.35061 - diff: 42.38ml

Epoch 61: current best loss = 72.45180, at epoch 39
Train batch 1/16 - 180.8ms/batch - loss: 74.33454 - diff: 41.34mlTrain batch 2/16 - 177.5ms/batch - loss: 156.14557 - diff: 47.47mlTrain batch 3/16 - 162.9ms/batch - loss: 139.49914 - diff: 47.90mlTrain batch 4/16 - 163.1ms/batch - loss: 137.66521 - diff: 49.14mlTrain batch 5/16 - 180.8ms/batch - loss: 134.47984 - diff: 49.28mlTrain batch 6/16 - 178.5ms/batch - loss: 130.88505 - diff: 47.69mlTrain batch 7/16 - 162.8ms/batch - loss: 125.81549 - diff: 47.15mlTrain batch 8/16 - 163.0ms/batch - loss: 123.82212 - diff: 46.50mlTrain batch 9/16 - 184.0ms/batch - loss: 118.58724 - diff: 45.75mlTrain batch 10/16 - 166.8ms/batch - loss: 114.71564 - diff: 44.79mlTrain batch 11/16 - 177.4ms/batch - loss: 111.93990 - diff: 44.79mlTrain batch 12/16 - 163.2ms/batch - loss: 112.76333 - diff: 44.99mlTrain batch 13/16 - 184.7ms/batch - loss: 114.81420 - diff: 45.78mlTrain batch 14/16 - 163.1ms/batch - loss: 111.76648 - diff: 45.07mlTrain batch 15/16 - 180.9ms/batch - loss: 109.91516 - diff: 44.63mlTrain batch 16/16 - 70.2ms/batch - loss: 114.15156 - diff: 44.59mlTrain batch 16/16 - 16.9s 70.2ms/batch - loss: 114.15156 - diff: 44.59ml
Test 1.3s: val_loss: 102.44797 - diff: 40.47ml
Epoch    62: reducing learning rate of group 0 to 1.2500e-04.

Epoch 62: current best loss = 72.45180, at epoch 39
Train batch 1/16 - 181.4ms/batch - loss: 113.90001 - diff: 43.76mlTrain batch 2/16 - 163.5ms/batch - loss: 116.11325 - diff: 47.10mlTrain batch 3/16 - 180.8ms/batch - loss: 113.99315 - diff: 46.59mlTrain batch 4/16 - 172.7ms/batch - loss: 109.61928 - diff: 44.92mlTrain batch 5/16 - 162.9ms/batch - loss: 104.99975 - diff: 44.32mlTrain batch 6/16 - 169.0ms/batch - loss: 107.68895 - diff: 44.78mlTrain batch 7/16 - 162.7ms/batch - loss: 108.20457 - diff: 45.20mlTrain batch 8/16 - 163.8ms/batch - loss: 105.80566 - diff: 44.73mlTrain batch 9/16 - 168.6ms/batch - loss: 102.07634 - diff: 43.87mlTrain batch 10/16 - 163.6ms/batch - loss: 98.13607 - diff: 42.95mlTrain batch 11/16 - 175.5ms/batch - loss: 97.79483 - diff: 42.95mlTrain batch 12/16 - 167.3ms/batch - loss: 93.76607 - diff: 41.87mlTrain batch 13/16 - 174.3ms/batch - loss: 94.86691 - diff: 42.18mlTrain batch 14/16 - 176.9ms/batch - loss: 94.74965 - diff: 42.37mlTrain batch 15/16 - 163.0ms/batch - loss: 93.84608 - diff: 42.11mlTrain batch 16/16 - 54.9ms/batch - loss: 153.40846 - diff: 43.16mlTrain batch 16/16 - 16.0s 54.9ms/batch - loss: 153.40846 - diff: 43.16ml
Test 1.2s: val_loss: 110.11458 - diff: 41.37ml

Epoch 63: current best loss = 72.45180, at epoch 39
Train batch 1/16 - 183.2ms/batch - loss: 84.92404 - diff: 36.58mlTrain batch 2/16 - 187.7ms/batch - loss: 94.32299 - diff: 41.04mlTrain batch 3/16 - 162.6ms/batch - loss: 107.61914 - diff: 43.93mlTrain batch 4/16 - 162.8ms/batch - loss: 109.65162 - diff: 45.83mlTrain batch 5/16 - 180.7ms/batch - loss: 109.29800 - diff: 46.01mlTrain batch 6/16 - 166.0ms/batch - loss: 118.10700 - diff: 47.42mlTrain batch 7/16 - 180.6ms/batch - loss: 118.61969 - diff: 47.96mlTrain batch 8/16 - 167.4ms/batch - loss: 115.09664 - diff: 46.99mlTrain batch 9/16 - 185.7ms/batch - loss: 115.07308 - diff: 46.93mlTrain batch 10/16 - 171.7ms/batch - loss: 110.67160 - diff: 46.05mlTrain batch 11/16 - 163.0ms/batch - loss: 120.76236 - diff: 46.34mlTrain batch 12/16 - 163.6ms/batch - loss: 114.87639 - diff: 44.91mlTrain batch 13/16 - 166.8ms/batch - loss: 110.88186 - diff: 44.30mlTrain batch 14/16 - 163.0ms/batch - loss: 106.56834 - diff: 43.24mlTrain batch 15/16 - 176.1ms/batch - loss: 106.22923 - diff: 43.26mlTrain batch 16/16 - 54.9ms/batch - loss: 106.90209 - diff: 43.03mlTrain batch 16/16 - 17.9s 54.9ms/batch - loss: 106.90209 - diff: 43.03ml
Test 1.2s: val_loss: 94.53707 - diff: 40.66ml

Epoch 64: current best loss = 72.45180, at epoch 39
Train batch 1/16 - 182.5ms/batch - loss: 92.48641 - diff: 38.25mlTrain batch 2/16 - 162.5ms/batch - loss: 113.32182 - diff: 42.99mlTrain batch 3/16 - 162.7ms/batch - loss: 93.54155 - diff: 39.52mlTrain batch 4/16 - 167.2ms/batch - loss: 89.16776 - diff: 39.96mlTrain batch 5/16 - 162.9ms/batch - loss: 90.19707 - diff: 40.17mlTrain batch 6/16 - 163.0ms/batch - loss: 100.54366 - diff: 42.03mlTrain batch 7/16 - 163.0ms/batch - loss: 96.94741 - diff: 41.24mlTrain batch 8/16 - 173.9ms/batch - loss: 95.87557 - diff: 41.25mlTrain batch 9/16 - 162.6ms/batch - loss: 100.78644 - diff: 41.55mlTrain batch 10/16 - 179.3ms/batch - loss: 101.06825 - diff: 41.89mlTrain batch 11/16 - 181.8ms/batch - loss: 100.70239 - diff: 41.81mlTrain batch 12/16 - 173.5ms/batch - loss: 96.90491 - diff: 41.05mlTrain batch 13/16 - 163.0ms/batch - loss: 94.99516 - diff: 40.95mlTrain batch 14/16 - 163.1ms/batch - loss: 95.65112 - diff: 41.10mlTrain batch 15/16 - 163.0ms/batch - loss: 103.76469 - diff: 41.54mlTrain batch 16/16 - 56.1ms/batch - loss: 104.70491 - diff: 41.39mlTrain batch 16/16 - 16.7s 56.1ms/batch - loss: 104.70491 - diff: 41.39ml
Test 1.3s: val_loss: 105.92248 - diff: 39.93ml

Epoch 65: current best loss = 72.45180, at epoch 39
Train batch 1/16 - 180.7ms/batch - loss: 78.50848 - diff: 37.00mlTrain batch 2/16 - 166.4ms/batch - loss: 118.84656 - diff: 47.24mlTrain batch 3/16 - 176.9ms/batch - loss: 93.12186 - diff: 40.06mlTrain batch 4/16 - 163.1ms/batch - loss: 99.64667 - diff: 41.21mlTrain batch 5/16 - 162.5ms/batch - loss: 91.53842 - diff: 39.47mlTrain batch 6/16 - 162.9ms/batch - loss: 84.91233 - diff: 38.18mlTrain batch 7/16 - 168.9ms/batch - loss: 85.41461 - diff: 38.88mlTrain batch 8/16 - 163.2ms/batch - loss: 82.83047 - diff: 38.77mlTrain batch 9/16 - 179.1ms/batch - loss: 80.47972 - diff: 38.50mlTrain batch 10/16 - 164.5ms/batch - loss: 100.24011 - diff: 40.14mlTrain batch 11/16 - 178.6ms/batch - loss: 103.38479 - diff: 40.84mlTrain batch 12/16 - 167.7ms/batch - loss: 103.84303 - diff: 41.25mlTrain batch 13/16 - 163.1ms/batch - loss: 105.71459 - diff: 42.25mlTrain batch 14/16 - 162.9ms/batch - loss: 103.58012 - diff: 42.17mlTrain batch 15/16 - 166.8ms/batch - loss: 99.74437 - diff: 41.21mlTrain batch 16/16 - 54.9ms/batch - loss: 106.35844 - diff: 41.30mlTrain batch 16/16 - 16.4s 54.9ms/batch - loss: 106.35844 - diff: 41.30ml
Test 1.0s: val_loss: 96.09827 - diff: 39.19ml

Epoch 66: current best loss = 72.45180, at epoch 39
Train batch 1/16 - 176.8ms/batch - loss: 107.81555 - diff: 44.29mlTrain batch 2/16 - 162.5ms/batch - loss: 88.76550 - diff: 40.92mlTrain batch 3/16 - 162.5ms/batch - loss: 93.55052 - diff: 41.91mlTrain batch 4/16 - 163.0ms/batch - loss: 89.79464 - diff: 40.12mlTrain batch 5/16 - 163.0ms/batch - loss: 83.39888 - diff: 38.89mlTrain batch 6/16 - 162.7ms/batch - loss: 105.85877 - diff: 40.28mlTrain batch 7/16 - 162.7ms/batch - loss: 107.65347 - diff: 41.50mlTrain batch 8/16 - 163.0ms/batch - loss: 108.50229 - diff: 42.31mlTrain batch 9/16 - 162.6ms/batch - loss: 104.65866 - diff: 42.17mlTrain batch 10/16 - 162.8ms/batch - loss: 103.36703 - diff: 41.33mlTrain batch 11/16 - 167.1ms/batch - loss: 107.61297 - diff: 41.98mlTrain batch 12/16 - 171.8ms/batch - loss: 105.67329 - diff: 41.97mlTrain batch 13/16 - 175.9ms/batch - loss: 101.87342 - diff: 41.31mlTrain batch 14/16 - 163.0ms/batch - loss: 100.40935 - diff: 41.18mlTrain batch 15/16 - 162.7ms/batch - loss: 98.96515 - diff: 41.13mlTrain batch 16/16 - 54.9ms/batch - loss: 99.37454 - diff: 40.90mlTrain batch 16/16 - 16.1s 54.9ms/batch - loss: 99.37454 - diff: 40.90ml
Test 1.2s: val_loss: 83.54488 - diff: 38.73ml

Epoch 67: current best loss = 72.45180, at epoch 39
Train batch 1/16 - 180.6ms/batch - loss: 167.12447 - diff: 51.20mlTrain batch 2/16 - 177.7ms/batch - loss: 115.44031 - diff: 43.86mlTrain batch 3/16 - 180.8ms/batch - loss: 112.67169 - diff: 44.70mlTrain batch 4/16 - 173.7ms/batch - loss: 109.69623 - diff: 44.86mlTrain batch 5/16 - 177.4ms/batch - loss: 106.40131 - diff: 44.28mlTrain batch 6/16 - 163.7ms/batch - loss: 104.96841 - diff: 44.25mlTrain batch 7/16 - 175.7ms/batch - loss: 108.41226 - diff: 44.71mlTrain batch 8/16 - 163.2ms/batch - loss: 100.47140 - diff: 42.93mlTrain batch 9/16 - 169.1ms/batch - loss: 94.42502 - diff: 41.39mlTrain batch 10/16 - 163.4ms/batch - loss: 92.16810 - diff: 40.96mlTrain batch 11/16 - 181.0ms/batch - loss: 91.31538 - diff: 40.88mlTrain batch 12/16 - 168.0ms/batch - loss: 101.72965 - diff: 41.34mlTrain batch 13/16 - 162.8ms/batch - loss: 98.70439 - diff: 40.69mlTrain batch 14/16 - 162.9ms/batch - loss: 99.32607 - diff: 40.90mlTrain batch 15/16 - 163.2ms/batch - loss: 101.87977 - diff: 41.81mlTrain batch 16/16 - 54.8ms/batch - loss: 104.48583 - diff: 41.66mlTrain batch 16/16 - 16.9s 54.8ms/batch - loss: 104.48583 - diff: 41.66ml
Test 1.2s: val_loss: 87.24202 - diff: 38.05ml

Epoch 68: current best loss = 72.45180, at epoch 39
Train batch 1/16 - 180.6ms/batch - loss: 82.61788 - diff: 39.52mlTrain batch 2/16 - 164.1ms/batch - loss: 81.18365 - diff: 39.69mlTrain batch 3/16 - 177.1ms/batch - loss: 85.25870 - diff: 39.85mlTrain batch 4/16 - 162.8ms/batch - loss: 81.07830 - diff: 38.08mlTrain batch 5/16 - 186.9ms/batch - loss: 82.54789 - diff: 38.51mlTrain batch 6/16 - 166.7ms/batch - loss: 106.18483 - diff: 40.54mlTrain batch 7/16 - 192.4ms/batch - loss: 104.36602 - diff: 41.14mlTrain batch 8/16 - 175.7ms/batch - loss: 103.28269 - diff: 41.41mlTrain batch 9/16 - 184.1ms/batch - loss: 98.88876 - diff: 40.91mlTrain batch 10/16 - 177.3ms/batch - loss: 97.56567 - diff: 41.09mlTrain batch 11/16 - 181.3ms/batch - loss: 93.39923 - diff: 40.53mlTrain batch 12/16 - 179.7ms/batch - loss: 90.43638 - diff: 40.08mlTrain batch 13/16 - 166.9ms/batch - loss: 90.57808 - diff: 40.28mlTrain batch 14/16 - 167.7ms/batch - loss: 95.61767 - diff: 41.21mlTrain batch 15/16 - 163.6ms/batch - loss: 97.39652 - diff: 41.59mlTrain batch 16/16 - 56.5ms/batch - loss: 102.00170 - diff: 41.64mlTrain batch 16/16 - 18.1s 56.5ms/batch - loss: 102.00170 - diff: 41.64ml
Test 1.2s: val_loss: 78.64575 - diff: 37.80ml

Epoch 69: current best loss = 72.45180, at epoch 39
Train batch 1/16 - 180.7ms/batch - loss: 67.73087 - diff: 37.20mlTrain batch 2/16 - 168.9ms/batch - loss: 92.51000 - diff: 40.45mlTrain batch 3/16 - 184.1ms/batch - loss: 92.07562 - diff: 40.47mlTrain batch 4/16 - 169.0ms/batch - loss: 87.17801 - diff: 39.68mlTrain batch 5/16 - 167.4ms/batch - loss: 77.97081 - diff: 37.40mlTrain batch 6/16 - 163.5ms/batch - loss: 77.70624 - diff: 37.70mlTrain batch 7/16 - 162.7ms/batch - loss: 74.72831 - diff: 37.24mlTrain batch 8/16 - 163.5ms/batch - loss: 74.22992 - diff: 37.11mlTrain batch 9/16 - 162.9ms/batch - loss: 90.29818 - diff: 38.83mlTrain batch 10/16 - 162.8ms/batch - loss: 90.71082 - diff: 38.76mlTrain batch 11/16 - 163.0ms/batch - loss: 89.26389 - diff: 38.49mlTrain batch 12/16 - 164.5ms/batch - loss: 91.28434 - diff: 39.54mlTrain batch 13/16 - 171.4ms/batch - loss: 95.16779 - diff: 40.18mlTrain batch 14/16 - 162.6ms/batch - loss: 96.69738 - diff: 40.82mlTrain batch 15/16 - 163.0ms/batch - loss: 95.72426 - diff: 40.71mlTrain batch 16/16 - 54.8ms/batch - loss: 104.88981 - diff: 40.79mlTrain batch 16/16 - 15.8s 54.8ms/batch - loss: 104.88981 - diff: 40.79ml
Test 1.2s: val_loss: 126.01728 - diff: 45.65ml

Epoch 70: current best loss = 72.45180, at epoch 39
Train batch 1/16 - 176.3ms/batch - loss: 143.87015 - diff: 53.58mlTrain batch 2/16 - 163.3ms/batch - loss: 111.69132 - diff: 47.46mlTrain batch 3/16 - 180.1ms/batch - loss: 100.90292 - diff: 45.12mlTrain batch 4/16 - 167.9ms/batch - loss: 100.31768 - diff: 44.22mlTrain batch 5/16 - 163.0ms/batch - loss: 88.11611 - diff: 40.93mlTrain batch 6/16 - 176.7ms/batch - loss: 105.30363 - diff: 40.57mlTrain batch 7/16 - 163.2ms/batch - loss: 108.84452 - diff: 41.22mlTrain batch 8/16 - 163.1ms/batch - loss: 102.87236 - diff: 40.32mlTrain batch 9/16 - 179.8ms/batch - loss: 97.66475 - diff: 39.49mlTrain batch 10/16 - 169.8ms/batch - loss: 98.34060 - diff: 40.31mlTrain batch 11/16 - 162.9ms/batch - loss: 98.49554 - diff: 40.38mlTrain batch 12/16 - 165.2ms/batch - loss: 96.67720 - diff: 40.13mlTrain batch 13/16 - 180.9ms/batch - loss: 94.25240 - diff: 39.82mlTrain batch 14/16 - 169.8ms/batch - loss: 99.19297 - diff: 40.78mlTrain batch 15/16 - 163.0ms/batch - loss: 101.61043 - diff: 41.28mlTrain batch 16/16 - 64.3ms/batch - loss: 105.19574 - diff: 41.32mlTrain batch 16/16 - 17.0s 64.3ms/batch - loss: 105.19574 - diff: 41.32ml
Test 1.0s: val_loss: 104.23093 - diff: 36.83ml

Epoch 71: current best loss = 72.45180, at epoch 39
Train batch 1/16 - 180.6ms/batch - loss: 62.35852 - diff: 35.31mlTrain batch 2/16 - 162.5ms/batch - loss: 82.48888 - diff: 40.28mlTrain batch 3/16 - 167.0ms/batch - loss: 75.44572 - diff: 38.70mlTrain batch 4/16 - 162.8ms/batch - loss: 71.20552 - diff: 37.20mlTrain batch 5/16 - 162.9ms/batch - loss: 73.01411 - diff: 38.10mlTrain batch 6/16 - 162.7ms/batch - loss: 80.22839 - diff: 39.17mlTrain batch 7/16 - 168.1ms/batch - loss: 104.28300 - diff: 41.29mlTrain batch 8/16 - 174.4ms/batch - loss: 100.30884 - diff: 40.55mlTrain batch 9/16 - 162.8ms/batch - loss: 98.58311 - diff: 40.18mlTrain batch 10/16 - 163.1ms/batch - loss: 94.36173 - diff: 39.79mlTrain batch 11/16 - 179.7ms/batch - loss: 97.52564 - diff: 41.04mlTrain batch 12/16 - 163.1ms/batch - loss: 99.63117 - diff: 41.61mlTrain batch 13/16 - 162.9ms/batch - loss: 99.61625 - diff: 41.91mlTrain batch 14/16 - 162.9ms/batch - loss: 97.60592 - diff: 41.70mlTrain batch 15/16 - 162.9ms/batch - loss: 95.03246 - diff: 40.61mlTrain batch 16/16 - 54.9ms/batch - loss: 95.82193 - diff: 40.41mlTrain batch 16/16 - 15.8s 54.9ms/batch - loss: 95.82193 - diff: 40.41ml
Test 1.0s: val_loss: 140.49029 - diff: 47.97ml

Epoch 72: current best loss = 72.45180, at epoch 39
Train batch 1/16 - 186.2ms/batch - loss: 286.04984 - diff: 53.72mlTrain batch 2/16 - 164.2ms/batch - loss: 174.50283 - diff: 45.72mlTrain batch 3/16 - 162.7ms/batch - loss: 161.65537 - diff: 46.33mlTrain batch 4/16 - 165.7ms/batch - loss: 134.77402 - diff: 43.54mlTrain batch 5/16 - 181.2ms/batch - loss: 115.99606 - diff: 40.56mlTrain batch 6/16 - 170.4ms/batch - loss: 112.01024 - diff: 40.73mlTrain batch 7/16 - 180.8ms/batch - loss: 105.58076 - diff: 40.03mlTrain batch 8/16 - 164.8ms/batch - loss: 103.15001 - diff: 40.38mlTrain batch 9/16 - 162.7ms/batch - loss: 107.01986 - diff: 41.87mlTrain batch 10/16 - 162.8ms/batch - loss: 106.81374 - diff: 42.46mlTrain batch 11/16 - 163.3ms/batch - loss: 112.45473 - diff: 43.21mlTrain batch 12/16 - 162.8ms/batch - loss: 109.44187 - diff: 42.99mlTrain batch 13/16 - 183.6ms/batch - loss: 106.40839 - diff: 42.66mlTrain batch 14/16 - 171.9ms/batch - loss: 105.34373 - diff: 42.62mlTrain batch 15/16 - 177.5ms/batch - loss: 102.38874 - diff: 42.18mlTrain batch 16/16 - 56.5ms/batch - loss: 102.24148 - diff: 41.88mlTrain batch 16/16 - 16.7s 56.5ms/batch - loss: 102.24148 - diff: 41.88ml
Test 1.2s: val_loss: 93.65421 - diff: 37.75ml
Epoch    73: reducing learning rate of group 0 to 6.2500e-05.

Epoch 73: current best loss = 72.45180, at epoch 39
Train batch 1/16 - 175.8ms/batch - loss: 254.57043 - diff: 53.08mlTrain batch 2/16 - 163.0ms/batch - loss: 155.38775 - diff: 42.92mlTrain batch 3/16 - 175.7ms/batch - loss: 124.17295 - diff: 40.25mlTrain batch 4/16 - 162.8ms/batch - loss: 109.57236 - diff: 38.64mlTrain batch 5/16 - 182.6ms/batch - loss: 102.10476 - diff: 38.48mlTrain batch 6/16 - 165.8ms/batch - loss: 101.29978 - diff: 40.08mlTrain batch 7/16 - 166.8ms/batch - loss: 97.06669 - diff: 39.21mlTrain batch 8/16 - 170.4ms/batch - loss: 93.06468 - diff: 38.92mlTrain batch 9/16 - 166.9ms/batch - loss: 91.44987 - diff: 39.27mlTrain batch 10/16 - 162.9ms/batch - loss: 89.13810 - diff: 38.88mlTrain batch 11/16 - 163.0ms/batch - loss: 89.39300 - diff: 38.84mlTrain batch 12/16 - 163.1ms/batch - loss: 86.77903 - diff: 38.50mlTrain batch 13/16 - 163.0ms/batch - loss: 86.37800 - diff: 38.56mlTrain batch 14/16 - 169.6ms/batch - loss: 84.23918 - diff: 37.97mlTrain batch 15/16 - 163.4ms/batch - loss: 86.92308 - diff: 38.37mlTrain batch 16/16 - 55.5ms/batch - loss: 87.82652 - diff: 38.21mlTrain batch 16/16 - 16.7s 55.5ms/batch - loss: 87.82652 - diff: 38.21ml
Test 1.1s: val_loss: 91.77806 - diff: 38.16ml

Epoch 74: current best loss = 72.45180, at epoch 39
Train batch 1/16 - 179.6ms/batch - loss: 57.24677 - diff: 33.61mlTrain batch 2/16 - 162.7ms/batch - loss: 57.14973 - diff: 34.47mlTrain batch 3/16 - 166.7ms/batch - loss: 57.89671 - diff: 33.87mlTrain batch 4/16 - 162.6ms/batch - loss: 65.86276 - diff: 35.40mlTrain batch 5/16 - 162.9ms/batch - loss: 67.80174 - diff: 35.81mlTrain batch 6/16 - 163.2ms/batch - loss: 65.72434 - diff: 35.64mlTrain batch 7/16 - 163.2ms/batch - loss: 69.72041 - diff: 35.91mlTrain batch 8/16 - 163.2ms/batch - loss: 86.94468 - diff: 37.54mlTrain batch 9/16 - 169.5ms/batch - loss: 85.30956 - diff: 37.81mlTrain batch 10/16 - 163.8ms/batch - loss: 86.92696 - diff: 38.15mlTrain batch 11/16 - 166.8ms/batch - loss: 83.52359 - diff: 37.67mlTrain batch 12/16 - 173.9ms/batch - loss: 83.41788 - diff: 37.68mlTrain batch 13/16 - 166.9ms/batch - loss: 82.89884 - diff: 37.89mlTrain batch 14/16 - 162.9ms/batch - loss: 90.11921 - diff: 39.45mlTrain batch 15/16 - 162.9ms/batch - loss: 88.57392 - diff: 39.16mlTrain batch 16/16 - 54.8ms/batch - loss: 89.53494 - diff: 39.02mlTrain batch 16/16 - 15.2s 54.8ms/batch - loss: 89.53494 - diff: 39.02ml
Test 1.1s: val_loss: 87.35346 - diff: 35.71ml

Epoch 75: current best loss = 72.45180, at epoch 39
Train batch 1/16 - 180.5ms/batch - loss: 111.75770 - diff: 46.32mlTrain batch 2/16 - 182.7ms/batch - loss: 88.01283 - diff: 42.59mlTrain batch 3/16 - 163.1ms/batch - loss: 75.19549 - diff: 38.92mlTrain batch 4/16 - 163.0ms/batch - loss: 75.56663 - diff: 39.35mlTrain batch 5/16 - 162.8ms/batch - loss: 70.02876 - diff: 38.10mlTrain batch 6/16 - 171.8ms/batch - loss: 72.95465 - diff: 38.81mlTrain batch 7/16 - 167.6ms/batch - loss: 78.90424 - diff: 39.22mlTrain batch 8/16 - 167.5ms/batch - loss: 75.58462 - diff: 38.32mlTrain batch 9/16 - 162.9ms/batch - loss: 78.94060 - diff: 38.57mlTrain batch 10/16 - 163.3ms/batch - loss: 92.77288 - diff: 39.60mlTrain batch 11/16 - 162.9ms/batch - loss: 90.65628 - diff: 39.31mlTrain batch 12/16 - 177.4ms/batch - loss: 88.24753 - diff: 39.10mlTrain batch 13/16 - 176.6ms/batch - loss: 96.73601 - diff: 39.74mlTrain batch 14/16 - 179.3ms/batch - loss: 94.43689 - diff: 39.34mlTrain batch 15/16 - 165.8ms/batch - loss: 93.71298 - diff: 39.50mlTrain batch 16/16 - 54.8ms/batch - loss: 95.39808 - diff: 39.39mlTrain batch 16/16 - 15.0s 54.8ms/batch - loss: 95.39808 - diff: 39.39ml
Test 1.1s: val_loss: 69.04382 - diff: 35.23ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_VGG19_Adam-0.001_MSE_DA3_best

Epoch 76: current best loss = 69.04382, at epoch 75
Train batch 1/16 - 180.5ms/batch - loss: 84.62413 - diff: 40.19mlTrain batch 2/16 - 166.3ms/batch - loss: 99.68936 - diff: 44.21mlTrain batch 3/16 - 182.9ms/batch - loss: 89.42650 - diff: 42.14mlTrain batch 4/16 - 162.8ms/batch - loss: 87.46450 - diff: 41.34mlTrain batch 5/16 - 180.9ms/batch - loss: 85.10803 - diff: 40.67mlTrain batch 6/16 - 169.4ms/batch - loss: 90.62146 - diff: 40.47mlTrain batch 7/16 - 163.1ms/batch - loss: 91.24886 - diff: 40.30mlTrain batch 8/16 - 163.1ms/batch - loss: 90.85236 - diff: 39.90mlTrain batch 9/16 - 175.4ms/batch - loss: 86.21361 - diff: 39.06mlTrain batch 10/16 - 163.6ms/batch - loss: 88.01249 - diff: 39.71mlTrain batch 11/16 - 183.7ms/batch - loss: 83.44279 - diff: 38.24mlTrain batch 12/16 - 163.2ms/batch - loss: 82.51614 - diff: 38.39mlTrain batch 13/16 - 177.2ms/batch - loss: 92.22405 - diff: 39.37mlTrain batch 14/16 - 168.9ms/batch - loss: 90.41243 - diff: 39.31mlTrain batch 15/16 - 185.4ms/batch - loss: 88.98223 - diff: 39.29mlTrain batch 16/16 - 61.0ms/batch - loss: 91.17979 - diff: 39.15mlTrain batch 16/16 - 17.9s 61.0ms/batch - loss: 91.17979 - diff: 39.15ml
Test 1.2s: val_loss: 70.16438 - diff: 35.41ml

Epoch 77: current best loss = 69.04382, at epoch 75
Train batch 1/16 - 180.6ms/batch - loss: 149.43912 - diff: 46.36mlTrain batch 2/16 - 168.5ms/batch - loss: 100.83246 - diff: 38.75mlTrain batch 3/16 - 162.8ms/batch - loss: 93.39141 - diff: 38.71mlTrain batch 4/16 - 162.7ms/batch - loss: 95.24271 - diff: 38.42mlTrain batch 5/16 - 178.1ms/batch - loss: 92.07345 - diff: 38.41mlTrain batch 6/16 - 175.9ms/batch - loss: 96.44707 - diff: 39.43mlTrain batch 7/16 - 162.8ms/batch - loss: 93.98278 - diff: 39.76mlTrain batch 8/16 - 167.7ms/batch - loss: 107.22594 - diff: 40.91mlTrain batch 9/16 - 164.3ms/batch - loss: 102.01218 - diff: 40.58mlTrain batch 10/16 - 163.0ms/batch - loss: 102.12263 - diff: 41.14mlTrain batch 11/16 - 162.7ms/batch - loss: 98.97471 - diff: 40.72mlTrain batch 12/16 - 173.7ms/batch - loss: 96.33385 - diff: 40.25mlTrain batch 13/16 - 183.5ms/batch - loss: 98.57255 - diff: 40.44mlTrain batch 14/16 - 163.0ms/batch - loss: 96.73917 - diff: 40.30mlTrain batch 15/16 - 162.8ms/batch - loss: 92.60000 - diff: 39.48mlTrain batch 16/16 - 54.9ms/batch - loss: 96.93481 - diff: 39.56mlTrain batch 16/16 - 17.2s 54.9ms/batch - loss: 96.93481 - diff: 39.56ml
Test 1.4s: val_loss: 68.20310 - diff: 34.47ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_VGG19_Adam-0.001_MSE_DA3_best

Epoch 78: current best loss = 68.20310, at epoch 77
Train batch 1/16 - 180.8ms/batch - loss: 122.60550 - diff: 45.59mlTrain batch 2/16 - 162.8ms/batch - loss: 105.89648 - diff: 45.61mlTrain batch 3/16 - 166.9ms/batch - loss: 100.13524 - diff: 44.29mlTrain batch 4/16 - 170.1ms/batch - loss: 101.76523 - diff: 43.82mlTrain batch 5/16 - 162.8ms/batch - loss: 96.45133 - diff: 43.06mlTrain batch 6/16 - 162.5ms/batch - loss: 94.34878 - diff: 42.65mlTrain batch 7/16 - 167.6ms/batch - loss: 97.41654 - diff: 42.18mlTrain batch 8/16 - 162.9ms/batch - loss: 97.17662 - diff: 41.98mlTrain batch 9/16 - 176.2ms/batch - loss: 90.21488 - diff: 40.16mlTrain batch 10/16 - 166.3ms/batch - loss: 101.98911 - diff: 40.90mlTrain batch 11/16 - 162.9ms/batch - loss: 99.42963 - diff: 40.45mlTrain batch 12/16 - 162.7ms/batch - loss: 98.18881 - diff: 40.65mlTrain batch 13/16 - 162.7ms/batch - loss: 94.37786 - diff: 39.98mlTrain batch 14/16 - 168.1ms/batch - loss: 91.70269 - diff: 39.53mlTrain batch 15/16 - 162.8ms/batch - loss: 90.31840 - diff: 39.43mlTrain batch 16/16 - 54.9ms/batch - loss: 91.46906 - diff: 39.30mlTrain batch 16/16 - 16.5s 54.9ms/batch - loss: 91.46906 - diff: 39.30ml
Test 1.4s: val_loss: 79.65871 - diff: 35.42ml

Epoch 79: current best loss = 68.20310, at epoch 77
Train batch 1/16 - 178.4ms/batch - loss: 160.76906 - diff: 55.90mlTrain batch 2/16 - 168.8ms/batch - loss: 113.10829 - diff: 45.41mlTrain batch 3/16 - 162.7ms/batch - loss: 104.30922 - diff: 43.81mlTrain batch 4/16 - 162.8ms/batch - loss: 89.33358 - diff: 40.07mlTrain batch 5/16 - 179.5ms/batch - loss: 86.00088 - diff: 39.16mlTrain batch 6/16 - 173.3ms/batch - loss: 85.98060 - diff: 39.10mlTrain batch 7/16 - 164.7ms/batch - loss: 103.00891 - diff: 40.04mlTrain batch 8/16 - 163.0ms/batch - loss: 103.99099 - diff: 40.27mlTrain batch 9/16 - 162.9ms/batch - loss: 106.32754 - diff: 41.86mlTrain batch 10/16 - 163.0ms/batch - loss: 102.94810 - diff: 41.75mlTrain batch 11/16 - 163.0ms/batch - loss: 101.78238 - diff: 41.64mlTrain batch 12/16 - 162.5ms/batch - loss: 96.74055 - diff: 40.58mlTrain batch 13/16 - 162.8ms/batch - loss: 94.27099 - diff: 40.21mlTrain batch 14/16 - 162.5ms/batch - loss: 91.12235 - diff: 39.47mlTrain batch 15/16 - 166.1ms/batch - loss: 93.90051 - diff: 40.24mlTrain batch 16/16 - 54.9ms/batch - loss: 95.49483 - diff: 40.12mlTrain batch 16/16 - 16.6s 54.9ms/batch - loss: 95.49483 - diff: 40.12ml
Test 1.2s: val_loss: 118.91770 - diff: 41.48ml

Epoch 80: current best loss = 68.20310, at epoch 77
Train batch 1/16 - 180.4ms/batch - loss: 63.27744 - diff: 37.21mlTrain batch 2/16 - 162.8ms/batch - loss: 58.69602 - diff: 35.87mlTrain batch 3/16 - 167.1ms/batch - loss: 53.20668 - diff: 34.00mlTrain batch 4/16 - 163.0ms/batch - loss: 56.04686 - diff: 34.38mlTrain batch 5/16 - 174.1ms/batch - loss: 61.32132 - diff: 36.23mlTrain batch 6/16 - 174.4ms/batch - loss: 89.24425 - diff: 37.95mlTrain batch 7/16 - 175.4ms/batch - loss: 89.57339 - diff: 38.64mlTrain batch 8/16 - 163.0ms/batch - loss: 88.75694 - diff: 39.28mlTrain batch 9/16 - 181.1ms/batch - loss: 85.81089 - diff: 38.83mlTrain batch 10/16 - 169.1ms/batch - loss: 82.47724 - diff: 38.03mlTrain batch 11/16 - 166.7ms/batch - loss: 82.38001 - diff: 37.62mlTrain batch 12/16 - 162.9ms/batch - loss: 88.34824 - diff: 39.06mlTrain batch 13/16 - 176.1ms/batch - loss: 92.61636 - diff: 39.84mlTrain batch 14/16 - 162.9ms/batch - loss: 90.17501 - diff: 39.52mlTrain batch 15/16 - 162.8ms/batch - loss: 88.85832 - diff: 39.32mlTrain batch 16/16 - 54.9ms/batch - loss: 95.21946 - diff: 39.23mlTrain batch 16/16 - 15.9s 54.9ms/batch - loss: 95.21946 - diff: 39.23ml
Test 1.2s: val_loss: 80.69047 - diff: 34.24ml

Epoch 81: current best loss = 68.20310, at epoch 77
Train batch 1/16 - 189.0ms/batch - loss: 74.04951 - diff: 41.58mlTrain batch 2/16 - 171.5ms/batch - loss: 150.55807 - diff: 49.27mlTrain batch 3/16 - 162.8ms/batch - loss: 144.06225 - diff: 51.78mlTrain batch 4/16 - 166.5ms/batch - loss: 128.20815 - diff: 49.24mlTrain batch 5/16 - 167.1ms/batch - loss: 117.03921 - diff: 47.64mlTrain batch 6/16 - 162.6ms/batch - loss: 113.79708 - diff: 46.91mlTrain batch 7/16 - 162.9ms/batch - loss: 104.43058 - diff: 44.47mlTrain batch 8/16 - 162.8ms/batch - loss: 98.49827 - diff: 43.40mlTrain batch 9/16 - 165.5ms/batch - loss: 101.09237 - diff: 43.47mlTrain batch 10/16 - 166.1ms/batch - loss: 99.44844 - diff: 42.60mlTrain batch 11/16 - 162.9ms/batch - loss: 100.32678 - diff: 42.29mlTrain batch 12/16 - 177.6ms/batch - loss: 96.73163 - diff: 41.46mlTrain batch 13/16 - 162.8ms/batch - loss: 96.30941 - diff: 41.45mlTrain batch 14/16 - 162.8ms/batch - loss: 92.12812 - diff: 40.51mlTrain batch 15/16 - 162.9ms/batch - loss: 91.12416 - diff: 40.33mlTrain batch 16/16 - 61.0ms/batch - loss: 101.58358 - diff: 40.67mlTrain batch 16/16 - 16.2s 61.0ms/batch - loss: 101.58358 - diff: 40.67ml
Test 1.0s: val_loss: 64.03290 - diff: 34.41ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_VGG19_Adam-0.001_MSE_DA3_best

Epoch 82: current best loss = 64.03290, at epoch 81
Train batch 1/16 - 180.8ms/batch - loss: 75.49866 - diff: 41.83mlTrain batch 2/16 - 187.0ms/batch - loss: 133.09851 - diff: 42.37mlTrain batch 3/16 - 162.7ms/batch - loss: 125.72823 - diff: 43.66mlTrain batch 4/16 - 162.8ms/batch - loss: 113.96718 - diff: 42.21mlTrain batch 5/16 - 187.1ms/batch - loss: 104.00202 - diff: 40.94mlTrain batch 6/16 - 162.9ms/batch - loss: 102.02526 - diff: 41.60mlTrain batch 7/16 - 163.2ms/batch - loss: 96.70976 - diff: 40.17mlTrain batch 8/16 - 162.9ms/batch - loss: 101.25312 - diff: 41.47mlTrain batch 9/16 - 180.7ms/batch - loss: 99.53876 - diff: 40.65mlTrain batch 10/16 - 183.2ms/batch - loss: 96.43743 - diff: 40.30mlTrain batch 11/16 - 180.9ms/batch - loss: 92.65435 - diff: 39.64mlTrain batch 12/16 - 171.9ms/batch - loss: 89.79465 - diff: 39.38mlTrain batch 13/16 - 162.9ms/batch - loss: 89.00351 - diff: 39.35mlTrain batch 14/16 - 163.1ms/batch - loss: 87.08974 - diff: 39.21mlTrain batch 15/16 - 162.7ms/batch - loss: 85.06557 - diff: 38.90mlTrain batch 16/16 - 54.8ms/batch - loss: 93.71543 - diff: 39.20mlTrain batch 16/16 - 17.4s 54.8ms/batch - loss: 93.71543 - diff: 39.20ml
Test 1.1s: val_loss: 82.68769 - diff: 35.96ml

Epoch 83: current best loss = 64.03290, at epoch 81
Train batch 1/16 - 180.8ms/batch - loss: 189.60699 - diff: 38.42mlTrain batch 2/16 - 179.8ms/batch - loss: 155.25380 - diff: 41.56mlTrain batch 3/16 - 175.0ms/batch - loss: 136.52786 - diff: 41.61mlTrain batch 4/16 - 163.5ms/batch - loss: 161.71476 - diff: 43.93mlTrain batch 5/16 - 180.5ms/batch - loss: 135.62537 - diff: 40.37mlTrain batch 6/16 - 163.2ms/batch - loss: 118.35727 - diff: 37.84mlTrain batch 7/16 - 162.9ms/batch - loss: 109.82198 - diff: 37.60mlTrain batch 8/16 - 164.2ms/batch - loss: 101.82702 - diff: 36.78mlTrain batch 9/16 - 168.8ms/batch - loss: 98.93455 - diff: 36.67mlTrain batch 10/16 - 179.8ms/batch - loss: 95.23538 - diff: 36.56mlTrain batch 11/16 - 163.8ms/batch - loss: 93.78206 - diff: 36.79mlTrain batch 12/16 - 168.0ms/batch - loss: 92.22153 - diff: 36.90mlTrain batch 13/16 - 162.7ms/batch - loss: 90.82950 - diff: 37.06mlTrain batch 14/16 - 163.1ms/batch - loss: 91.58201 - diff: 37.43mlTrain batch 15/16 - 162.9ms/batch - loss: 90.90025 - diff: 37.40mlTrain batch 16/16 - 54.9ms/batch - loss: 94.82103 - diff: 37.41mlTrain batch 16/16 - 15.9s 54.9ms/batch - loss: 94.82103 - diff: 37.41ml
Test 1.3s: val_loss: 92.43155 - diff: 38.88ml

Epoch 84: current best loss = 64.03290, at epoch 81
Train batch 1/16 - 180.9ms/batch - loss: 100.54308 - diff: 42.50mlTrain batch 2/16 - 172.3ms/batch - loss: 79.32420 - diff: 37.87mlTrain batch 3/16 - 166.7ms/batch - loss: 95.98366 - diff: 40.97mlTrain batch 4/16 - 168.0ms/batch - loss: 96.23033 - diff: 42.07mlTrain batch 5/16 - 180.8ms/batch - loss: 88.16310 - diff: 40.15mlTrain batch 6/16 - 172.3ms/batch - loss: 83.42511 - diff: 38.89mlTrain batch 7/16 - 162.7ms/batch - loss: 90.84405 - diff: 39.91mlTrain batch 8/16 - 171.9ms/batch - loss: 88.21427 - diff: 39.47mlTrain batch 9/16 - 162.6ms/batch - loss: 102.10654 - diff: 40.66mlTrain batch 10/16 - 166.8ms/batch - loss: 97.70859 - diff: 40.36mlTrain batch 11/16 - 165.8ms/batch - loss: 91.73832 - diff: 38.95mlTrain batch 12/16 - 163.0ms/batch - loss: 90.94224 - diff: 38.94mlTrain batch 13/16 - 163.1ms/batch - loss: 89.57311 - diff: 38.67mlTrain batch 14/16 - 163.1ms/batch - loss: 88.11401 - diff: 38.57mlTrain batch 15/16 - 163.0ms/batch - loss: 85.54393 - diff: 37.97mlTrain batch 16/16 - 54.8ms/batch - loss: 92.89024 - diff: 38.08mlTrain batch 16/16 - 16.4s 54.8ms/batch - loss: 92.89024 - diff: 38.08ml
Test 1.1s: val_loss: 74.26286 - diff: 34.81ml

Epoch 85: current best loss = 64.03290, at epoch 81
Train batch 1/16 - 180.9ms/batch - loss: 64.54185 - diff: 37.89mlTrain batch 2/16 - 179.2ms/batch - loss: 87.59723 - diff: 40.18mlTrain batch 3/16 - 162.8ms/batch - loss: 95.83437 - diff: 41.51mlTrain batch 4/16 - 170.0ms/batch - loss: 79.61346 - diff: 37.34mlTrain batch 5/16 - 163.0ms/batch - loss: 77.70708 - diff: 37.11mlTrain batch 6/16 - 163.3ms/batch - loss: 72.68007 - diff: 36.32mlTrain batch 7/16 - 180.9ms/batch - loss: 75.97526 - diff: 36.68mlTrain batch 8/16 - 174.2ms/batch - loss: 73.33263 - diff: 36.27mlTrain batch 9/16 - 165.7ms/batch - loss: 69.81461 - diff: 35.54mlTrain batch 10/16 - 167.8ms/batch - loss: 70.35684 - diff: 36.00mlTrain batch 11/16 - 162.9ms/batch - loss: 68.87685 - diff: 35.88mlTrain batch 12/16 - 162.9ms/batch - loss: 82.77718 - diff: 37.55mlTrain batch 13/16 - 176.7ms/batch - loss: 83.09225 - diff: 37.91mlTrain batch 14/16 - 162.9ms/batch - loss: 86.47995 - diff: 38.57mlTrain batch 15/16 - 180.8ms/batch - loss: 85.66773 - diff: 38.56mlTrain batch 16/16 - 61.0ms/batch - loss: 91.31325 - diff: 38.68mlTrain batch 16/16 - 17.9s 61.0ms/batch - loss: 91.31325 - diff: 38.68ml
Test 1.2s: val_loss: 70.79206 - diff: 34.91ml

Epoch 86: current best loss = 64.03290, at epoch 81
Train batch 1/16 - 180.5ms/batch - loss: 228.13661 - diff: 43.78mlTrain batch 2/16 - 170.2ms/batch - loss: 192.89734 - diff: 44.82mlTrain batch 3/16 - 162.9ms/batch - loss: 162.22839 - diff: 42.66mlTrain batch 4/16 - 163.0ms/batch - loss: 138.29210 - diff: 41.34mlTrain batch 5/16 - 178.5ms/batch - loss: 127.12737 - diff: 40.23mlTrain batch 6/16 - 164.1ms/batch - loss: 118.05776 - diff: 38.91mlTrain batch 7/16 - 162.9ms/batch - loss: 112.67112 - diff: 39.07mlTrain batch 8/16 - 162.8ms/batch - loss: 111.80151 - diff: 39.48mlTrain batch 9/16 - 162.9ms/batch - loss: 108.07939 - diff: 39.78mlTrain batch 10/16 - 172.2ms/batch - loss: 103.84028 - diff: 39.65mlTrain batch 11/16 - 165.1ms/batch - loss: 98.36191 - diff: 38.91mlTrain batch 12/16 - 168.0ms/batch - loss: 92.24584 - diff: 37.44mlTrain batch 13/16 - 163.0ms/batch - loss: 90.40049 - diff: 37.42mlTrain batch 14/16 - 171.1ms/batch - loss: 87.97498 - diff: 37.09mlTrain batch 15/16 - 162.8ms/batch - loss: 89.71529 - diff: 37.61mlTrain batch 16/16 - 55.0ms/batch - loss: 92.56545 - diff: 37.59mlTrain batch 16/16 - 16.5s 55.0ms/batch - loss: 92.56545 - diff: 37.59ml
Test 1.1s: val_loss: 85.69131 - diff: 35.90ml

Epoch 87: current best loss = 64.03290, at epoch 81
Train batch 1/16 - 180.6ms/batch - loss: 62.19410 - diff: 38.32mlTrain batch 2/16 - 173.9ms/batch - loss: 47.92945 - diff: 31.55mlTrain batch 3/16 - 179.7ms/batch - loss: 53.45721 - diff: 34.33mlTrain batch 4/16 - 163.2ms/batch - loss: 94.86529 - diff: 36.32mlTrain batch 5/16 - 163.0ms/batch - loss: 82.55892 - diff: 34.26mlTrain batch 6/16 - 179.1ms/batch - loss: 81.66942 - diff: 34.93mlTrain batch 7/16 - 162.8ms/batch - loss: 82.79179 - diff: 35.42mlTrain batch 8/16 - 162.8ms/batch - loss: 85.40575 - diff: 36.98mlTrain batch 9/16 - 162.9ms/batch - loss: 90.67004 - diff: 38.05mlTrain batch 10/16 - 163.0ms/batch - loss: 91.42213 - diff: 38.85mlTrain batch 11/16 - 162.6ms/batch - loss: 88.42674 - diff: 38.74mlTrain batch 12/16 - 164.1ms/batch - loss: 86.97717 - diff: 38.40mlTrain batch 13/16 - 163.0ms/batch - loss: 86.98110 - diff: 38.73mlTrain batch 14/16 - 162.8ms/batch - loss: 86.80266 - diff: 38.73mlTrain batch 15/16 - 162.9ms/batch - loss: 84.85257 - diff: 38.24mlTrain batch 16/16 - 54.9ms/batch - loss: 85.85621 - diff: 38.07mlTrain batch 16/16 - 16.2s 54.9ms/batch - loss: 85.85621 - diff: 38.07ml
Test 1.2s: val_loss: 72.84184 - diff: 34.44ml

Epoch 88: current best loss = 64.03290, at epoch 81
Train batch 1/16 - 177.6ms/batch - loss: 43.60571 - diff: 32.52mlTrain batch 2/16 - 163.2ms/batch - loss: 120.24524 - diff: 38.39mlTrain batch 3/16 - 184.5ms/batch - loss: 121.15097 - diff: 39.68mlTrain batch 4/16 - 167.8ms/batch - loss: 112.76390 - diff: 40.17mlTrain batch 5/16 - 169.4ms/batch - loss: 101.47733 - diff: 38.85mlTrain batch 6/16 - 168.5ms/batch - loss: 98.95944 - diff: 39.35mlTrain batch 7/16 - 174.1ms/batch - loss: 97.42229 - diff: 40.25mlTrain batch 8/16 - 164.0ms/batch - loss: 92.54731 - diff: 39.49mlTrain batch 9/16 - 180.9ms/batch - loss: 94.04054 - diff: 39.83mlTrain batch 10/16 - 178.8ms/batch - loss: 91.41280 - diff: 39.70mlTrain batch 11/16 - 163.1ms/batch - loss: 93.57356 - diff: 39.85mlTrain batch 12/16 - 170.4ms/batch - loss: 92.76192 - diff: 40.00mlTrain batch 13/16 - 162.8ms/batch - loss: 92.43099 - diff: 40.04mlTrain batch 14/16 - 170.4ms/batch - loss: 91.12591 - diff: 39.69mlTrain batch 15/16 - 163.2ms/batch - loss: 90.21478 - diff: 39.67mlTrain batch 16/16 - 54.9ms/batch - loss: 92.08267 - diff: 39.59mlTrain batch 16/16 - 17.7s 54.9ms/batch - loss: 92.08267 - diff: 39.59ml
Test 1.3s: val_loss: 66.18746 - diff: 32.88ml

Epoch 89: current best loss = 64.03290, at epoch 81
Train batch 1/16 - 187.7ms/batch - loss: 66.54647 - diff: 39.11mlTrain batch 2/16 - 165.2ms/batch - loss: 56.71965 - diff: 35.30mlTrain batch 3/16 - 168.2ms/batch - loss: 50.50287 - diff: 32.58mlTrain batch 4/16 - 163.1ms/batch - loss: 45.48857 - diff: 31.20mlTrain batch 5/16 - 176.3ms/batch - loss: 49.41640 - diff: 32.10mlTrain batch 6/16 - 177.8ms/batch - loss: 60.73264 - diff: 34.84mlTrain batch 7/16 - 163.3ms/batch - loss: 63.18870 - diff: 34.94mlTrain batch 8/16 - 173.7ms/batch - loss: 62.28824 - diff: 35.00mlTrain batch 9/16 - 180.8ms/batch - loss: 62.97955 - diff: 35.17mlTrain batch 10/16 - 172.1ms/batch - loss: 64.41630 - diff: 35.76mlTrain batch 11/16 - 171.0ms/batch - loss: 64.73917 - diff: 35.70mlTrain batch 12/16 - 175.9ms/batch - loss: 75.04047 - diff: 36.65mlTrain batch 13/16 - 167.1ms/batch - loss: 74.87749 - diff: 36.83mlTrain batch 14/16 - 162.9ms/batch - loss: 77.16102 - diff: 37.22mlTrain batch 15/16 - 163.2ms/batch - loss: 79.39366 - diff: 37.75mlTrain batch 16/16 - 54.9ms/batch - loss: 82.43324 - diff: 37.79mlTrain batch 16/16 - 17.0s 54.9ms/batch - loss: 82.43324 - diff: 37.79ml
Test 1.1s: val_loss: 78.05138 - diff: 33.23ml

Epoch 90: current best loss = 64.03290, at epoch 81
Train batch 1/16 - 179.1ms/batch - loss: 121.72242 - diff: 49.52mlTrain batch 2/16 - 167.1ms/batch - loss: 79.95784 - diff: 39.16mlTrain batch 3/16 - 190.1ms/batch - loss: 76.50205 - diff: 37.83mlTrain batch 4/16 - 170.8ms/batch - loss: 86.45419 - diff: 38.01mlTrain batch 5/16 - 175.8ms/batch - loss: 80.10319 - diff: 36.85mlTrain batch 6/16 - 163.2ms/batch - loss: 80.39863 - diff: 37.32mlTrain batch 7/16 - 169.4ms/batch - loss: 75.69727 - diff: 36.27mlTrain batch 8/16 - 163.0ms/batch - loss: 73.14621 - diff: 35.72mlTrain batch 9/16 - 178.1ms/batch - loss: 88.10987 - diff: 36.77mlTrain batch 10/16 - 163.2ms/batch - loss: 87.48672 - diff: 36.93mlTrain batch 11/16 - 163.0ms/batch - loss: 89.65535 - diff: 37.87mlTrain batch 12/16 - 167.6ms/batch - loss: 89.39891 - diff: 38.14mlTrain batch 13/16 - 178.5ms/batch - loss: 87.83255 - diff: 38.00mlTrain batch 14/16 - 163.2ms/batch - loss: 84.15887 - diff: 37.11mlTrain batch 15/16 - 162.8ms/batch - loss: 83.34357 - diff: 37.30mlTrain batch 16/16 - 54.9ms/batch - loss: 92.16533 - diff: 37.52mlTrain batch 16/16 - 16.7s 54.9ms/batch - loss: 92.16533 - diff: 37.52ml
Test 1.2s: val_loss: 96.25215 - diff: 39.64ml

Epoch 91: current best loss = 64.03290, at epoch 81
Train batch 1/16 - 181.0ms/batch - loss: 265.43082 - diff: 54.24mlTrain batch 2/16 - 172.1ms/batch - loss: 161.43347 - diff: 44.44mlTrain batch 3/16 - 162.8ms/batch - loss: 158.54444 - diff: 46.71mlTrain batch 4/16 - 163.0ms/batch - loss: 132.48258 - diff: 43.10mlTrain batch 5/16 - 200.5ms/batch - loss: 118.90827 - diff: 41.94mlTrain batch 6/16 - 166.0ms/batch - loss: 112.53311 - diff: 42.14mlTrain batch 7/16 - 169.8ms/batch - loss: 104.82660 - diff: 41.26mlTrain batch 8/16 - 170.1ms/batch - loss: 97.79221 - diff: 40.04mlTrain batch 9/16 - 175.5ms/batch - loss: 94.15110 - diff: 39.64mlTrain batch 10/16 - 163.0ms/batch - loss: 93.97452 - diff: 39.74mlTrain batch 11/16 - 178.5ms/batch - loss: 94.04884 - diff: 39.59mlTrain batch 12/16 - 164.0ms/batch - loss: 97.35463 - diff: 40.26mlTrain batch 13/16 - 163.6ms/batch - loss: 95.08737 - diff: 40.03mlTrain batch 14/16 - 162.8ms/batch - loss: 94.03349 - diff: 39.76mlTrain batch 15/16 - 163.0ms/batch - loss: 91.90065 - diff: 39.30mlTrain batch 16/16 - 54.9ms/batch - loss: 93.72058 - diff: 39.24mlTrain batch 16/16 - 15.9s 54.9ms/batch - loss: 93.72058 - diff: 39.24ml
Test 1.3s: val_loss: 66.21648 - diff: 32.51ml

Epoch 92: current best loss = 64.03290, at epoch 81
Train batch 1/16 - 181.8ms/batch - loss: 100.72868 - diff: 40.44mlTrain batch 2/16 - 176.9ms/batch - loss: 81.40569 - diff: 39.81mlTrain batch 3/16 - 162.8ms/batch - loss: 90.87344 - diff: 42.70mlTrain batch 4/16 - 163.0ms/batch - loss: 83.89950 - diff: 41.15mlTrain batch 5/16 - 162.7ms/batch - loss: 81.13628 - diff: 39.23mlTrain batch 6/16 - 162.8ms/batch - loss: 79.59651 - diff: 38.12mlTrain batch 7/16 - 162.7ms/batch - loss: 80.65843 - diff: 38.03mlTrain batch 8/16 - 162.8ms/batch - loss: 81.78531 - diff: 38.37mlTrain batch 9/16 - 171.1ms/batch - loss: 77.93062 - diff: 37.40mlTrain batch 10/16 - 163.0ms/batch - loss: 79.73349 - diff: 37.60mlTrain batch 11/16 - 163.0ms/batch - loss: 91.35902 - diff: 38.18mlTrain batch 12/16 - 162.5ms/batch - loss: 88.00085 - diff: 37.86mlTrain batch 13/16 - 162.7ms/batch - loss: 85.29248 - diff: 37.62mlTrain batch 14/16 - 162.9ms/batch - loss: 83.79849 - diff: 37.54mlTrain batch 15/16 - 163.3ms/batch - loss: 86.32051 - diff: 38.47mlTrain batch 16/16 - 54.9ms/batch - loss: 87.24222 - diff: 38.36mlTrain batch 16/16 - 15.7s 54.9ms/batch - loss: 87.24222 - diff: 38.36ml
Test 0.8s: val_loss: 63.41005 - diff: 32.20ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_VGG19_Adam-0.001_MSE_DA3_best

Epoch 93: current best loss = 63.41005, at epoch 92
Train batch 1/16 - 178.0ms/batch - loss: 118.86226 - diff: 46.01mlTrain batch 2/16 - 162.8ms/batch - loss: 82.66581 - diff: 38.29mlTrain batch 3/16 - 171.6ms/batch - loss: 78.27329 - diff: 37.94mlTrain batch 4/16 - 162.9ms/batch - loss: 75.83453 - diff: 37.79mlTrain batch 5/16 - 162.9ms/batch - loss: 73.37760 - diff: 37.10mlTrain batch 6/16 - 163.2ms/batch - loss: 69.98575 - diff: 36.34mlTrain batch 7/16 - 169.1ms/batch - loss: 70.79162 - diff: 36.68mlTrain batch 8/16 - 162.7ms/batch - loss: 67.25183 - diff: 36.11mlTrain batch 9/16 - 162.8ms/batch - loss: 66.61073 - diff: 35.86mlTrain batch 10/16 - 162.9ms/batch - loss: 68.46707 - diff: 36.04mlTrain batch 11/16 - 162.7ms/batch - loss: 66.41763 - diff: 35.67mlTrain batch 12/16 - 162.9ms/batch - loss: 69.33963 - diff: 36.28mlTrain batch 13/16 - 174.6ms/batch - loss: 79.11714 - diff: 36.87mlTrain batch 14/16 - 163.2ms/batch - loss: 78.80896 - diff: 36.69mlTrain batch 15/16 - 162.9ms/batch - loss: 75.57019 - diff: 35.91mlTrain batch 16/16 - 54.9ms/batch - loss: 76.56221 - diff: 35.75mlTrain batch 16/16 - 17.4s 54.9ms/batch - loss: 76.56221 - diff: 35.75ml
Test 1.2s: val_loss: 70.42459 - diff: 33.88ml

Epoch 94: current best loss = 63.41005, at epoch 92
Train batch 1/16 - 186.6ms/batch - loss: 52.09983 - diff: 34.10mlTrain batch 2/16 - 163.0ms/batch - loss: 46.50567 - diff: 30.68mlTrain batch 3/16 - 163.0ms/batch - loss: 59.09388 - diff: 33.06mlTrain batch 4/16 - 172.4ms/batch - loss: 65.81722 - diff: 35.15mlTrain batch 5/16 - 163.0ms/batch - loss: 63.24174 - diff: 34.63mlTrain batch 6/16 - 163.3ms/batch - loss: 61.90164 - diff: 34.54mlTrain batch 7/16 - 162.8ms/batch - loss: 58.24708 - diff: 33.20mlTrain batch 8/16 - 162.8ms/batch - loss: 69.59820 - diff: 34.89mlTrain batch 9/16 - 162.7ms/batch - loss: 74.63550 - diff: 36.30mlTrain batch 10/16 - 163.1ms/batch - loss: 71.33430 - diff: 35.53mlTrain batch 11/16 - 162.9ms/batch - loss: 71.02390 - diff: 35.22mlTrain batch 12/16 - 173.5ms/batch - loss: 67.87706 - diff: 34.51mlTrain batch 13/16 - 162.8ms/batch - loss: 69.54244 - diff: 34.85mlTrain batch 14/16 - 167.9ms/batch - loss: 68.99296 - diff: 34.95mlTrain batch 15/16 - 162.8ms/batch - loss: 78.70377 - diff: 35.90mlTrain batch 16/16 - 54.9ms/batch - loss: 83.63290 - diff: 36.06mlTrain batch 16/16 - 16.3s 54.9ms/batch - loss: 83.63290 - diff: 36.06ml
Test 1.2s: val_loss: 70.73597 - diff: 31.61ml

Epoch 95: current best loss = 63.41005, at epoch 92
Train batch 1/16 - 180.7ms/batch - loss: 98.56334 - diff: 45.24mlTrain batch 2/16 - 162.8ms/batch - loss: 67.18060 - diff: 34.72mlTrain batch 3/16 - 163.0ms/batch - loss: 77.23295 - diff: 37.10mlTrain batch 4/16 - 174.7ms/batch - loss: 109.86322 - diff: 40.84mlTrain batch 5/16 - 162.6ms/batch - loss: 100.56913 - diff: 39.80mlTrain batch 6/16 - 162.9ms/batch - loss: 95.81003 - diff: 39.31mlTrain batch 7/16 - 162.9ms/batch - loss: 89.67464 - diff: 38.22mlTrain batch 8/16 - 162.6ms/batch - loss: 91.74701 - diff: 38.97mlTrain batch 9/16 - 162.8ms/batch - loss: 91.63693 - diff: 39.10mlTrain batch 10/16 - 162.7ms/batch - loss: 87.58643 - diff: 38.36mlTrain batch 11/16 - 174.7ms/batch - loss: 89.32173 - diff: 38.54mlTrain batch 12/16 - 163.1ms/batch - loss: 85.20863 - diff: 37.60mlTrain batch 13/16 - 163.1ms/batch - loss: 83.24631 - diff: 37.28mlTrain batch 14/16 - 165.9ms/batch - loss: 82.36814 - diff: 37.42mlTrain batch 15/16 - 163.0ms/batch - loss: 90.18000 - diff: 38.27mlTrain batch 16/16 - 63.1ms/batch - loss: 89.66101 - diff: 37.96mlTrain batch 16/16 - 15.6s 63.1ms/batch - loss: 89.66101 - diff: 37.96ml
Test 1.1s: val_loss: 69.15494 - diff: 31.50ml

Epoch 96: current best loss = 63.41005, at epoch 92
Train batch 1/16 - 192.5ms/batch - loss: 168.34462 - diff: 40.03mlTrain batch 2/16 - 162.8ms/batch - loss: 125.54957 - diff: 40.34mlTrain batch 3/16 - 163.2ms/batch - loss: 99.65754 - diff: 38.02mlTrain batch 4/16 - 163.9ms/batch - loss: 115.29979 - diff: 39.68mlTrain batch 5/16 - 163.0ms/batch - loss: 111.79107 - diff: 39.45mlTrain batch 6/16 - 162.8ms/batch - loss: 100.47774 - diff: 38.05mlTrain batch 7/16 - 162.8ms/batch - loss: 96.11516 - diff: 37.48mlTrain batch 8/16 - 170.8ms/batch - loss: 90.18972 - diff: 36.91mlTrain batch 9/16 - 163.0ms/batch - loss: 91.62207 - diff: 37.38mlTrain batch 10/16 - 166.8ms/batch - loss: 88.51751 - diff: 36.90mlTrain batch 11/16 - 171.1ms/batch - loss: 86.40737 - diff: 36.81mlTrain batch 12/16 - 163.1ms/batch - loss: 84.63460 - diff: 36.86mlTrain batch 13/16 - 163.0ms/batch - loss: 81.61103 - diff: 36.37mlTrain batch 14/16 - 163.0ms/batch - loss: 80.05407 - diff: 36.10mlTrain batch 15/16 - 162.8ms/batch - loss: 79.82355 - diff: 36.44mlTrain batch 16/16 - 54.8ms/batch - loss: 88.79434 - diff: 36.77mlTrain batch 16/16 - 15.7s 54.8ms/batch - loss: 88.79434 - diff: 36.77ml
Test 1.1s: val_loss: 51.96563 - diff: 31.68ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_VGG19_Adam-0.001_MSE_DA3_best

Epoch 97: current best loss = 51.96563, at epoch 96
Train batch 1/16 - 183.9ms/batch - loss: 85.61368 - diff: 43.03mlTrain batch 2/16 - 166.0ms/batch - loss: 110.11514 - diff: 44.27mlTrain batch 3/16 - 162.7ms/batch - loss: 100.19440 - diff: 41.92mlTrain batch 4/16 - 162.9ms/batch - loss: 89.92284 - diff: 40.57mlTrain batch 5/16 - 163.0ms/batch - loss: 83.48026 - diff: 38.82mlTrain batch 6/16 - 162.9ms/batch - loss: 80.95729 - diff: 38.45mlTrain batch 7/16 - 162.9ms/batch - loss: 80.01041 - diff: 38.69mlTrain batch 8/16 - 163.0ms/batch - loss: 77.06561 - diff: 38.21mlTrain batch 9/16 - 165.4ms/batch - loss: 75.23529 - diff: 38.16mlTrain batch 10/16 - 171.4ms/batch - loss: 73.09130 - diff: 37.81mlTrain batch 11/16 - 162.8ms/batch - loss: 77.98613 - diff: 38.51mlTrain batch 12/16 - 169.8ms/batch - loss: 88.45579 - diff: 39.03mlTrain batch 13/16 - 163.4ms/batch - loss: 85.53201 - diff: 38.59mlTrain batch 14/16 - 164.7ms/batch - loss: 84.67122 - diff: 38.13mlTrain batch 15/16 - 162.9ms/batch - loss: 84.80362 - diff: 38.32mlTrain batch 16/16 - 55.0ms/batch - loss: 89.41040 - diff: 38.40mlTrain batch 16/16 - 16.1s 55.0ms/batch - loss: 89.41040 - diff: 38.40ml
Test 1.1s: val_loss: 66.58087 - diff: 31.85ml

Epoch 98: current best loss = 51.96563, at epoch 96
Train batch 1/16 - 187.2ms/batch - loss: 86.47401 - diff: 33.90mlTrain batch 2/16 - 171.1ms/batch - loss: 77.69302 - diff: 35.61mlTrain batch 3/16 - 181.5ms/batch - loss: 76.76235 - diff: 35.87mlTrain batch 4/16 - 163.5ms/batch - loss: 104.81072 - diff: 37.56mlTrain batch 5/16 - 163.0ms/batch - loss: 94.31289 - diff: 36.21mlTrain batch 6/16 - 163.2ms/batch - loss: 94.64243 - diff: 37.74mlTrain batch 7/16 - 175.1ms/batch - loss: 94.41151 - diff: 38.62mlTrain batch 8/16 - 178.0ms/batch - loss: 88.17801 - diff: 37.37mlTrain batch 9/16 - 163.0ms/batch - loss: 85.91726 - diff: 36.99mlTrain batch 10/16 - 163.1ms/batch - loss: 82.09943 - diff: 36.25mlTrain batch 11/16 - 180.7ms/batch - loss: 77.73366 - diff: 35.43mlTrain batch 12/16 - 170.6ms/batch - loss: 79.13531 - diff: 35.80mlTrain batch 13/16 - 163.1ms/batch - loss: 78.00170 - diff: 35.59mlTrain batch 14/16 - 163.0ms/batch - loss: 77.20836 - diff: 35.73mlTrain batch 15/16 - 174.3ms/batch - loss: 76.09832 - diff: 35.77mlTrain batch 16/16 - 62.2ms/batch - loss: 81.48904 - diff: 35.87mlTrain batch 16/16 - 17.6s 62.2ms/batch - loss: 81.48904 - diff: 35.87ml
Test 1.3s: val_loss: 63.52459 - diff: 32.47ml

Epoch 99: current best loss = 51.96563, at epoch 96
Train batch 1/16 - 180.9ms/batch - loss: 62.34905 - diff: 36.16mlTrain batch 2/16 - 171.8ms/batch - loss: 48.28430 - diff: 31.53mlTrain batch 3/16 - 175.4ms/batch - loss: 51.52363 - diff: 31.34mlTrain batch 4/16 - 171.5ms/batch - loss: 58.29869 - diff: 33.54mlTrain batch 5/16 - 162.8ms/batch - loss: 54.68537 - diff: 32.61mlTrain batch 6/16 - 169.3ms/batch - loss: 65.68793 - diff: 34.04mlTrain batch 7/16 - 187.0ms/batch - loss: 69.50518 - diff: 35.22mlTrain batch 8/16 - 167.2ms/batch - loss: 66.07773 - diff: 34.41mlTrain batch 9/16 - 172.0ms/batch - loss: 78.27012 - diff: 35.34mlTrain batch 10/16 - 179.9ms/batch - loss: 75.72793 - diff: 35.22mlTrain batch 11/16 - 168.1ms/batch - loss: 77.02140 - diff: 35.46mlTrain batch 12/16 - 171.7ms/batch - loss: 75.83492 - diff: 35.22mlTrain batch 13/16 - 163.0ms/batch - loss: 75.50381 - diff: 35.20mlTrain batch 14/16 - 163.1ms/batch - loss: 78.86149 - diff: 36.18mlTrain batch 15/16 - 162.8ms/batch - loss: 77.67875 - diff: 35.92mlTrain batch 16/16 - 54.9ms/batch - loss: 81.18134 - diff: 35.96mlTrain batch 16/16 - 16.9s 54.9ms/batch - loss: 81.18134 - diff: 35.96ml
Test 1.2s: val_loss: 64.97131 - diff: 31.93ml

Epoch 100: current best loss = 51.96563, at epoch 96
Train batch 1/16 - 194.4ms/batch - loss: 64.61011 - diff: 35.96mlTrain batch 2/16 - 163.9ms/batch - loss: 54.57872 - diff: 31.91mlTrain batch 3/16 - 163.0ms/batch - loss: 51.99971 - diff: 31.60mlTrain batch 4/16 - 173.2ms/batch - loss: 53.11743 - diff: 32.44mlTrain batch 5/16 - 162.8ms/batch - loss: 47.68292 - diff: 30.73mlTrain batch 6/16 - 163.0ms/batch - loss: 53.01685 - diff: 31.61mlTrain batch 7/16 - 171.1ms/batch - loss: 52.02374 - diff: 31.69mlTrain batch 8/16 - 167.0ms/batch - loss: 49.47926 - diff: 30.87mlTrain batch 9/16 - 165.3ms/batch - loss: 54.67262 - diff: 32.50mlTrain batch 10/16 - 162.9ms/batch - loss: 54.96785 - diff: 32.77mlTrain batch 11/16 - 162.6ms/batch - loss: 60.26896 - diff: 33.55mlTrain batch 12/16 - 209.0ms/batch - loss: 62.30073 - diff: 34.44mlTrain batch 13/16 - 162.9ms/batch - loss: 71.20899 - diff: 35.30mlTrain batch 14/16 - 162.8ms/batch - loss: 70.44978 - diff: 35.20mlTrain batch 15/16 - 171.1ms/batch - loss: 70.61602 - diff: 35.16mlTrain batch 16/16 - 54.9ms/batch - loss: 90.21550 - diff: 35.65mlTrain batch 16/16 - 15.4s 54.9ms/batch - loss: 90.21550 - diff: 35.65ml
Test 1.2s: val_loss: 48.94625 - diff: 30.23ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_VGG19_Adam-0.001_MSE_DA3_best

Epoch 101: current best loss = 48.94625, at epoch 100
Train batch 1/16 - 180.7ms/batch - loss: 78.04829 - diff: 39.69mlTrain batch 2/16 - 165.2ms/batch - loss: 95.31575 - diff: 45.57mlTrain batch 3/16 - 175.3ms/batch - loss: 85.03294 - diff: 43.55mlTrain batch 4/16 - 163.1ms/batch - loss: 113.76625 - diff: 45.65mlTrain batch 5/16 - 163.1ms/batch - loss: 100.61938 - diff: 42.69mlTrain batch 6/16 - 163.2ms/batch - loss: 98.99155 - diff: 42.65mlTrain batch 7/16 - 170.3ms/batch - loss: 92.45139 - diff: 40.89mlTrain batch 8/16 - 163.3ms/batch - loss: 87.66991 - diff: 39.49mlTrain batch 9/16 - 164.7ms/batch - loss: 82.96746 - diff: 38.51mlTrain batch 10/16 - 175.4ms/batch - loss: 85.65894 - diff: 38.69mlTrain batch 11/16 - 163.0ms/batch - loss: 82.45362 - diff: 38.14mlTrain batch 12/16 - 163.5ms/batch - loss: 82.36311 - diff: 38.03mlTrain batch 13/16 - 177.7ms/batch - loss: 79.19591 - diff: 37.30mlTrain batch 14/16 - 168.8ms/batch - loss: 77.61046 - diff: 37.02mlTrain batch 15/16 - 162.9ms/batch - loss: 75.88617 - diff: 36.82mlTrain batch 16/16 - 54.9ms/batch - loss: 76.20114 - diff: 36.60mlTrain batch 16/16 - 16.3s 54.9ms/batch - loss: 76.20114 - diff: 36.60ml
Test 1.1s: val_loss: 54.66155 - diff: 31.48ml

Epoch 102: current best loss = 48.94625, at epoch 100
Train batch 1/16 - 174.8ms/batch - loss: 85.27190 - diff: 36.42mlTrain batch 2/16 - 163.0ms/batch - loss: 81.40373 - diff: 37.69mlTrain batch 3/16 - 165.7ms/batch - loss: 69.86596 - diff: 35.55mlTrain batch 4/16 - 166.9ms/batch - loss: 70.49517 - diff: 35.84mlTrain batch 5/16 - 163.9ms/batch - loss: 75.06857 - diff: 37.07mlTrain batch 6/16 - 163.0ms/batch - loss: 76.13586 - diff: 36.18mlTrain batch 7/16 - 162.8ms/batch - loss: 75.83679 - diff: 36.57mlTrain batch 8/16 - 162.9ms/batch - loss: 73.03770 - diff: 35.30mlTrain batch 9/16 - 162.9ms/batch - loss: 74.73152 - diff: 36.31mlTrain batch 10/16 - 166.0ms/batch - loss: 88.63151 - diff: 37.83mlTrain batch 11/16 - 162.9ms/batch - loss: 87.20334 - diff: 37.90mlTrain batch 12/16 - 163.3ms/batch - loss: 86.69096 - diff: 38.33mlTrain batch 13/16 - 177.2ms/batch - loss: 83.97485 - diff: 37.87mlTrain batch 14/16 - 163.2ms/batch - loss: 85.64091 - diff: 38.24mlTrain batch 15/16 - 163.0ms/batch - loss: 87.13558 - diff: 38.84mlTrain batch 16/16 - 55.0ms/batch - loss: 87.41655 - diff: 38.60mlTrain batch 16/16 - 16.7s 55.0ms/batch - loss: 87.41655 - diff: 38.60ml
Test 1.1s: val_loss: 85.06627 - diff: 36.88ml

Epoch 103: current best loss = 48.94625, at epoch 100
Train batch 1/16 - 185.4ms/batch - loss: 69.33719 - diff: 33.00mlTrain batch 2/16 - 172.5ms/batch - loss: 84.37682 - diff: 37.77mlTrain batch 3/16 - 163.0ms/batch - loss: 73.76188 - diff: 35.65mlTrain batch 4/16 - 164.1ms/batch - loss: 77.54429 - diff: 36.52mlTrain batch 5/16 - 177.0ms/batch - loss: 79.88598 - diff: 37.99mlTrain batch 6/16 - 162.9ms/batch - loss: 76.48447 - diff: 37.54mlTrain batch 7/16 - 189.3ms/batch - loss: 75.25855 - diff: 37.49mlTrain batch 8/16 - 162.9ms/batch - loss: 92.59166 - diff: 39.52mlTrain batch 9/16 - 163.1ms/batch - loss: 88.70400 - diff: 38.60mlTrain batch 10/16 - 170.0ms/batch - loss: 84.57990 - diff: 37.65mlTrain batch 11/16 - 181.1ms/batch - loss: 78.86155 - diff: 36.17mlTrain batch 12/16 - 181.8ms/batch - loss: 78.49328 - diff: 36.61mlTrain batch 13/16 - 162.9ms/batch - loss: 78.01106 - diff: 36.66mlTrain batch 14/16 - 163.2ms/batch - loss: 76.50805 - diff: 36.37mlTrain batch 15/16 - 163.0ms/batch - loss: 75.99782 - diff: 35.76mlTrain batch 16/16 - 55.0ms/batch - loss: 76.46529 - diff: 35.58mlTrain batch 16/16 - 17.1s 55.0ms/batch - loss: 76.46529 - diff: 35.58ml
Test 1.1s: val_loss: 84.42313 - diff: 32.12ml

Epoch 104: current best loss = 48.94625, at epoch 100
Train batch 1/16 - 180.6ms/batch - loss: 23.66468 - diff: 20.45mlTrain batch 2/16 - 162.7ms/batch - loss: 36.99382 - diff: 24.16mlTrain batch 3/16 - 164.4ms/batch - loss: 36.06707 - diff: 25.24mlTrain batch 4/16 - 162.9ms/batch - loss: 41.23264 - diff: 28.23mlTrain batch 5/16 - 163.2ms/batch - loss: 60.99219 - diff: 32.39mlTrain batch 6/16 - 162.9ms/batch - loss: 61.10901 - diff: 33.03mlTrain batch 7/16 - 162.9ms/batch - loss: 79.13023 - diff: 35.11mlTrain batch 8/16 - 163.0ms/batch - loss: 83.73025 - diff: 36.73mlTrain batch 9/16 - 162.8ms/batch - loss: 82.65639 - diff: 36.98mlTrain batch 10/16 - 162.8ms/batch - loss: 81.44620 - diff: 36.87mlTrain batch 11/16 - 163.0ms/batch - loss: 82.00125 - diff: 36.91mlTrain batch 12/16 - 162.9ms/batch - loss: 79.28398 - diff: 36.58mlTrain batch 13/16 - 177.6ms/batch - loss: 78.16421 - diff: 36.76mlTrain batch 14/16 - 163.0ms/batch - loss: 75.22679 - diff: 35.99mlTrain batch 15/16 - 162.8ms/batch - loss: 76.30227 - diff: 36.14mlTrain batch 16/16 - 59.0ms/batch - loss: 82.83803 - diff: 36.31mlTrain batch 16/16 - 17.4s 59.0ms/batch - loss: 82.83803 - diff: 36.31ml
Test 1.1s: val_loss: 62.39108 - diff: 30.12ml

Epoch 105: current best loss = 48.94625, at epoch 100
Train batch 1/16 - 180.7ms/batch - loss: 45.05232 - diff: 29.05mlTrain batch 2/16 - 162.9ms/batch - loss: 52.37393 - diff: 32.16mlTrain batch 3/16 - 163.0ms/batch - loss: 52.64827 - diff: 31.69mlTrain batch 4/16 - 163.0ms/batch - loss: 59.82090 - diff: 34.40mlTrain batch 5/16 - 167.0ms/batch - loss: 78.30175 - diff: 35.57mlTrain batch 6/16 - 162.6ms/batch - loss: 72.63726 - diff: 34.53mlTrain batch 7/16 - 163.0ms/batch - loss: 68.94313 - diff: 34.28mlTrain batch 8/16 - 162.9ms/batch - loss: 65.39666 - diff: 33.64mlTrain batch 9/16 - 162.8ms/batch - loss: 64.73526 - diff: 33.59mlTrain batch 10/16 - 167.1ms/batch - loss: 63.89905 - diff: 33.72mlTrain batch 11/16 - 176.1ms/batch - loss: 63.81071 - diff: 33.60mlTrain batch 12/16 - 163.1ms/batch - loss: 66.47542 - diff: 34.13mlTrain batch 13/16 - 162.7ms/batch - loss: 66.65314 - diff: 34.29mlTrain batch 14/16 - 180.1ms/batch - loss: 65.52897 - diff: 34.23mlTrain batch 15/16 - 163.0ms/batch - loss: 65.90771 - diff: 34.20mlTrain batch 16/16 - 54.9ms/batch - loss: 67.72683 - diff: 34.13mlTrain batch 16/16 - 15.1s 54.9ms/batch - loss: 67.72683 - diff: 34.13ml
Test 1.2s: val_loss: 48.50952 - diff: 30.32ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_VGG19_Adam-0.001_MSE_DA3_best

Epoch 106: current best loss = 48.50952, at epoch 105
Train batch 1/16 - 173.8ms/batch - loss: 86.27366 - diff: 42.86mlTrain batch 2/16 - 164.3ms/batch - loss: 77.44819 - diff: 37.90mlTrain batch 3/16 - 187.8ms/batch - loss: 104.25399 - diff: 40.40mlTrain batch 4/16 - 163.3ms/batch - loss: 87.26619 - diff: 37.13mlTrain batch 5/16 - 163.0ms/batch - loss: 79.41717 - diff: 36.21mlTrain batch 6/16 - 165.2ms/batch - loss: 80.92258 - diff: 36.64mlTrain batch 7/16 - 180.8ms/batch - loss: 75.67755 - diff: 35.62mlTrain batch 8/16 - 172.4ms/batch - loss: 71.34649 - diff: 34.38mlTrain batch 9/16 - 163.0ms/batch - loss: 74.40592 - diff: 35.04mlTrain batch 10/16 - 171.7ms/batch - loss: 72.38882 - diff: 34.73mlTrain batch 11/16 - 163.1ms/batch - loss: 72.59265 - diff: 35.21mlTrain batch 12/16 - 169.6ms/batch - loss: 69.05101 - diff: 34.47mlTrain batch 13/16 - 165.0ms/batch - loss: 69.62317 - diff: 34.65mlTrain batch 14/16 - 162.0ms/batch - loss: 70.85591 - diff: 34.74mlTrain batch 15/16 - 162.9ms/batch - loss: 68.40501 - diff: 34.28mlTrain batch 16/16 - 63.3ms/batch - loss: 78.97787 - diff: 34.59mlTrain batch 16/16 - 16.6s 63.3ms/batch - loss: 78.97787 - diff: 34.59ml
Test 1.2s: val_loss: 60.92740 - diff: 32.29ml

Epoch 107: current best loss = 48.50952, at epoch 105
Train batch 1/16 - 188.4ms/batch - loss: 57.68787 - diff: 30.37mlTrain batch 2/16 - 163.1ms/batch - loss: 58.48476 - diff: 32.57mlTrain batch 3/16 - 195.2ms/batch - loss: 68.10133 - diff: 35.74mlTrain batch 4/16 - 171.5ms/batch - loss: 87.04901 - diff: 40.91mlTrain batch 5/16 - 183.3ms/batch - loss: 79.86214 - diff: 38.65mlTrain batch 6/16 - 162.8ms/batch - loss: 77.80923 - diff: 37.64mlTrain batch 7/16 - 163.0ms/batch - loss: 78.13815 - diff: 37.10mlTrain batch 8/16 - 163.0ms/batch - loss: 77.11701 - diff: 37.06mlTrain batch 9/16 - 163.0ms/batch - loss: 72.47785 - diff: 35.68mlTrain batch 10/16 - 162.7ms/batch - loss: 69.05610 - diff: 35.00mlTrain batch 11/16 - 183.9ms/batch - loss: 67.31956 - diff: 34.66mlTrain batch 12/16 - 173.8ms/batch - loss: 66.59338 - diff: 34.82mlTrain batch 13/16 - 186.7ms/batch - loss: 71.36581 - diff: 35.48mlTrain batch 14/16 - 172.6ms/batch - loss: 78.65951 - diff: 36.37mlTrain batch 15/16 - 162.7ms/batch - loss: 79.11665 - diff: 36.55mlTrain batch 16/16 - 54.9ms/batch - loss: 79.89103 - diff: 36.44mlTrain batch 16/16 - 18.2s 54.9ms/batch - loss: 79.89103 - diff: 36.44ml
Test 1.2s: val_loss: 50.85906 - diff: 29.56ml

Epoch 108: current best loss = 48.50952, at epoch 105
Train batch 1/16 - 179.3ms/batch - loss: 75.62391 - diff: 35.00mlTrain batch 2/16 - 162.9ms/batch - loss: 76.64599 - diff: 36.19mlTrain batch 3/16 - 163.4ms/batch - loss: 80.41607 - diff: 37.78mlTrain batch 4/16 - 172.1ms/batch - loss: 80.80742 - diff: 37.34mlTrain batch 5/16 - 162.8ms/batch - loss: 80.75215 - diff: 36.66mlTrain batch 6/16 - 163.2ms/batch - loss: 76.83257 - diff: 36.08mlTrain batch 7/16 - 162.5ms/batch - loss: 87.31388 - diff: 36.89mlTrain batch 8/16 - 162.9ms/batch - loss: 88.31571 - diff: 37.57mlTrain batch 9/16 - 168.5ms/batch - loss: 86.42792 - diff: 37.38mlTrain batch 10/16 - 162.9ms/batch - loss: 82.04216 - diff: 36.61mlTrain batch 11/16 - 163.1ms/batch - loss: 80.94991 - diff: 36.62mlTrain batch 12/16 - 162.8ms/batch - loss: 77.26679 - diff: 35.89mlTrain batch 13/16 - 163.1ms/batch - loss: 77.79137 - diff: 36.08mlTrain batch 14/16 - 169.2ms/batch - loss: 75.90479 - diff: 35.81mlTrain batch 15/16 - 163.0ms/batch - loss: 74.88677 - diff: 35.90mlTrain batch 16/16 - 54.9ms/batch - loss: 78.40291 - diff: 35.88mlTrain batch 16/16 - 17.4s 54.9ms/batch - loss: 78.40291 - diff: 35.88ml
Test 1.1s: val_loss: 57.19079 - diff: 32.97ml

Epoch 109: current best loss = 48.50952, at epoch 105
Train batch 1/16 - 180.7ms/batch - loss: 86.17664 - diff: 42.29mlTrain batch 2/16 - 172.1ms/batch - loss: 82.42248 - diff: 41.07mlTrain batch 3/16 - 177.2ms/batch - loss: 73.90380 - diff: 38.79mlTrain batch 4/16 - 169.3ms/batch - loss: 71.17364 - diff: 37.58mlTrain batch 5/16 - 178.3ms/batch - loss: 74.36064 - diff: 37.94mlTrain batch 6/16 - 168.6ms/batch - loss: 70.59029 - diff: 36.73mlTrain batch 7/16 - 162.9ms/batch - loss: 67.82515 - diff: 36.51mlTrain batch 8/16 - 163.5ms/batch - loss: 64.46524 - diff: 35.37mlTrain batch 9/16 - 162.9ms/batch - loss: 82.38830 - diff: 36.17mlTrain batch 10/16 - 163.0ms/batch - loss: 78.30956 - diff: 35.44mlTrain batch 11/16 - 168.2ms/batch - loss: 76.80602 - diff: 35.11mlTrain batch 12/16 - 163.1ms/batch - loss: 77.37790 - diff: 35.25mlTrain batch 13/16 - 177.6ms/batch - loss: 75.00255 - diff: 34.75mlTrain batch 14/16 - 162.9ms/batch - loss: 79.38970 - diff: 36.08mlTrain batch 15/16 - 162.7ms/batch - loss: 77.27540 - diff: 35.76mlTrain batch 16/16 - 54.9ms/batch - loss: 79.36052 - diff: 35.72mlTrain batch 16/16 - 15.1s 54.9ms/batch - loss: 79.36052 - diff: 35.72ml
Test 1.2s: val_loss: 75.17726 - diff: 30.88ml

Epoch 110: current best loss = 48.50952, at epoch 105
Train batch 1/16 - 186.4ms/batch - loss: 48.36842 - diff: 32.76mlTrain batch 2/16 - 162.7ms/batch - loss: 85.88476 - diff: 40.69mlTrain batch 3/16 - 162.9ms/batch - loss: 73.37883 - diff: 37.61mlTrain batch 4/16 - 165.0ms/batch - loss: 73.34173 - diff: 38.01mlTrain batch 5/16 - 163.0ms/batch - loss: 71.24837 - diff: 37.82mlTrain batch 6/16 - 162.9ms/batch - loss: 67.17220 - diff: 36.23mlTrain batch 7/16 - 164.6ms/batch - loss: 68.01494 - diff: 36.56mlTrain batch 8/16 - 162.8ms/batch - loss: 65.90728 - diff: 36.03mlTrain batch 9/16 - 163.0ms/batch - loss: 64.32935 - diff: 35.74mlTrain batch 10/16 - 171.8ms/batch - loss: 62.91478 - diff: 35.23mlTrain batch 11/16 - 162.5ms/batch - loss: 61.04597 - diff: 34.69mlTrain batch 12/16 - 169.9ms/batch - loss: 59.10390 - diff: 34.21mlTrain batch 13/16 - 178.2ms/batch - loss: 61.93063 - diff: 34.52mlTrain batch 14/16 - 178.3ms/batch - loss: 69.24613 - diff: 34.80mlTrain batch 15/16 - 162.8ms/batch - loss: 70.62730 - diff: 35.13mlTrain batch 16/16 - 55.0ms/batch - loss: 84.31723 - diff: 35.60mlTrain batch 16/16 - 16.8s 55.0ms/batch - loss: 84.31723 - diff: 35.60ml
Test 1.3s: val_loss: 68.83886 - diff: 38.12ml

Epoch 111: current best loss = 48.50952, at epoch 105
Train batch 1/16 - 180.6ms/batch - loss: 107.19872 - diff: 51.22mlTrain batch 2/16 - 187.3ms/batch - loss: 100.55992 - diff: 48.54mlTrain batch 3/16 - 173.7ms/batch - loss: 86.21082 - diff: 44.05mlTrain batch 4/16 - 169.8ms/batch - loss: 89.64074 - diff: 43.25mlTrain batch 5/16 - 179.4ms/batch - loss: 80.56178 - diff: 40.72mlTrain batch 6/16 - 163.4ms/batch - loss: 82.59232 - diff: 40.74mlTrain batch 7/16 - 164.7ms/batch - loss: 80.58287 - diff: 39.83mlTrain batch 8/16 - 162.9ms/batch - loss: 80.69167 - diff: 39.32mlTrain batch 9/16 - 162.9ms/batch - loss: 81.65017 - diff: 39.32mlTrain batch 10/16 - 181.0ms/batch - loss: 79.66294 - diff: 39.11mlTrain batch 11/16 - 163.1ms/batch - loss: 78.76201 - diff: 38.80mlTrain batch 12/16 - 164.5ms/batch - loss: 80.68325 - diff: 39.58mlTrain batch 13/16 - 176.6ms/batch - loss: 79.03631 - diff: 38.83mlTrain batch 14/16 - 163.2ms/batch - loss: 78.39185 - diff: 38.50mlTrain batch 15/16 - 175.2ms/batch - loss: 88.66410 - diff: 39.26mlTrain batch 16/16 - 61.8ms/batch - loss: 89.69575 - diff: 39.10mlTrain batch 16/16 - 16.8s 61.8ms/batch - loss: 89.69575 - diff: 39.10ml
Test 1.1s: val_loss: 64.16839 - diff: 32.24ml

Epoch 112: current best loss = 48.50952, at epoch 105
Train batch 1/16 - 180.9ms/batch - loss: 53.85077 - diff: 28.10mlTrain batch 2/16 - 162.7ms/batch - loss: 48.91416 - diff: 27.79mlTrain batch 3/16 - 162.9ms/batch - loss: 54.22332 - diff: 31.29mlTrain batch 4/16 - 162.9ms/batch - loss: 50.47134 - diff: 30.64mlTrain batch 5/16 - 162.7ms/batch - loss: 54.95688 - diff: 32.76mlTrain batch 6/16 - 163.1ms/batch - loss: 58.77848 - diff: 33.80mlTrain batch 7/16 - 169.0ms/batch - loss: 63.40690 - diff: 34.68mlTrain batch 8/16 - 165.6ms/batch - loss: 60.37205 - diff: 33.89mlTrain batch 9/16 - 162.9ms/batch - loss: 58.47291 - diff: 33.12mlTrain batch 10/16 - 162.9ms/batch - loss: 75.00029 - diff: 35.02mlTrain batch 11/16 - 163.2ms/batch - loss: 71.83647 - diff: 34.50mlTrain batch 12/16 - 162.9ms/batch - loss: 68.20066 - diff: 33.66mlTrain batch 13/16 - 163.1ms/batch - loss: 68.46730 - diff: 34.19mlTrain batch 14/16 - 163.1ms/batch - loss: 68.51420 - diff: 34.11mlTrain batch 15/16 - 163.2ms/batch - loss: 67.20254 - diff: 33.93mlTrain batch 16/16 - 54.8ms/batch - loss: 68.26392 - diff: 33.84mlTrain batch 16/16 - 15.4s 54.8ms/batch - loss: 68.26392 - diff: 33.84ml
Test 1.1s: val_loss: 52.70347 - diff: 29.62ml

Epoch 113: current best loss = 48.50952, at epoch 105
Train batch 1/16 - 180.7ms/batch - loss: 47.94202 - diff: 28.05mlTrain batch 2/16 - 173.0ms/batch - loss: 53.97745 - diff: 31.18mlTrain batch 3/16 - 162.9ms/batch - loss: 48.33940 - diff: 29.43mlTrain batch 4/16 - 166.2ms/batch - loss: 53.31949 - diff: 30.32mlTrain batch 5/16 - 183.1ms/batch - loss: 60.29968 - diff: 32.14mlTrain batch 6/16 - 167.8ms/batch - loss: 61.21367 - diff: 31.89mlTrain batch 7/16 - 166.2ms/batch - loss: 59.85073 - diff: 32.03mlTrain batch 8/16 - 172.8ms/batch - loss: 60.09509 - diff: 32.69mlTrain batch 9/16 - 162.8ms/batch - loss: 62.27750 - diff: 33.69mlTrain batch 10/16 - 164.1ms/batch - loss: 62.00188 - diff: 33.66mlTrain batch 11/16 - 173.9ms/batch - loss: 60.75891 - diff: 33.45mlTrain batch 12/16 - 162.7ms/batch - loss: 67.25755 - diff: 34.74mlTrain batch 13/16 - 170.1ms/batch - loss: 67.69419 - diff: 35.00mlTrain batch 14/16 - 163.2ms/batch - loss: 67.00473 - diff: 34.87mlTrain batch 15/16 - 163.0ms/batch - loss: 74.73434 - diff: 35.66mlTrain batch 16/16 - 55.0ms/batch - loss: 76.24076 - diff: 35.55mlTrain batch 16/16 - 14.5s 55.0ms/batch - loss: 76.24076 - diff: 35.55ml
Test 1.1s: val_loss: 52.64057 - diff: 30.93ml

Epoch 114: current best loss = 48.50952, at epoch 105
Train batch 1/16 - 180.9ms/batch - loss: 109.44019 - diff: 46.62mlTrain batch 2/16 - 167.4ms/batch - loss: 78.60450 - diff: 39.53mlTrain batch 3/16 - 162.8ms/batch - loss: 71.34327 - diff: 38.45mlTrain batch 4/16 - 166.0ms/batch - loss: 98.00918 - diff: 40.14mlTrain batch 5/16 - 178.9ms/batch - loss: 89.62848 - diff: 38.39mlTrain batch 6/16 - 171.1ms/batch - loss: 91.18658 - diff: 38.77mlTrain batch 7/16 - 163.0ms/batch - loss: 86.42947 - diff: 38.61mlTrain batch 8/16 - 163.4ms/batch - loss: 82.31902 - diff: 37.48mlTrain batch 9/16 - 163.0ms/batch - loss: 85.44617 - diff: 38.21mlTrain batch 10/16 - 164.3ms/batch - loss: 83.17492 - diff: 37.49mlTrain batch 11/16 - 181.3ms/batch - loss: 81.67352 - diff: 37.33mlTrain batch 12/16 - 170.1ms/batch - loss: 79.65477 - diff: 36.92mlTrain batch 13/16 - 163.0ms/batch - loss: 76.40209 - diff: 36.20mlTrain batch 14/16 - 163.5ms/batch - loss: 75.05880 - diff: 35.98mlTrain batch 15/16 - 182.6ms/batch - loss: 74.77816 - diff: 35.96mlTrain batch 16/16 - 62.3ms/batch - loss: 78.78053 - diff: 35.97mlTrain batch 16/16 - 16.6s 62.3ms/batch - loss: 78.78053 - diff: 35.97ml
Test 1.2s: val_loss: 48.11186 - diff: 28.45ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_VGG19_Adam-0.001_MSE_DA3_best

Epoch 115: current best loss = 48.11186, at epoch 114
Train batch 1/16 - 179.8ms/batch - loss: 56.32944 - diff: 31.15mlTrain batch 2/16 - 163.0ms/batch - loss: 50.12432 - diff: 29.75mlTrain batch 3/16 - 176.5ms/batch - loss: 50.25064 - diff: 28.97mlTrain batch 4/16 - 171.2ms/batch - loss: 59.96582 - diff: 32.03mlTrain batch 5/16 - 165.7ms/batch - loss: 61.17832 - diff: 33.02mlTrain batch 6/16 - 163.9ms/batch - loss: 76.10255 - diff: 35.54mlTrain batch 7/16 - 180.3ms/batch - loss: 72.54429 - diff: 35.32mlTrain batch 8/16 - 165.3ms/batch - loss: 67.80517 - diff: 33.66mlTrain batch 9/16 - 162.6ms/batch - loss: 65.84221 - diff: 33.43mlTrain batch 10/16 - 163.3ms/batch - loss: 71.78540 - diff: 34.56mlTrain batch 11/16 - 162.8ms/batch - loss: 70.45897 - diff: 34.30mlTrain batch 12/16 - 163.6ms/batch - loss: 71.21365 - diff: 34.84mlTrain batch 13/16 - 162.9ms/batch - loss: 69.27389 - diff: 34.34mlTrain batch 14/16 - 164.6ms/batch - loss: 66.63678 - diff: 33.80mlTrain batch 15/16 - 162.6ms/batch - loss: 66.46635 - diff: 34.01mlTrain batch 16/16 - 54.9ms/batch - loss: 76.17358 - diff: 34.34mlTrain batch 16/16 - 15.0s 54.9ms/batch - loss: 76.17358 - diff: 34.34ml
Test 1.3s: val_loss: 47.94879 - diff: 28.07ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_VGG19_Adam-0.001_MSE_DA3_best

Epoch 116: current best loss = 47.94879, at epoch 115
Train batch 1/16 - 176.8ms/batch - loss: 79.30820 - diff: 36.00mlTrain batch 2/16 - 162.9ms/batch - loss: 77.75221 - diff: 35.57mlTrain batch 3/16 - 162.8ms/batch - loss: 81.03237 - diff: 37.81mlTrain batch 4/16 - 163.1ms/batch - loss: 72.33966 - diff: 36.01mlTrain batch 5/16 - 162.7ms/batch - loss: 71.64055 - diff: 35.17mlTrain batch 6/16 - 163.0ms/batch - loss: 71.20368 - diff: 35.50mlTrain batch 7/16 - 172.1ms/batch - loss: 67.01027 - diff: 34.84mlTrain batch 8/16 - 163.2ms/batch - loss: 81.46131 - diff: 36.77mlTrain batch 9/16 - 165.8ms/batch - loss: 86.53195 - diff: 38.45mlTrain batch 10/16 - 163.6ms/batch - loss: 85.55560 - diff: 38.56mlTrain batch 11/16 - 162.8ms/batch - loss: 82.30132 - diff: 37.65mlTrain batch 12/16 - 163.4ms/batch - loss: 82.16824 - diff: 37.19mlTrain batch 13/16 - 163.0ms/batch - loss: 81.15301 - diff: 36.97mlTrain batch 14/16 - 162.8ms/batch - loss: 79.28111 - diff: 36.49mlTrain batch 15/16 - 162.8ms/batch - loss: 79.84410 - diff: 37.05mlTrain batch 16/16 - 54.8ms/batch - loss: 81.71791 - diff: 36.98mlTrain batch 16/16 - 16.7s 54.8ms/batch - loss: 81.71791 - diff: 36.98ml
Test 1.2s: val_loss: 46.44112 - diff: 28.78ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_VGG19_Adam-0.001_MSE_DA3_best

Epoch 117: current best loss = 46.44112, at epoch 116
Train batch 1/16 - 187.3ms/batch - loss: 53.81496 - diff: 32.64mlTrain batch 2/16 - 170.8ms/batch - loss: 46.72302 - diff: 31.58mlTrain batch 3/16 - 162.9ms/batch - loss: 53.02667 - diff: 34.06mlTrain batch 4/16 - 162.8ms/batch - loss: 68.71868 - diff: 37.37mlTrain batch 5/16 - 163.1ms/batch - loss: 90.94895 - diff: 37.91mlTrain batch 6/16 - 163.8ms/batch - loss: 87.88791 - diff: 37.73mlTrain batch 7/16 - 162.9ms/batch - loss: 81.33840 - diff: 36.31mlTrain batch 8/16 - 163.2ms/batch - loss: 80.98561 - diff: 36.93mlTrain batch 9/16 - 174.8ms/batch - loss: 81.45677 - diff: 36.95mlTrain batch 10/16 - 163.0ms/batch - loss: 76.27595 - diff: 35.66mlTrain batch 11/16 - 163.1ms/batch - loss: 75.17153 - diff: 35.50mlTrain batch 12/16 - 162.9ms/batch - loss: 74.09240 - diff: 35.38mlTrain batch 13/16 - 180.8ms/batch - loss: 72.79481 - diff: 35.32mlTrain batch 14/16 - 165.2ms/batch - loss: 71.70894 - diff: 34.97mlTrain batch 15/16 - 163.0ms/batch - loss: 69.69773 - diff: 34.60mlTrain batch 16/16 - 54.9ms/batch - loss: 73.50119 - diff: 34.59mlTrain batch 16/16 - 17.2s 54.9ms/batch - loss: 73.50119 - diff: 34.59ml
Test 1.3s: val_loss: 52.74181 - diff: 33.29ml

Epoch 118: current best loss = 46.44112, at epoch 116
Train batch 1/16 - 182.0ms/batch - loss: 206.52103 - diff: 55.02mlTrain batch 2/16 - 167.5ms/batch - loss: 141.70038 - diff: 46.52mlTrain batch 3/16 - 166.6ms/batch - loss: 123.08858 - diff: 44.02mlTrain batch 4/16 - 163.2ms/batch - loss: 109.94705 - diff: 41.79mlTrain batch 5/16 - 202.6ms/batch - loss: 99.44506 - diff: 40.21mlTrain batch 6/16 - 163.1ms/batch - loss: 91.49651 - diff: 39.14mlTrain batch 7/16 - 162.8ms/batch - loss: 89.95583 - diff: 39.27mlTrain batch 8/16 - 171.3ms/batch - loss: 85.24031 - diff: 38.30mlTrain batch 9/16 - 179.4ms/batch - loss: 81.21756 - diff: 37.30mlTrain batch 10/16 - 163.1ms/batch - loss: 79.88746 - diff: 37.62mlTrain batch 11/16 - 182.9ms/batch - loss: 80.00856 - diff: 38.01mlTrain batch 12/16 - 162.9ms/batch - loss: 77.37739 - diff: 37.62mlTrain batch 13/16 - 163.0ms/batch - loss: 75.32909 - diff: 36.97mlTrain batch 14/16 - 164.5ms/batch - loss: 72.44699 - diff: 36.24mlTrain batch 15/16 - 163.0ms/batch - loss: 70.87702 - diff: 35.83mlTrain batch 16/16 - 54.9ms/batch - loss: 80.64640 - diff: 36.15mlTrain batch 16/16 - 16.0s 54.9ms/batch - loss: 80.64640 - diff: 36.15ml
Test 1.2s: val_loss: 43.48765 - diff: 28.22ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_VGG19_Adam-0.001_MSE_DA3_best

Epoch 119: current best loss = 43.48765, at epoch 118
Train batch 1/16 - 180.9ms/batch - loss: 49.59611 - diff: 31.75mlTrain batch 2/16 - 162.8ms/batch - loss: 63.70686 - diff: 34.59mlTrain batch 3/16 - 168.7ms/batch - loss: 66.26620 - diff: 35.60mlTrain batch 4/16 - 163.0ms/batch - loss: 65.21384 - diff: 36.07mlTrain batch 5/16 - 175.5ms/batch - loss: 65.61977 - diff: 37.24mlTrain batch 6/16 - 163.0ms/batch - loss: 84.92804 - diff: 38.59mlTrain batch 7/16 - 180.2ms/batch - loss: 79.79901 - diff: 37.48mlTrain batch 8/16 - 162.9ms/batch - loss: 86.22712 - diff: 38.72mlTrain batch 9/16 - 163.3ms/batch - loss: 83.07917 - diff: 37.76mlTrain batch 10/16 - 173.4ms/batch - loss: 81.11255 - diff: 37.41mlTrain batch 11/16 - 163.6ms/batch - loss: 76.96173 - diff: 36.46mlTrain batch 12/16 - 163.1ms/batch - loss: 76.20850 - diff: 36.40mlTrain batch 13/16 - 176.2ms/batch - loss: 75.74579 - diff: 36.50mlTrain batch 14/16 - 169.2ms/batch - loss: 73.62866 - diff: 36.11mlTrain batch 15/16 - 167.8ms/batch - loss: 73.26067 - diff: 36.10mlTrain batch 16/16 - 55.0ms/batch - loss: 73.83343 - diff: 35.95mlTrain batch 16/16 - 16.0s 55.0ms/batch - loss: 73.83343 - diff: 35.95ml
Test 1.1s: val_loss: 80.80829 - diff: 37.45ml

Epoch 120: current best loss = 43.48765, at epoch 118
Train batch 1/16 - 177.6ms/batch - loss: 71.86638 - diff: 38.65mlTrain batch 2/16 - 172.8ms/batch - loss: 120.73427 - diff: 37.48mlTrain batch 3/16 - 214.2ms/batch - loss: 103.65868 - diff: 36.68mlTrain batch 4/16 - 162.9ms/batch - loss: 85.79332 - diff: 33.87mlTrain batch 5/16 - 169.3ms/batch - loss: 78.64909 - diff: 33.38mlTrain batch 6/16 - 170.5ms/batch - loss: 73.47148 - diff: 33.31mlTrain batch 7/16 - 162.9ms/batch - loss: 69.60934 - diff: 33.27mlTrain batch 8/16 - 163.7ms/batch - loss: 67.55731 - diff: 33.19mlTrain batch 9/16 - 163.2ms/batch - loss: 70.65011 - diff: 33.55mlTrain batch 10/16 - 163.3ms/batch - loss: 67.53239 - diff: 33.11mlTrain batch 11/16 - 162.8ms/batch - loss: 68.13602 - diff: 33.30mlTrain batch 12/16 - 163.3ms/batch - loss: 66.01352 - diff: 33.04mlTrain batch 13/16 - 163.1ms/batch - loss: 66.35719 - diff: 33.22mlTrain batch 14/16 - 163.0ms/batch - loss: 66.52409 - diff: 33.34mlTrain batch 15/16 - 162.9ms/batch - loss: 68.85967 - diff: 34.14mlTrain batch 16/16 - 54.9ms/batch - loss: 70.16363 - diff: 34.07mlTrain batch 16/16 - 14.3s 54.9ms/batch - loss: 70.16363 - diff: 34.07ml
Test 1.1s: val_loss: 44.41762 - diff: 28.20ml

Epoch 121: current best loss = 43.48765, at epoch 118
Train batch 1/16 - 186.1ms/batch - loss: 165.97313 - diff: 40.62mlTrain batch 2/16 - 163.2ms/batch - loss: 113.95798 - diff: 37.45mlTrain batch 3/16 - 176.3ms/batch - loss: 100.88978 - diff: 36.03mlTrain batch 4/16 - 162.8ms/batch - loss: 92.48292 - diff: 36.49mlTrain batch 5/16 - 173.4ms/batch - loss: 92.55429 - diff: 37.11mlTrain batch 6/16 - 163.6ms/batch - loss: 87.17326 - diff: 37.39mlTrain batch 7/16 - 216.9ms/batch - loss: 82.70149 - diff: 37.02mlTrain batch 8/16 - 164.7ms/batch - loss: 76.26963 - diff: 35.59mlTrain batch 9/16 - 177.6ms/batch - loss: 71.91375 - diff: 34.51mlTrain batch 10/16 - 171.3ms/batch - loss: 72.23725 - diff: 35.02mlTrain batch 11/16 - 162.9ms/batch - loss: 73.12798 - diff: 35.13mlTrain batch 12/16 - 163.5ms/batch - loss: 70.49082 - diff: 34.62mlTrain batch 13/16 - 163.1ms/batch - loss: 69.53029 - diff: 34.50mlTrain batch 14/16 - 162.9ms/batch - loss: 66.75313 - diff: 33.88mlTrain batch 15/16 - 162.8ms/batch - loss: 64.23373 - diff: 33.41mlTrain batch 16/16 - 54.9ms/batch - loss: 65.78420 - diff: 33.34mlTrain batch 16/16 - 15.8s 54.9ms/batch - loss: 65.78420 - diff: 33.34ml
Test 1.3s: val_loss: 46.67632 - diff: 28.15ml

Epoch 122: current best loss = 43.48765, at epoch 118
Train batch 1/16 - 180.6ms/batch - loss: 37.63572 - diff: 26.69mlTrain batch 2/16 - 166.3ms/batch - loss: 44.34887 - diff: 29.49mlTrain batch 3/16 - 163.2ms/batch - loss: 84.85951 - diff: 31.44mlTrain batch 4/16 - 163.0ms/batch - loss: 82.86796 - diff: 33.49mlTrain batch 5/16 - 177.1ms/batch - loss: 82.38849 - diff: 35.07mlTrain batch 6/16 - 163.3ms/batch - loss: 75.85719 - diff: 33.94mlTrain batch 7/16 - 162.8ms/batch - loss: 70.93714 - diff: 33.43mlTrain batch 8/16 - 166.1ms/batch - loss: 66.47346 - diff: 32.22mlTrain batch 9/16 - 162.9ms/batch - loss: 65.16927 - diff: 32.33mlTrain batch 10/16 - 162.8ms/batch - loss: 66.55347 - diff: 33.01mlTrain batch 11/16 - 162.9ms/batch - loss: 64.58750 - diff: 32.66mlTrain batch 12/16 - 162.7ms/batch - loss: 64.66753 - diff: 32.80mlTrain batch 13/16 - 163.0ms/batch - loss: 64.75304 - diff: 33.32mlTrain batch 14/16 - 163.1ms/batch - loss: 67.78942 - diff: 33.87mlTrain batch 15/16 - 162.8ms/batch - loss: 66.50721 - diff: 33.70mlTrain batch 16/16 - 54.9ms/batch - loss: 67.90270 - diff: 33.67mlTrain batch 16/16 - 16.5s 54.9ms/batch - loss: 67.90270 - diff: 33.67ml
Test 1.1s: val_loss: 47.41906 - diff: 27.73ml

Epoch 123: current best loss = 43.48765, at epoch 118
Train batch 1/16 - 180.8ms/batch - loss: 33.31455 - diff: 28.58mlTrain batch 2/16 - 165.1ms/batch - loss: 52.28178 - diff: 34.27mlTrain batch 3/16 - 163.2ms/batch - loss: 69.95165 - diff: 36.94mlTrain batch 4/16 - 163.6ms/batch - loss: 74.13575 - diff: 36.98mlTrain batch 5/16 - 162.9ms/batch - loss: 66.16706 - diff: 34.96mlTrain batch 6/16 - 162.9ms/batch - loss: 64.76104 - diff: 34.91mlTrain batch 7/16 - 163.1ms/batch - loss: 61.96437 - diff: 34.51mlTrain batch 8/16 - 173.5ms/batch - loss: 61.50294 - diff: 34.22mlTrain batch 9/16 - 166.4ms/batch - loss: 73.72860 - diff: 35.46mlTrain batch 10/16 - 180.4ms/batch - loss: 72.25853 - diff: 35.09mlTrain batch 11/16 - 171.9ms/batch - loss: 68.52145 - diff: 34.17mlTrain batch 12/16 - 162.9ms/batch - loss: 67.23442 - diff: 34.05mlTrain batch 13/16 - 163.0ms/batch - loss: 65.00423 - diff: 33.55mlTrain batch 14/16 - 180.8ms/batch - loss: 65.40234 - diff: 33.57mlTrain batch 15/16 - 173.5ms/batch - loss: 65.57244 - diff: 33.56mlTrain batch 16/16 - 54.7ms/batch - loss: 67.86220 - diff: 33.49mlTrain batch 16/16 - 15.8s 54.7ms/batch - loss: 67.86220 - diff: 33.49ml
Test 1.3s: val_loss: 48.25174 - diff: 31.56ml

Epoch 124: current best loss = 43.48765, at epoch 118
Train batch 1/16 - 187.8ms/batch - loss: 63.94484 - diff: 34.61mlTrain batch 2/16 - 163.0ms/batch - loss: 100.73071 - diff: 36.97mlTrain batch 3/16 - 176.1ms/batch - loss: 96.01921 - diff: 38.85mlTrain batch 4/16 - 163.0ms/batch - loss: 82.48616 - diff: 36.72mlTrain batch 5/16 - 163.0ms/batch - loss: 74.22642 - diff: 34.74mlTrain batch 6/16 - 162.9ms/batch - loss: 70.59017 - diff: 33.68mlTrain batch 7/16 - 163.2ms/batch - loss: 67.78112 - diff: 33.06mlTrain batch 8/16 - 163.2ms/batch - loss: 66.74046 - diff: 33.20mlTrain batch 9/16 - 163.0ms/batch - loss: 65.05557 - diff: 32.49mlTrain batch 10/16 - 164.5ms/batch - loss: 64.18835 - diff: 32.60mlTrain batch 11/16 - 163.1ms/batch - loss: 65.08171 - diff: 32.84mlTrain batch 12/16 - 163.0ms/batch - loss: 63.85754 - diff: 32.92mlTrain batch 13/16 - 163.2ms/batch - loss: 65.19884 - diff: 33.12mlTrain batch 14/16 - 163.1ms/batch - loss: 63.46982 - diff: 32.90mlTrain batch 15/16 - 162.9ms/batch - loss: 62.68040 - diff: 32.61mlTrain batch 16/16 - 54.9ms/batch - loss: 63.62171 - diff: 32.52mlTrain batch 16/16 - 16.2s 54.9ms/batch - loss: 63.62171 - diff: 32.52ml
Test 1.1s: val_loss: 40.05533 - diff: 26.68ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_VGG19_Adam-0.001_MSE_DA3_best

Epoch 125: current best loss = 40.05533, at epoch 124
Train batch 1/16 - 180.8ms/batch - loss: 42.79050 - diff: 28.33mlTrain batch 2/16 - 179.4ms/batch - loss: 47.39038 - diff: 31.06mlTrain batch 3/16 - 181.1ms/batch - loss: 43.65234 - diff: 29.90mlTrain batch 4/16 - 166.0ms/batch - loss: 66.64020 - diff: 33.74mlTrain batch 5/16 - 163.1ms/batch - loss: 64.56203 - diff: 33.67mlTrain batch 6/16 - 163.2ms/batch - loss: 65.40999 - diff: 34.47mlTrain batch 7/16 - 163.2ms/batch - loss: 65.74933 - diff: 34.69mlTrain batch 8/16 - 163.3ms/batch - loss: 63.86087 - diff: 34.04mlTrain batch 9/16 - 163.0ms/batch - loss: 67.95385 - diff: 35.24mlTrain batch 10/16 - 163.7ms/batch - loss: 67.93874 - diff: 35.20mlTrain batch 11/16 - 163.0ms/batch - loss: 69.51442 - diff: 35.39mlTrain batch 12/16 - 162.8ms/batch - loss: 67.55880 - diff: 34.78mlTrain batch 13/16 - 176.2ms/batch - loss: 69.35325 - diff: 35.51mlTrain batch 14/16 - 165.8ms/batch - loss: 69.81007 - diff: 35.73mlTrain batch 15/16 - 164.2ms/batch - loss: 69.24293 - diff: 35.82mlTrain batch 16/16 - 57.6ms/batch - loss: 79.55774 - diff: 36.14mlTrain batch 16/16 - 15.6s 57.6ms/batch - loss: 79.55774 - diff: 36.14ml
Test 1.3s: val_loss: 48.41743 - diff: 28.38ml

Epoch 126: current best loss = 40.05533, at epoch 124
Train batch 1/16 - 181.5ms/batch - loss: 73.47470 - diff: 37.86mlTrain batch 2/16 - 163.1ms/batch - loss: 60.93528 - diff: 34.49mlTrain batch 3/16 - 163.0ms/batch - loss: 52.70062 - diff: 32.44mlTrain batch 4/16 - 163.1ms/batch - loss: 52.75150 - diff: 33.28mlTrain batch 5/16 - 163.2ms/batch - loss: 84.51912 - diff: 37.03mlTrain batch 6/16 - 163.0ms/batch - loss: 90.56796 - diff: 39.24mlTrain batch 7/16 - 163.0ms/batch - loss: 88.04620 - diff: 38.44mlTrain batch 8/16 - 164.8ms/batch - loss: 83.10758 - diff: 37.57mlTrain batch 9/16 - 162.8ms/batch - loss: 76.98946 - diff: 35.85mlTrain batch 10/16 - 162.8ms/batch - loss: 74.00031 - diff: 35.18mlTrain batch 11/16 - 170.5ms/batch - loss: 71.26183 - diff: 34.86mlTrain batch 12/16 - 163.6ms/batch - loss: 69.87615 - diff: 34.84mlTrain batch 13/16 - 166.6ms/batch - loss: 67.22883 - diff: 34.18mlTrain batch 14/16 - 168.3ms/batch - loss: 65.89897 - diff: 34.08mlTrain batch 15/16 - 162.8ms/batch - loss: 65.60722 - diff: 34.11mlTrain batch 16/16 - 54.8ms/batch - loss: 66.88119 - diff: 34.03mlTrain batch 16/16 - 15.9s 54.8ms/batch - loss: 66.88119 - diff: 34.03ml
Test 1.2s: val_loss: 36.97311 - diff: 26.53ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_VGG19_Adam-0.001_MSE_DA3_best

Epoch 127: current best loss = 36.97311, at epoch 126
Train batch 1/16 - 179.7ms/batch - loss: 51.47786 - diff: 31.28mlTrain batch 2/16 - 174.7ms/batch - loss: 42.35644 - diff: 29.06mlTrain batch 3/16 - 169.4ms/batch - loss: 91.30802 - diff: 35.08mlTrain batch 4/16 - 163.6ms/batch - loss: 83.14612 - diff: 34.12mlTrain batch 5/16 - 176.1ms/batch - loss: 76.04453 - diff: 33.63mlTrain batch 6/16 - 175.8ms/batch - loss: 75.11732 - diff: 34.20mlTrain batch 7/16 - 175.9ms/batch - loss: 72.16023 - diff: 33.33mlTrain batch 8/16 - 166.7ms/batch - loss: 74.78499 - diff: 34.14mlTrain batch 9/16 - 173.8ms/batch - loss: 73.44719 - diff: 34.07mlTrain batch 10/16 - 175.8ms/batch - loss: 71.06624 - diff: 33.67mlTrain batch 11/16 - 163.0ms/batch - loss: 68.21520 - diff: 32.96mlTrain batch 12/16 - 163.2ms/batch - loss: 66.46951 - diff: 32.59mlTrain batch 13/16 - 163.0ms/batch - loss: 68.59549 - diff: 33.58mlTrain batch 14/16 - 186.1ms/batch - loss: 66.92229 - diff: 33.41mlTrain batch 15/16 - 162.9ms/batch - loss: 64.73688 - diff: 32.99mlTrain batch 16/16 - 55.0ms/batch - loss: 64.53711 - diff: 32.75mlTrain batch 16/16 - 15.9s 55.0ms/batch - loss: 64.53711 - diff: 32.75ml
Test 1.2s: val_loss: 84.00597 - diff: 33.77ml

Epoch 128: current best loss = 36.97311, at epoch 126
Train batch 1/16 - 189.5ms/batch - loss: 86.94536 - diff: 40.38mlTrain batch 2/16 - 167.9ms/batch - loss: 89.95916 - diff: 42.15mlTrain batch 3/16 - 170.9ms/batch - loss: 75.32977 - diff: 38.05mlTrain batch 4/16 - 176.7ms/batch - loss: 65.81068 - diff: 35.59mlTrain batch 5/16 - 202.7ms/batch - loss: 88.21679 - diff: 38.12mlTrain batch 6/16 - 163.1ms/batch - loss: 88.64179 - diff: 38.58mlTrain batch 7/16 - 176.1ms/batch - loss: 96.85508 - diff: 41.28mlTrain batch 8/16 - 166.7ms/batch - loss: 93.46838 - diff: 41.16mlTrain batch 9/16 - 162.9ms/batch - loss: 88.48968 - diff: 40.16mlTrain batch 10/16 - 162.9ms/batch - loss: 85.84133 - diff: 39.28mlTrain batch 11/16 - 171.1ms/batch - loss: 82.89990 - diff: 38.75mlTrain batch 12/16 - 174.6ms/batch - loss: 79.47713 - diff: 38.02mlTrain batch 13/16 - 162.9ms/batch - loss: 77.57268 - diff: 37.75mlTrain batch 14/16 - 176.4ms/batch - loss: 78.09959 - diff: 37.91mlTrain batch 15/16 - 163.2ms/batch - loss: 75.86051 - diff: 37.33mlTrain batch 16/16 - 54.6ms/batch - loss: 82.68713 - diff: 37.58mlTrain batch 16/16 - 16.0s 54.6ms/batch - loss: 82.68713 - diff: 37.58ml
Test 1.1s: val_loss: 76.55859 - diff: 37.49ml

Epoch 129: current best loss = 36.97311, at epoch 126
Train batch 1/16 - 180.8ms/batch - loss: 88.18871 - diff: 44.24mlTrain batch 2/16 - 164.1ms/batch - loss: 75.00484 - diff: 41.30mlTrain batch 3/16 - 222.5ms/batch - loss: 63.30105 - diff: 36.76mlTrain batch 4/16 - 163.8ms/batch - loss: 79.92375 - diff: 40.10mlTrain batch 5/16 - 163.2ms/batch - loss: 73.32892 - diff: 37.72mlTrain batch 6/16 - 163.1ms/batch - loss: 71.26856 - diff: 37.13mlTrain batch 7/16 - 162.8ms/batch - loss: 71.28174 - diff: 37.18mlTrain batch 8/16 - 163.4ms/batch - loss: 80.35473 - diff: 37.70mlTrain batch 9/16 - 163.0ms/batch - loss: 81.25506 - diff: 38.17mlTrain batch 10/16 - 162.9ms/batch - loss: 84.60348 - diff: 39.39mlTrain batch 11/16 - 174.2ms/batch - loss: 82.43746 - diff: 39.03mlTrain batch 12/16 - 163.0ms/batch - loss: 77.91356 - diff: 37.77mlTrain batch 13/16 - 163.2ms/batch - loss: 75.88098 - diff: 37.42mlTrain batch 14/16 - 162.8ms/batch - loss: 73.54304 - diff: 36.84mlTrain batch 15/16 - 162.8ms/batch - loss: 72.09546 - diff: 36.38mlTrain batch 16/16 - 55.9ms/batch - loss: 73.05967 - diff: 36.20mlTrain batch 16/16 - 15.0s 55.9ms/batch - loss: 73.05967 - diff: 36.20ml
Test 1.2s: val_loss: 60.07238 - diff: 31.59ml

Epoch 130: current best loss = 36.97311, at epoch 126
Train batch 1/16 - 174.4ms/batch - loss: 41.34777 - diff: 26.53mlTrain batch 2/16 - 165.9ms/batch - loss: 62.96176 - diff: 32.99mlTrain batch 3/16 - 165.8ms/batch - loss: 66.96977 - diff: 34.61mlTrain batch 4/16 - 171.4ms/batch - loss: 62.79389 - diff: 34.55mlTrain batch 5/16 - 178.6ms/batch - loss: 59.70887 - diff: 33.76mlTrain batch 6/16 - 170.5ms/batch - loss: 58.98600 - diff: 33.63mlTrain batch 7/16 - 162.7ms/batch - loss: 58.64738 - diff: 33.18mlTrain batch 8/16 - 163.2ms/batch - loss: 58.52936 - diff: 33.30mlTrain batch 9/16 - 184.1ms/batch - loss: 59.66062 - diff: 33.37mlTrain batch 10/16 - 165.5ms/batch - loss: 66.66960 - diff: 35.31mlTrain batch 11/16 - 163.0ms/batch - loss: 64.97116 - diff: 34.86mlTrain batch 12/16 - 172.8ms/batch - loss: 65.67363 - diff: 34.98mlTrain batch 13/16 - 165.9ms/batch - loss: 65.26228 - diff: 35.15mlTrain batch 14/16 - 163.3ms/batch - loss: 63.95323 - diff: 34.92mlTrain batch 15/16 - 163.0ms/batch - loss: 69.13860 - diff: 35.38mlTrain batch 16/16 - 54.7ms/batch - loss: 78.42023 - diff: 35.45mlTrain batch 16/16 - 16.6s 54.7ms/batch - loss: 78.42023 - diff: 35.45ml
Test 0.8s: val_loss: 66.48810 - diff: 38.09ml

Epoch 131: current best loss = 36.97311, at epoch 126
Train batch 1/16 - 180.7ms/batch - loss: 165.49548 - diff: 51.80mlTrain batch 2/16 - 170.5ms/batch - loss: 113.72528 - diff: 45.71mlTrain batch 3/16 - 162.8ms/batch - loss: 98.70995 - diff: 44.02mlTrain batch 4/16 - 162.6ms/batch - loss: 87.29678 - diff: 41.13mlTrain batch 5/16 - 162.6ms/batch - loss: 88.98235 - diff: 41.52mlTrain batch 6/16 - 163.6ms/batch - loss: 81.47000 - diff: 39.69mlTrain batch 7/16 - 163.0ms/batch - loss: 76.53413 - diff: 38.40mlTrain batch 8/16 - 165.7ms/batch - loss: 81.48915 - diff: 39.10mlTrain batch 9/16 - 162.9ms/batch - loss: 81.96853 - diff: 39.33mlTrain batch 10/16 - 163.1ms/batch - loss: 79.69100 - diff: 38.92mlTrain batch 11/16 - 162.8ms/batch - loss: 82.14749 - diff: 39.74mlTrain batch 12/16 - 163.1ms/batch - loss: 82.63932 - diff: 40.32mlTrain batch 13/16 - 162.8ms/batch - loss: 82.71269 - diff: 40.25mlTrain batch 14/16 - 171.4ms/batch - loss: 80.80890 - diff: 39.70mlTrain batch 15/16 - 163.0ms/batch - loss: 77.93433 - diff: 38.95mlTrain batch 16/16 - 54.9ms/batch - loss: 81.33985 - diff: 38.96mlTrain batch 16/16 - 15.6s 54.9ms/batch - loss: 81.33985 - diff: 38.96ml
Test 1.1s: val_loss: 73.23530 - diff: 34.82ml

Epoch 132: current best loss = 36.97311, at epoch 126
Train batch 1/16 - 180.9ms/batch - loss: 32.44591 - diff: 27.16mlTrain batch 2/16 - 173.4ms/batch - loss: 41.72448 - diff: 29.65mlTrain batch 3/16 - 162.9ms/batch - loss: 42.44556 - diff: 30.59mlTrain batch 4/16 - 169.4ms/batch - loss: 42.71078 - diff: 29.99mlTrain batch 5/16 - 187.2ms/batch - loss: 44.40012 - diff: 30.45mlTrain batch 6/16 - 163.0ms/batch - loss: 45.07025 - diff: 30.34mlTrain batch 7/16 - 175.4ms/batch - loss: 49.58147 - diff: 31.65mlTrain batch 8/16 - 163.0ms/batch - loss: 47.95626 - diff: 30.94mlTrain batch 9/16 - 178.7ms/batch - loss: 48.81483 - diff: 31.08mlTrain batch 10/16 - 163.0ms/batch - loss: 56.16199 - diff: 32.36mlTrain batch 11/16 - 180.6ms/batch - loss: 55.83185 - diff: 32.24mlTrain batch 12/16 - 164.2ms/batch - loss: 58.08380 - diff: 32.66mlTrain batch 13/16 - 169.2ms/batch - loss: 65.48530 - diff: 33.24mlTrain batch 14/16 - 163.1ms/batch - loss: 64.33027 - diff: 33.27mlTrain batch 15/16 - 163.0ms/batch - loss: 64.12505 - diff: 33.59mlTrain batch 16/16 - 54.9ms/batch - loss: 68.17135 - diff: 33.75mlTrain batch 16/16 - 17.7s 54.9ms/batch - loss: 68.17135 - diff: 33.75ml
Test 1.3s: val_loss: 39.58527 - diff: 27.07ml

Epoch 133: current best loss = 36.97311, at epoch 126
Train batch 1/16 - 175.7ms/batch - loss: 56.09818 - diff: 29.90mlTrain batch 2/16 - 163.3ms/batch - loss: 54.88977 - diff: 29.99mlTrain batch 3/16 - 189.1ms/batch - loss: 46.78871 - diff: 27.54mlTrain batch 4/16 - 174.4ms/batch - loss: 49.78725 - diff: 29.03mlTrain batch 5/16 - 162.9ms/batch - loss: 56.41256 - diff: 30.49mlTrain batch 6/16 - 162.9ms/batch - loss: 56.84110 - diff: 30.95mlTrain batch 7/16 - 170.7ms/batch - loss: 53.83258 - diff: 30.67mlTrain batch 8/16 - 166.9ms/batch - loss: 64.16434 - diff: 32.06mlTrain batch 9/16 - 162.9ms/batch - loss: 64.61720 - diff: 32.66mlTrain batch 10/16 - 171.4ms/batch - loss: 63.36952 - diff: 32.67mlTrain batch 11/16 - 162.8ms/batch - loss: 67.56339 - diff: 34.09mlTrain batch 12/16 - 163.0ms/batch - loss: 64.76422 - diff: 33.45mlTrain batch 13/16 - 165.9ms/batch - loss: 63.34004 - diff: 33.18mlTrain batch 14/16 - 171.0ms/batch - loss: 62.33918 - diff: 32.98mlTrain batch 15/16 - 162.8ms/batch - loss: 62.53111 - diff: 33.28mlTrain batch 16/16 - 56.7ms/batch - loss: 63.82922 - diff: 33.18mlTrain batch 16/16 - 16.6s 56.7ms/batch - loss: 63.82922 - diff: 33.18ml
Test 1.3s: val_loss: 56.81776 - diff: 31.50ml

Epoch 134: current best loss = 36.97311, at epoch 126
Train batch 1/16 - 181.1ms/batch - loss: 41.86311 - diff: 29.54mlTrain batch 2/16 - 169.5ms/batch - loss: 56.53043 - diff: 32.91mlTrain batch 3/16 - 163.1ms/batch - loss: 58.12013 - diff: 32.35mlTrain batch 4/16 - 163.4ms/batch - loss: 58.85200 - diff: 32.62mlTrain batch 5/16 - 187.9ms/batch - loss: 57.66590 - diff: 33.00mlTrain batch 6/16 - 163.1ms/batch - loss: 58.06469 - diff: 32.78mlTrain batch 7/16 - 178.8ms/batch - loss: 59.37609 - diff: 33.13mlTrain batch 8/16 - 180.3ms/batch - loss: 57.67724 - diff: 32.78mlTrain batch 9/16 - 176.3ms/batch - loss: 56.27165 - diff: 32.41mlTrain batch 10/16 - 172.0ms/batch - loss: 67.77190 - diff: 33.37mlTrain batch 11/16 - 163.1ms/batch - loss: 66.80929 - diff: 33.33mlTrain batch 12/16 - 170.7ms/batch - loss: 63.82356 - diff: 32.56mlTrain batch 13/16 - 162.8ms/batch - loss: 63.44898 - diff: 32.76mlTrain batch 14/16 - 163.2ms/batch - loss: 62.06745 - diff: 32.56mlTrain batch 15/16 - 163.0ms/batch - loss: 59.84326 - diff: 32.02mlTrain batch 16/16 - 54.9ms/batch - loss: 62.36590 - diff: 32.06mlTrain batch 16/16 - 16.9s 54.9ms/batch - loss: 62.36590 - diff: 32.06ml
Test 1.3s: val_loss: 43.16537 - diff: 27.16ml

Epoch 135: current best loss = 36.97311, at epoch 126
Train batch 1/16 - 173.9ms/batch - loss: 51.26326 - diff: 33.34mlTrain batch 2/16 - 163.2ms/batch - loss: 83.97891 - diff: 31.95mlTrain batch 3/16 - 181.4ms/batch - loss: 68.28315 - diff: 30.91mlTrain batch 4/16 - 166.6ms/batch - loss: 64.61253 - diff: 31.45mlTrain batch 5/16 - 163.0ms/batch - loss: 67.48192 - diff: 31.84mlTrain batch 6/16 - 162.9ms/batch - loss: 69.94315 - diff: 32.99mlTrain batch 7/16 - 162.7ms/batch - loss: 64.99497 - diff: 32.06mlTrain batch 8/16 - 163.2ms/batch - loss: 63.13538 - diff: 32.13mlTrain batch 9/16 - 162.7ms/batch - loss: 63.04937 - diff: 32.66mlTrain batch 10/16 - 165.2ms/batch - loss: 62.20540 - diff: 32.63mlTrain batch 11/16 - 163.0ms/batch - loss: 61.03341 - diff: 32.54mlTrain batch 12/16 - 169.9ms/batch - loss: 59.00181 - diff: 32.03mlTrain batch 13/16 - 176.3ms/batch - loss: 58.31941 - diff: 32.01mlTrain batch 14/16 - 163.1ms/batch - loss: 59.05944 - diff: 32.16mlTrain batch 15/16 - 172.0ms/batch - loss: 58.24243 - diff: 32.16mlTrain batch 16/16 - 60.6ms/batch - loss: 62.46255 - diff: 32.27mlTrain batch 16/16 - 17.2s 60.6ms/batch - loss: 62.46255 - diff: 32.27ml
Test 1.1s: val_loss: 53.58656 - diff: 31.71ml

Epoch 136: current best loss = 36.97311, at epoch 126
Train batch 1/16 - 181.2ms/batch - loss: 56.96969 - diff: 33.97mlTrain batch 2/16 - 175.1ms/batch - loss: 79.93343 - diff: 36.48mlTrain batch 3/16 - 163.0ms/batch - loss: 82.64595 - diff: 38.69mlTrain batch 4/16 - 183.5ms/batch - loss: 76.04644 - diff: 37.62mlTrain batch 5/16 - 163.0ms/batch - loss: 72.88579 - diff: 37.21mlTrain batch 6/16 - 165.7ms/batch - loss: 68.19258 - diff: 35.93mlTrain batch 7/16 - 179.9ms/batch - loss: 69.64539 - diff: 36.48mlTrain batch 8/16 - 171.2ms/batch - loss: 67.59035 - diff: 35.82mlTrain batch 9/16 - 162.6ms/batch - loss: 64.58750 - diff: 34.84mlTrain batch 10/16 - 163.4ms/batch - loss: 60.61799 - diff: 33.66mlTrain batch 11/16 - 175.3ms/batch - loss: 61.02090 - diff: 34.07mlTrain batch 12/16 - 170.6ms/batch - loss: 60.09662 - diff: 33.97mlTrain batch 13/16 - 170.8ms/batch - loss: 59.09178 - diff: 33.79mlTrain batch 14/16 - 163.1ms/batch - loss: 58.71094 - diff: 33.71mlTrain batch 15/16 - 164.5ms/batch - loss: 58.74334 - diff: 33.92mlTrain batch 16/16 - 54.9ms/batch - loss: 73.38587 - diff: 34.21mlTrain batch 16/16 - 17.0s 54.9ms/batch - loss: 73.38587 - diff: 34.21ml
Test 1.3s: val_loss: 40.49065 - diff: 25.79ml

Epoch 137: current best loss = 36.97311, at epoch 126
Train batch 1/16 - 180.9ms/batch - loss: 88.33005 - diff: 34.84mlTrain batch 2/16 - 162.9ms/batch - loss: 68.50966 - diff: 32.53mlTrain batch 3/16 - 162.8ms/batch - loss: 59.82177 - diff: 31.24mlTrain batch 4/16 - 170.5ms/batch - loss: 54.31954 - diff: 30.33mlTrain batch 5/16 - 162.8ms/batch - loss: 60.01957 - diff: 32.30mlTrain batch 6/16 - 162.8ms/batch - loss: 58.60359 - diff: 32.41mlTrain batch 7/16 - 167.3ms/batch - loss: 59.32710 - diff: 32.87mlTrain batch 8/16 - 163.0ms/batch - loss: 57.65842 - diff: 32.67mlTrain batch 9/16 - 162.9ms/batch - loss: 54.31262 - diff: 31.56mlTrain batch 10/16 - 163.0ms/batch - loss: 52.04970 - diff: 31.05mlTrain batch 11/16 - 185.8ms/batch - loss: 55.08638 - diff: 31.94mlTrain batch 12/16 - 167.6ms/batch - loss: 53.13150 - diff: 31.27mlTrain batch 13/16 - 162.8ms/batch - loss: 52.17518 - diff: 31.13mlTrain batch 14/16 - 163.0ms/batch - loss: 58.34827 - diff: 31.85mlTrain batch 15/16 - 180.7ms/batch - loss: 58.74905 - diff: 32.12mlTrain batch 16/16 - 59.1ms/batch - loss: 62.93167 - diff: 32.30mlTrain batch 16/16 - 17.2s 59.1ms/batch - loss: 62.93167 - diff: 32.30ml
Test 1.1s: val_loss: 42.30101 - diff: 27.08ml
Epoch   138: reducing learning rate of group 0 to 3.1250e-05.

Epoch 138: current best loss = 36.97311, at epoch 126
Train batch 1/16 - 180.7ms/batch - loss: 86.43275 - diff: 38.52mlTrain batch 2/16 - 166.1ms/batch - loss: 56.79906 - diff: 30.40mlTrain batch 3/16 - 178.7ms/batch - loss: 51.22394 - diff: 29.94mlTrain batch 4/16 - 163.2ms/batch - loss: 53.13787 - diff: 30.81mlTrain batch 5/16 - 163.3ms/batch - loss: 50.46983 - diff: 29.65mlTrain batch 6/16 - 163.2ms/batch - loss: 49.89048 - diff: 29.72mlTrain batch 7/16 - 174.8ms/batch - loss: 50.33973 - diff: 29.88mlTrain batch 8/16 - 163.2ms/batch - loss: 61.04266 - diff: 31.40mlTrain batch 9/16 - 187.5ms/batch - loss: 61.59450 - diff: 32.15mlTrain batch 10/16 - 167.7ms/batch - loss: 61.20223 - diff: 32.37mlTrain batch 11/16 - 175.1ms/batch - loss: 58.68314 - diff: 31.71mlTrain batch 12/16 - 177.6ms/batch - loss: 60.66486 - diff: 32.48mlTrain batch 13/16 - 174.3ms/batch - loss: 59.54533 - diff: 32.59mlTrain batch 14/16 - 182.4ms/batch - loss: 58.93539 - diff: 32.66mlTrain batch 15/16 - 168.1ms/batch - loss: 56.30883 - diff: 31.82mlTrain batch 16/16 - 55.0ms/batch - loss: 61.89306 - diff: 32.02mlTrain batch 16/16 - 16.0s 55.0ms/batch - loss: 61.89306 - diff: 32.02ml
Test 1.1s: val_loss: 38.08268 - diff: 25.14ml

Epoch 139: current best loss = 36.97311, at epoch 126
Train batch 1/16 - 180.7ms/batch - loss: 51.00988 - diff: 31.11mlTrain batch 2/16 - 162.7ms/batch - loss: 44.92241 - diff: 29.82mlTrain batch 3/16 - 162.7ms/batch - loss: 47.25763 - diff: 30.15mlTrain batch 4/16 - 173.6ms/batch - loss: 48.29190 - diff: 30.51mlTrain batch 5/16 - 173.8ms/batch - loss: 45.16385 - diff: 29.51mlTrain batch 6/16 - 165.9ms/batch - loss: 46.54458 - diff: 29.76mlTrain batch 7/16 - 163.1ms/batch - loss: 47.33532 - diff: 30.15mlTrain batch 8/16 - 163.0ms/batch - loss: 59.06485 - diff: 30.93mlTrain batch 9/16 - 162.8ms/batch - loss: 56.82065 - diff: 30.55mlTrain batch 10/16 - 162.6ms/batch - loss: 54.18468 - diff: 29.94mlTrain batch 11/16 - 162.9ms/batch - loss: 53.83894 - diff: 30.15mlTrain batch 12/16 - 166.1ms/batch - loss: 52.30512 - diff: 30.03mlTrain batch 13/16 - 163.0ms/batch - loss: 51.79944 - diff: 30.21mlTrain batch 14/16 - 165.4ms/batch - loss: 51.62945 - diff: 30.18mlTrain batch 15/16 - 162.9ms/batch - loss: 51.04173 - diff: 30.13mlTrain batch 16/16 - 54.8ms/batch - loss: 55.93088 - diff: 30.31mlTrain batch 16/16 - 16.9s 54.8ms/batch - loss: 55.93088 - diff: 30.31ml
Test 1.2s: val_loss: 34.73114 - diff: 24.85ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_VGG19_Adam-0.001_MSE_DA3_best

Epoch 140: current best loss = 34.73114, at epoch 139
Train batch 1/16 - 208.9ms/batch - loss: 99.53268 - diff: 34.91mlTrain batch 2/16 - 165.8ms/batch - loss: 72.17109 - diff: 31.93mlTrain batch 3/16 - 192.0ms/batch - loss: 67.94603 - diff: 31.88mlTrain batch 4/16 - 162.9ms/batch - loss: 59.35998 - diff: 30.16mlTrain batch 5/16 - 175.7ms/batch - loss: 58.75204 - diff: 30.39mlTrain batch 6/16 - 168.7ms/batch - loss: 57.30854 - diff: 31.00mlTrain batch 7/16 - 180.0ms/batch - loss: 52.36308 - diff: 29.64mlTrain batch 8/16 - 167.2ms/batch - loss: 49.09750 - diff: 28.80mlTrain batch 9/16 - 192.1ms/batch - loss: 48.67930 - diff: 28.86mlTrain batch 10/16 - 165.7ms/batch - loss: 49.06259 - diff: 29.43mlTrain batch 11/16 - 182.5ms/batch - loss: 52.24663 - diff: 30.09mlTrain batch 12/16 - 170.7ms/batch - loss: 51.82759 - diff: 30.00mlTrain batch 13/16 - 162.9ms/batch - loss: 52.52160 - diff: 30.39mlTrain batch 14/16 - 163.3ms/batch - loss: 52.91619 - diff: 30.64mlTrain batch 15/16 - 162.9ms/batch - loss: 53.05491 - diff: 30.81mlTrain batch 16/16 - 54.8ms/batch - loss: 58.17136 - diff: 30.95mlTrain batch 16/16 - 17.2s 54.8ms/batch - loss: 58.17136 - diff: 30.95ml
Test 1.3s: val_loss: 38.82374 - diff: 24.62ml

Epoch 141: current best loss = 34.73114, at epoch 139
Train batch 1/16 - 180.8ms/batch - loss: 49.00962 - diff: 32.40mlTrain batch 2/16 - 172.8ms/batch - loss: 49.93586 - diff: 30.18mlTrain batch 3/16 - 166.4ms/batch - loss: 57.27844 - diff: 31.23mlTrain batch 4/16 - 163.1ms/batch - loss: 54.38000 - diff: 31.68mlTrain batch 5/16 - 162.8ms/batch - loss: 51.67209 - diff: 30.87mlTrain batch 6/16 - 163.4ms/batch - loss: 50.18468 - diff: 30.43mlTrain batch 7/16 - 162.8ms/batch - loss: 49.29959 - diff: 30.41mlTrain batch 8/16 - 163.3ms/batch - loss: 58.20939 - diff: 30.95mlTrain batch 9/16 - 162.9ms/batch - loss: 56.66604 - diff: 30.66mlTrain batch 10/16 - 163.3ms/batch - loss: 54.57937 - diff: 30.44mlTrain batch 11/16 - 163.1ms/batch - loss: 55.50118 - diff: 31.15mlTrain batch 12/16 - 163.3ms/batch - loss: 55.88049 - diff: 31.51mlTrain batch 13/16 - 172.7ms/batch - loss: 56.01141 - diff: 31.77mlTrain batch 14/16 - 163.0ms/batch - loss: 53.95784 - diff: 31.12mlTrain batch 15/16 - 172.8ms/batch - loss: 53.84433 - diff: 31.17mlTrain batch 16/16 - 54.9ms/batch - loss: 54.45398 - diff: 31.08mlTrain batch 16/16 - 14.8s 54.9ms/batch - loss: 54.45398 - diff: 31.08ml
Test 1.1s: val_loss: 47.93261 - diff: 25.13ml

Epoch 142: current best loss = 34.73114, at epoch 139
Train batch 1/16 - 174.9ms/batch - loss: 160.50876 - diff: 41.43mlTrain batch 2/16 - 163.1ms/batch - loss: 117.34411 - diff: 38.57mlTrain batch 3/16 - 176.2ms/batch - loss: 91.33809 - diff: 35.74mlTrain batch 4/16 - 164.1ms/batch - loss: 80.79798 - diff: 35.05mlTrain batch 5/16 - 162.7ms/batch - loss: 74.07008 - diff: 34.45mlTrain batch 6/16 - 163.6ms/batch - loss: 66.64370 - diff: 32.42mlTrain batch 7/16 - 163.1ms/batch - loss: 64.10187 - diff: 32.33mlTrain batch 8/16 - 170.4ms/batch - loss: 64.08026 - diff: 32.57mlTrain batch 9/16 - 178.1ms/batch - loss: 62.33349 - diff: 32.37mlTrain batch 10/16 - 162.9ms/batch - loss: 58.26319 - diff: 31.26mlTrain batch 11/16 - 162.8ms/batch - loss: 57.23714 - diff: 31.08mlTrain batch 12/16 - 163.3ms/batch - loss: 54.76311 - diff: 30.44mlTrain batch 13/16 - 183.5ms/batch - loss: 54.60674 - diff: 30.47mlTrain batch 14/16 - 170.2ms/batch - loss: 54.65351 - diff: 30.68mlTrain batch 15/16 - 179.6ms/batch - loss: 55.49284 - diff: 30.96mlTrain batch 16/16 - 54.8ms/batch - loss: 57.81402 - diff: 30.91mlTrain batch 16/16 - 15.9s 54.8ms/batch - loss: 57.81402 - diff: 30.91ml
Test 1.1s: val_loss: 60.49886 - diff: 30.11ml

Epoch 143: current best loss = 34.73114, at epoch 139
Train batch 1/16 - 179.4ms/batch - loss: 33.42950 - diff: 25.19mlTrain batch 2/16 - 163.5ms/batch - loss: 29.81042 - diff: 24.73mlTrain batch 3/16 - 182.0ms/batch - loss: 36.75742 - diff: 27.27mlTrain batch 4/16 - 163.2ms/batch - loss: 41.96520 - diff: 29.05mlTrain batch 5/16 - 162.7ms/batch - loss: 43.51490 - diff: 30.03mlTrain batch 6/16 - 162.8ms/batch - loss: 44.69125 - diff: 29.97mlTrain batch 7/16 - 162.8ms/batch - loss: 45.06577 - diff: 30.07mlTrain batch 8/16 - 162.3ms/batch - loss: 47.86104 - diff: 30.26mlTrain batch 9/16 - 163.1ms/batch - loss: 46.39668 - diff: 29.95mlTrain batch 10/16 - 165.3ms/batch - loss: 49.72255 - diff: 30.64mlTrain batch 11/16 - 177.0ms/batch - loss: 48.65152 - diff: 30.28mlTrain batch 12/16 - 171.7ms/batch - loss: 48.53674 - diff: 30.32mlTrain batch 13/16 - 162.9ms/batch - loss: 53.88901 - diff: 30.97mlTrain batch 14/16 - 166.3ms/batch - loss: 53.59825 - diff: 31.12mlTrain batch 15/16 - 162.8ms/batch - loss: 51.87417 - diff: 30.62mlTrain batch 16/16 - 54.9ms/batch - loss: 54.46241 - diff: 30.63mlTrain batch 16/16 - 16.4s 54.9ms/batch - loss: 54.46241 - diff: 30.63ml
Test 1.1s: val_loss: 40.86658 - diff: 26.53ml

Epoch 144: current best loss = 34.73114, at epoch 139
Train batch 1/16 - 191.6ms/batch - loss: 27.73166 - diff: 23.63mlTrain batch 2/16 - 162.7ms/batch - loss: 70.62907 - diff: 33.98mlTrain batch 3/16 - 178.1ms/batch - loss: 92.07916 - diff: 40.46mlTrain batch 4/16 - 163.0ms/batch - loss: 75.74289 - diff: 36.11mlTrain batch 5/16 - 165.4ms/batch - loss: 69.44419 - diff: 34.96mlTrain batch 6/16 - 167.5ms/batch - loss: 65.44571 - diff: 34.80mlTrain batch 7/16 - 176.2ms/batch - loss: 68.11455 - diff: 35.94mlTrain batch 8/16 - 170.2ms/batch - loss: 66.07412 - diff: 35.31mlTrain batch 9/16 - 163.1ms/batch - loss: 63.96048 - diff: 34.82mlTrain batch 10/16 - 163.4ms/batch - loss: 62.61223 - diff: 34.25mlTrain batch 11/16 - 163.0ms/batch - loss: 61.01490 - diff: 33.92mlTrain batch 12/16 - 162.8ms/batch - loss: 59.52407 - diff: 33.64mlTrain batch 13/16 - 168.4ms/batch - loss: 63.70103 - diff: 33.86mlTrain batch 14/16 - 172.5ms/batch - loss: 62.45510 - diff: 33.46mlTrain batch 15/16 - 163.1ms/batch - loss: 61.99653 - diff: 33.37mlTrain batch 16/16 - 55.0ms/batch - loss: 64.24538 - diff: 33.40mlTrain batch 16/16 - 15.8s 55.0ms/batch - loss: 64.24538 - diff: 33.40ml
Test 1.1s: val_loss: 40.23665 - diff: 27.14ml

Epoch 145: current best loss = 34.73114, at epoch 139
Train batch 1/16 - 183.1ms/batch - loss: 40.80055 - diff: 26.81mlTrain batch 2/16 - 174.4ms/batch - loss: 37.95704 - diff: 25.98mlTrain batch 3/16 - 166.7ms/batch - loss: 38.09974 - diff: 26.80mlTrain batch 4/16 - 169.7ms/batch - loss: 43.68997 - diff: 29.05mlTrain batch 5/16 - 163.2ms/batch - loss: 46.22637 - diff: 29.40mlTrain batch 6/16 - 163.1ms/batch - loss: 53.83873 - diff: 31.18mlTrain batch 7/16 - 163.0ms/batch - loss: 51.55538 - diff: 30.80mlTrain batch 8/16 - 163.0ms/batch - loss: 51.41698 - diff: 30.89mlTrain batch 9/16 - 163.0ms/batch - loss: 51.11090 - diff: 31.05mlTrain batch 10/16 - 163.1ms/batch - loss: 49.22347 - diff: 30.58mlTrain batch 11/16 - 163.4ms/batch - loss: 48.84833 - diff: 30.62mlTrain batch 12/16 - 162.9ms/batch - loss: 50.05185 - diff: 30.45mlTrain batch 13/16 - 171.4ms/batch - loss: 56.39657 - diff: 31.10mlTrain batch 14/16 - 164.2ms/batch - loss: 55.75869 - diff: 31.35mlTrain batch 15/16 - 163.0ms/batch - loss: 54.38725 - diff: 31.10mlTrain batch 16/16 - 54.9ms/batch - loss: 55.64616 - diff: 30.98mlTrain batch 16/16 - 16.0s 54.9ms/batch - loss: 55.64616 - diff: 30.98ml
Test 1.2s: val_loss: 35.87969 - diff: 24.85ml

Epoch 146: current best loss = 34.73114, at epoch 139
Train batch 1/16 - 184.5ms/batch - loss: 120.63332 - diff: 38.74mlTrain batch 2/16 - 162.9ms/batch - loss: 79.11533 - diff: 32.06mlTrain batch 3/16 - 167.0ms/batch - loss: 67.41680 - diff: 31.60mlTrain batch 4/16 - 168.2ms/batch - loss: 58.75248 - diff: 30.10mlTrain batch 5/16 - 163.2ms/batch - loss: 52.58741 - diff: 29.09mlTrain batch 6/16 - 163.5ms/batch - loss: 51.37533 - diff: 29.54mlTrain batch 7/16 - 173.3ms/batch - loss: 50.32705 - diff: 29.50mlTrain batch 8/16 - 163.1ms/batch - loss: 49.01922 - diff: 29.44mlTrain batch 9/16 - 163.1ms/batch - loss: 52.22404 - diff: 30.55mlTrain batch 10/16 - 163.2ms/batch - loss: 54.20722 - diff: 31.06mlTrain batch 11/16 - 164.0ms/batch - loss: 52.90635 - diff: 30.89mlTrain batch 12/16 - 163.2ms/batch - loss: 50.97415 - diff: 30.38mlTrain batch 13/16 - 164.6ms/batch - loss: 49.97770 - diff: 30.19mlTrain batch 14/16 - 163.2ms/batch - loss: 48.70862 - diff: 29.95mlTrain batch 15/16 - 162.8ms/batch - loss: 47.15718 - diff: 29.39mlTrain batch 16/16 - 55.0ms/batch - loss: 47.99485 - diff: 29.28mlTrain batch 16/16 - 15.4s 55.0ms/batch - loss: 47.99485 - diff: 29.28ml
Test 1.1s: val_loss: 32.94578 - diff: 24.06ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_VGG19_Adam-0.001_MSE_DA3_best

Epoch 147: current best loss = 32.94578, at epoch 146
Train batch 1/16 - 181.3ms/batch - loss: 43.40594 - diff: 27.84mlTrain batch 2/16 - 162.8ms/batch - loss: 43.83288 - diff: 27.83mlTrain batch 3/16 - 184.1ms/batch - loss: 42.81904 - diff: 28.49mlTrain batch 4/16 - 165.5ms/batch - loss: 40.16355 - diff: 27.85mlTrain batch 5/16 - 170.8ms/batch - loss: 41.67273 - diff: 28.56mlTrain batch 6/16 - 163.1ms/batch - loss: 39.93693 - diff: 28.12mlTrain batch 7/16 - 166.3ms/batch - loss: 43.65235 - diff: 29.50mlTrain batch 8/16 - 174.2ms/batch - loss: 42.14664 - diff: 29.22mlTrain batch 9/16 - 163.0ms/batch - loss: 44.88206 - diff: 29.68mlTrain batch 10/16 - 163.0ms/batch - loss: 45.78717 - diff: 30.03mlTrain batch 11/16 - 163.1ms/batch - loss: 54.33629 - diff: 30.73mlTrain batch 12/16 - 163.1ms/batch - loss: 52.42167 - diff: 30.35mlTrain batch 13/16 - 163.3ms/batch - loss: 51.03448 - diff: 30.01mlTrain batch 14/16 - 166.9ms/batch - loss: 50.51549 - diff: 30.06mlTrain batch 15/16 - 162.8ms/batch - loss: 50.13920 - diff: 29.91mlTrain batch 16/16 - 54.9ms/batch - loss: 53.13050 - diff: 29.95mlTrain batch 16/16 - 16.7s 54.9ms/batch - loss: 53.13050 - diff: 29.95ml
Test 1.2s: val_loss: 37.65856 - diff: 25.49ml

Epoch 148: current best loss = 32.94578, at epoch 146
Train batch 1/16 - 180.8ms/batch - loss: 48.85999 - diff: 30.36mlTrain batch 2/16 - 175.3ms/batch - loss: 39.77416 - diff: 27.76mlTrain batch 3/16 - 162.9ms/batch - loss: 36.55878 - diff: 26.79mlTrain batch 4/16 - 163.1ms/batch - loss: 35.14822 - diff: 26.21mlTrain batch 5/16 - 163.0ms/batch - loss: 36.07683 - diff: 26.17mlTrain batch 6/16 - 179.5ms/batch - loss: 38.92214 - diff: 27.31mlTrain batch 7/16 - 162.9ms/batch - loss: 38.53333 - diff: 26.70mlTrain batch 8/16 - 163.1ms/batch - loss: 39.93535 - diff: 27.20mlTrain batch 9/16 - 162.9ms/batch - loss: 40.50634 - diff: 27.60mlTrain batch 10/16 - 171.3ms/batch - loss: 39.52993 - diff: 27.33mlTrain batch 11/16 - 169.6ms/batch - loss: 49.19631 - diff: 28.88mlTrain batch 12/16 - 163.3ms/batch - loss: 48.67867 - diff: 29.03mlTrain batch 13/16 - 162.8ms/batch - loss: 48.08624 - diff: 29.14mlTrain batch 14/16 - 171.7ms/batch - loss: 49.75646 - diff: 29.74mlTrain batch 15/16 - 162.8ms/batch - loss: 50.08486 - diff: 29.74mlTrain batch 16/16 - 54.8ms/batch - loss: 51.47932 - diff: 29.73mlTrain batch 16/16 - 15.4s 54.8ms/batch - loss: 51.47932 - diff: 29.73ml
Test 1.1s: val_loss: 43.45397 - diff: 24.56ml

Epoch 149: current best loss = 32.94578, at epoch 146
Train batch 1/16 - 180.9ms/batch - loss: 83.21873 - diff: 37.39mlTrain batch 2/16 - 171.3ms/batch - loss: 79.74546 - diff: 36.38mlTrain batch 3/16 - 169.0ms/batch - loss: 71.27236 - diff: 34.04mlTrain batch 4/16 - 162.9ms/batch - loss: 66.21772 - diff: 32.29mlTrain batch 5/16 - 162.8ms/batch - loss: 70.87416 - diff: 31.82mlTrain batch 6/16 - 163.1ms/batch - loss: 64.91515 - diff: 30.48mlTrain batch 7/16 - 163.1ms/batch - loss: 62.86979 - diff: 30.52mlTrain batch 8/16 - 181.0ms/batch - loss: 63.08703 - diff: 30.89mlTrain batch 9/16 - 163.1ms/batch - loss: 61.69401 - diff: 30.74mlTrain batch 10/16 - 163.1ms/batch - loss: 59.40882 - diff: 30.61mlTrain batch 11/16 - 163.0ms/batch - loss: 55.94420 - diff: 29.57mlTrain batch 12/16 - 165.2ms/batch - loss: 58.61430 - diff: 30.65mlTrain batch 13/16 - 181.4ms/batch - loss: 59.42449 - diff: 30.72mlTrain batch 14/16 - 164.4ms/batch - loss: 58.97982 - diff: 30.99mlTrain batch 15/16 - 163.0ms/batch - loss: 58.82401 - diff: 30.97mlTrain batch 16/16 - 54.9ms/batch - loss: 62.07044 - diff: 31.03mlTrain batch 16/16 - 15.2s 54.9ms/batch - loss: 62.07044 - diff: 31.03ml
Test 1.1s: val_loss: 37.18577 - diff: 27.46ml

