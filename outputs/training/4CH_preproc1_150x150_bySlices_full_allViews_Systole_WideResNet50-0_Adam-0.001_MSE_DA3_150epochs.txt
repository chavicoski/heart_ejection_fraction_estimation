nohup: ignoring input
Running experiment 4CH_preproc1_150x150_bySlices_dataset_allViews_Systole_WideResNet50_0_Adam-0.001_MSE_DA3
Going to train with the GPU in the slot 0 -> device model: GeForce RTX 2080
Model architecture:
 WideResNet50_0(
  (first_conv): Conv2d(30, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (pretrained_block): Sequential(
    (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): ReLU(inplace=True)
    (2): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (3): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (4): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (5): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (4): Bottleneck(
        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (5): Bottleneck(
        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
  )
  (reduction_block): Sequential(
    (0): AdaptiveAvgPool2d(output_size=(1, 1))
    (1): Flatten()
  )
  (dense_block): Sequential(
    (0): Linear(in_features=1024, out_features=512, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.4, inplace=False)
    (3): Linear(in_features=512, out_features=1, bias=True)
  )
) 


############################
# TRAIN PHASE:  150 epochs #
############################

Epoch 0: 
Train batch 1/31 - 196.9ms/batch - loss: 430.06403 - diff: 78.39mlTrain batch 2/31 - 178.3ms/batch - loss: 379.11726 - diff: 72.64mlTrain batch 3/31 - 170.5ms/batch - loss: 435.91352 - diff: 75.75mlTrain batch 4/31 - 170.3ms/batch - loss: 388.84695 - diff: 71.80mlTrain batch 5/31 - 170.4ms/batch - loss: 352.03185 - diff: 68.56mlTrain batch 6/31 - 170.4ms/batch - loss: 351.39386 - diff: 68.40mlTrain batch 7/31 - 170.5ms/batch - loss: 373.50280 - diff: 69.85mlTrain batch 8/31 - 170.5ms/batch - loss: 373.54334 - diff: 69.27mlTrain batch 9/31 - 170.3ms/batch - loss: 387.54374 - diff: 70.06mlTrain batch 10/31 - 170.4ms/batch - loss: 382.16326 - diff: 69.24mlTrain batch 11/31 - 170.4ms/batch - loss: 474.92836 - diff: 72.23mlTrain batch 12/31 - 170.2ms/batch - loss: 465.33047 - diff: 71.62mlTrain batch 13/31 - 170.3ms/batch - loss: 466.73912 - diff: 71.90mlTrain batch 14/31 - 170.3ms/batch - loss: 450.95914 - diff: 70.71mlTrain batch 15/31 - 170.6ms/batch - loss: 462.05705 - diff: 70.91mlTrain batch 16/31 - 170.5ms/batch - loss: 451.07275 - diff: 70.36mlTrain batch 17/31 - 170.3ms/batch - loss: 437.33468 - diff: 69.44mlTrain batch 18/31 - 170.8ms/batch - loss: 447.09626 - diff: 70.10mlTrain batch 19/31 - 170.8ms/batch - loss: 438.37806 - diff: 69.65mlTrain batch 20/31 - 170.8ms/batch - loss: 430.30196 - diff: 69.26mlTrain batch 21/31 - 170.7ms/batch - loss: 421.84302 - diff: 68.81mlTrain batch 22/31 - 170.9ms/batch - loss: 417.94048 - diff: 68.59mlTrain batch 23/31 - 170.8ms/batch - loss: 412.77035 - diff: 68.28mlTrain batch 24/31 - 170.7ms/batch - loss: 408.13485 - diff: 67.98mlTrain batch 25/31 - 170.8ms/batch - loss: 409.45959 - diff: 67.78mlTrain batch 26/31 - 170.9ms/batch - loss: 399.20860 - diff: 66.73mlTrain batch 27/31 - 170.9ms/batch - loss: 389.46844 - diff: 65.61mlTrain batch 28/31 - 170.8ms/batch - loss: 382.00862 - diff: 64.99mlTrain batch 29/31 - 170.8ms/batch - loss: 385.09448 - diff: 65.09mlTrain batch 30/31 - 171.0ms/batch - loss: 379.46063 - diff: 64.76mlTrain batch 31/31 - 85.4ms/batch - loss: 379.00236 - diff: 64.48mlTrain batch 31/31 - 10.1s 85.4ms/batch - loss: 379.00236 - diff: 64.48ml
Test 1.1s: val_loss: 263.79077 - diff: 49.73ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Systole_WideResNet50_0_Adam-0.001_MSE_DA3_best

Epoch 1: current best loss = 263.79077, at epoch 0
Train batch 1/31 - 170.9ms/batch - loss: 423.47031 - diff: 53.94mlTrain batch 2/31 - 171.0ms/batch - loss: 304.62731 - diff: 51.07mlTrain batch 3/31 - 170.9ms/batch - loss: 280.44726 - diff: 49.43mlTrain batch 4/31 - 171.2ms/batch - loss: 296.34122 - diff: 52.14mlTrain batch 5/31 - 171.0ms/batch - loss: 255.98654 - diff: 48.66mlTrain batch 6/31 - 170.9ms/batch - loss: 232.13290 - diff: 46.11mlTrain batch 7/31 - 171.0ms/batch - loss: 258.04047 - diff: 47.67mlTrain batch 8/31 - 170.9ms/batch - loss: 251.33496 - diff: 47.90mlTrain batch 9/31 - 171.0ms/batch - loss: 241.01927 - diff: 47.19mlTrain batch 10/31 - 170.8ms/batch - loss: 245.02977 - diff: 47.04mlTrain batch 11/31 - 170.8ms/batch - loss: 306.25803 - diff: 47.72mlTrain batch 12/31 - 171.1ms/batch - loss: 293.39439 - diff: 47.26mlTrain batch 13/31 - 170.7ms/batch - loss: 287.65542 - diff: 47.14mlTrain batch 14/31 - 171.2ms/batch - loss: 291.87925 - diff: 47.31mlTrain batch 15/31 - 170.9ms/batch - loss: 276.56189 - diff: 45.82mlTrain batch 16/31 - 171.4ms/batch - loss: 270.97172 - diff: 45.47mlTrain batch 17/31 - 170.9ms/batch - loss: 261.23597 - diff: 44.82mlTrain batch 18/31 - 170.9ms/batch - loss: 254.10235 - diff: 44.23mlTrain batch 19/31 - 171.0ms/batch - loss: 244.03559 - diff: 43.20mlTrain batch 20/31 - 171.0ms/batch - loss: 239.43802 - diff: 43.01mlTrain batch 21/31 - 170.9ms/batch - loss: 231.16356 - diff: 42.16mlTrain batch 22/31 - 171.2ms/batch - loss: 224.71134 - diff: 41.45mlTrain batch 23/31 - 171.3ms/batch - loss: 223.06538 - diff: 41.25mlTrain batch 24/31 - 171.2ms/batch - loss: 222.80386 - diff: 41.26mlTrain batch 25/31 - 171.1ms/batch - loss: 215.40590 - diff: 40.38mlTrain batch 26/31 - 171.3ms/batch - loss: 211.96506 - diff: 39.99mlTrain batch 27/31 - 171.2ms/batch - loss: 205.67219 - diff: 39.18mlTrain batch 28/31 - 171.3ms/batch - loss: 200.52143 - diff: 38.60mlTrain batch 29/31 - 171.2ms/batch - loss: 196.31942 - diff: 38.15mlTrain batch 30/31 - 171.2ms/batch - loss: 190.81775 - diff: 37.51mlTrain batch 31/31 - 85.5ms/batch - loss: 192.10878 - diff: 37.41mlTrain batch 31/31 - 10.0s 85.5ms/batch - loss: 192.10878 - diff: 37.41ml
Test 1.0s: val_loss: 82.83105 - diff: 24.82ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Systole_WideResNet50_0_Adam-0.001_MSE_DA3_best

Epoch 2: current best loss = 82.83105, at epoch 1
Train batch 1/31 - 171.1ms/batch - loss: 72.89245 - diff: 28.04mlTrain batch 2/31 - 171.2ms/batch - loss: 47.73212 - diff: 22.30mlTrain batch 3/31 - 171.1ms/batch - loss: 50.43639 - diff: 22.23mlTrain batch 4/31 - 171.1ms/batch - loss: 78.33745 - diff: 25.64mlTrain batch 5/31 - 171.2ms/batch - loss: 127.33603 - diff: 29.39mlTrain batch 6/31 - 171.2ms/batch - loss: 116.83096 - diff: 29.15mlTrain batch 7/31 - 171.2ms/batch - loss: 203.63314 - diff: 31.91mlTrain batch 8/31 - 171.2ms/batch - loss: 190.75678 - diff: 31.17mlTrain batch 9/31 - 171.2ms/batch - loss: 188.26525 - diff: 32.05mlTrain batch 10/31 - 171.2ms/batch - loss: 172.81860 - diff: 30.66mlTrain batch 11/31 - 171.3ms/batch - loss: 164.40185 - diff: 30.55mlTrain batch 12/31 - 171.4ms/batch - loss: 157.89741 - diff: 30.49mlTrain batch 13/31 - 171.1ms/batch - loss: 153.80509 - diff: 30.73mlTrain batch 14/31 - 171.3ms/batch - loss: 147.22702 - diff: 30.36mlTrain batch 15/31 - 171.3ms/batch - loss: 140.01387 - diff: 29.72mlTrain batch 16/31 - 171.5ms/batch - loss: 134.63503 - diff: 29.34mlTrain batch 17/31 - 171.4ms/batch - loss: 143.34328 - diff: 30.35mlTrain batch 18/31 - 171.3ms/batch - loss: 143.11935 - diff: 30.63mlTrain batch 19/31 - 171.1ms/batch - loss: 137.84904 - diff: 30.22mlTrain batch 20/31 - 171.4ms/batch - loss: 134.14626 - diff: 30.17mlTrain batch 21/31 - 171.2ms/batch - loss: 129.12491 - diff: 29.62mlTrain batch 22/31 - 171.7ms/batch - loss: 127.59940 - diff: 29.64mlTrain batch 23/31 - 171.4ms/batch - loss: 124.54707 - diff: 29.40mlTrain batch 24/31 - 171.3ms/batch - loss: 125.54994 - diff: 29.53mlTrain batch 25/31 - 171.6ms/batch - loss: 124.81837 - diff: 29.42mlTrain batch 26/31 - 171.4ms/batch - loss: 121.83498 - diff: 29.21mlTrain batch 27/31 - 171.3ms/batch - loss: 120.49313 - diff: 29.22mlTrain batch 28/31 - 171.3ms/batch - loss: 118.95081 - diff: 29.30mlTrain batch 29/31 - 171.2ms/batch - loss: 116.06534 - diff: 29.00mlTrain batch 30/31 - 171.5ms/batch - loss: 112.99841 - diff: 28.54mlTrain batch 31/31 - 85.6ms/batch - loss: 113.65719 - diff: 28.49mlTrain batch 31/31 - 10.0s 85.6ms/batch - loss: 113.65719 - diff: 28.49ml
Test 1.1s: val_loss: 80.80398 - diff: 26.70ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Systole_WideResNet50_0_Adam-0.001_MSE_DA3_best

Epoch 3: current best loss = 80.80398, at epoch 2
Train batch 1/31 - 171.2ms/batch - loss: 84.15499 - diff: 28.68mlTrain batch 2/31 - 171.2ms/batch - loss: 82.52870 - diff: 29.09mlTrain batch 3/31 - 171.1ms/batch - loss: 112.11438 - diff: 31.92mlTrain batch 4/31 - 171.3ms/batch - loss: 133.50767 - diff: 33.88mlTrain batch 5/31 - 171.1ms/batch - loss: 117.13713 - diff: 31.00mlTrain batch 6/31 - 171.4ms/batch - loss: 141.52743 - diff: 31.99mlTrain batch 7/31 - 171.3ms/batch - loss: 126.46117 - diff: 30.19mlTrain batch 8/31 - 171.3ms/batch - loss: 114.07752 - diff: 28.44mlTrain batch 9/31 - 171.4ms/batch - loss: 108.50430 - diff: 28.25mlTrain batch 10/31 - 171.9ms/batch - loss: 101.87792 - diff: 27.72mlTrain batch 11/31 - 171.8ms/batch - loss: 106.78639 - diff: 28.58mlTrain batch 12/31 - 171.9ms/batch - loss: 105.66867 - diff: 28.59mlTrain batch 13/31 - 171.7ms/batch - loss: 102.85911 - diff: 28.46mlTrain batch 14/31 - 171.9ms/batch - loss: 106.12539 - diff: 29.02mlTrain batch 15/31 - 171.7ms/batch - loss: 109.39115 - diff: 29.45mlTrain batch 16/31 - 171.8ms/batch - loss: 105.61133 - diff: 29.07mlTrain batch 17/31 - 171.6ms/batch - loss: 108.21428 - diff: 29.64mlTrain batch 18/31 - 171.9ms/batch - loss: 104.49439 - diff: 29.13mlTrain batch 19/31 - 171.7ms/batch - loss: 102.49184 - diff: 29.10mlTrain batch 20/31 - 171.8ms/batch - loss: 100.06449 - diff: 28.86mlTrain batch 21/31 - 171.8ms/batch - loss: 97.95465 - diff: 28.71mlTrain batch 22/31 - 171.9ms/batch - loss: 95.15759 - diff: 28.42mlTrain batch 23/31 - 171.8ms/batch - loss: 96.35108 - diff: 28.50mlTrain batch 24/31 - 171.9ms/batch - loss: 121.28150 - diff: 29.44mlTrain batch 25/31 - 171.6ms/batch - loss: 118.67242 - diff: 29.25mlTrain batch 26/31 - 171.8ms/batch - loss: 116.65082 - diff: 29.08mlTrain batch 27/31 - 171.8ms/batch - loss: 117.99565 - diff: 29.07mlTrain batch 28/31 - 172.0ms/batch - loss: 115.79865 - diff: 28.86mlTrain batch 29/31 - 171.7ms/batch - loss: 112.90618 - diff: 28.53mlTrain batch 30/31 - 171.9ms/batch - loss: 112.59938 - diff: 28.61mlTrain batch 31/31 - 85.8ms/batch - loss: 111.93842 - diff: 28.49mlTrain batch 31/31 - 10.1s 85.8ms/batch - loss: 111.93842 - diff: 28.49ml
Test 1.1s: val_loss: 79.55314 - diff: 26.06ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Systole_WideResNet50_0_Adam-0.001_MSE_DA3_best

Epoch 4: current best loss = 79.55314, at epoch 3
Train batch 1/31 - 171.6ms/batch - loss: 152.91452 - diff: 32.29mlTrain batch 2/31 - 171.9ms/batch - loss: 113.47895 - diff: 30.85mlTrain batch 3/31 - 171.8ms/batch - loss: 168.86507 - diff: 33.97mlTrain batch 4/31 - 171.9ms/batch - loss: 136.18893 - diff: 30.08mlTrain batch 5/31 - 171.6ms/batch - loss: 125.94478 - diff: 30.48mlTrain batch 6/31 - 171.4ms/batch - loss: 110.88213 - diff: 28.84mlTrain batch 7/31 - 171.8ms/batch - loss: 102.32445 - diff: 27.98mlTrain batch 8/31 - 171.9ms/batch - loss: 113.99346 - diff: 28.81mlTrain batch 9/31 - 171.6ms/batch - loss: 115.02262 - diff: 29.15mlTrain batch 10/31 - 172.1ms/batch - loss: 109.35434 - diff: 28.75mlTrain batch 11/31 - 171.7ms/batch - loss: 104.18431 - diff: 28.24mlTrain batch 12/31 - 171.9ms/batch - loss: 106.70404 - diff: 28.55mlTrain batch 13/31 - 171.9ms/batch - loss: 102.85123 - diff: 28.47mlTrain batch 14/31 - 172.0ms/batch - loss: 103.96046 - diff: 28.57mlTrain batch 15/31 - 171.8ms/batch - loss: 113.89997 - diff: 29.55mlTrain batch 16/31 - 171.9ms/batch - loss: 111.44981 - diff: 29.33mlTrain batch 17/31 - 171.7ms/batch - loss: 106.87326 - diff: 28.70mlTrain batch 18/31 - 172.0ms/batch - loss: 102.28193 - diff: 27.99mlTrain batch 19/31 - 171.8ms/batch - loss: 101.67448 - diff: 28.04mlTrain batch 20/31 - 172.0ms/batch - loss: 99.82114 - diff: 27.95mlTrain batch 21/31 - 171.8ms/batch - loss: 98.16061 - diff: 27.93mlTrain batch 22/31 - 171.4ms/batch - loss: 97.12638 - diff: 27.84mlTrain batch 23/31 - 172.0ms/batch - loss: 94.30785 - diff: 27.46mlTrain batch 24/31 - 171.8ms/batch - loss: 91.33264 - diff: 26.99mlTrain batch 25/31 - 171.9ms/batch - loss: 90.50458 - diff: 26.97mlTrain batch 26/31 - 172.0ms/batch - loss: 114.95941 - diff: 27.88mlTrain batch 27/31 - 171.9ms/batch - loss: 116.85997 - diff: 28.05mlTrain batch 28/31 - 172.2ms/batch - loss: 114.01519 - diff: 27.73mlTrain batch 29/31 - 171.9ms/batch - loss: 111.38013 - diff: 27.45mlTrain batch 30/31 - 172.1ms/batch - loss: 109.44174 - diff: 27.24mlTrain batch 31/31 - 85.9ms/batch - loss: 110.85634 - diff: 27.25mlTrain batch 31/31 - 10.0s 85.9ms/batch - loss: 110.85634 - diff: 27.25ml
Test 1.1s: val_loss: 103.33457 - diff: 26.56ml

Epoch 5: current best loss = 79.55314, at epoch 3
Train batch 1/31 - 171.9ms/batch - loss: 88.30998 - diff: 29.89mlTrain batch 2/31 - 171.9ms/batch - loss: 77.73846 - diff: 27.75mlTrain batch 3/31 - 171.7ms/batch - loss: 95.52577 - diff: 28.79mlTrain batch 4/31 - 171.9ms/batch - loss: 269.78370 - diff: 34.78mlTrain batch 5/31 - 171.7ms/batch - loss: 247.92218 - diff: 34.96mlTrain batch 6/31 - 172.0ms/batch - loss: 214.29185 - diff: 32.96mlTrain batch 7/31 - 171.5ms/batch - loss: 204.27884 - diff: 32.68mlTrain batch 8/31 - 171.8ms/batch - loss: 181.58638 - diff: 30.44mlTrain batch 9/31 - 171.9ms/batch - loss: 177.53777 - diff: 31.45mlTrain batch 10/31 - 172.2ms/batch - loss: 185.28320 - diff: 32.47mlTrain batch 11/31 - 171.9ms/batch - loss: 173.87405 - diff: 31.90mlTrain batch 12/31 - 172.1ms/batch - loss: 162.39395 - diff: 30.84mlTrain batch 13/31 - 171.9ms/batch - loss: 160.10684 - diff: 31.17mlTrain batch 14/31 - 172.1ms/batch - loss: 152.40252 - diff: 30.79mlTrain batch 15/31 - 172.0ms/batch - loss: 148.34465 - diff: 30.34mlTrain batch 16/31 - 172.1ms/batch - loss: 144.88504 - diff: 30.01mlTrain batch 17/31 - 172.0ms/batch - loss: 143.10211 - diff: 29.83mlTrain batch 18/31 - 172.2ms/batch - loss: 136.55692 - diff: 29.08mlTrain batch 19/31 - 171.9ms/batch - loss: 131.26386 - diff: 28.62mlTrain batch 20/31 - 172.1ms/batch - loss: 130.20254 - diff: 28.78mlTrain batch 21/31 - 172.0ms/batch - loss: 126.47430 - diff: 28.55mlTrain batch 22/31 - 172.1ms/batch - loss: 121.95158 - diff: 28.03mlTrain batch 23/31 - 172.7ms/batch - loss: 120.43051 - diff: 28.14mlTrain batch 24/31 - 172.5ms/batch - loss: 118.22743 - diff: 28.06mlTrain batch 25/31 - 172.1ms/batch - loss: 116.56592 - diff: 28.11mlTrain batch 26/31 - 172.0ms/batch - loss: 114.35767 - diff: 27.97mlTrain batch 27/31 - 171.9ms/batch - loss: 112.78614 - diff: 27.97mlTrain batch 28/31 - 172.2ms/batch - loss: 112.12847 - diff: 28.00mlTrain batch 29/31 - 172.1ms/batch - loss: 109.83262 - diff: 27.82mlTrain batch 30/31 - 172.5ms/batch - loss: 107.27584 - diff: 27.53mlTrain batch 31/31 - 86.3ms/batch - loss: 111.76620 - diff: 27.79mlTrain batch 31/31 - 10.0s 86.3ms/batch - loss: 111.76620 - diff: 27.79ml
Test 1.0s: val_loss: 86.32433 - diff: 26.06ml

Epoch 6: current best loss = 79.55314, at epoch 3
Train batch 1/31 - 171.9ms/batch - loss: 48.66525 - diff: 20.54mlTrain batch 2/31 - 171.9ms/batch - loss: 40.52224 - diff: 18.76mlTrain batch 3/31 - 172.1ms/batch - loss: 57.49826 - diff: 20.66mlTrain batch 4/31 - 172.4ms/batch - loss: 60.90702 - diff: 22.25mlTrain batch 5/31 - 172.2ms/batch - loss: 61.87534 - diff: 22.92mlTrain batch 6/31 - 172.4ms/batch - loss: 58.19868 - diff: 22.15mlTrain batch 7/31 - 172.2ms/batch - loss: 63.13652 - diff: 23.09mlTrain batch 8/31 - 172.8ms/batch - loss: 61.21826 - diff: 23.13mlTrain batch 9/31 - 171.9ms/batch - loss: 58.56031 - diff: 22.81mlTrain batch 10/31 - 172.3ms/batch - loss: 56.52246 - diff: 22.64mlTrain batch 11/31 - 172.5ms/batch - loss: 79.50327 - diff: 24.12mlTrain batch 12/31 - 172.6ms/batch - loss: 82.23423 - diff: 24.68mlTrain batch 13/31 - 172.2ms/batch - loss: 83.42108 - diff: 25.22mlTrain batch 14/31 - 172.7ms/batch - loss: 78.99815 - diff: 24.44mlTrain batch 15/31 - 172.4ms/batch - loss: 85.02559 - diff: 24.93mlTrain batch 16/31 - 172.4ms/batch - loss: 87.14383 - diff: 25.32mlTrain batch 17/31 - 172.5ms/batch - loss: 90.74491 - diff: 25.74mlTrain batch 18/31 - 172.8ms/batch - loss: 99.37419 - diff: 26.60mlTrain batch 19/31 - 172.4ms/batch - loss: 96.58455 - diff: 26.43mlTrain batch 20/31 - 172.4ms/batch - loss: 94.85453 - diff: 26.51mlTrain batch 21/31 - 172.5ms/batch - loss: 92.51915 - diff: 26.37mlTrain batch 22/31 - 172.6ms/batch - loss: 123.05815 - diff: 27.63mlTrain batch 23/31 - 172.2ms/batch - loss: 124.01795 - diff: 28.19mlTrain batch 24/31 - 172.5ms/batch - loss: 119.61805 - diff: 27.58mlTrain batch 25/31 - 172.4ms/batch - loss: 117.38494 - diff: 27.60mlTrain batch 26/31 - 172.4ms/batch - loss: 114.75283 - diff: 27.47mlTrain batch 27/31 - 172.5ms/batch - loss: 113.38311 - diff: 27.50mlTrain batch 28/31 - 172.8ms/batch - loss: 111.77292 - diff: 27.45mlTrain batch 29/31 - 172.2ms/batch - loss: 109.89785 - diff: 27.39mlTrain batch 30/31 - 172.6ms/batch - loss: 107.42462 - diff: 27.15mlTrain batch 31/31 - 86.6ms/batch - loss: 110.88504 - diff: 27.20mlTrain batch 31/31 - 10.1s 86.6ms/batch - loss: 110.88504 - diff: 27.20ml
Test 1.1s: val_loss: 91.25686 - diff: 26.50ml

Epoch 7: current best loss = 79.55314, at epoch 3
Train batch 1/31 - 172.5ms/batch - loss: 237.50018 - diff: 41.96mlTrain batch 2/31 - 172.8ms/batch - loss: 187.10826 - diff: 37.63mlTrain batch 3/31 - 172.8ms/batch - loss: 142.86732 - diff: 33.74mlTrain batch 4/31 - 172.2ms/batch - loss: 114.24910 - diff: 29.63mlTrain batch 5/31 - 172.4ms/batch - loss: 100.27903 - diff: 28.21mlTrain batch 6/31 - 172.3ms/batch - loss: 92.40447 - diff: 27.57mlTrain batch 7/31 - 172.6ms/batch - loss: 84.20537 - diff: 26.46mlTrain batch 8/31 - 172.2ms/batch - loss: 105.88590 - diff: 27.97mlTrain batch 9/31 - 172.5ms/batch - loss: 171.89124 - diff: 29.77mlTrain batch 10/31 - 172.6ms/batch - loss: 166.30576 - diff: 29.50mlTrain batch 11/31 - 172.5ms/batch - loss: 163.57176 - diff: 30.16mlTrain batch 12/31 - 173.0ms/batch - loss: 162.08468 - diff: 30.33mlTrain batch 13/31 - 172.3ms/batch - loss: 158.73628 - diff: 30.77mlTrain batch 14/31 - 173.2ms/batch - loss: 151.77034 - diff: 30.10mlTrain batch 15/31 - 172.7ms/batch - loss: 145.17856 - diff: 29.71mlTrain batch 16/31 - 172.9ms/batch - loss: 139.29166 - diff: 29.18mlTrain batch 17/31 - 172.3ms/batch - loss: 141.74660 - diff: 29.70mlTrain batch 18/31 - 172.4ms/batch - loss: 136.70959 - diff: 29.44mlTrain batch 19/31 - 172.7ms/batch - loss: 132.77130 - diff: 29.13mlTrain batch 20/31 - 172.6ms/batch - loss: 131.65845 - diff: 29.14mlTrain batch 21/31 - 172.5ms/batch - loss: 129.86203 - diff: 29.13mlTrain batch 22/31 - 172.7ms/batch - loss: 126.91756 - diff: 29.11mlTrain batch 23/31 - 172.5ms/batch - loss: 123.77125 - diff: 28.82mlTrain batch 24/31 - 172.7ms/batch - loss: 123.49303 - diff: 28.95mlTrain batch 25/31 - 172.6ms/batch - loss: 120.33955 - diff: 28.73mlTrain batch 26/31 - 172.9ms/batch - loss: 117.44879 - diff: 28.51mlTrain batch 27/31 - 172.3ms/batch - loss: 115.40728 - diff: 28.32mlTrain batch 28/31 - 172.8ms/batch - loss: 113.62084 - diff: 28.27mlTrain batch 29/31 - 172.8ms/batch - loss: 112.57570 - diff: 28.08mlTrain batch 30/31 - 173.0ms/batch - loss: 110.01996 - diff: 27.81mlTrain batch 31/31 - 86.3ms/batch - loss: 110.59152 - diff: 27.81mlTrain batch 31/31 - 10.1s 86.3ms/batch - loss: 110.59152 - diff: 27.81ml
Test 1.0s: val_loss: 81.14739 - diff: 26.83ml

Epoch 8: current best loss = 79.55314, at epoch 3
Train batch 1/31 - 172.8ms/batch - loss: 109.70838 - diff: 29.40mlTrain batch 2/31 - 172.9ms/batch - loss: 92.24650 - diff: 29.78mlTrain batch 3/31 - 172.6ms/batch - loss: 71.39704 - diff: 25.64mlTrain batch 4/31 - 172.8ms/batch - loss: 65.96862 - diff: 25.01mlTrain batch 5/31 - 172.7ms/batch - loss: 72.86750 - diff: 25.17mlTrain batch 6/31 - 172.7ms/batch - loss: 65.90979 - diff: 24.24mlTrain batch 7/31 - 172.8ms/batch - loss: 60.80253 - diff: 23.46mlTrain batch 8/31 - 172.7ms/batch - loss: 146.65425 - diff: 27.49mlTrain batch 9/31 - 172.4ms/batch - loss: 144.20404 - diff: 28.35mlTrain batch 10/31 - 173.0ms/batch - loss: 135.65918 - diff: 27.86mlTrain batch 11/31 - 172.6ms/batch - loss: 126.58371 - diff: 27.21mlTrain batch 12/31 - 172.7ms/batch - loss: 137.44787 - diff: 28.27mlTrain batch 13/31 - 172.5ms/batch - loss: 134.79993 - diff: 28.48mlTrain batch 14/31 - 172.8ms/batch - loss: 130.22328 - diff: 28.52mlTrain batch 15/31 - 172.5ms/batch - loss: 124.33243 - diff: 27.74mlTrain batch 16/31 - 172.8ms/batch - loss: 124.65120 - diff: 27.89mlTrain batch 17/31 - 172.7ms/batch - loss: 122.24219 - diff: 27.99mlTrain batch 18/31 - 172.9ms/batch - loss: 122.66682 - diff: 28.14mlTrain batch 19/31 - 172.7ms/batch - loss: 120.07721 - diff: 28.14mlTrain batch 20/31 - 172.8ms/batch - loss: 119.02694 - diff: 28.42mlTrain batch 21/31 - 172.7ms/batch - loss: 118.61741 - diff: 28.34mlTrain batch 22/31 - 172.8ms/batch - loss: 114.86514 - diff: 27.92mlTrain batch 23/31 - 172.7ms/batch - loss: 113.82697 - diff: 27.97mlTrain batch 24/31 - 172.8ms/batch - loss: 112.19406 - diff: 27.79mlTrain batch 25/31 - 172.8ms/batch - loss: 111.30114 - diff: 27.49mlTrain batch 26/31 - 172.8ms/batch - loss: 108.53092 - diff: 27.21mlTrain batch 27/31 - 172.7ms/batch - loss: 110.86399 - diff: 27.26mlTrain batch 28/31 - 173.0ms/batch - loss: 110.74440 - diff: 27.16mlTrain batch 29/31 - 172.8ms/batch - loss: 108.42371 - diff: 27.02mlTrain batch 30/31 - 173.0ms/batch - loss: 108.51449 - diff: 27.03mlTrain batch 31/31 - 86.8ms/batch - loss: 108.50784 - diff: 26.97mlTrain batch 31/31 - 10.0s 86.8ms/batch - loss: 108.50784 - diff: 26.97ml
Test 1.1s: val_loss: 76.15222 - diff: 26.44ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Systole_WideResNet50_0_Adam-0.001_MSE_DA3_best

Epoch 9: current best loss = 76.15222, at epoch 8
Train batch 1/31 - 188.1ms/batch - loss: 187.26990 - diff: 38.58mlTrain batch 2/31 - 172.9ms/batch - loss: 142.08359 - diff: 33.40mlTrain batch 3/31 - 172.4ms/batch - loss: 116.46215 - diff: 31.35mlTrain batch 4/31 - 172.5ms/batch - loss: 107.86897 - diff: 31.50mlTrain batch 5/31 - 172.5ms/batch - loss: 128.23560 - diff: 34.22mlTrain batch 6/31 - 172.9ms/batch - loss: 111.94359 - diff: 31.53mlTrain batch 7/31 - 172.7ms/batch - loss: 103.83023 - diff: 30.72mlTrain batch 8/31 - 173.3ms/batch - loss: 98.06133 - diff: 29.42mlTrain batch 9/31 - 172.9ms/batch - loss: 115.14038 - diff: 30.29mlTrain batch 10/31 - 173.4ms/batch - loss: 116.70087 - diff: 30.18mlTrain batch 11/31 - 172.6ms/batch - loss: 110.53787 - diff: 29.68mlTrain batch 12/31 - 173.4ms/batch - loss: 105.51008 - diff: 29.28mlTrain batch 13/31 - 173.1ms/batch - loss: 108.23666 - diff: 29.46mlTrain batch 14/31 - 173.1ms/batch - loss: 103.94648 - diff: 29.04mlTrain batch 15/31 - 172.9ms/batch - loss: 100.46480 - diff: 28.73mlTrain batch 16/31 - 173.3ms/batch - loss: 141.07962 - diff: 30.09mlTrain batch 17/31 - 173.0ms/batch - loss: 136.56843 - diff: 29.79mlTrain batch 18/31 - 173.5ms/batch - loss: 134.51348 - diff: 29.80mlTrain batch 19/31 - 173.0ms/batch - loss: 128.55880 - diff: 29.05mlTrain batch 20/31 - 173.0ms/batch - loss: 124.91107 - diff: 28.67mlTrain batch 21/31 - 173.1ms/batch - loss: 121.27142 - diff: 28.51mlTrain batch 22/31 - 173.2ms/batch - loss: 118.82071 - diff: 28.25mlTrain batch 23/31 - 172.9ms/batch - loss: 117.97345 - diff: 28.23mlTrain batch 24/31 - 173.4ms/batch - loss: 117.76498 - diff: 28.26mlTrain batch 25/31 - 172.9ms/batch - loss: 114.76551 - diff: 28.04mlTrain batch 26/31 - 173.5ms/batch - loss: 111.40574 - diff: 27.58mlTrain batch 27/31 - 173.2ms/batch - loss: 109.52944 - diff: 27.46mlTrain batch 28/31 - 173.3ms/batch - loss: 106.84643 - diff: 27.19mlTrain batch 29/31 - 172.6ms/batch - loss: 105.79486 - diff: 27.21mlTrain batch 30/31 - 173.6ms/batch - loss: 105.89635 - diff: 27.38mlTrain batch 31/31 - 86.9ms/batch - loss: 109.28200 - diff: 27.54mlTrain batch 31/31 - 10.0s 86.9ms/batch - loss: 109.28200 - diff: 27.54ml
Test 1.1s: val_loss: 75.76724 - diff: 26.15ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Systole_WideResNet50_0_Adam-0.001_MSE_DA3_best

Epoch 10: current best loss = 75.76724, at epoch 9
Train batch 1/31 - 173.2ms/batch - loss: 52.30836 - diff: 21.98mlTrain batch 2/31 - 173.2ms/batch - loss: 81.40796 - diff: 25.20mlTrain batch 3/31 - 172.9ms/batch - loss: 71.50847 - diff: 24.37mlTrain batch 4/31 - 173.4ms/batch - loss: 74.40277 - diff: 24.93mlTrain batch 5/31 - 173.0ms/batch - loss: 68.31510 - diff: 24.52mlTrain batch 6/31 - 173.1ms/batch - loss: 66.00903 - diff: 24.69mlTrain batch 7/31 - 172.9ms/batch - loss: 65.07752 - diff: 25.01mlTrain batch 8/31 - 173.2ms/batch - loss: 65.68028 - diff: 24.74mlTrain batch 9/31 - 173.0ms/batch - loss: 73.59029 - diff: 25.84mlTrain batch 10/31 - 173.3ms/batch - loss: 73.54596 - diff: 25.90mlTrain batch 11/31 - 172.8ms/batch - loss: 70.47714 - diff: 25.56mlTrain batch 12/31 - 173.3ms/batch - loss: 71.61638 - diff: 25.78mlTrain batch 13/31 - 172.9ms/batch - loss: 75.93393 - diff: 26.02mlTrain batch 14/31 - 173.4ms/batch - loss: 120.41246 - diff: 27.11mlTrain batch 15/31 - 173.1ms/batch - loss: 114.37859 - diff: 26.38mlTrain batch 16/31 - 173.2ms/batch - loss: 109.49224 - diff: 25.99mlTrain batch 17/31 - 173.2ms/batch - loss: 106.23202 - diff: 25.83mlTrain batch 18/31 - 173.3ms/batch - loss: 109.37635 - diff: 26.25mlTrain batch 19/31 - 173.1ms/batch - loss: 108.96879 - diff: 26.39mlTrain batch 20/31 - 173.3ms/batch - loss: 105.32245 - diff: 26.07mlTrain batch 21/31 - 172.9ms/batch - loss: 105.60245 - diff: 26.23mlTrain batch 22/31 - 173.6ms/batch - loss: 103.06492 - diff: 26.14mlTrain batch 23/31 - 173.0ms/batch - loss: 100.70308 - diff: 26.05mlTrain batch 24/31 - 173.1ms/batch - loss: 99.46295 - diff: 26.03mlTrain batch 25/31 - 173.2ms/batch - loss: 100.68642 - diff: 26.28mlTrain batch 26/31 - 173.5ms/batch - loss: 99.62578 - diff: 26.30mlTrain batch 27/31 - 172.9ms/batch - loss: 97.51472 - diff: 26.14mlTrain batch 28/31 - 173.3ms/batch - loss: 96.36986 - diff: 26.07mlTrain batch 29/31 - 173.0ms/batch - loss: 99.85011 - diff: 26.44mlTrain batch 30/31 - 173.6ms/batch - loss: 104.96790 - diff: 26.86mlTrain batch 31/31 - 86.9ms/batch - loss: 111.47120 - diff: 27.16mlTrain batch 31/31 - 10.0s 86.9ms/batch - loss: 111.47120 - diff: 27.16ml
Test 1.1s: val_loss: 74.65580 - diff: 26.12ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Systole_WideResNet50_0_Adam-0.001_MSE_DA3_best

Epoch 11: current best loss = 74.65580, at epoch 10
Train batch 1/31 - 173.1ms/batch - loss: 58.20378 - diff: 27.77mlTrain batch 2/31 - 173.0ms/batch - loss: 53.41012 - diff: 23.45mlTrain batch 3/31 - 173.0ms/batch - loss: 64.37937 - diff: 25.54mlTrain batch 4/31 - 173.4ms/batch - loss: 89.78593 - diff: 27.29mlTrain batch 5/31 - 173.2ms/batch - loss: 79.08386 - diff: 25.75mlTrain batch 6/31 - 173.5ms/batch - loss: 76.22342 - diff: 25.95mlTrain batch 7/31 - 173.0ms/batch - loss: 75.87784 - diff: 26.13mlTrain batch 8/31 - 173.5ms/batch - loss: 72.81312 - diff: 25.37mlTrain batch 9/31 - 173.2ms/batch - loss: 68.75295 - diff: 24.61mlTrain batch 10/31 - 173.4ms/batch - loss: 65.09718 - diff: 24.14mlTrain batch 11/31 - 173.1ms/batch - loss: 63.75757 - diff: 23.92mlTrain batch 12/31 - 173.5ms/batch - loss: 66.29105 - diff: 24.49mlTrain batch 13/31 - 173.2ms/batch - loss: 70.53323 - diff: 25.03mlTrain batch 14/31 - 173.2ms/batch - loss: 71.36166 - diff: 25.11mlTrain batch 15/31 - 173.1ms/batch - loss: 81.46426 - diff: 25.63mlTrain batch 16/31 - 173.4ms/batch - loss: 78.12550 - diff: 25.11mlTrain batch 17/31 - 173.1ms/batch - loss: 75.30017 - diff: 24.63mlTrain batch 18/31 - 173.4ms/batch - loss: 73.98234 - diff: 24.72mlTrain batch 19/31 - 173.2ms/batch - loss: 72.26017 - diff: 24.48mlTrain batch 20/31 - 173.0ms/batch - loss: 74.16345 - diff: 24.90mlTrain batch 21/31 - 173.1ms/batch - loss: 106.88309 - diff: 26.26mlTrain batch 22/31 - 173.4ms/batch - loss: 107.69079 - diff: 26.48mlTrain batch 23/31 - 173.4ms/batch - loss: 105.34711 - diff: 26.39mlTrain batch 24/31 - 173.4ms/batch - loss: 103.49348 - diff: 26.39mlTrain batch 25/31 - 173.1ms/batch - loss: 101.57995 - diff: 26.29mlTrain batch 26/31 - 173.5ms/batch - loss: 105.11684 - diff: 26.81mlTrain batch 27/31 - 173.1ms/batch - loss: 107.75605 - diff: 27.02mlTrain batch 28/31 - 173.2ms/batch - loss: 106.75313 - diff: 26.93mlTrain batch 29/31 - 173.3ms/batch - loss: 107.91213 - diff: 27.19mlTrain batch 30/31 - 173.3ms/batch - loss: 107.18762 - diff: 27.33mlTrain batch 31/31 - 86.9ms/batch - loss: 107.28378 - diff: 27.31mlTrain batch 31/31 - 10.0s 86.9ms/batch - loss: 107.28378 - diff: 27.31ml
Test 1.1s: val_loss: 75.44533 - diff: 26.45ml

Epoch 12: current best loss = 74.65580, at epoch 10
Train batch 1/31 - 173.2ms/batch - loss: 61.26861 - diff: 28.13mlTrain batch 2/31 - 173.0ms/batch - loss: 123.65343 - diff: 31.67mlTrain batch 3/31 - 173.1ms/batch - loss: 109.14715 - diff: 30.51mlTrain batch 4/31 - 173.1ms/batch - loss: 89.14478 - diff: 27.35mlTrain batch 5/31 - 173.2ms/batch - loss: 84.24756 - diff: 27.63mlTrain batch 6/31 - 173.3ms/batch - loss: 77.37712 - diff: 26.62mlTrain batch 7/31 - 173.1ms/batch - loss: 76.77255 - diff: 26.71mlTrain batch 8/31 - 173.4ms/batch - loss: 83.78981 - diff: 27.08mlTrain batch 9/31 - 173.1ms/batch - loss: 80.29360 - diff: 27.00mlTrain batch 10/31 - 173.3ms/batch - loss: 81.37301 - diff: 26.96mlTrain batch 11/31 - 173.3ms/batch - loss: 80.56530 - diff: 26.98mlTrain batch 12/31 - 173.6ms/batch - loss: 85.44017 - diff: 27.47mlTrain batch 13/31 - 172.9ms/batch - loss: 82.91610 - diff: 27.29mlTrain batch 14/31 - 173.4ms/batch - loss: 79.24042 - diff: 26.67mlTrain batch 15/31 - 173.1ms/batch - loss: 81.60331 - diff: 26.90mlTrain batch 16/31 - 173.5ms/batch - loss: 80.08247 - diff: 26.77mlTrain batch 17/31 - 173.1ms/batch - loss: 76.61989 - diff: 26.07mlTrain batch 18/31 - 173.5ms/batch - loss: 80.77343 - diff: 26.38mlTrain batch 19/31 - 173.2ms/batch - loss: 78.96112 - diff: 25.94mlTrain batch 20/31 - 173.5ms/batch - loss: 76.36006 - diff: 25.54mlTrain batch 21/31 - 173.4ms/batch - loss: 74.37662 - diff: 25.31mlTrain batch 22/31 - 173.5ms/batch - loss: 112.21584 - diff: 26.94mlTrain batch 23/31 - 173.4ms/batch - loss: 111.30294 - diff: 27.13mlTrain batch 24/31 - 173.6ms/batch - loss: 109.28370 - diff: 27.15mlTrain batch 25/31 - 173.2ms/batch - loss: 108.50646 - diff: 27.18mlTrain batch 26/31 - 173.5ms/batch - loss: 109.19531 - diff: 27.29mlTrain batch 27/31 - 173.4ms/batch - loss: 109.82203 - diff: 27.50mlTrain batch 28/31 - 173.5ms/batch - loss: 107.82476 - diff: 27.43mlTrain batch 29/31 - 173.3ms/batch - loss: 107.34813 - diff: 27.47mlTrain batch 30/31 - 173.3ms/batch - loss: 108.36128 - diff: 27.50mlTrain batch 31/31 - 86.9ms/batch - loss: 108.06711 - diff: 27.44mlTrain batch 31/31 - 10.0s 86.9ms/batch - loss: 108.06711 - diff: 27.44ml
Test 1.1s: val_loss: 73.96847 - diff: 25.59ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Systole_WideResNet50_0_Adam-0.001_MSE_DA3_best

Epoch 13: current best loss = 73.96847, at epoch 12
Train batch 1/31 - 173.2ms/batch - loss: 795.60150 - diff: 56.23mlTrain batch 2/31 - 173.6ms/batch - loss: 471.01977 - diff: 45.36mlTrain batch 3/31 - 173.1ms/batch - loss: 324.89415 - diff: 35.99mlTrain batch 4/31 - 173.6ms/batch - loss: 260.31654 - diff: 33.39mlTrain batch 5/31 - 173.3ms/batch - loss: 216.64086 - diff: 31.46mlTrain batch 6/31 - 173.8ms/batch - loss: 185.04349 - diff: 28.97mlTrain batch 7/31 - 173.0ms/batch - loss: 167.66038 - diff: 28.83mlTrain batch 8/31 - 173.4ms/batch - loss: 156.88530 - diff: 29.11mlTrain batch 9/31 - 173.1ms/batch - loss: 148.86175 - diff: 29.25mlTrain batch 10/31 - 173.5ms/batch - loss: 143.75945 - diff: 29.04mlTrain batch 11/31 - 173.0ms/batch - loss: 137.21928 - diff: 28.76mlTrain batch 12/31 - 173.5ms/batch - loss: 141.11478 - diff: 29.33mlTrain batch 13/31 - 173.2ms/batch - loss: 138.37830 - diff: 29.69mlTrain batch 14/31 - 173.4ms/batch - loss: 130.57784 - diff: 28.88mlTrain batch 15/31 - 173.1ms/batch - loss: 124.80207 - diff: 28.59mlTrain batch 16/31 - 173.5ms/batch - loss: 122.04353 - diff: 28.41mlTrain batch 17/31 - 173.3ms/batch - loss: 116.68240 - diff: 27.83mlTrain batch 18/31 - 173.4ms/batch - loss: 116.08320 - diff: 28.15mlTrain batch 19/31 - 173.1ms/batch - loss: 112.28514 - diff: 27.85mlTrain batch 20/31 - 173.6ms/batch - loss: 109.32663 - diff: 27.58mlTrain batch 21/31 - 173.1ms/batch - loss: 107.46683 - diff: 27.59mlTrain batch 22/31 - 173.6ms/batch - loss: 103.97836 - diff: 27.20mlTrain batch 23/31 - 173.1ms/batch - loss: 101.80975 - diff: 26.99mlTrain batch 24/31 - 172.9ms/batch - loss: 105.40525 - diff: 27.38mlTrain batch 25/31 - 173.3ms/batch - loss: 103.20973 - diff: 27.26mlTrain batch 26/31 - 173.3ms/batch - loss: 103.34188 - diff: 27.34mlTrain batch 27/31 - 173.3ms/batch - loss: 108.27778 - diff: 27.38mlTrain batch 28/31 - 173.4ms/batch - loss: 109.55272 - diff: 27.63mlTrain batch 29/31 - 173.2ms/batch - loss: 108.37730 - diff: 27.55mlTrain batch 30/31 - 173.5ms/batch - loss: 106.32502 - diff: 27.38mlTrain batch 31/31 - 86.9ms/batch - loss: 109.46447 - diff: 27.56mlTrain batch 31/31 - 10.1s 86.9ms/batch - loss: 109.46447 - diff: 27.56ml
Test 1.1s: val_loss: 77.46708 - diff: 26.75ml

Epoch 14: current best loss = 73.96847, at epoch 12
Train batch 1/31 - 173.0ms/batch - loss: 71.36647 - diff: 25.19mlTrain batch 2/31 - 173.5ms/batch - loss: 75.39836 - diff: 26.35mlTrain batch 3/31 - 173.2ms/batch - loss: 66.27958 - diff: 24.98mlTrain batch 4/31 - 173.5ms/batch - loss: 71.33851 - diff: 26.45mlTrain batch 5/31 - 173.4ms/batch - loss: 65.74342 - diff: 25.53mlTrain batch 6/31 - 173.9ms/batch - loss: 59.61227 - diff: 24.36mlTrain batch 7/31 - 173.5ms/batch - loss: 79.34947 - diff: 25.85mlTrain batch 8/31 - 173.7ms/batch - loss: 78.76796 - diff: 26.05mlTrain batch 9/31 - 173.1ms/batch - loss: 76.84607 - diff: 25.87mlTrain batch 10/31 - 173.2ms/batch - loss: 75.26479 - diff: 25.47mlTrain batch 11/31 - 173.2ms/batch - loss: 129.94924 - diff: 26.40mlTrain batch 12/31 - 173.3ms/batch - loss: 126.37774 - diff: 26.78mlTrain batch 13/31 - 173.0ms/batch - loss: 123.67522 - diff: 27.02mlTrain batch 14/31 - 173.5ms/batch - loss: 126.38118 - diff: 27.97mlTrain batch 15/31 - 173.2ms/batch - loss: 125.89122 - diff: 28.11mlTrain batch 16/31 - 173.9ms/batch - loss: 123.20005 - diff: 27.99mlTrain batch 17/31 - 173.3ms/batch - loss: 117.33112 - diff: 27.34mlTrain batch 18/31 - 174.0ms/batch - loss: 113.70319 - diff: 27.22mlTrain batch 19/31 - 173.5ms/batch - loss: 109.53294 - diff: 26.77mlTrain batch 20/31 - 173.3ms/batch - loss: 115.90705 - diff: 27.11mlTrain batch 21/31 - 173.3ms/batch - loss: 114.32860 - diff: 27.04mlTrain batch 22/31 - 172.9ms/batch - loss: 116.79226 - diff: 27.51mlTrain batch 23/31 - 173.3ms/batch - loss: 116.15099 - diff: 27.63mlTrain batch 24/31 - 173.3ms/batch - loss: 114.33193 - diff: 27.77mlTrain batch 25/31 - 173.1ms/batch - loss: 112.73086 - diff: 27.78mlTrain batch 26/31 - 173.6ms/batch - loss: 110.20599 - diff: 27.61mlTrain batch 27/31 - 173.3ms/batch - loss: 110.84420 - diff: 27.77mlTrain batch 28/31 - 173.5ms/batch - loss: 112.91508 - diff: 27.97mlTrain batch 29/31 - 173.0ms/batch - loss: 110.23331 - diff: 27.76mlTrain batch 30/31 - 173.7ms/batch - loss: 107.52961 - diff: 27.44mlTrain batch 31/31 - 87.1ms/batch - loss: 107.55488 - diff: 27.36mlTrain batch 31/31 - 10.1s 87.1ms/batch - loss: 107.55488 - diff: 27.36ml
Test 1.1s: val_loss: 74.02344 - diff: 24.46ml

Epoch 15: current best loss = 73.96847, at epoch 12
Train batch 1/31 - 173.3ms/batch - loss: 57.92559 - diff: 25.35mlTrain batch 2/31 - 173.3ms/batch - loss: 58.99546 - diff: 24.60mlTrain batch 3/31 - 173.5ms/batch - loss: 72.54772 - diff: 26.12mlTrain batch 4/31 - 174.0ms/batch - loss: 88.27526 - diff: 27.65mlTrain batch 5/31 - 173.2ms/batch - loss: 84.87897 - diff: 26.83mlTrain batch 6/31 - 173.5ms/batch - loss: 98.11619 - diff: 27.93mlTrain batch 7/31 - 173.2ms/batch - loss: 91.95416 - diff: 27.18mlTrain batch 8/31 - 173.4ms/batch - loss: 110.10573 - diff: 28.35mlTrain batch 9/31 - 173.3ms/batch - loss: 101.55848 - diff: 27.04mlTrain batch 10/31 - 173.5ms/batch - loss: 98.07222 - diff: 26.46mlTrain batch 11/31 - 173.3ms/batch - loss: 108.88918 - diff: 27.23mlTrain batch 12/31 - 173.7ms/batch - loss: 109.23656 - diff: 27.30mlTrain batch 13/31 - 173.4ms/batch - loss: 105.82026 - diff: 26.92mlTrain batch 14/31 - 173.9ms/batch - loss: 102.64960 - diff: 26.74mlTrain batch 15/31 - 173.6ms/batch - loss: 99.63869 - diff: 26.62mlTrain batch 16/31 - 173.7ms/batch - loss: 96.12722 - diff: 26.28mlTrain batch 17/31 - 173.6ms/batch - loss: 128.32221 - diff: 26.92mlTrain batch 18/31 - 173.6ms/batch - loss: 127.80452 - diff: 27.14mlTrain batch 19/31 - 173.7ms/batch - loss: 124.84638 - diff: 27.26mlTrain batch 20/31 - 174.0ms/batch - loss: 122.05624 - diff: 27.34mlTrain batch 21/31 - 173.4ms/batch - loss: 118.93250 - diff: 27.35mlTrain batch 22/31 - 173.5ms/batch - loss: 116.18464 - diff: 27.29mlTrain batch 23/31 - 173.3ms/batch - loss: 114.06048 - diff: 27.21mlTrain batch 24/31 - 173.5ms/batch - loss: 111.27287 - diff: 27.15mlTrain batch 25/31 - 173.2ms/batch - loss: 111.78925 - diff: 27.47mlTrain batch 26/31 - 173.6ms/batch - loss: 109.60825 - diff: 27.35mlTrain batch 27/31 - 173.6ms/batch - loss: 108.00424 - diff: 27.40mlTrain batch 28/31 - 174.0ms/batch - loss: 108.29203 - diff: 27.46mlTrain batch 29/31 - 173.9ms/batch - loss: 106.10118 - diff: 27.25mlTrain batch 30/31 - 174.0ms/batch - loss: 103.66636 - diff: 26.97mlTrain batch 31/31 - 87.3ms/batch - loss: 103.16664 - diff: 26.82mlTrain batch 31/31 - 10.1s 87.3ms/batch - loss: 103.16664 - diff: 26.82ml
Test 1.1s: val_loss: 85.70009 - diff: 25.09ml

Epoch 16: current best loss = 73.96847, at epoch 12
Train batch 1/31 - 173.3ms/batch - loss: 34.82295 - diff: 18.67mlTrain batch 2/31 - 173.1ms/batch - loss: 41.69006 - diff: 21.28mlTrain batch 3/31 - 173.3ms/batch - loss: 40.23730 - diff: 20.59mlTrain batch 4/31 - 173.9ms/batch - loss: 48.13637 - diff: 21.50mlTrain batch 5/31 - 173.1ms/batch - loss: 42.75417 - diff: 20.26mlTrain batch 6/31 - 173.5ms/batch - loss: 41.47549 - diff: 19.99mlTrain batch 7/31 - 173.1ms/batch - loss: 45.97451 - diff: 21.01mlTrain batch 8/31 - 173.7ms/batch - loss: 45.04210 - diff: 21.01mlTrain batch 9/31 - 173.4ms/batch - loss: 49.18823 - diff: 21.68mlTrain batch 10/31 - 173.8ms/batch - loss: 57.00688 - diff: 22.42mlTrain batch 11/31 - 173.4ms/batch - loss: 61.62163 - diff: 22.95mlTrain batch 12/31 - 174.0ms/batch - loss: 60.62859 - diff: 23.07mlTrain batch 13/31 - 173.9ms/batch - loss: 78.40585 - diff: 24.25mlTrain batch 14/31 - 174.1ms/batch - loss: 80.11855 - diff: 24.30mlTrain batch 15/31 - 173.6ms/batch - loss: 83.53982 - diff: 24.98mlTrain batch 16/31 - 174.1ms/batch - loss: 81.18745 - diff: 24.59mlTrain batch 17/31 - 173.7ms/batch - loss: 80.08588 - diff: 24.52mlTrain batch 18/31 - 174.0ms/batch - loss: 81.43420 - diff: 24.60mlTrain batch 19/31 - 173.9ms/batch - loss: 79.54476 - diff: 24.29mlTrain batch 20/31 - 173.4ms/batch - loss: 81.21686 - diff: 24.86mlTrain batch 21/31 - 173.8ms/batch - loss: 82.12596 - diff: 24.84mlTrain batch 22/31 - 173.8ms/batch - loss: 91.14806 - diff: 25.97mlTrain batch 23/31 - 173.2ms/batch - loss: 117.93925 - diff: 26.90mlTrain batch 24/31 - 173.4ms/batch - loss: 114.56871 - diff: 26.73mlTrain batch 25/31 - 173.1ms/batch - loss: 111.99879 - diff: 26.59mlTrain batch 26/31 - 173.8ms/batch - loss: 109.14798 - diff: 26.29mlTrain batch 27/31 - 173.2ms/batch - loss: 108.28679 - diff: 26.46mlTrain batch 28/31 - 173.7ms/batch - loss: 106.48645 - diff: 26.42mlTrain batch 29/31 - 173.8ms/batch - loss: 106.92395 - diff: 26.56mlTrain batch 30/31 - 173.8ms/batch - loss: 105.00200 - diff: 26.42mlTrain batch 31/31 - 87.2ms/batch - loss: 104.68698 - diff: 26.36mlTrain batch 31/31 - 10.0s 87.2ms/batch - loss: 104.68698 - diff: 26.36ml
Test 1.1s: val_loss: 73.68012 - diff: 25.81ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Systole_WideResNet50_0_Adam-0.001_MSE_DA3_best

Epoch 17: current best loss = 73.68012, at epoch 16
Train batch 1/31 - 173.3ms/batch - loss: 76.13302 - diff: 29.22mlTrain batch 2/31 - 173.7ms/batch - loss: 85.17916 - diff: 28.06mlTrain batch 3/31 - 173.4ms/batch - loss: 73.62537 - diff: 26.39mlTrain batch 4/31 - 173.4ms/batch - loss: 67.16027 - diff: 25.52mlTrain batch 5/31 - 173.7ms/batch - loss: 68.42664 - diff: 25.82mlTrain batch 6/31 - 173.7ms/batch - loss: 65.79641 - diff: 25.72mlTrain batch 7/31 - 173.3ms/batch - loss: 156.17141 - diff: 29.37mlTrain batch 8/31 - 173.6ms/batch - loss: 150.61144 - diff: 29.08mlTrain batch 9/31 - 173.2ms/batch - loss: 138.95853 - diff: 28.22mlTrain batch 10/31 - 173.6ms/batch - loss: 128.99750 - diff: 27.37mlTrain batch 11/31 - 173.2ms/batch - loss: 121.65513 - diff: 27.10mlTrain batch 12/31 - 173.6ms/batch - loss: 115.70200 - diff: 26.75mlTrain batch 13/31 - 173.4ms/batch - loss: 110.68568 - diff: 26.57mlTrain batch 14/31 - 173.7ms/batch - loss: 112.21136 - diff: 26.92mlTrain batch 15/31 - 173.1ms/batch - loss: 109.30755 - diff: 26.84mlTrain batch 16/31 - 173.7ms/batch - loss: 114.00248 - diff: 27.32mlTrain batch 17/31 - 173.5ms/batch - loss: 122.64800 - diff: 27.88mlTrain batch 18/31 - 173.7ms/batch - loss: 118.80111 - diff: 27.77mlTrain batch 19/31 - 173.4ms/batch - loss: 116.00546 - diff: 27.75mlTrain batch 20/31 - 173.8ms/batch - loss: 115.52992 - diff: 28.02mlTrain batch 21/31 - 173.4ms/batch - loss: 112.82586 - diff: 27.82mlTrain batch 22/31 - 173.5ms/batch - loss: 112.19725 - diff: 27.70mlTrain batch 23/31 - 173.1ms/batch - loss: 112.16195 - diff: 27.63mlTrain batch 24/31 - 173.6ms/batch - loss: 113.77537 - diff: 27.76mlTrain batch 25/31 - 173.3ms/batch - loss: 113.47756 - diff: 27.83mlTrain batch 26/31 - 173.3ms/batch - loss: 112.38564 - diff: 27.65mlTrain batch 27/31 - 173.5ms/batch - loss: 109.72482 - diff: 27.44mlTrain batch 28/31 - 174.0ms/batch - loss: 107.21674 - diff: 27.28mlTrain batch 29/31 - 173.8ms/batch - loss: 104.82782 - diff: 26.99mlTrain batch 30/31 - 174.2ms/batch - loss: 103.84606 - diff: 27.05mlTrain batch 31/31 - 87.3ms/batch - loss: 103.62492 - diff: 26.96mlTrain batch 31/31 - 10.1s 87.3ms/batch - loss: 103.62492 - diff: 26.96ml
Test 1.1s: val_loss: 73.45889 - diff: 24.97ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Systole_WideResNet50_0_Adam-0.001_MSE_DA3_best

Epoch 18: current best loss = 73.45889, at epoch 17
Train batch 1/31 - 173.4ms/batch - loss: 38.38920 - diff: 20.69mlTrain batch 2/31 - 173.9ms/batch - loss: 108.75899 - diff: 25.47mlTrain batch 3/31 - 173.8ms/batch - loss: 94.16923 - diff: 24.91mlTrain batch 4/31 - 173.9ms/batch - loss: 79.85438 - diff: 23.54mlTrain batch 5/31 - 173.4ms/batch - loss: 68.76444 - diff: 22.15mlTrain batch 6/31 - 173.4ms/batch - loss: 71.45501 - diff: 23.04mlTrain batch 7/31 - 173.3ms/batch - loss: 69.19889 - diff: 23.41mlTrain batch 8/31 - 173.4ms/batch - loss: 64.84653 - diff: 23.04mlTrain batch 9/31 - 173.4ms/batch - loss: 60.75146 - diff: 22.45mlTrain batch 10/31 - 173.7ms/batch - loss: 70.83340 - diff: 23.28mlTrain batch 11/31 - 173.9ms/batch - loss: 69.88621 - diff: 23.40mlTrain batch 12/31 - 173.9ms/batch - loss: 70.22072 - diff: 23.23mlTrain batch 13/31 - 173.9ms/batch - loss: 69.08739 - diff: 23.35mlTrain batch 14/31 - 174.1ms/batch - loss: 68.89006 - diff: 23.50mlTrain batch 15/31 - 173.9ms/batch - loss: 67.89304 - diff: 23.62mlTrain batch 16/31 - 173.6ms/batch - loss: 107.23497 - diff: 25.26mlTrain batch 17/31 - 173.7ms/batch - loss: 103.42327 - diff: 24.99mlTrain batch 18/31 - 173.8ms/batch - loss: 103.33547 - diff: 25.04mlTrain batch 19/31 - 173.8ms/batch - loss: 99.88525 - diff: 24.73mlTrain batch 20/31 - 174.1ms/batch - loss: 100.22755 - diff: 25.08mlTrain batch 21/31 - 173.8ms/batch - loss: 101.35203 - diff: 25.38mlTrain batch 22/31 - 174.1ms/batch - loss: 99.43092 - diff: 25.19mlTrain batch 23/31 - 173.8ms/batch - loss: 97.16538 - diff: 25.08mlTrain batch 24/31 - 173.8ms/batch - loss: 97.43864 - diff: 25.17mlTrain batch 25/31 - 173.9ms/batch - loss: 97.57678 - diff: 25.21mlTrain batch 26/31 - 174.1ms/batch - loss: 95.19116 - diff: 24.93mlTrain batch 27/31 - 173.6ms/batch - loss: 102.27518 - diff: 25.82mlTrain batch 28/31 - 174.2ms/batch - loss: 100.75379 - diff: 25.73mlTrain batch 29/31 - 173.8ms/batch - loss: 100.26095 - diff: 25.95mlTrain batch 30/31 - 173.7ms/batch - loss: 105.27951 - diff: 26.40mlTrain batch 31/31 - 87.2ms/batch - loss: 104.09489 - diff: 26.16mlTrain batch 31/31 - 10.1s 87.2ms/batch - loss: 104.09489 - diff: 26.16ml
Test 1.1s: val_loss: 72.64015 - diff: 25.98ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Systole_WideResNet50_0_Adam-0.001_MSE_DA3_best

Epoch 19: current best loss = 72.64015, at epoch 18
Train batch 1/31 - 173.3ms/batch - loss: 29.26107 - diff: 18.80mlTrain batch 2/31 - 173.4ms/batch - loss: 77.88695 - diff: 25.29mlTrain batch 3/31 - 173.4ms/batch - loss: 92.06654 - diff: 28.11mlTrain batch 4/31 - 173.7ms/batch - loss: 78.81149 - diff: 26.45mlTrain batch 5/31 - 173.4ms/batch - loss: 84.47184 - diff: 26.14mlTrain batch 6/31 - 174.2ms/batch - loss: 78.13609 - diff: 26.05mlTrain batch 7/31 - 173.7ms/batch - loss: 74.82014 - diff: 25.86mlTrain batch 8/31 - 174.0ms/batch - loss: 73.55715 - diff: 26.29mlTrain batch 9/31 - 173.6ms/batch - loss: 69.06878 - diff: 25.48mlTrain batch 10/31 - 174.2ms/batch - loss: 64.35490 - diff: 24.47mlTrain batch 11/31 - 173.8ms/batch - loss: 68.14852 - diff: 25.22mlTrain batch 12/31 - 174.1ms/batch - loss: 66.93287 - diff: 25.15mlTrain batch 13/31 - 173.8ms/batch - loss: 65.27337 - diff: 24.82mlTrain batch 14/31 - 173.6ms/batch - loss: 67.16230 - diff: 25.10mlTrain batch 15/31 - 174.0ms/batch - loss: 68.55090 - diff: 25.49mlTrain batch 16/31 - 174.0ms/batch - loss: 67.21128 - diff: 25.26mlTrain batch 17/31 - 173.9ms/batch - loss: 72.58204 - diff: 26.10mlTrain batch 18/31 - 174.1ms/batch - loss: 72.99787 - diff: 26.18mlTrain batch 19/31 - 173.8ms/batch - loss: 72.79896 - diff: 26.11mlTrain batch 20/31 - 173.6ms/batch - loss: 75.57705 - diff: 26.14mlTrain batch 21/31 - 174.0ms/batch - loss: 86.48866 - diff: 26.86mlTrain batch 22/31 - 174.1ms/batch - loss: 84.70469 - diff: 26.60mlTrain batch 23/31 - 173.7ms/batch - loss: 82.22690 - diff: 26.26mlTrain batch 24/31 - 174.1ms/batch - loss: 84.83760 - diff: 26.64mlTrain batch 25/31 - 173.9ms/batch - loss: 87.24663 - diff: 26.67mlTrain batch 26/31 - 174.0ms/batch - loss: 110.10023 - diff: 27.37mlTrain batch 27/31 - 173.7ms/batch - loss: 107.08809 - diff: 26.96mlTrain batch 28/31 - 173.9ms/batch - loss: 108.12447 - diff: 27.27mlTrain batch 29/31 - 173.8ms/batch - loss: 106.79045 - diff: 27.26mlTrain batch 30/31 - 174.1ms/batch - loss: 104.86586 - diff: 27.16mlTrain batch 31/31 - 87.1ms/batch - loss: 104.48947 - diff: 27.06mlTrain batch 31/31 - 10.0s 87.1ms/batch - loss: 104.48947 - diff: 27.06ml
Test 1.1s: val_loss: 73.28205 - diff: 24.78ml

Epoch 20: current best loss = 72.64015, at epoch 18
Train batch 1/31 - 173.8ms/batch - loss: 33.37641 - diff: 18.17mlTrain batch 2/31 - 173.4ms/batch - loss: 49.86813 - diff: 23.02mlTrain batch 3/31 - 173.8ms/batch - loss: 62.93663 - diff: 25.07mlTrain batch 4/31 - 173.8ms/batch - loss: 63.62200 - diff: 25.32mlTrain batch 5/31 - 173.6ms/batch - loss: 62.73840 - diff: 25.67mlTrain batch 6/31 - 174.0ms/batch - loss: 61.86260 - diff: 25.54mlTrain batch 7/31 - 173.6ms/batch - loss: 59.01570 - diff: 24.75mlTrain batch 8/31 - 174.0ms/batch - loss: 64.60853 - diff: 25.25mlTrain batch 9/31 - 173.8ms/batch - loss: 62.92026 - diff: 25.02mlTrain batch 10/31 - 174.0ms/batch - loss: 68.04820 - diff: 25.11mlTrain batch 11/31 - 173.9ms/batch - loss: 67.63367 - diff: 25.02mlTrain batch 12/31 - 173.9ms/batch - loss: 72.45218 - diff: 25.39mlTrain batch 13/31 - 174.0ms/batch - loss: 73.46205 - diff: 25.88mlTrain batch 14/31 - 173.9ms/batch - loss: 71.68583 - diff: 25.66mlTrain batch 15/31 - 173.8ms/batch - loss: 71.85915 - diff: 25.68mlTrain batch 16/31 - 173.9ms/batch - loss: 68.21023 - diff: 24.83mlTrain batch 17/31 - 173.9ms/batch - loss: 70.15210 - diff: 25.31mlTrain batch 18/31 - 173.9ms/batch - loss: 70.80127 - diff: 25.71mlTrain batch 19/31 - 173.8ms/batch - loss: 105.99854 - diff: 27.40mlTrain batch 20/31 - 174.1ms/batch - loss: 102.44692 - diff: 27.03mlTrain batch 21/31 - 173.8ms/batch - loss: 100.60111 - diff: 26.82mlTrain batch 22/31 - 174.0ms/batch - loss: 100.32635 - diff: 26.73mlTrain batch 23/31 - 173.7ms/batch - loss: 97.70213 - diff: 26.53mlTrain batch 24/31 - 174.1ms/batch - loss: 97.44449 - diff: 26.40mlTrain batch 25/31 - 173.8ms/batch - loss: 94.64109 - diff: 26.05mlTrain batch 26/31 - 173.8ms/batch - loss: 96.84709 - diff: 26.44mlTrain batch 27/31 - 173.8ms/batch - loss: 94.06137 - diff: 26.02mlTrain batch 28/31 - 174.0ms/batch - loss: 98.90035 - diff: 26.22mlTrain batch 29/31 - 173.7ms/batch - loss: 102.45586 - diff: 26.61mlTrain batch 30/31 - 174.2ms/batch - loss: 102.17998 - diff: 26.75mlTrain batch 31/31 - 87.2ms/batch - loss: 102.36966 - diff: 26.71mlTrain batch 31/31 - 10.1s 87.2ms/batch - loss: 102.36966 - diff: 26.71ml
Test 1.1s: val_loss: 71.27211 - diff: 25.87ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Systole_WideResNet50_0_Adam-0.001_MSE_DA3_best

Epoch 21: current best loss = 71.27211, at epoch 20
Train batch 1/31 - 173.5ms/batch - loss: 50.77267 - diff: 23.01mlTrain batch 2/31 - 173.8ms/batch - loss: 48.73619 - diff: 23.04mlTrain batch 3/31 - 174.1ms/batch - loss: 59.38945 - diff: 24.62mlTrain batch 4/31 - 174.2ms/batch - loss: 56.60839 - diff: 24.62mlTrain batch 5/31 - 173.9ms/batch - loss: 67.35289 - diff: 24.96mlTrain batch 6/31 - 174.1ms/batch - loss: 71.97837 - diff: 25.71mlTrain batch 7/31 - 173.8ms/batch - loss: 70.32161 - diff: 25.83mlTrain batch 8/31 - 173.9ms/batch - loss: 98.31136 - diff: 28.20mlTrain batch 9/31 - 173.8ms/batch - loss: 91.02434 - diff: 27.27mlTrain batch 10/31 - 173.9ms/batch - loss: 84.30133 - diff: 26.20mlTrain batch 11/31 - 173.8ms/batch - loss: 79.57947 - diff: 25.57mlTrain batch 12/31 - 174.0ms/batch - loss: 82.62092 - diff: 25.80mlTrain batch 13/31 - 173.8ms/batch - loss: 83.68835 - diff: 25.91mlTrain batch 14/31 - 173.9ms/batch - loss: 82.70998 - diff: 26.01mlTrain batch 15/31 - 173.8ms/batch - loss: 79.30256 - diff: 25.43mlTrain batch 16/31 - 173.8ms/batch - loss: 78.63587 - diff: 25.45mlTrain batch 17/31 - 173.6ms/batch - loss: 79.31267 - diff: 25.67mlTrain batch 18/31 - 173.9ms/batch - loss: 117.28610 - diff: 27.26mlTrain batch 19/31 - 173.8ms/batch - loss: 116.11942 - diff: 27.54mlTrain batch 20/31 - 174.0ms/batch - loss: 112.02532 - diff: 27.02mlTrain batch 21/31 - 173.9ms/batch - loss: 109.44199 - diff: 26.86mlTrain batch 22/31 - 173.9ms/batch - loss: 108.73691 - diff: 26.74mlTrain batch 23/31 - 173.8ms/batch - loss: 105.37756 - diff: 26.47mlTrain batch 24/31 - 173.9ms/batch - loss: 102.89287 - diff: 26.25mlTrain batch 25/31 - 173.8ms/batch - loss: 104.94388 - diff: 26.47mlTrain batch 26/31 - 173.8ms/batch - loss: 102.55752 - diff: 26.31mlTrain batch 27/31 - 173.6ms/batch - loss: 104.78670 - diff: 26.45mlTrain batch 28/31 - 174.0ms/batch - loss: 102.94954 - diff: 26.44mlTrain batch 29/31 - 173.9ms/batch - loss: 102.75262 - diff: 26.66mlTrain batch 30/31 - 173.8ms/batch - loss: 100.71308 - diff: 26.35mlTrain batch 31/31 - 87.2ms/batch - loss: 101.75407 - diff: 26.43mlTrain batch 31/31 - 10.1s 87.2ms/batch - loss: 101.75407 - diff: 26.43ml
Test 1.1s: val_loss: 73.57509 - diff: 25.52ml

Epoch 22: current best loss = 71.27211, at epoch 20
Train batch 1/31 - 174.0ms/batch - loss: 58.88586 - diff: 26.56mlTrain batch 2/31 - 174.1ms/batch - loss: 85.98898 - diff: 28.40mlTrain batch 3/31 - 173.8ms/batch - loss: 86.84510 - diff: 28.06mlTrain batch 4/31 - 173.9ms/batch - loss: 76.75125 - diff: 26.39mlTrain batch 5/31 - 173.6ms/batch - loss: 80.70042 - diff: 26.73mlTrain batch 6/31 - 174.0ms/batch - loss: 71.04059 - diff: 25.07mlTrain batch 7/31 - 173.8ms/batch - loss: 72.72607 - diff: 25.51mlTrain batch 8/31 - 173.9ms/batch - loss: 67.29423 - diff: 24.73mlTrain batch 9/31 - 173.8ms/batch - loss: 63.12885 - diff: 24.03mlTrain batch 10/31 - 174.0ms/batch - loss: 63.64051 - diff: 24.18mlTrain batch 11/31 - 173.8ms/batch - loss: 122.55739 - diff: 26.49mlTrain batch 12/31 - 173.6ms/batch - loss: 122.01667 - diff: 26.56mlTrain batch 13/31 - 173.9ms/batch - loss: 117.75784 - diff: 26.56mlTrain batch 14/31 - 174.0ms/batch - loss: 120.61044 - diff: 26.84mlTrain batch 15/31 - 173.8ms/batch - loss: 119.06170 - diff: 27.21mlTrain batch 16/31 - 174.1ms/batch - loss: 118.79779 - diff: 27.23mlTrain batch 17/31 - 174.0ms/batch - loss: 115.94804 - diff: 26.76mlTrain batch 18/31 - 174.2ms/batch - loss: 116.73034 - diff: 26.98mlTrain batch 19/31 - 173.7ms/batch - loss: 114.18425 - diff: 27.09mlTrain batch 20/31 - 174.1ms/batch - loss: 110.29073 - diff: 26.72mlTrain batch 21/31 - 173.8ms/batch - loss: 109.17187 - diff: 26.71mlTrain batch 22/31 - 174.0ms/batch - loss: 106.19081 - diff: 26.52mlTrain batch 23/31 - 173.6ms/batch - loss: 104.56791 - diff: 26.67mlTrain batch 24/31 - 173.4ms/batch - loss: 102.72081 - diff: 26.68mlTrain batch 25/31 - 173.9ms/batch - loss: 100.09396 - diff: 26.48mlTrain batch 26/31 - 173.9ms/batch - loss: 99.63307 - diff: 26.51mlTrain batch 27/31 - 173.9ms/batch - loss: 97.65226 - diff: 26.36mlTrain batch 28/31 - 174.3ms/batch - loss: 102.70803 - diff: 26.74mlTrain batch 29/31 - 173.9ms/batch - loss: 101.05358 - diff: 26.67mlTrain batch 30/31 - 174.3ms/batch - loss: 100.06679 - diff: 26.71mlTrain batch 31/31 - 87.3ms/batch - loss: 103.85356 - diff: 26.78mlTrain batch 31/31 - 10.0s 87.3ms/batch - loss: 103.85356 - diff: 26.78ml
Test 1.1s: val_loss: 69.71542 - diff: 24.63ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Systole_WideResNet50_0_Adam-0.001_MSE_DA3_best

Epoch 23: current best loss = 69.71542, at epoch 22
Train batch 1/31 - 173.9ms/batch - loss: 68.79572 - diff: 23.33mlTrain batch 2/31 - 173.9ms/batch - loss: 114.77014 - diff: 28.63mlTrain batch 3/31 - 173.9ms/batch - loss: 117.36493 - diff: 29.51mlTrain batch 4/31 - 174.2ms/batch - loss: 115.87907 - diff: 30.23mlTrain batch 5/31 - 173.8ms/batch - loss: 100.20230 - diff: 28.34mlTrain batch 6/31 - 173.9ms/batch - loss: 94.04088 - diff: 27.47mlTrain batch 7/31 - 173.8ms/batch - loss: 89.92483 - diff: 27.12mlTrain batch 8/31 - 174.1ms/batch - loss: 86.99216 - diff: 26.43mlTrain batch 9/31 - 173.7ms/batch - loss: 83.44252 - diff: 26.01mlTrain batch 10/31 - 174.0ms/batch - loss: 81.25284 - diff: 26.03mlTrain batch 11/31 - 173.7ms/batch - loss: 76.86695 - diff: 25.45mlTrain batch 12/31 - 174.1ms/batch - loss: 73.49968 - diff: 24.99mlTrain batch 13/31 - 173.8ms/batch - loss: 81.13405 - diff: 25.55mlTrain batch 14/31 - 173.3ms/batch - loss: 77.84460 - diff: 25.20mlTrain batch 15/31 - 173.7ms/batch - loss: 82.04385 - diff: 26.11mlTrain batch 16/31 - 174.1ms/batch - loss: 89.57028 - diff: 26.05mlTrain batch 17/31 - 173.6ms/batch - loss: 88.43442 - diff: 25.77mlTrain batch 18/31 - 174.0ms/batch - loss: 88.83062 - diff: 26.00mlTrain batch 19/31 - 173.8ms/batch - loss: 86.39932 - diff: 25.80mlTrain batch 20/31 - 174.0ms/batch - loss: 84.44787 - diff: 25.63mlTrain batch 21/31 - 173.9ms/batch - loss: 83.46038 - diff: 25.68mlTrain batch 22/31 - 174.1ms/batch - loss: 83.98877 - diff: 25.79mlTrain batch 23/31 - 173.9ms/batch - loss: 82.34342 - diff: 25.58mlTrain batch 24/31 - 174.1ms/batch - loss: 82.46125 - diff: 25.78mlTrain batch 25/31 - 174.0ms/batch - loss: 80.85714 - diff: 25.59mlTrain batch 26/31 - 174.2ms/batch - loss: 79.63341 - diff: 25.29mlTrain batch 27/31 - 173.9ms/batch - loss: 78.91451 - diff: 25.30mlTrain batch 28/31 - 174.0ms/batch - loss: 101.01214 - diff: 26.35mlTrain batch 29/31 - 173.9ms/batch - loss: 100.48415 - diff: 26.41mlTrain batch 30/31 - 174.0ms/batch - loss: 100.71395 - diff: 26.58mlTrain batch 31/31 - 87.4ms/batch - loss: 100.74260 - diff: 26.52mlTrain batch 31/31 - 10.0s 87.4ms/batch - loss: 100.74260 - diff: 26.52ml
Test 1.1s: val_loss: 69.13462 - diff: 23.44ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Systole_WideResNet50_0_Adam-0.001_MSE_DA3_best

Epoch 24: current best loss = 69.13462, at epoch 23
Train batch 1/31 - 174.0ms/batch - loss: 93.37190 - diff: 24.76mlTrain batch 2/31 - 174.0ms/batch - loss: 79.01729 - diff: 24.83mlTrain batch 3/31 - 173.9ms/batch - loss: 66.60946 - diff: 23.07mlTrain batch 4/31 - 173.9ms/batch - loss: 59.06752 - diff: 21.92mlTrain batch 5/31 - 173.7ms/batch - loss: 55.11431 - diff: 21.94mlTrain batch 6/31 - 174.0ms/batch - loss: 66.05391 - diff: 23.59mlTrain batch 7/31 - 174.0ms/batch - loss: 74.64627 - diff: 24.32mlTrain batch 8/31 - 174.2ms/batch - loss: 71.20117 - diff: 23.71mlTrain batch 9/31 - 173.9ms/batch - loss: 73.54493 - diff: 24.08mlTrain batch 10/31 - 174.2ms/batch - loss: 74.61144 - diff: 24.80mlTrain batch 11/31 - 174.0ms/batch - loss: 84.48235 - diff: 25.51mlTrain batch 12/31 - 173.9ms/batch - loss: 91.76078 - diff: 26.20mlTrain batch 13/31 - 173.9ms/batch - loss: 87.20906 - diff: 25.64mlTrain batch 14/31 - 174.0ms/batch - loss: 97.66385 - diff: 26.05mlTrain batch 15/31 - 174.0ms/batch - loss: 94.71301 - diff: 25.96mlTrain batch 16/31 - 173.9ms/batch - loss: 90.45791 - diff: 25.45mlTrain batch 17/31 - 173.7ms/batch - loss: 86.72081 - diff: 24.95mlTrain batch 18/31 - 174.0ms/batch - loss: 86.67543 - diff: 25.13mlTrain batch 19/31 - 173.7ms/batch - loss: 88.23260 - diff: 25.69mlTrain batch 20/31 - 174.0ms/batch - loss: 118.60006 - diff: 26.88mlTrain batch 21/31 - 173.9ms/batch - loss: 119.35692 - diff: 27.09mlTrain batch 22/31 - 173.9ms/batch - loss: 116.79892 - diff: 27.10mlTrain batch 23/31 - 174.0ms/batch - loss: 113.89320 - diff: 27.00mlTrain batch 24/31 - 173.8ms/batch - loss: 111.69275 - diff: 26.91mlTrain batch 25/31 - 173.9ms/batch - loss: 111.20843 - diff: 27.17mlTrain batch 26/31 - 174.0ms/batch - loss: 108.62295 - diff: 27.00mlTrain batch 27/31 - 174.0ms/batch - loss: 107.17441 - diff: 27.10mlTrain batch 28/31 - 173.8ms/batch - loss: 104.22419 - diff: 26.72mlTrain batch 29/31 - 173.8ms/batch - loss: 103.57450 - diff: 26.77mlTrain batch 30/31 - 174.0ms/batch - loss: 101.46370 - diff: 26.51mlTrain batch 31/31 - 87.1ms/batch - loss: 102.90357 - diff: 26.65mlTrain batch 31/31 - 10.0s 87.1ms/batch - loss: 102.90357 - diff: 26.65ml
Test 1.1s: val_loss: 68.90136 - diff: 25.38ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Systole_WideResNet50_0_Adam-0.001_MSE_DA3_best

Epoch 25: current best loss = 68.90136, at epoch 24
Train batch 1/31 - 173.9ms/batch - loss: 320.29562 - diff: 43.74mlTrain batch 2/31 - 174.2ms/batch - loss: 177.06968 - diff: 31.21mlTrain batch 3/31 - 173.7ms/batch - loss: 141.97197 - diff: 28.97mlTrain batch 4/31 - 174.1ms/batch - loss: 122.36945 - diff: 28.95mlTrain batch 5/31 - 173.8ms/batch - loss: 122.30841 - diff: 29.39mlTrain batch 6/31 - 173.9ms/batch - loss: 108.93051 - diff: 28.13mlTrain batch 7/31 - 173.6ms/batch - loss: 190.34700 - diff: 30.98mlTrain batch 8/31 - 174.1ms/batch - loss: 176.57126 - diff: 30.81mlTrain batch 9/31 - 174.0ms/batch - loss: 162.73880 - diff: 29.83mlTrain batch 10/31 - 174.2ms/batch - loss: 153.09041 - diff: 29.30mlTrain batch 11/31 - 173.9ms/batch - loss: 145.13828 - diff: 28.78mlTrain batch 12/31 - 174.1ms/batch - loss: 134.95407 - diff: 27.80mlTrain batch 13/31 - 173.8ms/batch - loss: 130.46305 - diff: 27.50mlTrain batch 14/31 - 173.7ms/batch - loss: 132.89029 - diff: 27.99mlTrain batch 15/31 - 173.8ms/batch - loss: 133.17363 - diff: 27.78mlTrain batch 16/31 - 174.2ms/batch - loss: 131.17624 - diff: 27.84mlTrain batch 17/31 - 173.8ms/batch - loss: 125.84100 - diff: 27.46mlTrain batch 18/31 - 173.9ms/batch - loss: 119.65977 - diff: 26.64mlTrain batch 19/31 - 173.6ms/batch - loss: 114.08603 - diff: 25.84mlTrain batch 20/31 - 174.0ms/batch - loss: 111.16650 - diff: 25.75mlTrain batch 21/31 - 173.8ms/batch - loss: 111.73248 - diff: 26.09mlTrain batch 22/31 - 173.9ms/batch - loss: 109.10153 - diff: 25.91mlTrain batch 23/31 - 173.9ms/batch - loss: 109.39367 - diff: 26.32mlTrain batch 24/31 - 173.9ms/batch - loss: 107.34251 - diff: 26.33mlTrain batch 25/31 - 174.0ms/batch - loss: 104.77152 - diff: 26.17mlTrain batch 26/31 - 174.1ms/batch - loss: 103.18788 - diff: 26.16mlTrain batch 27/31 - 173.8ms/batch - loss: 101.14442 - diff: 25.93mlTrain batch 28/31 - 173.9ms/batch - loss: 101.78774 - diff: 26.06mlTrain batch 29/31 - 173.8ms/batch - loss: 99.42104 - diff: 25.87mlTrain batch 30/31 - 174.1ms/batch - loss: 98.93642 - diff: 26.02mlTrain batch 31/31 - 87.2ms/batch - loss: 98.89179 - diff: 25.92mlTrain batch 31/31 - 10.0s 87.2ms/batch - loss: 98.89179 - diff: 25.92ml
Test 1.1s: val_loss: 77.73381 - diff: 24.96ml

Epoch 26: current best loss = 68.90136, at epoch 24
Train batch 1/31 - 173.7ms/batch - loss: 80.65713 - diff: 27.19mlTrain batch 2/31 - 174.0ms/batch - loss: 53.59639 - diff: 22.55mlTrain batch 3/31 - 173.8ms/batch - loss: 43.94528 - diff: 20.85mlTrain batch 4/31 - 174.2ms/batch - loss: 48.88359 - diff: 22.60mlTrain batch 5/31 - 173.9ms/batch - loss: 57.59347 - diff: 23.81mlTrain batch 6/31 - 174.0ms/batch - loss: 67.57561 - diff: 24.51mlTrain batch 7/31 - 174.0ms/batch - loss: 69.92558 - diff: 24.90mlTrain batch 8/31 - 174.0ms/batch - loss: 85.29656 - diff: 26.43mlTrain batch 9/31 - 173.8ms/batch - loss: 90.04374 - diff: 27.27mlTrain batch 10/31 - 174.0ms/batch - loss: 95.33129 - diff: 27.93mlTrain batch 11/31 - 173.9ms/batch - loss: 90.27410 - diff: 27.44mlTrain batch 12/31 - 174.0ms/batch - loss: 86.08465 - diff: 26.90mlTrain batch 13/31 - 173.7ms/batch - loss: 82.02953 - diff: 26.27mlTrain batch 14/31 - 173.7ms/batch - loss: 84.91532 - diff: 26.69mlTrain batch 15/31 - 173.9ms/batch - loss: 81.12594 - diff: 26.01mlTrain batch 16/31 - 173.9ms/batch - loss: 78.78858 - diff: 25.86mlTrain batch 17/31 - 173.7ms/batch - loss: 78.60906 - diff: 25.97mlTrain batch 18/31 - 174.2ms/batch - loss: 80.12286 - diff: 26.09mlTrain batch 19/31 - 173.9ms/batch - loss: 80.12450 - diff: 26.09mlTrain batch 20/31 - 174.1ms/batch - loss: 87.62646 - diff: 26.65mlTrain batch 21/31 - 173.6ms/batch - loss: 86.25940 - diff: 26.47mlTrain batch 22/31 - 174.0ms/batch - loss: 84.04679 - diff: 26.21mlTrain batch 23/31 - 174.0ms/batch - loss: 82.85907 - diff: 26.24mlTrain batch 24/31 - 173.9ms/batch - loss: 86.59550 - diff: 26.64mlTrain batch 25/31 - 174.0ms/batch - loss: 85.43311 - diff: 26.55mlTrain batch 26/31 - 173.8ms/batch - loss: 83.92675 - diff: 26.38mlTrain batch 27/31 - 173.9ms/batch - loss: 82.48803 - diff: 26.31mlTrain batch 28/31 - 174.2ms/batch - loss: 81.20456 - diff: 26.17mlTrain batch 29/31 - 173.9ms/batch - loss: 81.41422 - diff: 26.18mlTrain batch 30/31 - 174.2ms/batch - loss: 100.10948 - diff: 26.83mlTrain batch 31/31 - 87.2ms/batch - loss: 99.72805 - diff: 26.71mlTrain batch 31/31 - 10.1s 87.2ms/batch - loss: 99.72805 - diff: 26.71ml
Test 1.1s: val_loss: 69.23631 - diff: 23.51ml

Epoch 27: current best loss = 68.90136, at epoch 24
Train batch 1/31 - 174.0ms/batch - loss: 31.28590 - diff: 18.57mlTrain batch 2/31 - 174.1ms/batch - loss: 61.17471 - diff: 25.12mlTrain batch 3/31 - 173.7ms/batch - loss: 73.84866 - diff: 26.56mlTrain batch 4/31 - 174.2ms/batch - loss: 66.02045 - diff: 25.86mlTrain batch 5/31 - 174.0ms/batch - loss: 77.41084 - diff: 26.91mlTrain batch 6/31 - 174.2ms/batch - loss: 91.41440 - diff: 26.89mlTrain batch 7/31 - 173.9ms/batch - loss: 83.39599 - diff: 26.02mlTrain batch 8/31 - 173.4ms/batch - loss: 76.10538 - diff: 24.70mlTrain batch 9/31 - 173.9ms/batch - loss: 70.70097 - diff: 23.81mlTrain batch 10/31 - 173.9ms/batch - loss: 67.25455 - diff: 23.44mlTrain batch 11/31 - 173.9ms/batch - loss: 73.80194 - diff: 23.66mlTrain batch 12/31 - 174.1ms/batch - loss: 71.87196 - diff: 23.44mlTrain batch 13/31 - 173.8ms/batch - loss: 67.76766 - diff: 22.78mlTrain batch 14/31 - 174.0ms/batch - loss: 67.58285 - diff: 22.78mlTrain batch 15/31 - 173.7ms/batch - loss: 67.56952 - diff: 23.09mlTrain batch 16/31 - 174.0ms/batch - loss: 71.11801 - diff: 23.41mlTrain batch 17/31 - 174.0ms/batch - loss: 69.53798 - diff: 23.38mlTrain batch 18/31 - 174.1ms/batch - loss: 67.11984 - diff: 23.00mlTrain batch 19/31 - 173.8ms/batch - loss: 65.43797 - diff: 22.82mlTrain batch 20/31 - 174.1ms/batch - loss: 65.57721 - diff: 22.89mlTrain batch 21/31 - 174.0ms/batch - loss: 68.25241 - diff: 23.49mlTrain batch 22/31 - 174.0ms/batch - loss: 67.78298 - diff: 23.57mlTrain batch 23/31 - 173.8ms/batch - loss: 66.33634 - diff: 23.47mlTrain batch 24/31 - 174.2ms/batch - loss: 66.75822 - diff: 23.53mlTrain batch 25/31 - 174.0ms/batch - loss: 94.32886 - diff: 24.64mlTrain batch 26/31 - 174.2ms/batch - loss: 94.22556 - diff: 24.73mlTrain batch 27/31 - 173.7ms/batch - loss: 95.37329 - diff: 24.96mlTrain batch 28/31 - 174.1ms/batch - loss: 101.40319 - diff: 25.41mlTrain batch 29/31 - 173.8ms/batch - loss: 100.38054 - diff: 25.50mlTrain batch 30/31 - 174.0ms/batch - loss: 97.92125 - diff: 25.25mlTrain batch 31/31 - 87.2ms/batch - loss: 98.26512 - diff: 25.25mlTrain batch 31/31 - 10.8s 87.2ms/batch - loss: 98.26512 - diff: 25.25ml
Test 1.1s: val_loss: 66.18058 - diff: 23.79ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Systole_WideResNet50_0_Adam-0.001_MSE_DA3_best

Epoch 28: current best loss = 66.18058, at epoch 27
Train batch 1/31 - 173.8ms/batch - loss: 46.94281 - diff: 22.00mlTrain batch 2/31 - 173.9ms/batch - loss: 68.91374 - diff: 24.61mlTrain batch 3/31 - 173.8ms/batch - loss: 68.27270 - diff: 24.70mlTrain batch 4/31 - 174.0ms/batch - loss: 63.85084 - diff: 24.47mlTrain batch 5/31 - 173.7ms/batch - loss: 61.22587 - diff: 24.50mlTrain batch 6/31 - 174.0ms/batch - loss: 70.09322 - diff: 25.83mlTrain batch 7/31 - 174.0ms/batch - loss: 70.84584 - diff: 26.34mlTrain batch 8/31 - 174.0ms/batch - loss: 90.62196 - diff: 27.91mlTrain batch 9/31 - 173.8ms/batch - loss: 86.92180 - diff: 27.55mlTrain batch 10/31 - 173.9ms/batch - loss: 90.44501 - diff: 27.68mlTrain batch 11/31 - 173.8ms/batch - loss: 85.65146 - diff: 27.08mlTrain batch 12/31 - 173.8ms/batch - loss: 87.45272 - diff: 27.18mlTrain batch 13/31 - 173.9ms/batch - loss: 89.35480 - diff: 27.50mlTrain batch 14/31 - 174.1ms/batch - loss: 85.34011 - diff: 26.94mlTrain batch 15/31 - 173.9ms/batch - loss: 82.49137 - diff: 26.55mlTrain batch 16/31 - 174.1ms/batch - loss: 81.82077 - diff: 26.88mlTrain batch 17/31 - 173.9ms/batch - loss: 78.33753 - diff: 26.19mlTrain batch 18/31 - 173.9ms/batch - loss: 80.75568 - diff: 26.76mlTrain batch 19/31 - 173.9ms/batch - loss: 81.26420 - diff: 26.81mlTrain batch 20/31 - 173.8ms/batch - loss: 85.75787 - diff: 27.32mlTrain batch 21/31 - 173.9ms/batch - loss: 115.29864 - diff: 28.40mlTrain batch 22/31 - 174.1ms/batch - loss: 111.40159 - diff: 27.97mlTrain batch 23/31 - 173.9ms/batch - loss: 108.04967 - diff: 27.54mlTrain batch 24/31 - 174.2ms/batch - loss: 106.37276 - diff: 27.54mlTrain batch 25/31 - 174.0ms/batch - loss: 105.57022 - diff: 27.49mlTrain batch 26/31 - 174.8ms/batch - loss: 103.37935 - diff: 27.23mlTrain batch 27/31 - 174.0ms/batch - loss: 101.71332 - diff: 27.08mlTrain batch 28/31 - 174.1ms/batch - loss: 99.69755 - diff: 26.84mlTrain batch 29/31 - 173.8ms/batch - loss: 100.69953 - diff: 27.05mlTrain batch 30/31 - 174.1ms/batch - loss: 98.58488 - diff: 26.85mlTrain batch 31/31 - 87.3ms/batch - loss: 98.93998 - diff: 26.81mlTrain batch 31/31 - 10.4s 87.3ms/batch - loss: 98.93998 - diff: 26.81ml
Test 1.1s: val_loss: 68.81376 - diff: 24.90ml

Epoch 29: current best loss = 66.18058, at epoch 27
Train batch 1/31 - 173.9ms/batch - loss: 98.03291 - diff: 27.96mlTrain batch 2/31 - 174.1ms/batch - loss: 91.64038 - diff: 26.95mlTrain batch 3/31 - 173.9ms/batch - loss: 77.99880 - diff: 25.71mlTrain batch 4/31 - 174.0ms/batch - loss: 80.48640 - diff: 26.45mlTrain batch 5/31 - 174.0ms/batch - loss: 72.39988 - diff: 25.37mlTrain batch 6/31 - 174.2ms/batch - loss: 65.51321 - diff: 24.31mlTrain batch 7/31 - 174.0ms/batch - loss: 69.48431 - diff: 24.05mlTrain batch 8/31 - 174.0ms/batch - loss: 68.46043 - diff: 23.79mlTrain batch 9/31 - 174.0ms/batch - loss: 71.46768 - diff: 24.56mlTrain batch 10/31 - 173.5ms/batch - loss: 133.60216 - diff: 26.86mlTrain batch 11/31 - 174.0ms/batch - loss: 127.05815 - diff: 26.48mlTrain batch 12/31 - 174.4ms/batch - loss: 120.24340 - diff: 26.10mlTrain batch 13/31 - 174.0ms/batch - loss: 115.39958 - diff: 25.95mlTrain batch 14/31 - 174.4ms/batch - loss: 113.11958 - diff: 26.04mlTrain batch 15/31 - 173.9ms/batch - loss: 109.20097 - diff: 25.94mlTrain batch 16/31 - 173.8ms/batch - loss: 111.60105 - diff: 26.46mlTrain batch 17/31 - 173.9ms/batch - loss: 114.47578 - diff: 26.83mlTrain batch 18/31 - 174.2ms/batch - loss: 112.50580 - diff: 26.96mlTrain batch 19/31 - 173.7ms/batch - loss: 108.73809 - diff: 26.66mlTrain batch 20/31 - 174.2ms/batch - loss: 105.02063 - diff: 26.34mlTrain batch 21/31 - 173.8ms/batch - loss: 102.07900 - diff: 26.18mlTrain batch 22/31 - 173.9ms/batch - loss: 100.50897 - diff: 26.08mlTrain batch 23/31 - 173.8ms/batch - loss: 98.27610 - diff: 25.82mlTrain batch 24/31 - 174.1ms/batch - loss: 95.41632 - diff: 25.57mlTrain batch 25/31 - 173.9ms/batch - loss: 93.94640 - diff: 25.48mlTrain batch 26/31 - 174.2ms/batch - loss: 92.44741 - diff: 25.38mlTrain batch 27/31 - 173.9ms/batch - loss: 91.87385 - diff: 25.37mlTrain batch 28/31 - 174.1ms/batch - loss: 89.47351 - diff: 25.08mlTrain batch 29/31 - 173.7ms/batch - loss: 95.35275 - diff: 25.63mlTrain batch 30/31 - 174.1ms/batch - loss: 97.34255 - diff: 25.86mlTrain batch 31/31 - 87.2ms/batch - loss: 96.74284 - diff: 25.75mlTrain batch 31/31 - 11.6s 87.2ms/batch - loss: 96.74284 - diff: 25.75ml
Test 1.1s: val_loss: 66.67409 - diff: 22.97ml

Epoch 30: current best loss = 66.18058, at epoch 27
Train batch 1/31 - 173.9ms/batch - loss: 62.37183 - diff: 25.03mlTrain batch 2/31 - 173.7ms/batch - loss: 77.28230 - diff: 27.22mlTrain batch 3/31 - 174.0ms/batch - loss: 70.98490 - diff: 25.89mlTrain batch 4/31 - 174.1ms/batch - loss: 65.09709 - diff: 25.39mlTrain batch 5/31 - 173.9ms/batch - loss: 56.71858 - diff: 23.62mlTrain batch 6/31 - 174.0ms/batch - loss: 50.54099 - diff: 22.18mlTrain batch 7/31 - 173.8ms/batch - loss: 51.26916 - diff: 22.19mlTrain batch 8/31 - 174.0ms/batch - loss: 51.67753 - diff: 22.51mlTrain batch 9/31 - 173.8ms/batch - loss: 59.88370 - diff: 23.29mlTrain batch 10/31 - 173.7ms/batch - loss: 58.54005 - diff: 23.28mlTrain batch 11/31 - 174.2ms/batch - loss: 54.39510 - diff: 22.14mlTrain batch 12/31 - 174.0ms/batch - loss: 57.24776 - diff: 22.47mlTrain batch 13/31 - 173.4ms/batch - loss: 56.69033 - diff: 22.48mlTrain batch 14/31 - 173.8ms/batch - loss: 55.76507 - diff: 22.17mlTrain batch 15/31 - 174.0ms/batch - loss: 56.54085 - diff: 22.40mlTrain batch 16/31 - 174.0ms/batch - loss: 59.17518 - diff: 22.60mlTrain batch 17/31 - 174.0ms/batch - loss: 64.69318 - diff: 23.09mlTrain batch 18/31 - 173.8ms/batch - loss: 67.20700 - diff: 23.47mlTrain batch 19/31 - 174.1ms/batch - loss: 65.36896 - diff: 23.14mlTrain batch 20/31 - 173.8ms/batch - loss: 63.44280 - diff: 22.78mlTrain batch 21/31 - 174.0ms/batch - loss: 61.85653 - diff: 22.41mlTrain batch 22/31 - 173.9ms/batch - loss: 61.73108 - diff: 22.48mlTrain batch 23/31 - 173.9ms/batch - loss: 60.75277 - diff: 22.45mlTrain batch 24/31 - 173.9ms/batch - loss: 67.87189 - diff: 23.00mlTrain batch 25/31 - 174.1ms/batch - loss: 66.32903 - diff: 22.81mlTrain batch 26/31 - 173.9ms/batch - loss: 71.18532 - diff: 23.20mlTrain batch 27/31 - 174.2ms/batch - loss: 71.28579 - diff: 23.50mlTrain batch 28/31 - 173.9ms/batch - loss: 74.69164 - diff: 24.03mlTrain batch 29/31 - 174.0ms/batch - loss: 93.85865 - diff: 24.69mlTrain batch 30/31 - 173.8ms/batch - loss: 94.70568 - diff: 24.85mlTrain batch 31/31 - 87.2ms/batch - loss: 94.85736 - diff: 24.82mlTrain batch 31/31 - 11.0s 87.2ms/batch - loss: 94.85736 - diff: 24.82ml
Test 1.1s: val_loss: 76.04082 - diff: 23.93ml

Epoch 31: current best loss = 66.18058, at epoch 27
Train batch 1/31 - 174.0ms/batch - loss: 55.57522 - diff: 22.85mlTrain batch 2/31 - 174.2ms/batch - loss: 113.28386 - diff: 30.06mlTrain batch 3/31 - 174.0ms/batch - loss: 107.57215 - diff: 30.40mlTrain batch 4/31 - 174.2ms/batch - loss: 87.71804 - diff: 27.33mlTrain batch 5/31 - 174.0ms/batch - loss: 97.21818 - diff: 28.75mlTrain batch 6/31 - 173.9ms/batch - loss: 85.96991 - diff: 26.75mlTrain batch 7/31 - 174.0ms/batch - loss: 84.42755 - diff: 27.11mlTrain batch 8/31 - 174.1ms/batch - loss: 88.98657 - diff: 27.48mlTrain batch 9/31 - 173.9ms/batch - loss: 82.96747 - diff: 26.79mlTrain batch 10/31 - 173.4ms/batch - loss: 77.77399 - diff: 25.95mlTrain batch 11/31 - 173.9ms/batch - loss: 76.57414 - diff: 26.00mlTrain batch 12/31 - 174.1ms/batch - loss: 75.55665 - diff: 25.80mlTrain batch 13/31 - 174.0ms/batch - loss: 72.46769 - diff: 25.17mlTrain batch 14/31 - 174.1ms/batch - loss: 108.09990 - diff: 26.21mlTrain batch 15/31 - 173.7ms/batch - loss: 102.48168 - diff: 25.56mlTrain batch 16/31 - 174.0ms/batch - loss: 99.22194 - diff: 25.37mlTrain batch 17/31 - 174.0ms/batch - loss: 100.15661 - diff: 25.82mlTrain batch 18/31 - 174.1ms/batch - loss: 100.83975 - diff: 26.36mlTrain batch 19/31 - 173.9ms/batch - loss: 100.52314 - diff: 26.49mlTrain batch 20/31 - 174.0ms/batch - loss: 99.23520 - diff: 26.57mlTrain batch 21/31 - 173.9ms/batch - loss: 98.44372 - diff: 26.62mlTrain batch 22/31 - 173.7ms/batch - loss: 96.26922 - diff: 26.51mlTrain batch 23/31 - 173.8ms/batch - loss: 101.99825 - diff: 26.77mlTrain batch 24/31 - 174.0ms/batch - loss: 102.36204 - diff: 26.75mlTrain batch 25/31 - 174.2ms/batch - loss: 101.57002 - diff: 26.85mlTrain batch 26/31 - 174.2ms/batch - loss: 98.20294 - diff: 26.27mlTrain batch 27/31 - 173.8ms/batch - loss: 95.81534 - diff: 26.03mlTrain batch 28/31 - 174.0ms/batch - loss: 94.05831 - diff: 25.93mlTrain batch 29/31 - 173.9ms/batch - loss: 91.87968 - diff: 25.70mlTrain batch 30/31 - 174.2ms/batch - loss: 93.77501 - diff: 25.98mlTrain batch 31/31 - 87.5ms/batch - loss: 94.29551 - diff: 25.90mlTrain batch 31/31 - 10.9s 87.5ms/batch - loss: 94.29551 - diff: 25.90ml
Test 1.1s: val_loss: 64.10700 - diff: 22.87ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Systole_WideResNet50_0_Adam-0.001_MSE_DA3_best

Epoch 32: current best loss = 64.10700, at epoch 31
Train batch 1/31 - 173.8ms/batch - loss: 52.99323 - diff: 18.26mlTrain batch 2/31 - 174.2ms/batch - loss: 36.57028 - diff: 16.61mlTrain batch 3/31 - 173.9ms/batch - loss: 60.11581 - diff: 19.79mlTrain batch 4/31 - 174.1ms/batch - loss: 54.60153 - diff: 19.84mlTrain batch 5/31 - 173.7ms/batch - loss: 66.19624 - diff: 22.97mlTrain batch 6/31 - 174.1ms/batch - loss: 59.66907 - diff: 21.83mlTrain batch 7/31 - 174.0ms/batch - loss: 58.04627 - diff: 21.94mlTrain batch 8/31 - 174.0ms/batch - loss: 58.55185 - diff: 21.95mlTrain batch 9/31 - 173.8ms/batch - loss: 75.74760 - diff: 23.14mlTrain batch 10/31 - 174.2ms/batch - loss: 131.44070 - diff: 25.67mlTrain batch 11/31 - 173.9ms/batch - loss: 124.13405 - diff: 25.54mlTrain batch 12/31 - 174.2ms/batch - loss: 122.37750 - diff: 26.07mlTrain batch 13/31 - 173.9ms/batch - loss: 119.59318 - diff: 26.15mlTrain batch 14/31 - 174.0ms/batch - loss: 114.14412 - diff: 25.85mlTrain batch 15/31 - 173.8ms/batch - loss: 116.94093 - diff: 26.17mlTrain batch 16/31 - 174.5ms/batch - loss: 111.15880 - diff: 25.49mlTrain batch 17/31 - 173.9ms/batch - loss: 107.58636 - diff: 25.22mlTrain batch 18/31 - 173.9ms/batch - loss: 105.05755 - diff: 25.12mlTrain batch 19/31 - 173.8ms/batch - loss: 103.91145 - diff: 25.23mlTrain batch 20/31 - 174.2ms/batch - loss: 106.81022 - diff: 25.73mlTrain batch 21/31 - 174.0ms/batch - loss: 103.05939 - diff: 25.33mlTrain batch 22/31 - 173.6ms/batch - loss: 100.65419 - diff: 25.24mlTrain batch 23/31 - 173.9ms/batch - loss: 97.91206 - diff: 25.05mlTrain batch 24/31 - 173.8ms/batch - loss: 97.06712 - diff: 25.18mlTrain batch 25/31 - 174.0ms/batch - loss: 94.89924 - diff: 25.09mlTrain batch 26/31 - 174.1ms/batch - loss: 98.11528 - diff: 25.47mlTrain batch 27/31 - 174.0ms/batch - loss: 96.70944 - diff: 25.53mlTrain batch 28/31 - 174.0ms/batch - loss: 94.27411 - diff: 25.30mlTrain batch 29/31 - 173.8ms/batch - loss: 92.36259 - diff: 25.11mlTrain batch 30/31 - 174.2ms/batch - loss: 92.94858 - diff: 25.24mlTrain batch 31/31 - 87.2ms/batch - loss: 93.12470 - diff: 25.24mlTrain batch 31/31 - 10.5s 87.2ms/batch - loss: 93.12470 - diff: 25.24ml
Test 1.1s: val_loss: 63.60913 - diff: 23.14ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Systole_WideResNet50_0_Adam-0.001_MSE_DA3_best

Epoch 33: current best loss = 63.60913, at epoch 32
Train batch 1/31 - 174.0ms/batch - loss: 74.12678 - diff: 27.96mlTrain batch 2/31 - 173.5ms/batch - loss: 70.07973 - diff: 26.92mlTrain batch 3/31 - 174.0ms/batch - loss: 63.38514 - diff: 24.95mlTrain batch 4/31 - 174.0ms/batch - loss: 56.96388 - diff: 24.10mlTrain batch 5/31 - 174.1ms/batch - loss: 68.09975 - diff: 24.84mlTrain batch 6/31 - 174.1ms/batch - loss: 72.38405 - diff: 25.47mlTrain batch 7/31 - 173.9ms/batch - loss: 71.27624 - diff: 25.23mlTrain batch 8/31 - 174.2ms/batch - loss: 89.53548 - diff: 26.83mlTrain batch 9/31 - 174.0ms/batch - loss: 83.95378 - diff: 26.06mlTrain batch 10/31 - 174.4ms/batch - loss: 86.52205 - diff: 25.98mlTrain batch 11/31 - 173.8ms/batch - loss: 81.74672 - diff: 25.37mlTrain batch 12/31 - 174.2ms/batch - loss: 77.81289 - diff: 24.71mlTrain batch 13/31 - 173.7ms/batch - loss: 78.92664 - diff: 24.99mlTrain batch 14/31 - 173.9ms/batch - loss: 76.84781 - diff: 24.96mlTrain batch 15/31 - 173.8ms/batch - loss: 77.82392 - diff: 24.97mlTrain batch 16/31 - 174.1ms/batch - loss: 76.79932 - diff: 24.94mlTrain batch 17/31 - 174.0ms/batch - loss: 73.77508 - diff: 24.50mlTrain batch 18/31 - 173.9ms/batch - loss: 72.65693 - diff: 24.36mlTrain batch 19/31 - 174.1ms/batch - loss: 71.04589 - diff: 24.32mlTrain batch 20/31 - 174.0ms/batch - loss: 68.37862 - diff: 23.77mlTrain batch 21/31 - 173.8ms/batch - loss: 71.38565 - diff: 24.23mlTrain batch 22/31 - 174.0ms/batch - loss: 69.89044 - diff: 24.04mlTrain batch 23/31 - 174.1ms/batch - loss: 69.65967 - diff: 23.87mlTrain batch 24/31 - 190.5ms/batch - loss: 69.31255 - diff: 23.81mlTrain batch 25/31 - 173.4ms/batch - loss: 69.81528 - diff: 23.80mlTrain batch 26/31 - 173.8ms/batch - loss: 70.86538 - diff: 24.05mlTrain batch 27/31 - 174.3ms/batch - loss: 72.91221 - diff: 24.30mlTrain batch 28/31 - 174.0ms/batch - loss: 71.85932 - diff: 24.23mlTrain batch 29/31 - 173.9ms/batch - loss: 75.13524 - diff: 24.51mlTrain batch 30/31 - 173.9ms/batch - loss: 92.21402 - diff: 25.10mlTrain batch 31/31 - 87.2ms/batch - loss: 91.40377 - diff: 24.90mlTrain batch 31/31 - 11.4s 87.2ms/batch - loss: 91.40377 - diff: 24.90ml
Test 1.1s: val_loss: 61.34810 - diff: 23.26ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Systole_WideResNet50_0_Adam-0.001_MSE_DA3_best

Epoch 34: current best loss = 61.34810, at epoch 33
Train batch 1/31 - 188.2ms/batch - loss: 82.72244 - diff: 26.42mlTrain batch 2/31 - 174.5ms/batch - loss: 78.16525 - diff: 25.23mlTrain batch 3/31 - 173.7ms/batch - loss: 279.06797 - diff: 33.51mlTrain batch 4/31 - 174.1ms/batch - loss: 262.14590 - diff: 34.42mlTrain batch 5/31 - 174.0ms/batch - loss: 215.27804 - diff: 30.93mlTrain batch 6/31 - 174.0ms/batch - loss: 199.24978 - diff: 31.30mlTrain batch 7/31 - 174.0ms/batch - loss: 177.34604 - diff: 29.98mlTrain batch 8/31 - 173.9ms/batch - loss: 174.29552 - diff: 30.22mlTrain batch 9/31 - 173.9ms/batch - loss: 162.74768 - diff: 29.76mlTrain batch 10/31 - 174.2ms/batch - loss: 152.66794 - diff: 29.45mlTrain batch 11/31 - 174.0ms/batch - loss: 143.60799 - diff: 29.11mlTrain batch 12/31 - 174.3ms/batch - loss: 139.30709 - diff: 29.11mlTrain batch 13/31 - 173.9ms/batch - loss: 131.72961 - diff: 28.52mlTrain batch 14/31 - 174.1ms/batch - loss: 125.17785 - diff: 28.15mlTrain batch 15/31 - 173.6ms/batch - loss: 119.96892 - diff: 27.75mlTrain batch 16/31 - 173.4ms/batch - loss: 116.85170 - diff: 27.85mlTrain batch 17/31 - 173.7ms/batch - loss: 123.22211 - diff: 28.27mlTrain batch 18/31 - 174.1ms/batch - loss: 123.05514 - diff: 28.31mlTrain batch 19/31 - 173.9ms/batch - loss: 118.72586 - diff: 28.09mlTrain batch 20/31 - 174.2ms/batch - loss: 113.91299 - diff: 27.36mlTrain batch 21/31 - 173.9ms/batch - loss: 113.49066 - diff: 27.65mlTrain batch 22/31 - 174.4ms/batch - loss: 109.77581 - diff: 27.27mlTrain batch 23/31 - 173.8ms/batch - loss: 106.92654 - diff: 27.04mlTrain batch 24/31 - 174.3ms/batch - loss: 104.68742 - diff: 26.92mlTrain batch 25/31 - 173.8ms/batch - loss: 103.06122 - diff: 26.78mlTrain batch 26/31 - 174.0ms/batch - loss: 100.09639 - diff: 26.43mlTrain batch 27/31 - 173.9ms/batch - loss: 99.33431 - diff: 26.44mlTrain batch 28/31 - 174.5ms/batch - loss: 96.83361 - diff: 26.16mlTrain batch 29/31 - 174.1ms/batch - loss: 94.82270 - diff: 25.97mlTrain batch 30/31 - 174.4ms/batch - loss: 94.35970 - diff: 25.98mlTrain batch 31/31 - 87.3ms/batch - loss: 96.42286 - diff: 25.91mlTrain batch 31/31 - 10.8s 87.3ms/batch - loss: 96.42286 - diff: 25.91ml
Test 1.1s: val_loss: 89.20234 - diff: 21.50ml

Epoch 35: current best loss = 61.34810, at epoch 33
Train batch 1/31 - 174.0ms/batch - loss: 153.14476 - diff: 31.96mlTrain batch 2/31 - 174.2ms/batch - loss: 119.62518 - diff: 30.38mlTrain batch 3/31 - 174.1ms/batch - loss: 95.68144 - diff: 28.13mlTrain batch 4/31 - 174.1ms/batch - loss: 86.90550 - diff: 26.90mlTrain batch 5/31 - 173.9ms/batch - loss: 84.94301 - diff: 26.49mlTrain batch 6/31 - 174.2ms/batch - loss: 109.23668 - diff: 27.51mlTrain batch 7/31 - 174.0ms/batch - loss: 99.53007 - diff: 26.78mlTrain batch 8/31 - 174.2ms/batch - loss: 89.08205 - diff: 25.21mlTrain batch 9/31 - 174.2ms/batch - loss: 84.60752 - diff: 25.06mlTrain batch 10/31 - 174.1ms/batch - loss: 80.14713 - diff: 24.83mlTrain batch 11/31 - 174.0ms/batch - loss: 76.16263 - diff: 24.28mlTrain batch 12/31 - 174.1ms/batch - loss: 72.31159 - diff: 23.73mlTrain batch 13/31 - 173.9ms/batch - loss: 71.37036 - diff: 24.00mlTrain batch 14/31 - 174.0ms/batch - loss: 76.87949 - diff: 24.24mlTrain batch 15/31 - 174.0ms/batch - loss: 75.22417 - diff: 23.73mlTrain batch 16/31 - 174.2ms/batch - loss: 71.88225 - diff: 23.23mlTrain batch 17/31 - 174.0ms/batch - loss: 73.97142 - diff: 23.53mlTrain batch 18/31 - 173.9ms/batch - loss: 77.19091 - diff: 24.09mlTrain batch 19/31 - 174.1ms/batch - loss: 75.21503 - diff: 23.96mlTrain batch 20/31 - 173.8ms/batch - loss: 72.72455 - diff: 23.61mlTrain batch 21/31 - 174.2ms/batch - loss: 70.98897 - diff: 23.46mlTrain batch 22/31 - 174.0ms/batch - loss: 70.34839 - diff: 23.49mlTrain batch 23/31 - 174.3ms/batch - loss: 68.24438 - diff: 23.10mlTrain batch 24/31 - 173.9ms/batch - loss: 69.76724 - diff: 23.32mlTrain batch 25/31 - 174.0ms/batch - loss: 68.86972 - diff: 23.27mlTrain batch 26/31 - 174.0ms/batch - loss: 70.02155 - diff: 23.55mlTrain batch 27/31 - 174.0ms/batch - loss: 71.77104 - diff: 23.78mlTrain batch 28/31 - 174.1ms/batch - loss: 71.86835 - diff: 23.92mlTrain batch 29/31 - 174.0ms/batch - loss: 70.84123 - diff: 23.82mlTrain batch 30/31 - 174.0ms/batch - loss: 70.91554 - diff: 23.90mlTrain batch 31/31 - 87.2ms/batch - loss: 121.29202 - diff: 24.80mlTrain batch 31/31 - 11.2s 87.2ms/batch - loss: 121.29202 - diff: 24.80ml
Test 1.1s: val_loss: 63.64902 - diff: 24.31ml

Epoch 36: current best loss = 61.34810, at epoch 33
Train batch 1/31 - 174.1ms/batch - loss: 52.83108 - diff: 22.96mlTrain batch 2/31 - 174.1ms/batch - loss: 52.16775 - diff: 24.40mlTrain batch 3/31 - 174.1ms/batch - loss: 54.60202 - diff: 24.42mlTrain batch 4/31 - 174.0ms/batch - loss: 57.44756 - diff: 25.14mlTrain batch 5/31 - 173.9ms/batch - loss: 54.33507 - diff: 24.26mlTrain batch 6/31 - 173.4ms/batch - loss: 81.98961 - diff: 26.06mlTrain batch 7/31 - 174.0ms/batch - loss: 76.86232 - diff: 25.32mlTrain batch 8/31 - 173.4ms/batch - loss: 84.54985 - diff: 25.95mlTrain batch 9/31 - 173.5ms/batch - loss: 84.77451 - diff: 25.77mlTrain batch 10/31 - 173.6ms/batch - loss: 82.31696 - diff: 25.27mlTrain batch 11/31 - 174.0ms/batch - loss: 84.20908 - diff: 25.77mlTrain batch 12/31 - 174.5ms/batch - loss: 80.07998 - diff: 25.33mlTrain batch 13/31 - 173.7ms/batch - loss: 78.66393 - diff: 25.38mlTrain batch 14/31 - 174.2ms/batch - loss: 76.74556 - diff: 25.33mlTrain batch 15/31 - 173.8ms/batch - loss: 75.15167 - diff: 25.22mlTrain batch 16/31 - 173.9ms/batch - loss: 82.63064 - diff: 25.99mlTrain batch 17/31 - 173.6ms/batch - loss: 79.40019 - diff: 25.47mlTrain batch 18/31 - 174.1ms/batch - loss: 77.01469 - diff: 25.19mlTrain batch 19/31 - 173.9ms/batch - loss: 79.64264 - diff: 25.54mlTrain batch 20/31 - 174.1ms/batch - loss: 107.33873 - diff: 26.55mlTrain batch 21/31 - 174.2ms/batch - loss: 104.45927 - diff: 26.35mlTrain batch 22/31 - 174.2ms/batch - loss: 104.69953 - diff: 26.70mlTrain batch 23/31 - 173.9ms/batch - loss: 101.95990 - diff: 26.57mlTrain batch 24/31 - 174.3ms/batch - loss: 99.27744 - diff: 26.31mlTrain batch 25/31 - 173.6ms/batch - loss: 96.57733 - diff: 25.90mlTrain batch 26/31 - 174.1ms/batch - loss: 94.37542 - diff: 25.72mlTrain batch 27/31 - 173.7ms/batch - loss: 94.29578 - diff: 25.86mlTrain batch 28/31 - 174.3ms/batch - loss: 93.54454 - diff: 25.89mlTrain batch 29/31 - 173.8ms/batch - loss: 93.05764 - diff: 25.86mlTrain batch 30/31 - 174.0ms/batch - loss: 91.54272 - diff: 25.81mlTrain batch 31/31 - 87.3ms/batch - loss: 94.35268 - diff: 25.90mlTrain batch 31/31 - 11.3s 87.3ms/batch - loss: 94.35268 - diff: 25.90ml
Test 1.1s: val_loss: 62.72570 - diff: 23.46ml

Epoch 37: current best loss = 61.34810, at epoch 33
Train batch 1/31 - 173.8ms/batch - loss: 56.98077 - diff: 26.50mlTrain batch 2/31 - 173.5ms/batch - loss: 77.13251 - diff: 27.83mlTrain batch 3/31 - 173.5ms/batch - loss: 79.85606 - diff: 28.23mlTrain batch 4/31 - 174.1ms/batch - loss: 104.65960 - diff: 28.97mlTrain batch 5/31 - 173.9ms/batch - loss: 87.62528 - diff: 26.24mlTrain batch 6/31 - 173.8ms/batch - loss: 79.41832 - diff: 25.43mlTrain batch 7/31 - 174.0ms/batch - loss: 89.75799 - diff: 26.43mlTrain batch 8/31 - 174.1ms/batch - loss: 83.20765 - diff: 25.64mlTrain batch 9/31 - 173.9ms/batch - loss: 140.43667 - diff: 27.33mlTrain batch 10/31 - 173.3ms/batch - loss: 129.67341 - diff: 26.58mlTrain batch 11/31 - 173.4ms/batch - loss: 145.87114 - diff: 28.20mlTrain batch 12/31 - 174.1ms/batch - loss: 138.79371 - diff: 27.89mlTrain batch 13/31 - 173.7ms/batch - loss: 136.61498 - diff: 28.13mlTrain batch 14/31 - 174.2ms/batch - loss: 136.50658 - diff: 28.45mlTrain batch 15/31 - 174.0ms/batch - loss: 131.03031 - diff: 28.03mlTrain batch 16/31 - 174.8ms/batch - loss: 125.66848 - diff: 27.67mlTrain batch 17/31 - 174.5ms/batch - loss: 119.84969 - diff: 27.03mlTrain batch 18/31 - 174.7ms/batch - loss: 116.01654 - diff: 26.87mlTrain batch 19/31 - 173.9ms/batch - loss: 111.70181 - diff: 26.52mlTrain batch 20/31 - 173.9ms/batch - loss: 110.61518 - diff: 26.59mlTrain batch 21/31 - 173.9ms/batch - loss: 106.91543 - diff: 26.27mlTrain batch 22/31 - 173.5ms/batch - loss: 106.03078 - diff: 26.24mlTrain batch 23/31 - 174.5ms/batch - loss: 102.54301 - diff: 25.77mlTrain batch 24/31 - 174.4ms/batch - loss: 99.72550 - diff: 25.51mlTrain batch 25/31 - 173.8ms/batch - loss: 96.98341 - diff: 25.30mlTrain batch 26/31 - 174.0ms/batch - loss: 95.51225 - diff: 25.17mlTrain batch 27/31 - 173.8ms/batch - loss: 93.13990 - diff: 24.96mlTrain batch 28/31 - 174.0ms/batch - loss: 93.32152 - diff: 24.94mlTrain batch 29/31 - 173.9ms/batch - loss: 91.72724 - diff: 24.74mlTrain batch 30/31 - 174.4ms/batch - loss: 90.02837 - diff: 24.59mlTrain batch 31/31 - 87.5ms/batch - loss: 95.89205 - diff: 24.81mlTrain batch 31/31 - 10.9s 87.5ms/batch - loss: 95.89205 - diff: 24.81ml
Test 1.1s: val_loss: 59.01729 - diff: 22.03ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Systole_WideResNet50_0_Adam-0.001_MSE_DA3_best

Epoch 38: current best loss = 59.01729, at epoch 37
Train batch 1/31 - 173.9ms/batch - loss: 40.48040 - diff: 21.68mlTrain batch 2/31 - 174.2ms/batch - loss: 95.60232 - diff: 27.44mlTrain batch 3/31 - 174.0ms/batch - loss: 89.10842 - diff: 25.91mlTrain batch 4/31 - 174.2ms/batch - loss: 74.88829 - diff: 24.26mlTrain batch 5/31 - 174.2ms/batch - loss: 65.98247 - diff: 23.21mlTrain batch 6/31 - 174.0ms/batch - loss: 64.66629 - diff: 23.46mlTrain batch 7/31 - 174.0ms/batch - loss: 64.11445 - diff: 23.31mlTrain batch 8/31 - 174.1ms/batch - loss: 94.35331 - diff: 25.71mlTrain batch 9/31 - 173.8ms/batch - loss: 101.61098 - diff: 26.63mlTrain batch 10/31 - 173.5ms/batch - loss: 95.99704 - diff: 26.05mlTrain batch 11/31 - 173.7ms/batch - loss: 91.31322 - diff: 25.61mlTrain batch 12/31 - 174.3ms/batch - loss: 90.56273 - diff: 26.08mlTrain batch 13/31 - 173.8ms/batch - loss: 84.94813 - diff: 25.19mlTrain batch 14/31 - 174.2ms/batch - loss: 81.46697 - diff: 24.82mlTrain batch 15/31 - 174.2ms/batch - loss: 79.90353 - diff: 24.74mlTrain batch 16/31 - 174.5ms/batch - loss: 79.32385 - diff: 24.79mlTrain batch 17/31 - 174.3ms/batch - loss: 109.89695 - diff: 26.00mlTrain batch 18/31 - 174.6ms/batch - loss: 108.90219 - diff: 26.19mlTrain batch 19/31 - 173.9ms/batch - loss: 113.15485 - diff: 26.75mlTrain batch 20/31 - 174.0ms/batch - loss: 111.28227 - diff: 26.88mlTrain batch 21/31 - 173.9ms/batch - loss: 112.43103 - diff: 27.22mlTrain batch 22/31 - 174.1ms/batch - loss: 109.83425 - diff: 27.16mlTrain batch 23/31 - 173.9ms/batch - loss: 106.71643 - diff: 26.89mlTrain batch 24/31 - 174.1ms/batch - loss: 104.24500 - diff: 26.73mlTrain batch 25/31 - 173.9ms/batch - loss: 101.37827 - diff: 26.39mlTrain batch 26/31 - 174.3ms/batch - loss: 99.30854 - diff: 26.26mlTrain batch 27/31 - 174.0ms/batch - loss: 97.24230 - diff: 26.06mlTrain batch 28/31 - 174.0ms/batch - loss: 95.22921 - diff: 25.88mlTrain batch 29/31 - 174.0ms/batch - loss: 93.00003 - diff: 25.64mlTrain batch 30/31 - 174.1ms/batch - loss: 90.44789 - diff: 25.24mlTrain batch 31/31 - 87.2ms/batch - loss: 93.09454 - diff: 25.29mlTrain batch 31/31 - 11.6s 87.2ms/batch - loss: 93.09454 - diff: 25.29ml
Test 1.1s: val_loss: 63.18152 - diff: 23.24ml

Epoch 39: current best loss = 59.01729, at epoch 37
Train batch 1/31 - 174.0ms/batch - loss: 61.77307 - diff: 23.11mlTrain batch 2/31 - 173.6ms/batch - loss: 59.36703 - diff: 21.20mlTrain batch 3/31 - 174.1ms/batch - loss: 54.62096 - diff: 21.85mlTrain batch 4/31 - 174.0ms/batch - loss: 55.55504 - diff: 22.81mlTrain batch 5/31 - 173.7ms/batch - loss: 56.76850 - diff: 22.53mlTrain batch 6/31 - 174.4ms/batch - loss: 86.68578 - diff: 24.59mlTrain batch 7/31 - 174.3ms/batch - loss: 166.31631 - diff: 27.90mlTrain batch 8/31 - 174.5ms/batch - loss: 154.09546 - diff: 27.60mlTrain batch 9/31 - 173.8ms/batch - loss: 142.80179 - diff: 27.15mlTrain batch 10/31 - 174.0ms/batch - loss: 133.26809 - diff: 26.39mlTrain batch 11/31 - 173.9ms/batch - loss: 123.84849 - diff: 25.42mlTrain batch 12/31 - 174.1ms/batch - loss: 117.79036 - diff: 25.35mlTrain batch 13/31 - 174.3ms/batch - loss: 110.37061 - diff: 24.56mlTrain batch 14/31 - 174.2ms/batch - loss: 114.05133 - diff: 25.57mlTrain batch 15/31 - 174.5ms/batch - loss: 108.35066 - diff: 24.99mlTrain batch 16/31 - 174.5ms/batch - loss: 108.06660 - diff: 25.35mlTrain batch 17/31 - 174.3ms/batch - loss: 104.16846 - diff: 25.17mlTrain batch 18/31 - 174.3ms/batch - loss: 101.79010 - diff: 25.00mlTrain batch 19/31 - 174.2ms/batch - loss: 99.56564 - diff: 25.09mlTrain batch 20/31 - 174.3ms/batch - loss: 100.88430 - diff: 25.33mlTrain batch 21/31 - 173.9ms/batch - loss: 97.51031 - diff: 24.97mlTrain batch 22/31 - 173.8ms/batch - loss: 94.58614 - diff: 24.65mlTrain batch 23/31 - 173.8ms/batch - loss: 94.50725 - diff: 24.69mlTrain batch 24/31 - 174.1ms/batch - loss: 94.79929 - diff: 24.85mlTrain batch 25/31 - 173.9ms/batch - loss: 91.81649 - diff: 24.46mlTrain batch 26/31 - 173.6ms/batch - loss: 90.64407 - diff: 24.54mlTrain batch 27/31 - 174.0ms/batch - loss: 91.86984 - diff: 24.97mlTrain batch 28/31 - 174.0ms/batch - loss: 90.05811 - diff: 24.83mlTrain batch 29/31 - 174.1ms/batch - loss: 90.63000 - diff: 24.95mlTrain batch 30/31 - 173.8ms/batch - loss: 89.10758 - diff: 24.88mlTrain batch 31/31 - 86.7ms/batch - loss: 89.58997 - diff: 24.88mlTrain batch 31/31 - 11.2s 86.7ms/batch - loss: 89.58997 - diff: 24.88ml
Test 1.1s: val_loss: 60.67914 - diff: 22.02ml

Epoch 40: current best loss = 59.01729, at epoch 37
Train batch 1/31 - 174.0ms/batch - loss: 64.79869 - diff: 23.70mlTrain batch 2/31 - 173.7ms/batch - loss: 56.64416 - diff: 23.50mlTrain batch 3/31 - 173.9ms/batch - loss: 51.45351 - diff: 23.03mlTrain batch 4/31 - 173.7ms/batch - loss: 57.13654 - diff: 23.63mlTrain batch 5/31 - 174.0ms/batch - loss: 64.39361 - diff: 24.45mlTrain batch 6/31 - 174.2ms/batch - loss: 59.93672 - diff: 23.69mlTrain batch 7/31 - 174.0ms/batch - loss: 55.03347 - diff: 22.79mlTrain batch 8/31 - 174.2ms/batch - loss: 67.30930 - diff: 24.00mlTrain batch 9/31 - 173.7ms/batch - loss: 87.35419 - diff: 25.10mlTrain batch 10/31 - 174.1ms/batch - loss: 82.67939 - diff: 24.77mlTrain batch 11/31 - 174.0ms/batch - loss: 78.45728 - diff: 24.51mlTrain batch 12/31 - 174.1ms/batch - loss: 74.85427 - diff: 24.11mlTrain batch 13/31 - 174.0ms/batch - loss: 74.93897 - diff: 24.12mlTrain batch 14/31 - 174.5ms/batch - loss: 71.59170 - diff: 23.71mlTrain batch 15/31 - 174.2ms/batch - loss: 69.77456 - diff: 23.43mlTrain batch 16/31 - 173.7ms/batch - loss: 67.46576 - diff: 23.17mlTrain batch 17/31 - 173.8ms/batch - loss: 67.64449 - diff: 23.49mlTrain batch 18/31 - 174.2ms/batch - loss: 71.20317 - diff: 23.49mlTrain batch 19/31 - 174.0ms/batch - loss: 71.92778 - diff: 23.62mlTrain batch 20/31 - 174.0ms/batch - loss: 69.39710 - diff: 23.20mlTrain batch 21/31 - 173.9ms/batch - loss: 70.78938 - diff: 23.16mlTrain batch 22/31 - 174.0ms/batch - loss: 68.98683 - diff: 22.99mlTrain batch 23/31 - 174.0ms/batch - loss: 67.68787 - diff: 22.71mlTrain batch 24/31 - 173.6ms/batch - loss: 67.42113 - diff: 22.72mlTrain batch 25/31 - 173.9ms/batch - loss: 70.26890 - diff: 23.22mlTrain batch 26/31 - 174.2ms/batch - loss: 68.70265 - diff: 23.03mlTrain batch 27/31 - 174.1ms/batch - loss: 67.68244 - diff: 22.94mlTrain batch 28/31 - 174.3ms/batch - loss: 68.06438 - diff: 22.91mlTrain batch 29/31 - 173.8ms/batch - loss: 67.82656 - diff: 22.83mlTrain batch 30/31 - 174.4ms/batch - loss: 91.90529 - diff: 23.95mlTrain batch 31/31 - 87.3ms/batch - loss: 92.91956 - diff: 23.97mlTrain batch 31/31 - 11.7s 87.3ms/batch - loss: 92.91956 - diff: 23.97ml
Test 1.1s: val_loss: 79.29952 - diff: 26.97ml

Epoch 41: current best loss = 59.01729, at epoch 37
Train batch 1/31 - 174.0ms/batch - loss: 74.46637 - diff: 27.18mlTrain batch 2/31 - 173.7ms/batch - loss: 47.29117 - diff: 21.61mlTrain batch 3/31 - 174.0ms/batch - loss: 56.54633 - diff: 23.51mlTrain batch 4/31 - 174.4ms/batch - loss: 55.10534 - diff: 21.93mlTrain batch 5/31 - 173.8ms/batch - loss: 55.39504 - diff: 22.87mlTrain batch 6/31 - 174.2ms/batch - loss: 53.09211 - diff: 22.55mlTrain batch 7/31 - 173.9ms/batch - loss: 50.42669 - diff: 22.31mlTrain batch 8/31 - 174.4ms/batch - loss: 68.04490 - diff: 24.00mlTrain batch 9/31 - 174.0ms/batch - loss: 65.99919 - diff: 24.16mlTrain batch 10/31 - 173.6ms/batch - loss: 67.36441 - diff: 24.54mlTrain batch 11/31 - 173.6ms/batch - loss: 64.73934 - diff: 24.30mlTrain batch 12/31 - 174.3ms/batch - loss: 63.76036 - diff: 24.54mlTrain batch 13/31 - 174.1ms/batch - loss: 64.92375 - diff: 24.96mlTrain batch 14/31 - 174.3ms/batch - loss: 63.07504 - diff: 24.69mlTrain batch 15/31 - 173.9ms/batch - loss: 61.61393 - diff: 24.44mlTrain batch 16/31 - 174.4ms/batch - loss: 72.87248 - diff: 24.85mlTrain batch 17/31 - 173.9ms/batch - loss: 70.46226 - diff: 24.57mlTrain batch 18/31 - 174.5ms/batch - loss: 67.93990 - diff: 24.25mlTrain batch 19/31 - 174.0ms/batch - loss: 66.97507 - diff: 24.12mlTrain batch 20/31 - 174.5ms/batch - loss: 70.70694 - diff: 24.51mlTrain batch 21/31 - 174.0ms/batch - loss: 72.56156 - diff: 24.67mlTrain batch 22/31 - 174.0ms/batch - loss: 71.23568 - diff: 24.60mlTrain batch 23/31 - 173.9ms/batch - loss: 71.28255 - diff: 24.64mlTrain batch 24/31 - 174.2ms/batch - loss: 69.83443 - diff: 24.35mlTrain batch 25/31 - 174.0ms/batch - loss: 70.61501 - diff: 24.43mlTrain batch 26/31 - 174.7ms/batch - loss: 70.95680 - diff: 24.42mlTrain batch 27/31 - 173.7ms/batch - loss: 94.54319 - diff: 25.23mlTrain batch 28/31 - 174.0ms/batch - loss: 92.53697 - diff: 25.01mlTrain batch 29/31 - 173.8ms/batch - loss: 94.08857 - diff: 25.11mlTrain batch 30/31 - 174.1ms/batch - loss: 91.95940 - diff: 24.82mlTrain batch 31/31 - 87.2ms/batch - loss: 91.07550 - diff: 24.65mlTrain batch 31/31 - 10.4s 87.2ms/batch - loss: 91.07550 - diff: 24.65ml
Test 1.1s: val_loss: 71.23120 - diff: 20.48ml

Epoch 42: current best loss = 59.01729, at epoch 37
Train batch 1/31 - 173.8ms/batch - loss: 109.73092 - diff: 29.38mlTrain batch 2/31 - 174.1ms/batch - loss: 85.27244 - diff: 26.93mlTrain batch 3/31 - 173.8ms/batch - loss: 79.07256 - diff: 24.27mlTrain batch 4/31 - 173.9ms/batch - loss: 73.81730 - diff: 24.64mlTrain batch 5/31 - 174.3ms/batch - loss: 64.51325 - diff: 23.05mlTrain batch 6/31 - 174.1ms/batch - loss: 58.13269 - diff: 22.18mlTrain batch 7/31 - 174.3ms/batch - loss: 55.20269 - diff: 21.24mlTrain batch 8/31 - 173.9ms/batch - loss: 129.47365 - diff: 25.13mlTrain batch 9/31 - 174.3ms/batch - loss: 123.09441 - diff: 24.74mlTrain batch 10/31 - 174.0ms/batch - loss: 115.50989 - diff: 24.62mlTrain batch 11/31 - 173.8ms/batch - loss: 110.19024 - diff: 24.66mlTrain batch 12/31 - 174.3ms/batch - loss: 103.27127 - diff: 24.06mlTrain batch 13/31 - 174.3ms/batch - loss: 98.26549 - diff: 23.90mlTrain batch 14/31 - 174.3ms/batch - loss: 100.45605 - diff: 24.08mlTrain batch 15/31 - 174.2ms/batch - loss: 96.93703 - diff: 24.00mlTrain batch 16/31 - 174.0ms/batch - loss: 97.50485 - diff: 24.14mlTrain batch 17/31 - 173.8ms/batch - loss: 94.38338 - diff: 24.08mlTrain batch 18/31 - 174.2ms/batch - loss: 91.75821 - diff: 23.93mlTrain batch 19/31 - 174.1ms/batch - loss: 92.30512 - diff: 24.04mlTrain batch 20/31 - 173.8ms/batch - loss: 99.93133 - diff: 24.84mlTrain batch 21/31 - 173.7ms/batch - loss: 97.47066 - diff: 24.81mlTrain batch 22/31 - 174.2ms/batch - loss: 95.37860 - diff: 24.78mlTrain batch 23/31 - 173.8ms/batch - loss: 93.31758 - diff: 24.64mlTrain batch 24/31 - 174.2ms/batch - loss: 92.41505 - diff: 24.59mlTrain batch 25/31 - 174.1ms/batch - loss: 90.41425 - diff: 24.50mlTrain batch 26/31 - 174.3ms/batch - loss: 89.42421 - diff: 24.41mlTrain batch 27/31 - 173.9ms/batch - loss: 89.03038 - diff: 24.36mlTrain batch 28/31 - 174.2ms/batch - loss: 89.38374 - diff: 24.36mlTrain batch 29/31 - 174.0ms/batch - loss: 87.91560 - diff: 24.19mlTrain batch 30/31 - 173.9ms/batch - loss: 88.77758 - diff: 24.52mlTrain batch 31/31 - 87.3ms/batch - loss: 88.88928 - diff: 24.43mlTrain batch 31/31 - 10.5s 87.3ms/batch - loss: 88.88928 - diff: 24.43ml
Test 1.1s: val_loss: 59.69928 - diff: 20.58ml

Epoch 43: current best loss = 59.01729, at epoch 37
Train batch 1/31 - 174.2ms/batch - loss: 113.70734 - diff: 30.54mlTrain batch 2/31 - 173.8ms/batch - loss: 82.20971 - diff: 26.99mlTrain batch 3/31 - 174.0ms/batch - loss: 78.81142 - diff: 26.13mlTrain batch 4/31 - 174.1ms/batch - loss: 91.17103 - diff: 27.89mlTrain batch 5/31 - 174.0ms/batch - loss: 108.64466 - diff: 29.49mlTrain batch 6/31 - 174.1ms/batch - loss: 102.81698 - diff: 29.25mlTrain batch 7/31 - 173.9ms/batch - loss: 114.02768 - diff: 29.61mlTrain batch 8/31 - 174.1ms/batch - loss: 105.10336 - diff: 28.55mlTrain batch 9/31 - 173.9ms/batch - loss: 104.10007 - diff: 28.96mlTrain batch 10/31 - 174.6ms/batch - loss: 96.73243 - diff: 28.05mlTrain batch 11/31 - 173.7ms/batch - loss: 96.47977 - diff: 27.93mlTrain batch 12/31 - 174.2ms/batch - loss: 93.27880 - diff: 27.63mlTrain batch 13/31 - 174.0ms/batch - loss: 89.00782 - diff: 27.14mlTrain batch 14/31 - 174.1ms/batch - loss: 92.08588 - diff: 27.20mlTrain batch 15/31 - 173.8ms/batch - loss: 89.48237 - diff: 27.08mlTrain batch 16/31 - 174.2ms/batch - loss: 85.97425 - diff: 26.57mlTrain batch 17/31 - 174.0ms/batch - loss: 82.66037 - diff: 26.12mlTrain batch 18/31 - 174.4ms/batch - loss: 80.29755 - diff: 25.92mlTrain batch 19/31 - 174.0ms/batch - loss: 77.53934 - diff: 25.44mlTrain batch 20/31 - 174.2ms/batch - loss: 75.34021 - diff: 25.08mlTrain batch 21/31 - 174.2ms/batch - loss: 75.89686 - diff: 25.20mlTrain batch 22/31 - 174.3ms/batch - loss: 74.43268 - diff: 25.06mlTrain batch 23/31 - 173.9ms/batch - loss: 74.48270 - diff: 25.07mlTrain batch 24/31 - 174.1ms/batch - loss: 99.38524 - diff: 25.82mlTrain batch 25/31 - 174.0ms/batch - loss: 97.06645 - diff: 25.70mlTrain batch 26/31 - 174.5ms/batch - loss: 95.85200 - diff: 25.54mlTrain batch 27/31 - 174.0ms/batch - loss: 93.90531 - diff: 25.36mlTrain batch 28/31 - 174.3ms/batch - loss: 93.08130 - diff: 25.36mlTrain batch 29/31 - 174.1ms/batch - loss: 90.73551 - diff: 25.01mlTrain batch 30/31 - 174.3ms/batch - loss: 89.45785 - diff: 24.89mlTrain batch 31/31 - 87.2ms/batch - loss: 89.35166 - diff: 24.76mlTrain batch 31/31 - 11.8s 87.2ms/batch - loss: 89.35166 - diff: 24.76ml
Test 1.1s: val_loss: 56.79747 - diff: 21.36ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Systole_WideResNet50_0_Adam-0.001_MSE_DA3_best

Epoch 44: current best loss = 56.79747, at epoch 43
Train batch 1/31 - 173.9ms/batch - loss: 28.21838 - diff: 18.59mlTrain batch 2/31 - 174.4ms/batch - loss: 64.25268 - diff: 24.87mlTrain batch 3/31 - 174.2ms/batch - loss: 101.19365 - diff: 27.57mlTrain batch 4/31 - 174.4ms/batch - loss: 115.16785 - diff: 29.84mlTrain batch 5/31 - 174.0ms/batch - loss: 99.64121 - diff: 27.84mlTrain batch 6/31 - 174.4ms/batch - loss: 90.04078 - diff: 26.49mlTrain batch 7/31 - 173.9ms/batch - loss: 87.15011 - diff: 26.17mlTrain batch 8/31 - 174.3ms/batch - loss: 82.07361 - diff: 25.53mlTrain batch 9/31 - 174.0ms/batch - loss: 75.31996 - diff: 24.40mlTrain batch 10/31 - 173.9ms/batch - loss: 74.28836 - diff: 24.39mlTrain batch 11/31 - 173.7ms/batch - loss: 129.25690 - diff: 26.65mlTrain batch 12/31 - 174.1ms/batch - loss: 123.17559 - diff: 26.34mlTrain batch 13/31 - 174.0ms/batch - loss: 117.09499 - diff: 25.87mlTrain batch 14/31 - 174.2ms/batch - loss: 111.04829 - diff: 25.40mlTrain batch 15/31 - 174.1ms/batch - loss: 107.24654 - diff: 25.15mlTrain batch 16/31 - 174.8ms/batch - loss: 104.85456 - diff: 25.23mlTrain batch 17/31 - 174.1ms/batch - loss: 109.64145 - diff: 25.48mlTrain batch 18/31 - 173.9ms/batch - loss: 105.18703 - diff: 25.03mlTrain batch 19/31 - 173.8ms/batch - loss: 101.02488 - diff: 24.63mlTrain batch 20/31 - 173.5ms/batch - loss: 100.43896 - diff: 24.59mlTrain batch 21/31 - 174.1ms/batch - loss: 98.92684 - diff: 24.56mlTrain batch 22/31 - 174.2ms/batch - loss: 96.15561 - diff: 24.39mlTrain batch 23/31 - 173.9ms/batch - loss: 94.13982 - diff: 24.31mlTrain batch 24/31 - 173.6ms/batch - loss: 96.90916 - diff: 24.65mlTrain batch 25/31 - 174.2ms/batch - loss: 94.06572 - diff: 24.33mlTrain batch 26/31 - 174.4ms/batch - loss: 94.17147 - diff: 24.24mlTrain batch 27/31 - 174.0ms/batch - loss: 92.04153 - diff: 24.03mlTrain batch 28/31 - 174.2ms/batch - loss: 89.67769 - diff: 23.84mlTrain batch 29/31 - 173.6ms/batch - loss: 90.29843 - diff: 24.00mlTrain batch 30/31 - 173.8ms/batch - loss: 89.18724 - diff: 24.03mlTrain batch 31/31 - 87.2ms/batch - loss: 89.74073 - diff: 24.10mlTrain batch 31/31 - 11.6s 87.2ms/batch - loss: 89.74073 - diff: 24.10ml
Test 1.1s: val_loss: 60.64984 - diff: 22.18ml

Epoch 45: current best loss = 56.79747, at epoch 43
Going to unfreeze the pretrained weights
Train batch 1/31 - 234.9ms/batch - loss: 34.01593 - diff: 20.07mlTrain batch 2/31 - 236.9ms/batch - loss: 56.50639 - diff: 22.09mlTrain batch 3/31 - 236.7ms/batch - loss: 61.30007 - diff: 24.42mlTrain batch 4/31 - 235.7ms/batch - loss: 61.98581 - diff: 24.39mlTrain batch 5/31 - 236.4ms/batch - loss: 78.02659 - diff: 26.16mlTrain batch 6/31 - 236.9ms/batch - loss: 97.15135 - diff: 27.93mlTrain batch 7/31 - 237.1ms/batch - loss: 96.07706 - diff: 28.33mlTrain batch 8/31 - 236.5ms/batch - loss: 87.29247 - diff: 27.09mlTrain batch 9/31 - 237.2ms/batch - loss: 86.95213 - diff: 26.47mlTrain batch 10/31 - 236.8ms/batch - loss: 86.53628 - diff: 26.33mlTrain batch 11/31 - 236.8ms/batch - loss: 87.27848 - diff: 26.88mlTrain batch 12/31 - 236.4ms/batch - loss: 89.73813 - diff: 26.94mlTrain batch 13/31 - 236.9ms/batch - loss: 88.18626 - diff: 26.64mlTrain batch 14/31 - 236.8ms/batch - loss: 87.85984 - diff: 26.52mlTrain batch 15/31 - 237.1ms/batch - loss: 86.23427 - diff: 26.44mlTrain batch 16/31 - 236.8ms/batch - loss: 83.25138 - diff: 26.04mlTrain batch 17/31 - 236.6ms/batch - loss: 118.42771 - diff: 27.45mlTrain batch 18/31 - 236.9ms/batch - loss: 116.70312 - diff: 27.55mlTrain batch 19/31 - 236.8ms/batch - loss: 113.95011 - diff: 27.36mlTrain batch 20/31 - 236.4ms/batch - loss: 111.02453 - diff: 27.25mlTrain batch 21/31 - 236.0ms/batch - loss: 108.89887 - diff: 27.06mlTrain batch 22/31 - 237.3ms/batch - loss: 108.68358 - diff: 26.81mlTrain batch 23/31 - 237.1ms/batch - loss: 108.52048 - diff: 27.03mlTrain batch 24/31 - 236.7ms/batch - loss: 105.28876 - diff: 26.52mlTrain batch 25/31 - 236.6ms/batch - loss: 104.97520 - diff: 26.53mlTrain batch 26/31 - 237.0ms/batch - loss: 103.41845 - diff: 26.48mlTrain batch 27/31 - 237.0ms/batch - loss: 101.29800 - diff: 26.35mlTrain batch 28/31 - 236.3ms/batch - loss: 100.71430 - diff: 26.46mlTrain batch 29/31 - 236.5ms/batch - loss: 97.64368 - diff: 25.92mlTrain batch 30/31 - 236.6ms/batch - loss: 102.13657 - diff: 26.33mlTrain batch 31/31 - 121.6ms/batch - loss: 102.63661 - diff: 26.33mlTrain batch 31/31 - 12.1s 121.6ms/batch - loss: 102.63661 - diff: 26.33ml
Test 1.1s: val_loss: 62.71495 - diff: 22.95ml

Epoch 46: current best loss = 56.79747, at epoch 43
Train batch 1/31 - 237.0ms/batch - loss: 44.62839 - diff: 20.08mlTrain batch 2/31 - 237.2ms/batch - loss: 112.92593 - diff: 30.46mlTrain batch 3/31 - 236.9ms/batch - loss: 235.65161 - diff: 32.89mlTrain batch 4/31 - 237.0ms/batch - loss: 200.03693 - diff: 33.32mlTrain batch 5/31 - 236.4ms/batch - loss: 173.88610 - diff: 31.44mlTrain batch 6/31 - 237.0ms/batch - loss: 157.51069 - diff: 30.92mlTrain batch 7/31 - 237.0ms/batch - loss: 141.07678 - diff: 29.78mlTrain batch 8/31 - 236.4ms/batch - loss: 128.82475 - diff: 28.61mlTrain batch 9/31 - 236.8ms/batch - loss: 126.65723 - diff: 28.83mlTrain batch 10/31 - 236.7ms/batch - loss: 119.89939 - diff: 28.34mlTrain batch 11/31 - 236.6ms/batch - loss: 118.16046 - diff: 28.39mlTrain batch 12/31 - 236.8ms/batch - loss: 112.60941 - diff: 27.81mlTrain batch 13/31 - 236.8ms/batch - loss: 112.58535 - diff: 27.90mlTrain batch 14/31 - 236.9ms/batch - loss: 110.48407 - diff: 27.77mlTrain batch 15/31 - 237.0ms/batch - loss: 106.55525 - diff: 27.45mlTrain batch 16/31 - 236.4ms/batch - loss: 105.73894 - diff: 27.82mlTrain batch 17/31 - 236.9ms/batch - loss: 107.47404 - diff: 28.11mlTrain batch 18/31 - 236.6ms/batch - loss: 108.57924 - diff: 28.47mlTrain batch 19/31 - 237.0ms/batch - loss: 107.07292 - diff: 28.40mlTrain batch 20/31 - 236.8ms/batch - loss: 104.38802 - diff: 28.30mlTrain batch 21/31 - 237.1ms/batch - loss: 102.37063 - diff: 28.16mlTrain batch 22/31 - 236.9ms/batch - loss: 100.61360 - diff: 27.82mlTrain batch 23/31 - 236.9ms/batch - loss: 97.36072 - diff: 27.17mlTrain batch 24/31 - 236.5ms/batch - loss: 100.33158 - diff: 27.31mlTrain batch 25/31 - 237.2ms/batch - loss: 97.68264 - diff: 26.96mlTrain batch 26/31 - 236.9ms/batch - loss: 96.62195 - diff: 26.89mlTrain batch 27/31 - 237.3ms/batch - loss: 95.54269 - diff: 26.72mlTrain batch 28/31 - 236.7ms/batch - loss: 93.61644 - diff: 26.50mlTrain batch 29/31 - 237.2ms/batch - loss: 94.88978 - diff: 26.54mlTrain batch 30/31 - 236.5ms/batch - loss: 94.59584 - diff: 26.67mlTrain batch 31/31 - 122.0ms/batch - loss: 108.82267 - diff: 27.05mlTrain batch 31/31 - 11.5s 122.0ms/batch - loss: 108.82267 - diff: 27.05ml
Test 1.1s: val_loss: 269.08519 - diff: 55.34ml

Epoch 47: current best loss = 56.79747, at epoch 43
Train batch 1/31 - 236.5ms/batch - loss: 82.12454 - diff: 31.25mlTrain batch 2/31 - 237.4ms/batch - loss: 59.87394 - diff: 25.96mlTrain batch 3/31 - 236.5ms/batch - loss: 66.10992 - diff: 24.74mlTrain batch 4/31 - 237.2ms/batch - loss: 79.52774 - diff: 26.25mlTrain batch 5/31 - 236.6ms/batch - loss: 91.87432 - diff: 28.26mlTrain batch 6/31 - 237.3ms/batch - loss: 89.53210 - diff: 28.76mlTrain batch 7/31 - 237.3ms/batch - loss: 86.38907 - diff: 28.63mlTrain batch 8/31 - 237.1ms/batch - loss: 84.82064 - diff: 28.35mlTrain batch 9/31 - 236.9ms/batch - loss: 78.08037 - diff: 27.06mlTrain batch 10/31 - 237.1ms/batch - loss: 78.62127 - diff: 26.56mlTrain batch 11/31 - 237.1ms/batch - loss: 76.91344 - diff: 26.59mlTrain batch 12/31 - 237.2ms/batch - loss: 80.66006 - diff: 26.88mlTrain batch 13/31 - 237.0ms/batch - loss: 77.64932 - diff: 26.39mlTrain batch 14/31 - 237.0ms/batch - loss: 77.82413 - diff: 26.12mlTrain batch 15/31 - 237.0ms/batch - loss: 76.32096 - diff: 26.13mlTrain batch 16/31 - 236.9ms/batch - loss: 111.85883 - diff: 27.47mlTrain batch 17/31 - 237.1ms/batch - loss: 109.31985 - diff: 27.28mlTrain batch 18/31 - 236.9ms/batch - loss: 105.02557 - diff: 26.81mlTrain batch 19/31 - 237.4ms/batch - loss: 103.00709 - diff: 26.75mlTrain batch 20/31 - 237.3ms/batch - loss: 102.46916 - diff: 26.69mlTrain batch 21/31 - 237.2ms/batch - loss: 102.12210 - diff: 26.70mlTrain batch 22/31 - 237.3ms/batch - loss: 100.39380 - diff: 26.80mlTrain batch 23/31 - 236.9ms/batch - loss: 98.12564 - diff: 26.68mlTrain batch 24/31 - 236.6ms/batch - loss: 95.53662 - diff: 26.44mlTrain batch 25/31 - 237.1ms/batch - loss: 93.89041 - diff: 26.16mlTrain batch 26/31 - 237.0ms/batch - loss: 92.66083 - diff: 26.15mlTrain batch 27/31 - 237.1ms/batch - loss: 90.95790 - diff: 25.97mlTrain batch 28/31 - 237.2ms/batch - loss: 96.24529 - diff: 26.56mlTrain batch 29/31 - 237.4ms/batch - loss: 94.92303 - diff: 26.45mlTrain batch 30/31 - 237.2ms/batch - loss: 94.58413 - diff: 26.42mlTrain batch 31/31 - 122.0ms/batch - loss: 94.85540 - diff: 26.35mlTrain batch 31/31 - 11.0s 122.0ms/batch - loss: 94.85540 - diff: 26.35ml
Test 1.1s: val_loss: 52.39338 - diff: 19.96ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Systole_WideResNet50_0_Adam-0.001_MSE_DA3_best

Epoch 48: current best loss = 52.39338, at epoch 47
Train batch 1/31 - 238.0ms/batch - loss: 69.08584 - diff: 23.18mlTrain batch 2/31 - 236.9ms/batch - loss: 70.53937 - diff: 22.17mlTrain batch 3/31 - 236.8ms/batch - loss: 59.43480 - diff: 21.30mlTrain batch 4/31 - 237.0ms/batch - loss: 53.34420 - diff: 20.80mlTrain batch 5/31 - 236.9ms/batch - loss: 53.54458 - diff: 21.94mlTrain batch 6/31 - 236.9ms/batch - loss: 58.55455 - diff: 22.58mlTrain batch 7/31 - 237.1ms/batch - loss: 60.20800 - diff: 22.39mlTrain batch 8/31 - 236.9ms/batch - loss: 57.49674 - diff: 21.89mlTrain batch 9/31 - 236.9ms/batch - loss: 54.29981 - diff: 21.27mlTrain batch 10/31 - 237.2ms/batch - loss: 50.94298 - diff: 20.49mlTrain batch 11/31 - 237.0ms/batch - loss: 92.99679 - diff: 22.35mlTrain batch 12/31 - 238.1ms/batch - loss: 88.12672 - diff: 21.93mlTrain batch 13/31 - 236.4ms/batch - loss: 85.30383 - diff: 22.01mlTrain batch 14/31 - 237.1ms/batch - loss: 81.53326 - diff: 21.76mlTrain batch 15/31 - 237.0ms/batch - loss: 79.44456 - diff: 21.78mlTrain batch 16/31 - 238.0ms/batch - loss: 82.61676 - diff: 22.32mlTrain batch 17/31 - 236.6ms/batch - loss: 80.62350 - diff: 22.32mlTrain batch 18/31 - 237.9ms/batch - loss: 80.46645 - diff: 22.53mlTrain batch 19/31 - 237.3ms/batch - loss: 85.30299 - diff: 23.10mlTrain batch 20/31 - 237.1ms/batch - loss: 83.64954 - diff: 22.96mlTrain batch 21/31 - 237.0ms/batch - loss: 81.88345 - diff: 23.01mlTrain batch 22/31 - 237.4ms/batch - loss: 79.52206 - diff: 22.83mlTrain batch 23/31 - 237.1ms/batch - loss: 81.57982 - diff: 23.14mlTrain batch 24/31 - 237.2ms/batch - loss: 80.43131 - diff: 23.10mlTrain batch 25/31 - 236.8ms/batch - loss: 80.15921 - diff: 23.21mlTrain batch 26/31 - 237.7ms/batch - loss: 80.59282 - diff: 23.47mlTrain batch 27/31 - 237.0ms/batch - loss: 79.98291 - diff: 23.53mlTrain batch 28/31 - 237.1ms/batch - loss: 80.83323 - diff: 23.58mlTrain batch 29/31 - 236.7ms/batch - loss: 86.94460 - diff: 24.17mlTrain batch 30/31 - 237.2ms/batch - loss: 84.86431 - diff: 23.90mlTrain batch 31/31 - 122.0ms/batch - loss: 84.64845 - diff: 23.79mlTrain batch 31/31 - 11.3s 122.0ms/batch - loss: 84.64845 - diff: 23.79ml
Test 1.1s: val_loss: 97.67953 - diff: 30.25ml

Epoch 49: current best loss = 52.39338, at epoch 47
Train batch 1/31 - 236.5ms/batch - loss: 106.66612 - diff: 27.08mlTrain batch 2/31 - 236.9ms/batch - loss: 84.38395 - diff: 25.25mlTrain batch 3/31 - 236.7ms/batch - loss: 92.79002 - diff: 25.53mlTrain batch 4/31 - 237.6ms/batch - loss: 79.86114 - diff: 24.44mlTrain batch 5/31 - 236.9ms/batch - loss: 68.33387 - diff: 22.85mlTrain batch 6/31 - 237.3ms/batch - loss: 65.34021 - diff: 22.78mlTrain batch 7/31 - 237.0ms/batch - loss: 66.91668 - diff: 22.98mlTrain batch 8/31 - 237.2ms/batch - loss: 61.70482 - diff: 22.04mlTrain batch 9/31 - 236.9ms/batch - loss: 57.61913 - diff: 21.32mlTrain batch 10/31 - 237.5ms/batch - loss: 56.83637 - diff: 21.58mlTrain batch 11/31 - 237.0ms/batch - loss: 57.54720 - diff: 21.87mlTrain batch 12/31 - 239.6ms/batch - loss: 67.36859 - diff: 22.45mlTrain batch 13/31 - 237.1ms/batch - loss: 65.69512 - diff: 22.43mlTrain batch 14/31 - 238.2ms/batch - loss: 72.79677 - diff: 23.04mlTrain batch 15/31 - 237.2ms/batch - loss: 71.87633 - diff: 22.95mlTrain batch 16/31 - 237.5ms/batch - loss: 71.72372 - diff: 23.23mlTrain batch 17/31 - 236.9ms/batch - loss: 70.98172 - diff: 23.35mlTrain batch 18/31 - 237.2ms/batch - loss: 67.94151 - diff: 22.80mlTrain batch 19/31 - 237.2ms/batch - loss: 68.20216 - diff: 23.07mlTrain batch 20/31 - 237.9ms/batch - loss: 66.10298 - diff: 22.82mlTrain batch 21/31 - 236.9ms/batch - loss: 66.27102 - diff: 22.75mlTrain batch 22/31 - 237.2ms/batch - loss: 67.43090 - diff: 22.96mlTrain batch 23/31 - 237.4ms/batch - loss: 65.39127 - diff: 22.60mlTrain batch 24/31 - 237.8ms/batch - loss: 63.49372 - diff: 22.31mlTrain batch 25/31 - 237.0ms/batch - loss: 63.80763 - diff: 22.42mlTrain batch 26/31 - 237.7ms/batch - loss: 63.77635 - diff: 22.51mlTrain batch 27/31 - 237.5ms/batch - loss: 67.16240 - diff: 22.92mlTrain batch 28/31 - 239.9ms/batch - loss: 67.11809 - diff: 23.00mlTrain batch 29/31 - 237.5ms/batch - loss: 66.47581 - diff: 23.02mlTrain batch 30/31 - 239.8ms/batch - loss: 83.47568 - diff: 23.61mlTrain batch 31/31 - 124.2ms/batch - loss: 82.71846 - diff: 23.43mlTrain batch 31/31 - 10.8s 124.2ms/batch - loss: 82.71846 - diff: 23.43ml
Test 1.1s: val_loss: 55.21528 - diff: 20.56ml

Epoch 50: current best loss = 52.39338, at epoch 47
Train batch 1/31 - 236.9ms/batch - loss: 29.78508 - diff: 16.24mlTrain batch 2/31 - 237.7ms/batch - loss: 43.42884 - diff: 18.63mlTrain batch 3/31 - 237.1ms/batch - loss: 65.78378 - diff: 22.38mlTrain batch 4/31 - 237.7ms/batch - loss: 63.71114 - diff: 22.60mlTrain batch 5/31 - 237.4ms/batch - loss: 63.68385 - diff: 23.68mlTrain batch 6/31 - 237.5ms/batch - loss: 59.52186 - diff: 23.15mlTrain batch 7/31 - 237.7ms/batch - loss: 74.72019 - diff: 24.69mlTrain batch 8/31 - 238.5ms/batch - loss: 69.37784 - diff: 23.89mlTrain batch 9/31 - 236.8ms/batch - loss: 64.18645 - diff: 23.06mlTrain batch 10/31 - 237.0ms/batch - loss: 61.80844 - diff: 22.68mlTrain batch 11/31 - 237.0ms/batch - loss: 59.03698 - diff: 22.35mlTrain batch 12/31 - 237.2ms/batch - loss: 60.27142 - diff: 22.82mlTrain batch 13/31 - 237.0ms/batch - loss: 62.25734 - diff: 22.79mlTrain batch 14/31 - 238.0ms/batch - loss: 61.41301 - diff: 22.62mlTrain batch 15/31 - 236.9ms/batch - loss: 61.62313 - diff: 22.59mlTrain batch 16/31 - 237.5ms/batch - loss: 62.29910 - diff: 22.74mlTrain batch 17/31 - 236.8ms/batch - loss: 63.00034 - diff: 22.80mlTrain batch 18/31 - 237.6ms/batch - loss: 62.13894 - diff: 22.67mlTrain batch 19/31 - 237.2ms/batch - loss: 67.97739 - diff: 23.42mlTrain batch 20/31 - 237.1ms/batch - loss: 67.60045 - diff: 23.45mlTrain batch 21/31 - 237.4ms/batch - loss: 86.47562 - diff: 24.30mlTrain batch 22/31 - 239.5ms/batch - loss: 86.11855 - diff: 24.44mlTrain batch 23/31 - 236.8ms/batch - loss: 84.30777 - diff: 24.31mlTrain batch 24/31 - 239.5ms/batch - loss: 84.73673 - diff: 24.59mlTrain batch 25/31 - 237.6ms/batch - loss: 84.21904 - diff: 24.66mlTrain batch 26/31 - 238.9ms/batch - loss: 86.48546 - diff: 25.00mlTrain batch 27/31 - 238.1ms/batch - loss: 84.16555 - diff: 24.71mlTrain batch 28/31 - 238.1ms/batch - loss: 82.74258 - diff: 24.59mlTrain batch 29/31 - 238.3ms/batch - loss: 81.75096 - diff: 24.56mlTrain batch 30/31 - 238.3ms/batch - loss: 80.11389 - diff: 24.44mlTrain batch 31/31 - 123.6ms/batch - loss: 82.29644 - diff: 24.56mlTrain batch 31/31 - 11.2s 123.6ms/batch - loss: 82.29644 - diff: 24.56ml
Test 1.1s: val_loss: 65.93093 - diff: 21.30ml

Epoch 51: current best loss = 52.39338, at epoch 47
Train batch 1/31 - 237.4ms/batch - loss: 22.52065 - diff: 14.23mlTrain batch 2/31 - 237.4ms/batch - loss: 52.51813 - diff: 17.37mlTrain batch 3/31 - 237.2ms/batch - loss: 51.28002 - diff: 18.56mlTrain batch 4/31 - 240.2ms/batch - loss: 51.07022 - diff: 19.73mlTrain batch 5/31 - 237.8ms/batch - loss: 50.21003 - diff: 20.31mlTrain batch 6/31 - 239.4ms/batch - loss: 55.86450 - diff: 20.83mlTrain batch 7/31 - 237.1ms/batch - loss: 56.98301 - diff: 21.51mlTrain batch 8/31 - 238.1ms/batch - loss: 58.09412 - diff: 21.75mlTrain batch 9/31 - 237.0ms/batch - loss: 107.69725 - diff: 24.25mlTrain batch 10/31 - 237.2ms/batch - loss: 121.80940 - diff: 25.98mlTrain batch 11/31 - 237.0ms/batch - loss: 117.69165 - diff: 26.16mlTrain batch 12/31 - 237.5ms/batch - loss: 112.24193 - diff: 25.84mlTrain batch 13/31 - 237.6ms/batch - loss: 108.07025 - diff: 25.92mlTrain batch 14/31 - 237.3ms/batch - loss: 106.34487 - diff: 26.18mlTrain batch 15/31 - 237.7ms/batch - loss: 104.80380 - diff: 26.32mlTrain batch 16/31 - 236.9ms/batch - loss: 103.68509 - diff: 26.55mlTrain batch 17/31 - 237.4ms/batch - loss: 101.51969 - diff: 26.53mlTrain batch 18/31 - 237.3ms/batch - loss: 99.16218 - diff: 26.41mlTrain batch 19/31 - 237.1ms/batch - loss: 97.14948 - diff: 26.40mlTrain batch 20/31 - 237.3ms/batch - loss: 110.15563 - diff: 27.22mlTrain batch 21/31 - 239.9ms/batch - loss: 105.86683 - diff: 26.57mlTrain batch 22/31 - 237.2ms/batch - loss: 102.35077 - diff: 26.07mlTrain batch 23/31 - 238.4ms/batch - loss: 98.85761 - diff: 25.59mlTrain batch 24/31 - 236.8ms/batch - loss: 101.32149 - diff: 25.75mlTrain batch 25/31 - 237.3ms/batch - loss: 98.66471 - diff: 25.49mlTrain batch 26/31 - 237.0ms/batch - loss: 96.23379 - diff: 25.27mlTrain batch 27/31 - 237.4ms/batch - loss: 96.18639 - diff: 25.38mlTrain batch 28/31 - 237.4ms/batch - loss: 93.49023 - diff: 24.98mlTrain batch 29/31 - 236.4ms/batch - loss: 92.69629 - diff: 25.03mlTrain batch 30/31 - 237.8ms/batch - loss: 92.18407 - diff: 25.10mlTrain batch 31/31 - 124.8ms/batch - loss: 91.46470 - diff: 24.97mlTrain batch 31/31 - 12.0s 124.8ms/batch - loss: 91.46470 - diff: 24.97ml
Test 1.1s: val_loss: 85.71674 - diff: 26.34ml

Epoch 52: current best loss = 52.39338, at epoch 47
Train batch 1/31 - 237.0ms/batch - loss: 148.29524 - diff: 34.79mlTrain batch 2/31 - 237.4ms/batch - loss: 352.50269 - diff: 40.11mlTrain batch 3/31 - 237.2ms/batch - loss: 260.14758 - diff: 36.33mlTrain batch 4/31 - 238.4ms/batch - loss: 212.72572 - diff: 33.67mlTrain batch 5/31 - 236.9ms/batch - loss: 176.69614 - diff: 30.66mlTrain batch 6/31 - 237.4ms/batch - loss: 154.34956 - diff: 28.97mlTrain batch 7/31 - 237.9ms/batch - loss: 142.29381 - diff: 28.51mlTrain batch 8/31 - 238.8ms/batch - loss: 129.51053 - diff: 27.56mlTrain batch 9/31 - 237.5ms/batch - loss: 120.31209 - diff: 26.84mlTrain batch 10/31 - 239.8ms/batch - loss: 122.11161 - diff: 27.11mlTrain batch 11/31 - 236.8ms/batch - loss: 113.86812 - diff: 26.11mlTrain batch 12/31 - 239.2ms/batch - loss: 106.28250 - diff: 25.29mlTrain batch 13/31 - 237.7ms/batch - loss: 103.36268 - diff: 25.26mlTrain batch 14/31 - 238.5ms/batch - loss: 102.89427 - diff: 25.43mlTrain batch 15/31 - 237.3ms/batch - loss: 109.94034 - diff: 25.57mlTrain batch 16/31 - 238.5ms/batch - loss: 107.23506 - diff: 25.16mlTrain batch 17/31 - 237.8ms/batch - loss: 105.99193 - diff: 25.32mlTrain batch 18/31 - 237.4ms/batch - loss: 104.41030 - diff: 25.31mlTrain batch 19/31 - 237.4ms/batch - loss: 100.07436 - diff: 24.80mlTrain batch 20/31 - 238.0ms/batch - loss: 100.69664 - diff: 25.04mlTrain batch 21/31 - 237.6ms/batch - loss: 98.18229 - diff: 24.93mlTrain batch 22/31 - 240.2ms/batch - loss: 97.14155 - diff: 24.95mlTrain batch 23/31 - 237.9ms/batch - loss: 96.36174 - diff: 24.96mlTrain batch 24/31 - 239.8ms/batch - loss: 96.82511 - diff: 25.12mlTrain batch 25/31 - 238.2ms/batch - loss: 94.52753 - diff: 24.98mlTrain batch 26/31 - 240.0ms/batch - loss: 95.71223 - diff: 25.14mlTrain batch 27/31 - 237.0ms/batch - loss: 93.37427 - diff: 24.94mlTrain batch 28/31 - 238.0ms/batch - loss: 90.69212 - diff: 24.59mlTrain batch 29/31 - 237.4ms/batch - loss: 90.48250 - diff: 24.66mlTrain batch 30/31 - 239.4ms/batch - loss: 88.54161 - diff: 24.44mlTrain batch 31/31 - 124.1ms/batch - loss: 88.57124 - diff: 24.39mlTrain batch 31/31 - 11.3s 124.1ms/batch - loss: 88.57124 - diff: 24.39ml
Test 1.1s: val_loss: 94.18565 - diff: 25.25ml

Epoch 53: current best loss = 52.39338, at epoch 47
Train batch 1/31 - 236.9ms/batch - loss: 84.51079 - diff: 28.82mlTrain batch 2/31 - 237.8ms/batch - loss: 95.42500 - diff: 27.62mlTrain batch 3/31 - 238.1ms/batch - loss: 75.46186 - diff: 24.45mlTrain batch 4/31 - 238.3ms/batch - loss: 65.00961 - diff: 22.70mlTrain batch 5/31 - 237.4ms/batch - loss: 65.14738 - diff: 23.13mlTrain batch 6/31 - 239.9ms/batch - loss: 62.37236 - diff: 22.73mlTrain batch 7/31 - 238.2ms/batch - loss: 61.03101 - diff: 22.70mlTrain batch 8/31 - 240.0ms/batch - loss: 61.26197 - diff: 22.67mlTrain batch 9/31 - 238.2ms/batch - loss: 82.36062 - diff: 23.58mlTrain batch 10/31 - 237.6ms/batch - loss: 78.73825 - diff: 23.19mlTrain batch 11/31 - 238.0ms/batch - loss: 79.55433 - diff: 23.03mlTrain batch 12/31 - 237.9ms/batch - loss: 83.94819 - diff: 23.51mlTrain batch 13/31 - 238.5ms/batch - loss: 85.63357 - diff: 23.97mlTrain batch 14/31 - 238.5ms/batch - loss: 82.16056 - diff: 23.62mlTrain batch 15/31 - 237.6ms/batch - loss: 84.50468 - diff: 24.32mlTrain batch 16/31 - 238.0ms/batch - loss: 83.57598 - diff: 24.46mlTrain batch 17/31 - 237.9ms/batch - loss: 83.31490 - diff: 24.20mlTrain batch 18/31 - 237.9ms/batch - loss: 80.57745 - diff: 23.86mlTrain batch 19/31 - 240.1ms/batch - loss: 82.30214 - diff: 24.09mlTrain batch 20/31 - 237.8ms/batch - loss: 81.02962 - diff: 24.08mlTrain batch 21/31 - 240.0ms/batch - loss: 79.51687 - diff: 24.10mlTrain batch 22/31 - 237.3ms/batch - loss: 77.83726 - diff: 23.98mlTrain batch 23/31 - 239.5ms/batch - loss: 76.72790 - diff: 23.84mlTrain batch 24/31 - 238.0ms/batch - loss: 78.04469 - diff: 23.76mlTrain batch 25/31 - 239.9ms/batch - loss: 77.34858 - diff: 23.66mlTrain batch 26/31 - 243.1ms/batch - loss: 75.62222 - diff: 23.44mlTrain batch 27/31 - 239.1ms/batch - loss: 73.58682 - diff: 23.01mlTrain batch 28/31 - 237.8ms/batch - loss: 92.32110 - diff: 23.61mlTrain batch 29/31 - 237.8ms/batch - loss: 89.85383 - diff: 23.26mlTrain batch 30/31 - 238.6ms/batch - loss: 89.38241 - diff: 23.24mlTrain batch 31/31 - 124.5ms/batch - loss: 93.61224 - diff: 23.42mlTrain batch 31/31 - 10.6s 124.5ms/batch - loss: 93.61224 - diff: 23.42ml
Test 1.1s: val_loss: 58.71663 - diff: 21.26ml

Epoch 54: current best loss = 52.39338, at epoch 47
Train batch 1/31 - 237.3ms/batch - loss: 83.40585 - diff: 21.34mlTrain batch 2/31 - 239.5ms/batch - loss: 166.22046 - diff: 29.63mlTrain batch 3/31 - 237.4ms/batch - loss: 133.46335 - diff: 27.99mlTrain batch 4/31 - 239.5ms/batch - loss: 118.00628 - diff: 27.60mlTrain batch 5/31 - 237.7ms/batch - loss: 102.31592 - diff: 25.90mlTrain batch 6/31 - 239.4ms/batch - loss: 90.37138 - diff: 24.62mlTrain batch 7/31 - 238.0ms/batch - loss: 86.01784 - diff: 24.37mlTrain batch 8/31 - 239.3ms/batch - loss: 80.81485 - diff: 24.30mlTrain batch 9/31 - 237.7ms/batch - loss: 77.29453 - diff: 23.84mlTrain batch 10/31 - 238.4ms/batch - loss: 73.72377 - diff: 23.68mlTrain batch 11/31 - 238.8ms/batch - loss: 70.80381 - diff: 23.53mlTrain batch 12/31 - 237.2ms/batch - loss: 110.37450 - diff: 24.92mlTrain batch 13/31 - 240.0ms/batch - loss: 109.84582 - diff: 24.94mlTrain batch 14/31 - 237.9ms/batch - loss: 103.77633 - diff: 24.29mlTrain batch 15/31 - 240.1ms/batch - loss: 106.94149 - diff: 24.91mlTrain batch 16/31 - 240.8ms/batch - loss: 102.87927 - diff: 24.63mlTrain batch 17/31 - 238.2ms/batch - loss: 99.66176 - diff: 24.54mlTrain batch 18/31 - 237.5ms/batch - loss: 99.21334 - diff: 24.69mlTrain batch 19/31 - 239.9ms/batch - loss: 96.08760 - diff: 24.49mlTrain batch 20/31 - 237.7ms/batch - loss: 94.48373 - diff: 24.58mlTrain batch 21/31 - 240.0ms/batch - loss: 92.49956 - diff: 24.42mlTrain batch 22/31 - 237.9ms/batch - loss: 90.71841 - diff: 24.33mlTrain batch 23/31 - 238.1ms/batch - loss: 88.14337 - diff: 23.97mlTrain batch 24/31 - 237.4ms/batch - loss: 92.73272 - diff: 24.77mlTrain batch 25/31 - 239.5ms/batch - loss: 90.34697 - diff: 24.46mlTrain batch 26/31 - 237.4ms/batch - loss: 87.60002 - diff: 24.03mlTrain batch 27/31 - 240.3ms/batch - loss: 87.58821 - diff: 24.01mlTrain batch 28/31 - 238.0ms/batch - loss: 87.53230 - diff: 23.94mlTrain batch 29/31 - 239.7ms/batch - loss: 85.14506 - diff: 23.55mlTrain batch 30/31 - 237.3ms/batch - loss: 84.71469 - diff: 23.53mlTrain batch 31/31 - 122.1ms/batch - loss: 85.02383 - diff: 23.52mlTrain batch 31/31 - 11.6s 122.1ms/batch - loss: 85.02383 - diff: 23.52ml
Test 1.2s: val_loss: 80.72831 - diff: 28.71ml

Epoch 55: current best loss = 52.39338, at epoch 47
Train batch 1/31 - 237.2ms/batch - loss: 35.62577 - diff: 18.02mlTrain batch 2/31 - 238.0ms/batch - loss: 37.24416 - diff: 19.47mlTrain batch 3/31 - 236.9ms/batch - loss: 42.11986 - diff: 18.57mlTrain batch 4/31 - 238.0ms/batch - loss: 47.75455 - diff: 20.41mlTrain batch 5/31 - 237.9ms/batch - loss: 44.45340 - diff: 20.23mlTrain batch 6/31 - 237.9ms/batch - loss: 57.67929 - diff: 22.16mlTrain batch 7/31 - 239.1ms/batch - loss: 62.17152 - diff: 22.84mlTrain batch 8/31 - 238.7ms/batch - loss: 57.33656 - diff: 22.05mlTrain batch 9/31 - 237.5ms/batch - loss: 52.91827 - diff: 21.10mlTrain batch 10/31 - 237.9ms/batch - loss: 101.90693 - diff: 23.08mlTrain batch 11/31 - 238.0ms/batch - loss: 97.21243 - diff: 22.81mlTrain batch 12/31 - 240.2ms/batch - loss: 98.27321 - diff: 23.34mlTrain batch 13/31 - 237.5ms/batch - loss: 93.11007 - diff: 22.99mlTrain batch 14/31 - 238.6ms/batch - loss: 93.13551 - diff: 23.52mlTrain batch 15/31 - 238.7ms/batch - loss: 95.30977 - diff: 23.86mlTrain batch 16/31 - 240.1ms/batch - loss: 92.52717 - diff: 23.86mlTrain batch 17/31 - 237.7ms/batch - loss: 92.70762 - diff: 24.02mlTrain batch 18/31 - 239.5ms/batch - loss: 91.18873 - diff: 24.25mlTrain batch 19/31 - 238.6ms/batch - loss: 89.07376 - diff: 24.08mlTrain batch 20/31 - 239.9ms/batch - loss: 86.59877 - diff: 23.85mlTrain batch 21/31 - 238.7ms/batch - loss: 84.15744 - diff: 23.66mlTrain batch 22/31 - 237.7ms/batch - loss: 81.28489 - diff: 23.34mlTrain batch 23/31 - 239.9ms/batch - loss: 81.15181 - diff: 23.32mlTrain batch 24/31 - 238.2ms/batch - loss: 78.93775 - diff: 23.02mlTrain batch 25/31 - 239.4ms/batch - loss: 80.41375 - diff: 23.16mlTrain batch 26/31 - 238.2ms/batch - loss: 78.88699 - diff: 22.93mlTrain batch 27/31 - 240.1ms/batch - loss: 79.88012 - diff: 23.11mlTrain batch 28/31 - 238.5ms/batch - loss: 80.74273 - diff: 23.26mlTrain batch 29/31 - 237.9ms/batch - loss: 84.65848 - diff: 23.62mlTrain batch 30/31 - 237.9ms/batch - loss: 82.47004 - diff: 23.28mlTrain batch 31/31 - 125.0ms/batch - loss: 82.19095 - diff: 23.21mlTrain batch 31/31 - 10.7s 125.0ms/batch - loss: 82.19095 - diff: 23.21ml
Test 1.1s: val_loss: 59.96956 - diff: 19.98ml

Epoch 56: current best loss = 52.39338, at epoch 47
Train batch 1/31 - 236.8ms/batch - loss: 32.19074 - diff: 18.33mlTrain batch 2/31 - 238.6ms/batch - loss: 71.07203 - diff: 23.00mlTrain batch 3/31 - 238.5ms/batch - loss: 63.41290 - diff: 22.11mlTrain batch 4/31 - 239.0ms/batch - loss: 73.83441 - diff: 24.53mlTrain batch 5/31 - 237.7ms/batch - loss: 74.58876 - diff: 24.84mlTrain batch 6/31 - 238.2ms/batch - loss: 76.35868 - diff: 25.44mlTrain batch 7/31 - 237.9ms/batch - loss: 71.93224 - diff: 24.80mlTrain batch 8/31 - 237.9ms/batch - loss: 70.18404 - diff: 24.36mlTrain batch 9/31 - 238.7ms/batch - loss: 66.25562 - diff: 23.82mlTrain batch 10/31 - 237.5ms/batch - loss: 63.72298 - diff: 23.52mlTrain batch 11/31 - 238.9ms/batch - loss: 66.14829 - diff: 24.33mlTrain batch 12/31 - 237.5ms/batch - loss: 65.49816 - diff: 23.86mlTrain batch 13/31 - 239.8ms/batch - loss: 64.62790 - diff: 23.76mlTrain batch 14/31 - 237.8ms/batch - loss: 61.30086 - diff: 23.00mlTrain batch 15/31 - 238.6ms/batch - loss: 97.39766 - diff: 25.08mlTrain batch 16/31 - 237.8ms/batch - loss: 98.40268 - diff: 25.50mlTrain batch 17/31 - 237.7ms/batch - loss: 99.84796 - diff: 25.67mlTrain batch 18/31 - 238.4ms/batch - loss: 98.55175 - diff: 25.56mlTrain batch 19/31 - 238.2ms/batch - loss: 99.41749 - diff: 25.88mlTrain batch 20/31 - 237.4ms/batch - loss: 97.06299 - diff: 25.94mlTrain batch 21/31 - 238.1ms/batch - loss: 99.03697 - diff: 26.09mlTrain batch 22/31 - 237.9ms/batch - loss: 95.74841 - diff: 25.63mlTrain batch 23/31 - 239.5ms/batch - loss: 95.88686 - diff: 25.98mlTrain batch 24/31 - 237.4ms/batch - loss: 96.88307 - diff: 26.48mlTrain batch 25/31 - 240.0ms/batch - loss: 95.65252 - diff: 26.38mlTrain batch 26/31 - 237.8ms/batch - loss: 93.99841 - diff: 26.37mlTrain batch 27/31 - 239.9ms/batch - loss: 91.73863 - diff: 26.14mlTrain batch 28/31 - 237.7ms/batch - loss: 93.74778 - diff: 26.38mlTrain batch 29/31 - 237.9ms/batch - loss: 91.82103 - diff: 26.05mlTrain batch 30/31 - 237.7ms/batch - loss: 89.66671 - diff: 25.78mlTrain batch 31/31 - 123.4ms/batch - loss: 89.84288 - diff: 25.74mlTrain batch 31/31 - 11.8s 123.4ms/batch - loss: 89.84288 - diff: 25.74ml
Test 1.1s: val_loss: 108.02164 - diff: 32.52ml

Epoch 57: current best loss = 52.39338, at epoch 47
Train batch 1/31 - 237.8ms/batch - loss: 34.36993 - diff: 20.69mlTrain batch 2/31 - 238.6ms/batch - loss: 53.73413 - diff: 23.17mlTrain batch 3/31 - 237.2ms/batch - loss: 60.22431 - diff: 22.34mlTrain batch 4/31 - 239.9ms/batch - loss: 50.37689 - diff: 20.41mlTrain batch 5/31 - 238.4ms/batch - loss: 46.20359 - diff: 19.96mlTrain batch 6/31 - 240.7ms/batch - loss: 47.75696 - diff: 20.46mlTrain batch 7/31 - 237.5ms/batch - loss: 46.98788 - diff: 19.76mlTrain batch 8/31 - 240.1ms/batch - loss: 46.39614 - diff: 19.57mlTrain batch 9/31 - 237.9ms/batch - loss: 54.04828 - diff: 20.53mlTrain batch 10/31 - 239.8ms/batch - loss: 54.87181 - diff: 20.66mlTrain batch 11/31 - 237.9ms/batch - loss: 57.38829 - diff: 20.89mlTrain batch 12/31 - 238.9ms/batch - loss: 56.34355 - diff: 20.90mlTrain batch 13/31 - 237.7ms/batch - loss: 55.97478 - diff: 20.75mlTrain batch 14/31 - 240.3ms/batch - loss: 54.23905 - diff: 20.63mlTrain batch 15/31 - 238.3ms/batch - loss: 54.29455 - diff: 21.05mlTrain batch 16/31 - 239.4ms/batch - loss: 54.88723 - diff: 21.32mlTrain batch 17/31 - 237.7ms/batch - loss: 61.28819 - diff: 21.94mlTrain batch 18/31 - 239.3ms/batch - loss: 94.81600 - diff: 23.85mlTrain batch 19/31 - 237.8ms/batch - loss: 91.73009 - diff: 23.67mlTrain batch 20/31 - 240.1ms/batch - loss: 89.40164 - diff: 23.67mlTrain batch 21/31 - 241.5ms/batch - loss: 88.42943 - diff: 23.81mlTrain batch 22/31 - 237.7ms/batch - loss: 86.62620 - diff: 23.81mlTrain batch 23/31 - 236.9ms/batch - loss: 85.02867 - diff: 23.62mlTrain batch 24/31 - 239.1ms/batch - loss: 83.42837 - diff: 23.51mlTrain batch 25/31 - 237.9ms/batch - loss: 86.57096 - diff: 23.85mlTrain batch 26/31 - 240.3ms/batch - loss: 85.16118 - diff: 23.77mlTrain batch 27/31 - 237.5ms/batch - loss: 85.16095 - diff: 23.77mlTrain batch 28/31 - 239.9ms/batch - loss: 83.59127 - diff: 23.63mlTrain batch 29/31 - 237.9ms/batch - loss: 82.14455 - diff: 23.48mlTrain batch 30/31 - 238.7ms/batch - loss: 80.08621 - diff: 23.23mlTrain batch 31/31 - 123.0ms/batch - loss: 83.46285 - diff: 23.39mlTrain batch 31/31 - 11.5s 123.0ms/batch - loss: 83.46285 - diff: 23.39ml
Test 1.1s: val_loss: 71.83442 - diff: 24.93ml

Epoch 58: current best loss = 52.39338, at epoch 47
Train batch 1/31 - 237.0ms/batch - loss: 97.83978 - diff: 26.54mlTrain batch 2/31 - 240.0ms/batch - loss: 111.96089 - diff: 28.44mlTrain batch 3/31 - 237.5ms/batch - loss: 94.10841 - diff: 26.18mlTrain batch 4/31 - 240.2ms/batch - loss: 76.25042 - diff: 23.50mlTrain batch 5/31 - 239.1ms/batch - loss: 67.44753 - diff: 22.16mlTrain batch 6/31 - 240.1ms/batch - loss: 68.23049 - diff: 22.49mlTrain batch 7/31 - 237.8ms/batch - loss: 62.92604 - diff: 21.83mlTrain batch 8/31 - 238.4ms/batch - loss: 70.36312 - diff: 22.90mlTrain batch 9/31 - 237.6ms/batch - loss: 81.53655 - diff: 23.50mlTrain batch 10/31 - 240.0ms/batch - loss: 78.45290 - diff: 23.55mlTrain batch 11/31 - 237.6ms/batch - loss: 81.27172 - diff: 24.13mlTrain batch 12/31 - 239.9ms/batch - loss: 83.79631 - diff: 24.42mlTrain batch 13/31 - 238.2ms/batch - loss: 79.52183 - diff: 23.83mlTrain batch 14/31 - 240.4ms/batch - loss: 76.24346 - diff: 23.55mlTrain batch 15/31 - 238.3ms/batch - loss: 74.41979 - diff: 23.43mlTrain batch 16/31 - 239.7ms/batch - loss: 76.45901 - diff: 23.65mlTrain batch 17/31 - 238.2ms/batch - loss: 76.51202 - diff: 23.62mlTrain batch 18/31 - 240.0ms/batch - loss: 76.59163 - diff: 23.80mlTrain batch 19/31 - 237.9ms/batch - loss: 74.02772 - diff: 23.39mlTrain batch 20/31 - 239.2ms/batch - loss: 72.72314 - diff: 23.28mlTrain batch 21/31 - 237.3ms/batch - loss: 72.43664 - diff: 23.42mlTrain batch 22/31 - 239.2ms/batch - loss: 70.05862 - diff: 23.04mlTrain batch 23/31 - 237.6ms/batch - loss: 68.76848 - diff: 23.03mlTrain batch 24/31 - 239.8ms/batch - loss: 66.67428 - diff: 22.68mlTrain batch 25/31 - 237.9ms/batch - loss: 65.40662 - diff: 22.58mlTrain batch 26/31 - 239.7ms/batch - loss: 64.02792 - diff: 22.37mlTrain batch 27/31 - 238.0ms/batch - loss: 80.20351 - diff: 23.09mlTrain batch 28/31 - 240.2ms/batch - loss: 79.88883 - diff: 23.24mlTrain batch 29/31 - 237.6ms/batch - loss: 78.95192 - diff: 23.12mlTrain batch 30/31 - 240.3ms/batch - loss: 77.63404 - diff: 23.08mlTrain batch 31/31 - 124.4ms/batch - loss: 78.76597 - diff: 23.12mlTrain batch 31/31 - 11.3s 124.4ms/batch - loss: 78.76597 - diff: 23.12ml
Test 1.1s: val_loss: 72.68881 - diff: 21.79ml
Epoch    59: reducing learning rate of group 0 to 5.0000e-04.

Epoch 59: current best loss = 52.39338, at epoch 47
Train batch 1/31 - 238.1ms/batch - loss: 62.51977 - diff: 24.29mlTrain batch 2/31 - 236.3ms/batch - loss: 79.54180 - diff: 26.75mlTrain batch 3/31 - 237.8ms/batch - loss: 61.73435 - diff: 22.58mlTrain batch 4/31 - 238.6ms/batch - loss: 60.50638 - diff: 22.86mlTrain batch 5/31 - 237.4ms/batch - loss: 55.19775 - diff: 22.26mlTrain batch 6/31 - 240.2ms/batch - loss: 51.15561 - diff: 21.92mlTrain batch 7/31 - 237.1ms/batch - loss: 120.41849 - diff: 24.72mlTrain batch 8/31 - 240.1ms/batch - loss: 112.13338 - diff: 24.70mlTrain batch 9/31 - 237.8ms/batch - loss: 109.28312 - diff: 24.61mlTrain batch 10/31 - 240.2ms/batch - loss: 109.43801 - diff: 25.03mlTrain batch 11/31 - 237.7ms/batch - loss: 104.29237 - diff: 24.47mlTrain batch 12/31 - 239.9ms/batch - loss: 98.14760 - diff: 23.78mlTrain batch 13/31 - 238.3ms/batch - loss: 92.51287 - diff: 23.22mlTrain batch 14/31 - 240.3ms/batch - loss: 88.70515 - diff: 22.62mlTrain batch 15/31 - 238.2ms/batch - loss: 88.90421 - diff: 23.19mlTrain batch 16/31 - 240.2ms/batch - loss: 89.82307 - diff: 23.51mlTrain batch 17/31 - 238.8ms/batch - loss: 86.14532 - diff: 23.07mlTrain batch 18/31 - 239.9ms/batch - loss: 84.73483 - diff: 23.10mlTrain batch 19/31 - 238.0ms/batch - loss: 82.14750 - diff: 22.87mlTrain batch 20/31 - 239.1ms/batch - loss: 79.66812 - diff: 22.65mlTrain batch 21/31 - 237.8ms/batch - loss: 79.47610 - diff: 22.62mlTrain batch 22/31 - 240.1ms/batch - loss: 78.21736 - diff: 22.71mlTrain batch 23/31 - 237.9ms/batch - loss: 76.07525 - diff: 22.44mlTrain batch 24/31 - 240.2ms/batch - loss: 74.56594 - diff: 22.38mlTrain batch 25/31 - 237.8ms/batch - loss: 73.55749 - diff: 22.34mlTrain batch 26/31 - 240.5ms/batch - loss: 71.99745 - diff: 22.23mlTrain batch 27/31 - 238.0ms/batch - loss: 70.77119 - diff: 22.16mlTrain batch 28/31 - 240.0ms/batch - loss: 74.33515 - diff: 22.73mlTrain batch 29/31 - 238.1ms/batch - loss: 76.82468 - diff: 22.85mlTrain batch 30/31 - 240.3ms/batch - loss: 76.09928 - diff: 22.83mlTrain batch 31/31 - 124.2ms/batch - loss: 78.27994 - diff: 22.87mlTrain batch 31/31 - 10.8s 124.2ms/batch - loss: 78.27994 - diff: 22.87ml
Test 1.1s: val_loss: 60.30913 - diff: 20.67ml

Epoch 60: current best loss = 52.39338, at epoch 47
Train batch 1/31 - 237.9ms/batch - loss: 41.37510 - diff: 20.71mlTrain batch 2/31 - 240.1ms/batch - loss: 72.11208 - diff: 22.49mlTrain batch 3/31 - 237.7ms/batch - loss: 60.95980 - diff: 21.07mlTrain batch 4/31 - 240.3ms/batch - loss: 54.88351 - diff: 19.42mlTrain batch 5/31 - 237.8ms/batch - loss: 50.97223 - diff: 19.01mlTrain batch 6/31 - 240.1ms/batch - loss: 60.23164 - diff: 20.23mlTrain batch 7/31 - 239.1ms/batch - loss: 57.63457 - diff: 20.05mlTrain batch 8/31 - 240.4ms/batch - loss: 55.81776 - diff: 19.81mlTrain batch 9/31 - 240.9ms/batch - loss: 58.33822 - diff: 20.76mlTrain batch 10/31 - 238.2ms/batch - loss: 60.79494 - diff: 21.71mlTrain batch 11/31 - 237.9ms/batch - loss: 60.36848 - diff: 21.83mlTrain batch 12/31 - 240.1ms/batch - loss: 66.10239 - diff: 22.74mlTrain batch 13/31 - 237.9ms/batch - loss: 64.99766 - diff: 22.62mlTrain batch 14/31 - 240.1ms/batch - loss: 62.87246 - diff: 22.58mlTrain batch 15/31 - 236.9ms/batch - loss: 60.67831 - diff: 22.36mlTrain batch 16/31 - 242.0ms/batch - loss: 59.93640 - diff: 22.34mlTrain batch 17/31 - 237.9ms/batch - loss: 58.63061 - diff: 22.33mlTrain batch 18/31 - 239.4ms/batch - loss: 57.96169 - diff: 22.39mlTrain batch 19/31 - 237.7ms/batch - loss: 56.17754 - diff: 22.06mlTrain batch 20/31 - 240.2ms/batch - loss: 54.52678 - diff: 21.79mlTrain batch 21/31 - 237.8ms/batch - loss: 55.31926 - diff: 22.09mlTrain batch 22/31 - 240.3ms/batch - loss: 57.86200 - diff: 22.41mlTrain batch 23/31 - 237.5ms/batch - loss: 56.73626 - diff: 22.16mlTrain batch 24/31 - 239.8ms/batch - loss: 56.54439 - diff: 21.93mlTrain batch 25/31 - 238.4ms/batch - loss: 57.23854 - diff: 21.95mlTrain batch 26/31 - 240.2ms/batch - loss: 59.87081 - diff: 22.22mlTrain batch 27/31 - 238.2ms/batch - loss: 59.14379 - diff: 22.18mlTrain batch 28/31 - 240.3ms/batch - loss: 59.24257 - diff: 22.29mlTrain batch 29/31 - 238.6ms/batch - loss: 58.77812 - diff: 22.21mlTrain batch 30/31 - 239.9ms/batch - loss: 71.59084 - diff: 22.75mlTrain batch 31/31 - 124.7ms/batch - loss: 70.98252 - diff: 22.60mlTrain batch 31/31 - 11.2s 124.7ms/batch - loss: 70.98252 - diff: 22.60ml
Test 1.1s: val_loss: 70.99343 - diff: 25.44ml

Epoch 61: current best loss = 52.39338, at epoch 47
Train batch 1/31 - 237.1ms/batch - loss: 432.33386 - diff: 32.70mlTrain batch 2/31 - 237.6ms/batch - loss: 232.22701 - diff: 24.63mlTrain batch 3/31 - 237.7ms/batch - loss: 188.99234 - diff: 26.50mlTrain batch 4/31 - 240.1ms/batch - loss: 156.08093 - diff: 25.98mlTrain batch 5/31 - 237.6ms/batch - loss: 134.49632 - diff: 24.64mlTrain batch 6/31 - 240.4ms/batch - loss: 120.39014 - diff: 24.79mlTrain batch 7/31 - 237.9ms/batch - loss: 105.26166 - diff: 23.11mlTrain batch 8/31 - 238.6ms/batch - loss: 97.70318 - diff: 22.83mlTrain batch 9/31 - 238.0ms/batch - loss: 101.35127 - diff: 24.41mlTrain batch 10/31 - 239.8ms/batch - loss: 94.69153 - diff: 23.83mlTrain batch 11/31 - 237.3ms/batch - loss: 91.27408 - diff: 23.87mlTrain batch 12/31 - 239.5ms/batch - loss: 90.08980 - diff: 24.16mlTrain batch 13/31 - 237.5ms/batch - loss: 93.58333 - diff: 25.08mlTrain batch 14/31 - 240.1ms/batch - loss: 93.82471 - diff: 25.51mlTrain batch 15/31 - 238.6ms/batch - loss: 90.54265 - diff: 25.20mlTrain batch 16/31 - 240.1ms/batch - loss: 87.16897 - diff: 24.96mlTrain batch 17/31 - 237.9ms/batch - loss: 85.36907 - diff: 24.93mlTrain batch 18/31 - 240.3ms/batch - loss: 82.06066 - diff: 24.46mlTrain batch 19/31 - 238.7ms/batch - loss: 78.92712 - diff: 24.02mlTrain batch 20/31 - 239.7ms/batch - loss: 78.21557 - diff: 23.86mlTrain batch 21/31 - 237.6ms/batch - loss: 78.19686 - diff: 23.91mlTrain batch 22/31 - 239.9ms/batch - loss: 76.02460 - diff: 23.64mlTrain batch 23/31 - 237.7ms/batch - loss: 74.83637 - diff: 23.49mlTrain batch 24/31 - 240.4ms/batch - loss: 75.43940 - diff: 23.61mlTrain batch 25/31 - 237.9ms/batch - loss: 73.19870 - diff: 23.22mlTrain batch 26/31 - 240.1ms/batch - loss: 71.53458 - diff: 22.98mlTrain batch 27/31 - 237.7ms/batch - loss: 69.94062 - diff: 22.74mlTrain batch 28/31 - 240.1ms/batch - loss: 69.65162 - diff: 22.74mlTrain batch 29/31 - 237.8ms/batch - loss: 69.83913 - diff: 22.75mlTrain batch 30/31 - 240.2ms/batch - loss: 69.28925 - diff: 22.80mlTrain batch 31/31 - 124.4ms/batch - loss: 68.72438 - diff: 22.62mlTrain batch 31/31 - 11.3s 124.4ms/batch - loss: 68.72438 - diff: 22.62ml
Test 1.1s: val_loss: 55.93939 - diff: 19.28ml

Epoch 62: current best loss = 52.39338, at epoch 47
Train batch 1/31 - 237.0ms/batch - loss: 332.60080 - diff: 32.03mlTrain batch 2/31 - 237.9ms/batch - loss: 192.07998 - diff: 26.73mlTrain batch 3/31 - 237.9ms/batch - loss: 137.72639 - diff: 23.29mlTrain batch 4/31 - 240.3ms/batch - loss: 121.49898 - diff: 23.28mlTrain batch 5/31 - 238.2ms/batch - loss: 108.54484 - diff: 22.88mlTrain batch 6/31 - 240.3ms/batch - loss: 106.12700 - diff: 23.79mlTrain batch 7/31 - 237.7ms/batch - loss: 96.51053 - diff: 23.09mlTrain batch 8/31 - 240.0ms/batch - loss: 92.03398 - diff: 23.38mlTrain batch 9/31 - 237.9ms/batch - loss: 88.44691 - diff: 23.60mlTrain batch 10/31 - 240.3ms/batch - loss: 85.73445 - diff: 23.33mlTrain batch 11/31 - 237.6ms/batch - loss: 81.03359 - diff: 22.94mlTrain batch 12/31 - 240.0ms/batch - loss: 81.69965 - diff: 23.45mlTrain batch 13/31 - 238.4ms/batch - loss: 76.82821 - diff: 22.64mlTrain batch 14/31 - 240.3ms/batch - loss: 76.29487 - diff: 22.86mlTrain batch 15/31 - 238.5ms/batch - loss: 77.20413 - diff: 23.39mlTrain batch 16/31 - 239.9ms/batch - loss: 77.18435 - diff: 23.54mlTrain batch 17/31 - 238.9ms/batch - loss: 76.00707 - diff: 23.45mlTrain batch 18/31 - 239.8ms/batch - loss: 74.07628 - diff: 23.28mlTrain batch 19/31 - 237.8ms/batch - loss: 73.39420 - diff: 23.23mlTrain batch 20/31 - 240.0ms/batch - loss: 71.95108 - diff: 23.00mlTrain batch 21/31 - 238.9ms/batch - loss: 69.36575 - diff: 22.63mlTrain batch 22/31 - 240.0ms/batch - loss: 69.03665 - diff: 22.79mlTrain batch 23/31 - 237.6ms/batch - loss: 69.27821 - diff: 22.91mlTrain batch 24/31 - 239.4ms/batch - loss: 67.85596 - diff: 22.78mlTrain batch 25/31 - 237.5ms/batch - loss: 67.64415 - diff: 22.77mlTrain batch 26/31 - 240.4ms/batch - loss: 65.88066 - diff: 22.52mlTrain batch 27/31 - 238.1ms/batch - loss: 64.82069 - diff: 22.42mlTrain batch 28/31 - 240.3ms/batch - loss: 64.43017 - diff: 22.48mlTrain batch 29/31 - 238.0ms/batch - loss: 63.93663 - diff: 22.54mlTrain batch 30/31 - 239.6ms/batch - loss: 69.04474 - diff: 22.96mlTrain batch 31/31 - 124.6ms/batch - loss: 70.88484 - diff: 22.97mlTrain batch 31/31 - 10.8s 124.6ms/batch - loss: 70.88484 - diff: 22.97ml
Test 1.1s: val_loss: 58.68924 - diff: 18.94ml

Epoch 63: current best loss = 52.39338, at epoch 47
Train batch 1/31 - 236.8ms/batch - loss: 71.57675 - diff: 27.10mlTrain batch 2/31 - 240.0ms/batch - loss: 50.50194 - diff: 22.36mlTrain batch 3/31 - 238.5ms/batch - loss: 40.23111 - diff: 20.11mlTrain batch 4/31 - 239.7ms/batch - loss: 37.36790 - diff: 18.87mlTrain batch 5/31 - 238.0ms/batch - loss: 37.25858 - diff: 19.08mlTrain batch 6/31 - 240.3ms/batch - loss: 36.11092 - diff: 18.70mlTrain batch 7/31 - 238.5ms/batch - loss: 35.34258 - diff: 18.49mlTrain batch 8/31 - 239.4ms/batch - loss: 91.15361 - diff: 21.01mlTrain batch 9/31 - 237.9ms/batch - loss: 82.79698 - diff: 20.13mlTrain batch 10/31 - 240.1ms/batch - loss: 81.78274 - diff: 20.69mlTrain batch 11/31 - 237.8ms/batch - loss: 79.82989 - diff: 20.91mlTrain batch 12/31 - 239.5ms/batch - loss: 80.06745 - diff: 21.36mlTrain batch 13/31 - 238.2ms/batch - loss: 76.59809 - diff: 21.23mlTrain batch 14/31 - 240.3ms/batch - loss: 73.78942 - diff: 21.08mlTrain batch 15/31 - 237.9ms/batch - loss: 73.02500 - diff: 21.22mlTrain batch 16/31 - 240.1ms/batch - loss: 72.12400 - diff: 21.42mlTrain batch 17/31 - 238.1ms/batch - loss: 69.52734 - diff: 21.15mlTrain batch 18/31 - 240.1ms/batch - loss: 70.34628 - diff: 21.26mlTrain batch 19/31 - 238.5ms/batch - loss: 68.76432 - diff: 21.09mlTrain batch 20/31 - 239.8ms/batch - loss: 68.14885 - diff: 21.16mlTrain batch 21/31 - 237.9ms/batch - loss: 66.29220 - diff: 21.01mlTrain batch 22/31 - 239.7ms/batch - loss: 64.31712 - diff: 20.73mlTrain batch 23/31 - 238.3ms/batch - loss: 66.47350 - diff: 21.13mlTrain batch 24/31 - 240.3ms/batch - loss: 64.95158 - diff: 20.93mlTrain batch 25/31 - 237.7ms/batch - loss: 65.97849 - diff: 21.26mlTrain batch 26/31 - 240.3ms/batch - loss: 66.20514 - diff: 21.24mlTrain batch 27/31 - 237.6ms/batch - loss: 65.50237 - diff: 21.22mlTrain batch 28/31 - 239.8ms/batch - loss: 65.98952 - diff: 21.26mlTrain batch 29/31 - 238.4ms/batch - loss: 66.24716 - diff: 21.34mlTrain batch 30/31 - 240.2ms/batch - loss: 66.41614 - diff: 21.27mlTrain batch 31/31 - 124.2ms/batch - loss: 67.70755 - diff: 21.34mlTrain batch 31/31 - 11.1s 124.2ms/batch - loss: 67.70755 - diff: 21.34ml
Test 1.1s: val_loss: 66.24590 - diff: 24.46ml

Epoch 64: current best loss = 52.39338, at epoch 47
Train batch 1/31 - 237.2ms/batch - loss: 29.54773 - diff: 17.03mlTrain batch 2/31 - 237.6ms/batch - loss: 37.91106 - diff: 18.65mlTrain batch 3/31 - 244.2ms/batch - loss: 124.73037 - diff: 23.70mlTrain batch 4/31 - 239.4ms/batch - loss: 109.63354 - diff: 23.62mlTrain batch 5/31 - 237.6ms/batch - loss: 102.91470 - diff: 23.71mlTrain batch 6/31 - 240.2ms/batch - loss: 90.11535 - diff: 22.45mlTrain batch 7/31 - 238.3ms/batch - loss: 83.02684 - diff: 22.04mlTrain batch 8/31 - 240.2ms/batch - loss: 79.48041 - diff: 22.07mlTrain batch 9/31 - 238.2ms/batch - loss: 77.07960 - diff: 22.06mlTrain batch 10/31 - 240.3ms/batch - loss: 73.60827 - diff: 21.63mlTrain batch 11/31 - 238.0ms/batch - loss: 71.07697 - diff: 21.43mlTrain batch 12/31 - 239.5ms/batch - loss: 75.75531 - diff: 21.74mlTrain batch 13/31 - 237.5ms/batch - loss: 74.39087 - diff: 21.69mlTrain batch 14/31 - 240.3ms/batch - loss: 71.28742 - diff: 21.39mlTrain batch 15/31 - 238.1ms/batch - loss: 69.93244 - diff: 21.48mlTrain batch 16/31 - 240.2ms/batch - loss: 68.88579 - diff: 21.62mlTrain batch 17/31 - 238.4ms/batch - loss: 71.41850 - diff: 22.32mlTrain batch 18/31 - 237.7ms/batch - loss: 72.59971 - diff: 22.89mlTrain batch 19/31 - 240.4ms/batch - loss: 72.53635 - diff: 23.01mlTrain batch 20/31 - 238.9ms/batch - loss: 71.74158 - diff: 23.04mlTrain batch 21/31 - 239.9ms/batch - loss: 69.52988 - diff: 22.72mlTrain batch 22/31 - 237.5ms/batch - loss: 69.44394 - diff: 22.71mlTrain batch 23/31 - 239.7ms/batch - loss: 69.05471 - diff: 22.68mlTrain batch 24/31 - 237.8ms/batch - loss: 68.79513 - diff: 22.80mlTrain batch 25/31 - 240.0ms/batch - loss: 67.18201 - diff: 22.53mlTrain batch 26/31 - 238.3ms/batch - loss: 67.14312 - diff: 22.32mlTrain batch 27/31 - 240.2ms/batch - loss: 67.79001 - diff: 22.29mlTrain batch 28/31 - 237.8ms/batch - loss: 66.88694 - diff: 22.19mlTrain batch 29/31 - 240.1ms/batch - loss: 65.73152 - diff: 22.07mlTrain batch 30/31 - 238.7ms/batch - loss: 65.97857 - diff: 22.20mlTrain batch 31/31 - 124.6ms/batch - loss: 65.44556 - diff: 22.05mlTrain batch 31/31 - 11.0s 124.6ms/batch - loss: 65.44556 - diff: 22.05ml
Test 1.1s: val_loss: 53.66254 - diff: 20.59ml

Epoch 65: current best loss = 52.39338, at epoch 47
Train batch 1/31 - 237.5ms/batch - loss: 112.33231 - diff: 32.19mlTrain batch 2/31 - 240.3ms/batch - loss: 85.60527 - diff: 27.36mlTrain batch 3/31 - 237.7ms/batch - loss: 68.12772 - diff: 23.53mlTrain batch 4/31 - 239.6ms/batch - loss: 57.16169 - diff: 21.39mlTrain batch 5/31 - 237.5ms/batch - loss: 54.55530 - diff: 21.21mlTrain batch 6/31 - 240.1ms/batch - loss: 49.84825 - diff: 20.33mlTrain batch 7/31 - 237.9ms/batch - loss: 51.57806 - diff: 20.43mlTrain batch 8/31 - 240.2ms/batch - loss: 55.85808 - diff: 21.33mlTrain batch 9/31 - 237.6ms/batch - loss: 58.52621 - diff: 21.80mlTrain batch 10/31 - 240.4ms/batch - loss: 55.28306 - diff: 21.38mlTrain batch 11/31 - 238.4ms/batch - loss: 53.62358 - diff: 21.08mlTrain batch 12/31 - 240.2ms/batch - loss: 53.57339 - diff: 21.08mlTrain batch 13/31 - 238.4ms/batch - loss: 54.94393 - diff: 21.26mlTrain batch 14/31 - 240.3ms/batch - loss: 52.40065 - diff: 20.80mlTrain batch 15/31 - 237.7ms/batch - loss: 51.34717 - diff: 20.50mlTrain batch 16/31 - 239.6ms/batch - loss: 52.03599 - diff: 20.75mlTrain batch 17/31 - 238.9ms/batch - loss: 52.39292 - diff: 20.90mlTrain batch 18/31 - 240.0ms/batch - loss: 51.49234 - diff: 20.90mlTrain batch 19/31 - 237.9ms/batch - loss: 51.93663 - diff: 20.91mlTrain batch 20/31 - 240.1ms/batch - loss: 60.04945 - diff: 21.77mlTrain batch 21/31 - 238.9ms/batch - loss: 58.80093 - diff: 21.67mlTrain batch 22/31 - 240.3ms/batch - loss: 57.15377 - diff: 21.35mlTrain batch 23/31 - 238.6ms/batch - loss: 56.84005 - diff: 21.21mlTrain batch 24/31 - 240.0ms/batch - loss: 56.44561 - diff: 21.18mlTrain batch 25/31 - 237.5ms/batch - loss: 55.05912 - diff: 20.90mlTrain batch 26/31 - 240.1ms/batch - loss: 70.95097 - diff: 21.82mlTrain batch 27/31 - 237.9ms/batch - loss: 69.26607 - diff: 21.66mlTrain batch 28/31 - 240.0ms/batch - loss: 68.08041 - diff: 21.58mlTrain batch 29/31 - 238.3ms/batch - loss: 66.48210 - diff: 21.36mlTrain batch 30/31 - 240.3ms/batch - loss: 66.02814 - diff: 21.28mlTrain batch 31/31 - 124.5ms/batch - loss: 66.99659 - diff: 21.31mlTrain batch 31/31 - 10.8s 124.5ms/batch - loss: 66.99659 - diff: 21.31ml
Test 1.1s: val_loss: 54.97289 - diff: 19.77ml

Epoch 66: current best loss = 52.39338, at epoch 47
Train batch 1/31 - 238.0ms/batch - loss: 17.36107 - diff: 13.68mlTrain batch 2/31 - 238.6ms/batch - loss: 32.16734 - diff: 18.08mlTrain batch 3/31 - 239.2ms/batch - loss: 32.08522 - diff: 17.50mlTrain batch 4/31 - 242.6ms/batch - loss: 140.11299 - diff: 26.48mlTrain batch 5/31 - 238.4ms/batch - loss: 121.55425 - diff: 25.49mlTrain batch 6/31 - 237.9ms/batch - loss: 117.66139 - diff: 25.89mlTrain batch 7/31 - 240.2ms/batch - loss: 103.90904 - diff: 24.37mlTrain batch 8/31 - 238.2ms/batch - loss: 95.54022 - diff: 23.78mlTrain batch 9/31 - 238.3ms/batch - loss: 94.46981 - diff: 24.31mlTrain batch 10/31 - 238.8ms/batch - loss: 89.26362 - diff: 23.94mlTrain batch 11/31 - 240.2ms/batch - loss: 84.47430 - diff: 23.73mlTrain batch 12/31 - 238.1ms/batch - loss: 82.19248 - diff: 23.87mlTrain batch 13/31 - 239.1ms/batch - loss: 79.33919 - diff: 23.49mlTrain batch 14/31 - 238.6ms/batch - loss: 77.37081 - diff: 23.46mlTrain batch 15/31 - 238.1ms/batch - loss: 77.64000 - diff: 23.71mlTrain batch 16/31 - 240.8ms/batch - loss: 75.53651 - diff: 23.41mlTrain batch 17/31 - 238.8ms/batch - loss: 73.07431 - diff: 23.09mlTrain batch 18/31 - 238.5ms/batch - loss: 71.55548 - diff: 22.98mlTrain batch 19/31 - 237.5ms/batch - loss: 69.49092 - diff: 22.72mlTrain batch 20/31 - 240.2ms/batch - loss: 66.66054 - diff: 22.17mlTrain batch 21/31 - 238.7ms/batch - loss: 64.47850 - diff: 21.80mlTrain batch 22/31 - 240.0ms/batch - loss: 64.64581 - diff: 22.03mlTrain batch 23/31 - 238.1ms/batch - loss: 62.98203 - diff: 21.78mlTrain batch 24/31 - 240.0ms/batch - loss: 61.19600 - diff: 21.46mlTrain batch 25/31 - 238.2ms/batch - loss: 60.15809 - diff: 21.17mlTrain batch 26/31 - 239.6ms/batch - loss: 58.53668 - diff: 20.89mlTrain batch 27/31 - 248.3ms/batch - loss: 57.10514 - diff: 20.65mlTrain batch 28/31 - 238.2ms/batch - loss: 57.47964 - diff: 20.69mlTrain batch 29/31 - 238.2ms/batch - loss: 56.38428 - diff: 20.50mlTrain batch 30/31 - 240.2ms/batch - loss: 60.22201 - diff: 21.15mlTrain batch 31/31 - 124.4ms/batch - loss: 66.26912 - diff: 21.35mlTrain batch 31/31 - 11.3s 124.4ms/batch - loss: 66.26912 - diff: 21.35ml
Test 1.1s: val_loss: 98.31759 - diff: 27.39ml

Epoch 67: current best loss = 52.39338, at epoch 47
Train batch 1/31 - 237.8ms/batch - loss: 34.59738 - diff: 15.63mlTrain batch 2/31 - 240.2ms/batch - loss: 37.22792 - diff: 16.81mlTrain batch 3/31 - 237.9ms/batch - loss: 49.93773 - diff: 19.99mlTrain batch 4/31 - 238.7ms/batch - loss: 46.38533 - diff: 19.13mlTrain batch 5/31 - 238.2ms/batch - loss: 43.90778 - diff: 19.02mlTrain batch 6/31 - 238.8ms/batch - loss: 53.13435 - diff: 20.32mlTrain batch 7/31 - 238.2ms/batch - loss: 99.52858 - diff: 22.86mlTrain batch 8/31 - 238.7ms/batch - loss: 92.79761 - diff: 22.78mlTrain batch 9/31 - 237.6ms/batch - loss: 85.97786 - diff: 22.15mlTrain batch 10/31 - 240.2ms/batch - loss: 84.11882 - diff: 22.72mlTrain batch 11/31 - 237.8ms/batch - loss: 85.17277 - diff: 23.23mlTrain batch 12/31 - 241.2ms/batch - loss: 81.34513 - diff: 22.82mlTrain batch 13/31 - 237.3ms/batch - loss: 78.13236 - diff: 22.55mlTrain batch 14/31 - 237.7ms/batch - loss: 74.75045 - diff: 22.25mlTrain batch 15/31 - 237.2ms/batch - loss: 76.61334 - diff: 22.78mlTrain batch 16/31 - 240.2ms/batch - loss: 74.77102 - diff: 22.89mlTrain batch 17/31 - 236.9ms/batch - loss: 72.66441 - diff: 22.69mlTrain batch 18/31 - 238.4ms/batch - loss: 70.93587 - diff: 22.53mlTrain batch 19/31 - 237.3ms/batch - loss: 71.77574 - diff: 22.58mlTrain batch 20/31 - 239.8ms/batch - loss: 68.64180 - diff: 21.93mlTrain batch 21/31 - 237.6ms/batch - loss: 67.32478 - diff: 21.84mlTrain batch 22/31 - 239.5ms/batch - loss: 66.75838 - diff: 21.68mlTrain batch 23/31 - 237.8ms/batch - loss: 66.22118 - diff: 21.67mlTrain batch 24/31 - 239.7ms/batch - loss: 64.80602 - diff: 21.55mlTrain batch 25/31 - 237.8ms/batch - loss: 65.76879 - diff: 21.76mlTrain batch 26/31 - 238.2ms/batch - loss: 64.34989 - diff: 21.59mlTrain batch 27/31 - 237.5ms/batch - loss: 63.14065 - diff: 21.48mlTrain batch 28/31 - 238.1ms/batch - loss: 63.77315 - diff: 21.60mlTrain batch 29/31 - 238.1ms/batch - loss: 62.36846 - diff: 21.41mlTrain batch 30/31 - 239.5ms/batch - loss: 61.37659 - diff: 21.31mlTrain batch 31/31 - 124.6ms/batch - loss: 62.86680 - diff: 21.37mlTrain batch 31/31 - 12.8s 124.6ms/batch - loss: 62.86680 - diff: 21.37ml
Test 1.1s: val_loss: 56.22858 - diff: 19.55ml

Epoch 68: current best loss = 52.39338, at epoch 47
Train batch 1/31 - 237.0ms/batch - loss: 30.18800 - diff: 19.22mlTrain batch 2/31 - 240.2ms/batch - loss: 38.20222 - diff: 21.07mlTrain batch 3/31 - 238.0ms/batch - loss: 42.15464 - diff: 20.45mlTrain batch 4/31 - 238.5ms/batch - loss: 53.00371 - diff: 22.09mlTrain batch 5/31 - 237.9ms/batch - loss: 46.95290 - diff: 20.28mlTrain batch 6/31 - 245.5ms/batch - loss: 49.51742 - diff: 20.59mlTrain batch 7/31 - 237.8ms/batch - loss: 120.68859 - diff: 25.70mlTrain batch 8/31 - 237.9ms/batch - loss: 113.54658 - diff: 25.00mlTrain batch 9/31 - 238.1ms/batch - loss: 102.79660 - diff: 23.72mlTrain batch 10/31 - 238.3ms/batch - loss: 95.48522 - diff: 23.06mlTrain batch 11/31 - 238.2ms/batch - loss: 95.17000 - diff: 23.51mlTrain batch 12/31 - 237.5ms/batch - loss: 90.64007 - diff: 23.30mlTrain batch 13/31 - 240.3ms/batch - loss: 85.55609 - diff: 22.83mlTrain batch 14/31 - 237.5ms/batch - loss: 83.92456 - diff: 22.83mlTrain batch 15/31 - 237.9ms/batch - loss: 83.39685 - diff: 22.90mlTrain batch 16/31 - 237.4ms/batch - loss: 79.87433 - diff: 22.54mlTrain batch 17/31 - 237.3ms/batch - loss: 76.94728 - diff: 22.33mlTrain batch 18/31 - 237.8ms/batch - loss: 75.61574 - diff: 22.21mlTrain batch 19/31 - 239.3ms/batch - loss: 74.41566 - diff: 22.08mlTrain batch 20/31 - 237.8ms/batch - loss: 73.56766 - diff: 22.03mlTrain batch 21/31 - 238.5ms/batch - loss: 73.05858 - diff: 22.14mlTrain batch 22/31 - 237.5ms/batch - loss: 72.43833 - diff: 22.29mlTrain batch 23/31 - 239.7ms/batch - loss: 74.18010 - diff: 22.60mlTrain batch 24/31 - 237.7ms/batch - loss: 73.11384 - diff: 22.56mlTrain batch 25/31 - 239.0ms/batch - loss: 71.93809 - diff: 22.55mlTrain batch 26/31 - 238.0ms/batch - loss: 70.30399 - diff: 22.27mlTrain batch 27/31 - 238.7ms/batch - loss: 70.42514 - diff: 22.40mlTrain batch 28/31 - 237.8ms/batch - loss: 69.51447 - diff: 22.27mlTrain batch 29/31 - 239.4ms/batch - loss: 68.21158 - diff: 22.17mlTrain batch 30/31 - 237.9ms/batch - loss: 66.60227 - diff: 21.90mlTrain batch 31/31 - 124.9ms/batch - loss: 66.53327 - diff: 21.84mlTrain batch 31/31 - 11.7s 124.9ms/batch - loss: 66.53327 - diff: 21.84ml
Test 1.1s: val_loss: 61.04323 - diff: 22.87ml

Epoch 69: current best loss = 52.39338, at epoch 47
Train batch 1/31 - 237.2ms/batch - loss: 22.47448 - diff: 13.28mlTrain batch 2/31 - 236.8ms/batch - loss: 25.15493 - diff: 13.86mlTrain batch 3/31 - 238.7ms/batch - loss: 26.66631 - diff: 14.95mlTrain batch 4/31 - 241.8ms/batch - loss: 57.86813 - diff: 18.95mlTrain batch 5/31 - 237.6ms/batch - loss: 50.68098 - diff: 18.25mlTrain batch 6/31 - 240.0ms/batch - loss: 51.06326 - diff: 18.78mlTrain batch 7/31 - 238.3ms/batch - loss: 50.78099 - diff: 19.06mlTrain batch 8/31 - 238.1ms/batch - loss: 53.03834 - diff: 19.59mlTrain batch 9/31 - 239.8ms/batch - loss: 49.77889 - diff: 19.11mlTrain batch 10/31 - 241.3ms/batch - loss: 77.55370 - diff: 21.00mlTrain batch 11/31 - 237.4ms/batch - loss: 75.52032 - diff: 21.32mlTrain batch 12/31 - 240.3ms/batch - loss: 71.15028 - diff: 20.83mlTrain batch 13/31 - 247.5ms/batch - loss: 71.12904 - diff: 21.14mlTrain batch 14/31 - 238.3ms/batch - loss: 71.27735 - diff: 21.31mlTrain batch 15/31 - 242.3ms/batch - loss: 68.43493 - diff: 20.99mlTrain batch 16/31 - 237.8ms/batch - loss: 65.57068 - diff: 20.58mlTrain batch 17/31 - 240.8ms/batch - loss: 64.24310 - diff: 20.46mlTrain batch 18/31 - 240.3ms/batch - loss: 64.49495 - diff: 20.64mlTrain batch 19/31 - 237.9ms/batch - loss: 63.66263 - diff: 20.72mlTrain batch 20/31 - 240.1ms/batch - loss: 62.97752 - diff: 20.88mlTrain batch 21/31 - 237.5ms/batch - loss: 63.90862 - diff: 21.05mlTrain batch 22/31 - 240.2ms/batch - loss: 62.73612 - diff: 20.94mlTrain batch 23/31 - 237.6ms/batch - loss: 62.99354 - diff: 21.19mlTrain batch 24/31 - 240.0ms/batch - loss: 62.01768 - diff: 21.18mlTrain batch 25/31 - 243.5ms/batch - loss: 61.08090 - diff: 21.08mlTrain batch 26/31 - 240.2ms/batch - loss: 60.37986 - diff: 21.04mlTrain batch 27/31 - 237.9ms/batch - loss: 60.30942 - diff: 21.20mlTrain batch 28/31 - 239.1ms/batch - loss: 58.93694 - diff: 21.00mlTrain batch 29/31 - 238.7ms/batch - loss: 58.80658 - diff: 21.10mlTrain batch 30/31 - 238.9ms/batch - loss: 59.76387 - diff: 21.24mlTrain batch 31/31 - 124.9ms/batch - loss: 62.57991 - diff: 21.26mlTrain batch 31/31 - 10.9s 124.9ms/batch - loss: 62.57991 - diff: 21.26ml
Test 1.1s: val_loss: 69.03485 - diff: 24.35ml
Epoch    70: reducing learning rate of group 0 to 2.5000e-04.

Epoch 70: current best loss = 52.39338, at epoch 47
Train batch 1/31 - 237.0ms/batch - loss: 252.53516 - diff: 27.64mlTrain batch 2/31 - 237.9ms/batch - loss: 155.30579 - diff: 24.17mlTrain batch 3/31 - 238.3ms/batch - loss: 135.42828 - diff: 23.64mlTrain batch 4/31 - 240.1ms/batch - loss: 107.71863 - diff: 21.16mlTrain batch 5/31 - 238.5ms/batch - loss: 96.28529 - diff: 21.18mlTrain batch 6/31 - 237.5ms/batch - loss: 86.85061 - diff: 21.01mlTrain batch 7/31 - 239.5ms/batch - loss: 80.22927 - diff: 20.92mlTrain batch 8/31 - 237.4ms/batch - loss: 73.52613 - diff: 20.30mlTrain batch 9/31 - 242.3ms/batch - loss: 69.14204 - diff: 20.01mlTrain batch 10/31 - 236.9ms/batch - loss: 67.26470 - diff: 20.01mlTrain batch 11/31 - 240.0ms/batch - loss: 63.60712 - diff: 19.72mlTrain batch 12/31 - 236.8ms/batch - loss: 60.23606 - diff: 19.44mlTrain batch 13/31 - 238.7ms/batch - loss: 57.15082 - diff: 19.07mlTrain batch 14/31 - 236.7ms/batch - loss: 56.72128 - diff: 19.25mlTrain batch 15/31 - 238.4ms/batch - loss: 56.19761 - diff: 19.40mlTrain batch 16/31 - 237.6ms/batch - loss: 55.18276 - diff: 19.54mlTrain batch 17/31 - 239.9ms/batch - loss: 54.65411 - diff: 19.86mlTrain batch 18/31 - 237.8ms/batch - loss: 54.30307 - diff: 19.88mlTrain batch 19/31 - 238.0ms/batch - loss: 53.65040 - diff: 20.06mlTrain batch 20/31 - 237.1ms/batch - loss: 51.80700 - diff: 19.70mlTrain batch 21/31 - 238.2ms/batch - loss: 51.60943 - diff: 19.75mlTrain batch 22/31 - 237.8ms/batch - loss: 51.75079 - diff: 19.76mlTrain batch 23/31 - 238.6ms/batch - loss: 52.94077 - diff: 19.91mlTrain batch 24/31 - 237.4ms/batch - loss: 51.72534 - diff: 19.80mlTrain batch 25/31 - 240.2ms/batch - loss: 50.25606 - diff: 19.56mlTrain batch 26/31 - 238.4ms/batch - loss: 50.91150 - diff: 19.48mlTrain batch 27/31 - 240.1ms/batch - loss: 52.57597 - diff: 19.71mlTrain batch 28/31 - 237.9ms/batch - loss: 52.28626 - diff: 19.75mlTrain batch 29/31 - 238.7ms/batch - loss: 51.93859 - diff: 19.69mlTrain batch 30/31 - 237.9ms/batch - loss: 53.14244 - diff: 19.79mlTrain batch 31/31 - 123.0ms/batch - loss: 56.50152 - diff: 19.95mlTrain batch 31/31 - 12.1s 123.0ms/batch - loss: 56.50152 - diff: 19.95ml
Test 1.1s: val_loss: 54.48963 - diff: 18.55ml

Epoch 71: current best loss = 52.39338, at epoch 47
Train batch 1/31 - 236.9ms/batch - loss: 69.86008 - diff: 23.98mlTrain batch 2/31 - 241.2ms/batch - loss: 60.10043 - diff: 21.94mlTrain batch 3/31 - 243.6ms/batch - loss: 56.92367 - diff: 21.22mlTrain batch 4/31 - 238.7ms/batch - loss: 53.50505 - diff: 21.02mlTrain batch 5/31 - 237.3ms/batch - loss: 50.05133 - diff: 20.78mlTrain batch 6/31 - 237.8ms/batch - loss: 47.24448 - diff: 20.45mlTrain batch 7/31 - 241.1ms/batch - loss: 48.53444 - diff: 21.17mlTrain batch 8/31 - 238.8ms/batch - loss: 49.33159 - diff: 21.19mlTrain batch 9/31 - 237.9ms/batch - loss: 48.45196 - diff: 20.99mlTrain batch 10/31 - 238.1ms/batch - loss: 45.94117 - diff: 20.40mlTrain batch 11/31 - 237.9ms/batch - loss: 44.73355 - diff: 20.20mlTrain batch 12/31 - 239.7ms/batch - loss: 42.99547 - diff: 19.85mlTrain batch 13/31 - 237.8ms/batch - loss: 44.86167 - diff: 20.21mlTrain batch 14/31 - 238.0ms/batch - loss: 46.12984 - diff: 20.46mlTrain batch 15/31 - 240.0ms/batch - loss: 47.47043 - diff: 20.67mlTrain batch 16/31 - 239.4ms/batch - loss: 48.68139 - diff: 20.72mlTrain batch 17/31 - 237.8ms/batch - loss: 47.37123 - diff: 20.39mlTrain batch 18/31 - 237.5ms/batch - loss: 48.03400 - diff: 20.56mlTrain batch 19/31 - 239.4ms/batch - loss: 47.03226 - diff: 20.43mlTrain batch 20/31 - 237.4ms/batch - loss: 46.22110 - diff: 20.31mlTrain batch 21/31 - 240.0ms/batch - loss: 46.53737 - diff: 20.55mlTrain batch 22/31 - 237.9ms/batch - loss: 46.66686 - diff: 20.50mlTrain batch 23/31 - 238.9ms/batch - loss: 46.67509 - diff: 20.53mlTrain batch 24/31 - 238.0ms/batch - loss: 45.32221 - diff: 20.24mlTrain batch 25/31 - 238.6ms/batch - loss: 44.83814 - diff: 20.08mlTrain batch 26/31 - 237.4ms/batch - loss: 57.87014 - diff: 21.14mlTrain batch 27/31 - 239.7ms/batch - loss: 56.29363 - diff: 20.81mlTrain batch 28/31 - 237.8ms/batch - loss: 55.38951 - diff: 20.71mlTrain batch 29/31 - 240.2ms/batch - loss: 54.37879 - diff: 20.62mlTrain batch 30/31 - 237.8ms/batch - loss: 54.63664 - diff: 20.68mlTrain batch 31/31 - 124.3ms/batch - loss: 54.62439 - diff: 20.61mlTrain batch 31/31 - 11.7s 124.3ms/batch - loss: 54.62439 - diff: 20.61ml
Test 1.1s: val_loss: 53.70812 - diff: 20.87ml

Epoch 72: current best loss = 52.39338, at epoch 47
Train batch 1/31 - 237.2ms/batch - loss: 37.75584 - diff: 19.73mlTrain batch 2/31 - 237.8ms/batch - loss: 25.76977 - diff: 16.04mlTrain batch 3/31 - 238.0ms/batch - loss: 24.51873 - diff: 16.19mlTrain batch 4/31 - 240.0ms/batch - loss: 32.35158 - diff: 16.93mlTrain batch 5/31 - 237.8ms/batch - loss: 31.49539 - diff: 17.01mlTrain batch 6/31 - 240.1ms/batch - loss: 31.16990 - diff: 16.82mlTrain batch 7/31 - 238.2ms/batch - loss: 43.85785 - diff: 18.12mlTrain batch 8/31 - 237.9ms/batch - loss: 55.14332 - diff: 18.74mlTrain batch 9/31 - 239.4ms/batch - loss: 53.46043 - diff: 18.77mlTrain batch 10/31 - 237.5ms/batch - loss: 49.81455 - diff: 18.25mlTrain batch 11/31 - 239.8ms/batch - loss: 47.36591 - diff: 18.03mlTrain batch 12/31 - 239.4ms/batch - loss: 48.62270 - diff: 18.48mlTrain batch 13/31 - 238.4ms/batch - loss: 46.38065 - diff: 18.03mlTrain batch 14/31 - 237.9ms/batch - loss: 48.74456 - diff: 18.72mlTrain batch 15/31 - 238.5ms/batch - loss: 51.13343 - diff: 19.08mlTrain batch 16/31 - 238.0ms/batch - loss: 51.40895 - diff: 19.29mlTrain batch 17/31 - 237.9ms/batch - loss: 49.74613 - diff: 19.01mlTrain batch 18/31 - 240.1ms/batch - loss: 48.82227 - diff: 18.82mlTrain batch 19/31 - 237.9ms/batch - loss: 50.68488 - diff: 19.29mlTrain batch 20/31 - 240.4ms/batch - loss: 50.43456 - diff: 19.41mlTrain batch 21/31 - 243.2ms/batch - loss: 50.40644 - diff: 19.45mlTrain batch 22/31 - 237.7ms/batch - loss: 49.92329 - diff: 19.39mlTrain batch 23/31 - 237.3ms/batch - loss: 49.93122 - diff: 19.38mlTrain batch 24/31 - 237.9ms/batch - loss: 49.00289 - diff: 19.29mlTrain batch 25/31 - 237.5ms/batch - loss: 48.02258 - diff: 19.16mlTrain batch 26/31 - 239.8ms/batch - loss: 47.31635 - diff: 19.12mlTrain batch 27/31 - 237.9ms/batch - loss: 49.54368 - diff: 19.45mlTrain batch 28/31 - 239.0ms/batch - loss: 48.90250 - diff: 19.30mlTrain batch 29/31 - 238.4ms/batch - loss: 48.33540 - diff: 19.26mlTrain batch 30/31 - 239.7ms/batch - loss: 48.42200 - diff: 19.36mlTrain batch 31/31 - 124.7ms/batch - loss: 48.48175 - diff: 19.29mlTrain batch 31/31 - 10.9s 124.7ms/batch - loss: 48.48175 - diff: 19.29ml
Test 1.1s: val_loss: 50.99217 - diff: 18.62ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Systole_WideResNet50_0_Adam-0.001_MSE_DA3_best

Epoch 73: current best loss = 50.99217, at epoch 72
Train batch 1/31 - 236.8ms/batch - loss: 19.42715 - diff: 13.75mlTrain batch 2/31 - 237.2ms/batch - loss: 26.64714 - diff: 17.06mlTrain batch 3/31 - 237.1ms/batch - loss: 23.66033 - diff: 15.86mlTrain batch 4/31 - 239.4ms/batch - loss: 24.91098 - diff: 16.17mlTrain batch 5/31 - 237.0ms/batch - loss: 25.19942 - diff: 15.60mlTrain batch 6/31 - 238.2ms/batch - loss: 30.56703 - diff: 16.89mlTrain batch 7/31 - 238.3ms/batch - loss: 28.74657 - diff: 16.37mlTrain batch 8/31 - 237.8ms/batch - loss: 26.61646 - diff: 15.68mlTrain batch 9/31 - 240.1ms/batch - loss: 27.71592 - diff: 15.83mlTrain batch 10/31 - 241.9ms/batch - loss: 29.79963 - diff: 16.43mlTrain batch 11/31 - 238.5ms/batch - loss: 33.43857 - diff: 17.07mlTrain batch 12/31 - 238.4ms/batch - loss: 32.29824 - diff: 16.81mlTrain batch 13/31 - 240.0ms/batch - loss: 33.37840 - diff: 17.14mlTrain batch 14/31 - 237.7ms/batch - loss: 33.72405 - diff: 17.18mlTrain batch 15/31 - 240.2ms/batch - loss: 39.01255 - diff: 17.76mlTrain batch 16/31 - 237.3ms/batch - loss: 38.23257 - diff: 17.63mlTrain batch 17/31 - 237.4ms/batch - loss: 37.25785 - diff: 17.44mlTrain batch 18/31 - 238.0ms/batch - loss: 39.18700 - diff: 17.89mlTrain batch 19/31 - 239.0ms/batch - loss: 38.56576 - diff: 17.75mlTrain batch 20/31 - 237.3ms/batch - loss: 38.23383 - diff: 17.72mlTrain batch 21/31 - 238.1ms/batch - loss: 38.88248 - diff: 17.96mlTrain batch 22/31 - 237.9ms/batch - loss: 38.76107 - diff: 18.04mlTrain batch 23/31 - 239.9ms/batch - loss: 38.03797 - diff: 17.95mlTrain batch 24/31 - 237.4ms/batch - loss: 39.83339 - diff: 18.37mlTrain batch 25/31 - 240.3ms/batch - loss: 40.41559 - diff: 18.63mlTrain batch 26/31 - 237.4ms/batch - loss: 42.12052 - diff: 18.90mlTrain batch 27/31 - 239.7ms/batch - loss: 42.53407 - diff: 19.05mlTrain batch 28/31 - 238.5ms/batch - loss: 42.09164 - diff: 19.00mlTrain batch 29/31 - 240.0ms/batch - loss: 41.82853 - diff: 19.05mlTrain batch 30/31 - 238.3ms/batch - loss: 41.72787 - diff: 19.10mlTrain batch 31/31 - 123.9ms/batch - loss: 43.19962 - diff: 19.20mlTrain batch 31/31 - 11.5s 123.9ms/batch - loss: 43.19962 - diff: 19.20ml
Test 1.2s: val_loss: 49.87038 - diff: 18.81ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Systole_WideResNet50_0_Adam-0.001_MSE_DA3_best

Epoch 74: current best loss = 49.87038, at epoch 73
Train batch 1/31 - 236.7ms/batch - loss: 233.66602 - diff: 40.02mlTrain batch 2/31 - 237.3ms/batch - loss: 140.75146 - diff: 32.19mlTrain batch 3/31 - 237.0ms/batch - loss: 152.52305 - diff: 33.43mlTrain batch 4/31 - 237.4ms/batch - loss: 125.00718 - diff: 30.23mlTrain batch 5/31 - 237.0ms/batch - loss: 103.56917 - diff: 26.88mlTrain batch 6/31 - 237.3ms/batch - loss: 91.32313 - diff: 25.36mlTrain batch 7/31 - 237.3ms/batch - loss: 80.00032 - diff: 23.26mlTrain batch 8/31 - 237.4ms/batch - loss: 73.53419 - diff: 22.56mlTrain batch 9/31 - 236.8ms/batch - loss: 68.19034 - diff: 21.72mlTrain batch 10/31 - 238.7ms/batch - loss: 64.18274 - diff: 21.31mlTrain batch 11/31 - 237.0ms/batch - loss: 60.59720 - diff: 20.96mlTrain batch 12/31 - 238.3ms/batch - loss: 58.96090 - diff: 21.01mlTrain batch 13/31 - 237.2ms/batch - loss: 58.64217 - diff: 20.84mlTrain batch 14/31 - 238.0ms/batch - loss: 57.09550 - diff: 20.47mlTrain batch 15/31 - 236.7ms/batch - loss: 56.19731 - diff: 20.56mlTrain batch 16/31 - 237.8ms/batch - loss: 54.88491 - diff: 20.24mlTrain batch 17/31 - 237.0ms/batch - loss: 54.69015 - diff: 20.41mlTrain batch 18/31 - 238.1ms/batch - loss: 52.82299 - diff: 20.13mlTrain batch 19/31 - 237.7ms/batch - loss: 51.21837 - diff: 19.82mlTrain batch 20/31 - 238.7ms/batch - loss: 49.88956 - diff: 19.56mlTrain batch 21/31 - 237.2ms/batch - loss: 48.36841 - diff: 19.34mlTrain batch 22/31 - 237.7ms/batch - loss: 48.49607 - diff: 19.38mlTrain batch 23/31 - 237.5ms/batch - loss: 50.04166 - diff: 19.66mlTrain batch 24/31 - 239.8ms/batch - loss: 49.51777 - diff: 19.70mlTrain batch 25/31 - 238.2ms/batch - loss: 50.40187 - diff: 19.92mlTrain batch 26/31 - 239.9ms/batch - loss: 49.70026 - diff: 19.87mlTrain batch 27/31 - 237.0ms/batch - loss: 49.19340 - diff: 19.82mlTrain batch 28/31 - 237.5ms/batch - loss: 49.57351 - diff: 20.00mlTrain batch 29/31 - 237.8ms/batch - loss: 49.60364 - diff: 20.01mlTrain batch 30/31 - 240.0ms/batch - loss: 48.60894 - diff: 19.85mlTrain batch 31/31 - 123.6ms/batch - loss: 48.93279 - diff: 19.84mlTrain batch 31/31 - 12.1s 123.6ms/batch - loss: 48.93279 - diff: 19.84ml
Test 1.1s: val_loss: 96.51829 - diff: 25.69ml

Epoch 75: current best loss = 49.87038, at epoch 73
Train batch 1/31 - 237.0ms/batch - loss: 25.96836 - diff: 17.65mlTrain batch 2/31 - 237.4ms/batch - loss: 27.59829 - diff: 16.52mlTrain batch 3/31 - 237.3ms/batch - loss: 30.93109 - diff: 16.73mlTrain batch 4/31 - 238.0ms/batch - loss: 27.27585 - diff: 15.91mlTrain batch 5/31 - 238.7ms/batch - loss: 27.48706 - diff: 16.18mlTrain batch 6/31 - 240.1ms/batch - loss: 29.72685 - diff: 16.55mlTrain batch 7/31 - 237.0ms/batch - loss: 32.09378 - diff: 16.79mlTrain batch 8/31 - 237.8ms/batch - loss: 36.08531 - diff: 16.92mlTrain batch 9/31 - 237.7ms/batch - loss: 35.86603 - diff: 17.06mlTrain batch 10/31 - 239.1ms/batch - loss: 36.86776 - diff: 17.26mlTrain batch 11/31 - 237.0ms/batch - loss: 37.51243 - diff: 17.70mlTrain batch 12/31 - 237.8ms/batch - loss: 38.76476 - diff: 17.86mlTrain batch 13/31 - 237.5ms/batch - loss: 39.39323 - diff: 18.08mlTrain batch 14/31 - 239.4ms/batch - loss: 38.05023 - diff: 17.89mlTrain batch 15/31 - 238.2ms/batch - loss: 39.26109 - diff: 18.26mlTrain batch 16/31 - 239.3ms/batch - loss: 38.75359 - diff: 18.28mlTrain batch 17/31 - 237.7ms/batch - loss: 37.94231 - diff: 18.12mlTrain batch 18/31 - 239.5ms/batch - loss: 37.78304 - diff: 18.09mlTrain batch 19/31 - 237.3ms/batch - loss: 37.86912 - diff: 18.14mlTrain batch 20/31 - 238.9ms/batch - loss: 36.84338 - diff: 17.90mlTrain batch 21/31 - 237.7ms/batch - loss: 42.69713 - diff: 18.32mlTrain batch 22/31 - 239.7ms/batch - loss: 42.16948 - diff: 18.28mlTrain batch 23/31 - 237.9ms/batch - loss: 41.75575 - diff: 18.24mlTrain batch 24/31 - 238.0ms/batch - loss: 42.66058 - diff: 18.49mlTrain batch 25/31 - 237.3ms/batch - loss: 42.74897 - diff: 18.55mlTrain batch 26/31 - 239.5ms/batch - loss: 42.10257 - diff: 18.52mlTrain batch 27/31 - 237.2ms/batch - loss: 41.52646 - diff: 18.38mlTrain batch 28/31 - 240.4ms/batch - loss: 41.72421 - diff: 18.57mlTrain batch 29/31 - 239.0ms/batch - loss: 41.13964 - diff: 18.40mlTrain batch 30/31 - 238.0ms/batch - loss: 40.44876 - diff: 18.28mlTrain batch 31/31 - 123.0ms/batch - loss: 43.12766 - diff: 18.44mlTrain batch 31/31 - 11.4s 123.0ms/batch - loss: 43.12766 - diff: 18.44ml
Test 1.1s: val_loss: 52.85888 - diff: 18.95ml

Epoch 76: current best loss = 49.87038, at epoch 73
Train batch 1/31 - 237.2ms/batch - loss: 34.90054 - diff: 15.19mlTrain batch 2/31 - 238.6ms/batch - loss: 28.87835 - diff: 15.70mlTrain batch 3/31 - 238.5ms/batch - loss: 77.11179 - diff: 20.65mlTrain batch 4/31 - 239.6ms/batch - loss: 69.64553 - diff: 21.09mlTrain batch 5/31 - 237.8ms/batch - loss: 61.51759 - diff: 20.30mlTrain batch 6/31 - 239.7ms/batch - loss: 55.28730 - diff: 19.47mlTrain batch 7/31 - 237.9ms/batch - loss: 52.76289 - diff: 19.20mlTrain batch 8/31 - 240.1ms/batch - loss: 50.31065 - diff: 19.02mlTrain batch 9/31 - 238.2ms/batch - loss: 46.39102 - diff: 18.27mlTrain batch 10/31 - 237.8ms/batch - loss: 44.11612 - diff: 18.04mlTrain batch 11/31 - 239.9ms/batch - loss: 40.97342 - diff: 17.35mlTrain batch 12/31 - 238.3ms/batch - loss: 40.71996 - diff: 17.57mlTrain batch 13/31 - 237.6ms/batch - loss: 38.74309 - diff: 17.21mlTrain batch 14/31 - 237.3ms/batch - loss: 40.40838 - diff: 17.64mlTrain batch 15/31 - 237.7ms/batch - loss: 39.19632 - diff: 17.40mlTrain batch 16/31 - 237.9ms/batch - loss: 38.88294 - diff: 17.48mlTrain batch 17/31 - 237.1ms/batch - loss: 38.91478 - diff: 17.50mlTrain batch 18/31 - 241.5ms/batch - loss: 40.90825 - diff: 17.73mlTrain batch 19/31 - 238.1ms/batch - loss: 42.44271 - diff: 18.20mlTrain batch 20/31 - 239.9ms/batch - loss: 42.12037 - diff: 18.33mlTrain batch 21/31 - 237.5ms/batch - loss: 41.80767 - diff: 18.33mlTrain batch 22/31 - 239.0ms/batch - loss: 41.51518 - diff: 18.27mlTrain batch 23/31 - 237.8ms/batch - loss: 42.23076 - diff: 18.41mlTrain batch 24/31 - 239.8ms/batch - loss: 41.13876 - diff: 18.15mlTrain batch 25/31 - 237.4ms/batch - loss: 40.98714 - diff: 18.22mlTrain batch 26/31 - 240.3ms/batch - loss: 40.35793 - diff: 18.10mlTrain batch 27/31 - 238.6ms/batch - loss: 40.28469 - diff: 18.20mlTrain batch 28/31 - 239.5ms/batch - loss: 39.94300 - diff: 18.15mlTrain batch 29/31 - 237.8ms/batch - loss: 40.04190 - diff: 18.26mlTrain batch 30/31 - 240.2ms/batch - loss: 39.98594 - diff: 18.33mlTrain batch 31/31 - 124.5ms/batch - loss: 40.72043 - diff: 18.39mlTrain batch 31/31 - 11.3s 124.5ms/batch - loss: 40.72043 - diff: 18.39ml
Test 1.1s: val_loss: 49.44600 - diff: 20.91ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Systole_WideResNet50_0_Adam-0.001_MSE_DA3_best

Epoch 77: current best loss = 49.44600, at epoch 76
Train batch 1/31 - 252.7ms/batch - loss: 22.49400 - diff: 14.70mlTrain batch 2/31 - 237.4ms/batch - loss: 27.00519 - diff: 15.71mlTrain batch 3/31 - 237.2ms/batch - loss: 24.47207 - diff: 14.64mlTrain batch 4/31 - 238.1ms/batch - loss: 33.20182 - diff: 16.07mlTrain batch 5/31 - 238.0ms/batch - loss: 33.20019 - diff: 16.68mlTrain batch 6/31 - 238.0ms/batch - loss: 33.40016 - diff: 17.07mlTrain batch 7/31 - 237.3ms/batch - loss: 36.23668 - diff: 17.32mlTrain batch 8/31 - 236.5ms/batch - loss: 35.44971 - diff: 17.39mlTrain batch 9/31 - 241.2ms/batch - loss: 38.67420 - diff: 18.32mlTrain batch 10/31 - 238.3ms/batch - loss: 38.88028 - diff: 18.61mlTrain batch 11/31 - 237.3ms/batch - loss: 38.52295 - diff: 18.77mlTrain batch 12/31 - 238.0ms/batch - loss: 38.87045 - diff: 19.04mlTrain batch 13/31 - 237.9ms/batch - loss: 38.36973 - diff: 18.99mlTrain batch 14/31 - 238.8ms/batch - loss: 40.03613 - diff: 19.17mlTrain batch 15/31 - 237.2ms/batch - loss: 39.52520 - diff: 19.18mlTrain batch 16/31 - 239.9ms/batch - loss: 40.97593 - diff: 19.52mlTrain batch 17/31 - 237.4ms/batch - loss: 41.45278 - diff: 19.79mlTrain batch 18/31 - 238.3ms/batch - loss: 41.42863 - diff: 19.90mlTrain batch 19/31 - 237.6ms/batch - loss: 40.60975 - diff: 19.58mlTrain batch 20/31 - 240.2ms/batch - loss: 47.66131 - diff: 20.04mlTrain batch 21/31 - 237.6ms/batch - loss: 46.76378 - diff: 19.84mlTrain batch 22/31 - 239.0ms/batch - loss: 45.72138 - diff: 19.62mlTrain batch 23/31 - 237.8ms/batch - loss: 44.95480 - diff: 19.45mlTrain batch 24/31 - 238.8ms/batch - loss: 43.73806 - diff: 19.11mlTrain batch 25/31 - 238.0ms/batch - loss: 43.50928 - diff: 19.15mlTrain batch 26/31 - 240.1ms/batch - loss: 42.76330 - diff: 19.01mlTrain batch 27/31 - 238.5ms/batch - loss: 42.56292 - diff: 18.92mlTrain batch 28/31 - 238.5ms/batch - loss: 42.01635 - diff: 18.89mlTrain batch 29/31 - 237.5ms/batch - loss: 41.60330 - diff: 18.89mlTrain batch 30/31 - 240.1ms/batch - loss: 40.87133 - diff: 18.77mlTrain batch 31/31 - 124.7ms/batch - loss: 41.21410 - diff: 18.75mlTrain batch 31/31 - 11.6s 124.7ms/batch - loss: 41.21410 - diff: 18.75ml
Test 1.1s: val_loss: 49.01108 - diff: 19.81ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Systole_WideResNet50_0_Adam-0.001_MSE_DA3_best

Epoch 78: current best loss = 49.01108, at epoch 77
Train batch 1/31 - 237.2ms/batch - loss: 61.50492 - diff: 24.21mlTrain batch 2/31 - 237.8ms/batch - loss: 55.95398 - diff: 21.65mlTrain batch 3/31 - 237.4ms/batch - loss: 44.88272 - diff: 18.77mlTrain batch 4/31 - 237.6ms/batch - loss: 37.68090 - diff: 17.05mlTrain batch 5/31 - 237.5ms/batch - loss: 42.15009 - diff: 17.84mlTrain batch 6/31 - 239.0ms/batch - loss: 41.49123 - diff: 17.95mlTrain batch 7/31 - 237.8ms/batch - loss: 38.37738 - diff: 17.45mlTrain batch 8/31 - 237.5ms/batch - loss: 50.50024 - diff: 19.18mlTrain batch 9/31 - 237.4ms/batch - loss: 48.28272 - diff: 18.90mlTrain batch 10/31 - 237.8ms/batch - loss: 47.42240 - diff: 19.05mlTrain batch 11/31 - 237.5ms/batch - loss: 45.87696 - diff: 18.95mlTrain batch 12/31 - 238.6ms/batch - loss: 44.56483 - diff: 18.83mlTrain batch 13/31 - 237.8ms/batch - loss: 45.80859 - diff: 19.22mlTrain batch 14/31 - 237.7ms/batch - loss: 45.65944 - diff: 19.35mlTrain batch 15/31 - 237.4ms/batch - loss: 44.87164 - diff: 19.20mlTrain batch 16/31 - 237.5ms/batch - loss: 44.44510 - diff: 19.14mlTrain batch 17/31 - 237.3ms/batch - loss: 44.54167 - diff: 19.27mlTrain batch 18/31 - 239.3ms/batch - loss: 43.88204 - diff: 18.99mlTrain batch 19/31 - 238.0ms/batch - loss: 42.55185 - diff: 18.70mlTrain batch 20/31 - 238.6ms/batch - loss: 42.96069 - diff: 18.94mlTrain batch 21/31 - 237.6ms/batch - loss: 44.21615 - diff: 19.20mlTrain batch 22/31 - 237.4ms/batch - loss: 44.09801 - diff: 19.14mlTrain batch 23/31 - 237.9ms/batch - loss: 43.32499 - diff: 19.01mlTrain batch 24/31 - 237.5ms/batch - loss: 42.19778 - diff: 18.80mlTrain batch 25/31 - 237.4ms/batch - loss: 43.84359 - diff: 18.92mlTrain batch 26/31 - 238.0ms/batch - loss: 43.54773 - diff: 18.88mlTrain batch 27/31 - 237.8ms/batch - loss: 42.75361 - diff: 18.67mlTrain batch 28/31 - 237.6ms/batch - loss: 42.67417 - diff: 18.64mlTrain batch 29/31 - 237.9ms/batch - loss: 42.39913 - diff: 18.56mlTrain batch 30/31 - 238.0ms/batch - loss: 41.93867 - diff: 18.49mlTrain batch 31/31 - 124.7ms/batch - loss: 42.59242 - diff: 18.52mlTrain batch 31/31 - 11.6s 124.7ms/batch - loss: 42.59242 - diff: 18.52ml
Test 1.1s: val_loss: 45.83447 - diff: 18.17ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Systole_WideResNet50_0_Adam-0.001_MSE_DA3_best

Epoch 79: current best loss = 45.83447, at epoch 78
Train batch 1/31 - 237.0ms/batch - loss: 71.66354 - diff: 21.97mlTrain batch 2/31 - 237.4ms/batch - loss: 60.30763 - diff: 22.29mlTrain batch 3/31 - 237.5ms/batch - loss: 66.85322 - diff: 23.83mlTrain batch 4/31 - 238.0ms/batch - loss: 63.06714 - diff: 22.85mlTrain batch 5/31 - 237.7ms/batch - loss: 56.28395 - diff: 21.63mlTrain batch 6/31 - 238.8ms/batch - loss: 52.13247 - diff: 21.00mlTrain batch 7/31 - 237.5ms/batch - loss: 48.18111 - diff: 20.41mlTrain batch 8/31 - 237.7ms/batch - loss: 48.35775 - diff: 20.63mlTrain batch 9/31 - 238.2ms/batch - loss: 44.65477 - diff: 19.71mlTrain batch 10/31 - 237.9ms/batch - loss: 45.24829 - diff: 19.74mlTrain batch 11/31 - 237.8ms/batch - loss: 44.92369 - diff: 19.74mlTrain batch 12/31 - 239.5ms/batch - loss: 43.59040 - diff: 19.41mlTrain batch 13/31 - 238.0ms/batch - loss: 41.75961 - diff: 19.04mlTrain batch 14/31 - 239.8ms/batch - loss: 40.32053 - diff: 18.78mlTrain batch 15/31 - 237.4ms/batch - loss: 40.11807 - diff: 18.63mlTrain batch 16/31 - 238.7ms/batch - loss: 41.12069 - diff: 18.71mlTrain batch 17/31 - 237.9ms/batch - loss: 40.31645 - diff: 18.56mlTrain batch 18/31 - 239.5ms/batch - loss: 38.56699 - diff: 18.03mlTrain batch 19/31 - 237.3ms/batch - loss: 37.62635 - diff: 17.96mlTrain batch 20/31 - 238.8ms/batch - loss: 39.08721 - diff: 18.34mlTrain batch 21/31 - 237.8ms/batch - loss: 38.57852 - diff: 18.23mlTrain batch 22/31 - 240.1ms/batch - loss: 38.34480 - diff: 18.25mlTrain batch 23/31 - 238.4ms/batch - loss: 37.41329 - diff: 18.08mlTrain batch 24/31 - 238.2ms/batch - loss: 36.60335 - diff: 17.91mlTrain batch 25/31 - 237.6ms/batch - loss: 35.99587 - diff: 17.69mlTrain batch 26/31 - 240.0ms/batch - loss: 44.73180 - diff: 18.55mlTrain batch 27/31 - 237.6ms/batch - loss: 43.83003 - diff: 18.35mlTrain batch 28/31 - 239.9ms/batch - loss: 43.51762 - diff: 18.35mlTrain batch 29/31 - 238.2ms/batch - loss: 43.39904 - diff: 18.40mlTrain batch 30/31 - 239.7ms/batch - loss: 42.78235 - diff: 18.30mlTrain batch 31/31 - 123.6ms/batch - loss: 43.69104 - diff: 18.37mlTrain batch 31/31 - 10.5s 123.6ms/batch - loss: 43.69104 - diff: 18.37ml
Test 1.1s: val_loss: 45.51403 - diff: 19.42ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Systole_WideResNet50_0_Adam-0.001_MSE_DA3_best

Epoch 80: current best loss = 45.51403, at epoch 79
Train batch 1/31 - 237.2ms/batch - loss: 13.10245 - diff: 8.91mlTrain batch 2/31 - 237.6ms/batch - loss: 22.97381 - diff: 12.82mlTrain batch 3/31 - 237.6ms/batch - loss: 18.40275 - diff: 12.11mlTrain batch 4/31 - 237.6ms/batch - loss: 18.32361 - diff: 12.49mlTrain batch 5/31 - 237.4ms/batch - loss: 19.37264 - diff: 12.97mlTrain batch 6/31 - 237.5ms/batch - loss: 23.16742 - diff: 14.20mlTrain batch 7/31 - 237.8ms/batch - loss: 24.11001 - diff: 14.68mlTrain batch 8/31 - 237.4ms/batch - loss: 24.36858 - diff: 14.63mlTrain batch 9/31 - 237.9ms/batch - loss: 23.96716 - diff: 14.70mlTrain batch 10/31 - 237.4ms/batch - loss: 24.70717 - diff: 15.09mlTrain batch 11/31 - 237.8ms/batch - loss: 24.73327 - diff: 15.14mlTrain batch 12/31 - 239.2ms/batch - loss: 23.98648 - diff: 14.99mlTrain batch 13/31 - 237.2ms/batch - loss: 23.76376 - diff: 14.87mlTrain batch 14/31 - 239.3ms/batch - loss: 27.21115 - diff: 15.42mlTrain batch 15/31 - 237.3ms/batch - loss: 26.49694 - diff: 15.14mlTrain batch 16/31 - 238.0ms/batch - loss: 26.68788 - diff: 15.26mlTrain batch 17/31 - 237.8ms/batch - loss: 27.41827 - diff: 15.47mlTrain batch 18/31 - 237.7ms/batch - loss: 27.73221 - diff: 15.55mlTrain batch 19/31 - 237.5ms/batch - loss: 30.77368 - diff: 15.99mlTrain batch 20/31 - 240.1ms/batch - loss: 32.85236 - diff: 16.43mlTrain batch 21/31 - 238.2ms/batch - loss: 32.26239 - diff: 16.31mlTrain batch 22/31 - 240.0ms/batch - loss: 34.27193 - diff: 16.76mlTrain batch 23/31 - 237.7ms/batch - loss: 33.69441 - diff: 16.63mlTrain batch 24/31 - 238.4ms/batch - loss: 33.61880 - diff: 16.63mlTrain batch 25/31 - 237.8ms/batch - loss: 34.87674 - diff: 16.89mlTrain batch 26/31 - 238.8ms/batch - loss: 37.28247 - diff: 17.32mlTrain batch 27/31 - 238.0ms/batch - loss: 37.31425 - diff: 17.35mlTrain batch 28/31 - 240.1ms/batch - loss: 36.92719 - diff: 17.36mlTrain batch 29/31 - 238.6ms/batch - loss: 37.21474 - diff: 17.41mlTrain batch 30/31 - 239.5ms/batch - loss: 37.26454 - diff: 17.42mlTrain batch 31/31 - 124.2ms/batch - loss: 40.05763 - diff: 17.60mlTrain batch 31/31 - 11.7s 124.2ms/batch - loss: 40.05763 - diff: 17.60ml
Test 1.1s: val_loss: 45.25720 - diff: 18.80ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Systole_WideResNet50_0_Adam-0.001_MSE_DA3_best

Epoch 81: current best loss = 45.25720, at epoch 80
Train batch 1/31 - 236.4ms/batch - loss: 31.79652 - diff: 19.15mlTrain batch 2/31 - 237.0ms/batch - loss: 32.88717 - diff: 18.21mlTrain batch 3/31 - 237.6ms/batch - loss: 33.28915 - diff: 18.00mlTrain batch 4/31 - 236.7ms/batch - loss: 29.48799 - diff: 17.11mlTrain batch 5/31 - 237.6ms/batch - loss: 38.44286 - diff: 18.31mlTrain batch 6/31 - 237.9ms/batch - loss: 37.13218 - diff: 18.05mlTrain batch 7/31 - 237.3ms/batch - loss: 39.72823 - diff: 18.83mlTrain batch 8/31 - 237.8ms/batch - loss: 39.77640 - diff: 19.20mlTrain batch 9/31 - 237.5ms/batch - loss: 37.48451 - diff: 18.69mlTrain batch 10/31 - 239.3ms/batch - loss: 40.80539 - diff: 19.12mlTrain batch 11/31 - 238.0ms/batch - loss: 38.25381 - diff: 18.48mlTrain batch 12/31 - 239.9ms/batch - loss: 36.40762 - diff: 18.05mlTrain batch 13/31 - 238.7ms/batch - loss: 34.92643 - diff: 17.72mlTrain batch 14/31 - 239.3ms/batch - loss: 35.11491 - diff: 17.92mlTrain batch 15/31 - 238.5ms/batch - loss: 34.10393 - diff: 17.73mlTrain batch 16/31 - 237.6ms/batch - loss: 35.86304 - diff: 17.79mlTrain batch 17/31 - 238.6ms/batch - loss: 35.10309 - diff: 17.67mlTrain batch 18/31 - 237.7ms/batch - loss: 34.69336 - diff: 17.61mlTrain batch 19/31 - 237.8ms/batch - loss: 34.66191 - diff: 17.75mlTrain batch 20/31 - 237.9ms/batch - loss: 34.38134 - diff: 17.66mlTrain batch 21/31 - 237.8ms/batch - loss: 35.36921 - diff: 17.84mlTrain batch 22/31 - 238.4ms/batch - loss: 35.31526 - diff: 17.92mlTrain batch 23/31 - 237.7ms/batch - loss: 34.40174 - diff: 17.65mlTrain batch 24/31 - 238.4ms/batch - loss: 34.57514 - diff: 17.67mlTrain batch 25/31 - 238.1ms/batch - loss: 34.87707 - diff: 17.72mlTrain batch 26/31 - 238.3ms/batch - loss: 40.01620 - diff: 18.20mlTrain batch 27/31 - 238.1ms/batch - loss: 39.50071 - diff: 18.18mlTrain batch 28/31 - 237.7ms/batch - loss: 39.41740 - diff: 18.07mlTrain batch 29/31 - 237.8ms/batch - loss: 38.68359 - diff: 17.91mlTrain batch 30/31 - 237.8ms/batch - loss: 39.15070 - diff: 18.02mlTrain batch 31/31 - 124.7ms/batch - loss: 39.28395 - diff: 17.92mlTrain batch 31/31 - 10.9s 124.7ms/batch - loss: 39.28395 - diff: 17.92ml
Test 1.1s: val_loss: 55.15918 - diff: 20.28ml

Epoch 82: current best loss = 45.25720, at epoch 80
Train batch 1/31 - 236.6ms/batch - loss: 60.51049 - diff: 22.14mlTrain batch 2/31 - 237.1ms/batch - loss: 64.78159 - diff: 24.24mlTrain batch 3/31 - 238.3ms/batch - loss: 48.45132 - diff: 20.12mlTrain batch 4/31 - 240.1ms/batch - loss: 39.95395 - diff: 18.28mlTrain batch 5/31 - 238.4ms/batch - loss: 37.80294 - diff: 18.52mlTrain batch 6/31 - 237.8ms/batch - loss: 34.80738 - diff: 17.84mlTrain batch 7/31 - 239.0ms/batch - loss: 33.80221 - diff: 17.99mlTrain batch 8/31 - 237.3ms/batch - loss: 34.85498 - diff: 18.45mlTrain batch 9/31 - 240.1ms/batch - loss: 34.87450 - diff: 18.30mlTrain batch 10/31 - 237.2ms/batch - loss: 34.17893 - diff: 18.17mlTrain batch 11/31 - 237.5ms/batch - loss: 33.47330 - diff: 18.02mlTrain batch 12/31 - 237.8ms/batch - loss: 32.95521 - diff: 17.85mlTrain batch 13/31 - 237.8ms/batch - loss: 31.65838 - diff: 17.45mlTrain batch 14/31 - 237.4ms/batch - loss: 31.63399 - diff: 17.45mlTrain batch 15/31 - 238.3ms/batch - loss: 31.32489 - diff: 17.34mlTrain batch 16/31 - 237.3ms/batch - loss: 31.25184 - diff: 17.09mlTrain batch 17/31 - 239.3ms/batch - loss: 30.88421 - diff: 16.97mlTrain batch 18/31 - 238.4ms/batch - loss: 32.75614 - diff: 17.22mlTrain batch 19/31 - 238.7ms/batch - loss: 33.58862 - diff: 17.29mlTrain batch 20/31 - 237.9ms/batch - loss: 32.67731 - diff: 17.04mlTrain batch 21/31 - 237.6ms/batch - loss: 32.73390 - diff: 17.02mlTrain batch 22/31 - 237.5ms/batch - loss: 39.28746 - diff: 18.20mlTrain batch 23/31 - 240.1ms/batch - loss: 39.56644 - diff: 18.31mlTrain batch 24/31 - 237.9ms/batch - loss: 39.25410 - diff: 18.26mlTrain batch 25/31 - 240.0ms/batch - loss: 39.38065 - diff: 18.37mlTrain batch 26/31 - 237.5ms/batch - loss: 39.30931 - diff: 18.40mlTrain batch 27/31 - 239.2ms/batch - loss: 38.59171 - diff: 18.23mlTrain batch 28/31 - 238.1ms/batch - loss: 39.73203 - diff: 18.39mlTrain batch 29/31 - 240.0ms/batch - loss: 41.25303 - diff: 18.59mlTrain batch 30/31 - 237.3ms/batch - loss: 45.32107 - diff: 18.88mlTrain batch 31/31 - 122.3ms/batch - loss: 45.76319 - diff: 18.85mlTrain batch 31/31 - 11.6s 122.3ms/batch - loss: 45.76319 - diff: 18.85ml
Test 1.1s: val_loss: 89.14866 - diff: 27.32ml

Epoch 83: current best loss = 45.25720, at epoch 80
Train batch 1/31 - 237.0ms/batch - loss: 21.67443 - diff: 15.11mlTrain batch 2/31 - 238.9ms/batch - loss: 34.19420 - diff: 17.79mlTrain batch 3/31 - 237.8ms/batch - loss: 41.66719 - diff: 19.61mlTrain batch 4/31 - 237.9ms/batch - loss: 41.14154 - diff: 18.88mlTrain batch 5/31 - 237.3ms/batch - loss: 39.14994 - diff: 18.75mlTrain batch 6/31 - 240.1ms/batch - loss: 35.69216 - diff: 17.84mlTrain batch 7/31 - 237.7ms/batch - loss: 34.06601 - diff: 17.46mlTrain batch 8/31 - 238.9ms/batch - loss: 34.98074 - diff: 17.15mlTrain batch 9/31 - 238.2ms/batch - loss: 34.97783 - diff: 17.31mlTrain batch 10/31 - 240.0ms/batch - loss: 34.20330 - diff: 17.42mlTrain batch 11/31 - 237.7ms/batch - loss: 32.73710 - diff: 17.11mlTrain batch 12/31 - 239.1ms/batch - loss: 32.39106 - diff: 17.06mlTrain batch 13/31 - 238.3ms/batch - loss: 53.42477 - diff: 19.64mlTrain batch 14/31 - 239.9ms/batch - loss: 52.01923 - diff: 19.52mlTrain batch 15/31 - 237.6ms/batch - loss: 49.96970 - diff: 19.19mlTrain batch 16/31 - 240.3ms/batch - loss: 49.37962 - diff: 19.27mlTrain batch 17/31 - 238.2ms/batch - loss: 48.17882 - diff: 19.20mlTrain batch 18/31 - 240.0ms/batch - loss: 47.02239 - diff: 18.98mlTrain batch 19/31 - 237.4ms/batch - loss: 46.66382 - diff: 19.06mlTrain batch 20/31 - 239.9ms/batch - loss: 48.39668 - diff: 19.47mlTrain batch 21/31 - 237.7ms/batch - loss: 46.85371 - diff: 19.14mlTrain batch 22/31 - 238.9ms/batch - loss: 47.29941 - diff: 19.25mlTrain batch 23/31 - 238.6ms/batch - loss: 46.64737 - diff: 19.21mlTrain batch 24/31 - 239.9ms/batch - loss: 46.64795 - diff: 19.24mlTrain batch 25/31 - 237.6ms/batch - loss: 45.59814 - diff: 18.99mlTrain batch 26/31 - 237.6ms/batch - loss: 45.03698 - diff: 18.93mlTrain batch 27/31 - 238.5ms/batch - loss: 44.77047 - diff: 18.91mlTrain batch 28/31 - 238.8ms/batch - loss: 44.54396 - diff: 18.89mlTrain batch 29/31 - 237.5ms/batch - loss: 43.64336 - diff: 18.64mlTrain batch 30/31 - 237.4ms/batch - loss: 43.66463 - diff: 18.65mlTrain batch 31/31 - 124.7ms/batch - loss: 44.98859 - diff: 18.69mlTrain batch 31/31 - 10.9s 124.7ms/batch - loss: 44.98859 - diff: 18.69ml
Test 1.1s: val_loss: 57.19605 - diff: 18.94ml

Epoch 84: current best loss = 45.25720, at epoch 80
Train batch 1/31 - 237.0ms/batch - loss: 14.51782 - diff: 12.69mlTrain batch 2/31 - 240.1ms/batch - loss: 20.69165 - diff: 14.12mlTrain batch 3/31 - 237.9ms/batch - loss: 19.43254 - diff: 14.22mlTrain batch 4/31 - 240.2ms/batch - loss: 36.50482 - diff: 16.69mlTrain batch 5/31 - 237.4ms/batch - loss: 33.97698 - diff: 16.50mlTrain batch 6/31 - 238.0ms/batch - loss: 33.87251 - diff: 16.72mlTrain batch 7/31 - 237.5ms/batch - loss: 34.69242 - diff: 17.25mlTrain batch 8/31 - 239.7ms/batch - loss: 34.83870 - diff: 17.44mlTrain batch 9/31 - 237.9ms/batch - loss: 32.97354 - diff: 17.03mlTrain batch 10/31 - 237.9ms/batch - loss: 33.38755 - diff: 17.34mlTrain batch 11/31 - 237.8ms/batch - loss: 32.02886 - diff: 16.98mlTrain batch 12/31 - 239.2ms/batch - loss: 33.17351 - diff: 17.45mlTrain batch 13/31 - 237.8ms/batch - loss: 34.95623 - diff: 17.94mlTrain batch 14/31 - 240.1ms/batch - loss: 36.30850 - diff: 18.41mlTrain batch 15/31 - 237.7ms/batch - loss: 37.37669 - diff: 18.32mlTrain batch 16/31 - 239.3ms/batch - loss: 36.88680 - diff: 18.25mlTrain batch 17/31 - 237.6ms/batch - loss: 36.80378 - diff: 18.14mlTrain batch 18/31 - 240.2ms/batch - loss: 36.12975 - diff: 17.98mlTrain batch 19/31 - 237.5ms/batch - loss: 35.95131 - diff: 17.92mlTrain batch 20/31 - 240.2ms/batch - loss: 35.36293 - diff: 17.82mlTrain batch 21/31 - 237.4ms/batch - loss: 35.57931 - diff: 17.87mlTrain batch 22/31 - 240.3ms/batch - loss: 36.04235 - diff: 18.02mlTrain batch 23/31 - 237.9ms/batch - loss: 35.27744 - diff: 17.75mlTrain batch 24/31 - 239.9ms/batch - loss: 37.22705 - diff: 18.21mlTrain batch 25/31 - 237.7ms/batch - loss: 36.31371 - diff: 17.95mlTrain batch 26/31 - 240.0ms/batch - loss: 36.03494 - diff: 17.96mlTrain batch 27/31 - 238.2ms/batch - loss: 36.00631 - diff: 18.08mlTrain batch 28/31 - 240.0ms/batch - loss: 35.11526 - diff: 17.83mlTrain batch 29/31 - 237.6ms/batch - loss: 34.44158 - diff: 17.63mlTrain batch 30/31 - 240.1ms/batch - loss: 34.44413 - diff: 17.74mlTrain batch 31/31 - 125.0ms/batch - loss: 34.26153 - diff: 17.64mlTrain batch 31/31 - 11.3s 125.0ms/batch - loss: 34.26153 - diff: 17.64ml
Test 1.1s: val_loss: 46.68439 - diff: 19.59ml

Epoch 85: current best loss = 45.25720, at epoch 80
Train batch 1/31 - 237.1ms/batch - loss: 37.80225 - diff: 18.84mlTrain batch 2/31 - 239.7ms/batch - loss: 28.79832 - diff: 16.74mlTrain batch 3/31 - 238.6ms/batch - loss: 27.91407 - diff: 16.00mlTrain batch 4/31 - 239.7ms/batch - loss: 29.57059 - diff: 16.90mlTrain batch 5/31 - 238.5ms/batch - loss: 29.46045 - diff: 16.79mlTrain batch 6/31 - 239.5ms/batch - loss: 29.03141 - diff: 16.51mlTrain batch 7/31 - 237.4ms/batch - loss: 28.29334 - diff: 16.52mlTrain batch 8/31 - 239.8ms/batch - loss: 30.22285 - diff: 17.10mlTrain batch 9/31 - 237.7ms/batch - loss: 31.85429 - diff: 17.47mlTrain batch 10/31 - 239.9ms/batch - loss: 30.70408 - diff: 17.28mlTrain batch 11/31 - 237.9ms/batch - loss: 29.75067 - diff: 17.07mlTrain batch 12/31 - 239.0ms/batch - loss: 29.86376 - diff: 17.24mlTrain batch 13/31 - 238.1ms/batch - loss: 31.00392 - diff: 17.29mlTrain batch 14/31 - 238.5ms/batch - loss: 30.58034 - diff: 17.15mlTrain batch 15/31 - 237.9ms/batch - loss: 29.99586 - diff: 17.07mlTrain batch 16/31 - 238.1ms/batch - loss: 39.15758 - diff: 18.33mlTrain batch 17/31 - 238.0ms/batch - loss: 37.69764 - diff: 17.95mlTrain batch 18/31 - 239.3ms/batch - loss: 36.72421 - diff: 17.70mlTrain batch 19/31 - 238.6ms/batch - loss: 36.23029 - diff: 17.61mlTrain batch 20/31 - 237.7ms/batch - loss: 36.20383 - diff: 17.53mlTrain batch 21/31 - 238.9ms/batch - loss: 35.50060 - diff: 17.30mlTrain batch 22/31 - 238.1ms/batch - loss: 35.23418 - diff: 17.33mlTrain batch 23/31 - 237.9ms/batch - loss: 35.92383 - diff: 17.48mlTrain batch 24/31 - 240.2ms/batch - loss: 35.81100 - diff: 17.48mlTrain batch 25/31 - 238.0ms/batch - loss: 35.37517 - diff: 17.44mlTrain batch 26/31 - 240.2ms/batch - loss: 35.57186 - diff: 17.60mlTrain batch 27/31 - 237.6ms/batch - loss: 35.08020 - diff: 17.49mlTrain batch 28/31 - 239.9ms/batch - loss: 36.64002 - diff: 17.77mlTrain batch 29/31 - 238.3ms/batch - loss: 36.04060 - diff: 17.65mlTrain batch 30/31 - 239.9ms/batch - loss: 36.96835 - diff: 17.91mlTrain batch 31/31 - 123.9ms/batch - loss: 38.40134 - diff: 18.08mlTrain batch 31/31 - 10.7s 123.9ms/batch - loss: 38.40134 - diff: 18.08ml
Test 1.1s: val_loss: 45.76526 - diff: 19.22ml

Epoch 86: current best loss = 45.25720, at epoch 80
Train batch 1/31 - 238.7ms/batch - loss: 50.31636 - diff: 22.03mlTrain batch 2/31 - 240.5ms/batch - loss: 39.86044 - diff: 18.89mlTrain batch 3/31 - 237.7ms/batch - loss: 50.56765 - diff: 21.61mlTrain batch 4/31 - 239.6ms/batch - loss: 42.60759 - diff: 19.64mlTrain batch 5/31 - 237.8ms/batch - loss: 40.88199 - diff: 19.75mlTrain batch 6/31 - 240.1ms/batch - loss: 37.78090 - diff: 18.69mlTrain batch 7/31 - 238.6ms/batch - loss: 38.51877 - diff: 18.57mlTrain batch 8/31 - 238.7ms/batch - loss: 35.47870 - diff: 17.76mlTrain batch 9/31 - 238.1ms/batch - loss: 32.84327 - diff: 16.99mlTrain batch 10/31 - 238.7ms/batch - loss: 31.58398 - diff: 16.76mlTrain batch 11/31 - 240.1ms/batch - loss: 30.98367 - diff: 16.62mlTrain batch 12/31 - 237.9ms/batch - loss: 31.34206 - diff: 16.67mlTrain batch 13/31 - 238.6ms/batch - loss: 30.61223 - diff: 16.50mlTrain batch 14/31 - 238.4ms/batch - loss: 30.84188 - diff: 16.61mlTrain batch 15/31 - 240.2ms/batch - loss: 30.76817 - diff: 16.75mlTrain batch 16/31 - 237.9ms/batch - loss: 31.45142 - diff: 16.90mlTrain batch 17/31 - 240.0ms/batch - loss: 31.50214 - diff: 16.87mlTrain batch 18/31 - 238.3ms/batch - loss: 34.33297 - diff: 17.60mlTrain batch 19/31 - 240.1ms/batch - loss: 34.15987 - diff: 17.55mlTrain batch 20/31 - 238.6ms/batch - loss: 33.32041 - diff: 17.40mlTrain batch 21/31 - 239.8ms/batch - loss: 32.65960 - diff: 17.16mlTrain batch 22/31 - 239.1ms/batch - loss: 32.59081 - diff: 17.13mlTrain batch 23/31 - 239.9ms/batch - loss: 32.60511 - diff: 17.06mlTrain batch 24/31 - 238.0ms/batch - loss: 32.03614 - diff: 16.87mlTrain batch 25/31 - 240.0ms/batch - loss: 31.17675 - diff: 16.62mlTrain batch 26/31 - 237.8ms/batch - loss: 30.74085 - diff: 16.52mlTrain batch 27/31 - 238.7ms/batch - loss: 30.94076 - diff: 16.63mlTrain batch 28/31 - 237.8ms/batch - loss: 31.31274 - diff: 16.75mlTrain batch 29/31 - 240.3ms/batch - loss: 31.15449 - diff: 16.68mlTrain batch 30/31 - 238.3ms/batch - loss: 30.69983 - diff: 16.52mlTrain batch 31/31 - 123.5ms/batch - loss: 31.38309 - diff: 16.52mlTrain batch 31/31 - 11.9s 123.5ms/batch - loss: 31.38309 - diff: 16.52ml
Test 1.2s: val_loss: 44.58497 - diff: 18.15ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Systole_WideResNet50_0_Adam-0.001_MSE_DA3_best

Epoch 87: current best loss = 44.58497, at epoch 86
Train batch 1/31 - 236.9ms/batch - loss: 35.38534 - diff: 17.41mlTrain batch 2/31 - 237.4ms/batch - loss: 24.72587 - diff: 14.61mlTrain batch 3/31 - 238.3ms/batch - loss: 22.43830 - diff: 14.34mlTrain batch 4/31 - 237.7ms/batch - loss: 29.75365 - diff: 15.09mlTrain batch 5/31 - 239.0ms/batch - loss: 29.31730 - diff: 15.30mlTrain batch 6/31 - 237.7ms/batch - loss: 27.22615 - diff: 14.96mlTrain batch 7/31 - 238.8ms/batch - loss: 24.47255 - diff: 14.09mlTrain batch 8/31 - 236.6ms/batch - loss: 28.39528 - diff: 15.23mlTrain batch 9/31 - 239.7ms/batch - loss: 27.54407 - diff: 15.14mlTrain batch 10/31 - 237.0ms/batch - loss: 28.10549 - diff: 15.30mlTrain batch 11/31 - 237.3ms/batch - loss: 27.96683 - diff: 15.38mlTrain batch 12/31 - 237.9ms/batch - loss: 30.12020 - diff: 16.05mlTrain batch 13/31 - 240.1ms/batch - loss: 29.35832 - diff: 16.09mlTrain batch 14/31 - 237.6ms/batch - loss: 29.14590 - diff: 16.17mlTrain batch 15/31 - 239.9ms/batch - loss: 29.07372 - diff: 16.03mlTrain batch 16/31 - 237.4ms/batch - loss: 28.74924 - diff: 15.99mlTrain batch 17/31 - 240.3ms/batch - loss: 28.65681 - diff: 15.93mlTrain batch 18/31 - 239.4ms/batch - loss: 28.43771 - diff: 15.75mlTrain batch 19/31 - 239.4ms/batch - loss: 29.13034 - diff: 15.90mlTrain batch 20/31 - 238.2ms/batch - loss: 29.87748 - diff: 16.14mlTrain batch 21/31 - 239.9ms/batch - loss: 30.43444 - diff: 16.21mlTrain batch 22/31 - 238.2ms/batch - loss: 30.25626 - diff: 16.22mlTrain batch 23/31 - 239.7ms/batch - loss: 30.00158 - diff: 16.19mlTrain batch 24/31 - 237.9ms/batch - loss: 31.89470 - diff: 16.60mlTrain batch 25/31 - 239.0ms/batch - loss: 30.95381 - diff: 16.32mlTrain batch 26/31 - 239.1ms/batch - loss: 30.29528 - diff: 16.13mlTrain batch 27/31 - 239.1ms/batch - loss: 32.91180 - diff: 16.56mlTrain batch 28/31 - 237.7ms/batch - loss: 33.34051 - diff: 16.66mlTrain batch 29/31 - 237.9ms/batch - loss: 32.61087 - diff: 16.51mlTrain batch 30/31 - 237.8ms/batch - loss: 33.39305 - diff: 16.72mlTrain batch 31/31 - 124.8ms/batch - loss: 33.63135 - diff: 16.70mlTrain batch 31/31 - 11.8s 124.8ms/batch - loss: 33.63135 - diff: 16.70ml
Test 1.2s: val_loss: 44.34826 - diff: 19.31ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Systole_WideResNet50_0_Adam-0.001_MSE_DA3_best

Epoch 88: current best loss = 44.34826, at epoch 87
Train batch 1/31 - 237.4ms/batch - loss: 81.06524 - diff: 23.00mlTrain batch 2/31 - 237.4ms/batch - loss: 51.34844 - diff: 18.82mlTrain batch 3/31 - 236.9ms/batch - loss: 41.15343 - diff: 17.27mlTrain batch 4/31 - 237.1ms/batch - loss: 33.27880 - diff: 15.33mlTrain batch 5/31 - 237.4ms/batch - loss: 31.04775 - diff: 15.29mlTrain batch 6/31 - 238.1ms/batch - loss: 31.66959 - diff: 16.22mlTrain batch 7/31 - 246.2ms/batch - loss: 30.52908 - diff: 15.99mlTrain batch 8/31 - 237.6ms/batch - loss: 30.08447 - diff: 16.06mlTrain batch 9/31 - 241.1ms/batch - loss: 29.27607 - diff: 15.68mlTrain batch 10/31 - 237.3ms/batch - loss: 27.71558 - diff: 14.98mlTrain batch 11/31 - 238.0ms/batch - loss: 26.92346 - diff: 14.86mlTrain batch 12/31 - 239.9ms/batch - loss: 25.28463 - diff: 14.29mlTrain batch 13/31 - 238.3ms/batch - loss: 24.14092 - diff: 14.07mlTrain batch 14/31 - 237.8ms/batch - loss: 23.28200 - diff: 13.93mlTrain batch 15/31 - 238.6ms/batch - loss: 23.10744 - diff: 13.98mlTrain batch 16/31 - 240.1ms/batch - loss: 25.43829 - diff: 14.46mlTrain batch 17/31 - 238.5ms/batch - loss: 27.90284 - diff: 14.89mlTrain batch 18/31 - 238.1ms/batch - loss: 27.56217 - diff: 14.90mlTrain batch 19/31 - 239.6ms/batch - loss: 26.58246 - diff: 14.55mlTrain batch 20/31 - 237.1ms/batch - loss: 25.96575 - diff: 14.46mlTrain batch 21/31 - 238.6ms/batch - loss: 25.34035 - diff: 14.28mlTrain batch 22/31 - 236.9ms/batch - loss: 35.49232 - diff: 15.54mlTrain batch 23/31 - 239.8ms/batch - loss: 34.83666 - diff: 15.47mlTrain batch 24/31 - 237.7ms/batch - loss: 34.66816 - diff: 15.54mlTrain batch 25/31 - 239.8ms/batch - loss: 34.26541 - diff: 15.56mlTrain batch 26/31 - 237.9ms/batch - loss: 33.75830 - diff: 15.58mlTrain batch 27/31 - 238.0ms/batch - loss: 33.74801 - diff: 15.66mlTrain batch 28/31 - 239.5ms/batch - loss: 33.20032 - diff: 15.53mlTrain batch 29/31 - 240.3ms/batch - loss: 34.24817 - diff: 15.85mlTrain batch 30/31 - 237.8ms/batch - loss: 33.59056 - diff: 15.72mlTrain batch 31/31 - 124.6ms/batch - loss: 34.21144 - diff: 15.80mlTrain batch 31/31 - 11.4s 124.6ms/batch - loss: 34.21144 - diff: 15.80ml
Test 1.1s: val_loss: 45.26424 - diff: 19.14ml

Epoch 89: current best loss = 44.34826, at epoch 87
Train batch 1/31 - 236.8ms/batch - loss: 18.35188 - diff: 13.02mlTrain batch 2/31 - 237.2ms/batch - loss: 20.23720 - diff: 14.06mlTrain batch 3/31 - 237.8ms/batch - loss: 37.29768 - diff: 18.17mlTrain batch 4/31 - 241.7ms/batch - loss: 42.04675 - diff: 19.86mlTrain batch 5/31 - 237.5ms/batch - loss: 38.80740 - diff: 19.18mlTrain batch 6/31 - 237.4ms/batch - loss: 38.24609 - diff: 18.86mlTrain batch 7/31 - 240.0ms/batch - loss: 39.79837 - diff: 19.05mlTrain batch 8/31 - 238.5ms/batch - loss: 41.69715 - diff: 19.35mlTrain batch 9/31 - 237.9ms/batch - loss: 41.04811 - diff: 19.34mlTrain batch 10/31 - 237.6ms/batch - loss: 38.51019 - diff: 18.65mlTrain batch 11/31 - 239.4ms/batch - loss: 38.02591 - diff: 18.54mlTrain batch 12/31 - 241.5ms/batch - loss: 36.74501 - diff: 18.32mlTrain batch 13/31 - 237.5ms/batch - loss: 36.99660 - diff: 18.30mlTrain batch 14/31 - 238.6ms/batch - loss: 39.15479 - diff: 18.83mlTrain batch 15/31 - 238.9ms/batch - loss: 39.91967 - diff: 18.99mlTrain batch 16/31 - 237.5ms/batch - loss: 44.38772 - diff: 19.44mlTrain batch 17/31 - 239.7ms/batch - loss: 43.54470 - diff: 19.45mlTrain batch 18/31 - 240.4ms/batch - loss: 42.66985 - diff: 19.23mlTrain batch 19/31 - 238.1ms/batch - loss: 41.50121 - diff: 18.99mlTrain batch 20/31 - 238.4ms/batch - loss: 41.83528 - diff: 18.98mlTrain batch 21/31 - 240.0ms/batch - loss: 40.57246 - diff: 18.63mlTrain batch 22/31 - 238.9ms/batch - loss: 39.93606 - diff: 18.46mlTrain batch 23/31 - 239.4ms/batch - loss: 40.05403 - diff: 18.59mlTrain batch 24/31 - 237.6ms/batch - loss: 39.25512 - diff: 18.40mlTrain batch 25/31 - 240.3ms/batch - loss: 39.31370 - diff: 18.52mlTrain batch 26/31 - 237.7ms/batch - loss: 39.52319 - diff: 18.48mlTrain batch 27/31 - 240.5ms/batch - loss: 41.75275 - diff: 18.82mlTrain batch 28/31 - 238.5ms/batch - loss: 40.91683 - diff: 18.65mlTrain batch 29/31 - 237.5ms/batch - loss: 40.28099 - diff: 18.49mlTrain batch 30/31 - 237.8ms/batch - loss: 39.76461 - diff: 18.41mlTrain batch 31/31 - 124.3ms/batch - loss: 39.99243 - diff: 18.39mlTrain batch 31/31 - 11.2s 124.3ms/batch - loss: 39.99243 - diff: 18.39ml
Test 1.1s: val_loss: 43.71202 - diff: 17.94ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Systole_WideResNet50_0_Adam-0.001_MSE_DA3_best

Epoch 90: current best loss = 43.71202, at epoch 89
Train batch 1/31 - 236.8ms/batch - loss: 50.73999 - diff: 22.21mlTrain batch 2/31 - 236.3ms/batch - loss: 51.07549 - diff: 22.16mlTrain batch 3/31 - 237.3ms/batch - loss: 47.13571 - diff: 20.48mlTrain batch 4/31 - 239.3ms/batch - loss: 43.39424 - diff: 19.16mlTrain batch 5/31 - 237.7ms/batch - loss: 40.24013 - diff: 18.56mlTrain batch 6/31 - 239.3ms/batch - loss: 36.56123 - diff: 17.86mlTrain batch 7/31 - 237.6ms/batch - loss: 36.30699 - diff: 17.66mlTrain batch 8/31 - 237.8ms/batch - loss: 42.64261 - diff: 19.31mlTrain batch 9/31 - 237.8ms/batch - loss: 40.81338 - diff: 19.01mlTrain batch 10/31 - 238.7ms/batch - loss: 40.70266 - diff: 19.06mlTrain batch 11/31 - 238.1ms/batch - loss: 37.85442 - diff: 18.17mlTrain batch 12/31 - 239.2ms/batch - loss: 37.35787 - diff: 18.02mlTrain batch 13/31 - 237.9ms/batch - loss: 36.04755 - diff: 17.79mlTrain batch 14/31 - 237.9ms/batch - loss: 35.44919 - diff: 17.46mlTrain batch 15/31 - 237.8ms/batch - loss: 33.85050 - diff: 17.01mlTrain batch 16/31 - 239.9ms/batch - loss: 32.91078 - diff: 16.82mlTrain batch 17/31 - 237.9ms/batch - loss: 33.14639 - diff: 17.00mlTrain batch 18/31 - 240.3ms/batch - loss: 32.03605 - diff: 16.72mlTrain batch 19/31 - 239.5ms/batch - loss: 31.81291 - diff: 16.60mlTrain batch 20/31 - 238.3ms/batch - loss: 32.10517 - diff: 16.65mlTrain batch 21/31 - 241.3ms/batch - loss: 33.93974 - diff: 16.95mlTrain batch 22/31 - 237.9ms/batch - loss: 33.23812 - diff: 16.64mlTrain batch 23/31 - 237.8ms/batch - loss: 33.00955 - diff: 16.55mlTrain batch 24/31 - 239.8ms/batch - loss: 32.70024 - diff: 16.61mlTrain batch 25/31 - 239.0ms/batch - loss: 32.06577 - diff: 16.46mlTrain batch 26/31 - 237.5ms/batch - loss: 33.01380 - diff: 16.66mlTrain batch 27/31 - 239.5ms/batch - loss: 32.82053 - diff: 16.68mlTrain batch 28/31 - 238.3ms/batch - loss: 32.52670 - diff: 16.60mlTrain batch 29/31 - 238.4ms/batch - loss: 32.44918 - diff: 16.54mlTrain batch 30/31 - 239.5ms/batch - loss: 31.79383 - diff: 16.35mlTrain batch 31/31 - 123.5ms/batch - loss: 32.22676 - diff: 16.36mlTrain batch 31/31 - 11.4s 123.5ms/batch - loss: 32.22676 - diff: 16.36ml
Test 1.1s: val_loss: 49.60706 - diff: 19.48ml

Epoch 91: current best loss = 43.71202, at epoch 89
Train batch 1/31 - 237.3ms/batch - loss: 25.21255 - diff: 16.17mlTrain batch 2/31 - 238.1ms/batch - loss: 32.12402 - diff: 16.67mlTrain batch 3/31 - 237.5ms/batch - loss: 26.65204 - diff: 15.18mlTrain batch 4/31 - 238.7ms/batch - loss: 22.60174 - diff: 13.99mlTrain batch 5/31 - 238.4ms/batch - loss: 24.50098 - diff: 14.76mlTrain batch 6/31 - 237.3ms/batch - loss: 24.37641 - diff: 14.94mlTrain batch 7/31 - 238.4ms/batch - loss: 22.47885 - diff: 14.51mlTrain batch 8/31 - 238.0ms/batch - loss: 23.06987 - diff: 14.47mlTrain batch 9/31 - 239.6ms/batch - loss: 21.53575 - diff: 13.84mlTrain batch 10/31 - 237.3ms/batch - loss: 20.41870 - diff: 13.54mlTrain batch 11/31 - 238.3ms/batch - loss: 22.80138 - diff: 14.19mlTrain batch 12/31 - 237.3ms/batch - loss: 23.47418 - diff: 14.68mlTrain batch 13/31 - 239.5ms/batch - loss: 25.83767 - diff: 15.47mlTrain batch 14/31 - 237.7ms/batch - loss: 25.72097 - diff: 15.46mlTrain batch 15/31 - 238.6ms/batch - loss: 26.10670 - diff: 15.44mlTrain batch 16/31 - 237.7ms/batch - loss: 26.70034 - diff: 15.62mlTrain batch 17/31 - 238.0ms/batch - loss: 26.78510 - diff: 15.74mlTrain batch 18/31 - 237.8ms/batch - loss: 26.14029 - diff: 15.60mlTrain batch 19/31 - 239.9ms/batch - loss: 26.44481 - diff: 15.68mlTrain batch 20/31 - 237.6ms/batch - loss: 27.54916 - diff: 15.85mlTrain batch 21/31 - 239.9ms/batch - loss: 27.96102 - diff: 16.07mlTrain batch 22/31 - 238.1ms/batch - loss: 28.59591 - diff: 16.10mlTrain batch 23/31 - 240.0ms/batch - loss: 28.00149 - diff: 15.99mlTrain batch 24/31 - 238.0ms/batch - loss: 27.65756 - diff: 15.91mlTrain batch 25/31 - 237.6ms/batch - loss: 27.59426 - diff: 15.88mlTrain batch 26/31 - 242.9ms/batch - loss: 27.10172 - diff: 15.72mlTrain batch 27/31 - 239.5ms/batch - loss: 27.93670 - diff: 15.78mlTrain batch 28/31 - 239.9ms/batch - loss: 28.16205 - diff: 15.78mlTrain batch 29/31 - 238.3ms/batch - loss: 28.94531 - diff: 15.87mlTrain batch 30/31 - 240.1ms/batch - loss: 29.41380 - diff: 16.03mlTrain batch 31/31 - 124.5ms/batch - loss: 29.91541 - diff: 16.01mlTrain batch 31/31 - 11.4s 124.5ms/batch - loss: 29.91541 - diff: 16.01ml
Test 1.1s: val_loss: 44.66418 - diff: 17.91ml

Epoch 92: current best loss = 43.71202, at epoch 89
Train batch 1/31 - 237.4ms/batch - loss: 87.75396 - diff: 30.93mlTrain batch 2/31 - 237.1ms/batch - loss: 62.73166 - diff: 26.14mlTrain batch 3/31 - 238.0ms/batch - loss: 54.19005 - diff: 24.51mlTrain batch 4/31 - 237.2ms/batch - loss: 43.39016 - diff: 21.14mlTrain batch 5/31 - 240.0ms/batch - loss: 40.03637 - diff: 19.98mlTrain batch 6/31 - 237.0ms/batch - loss: 36.54763 - diff: 19.11mlTrain batch 7/31 - 238.5ms/batch - loss: 33.00122 - diff: 18.08mlTrain batch 8/31 - 236.6ms/batch - loss: 32.08895 - diff: 17.83mlTrain batch 9/31 - 240.0ms/batch - loss: 30.57412 - diff: 17.34mlTrain batch 10/31 - 238.4ms/batch - loss: 28.95306 - diff: 16.81mlTrain batch 11/31 - 240.0ms/batch - loss: 29.15244 - diff: 16.79mlTrain batch 12/31 - 238.4ms/batch - loss: 29.33230 - diff: 16.87mlTrain batch 13/31 - 239.9ms/batch - loss: 29.43578 - diff: 16.99mlTrain batch 14/31 - 238.2ms/batch - loss: 31.45070 - diff: 17.51mlTrain batch 15/31 - 239.1ms/batch - loss: 30.66947 - diff: 17.08mlTrain batch 16/31 - 237.9ms/batch - loss: 29.58368 - diff: 16.80mlTrain batch 17/31 - 239.9ms/batch - loss: 30.85060 - diff: 17.00mlTrain batch 18/31 - 238.0ms/batch - loss: 31.68067 - diff: 17.27mlTrain batch 19/31 - 245.2ms/batch - loss: 34.87778 - diff: 17.57mlTrain batch 20/31 - 238.2ms/batch - loss: 34.68846 - diff: 17.48mlTrain batch 21/31 - 239.7ms/batch - loss: 34.01557 - diff: 17.31mlTrain batch 22/31 - 237.7ms/batch - loss: 34.59437 - diff: 17.21mlTrain batch 23/31 - 240.4ms/batch - loss: 34.15937 - diff: 17.09mlTrain batch 24/31 - 238.0ms/batch - loss: 33.66444 - diff: 16.96mlTrain batch 25/31 - 239.8ms/batch - loss: 33.91435 - diff: 17.09mlTrain batch 26/31 - 240.9ms/batch - loss: 34.48526 - diff: 17.24mlTrain batch 27/31 - 240.2ms/batch - loss: 35.04832 - diff: 17.44mlTrain batch 28/31 - 238.1ms/batch - loss: 35.08858 - diff: 17.50mlTrain batch 29/31 - 242.6ms/batch - loss: 34.70211 - diff: 17.41mlTrain batch 30/31 - 243.0ms/batch - loss: 37.67895 - diff: 17.74mlTrain batch 31/31 - 122.3ms/batch - loss: 39.64196 - diff: 17.92mlTrain batch 31/31 - 11.2s 122.3ms/batch - loss: 39.64196 - diff: 17.92ml
Test 1.2s: val_loss: 44.53727 - diff: 19.44ml

Epoch 93: current best loss = 43.71202, at epoch 89
Train batch 1/31 - 237.3ms/batch - loss: 51.72314 - diff: 23.01mlTrain batch 2/31 - 239.1ms/batch - loss: 44.01235 - diff: 20.39mlTrain batch 3/31 - 237.7ms/batch - loss: 37.95833 - diff: 18.38mlTrain batch 4/31 - 240.0ms/batch - loss: 32.50165 - diff: 17.36mlTrain batch 5/31 - 238.2ms/batch - loss: 36.63871 - diff: 18.64mlTrain batch 6/31 - 240.3ms/batch - loss: 33.87442 - diff: 18.07mlTrain batch 7/31 - 237.6ms/batch - loss: 31.48655 - diff: 17.45mlTrain batch 8/31 - 240.9ms/batch - loss: 31.68353 - diff: 17.55mlTrain batch 9/31 - 238.0ms/batch - loss: 34.10996 - diff: 17.67mlTrain batch 10/31 - 239.8ms/batch - loss: 31.78782 - diff: 16.86mlTrain batch 11/31 - 238.3ms/batch - loss: 33.60431 - diff: 17.17mlTrain batch 12/31 - 237.6ms/batch - loss: 32.45448 - diff: 16.90mlTrain batch 13/31 - 239.2ms/batch - loss: 32.50744 - diff: 17.09mlTrain batch 14/31 - 238.3ms/batch - loss: 31.90171 - diff: 17.04mlTrain batch 15/31 - 239.3ms/batch - loss: 31.78077 - diff: 16.81mlTrain batch 16/31 - 238.2ms/batch - loss: 30.93783 - diff: 16.69mlTrain batch 17/31 - 239.8ms/batch - loss: 30.40461 - diff: 16.57mlTrain batch 18/31 - 238.6ms/batch - loss: 30.22770 - diff: 16.58mlTrain batch 19/31 - 239.9ms/batch - loss: 30.07760 - diff: 16.62mlTrain batch 20/31 - 240.1ms/batch - loss: 30.30166 - diff: 16.68mlTrain batch 21/31 - 239.3ms/batch - loss: 30.59430 - diff: 16.63mlTrain batch 22/31 - 237.9ms/batch - loss: 31.24268 - diff: 16.91mlTrain batch 23/31 - 240.1ms/batch - loss: 31.30752 - diff: 16.84mlTrain batch 24/31 - 237.7ms/batch - loss: 31.32945 - diff: 16.78mlTrain batch 25/31 - 240.2ms/batch - loss: 31.08939 - diff: 16.74mlTrain batch 26/31 - 240.8ms/batch - loss: 31.10573 - diff: 16.75mlTrain batch 27/31 - 240.6ms/batch - loss: 30.33320 - diff: 16.50mlTrain batch 28/31 - 237.9ms/batch - loss: 31.31982 - diff: 16.66mlTrain batch 29/31 - 240.0ms/batch - loss: 31.28195 - diff: 16.66mlTrain batch 30/31 - 238.7ms/batch - loss: 31.24978 - diff: 16.55mlTrain batch 31/31 - 124.3ms/batch - loss: 31.62185 - diff: 16.55mlTrain batch 31/31 - 10.8s 124.3ms/batch - loss: 31.62185 - diff: 16.55ml
Test 1.1s: val_loss: 62.62485 - diff: 23.11ml

Epoch 94: current best loss = 43.71202, at epoch 89
Train batch 1/31 - 250.0ms/batch - loss: 9.78775 - diff: 10.37mlTrain batch 2/31 - 237.9ms/batch - loss: 18.43547 - diff: 14.27mlTrain batch 3/31 - 237.4ms/batch - loss: 22.17545 - diff: 15.88mlTrain batch 4/31 - 240.3ms/batch - loss: 24.24763 - diff: 16.04mlTrain batch 5/31 - 241.0ms/batch - loss: 28.24275 - diff: 16.98mlTrain batch 6/31 - 238.1ms/batch - loss: 30.75052 - diff: 17.47mlTrain batch 7/31 - 240.9ms/batch - loss: 32.17584 - diff: 17.28mlTrain batch 8/31 - 240.2ms/batch - loss: 32.60768 - diff: 17.34mlTrain batch 9/31 - 238.7ms/batch - loss: 34.07217 - diff: 17.58mlTrain batch 10/31 - 240.0ms/batch - loss: 33.91838 - diff: 17.70mlTrain batch 11/31 - 237.9ms/batch - loss: 32.97441 - diff: 17.40mlTrain batch 12/31 - 239.4ms/batch - loss: 35.17551 - diff: 17.97mlTrain batch 13/31 - 237.8ms/batch - loss: 34.68174 - diff: 17.82mlTrain batch 14/31 - 240.1ms/batch - loss: 34.08576 - diff: 17.67mlTrain batch 15/31 - 238.1ms/batch - loss: 33.63679 - diff: 17.61mlTrain batch 16/31 - 240.2ms/batch - loss: 32.63507 - diff: 17.31mlTrain batch 17/31 - 237.9ms/batch - loss: 31.46391 - diff: 16.97mlTrain batch 18/31 - 240.3ms/batch - loss: 30.31016 - diff: 16.61mlTrain batch 19/31 - 238.2ms/batch - loss: 29.99144 - diff: 16.63mlTrain batch 20/31 - 240.2ms/batch - loss: 29.41096 - diff: 16.45mlTrain batch 21/31 - 237.7ms/batch - loss: 28.91298 - diff: 16.26mlTrain batch 22/31 - 237.6ms/batch - loss: 28.33691 - diff: 16.12mlTrain batch 23/31 - 238.5ms/batch - loss: 28.43633 - diff: 16.14mlTrain batch 24/31 - 239.9ms/batch - loss: 29.38460 - diff: 16.26mlTrain batch 25/31 - 238.9ms/batch - loss: 28.80518 - diff: 16.13mlTrain batch 26/31 - 239.6ms/batch - loss: 28.43143 - diff: 16.07mlTrain batch 27/31 - 237.8ms/batch - loss: 28.28896 - diff: 15.93mlTrain batch 28/31 - 239.4ms/batch - loss: 28.18482 - diff: 15.94mlTrain batch 29/31 - 238.5ms/batch - loss: 27.86841 - diff: 15.91mlTrain batch 30/31 - 240.1ms/batch - loss: 27.75204 - diff: 15.90mlTrain batch 31/31 - 125.0ms/batch - loss: 30.71277 - diff: 16.07mlTrain batch 31/31 - 10.7s 125.0ms/batch - loss: 30.71277 - diff: 16.07ml
Test 1.1s: val_loss: 49.45881 - diff: 19.05ml

Epoch 95: current best loss = 43.71202, at epoch 89
Train batch 1/31 - 237.2ms/batch - loss: 32.63298 - diff: 17.66mlTrain batch 2/31 - 238.5ms/batch - loss: 33.86263 - diff: 17.59mlTrain batch 3/31 - 237.4ms/batch - loss: 31.82286 - diff: 17.35mlTrain batch 4/31 - 240.3ms/batch - loss: 33.54526 - diff: 18.04mlTrain batch 5/31 - 238.9ms/batch - loss: 34.57241 - diff: 18.16mlTrain batch 6/31 - 240.1ms/batch - loss: 32.71523 - diff: 17.37mlTrain batch 7/31 - 237.1ms/batch - loss: 39.61401 - diff: 18.70mlTrain batch 8/31 - 243.3ms/batch - loss: 40.67799 - diff: 18.93mlTrain batch 9/31 - 237.5ms/batch - loss: 49.35740 - diff: 19.67mlTrain batch 10/31 - 240.4ms/batch - loss: 47.84359 - diff: 19.64mlTrain batch 11/31 - 237.8ms/batch - loss: 46.44122 - diff: 19.36mlTrain batch 12/31 - 240.1ms/batch - loss: 44.82514 - diff: 19.03mlTrain batch 13/31 - 238.2ms/batch - loss: 43.94507 - diff: 19.08mlTrain batch 14/31 - 240.0ms/batch - loss: 42.70258 - diff: 18.74mlTrain batch 15/31 - 238.5ms/batch - loss: 40.72860 - diff: 18.24mlTrain batch 16/31 - 238.4ms/batch - loss: 41.35377 - diff: 18.36mlTrain batch 17/31 - 237.8ms/batch - loss: 41.30569 - diff: 18.32mlTrain batch 18/31 - 238.4ms/batch - loss: 41.47087 - diff: 18.43mlTrain batch 19/31 - 238.7ms/batch - loss: 40.01562 - diff: 18.12mlTrain batch 20/31 - 237.8ms/batch - loss: 39.94954 - diff: 18.08mlTrain batch 21/31 - 237.7ms/batch - loss: 42.20236 - diff: 18.52mlTrain batch 22/31 - 237.7ms/batch - loss: 40.55670 - diff: 18.01mlTrain batch 23/31 - 240.4ms/batch - loss: 39.96093 - diff: 17.94mlTrain batch 24/31 - 237.9ms/batch - loss: 40.30221 - diff: 17.99mlTrain batch 25/31 - 237.7ms/batch - loss: 40.50885 - diff: 18.07mlTrain batch 26/31 - 239.8ms/batch - loss: 39.91661 - diff: 17.92mlTrain batch 27/31 - 238.2ms/batch - loss: 39.32640 - diff: 17.73mlTrain batch 28/31 - 240.1ms/batch - loss: 39.12490 - diff: 17.71mlTrain batch 29/31 - 238.1ms/batch - loss: 38.72456 - diff: 17.70mlTrain batch 30/31 - 237.3ms/batch - loss: 38.05313 - diff: 17.58mlTrain batch 31/31 - 124.1ms/batch - loss: 38.17941 - diff: 17.55mlTrain batch 31/31 - 11.3s 124.1ms/batch - loss: 38.17941 - diff: 17.55ml
Test 1.1s: val_loss: 69.55421 - diff: 25.79ml

Epoch 96: current best loss = 43.71202, at epoch 89
Train batch 1/31 - 237.5ms/batch - loss: 28.92090 - diff: 17.16mlTrain batch 2/31 - 238.8ms/batch - loss: 32.34608 - diff: 17.58mlTrain batch 3/31 - 237.6ms/batch - loss: 28.82507 - diff: 16.30mlTrain batch 4/31 - 239.6ms/batch - loss: 30.40925 - diff: 17.09mlTrain batch 5/31 - 240.0ms/batch - loss: 26.67707 - diff: 15.98mlTrain batch 6/31 - 239.6ms/batch - loss: 25.86212 - diff: 15.77mlTrain batch 7/31 - 238.1ms/batch - loss: 33.82075 - diff: 16.47mlTrain batch 8/31 - 239.3ms/batch - loss: 32.41675 - diff: 16.32mlTrain batch 9/31 - 237.8ms/batch - loss: 31.28149 - diff: 16.23mlTrain batch 10/31 - 239.9ms/batch - loss: 29.65543 - diff: 15.68mlTrain batch 11/31 - 238.2ms/batch - loss: 28.19876 - diff: 15.33mlTrain batch 12/31 - 240.3ms/batch - loss: 29.01172 - diff: 15.53mlTrain batch 13/31 - 237.7ms/batch - loss: 30.37165 - diff: 15.85mlTrain batch 14/31 - 239.4ms/batch - loss: 29.30002 - diff: 15.48mlTrain batch 15/31 - 238.5ms/batch - loss: 30.03187 - diff: 15.81mlTrain batch 16/31 - 239.8ms/batch - loss: 30.24307 - diff: 15.73mlTrain batch 17/31 - 238.9ms/batch - loss: 32.46682 - diff: 16.20mlTrain batch 18/31 - 239.7ms/batch - loss: 33.41910 - diff: 16.54mlTrain batch 19/31 - 238.0ms/batch - loss: 32.94723 - diff: 16.40mlTrain batch 20/31 - 238.1ms/batch - loss: 33.15137 - diff: 16.43mlTrain batch 21/31 - 240.1ms/batch - loss: 32.51546 - diff: 16.33mlTrain batch 22/31 - 238.1ms/batch - loss: 32.23306 - diff: 16.36mlTrain batch 23/31 - 240.0ms/batch - loss: 32.59898 - diff: 16.50mlTrain batch 24/31 - 238.0ms/batch - loss: 32.08357 - diff: 16.42mlTrain batch 25/31 - 240.1ms/batch - loss: 32.83339 - diff: 16.68mlTrain batch 26/31 - 238.0ms/batch - loss: 32.25390 - diff: 16.59mlTrain batch 27/31 - 240.2ms/batch - loss: 32.25033 - diff: 16.56mlTrain batch 28/31 - 238.0ms/batch - loss: 34.76833 - diff: 16.91mlTrain batch 29/31 - 239.4ms/batch - loss: 34.32523 - diff: 16.84mlTrain batch 30/31 - 238.9ms/batch - loss: 34.05426 - diff: 16.84mlTrain batch 31/31 - 124.2ms/batch - loss: 33.86630 - diff: 16.75mlTrain batch 31/31 - 11.3s 124.2ms/batch - loss: 33.86630 - diff: 16.75ml
Test 1.1s: val_loss: 39.34780 - diff: 16.65ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Systole_WideResNet50_0_Adam-0.001_MSE_DA3_best

Epoch 97: current best loss = 39.34780, at epoch 96
Train batch 1/31 - 237.0ms/batch - loss: 27.13025 - diff: 17.16mlTrain batch 2/31 - 237.4ms/batch - loss: 22.70973 - diff: 15.55mlTrain batch 3/31 - 237.7ms/batch - loss: 19.81109 - diff: 14.68mlTrain batch 4/31 - 239.8ms/batch - loss: 22.35118 - diff: 15.44mlTrain batch 5/31 - 237.2ms/batch - loss: 22.20283 - diff: 15.19mlTrain batch 6/31 - 240.0ms/batch - loss: 23.86454 - diff: 15.71mlTrain batch 7/31 - 237.4ms/batch - loss: 22.94830 - diff: 15.38mlTrain batch 8/31 - 239.6ms/batch - loss: 23.61953 - diff: 15.76mlTrain batch 9/31 - 237.2ms/batch - loss: 23.86599 - diff: 15.80mlTrain batch 10/31 - 237.9ms/batch - loss: 22.36569 - diff: 15.23mlTrain batch 11/31 - 238.7ms/batch - loss: 21.66696 - diff: 14.93mlTrain batch 12/31 - 238.6ms/batch - loss: 22.84957 - diff: 15.27mlTrain batch 13/31 - 237.7ms/batch - loss: 22.85845 - diff: 15.38mlTrain batch 14/31 - 237.9ms/batch - loss: 24.95548 - diff: 15.75mlTrain batch 15/31 - 238.0ms/batch - loss: 24.41970 - diff: 15.56mlTrain batch 16/31 - 240.2ms/batch - loss: 24.67924 - diff: 15.67mlTrain batch 17/31 - 237.4ms/batch - loss: 24.18254 - diff: 15.54mlTrain batch 18/31 - 239.7ms/batch - loss: 23.98199 - diff: 15.39mlTrain batch 19/31 - 238.5ms/batch - loss: 24.56487 - diff: 15.57mlTrain batch 20/31 - 240.0ms/batch - loss: 24.22291 - diff: 15.46mlTrain batch 21/31 - 238.1ms/batch - loss: 24.07665 - diff: 15.46mlTrain batch 22/31 - 238.2ms/batch - loss: 23.76887 - diff: 15.38mlTrain batch 23/31 - 239.0ms/batch - loss: 23.19438 - diff: 15.19mlTrain batch 24/31 - 237.5ms/batch - loss: 23.59974 - diff: 15.22mlTrain batch 25/31 - 239.9ms/batch - loss: 23.35770 - diff: 15.21mlTrain batch 26/31 - 237.8ms/batch - loss: 23.51439 - diff: 15.31mlTrain batch 27/31 - 240.1ms/batch - loss: 23.86191 - diff: 15.37mlTrain batch 28/31 - 237.8ms/batch - loss: 23.38697 - diff: 15.21mlTrain batch 29/31 - 238.7ms/batch - loss: 23.42647 - diff: 15.16mlTrain batch 30/31 - 237.9ms/batch - loss: 23.18326 - diff: 15.07mlTrain batch 31/31 - 122.5ms/batch - loss: 23.20798 - diff: 14.99mlTrain batch 31/31 - 11.3s 122.5ms/batch - loss: 23.20798 - diff: 14.99ml
Test 1.2s: val_loss: 39.48640 - diff: 17.57ml

Epoch 98: current best loss = 39.34780, at epoch 96
Train batch 1/31 - 237.3ms/batch - loss: 34.47955 - diff: 16.56mlTrain batch 2/31 - 238.0ms/batch - loss: 38.69487 - diff: 18.46mlTrain batch 3/31 - 237.4ms/batch - loss: 32.06231 - diff: 17.19mlTrain batch 4/31 - 240.1ms/batch - loss: 32.65694 - diff: 17.51mlTrain batch 5/31 - 238.1ms/batch - loss: 34.31347 - diff: 17.72mlTrain batch 6/31 - 237.2ms/batch - loss: 34.29735 - diff: 17.76mlTrain batch 7/31 - 240.1ms/batch - loss: 31.95764 - diff: 17.27mlTrain batch 8/31 - 237.6ms/batch - loss: 30.35295 - diff: 16.85mlTrain batch 9/31 - 238.9ms/batch - loss: 28.69210 - diff: 16.52mlTrain batch 10/31 - 238.4ms/batch - loss: 33.17915 - diff: 17.22mlTrain batch 11/31 - 240.1ms/batch - loss: 32.05200 - diff: 16.87mlTrain batch 12/31 - 237.1ms/batch - loss: 31.84332 - diff: 16.98mlTrain batch 13/31 - 239.0ms/batch - loss: 32.95380 - diff: 17.48mlTrain batch 14/31 - 237.9ms/batch - loss: 31.28197 - diff: 17.00mlTrain batch 15/31 - 240.2ms/batch - loss: 31.64712 - diff: 17.06mlTrain batch 16/31 - 237.6ms/batch - loss: 31.32128 - diff: 16.95mlTrain batch 17/31 - 237.9ms/batch - loss: 31.57257 - diff: 16.95mlTrain batch 18/31 - 237.9ms/batch - loss: 30.86623 - diff: 16.71mlTrain batch 19/31 - 239.8ms/batch - loss: 30.58645 - diff: 16.59mlTrain batch 20/31 - 238.6ms/batch - loss: 30.25580 - diff: 16.43mlTrain batch 21/31 - 239.6ms/batch - loss: 33.38889 - diff: 16.96mlTrain batch 22/31 - 246.0ms/batch - loss: 33.00274 - diff: 16.96mlTrain batch 23/31 - 239.9ms/batch - loss: 32.64093 - diff: 16.86mlTrain batch 24/31 - 237.0ms/batch - loss: 31.82391 - diff: 16.63mlTrain batch 25/31 - 240.3ms/batch - loss: 32.98456 - diff: 16.78mlTrain batch 26/31 - 238.0ms/batch - loss: 32.83519 - diff: 16.86mlTrain batch 27/31 - 239.6ms/batch - loss: 32.26775 - diff: 16.72mlTrain batch 28/31 - 237.4ms/batch - loss: 31.69587 - diff: 16.58mlTrain batch 29/31 - 240.0ms/batch - loss: 31.70288 - diff: 16.60mlTrain batch 30/31 - 237.9ms/batch - loss: 31.79313 - diff: 16.72mlTrain batch 31/31 - 124.2ms/batch - loss: 32.07548 - diff: 16.71mlTrain batch 31/31 - 12.0s 124.2ms/batch - loss: 32.07548 - diff: 16.71ml
Test 1.1s: val_loss: 50.19601 - diff: 21.04ml

Epoch 99: current best loss = 39.34780, at epoch 96
Train batch 1/31 - 237.3ms/batch - loss: 11.96257 - diff: 11.61mlTrain batch 2/31 - 238.0ms/batch - loss: 16.78436 - diff: 12.57mlTrain batch 3/31 - 237.7ms/batch - loss: 14.90436 - diff: 11.82mlTrain batch 4/31 - 240.2ms/batch - loss: 14.64042 - diff: 11.39mlTrain batch 5/31 - 237.3ms/batch - loss: 14.69592 - diff: 11.70mlTrain batch 6/31 - 238.9ms/batch - loss: 13.81611 - diff: 11.35mlTrain batch 7/31 - 237.9ms/batch - loss: 12.93351 - diff: 11.03mlTrain batch 8/31 - 238.3ms/batch - loss: 14.29305 - diff: 11.58mlTrain batch 9/31 - 238.4ms/batch - loss: 15.77157 - diff: 12.20mlTrain batch 10/31 - 239.7ms/batch - loss: 15.85366 - diff: 12.41mlTrain batch 11/31 - 237.5ms/batch - loss: 18.23188 - diff: 13.06mlTrain batch 12/31 - 240.1ms/batch - loss: 19.13888 - diff: 13.42mlTrain batch 13/31 - 238.2ms/batch - loss: 20.54355 - diff: 13.83mlTrain batch 14/31 - 238.7ms/batch - loss: 20.80220 - diff: 13.92mlTrain batch 15/31 - 237.6ms/batch - loss: 20.32819 - diff: 13.65mlTrain batch 16/31 - 240.1ms/batch - loss: 20.11616 - diff: 13.64mlTrain batch 17/31 - 238.3ms/batch - loss: 21.29509 - diff: 13.92mlTrain batch 18/31 - 238.6ms/batch - loss: 22.31498 - diff: 14.25mlTrain batch 19/31 - 237.9ms/batch - loss: 25.08719 - diff: 14.65mlTrain batch 20/31 - 237.9ms/batch - loss: 25.07720 - diff: 14.75mlTrain batch 21/31 - 237.6ms/batch - loss: 24.60632 - diff: 14.65mlTrain batch 22/31 - 240.3ms/batch - loss: 24.61500 - diff: 14.76mlTrain batch 23/31 - 238.0ms/batch - loss: 26.61963 - diff: 15.15mlTrain batch 24/31 - 240.2ms/batch - loss: 27.51908 - diff: 15.41mlTrain batch 25/31 - 238.1ms/batch - loss: 27.86304 - diff: 15.57mlTrain batch 26/31 - 240.2ms/batch - loss: 28.46346 - diff: 15.63mlTrain batch 27/31 - 238.5ms/batch - loss: 28.24525 - diff: 15.62mlTrain batch 28/31 - 240.1ms/batch - loss: 28.50226 - diff: 15.70mlTrain batch 29/31 - 238.6ms/batch - loss: 28.24494 - diff: 15.65mlTrain batch 30/31 - 240.1ms/batch - loss: 28.11043 - diff: 15.67mlTrain batch 31/31 - 124.8ms/batch - loss: 29.12653 - diff: 15.78mlTrain batch 31/31 - 11.0s 124.8ms/batch - loss: 29.12653 - diff: 15.78ml
Test 1.2s: val_loss: 56.75428 - diff: 20.02ml

Epoch 100: current best loss = 39.34780, at epoch 96
Train batch 1/31 - 236.9ms/batch - loss: 31.78277 - diff: 16.71mlTrain batch 2/31 - 239.2ms/batch - loss: 23.52323 - diff: 15.16mlTrain batch 3/31 - 239.1ms/batch - loss: 28.97382 - diff: 15.92mlTrain batch 4/31 - 237.7ms/batch - loss: 32.85817 - diff: 16.93mlTrain batch 5/31 - 238.0ms/batch - loss: 28.87847 - diff: 15.84mlTrain batch 6/31 - 238.6ms/batch - loss: 27.25970 - diff: 15.73mlTrain batch 7/31 - 236.9ms/batch - loss: 29.70113 - diff: 16.05mlTrain batch 8/31 - 238.0ms/batch - loss: 27.56884 - diff: 15.59mlTrain batch 9/31 - 237.8ms/batch - loss: 28.24741 - diff: 15.84mlTrain batch 10/31 - 240.0ms/batch - loss: 28.67148 - diff: 16.05mlTrain batch 11/31 - 238.0ms/batch - loss: 28.89145 - diff: 16.07mlTrain batch 12/31 - 239.9ms/batch - loss: 33.92850 - diff: 16.77mlTrain batch 13/31 - 238.4ms/batch - loss: 35.08205 - diff: 17.02mlTrain batch 14/31 - 237.7ms/batch - loss: 33.98070 - diff: 16.89mlTrain batch 15/31 - 237.6ms/batch - loss: 32.89092 - diff: 16.60mlTrain batch 16/31 - 239.9ms/batch - loss: 32.79514 - diff: 16.66mlTrain batch 17/31 - 239.8ms/batch - loss: 32.17320 - diff: 16.58mlTrain batch 18/31 - 240.3ms/batch - loss: 31.99721 - diff: 16.64mlTrain batch 19/31 - 238.7ms/batch - loss: 31.89602 - diff: 16.64mlTrain batch 20/31 - 239.1ms/batch - loss: 31.24421 - diff: 16.45mlTrain batch 21/31 - 237.6ms/batch - loss: 31.94725 - diff: 16.58mlTrain batch 22/31 - 240.0ms/batch - loss: 32.43529 - diff: 16.74mlTrain batch 23/31 - 237.3ms/batch - loss: 32.09696 - diff: 16.70mlTrain batch 24/31 - 239.1ms/batch - loss: 32.68887 - diff: 16.87mlTrain batch 25/31 - 237.8ms/batch - loss: 33.28720 - diff: 17.12mlTrain batch 26/31 - 240.2ms/batch - loss: 33.10311 - diff: 17.05mlTrain batch 27/31 - 238.5ms/batch - loss: 33.74276 - diff: 17.26mlTrain batch 28/31 - 240.0ms/batch - loss: 33.17079 - diff: 17.08mlTrain batch 29/31 - 237.4ms/batch - loss: 32.74700 - diff: 16.98mlTrain batch 30/31 - 240.3ms/batch - loss: 32.53522 - diff: 16.96mlTrain batch 31/31 - 124.6ms/batch - loss: 32.51619 - diff: 16.91mlTrain batch 31/31 - 11.6s 124.6ms/batch - loss: 32.51619 - diff: 16.91ml
Test 1.2s: val_loss: 35.62473 - diff: 16.44ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Systole_WideResNet50_0_Adam-0.001_MSE_DA3_best

Epoch 101: current best loss = 35.62473, at epoch 100
Train batch 1/31 - 237.4ms/batch - loss: 37.74990 - diff: 17.56mlTrain batch 2/31 - 237.7ms/batch - loss: 28.96210 - diff: 15.45mlTrain batch 3/31 - 237.2ms/batch - loss: 27.96481 - diff: 15.57mlTrain batch 4/31 - 239.4ms/batch - loss: 24.95100 - diff: 14.56mlTrain batch 5/31 - 236.6ms/batch - loss: 23.43833 - diff: 14.54mlTrain batch 6/31 - 236.7ms/batch - loss: 23.82911 - diff: 14.98mlTrain batch 7/31 - 237.0ms/batch - loss: 24.25357 - diff: 15.37mlTrain batch 8/31 - 237.6ms/batch - loss: 22.49929 - diff: 14.75mlTrain batch 9/31 - 237.3ms/batch - loss: 23.90894 - diff: 15.07mlTrain batch 10/31 - 237.9ms/batch - loss: 23.79311 - diff: 15.13mlTrain batch 11/31 - 237.7ms/batch - loss: 23.07949 - diff: 14.88mlTrain batch 12/31 - 240.2ms/batch - loss: 23.26147 - diff: 14.89mlTrain batch 13/31 - 237.8ms/batch - loss: 22.48289 - diff: 14.74mlTrain batch 14/31 - 239.7ms/batch - loss: 23.83787 - diff: 15.20mlTrain batch 15/31 - 238.2ms/batch - loss: 24.66283 - diff: 15.51mlTrain batch 16/31 - 240.2ms/batch - loss: 24.18835 - diff: 15.33mlTrain batch 17/31 - 237.6ms/batch - loss: 25.87474 - diff: 15.52mlTrain batch 18/31 - 239.3ms/batch - loss: 25.78360 - diff: 15.37mlTrain batch 19/31 - 237.9ms/batch - loss: 25.99693 - diff: 15.47mlTrain batch 20/31 - 239.6ms/batch - loss: 25.97664 - diff: 15.54mlTrain batch 21/31 - 237.8ms/batch - loss: 25.70620 - diff: 15.50mlTrain batch 22/31 - 238.0ms/batch - loss: 25.24488 - diff: 15.38mlTrain batch 23/31 - 238.0ms/batch - loss: 24.62662 - diff: 15.18mlTrain batch 24/31 - 239.0ms/batch - loss: 24.30563 - diff: 15.05mlTrain batch 25/31 - 238.0ms/batch - loss: 24.27942 - diff: 15.07mlTrain batch 26/31 - 239.5ms/batch - loss: 24.36621 - diff: 15.15mlTrain batch 27/31 - 237.9ms/batch - loss: 26.86445 - diff: 15.49mlTrain batch 28/31 - 239.7ms/batch - loss: 27.12369 - diff: 15.57mlTrain batch 29/31 - 237.3ms/batch - loss: 27.02909 - diff: 15.59mlTrain batch 30/31 - 237.9ms/batch - loss: 27.63474 - diff: 15.62mlTrain batch 31/31 - 124.7ms/batch - loss: 28.64690 - diff: 15.68mlTrain batch 31/31 - 11.6s 124.7ms/batch - loss: 28.64690 - diff: 15.68ml
Test 1.1s: val_loss: 44.52961 - diff: 17.84ml

Epoch 102: current best loss = 35.62473, at epoch 100
Train batch 1/31 - 237.0ms/batch - loss: 23.03194 - diff: 15.13mlTrain batch 2/31 - 237.5ms/batch - loss: 33.64095 - diff: 17.79mlTrain batch 3/31 - 238.6ms/batch - loss: 33.68114 - diff: 17.99mlTrain batch 4/31 - 238.7ms/batch - loss: 31.65298 - diff: 17.50mlTrain batch 5/31 - 237.9ms/batch - loss: 28.97000 - diff: 16.97mlTrain batch 6/31 - 238.1ms/batch - loss: 26.23456 - diff: 16.12mlTrain batch 7/31 - 239.2ms/batch - loss: 24.81807 - diff: 15.70mlTrain batch 8/31 - 237.5ms/batch - loss: 25.32810 - diff: 15.85mlTrain batch 9/31 - 237.2ms/batch - loss: 25.19413 - diff: 15.84mlTrain batch 10/31 - 238.4ms/batch - loss: 24.14655 - diff: 15.37mlTrain batch 11/31 - 238.1ms/batch - loss: 26.06975 - diff: 15.83mlTrain batch 12/31 - 240.0ms/batch - loss: 25.00033 - diff: 15.51mlTrain batch 13/31 - 237.8ms/batch - loss: 24.35583 - diff: 15.36mlTrain batch 14/31 - 240.1ms/batch - loss: 23.22471 - diff: 14.87mlTrain batch 15/31 - 238.2ms/batch - loss: 23.39317 - diff: 14.87mlTrain batch 16/31 - 238.2ms/batch - loss: 23.15872 - diff: 14.87mlTrain batch 17/31 - 237.7ms/batch - loss: 23.79300 - diff: 14.91mlTrain batch 18/31 - 238.6ms/batch - loss: 25.16218 - diff: 15.10mlTrain batch 19/31 - 237.9ms/batch - loss: 25.13577 - diff: 15.02mlTrain batch 20/31 - 240.1ms/batch - loss: 24.50397 - diff: 14.87mlTrain batch 21/31 - 237.9ms/batch - loss: 24.08748 - diff: 14.76mlTrain batch 22/31 - 240.3ms/batch - loss: 25.51458 - diff: 14.96mlTrain batch 23/31 - 238.1ms/batch - loss: 26.49321 - diff: 15.24mlTrain batch 24/31 - 239.2ms/batch - loss: 26.06230 - diff: 15.13mlTrain batch 25/31 - 237.8ms/batch - loss: 25.73476 - diff: 15.11mlTrain batch 26/31 - 237.3ms/batch - loss: 26.72856 - diff: 15.36mlTrain batch 27/31 - 237.8ms/batch - loss: 26.35491 - diff: 15.33mlTrain batch 28/31 - 237.7ms/batch - loss: 26.01880 - diff: 15.27mlTrain batch 29/31 - 237.7ms/batch - loss: 25.89683 - diff: 15.30mlTrain batch 30/31 - 237.5ms/batch - loss: 26.88347 - diff: 15.54mlTrain batch 31/31 - 122.4ms/batch - loss: 27.11162 - diff: 15.52mlTrain batch 31/31 - 12.0s 122.4ms/batch - loss: 27.11162 - diff: 15.52ml
Test 1.1s: val_loss: 43.25945 - diff: 17.89ml

Epoch 103: current best loss = 35.62473, at epoch 100
Train batch 1/31 - 237.0ms/batch - loss: 13.02703 - diff: 11.16mlTrain batch 2/31 - 238.0ms/batch - loss: 41.54800 - diff: 19.09mlTrain batch 3/31 - 237.6ms/batch - loss: 33.71123 - diff: 17.26mlTrain batch 4/31 - 239.9ms/batch - loss: 39.30715 - diff: 17.20mlTrain batch 5/31 - 237.1ms/batch - loss: 38.99764 - diff: 17.91mlTrain batch 6/31 - 239.0ms/batch - loss: 34.30998 - diff: 16.58mlTrain batch 7/31 - 238.3ms/batch - loss: 34.01161 - diff: 16.84mlTrain batch 8/31 - 238.4ms/batch - loss: 30.75475 - diff: 15.96mlTrain batch 9/31 - 239.8ms/batch - loss: 30.73281 - diff: 16.02mlTrain batch 10/31 - 237.8ms/batch - loss: 30.95726 - diff: 16.15mlTrain batch 11/31 - 240.4ms/batch - loss: 31.58318 - diff: 16.38mlTrain batch 12/31 - 237.9ms/batch - loss: 30.90314 - diff: 16.19mlTrain batch 13/31 - 239.6ms/batch - loss: 30.57260 - diff: 16.09mlTrain batch 14/31 - 237.0ms/batch - loss: 30.25234 - diff: 16.02mlTrain batch 15/31 - 238.7ms/batch - loss: 29.87244 - diff: 15.87mlTrain batch 16/31 - 238.6ms/batch - loss: 29.15848 - diff: 15.81mlTrain batch 17/31 - 239.6ms/batch - loss: 28.31075 - diff: 15.62mlTrain batch 18/31 - 237.9ms/batch - loss: 27.40289 - diff: 15.34mlTrain batch 19/31 - 238.4ms/batch - loss: 26.96406 - diff: 15.33mlTrain batch 20/31 - 237.9ms/batch - loss: 27.38847 - diff: 15.49mlTrain batch 21/31 - 238.1ms/batch - loss: 27.20197 - diff: 15.54mlTrain batch 22/31 - 239.9ms/batch - loss: 26.78632 - diff: 15.48mlTrain batch 23/31 - 237.5ms/batch - loss: 26.24777 - diff: 15.32mlTrain batch 24/31 - 238.0ms/batch - loss: 26.44144 - diff: 15.41mlTrain batch 25/31 - 237.7ms/batch - loss: 26.39827 - diff: 15.47mlTrain batch 26/31 - 238.2ms/batch - loss: 25.96512 - diff: 15.35mlTrain batch 27/31 - 238.5ms/batch - loss: 26.02061 - diff: 15.31mlTrain batch 28/31 - 239.9ms/batch - loss: 25.82813 - diff: 15.26mlTrain batch 29/31 - 237.6ms/batch - loss: 25.74209 - diff: 15.28mlTrain batch 30/31 - 239.5ms/batch - loss: 25.29572 - diff: 15.05mlTrain batch 31/31 - 123.2ms/batch - loss: 26.11755 - diff: 15.11mlTrain batch 31/31 - 11.4s 123.2ms/batch - loss: 26.11755 - diff: 15.11ml
Test 1.2s: val_loss: 51.25590 - diff: 21.20ml

Epoch 104: current best loss = 35.62473, at epoch 100
Train batch 1/31 - 237.3ms/batch - loss: 10.55193 - diff: 10.49mlTrain batch 2/31 - 237.7ms/batch - loss: 17.38512 - diff: 13.01mlTrain batch 3/31 - 237.4ms/batch - loss: 16.07137 - diff: 12.95mlTrain batch 4/31 - 238.0ms/batch - loss: 16.27206 - diff: 12.45mlTrain batch 5/31 - 237.4ms/batch - loss: 16.08454 - diff: 12.35mlTrain batch 6/31 - 236.9ms/batch - loss: 15.63569 - diff: 12.00mlTrain batch 7/31 - 237.3ms/batch - loss: 18.22537 - diff: 12.53mlTrain batch 8/31 - 236.9ms/batch - loss: 17.94555 - diff: 12.59mlTrain batch 9/31 - 237.7ms/batch - loss: 17.27684 - diff: 12.46mlTrain batch 10/31 - 237.6ms/batch - loss: 18.01239 - diff: 12.57mlTrain batch 11/31 - 240.0ms/batch - loss: 18.71477 - diff: 12.99mlTrain batch 12/31 - 237.3ms/batch - loss: 18.93436 - diff: 13.06mlTrain batch 13/31 - 240.0ms/batch - loss: 21.89784 - diff: 14.00mlTrain batch 14/31 - 238.3ms/batch - loss: 22.67372 - diff: 14.45mlTrain batch 15/31 - 238.5ms/batch - loss: 24.23896 - diff: 14.62mlTrain batch 16/31 - 237.2ms/batch - loss: 25.29350 - diff: 14.95mlTrain batch 17/31 - 239.5ms/batch - loss: 24.38939 - diff: 14.64mlTrain batch 18/31 - 237.6ms/batch - loss: 24.02568 - diff: 14.56mlTrain batch 19/31 - 237.8ms/batch - loss: 23.67115 - diff: 14.49mlTrain batch 20/31 - 237.1ms/batch - loss: 23.45454 - diff: 14.50mlTrain batch 21/31 - 237.9ms/batch - loss: 23.98416 - diff: 14.55mlTrain batch 22/31 - 237.2ms/batch - loss: 24.16213 - diff: 14.70mlTrain batch 23/31 - 237.1ms/batch - loss: 24.99875 - diff: 14.74mlTrain batch 24/31 - 238.6ms/batch - loss: 25.86944 - diff: 14.94mlTrain batch 25/31 - 238.0ms/batch - loss: 25.64240 - diff: 14.94mlTrain batch 26/31 - 237.6ms/batch - loss: 25.21190 - diff: 14.81mlTrain batch 27/31 - 237.2ms/batch - loss: 24.65325 - diff: 14.62mlTrain batch 28/31 - 238.3ms/batch - loss: 24.07553 - diff: 14.42mlTrain batch 29/31 - 238.2ms/batch - loss: 24.90458 - diff: 14.66mlTrain batch 30/31 - 237.1ms/batch - loss: 24.74761 - diff: 14.68mlTrain batch 31/31 - 122.1ms/batch - loss: 25.23637 - diff: 14.69mlTrain batch 31/31 - 11.7s 122.1ms/batch - loss: 25.23637 - diff: 14.69ml
Test 1.1s: val_loss: 45.94544 - diff: 18.00ml

Epoch 105: current best loss = 35.62473, at epoch 100
Train batch 1/31 - 237.8ms/batch - loss: 19.00421 - diff: 14.65mlTrain batch 2/31 - 240.0ms/batch - loss: 17.00984 - diff: 13.75mlTrain batch 3/31 - 237.2ms/batch - loss: 18.21458 - diff: 13.30mlTrain batch 4/31 - 237.4ms/batch - loss: 17.40697 - diff: 12.60mlTrain batch 5/31 - 237.3ms/batch - loss: 19.87847 - diff: 13.67mlTrain batch 6/31 - 238.9ms/batch - loss: 25.76593 - diff: 14.63mlTrain batch 7/31 - 237.0ms/batch - loss: 29.42838 - diff: 15.46mlTrain batch 8/31 - 240.1ms/batch - loss: 26.50819 - diff: 14.56mlTrain batch 9/31 - 237.6ms/batch - loss: 25.33455 - diff: 14.34mlTrain batch 10/31 - 236.9ms/batch - loss: 26.30945 - diff: 14.01mlTrain batch 11/31 - 237.7ms/batch - loss: 25.77207 - diff: 13.98mlTrain batch 12/31 - 239.4ms/batch - loss: 25.34326 - diff: 14.06mlTrain batch 13/31 - 237.8ms/batch - loss: 25.74186 - diff: 14.15mlTrain batch 14/31 - 239.6ms/batch - loss: 25.34435 - diff: 14.17mlTrain batch 15/31 - 238.1ms/batch - loss: 27.53366 - diff: 14.67mlTrain batch 16/31 - 240.1ms/batch - loss: 27.74161 - diff: 14.64mlTrain batch 17/31 - 238.2ms/batch - loss: 26.95765 - diff: 14.52mlTrain batch 18/31 - 239.3ms/batch - loss: 26.78064 - diff: 14.61mlTrain batch 19/31 - 237.1ms/batch - loss: 26.86242 - diff: 14.64mlTrain batch 20/31 - 239.8ms/batch - loss: 26.89292 - diff: 14.73mlTrain batch 21/31 - 237.7ms/batch - loss: 26.55362 - diff: 14.73mlTrain batch 22/31 - 239.9ms/batch - loss: 25.79801 - diff: 14.52mlTrain batch 23/31 - 237.6ms/batch - loss: 25.72246 - diff: 14.59mlTrain batch 24/31 - 237.8ms/batch - loss: 25.13932 - diff: 14.45mlTrain batch 25/31 - 237.8ms/batch - loss: 25.32389 - diff: 14.47mlTrain batch 26/31 - 240.1ms/batch - loss: 25.07906 - diff: 14.47mlTrain batch 27/31 - 237.7ms/batch - loss: 25.98640 - diff: 14.72mlTrain batch 28/31 - 240.2ms/batch - loss: 25.57664 - diff: 14.64mlTrain batch 29/31 - 246.0ms/batch - loss: 25.32267 - diff: 14.56mlTrain batch 30/31 - 237.7ms/batch - loss: 27.15659 - diff: 14.88mlTrain batch 31/31 - 124.3ms/batch - loss: 29.49117 - diff: 15.06mlTrain batch 31/31 - 11.1s 124.3ms/batch - loss: 29.49117 - diff: 15.06ml
Test 1.1s: val_loss: 49.59205 - diff: 17.50ml

Epoch 106: current best loss = 35.62473, at epoch 100
Train batch 1/31 - 237.7ms/batch - loss: 15.37093 - diff: 11.22mlTrain batch 2/31 - 240.1ms/batch - loss: 18.35768 - diff: 12.91mlTrain batch 3/31 - 237.5ms/batch - loss: 15.85326 - diff: 12.14mlTrain batch 4/31 - 238.0ms/batch - loss: 18.86120 - diff: 13.43mlTrain batch 5/31 - 239.4ms/batch - loss: 18.34306 - diff: 13.04mlTrain batch 6/31 - 239.9ms/batch - loss: 19.32926 - diff: 13.35mlTrain batch 7/31 - 238.4ms/batch - loss: 27.35238 - diff: 15.72mlTrain batch 8/31 - 239.7ms/batch - loss: 39.66017 - diff: 18.04mlTrain batch 9/31 - 237.6ms/batch - loss: 42.90732 - diff: 19.00mlTrain batch 10/31 - 239.6ms/batch - loss: 41.10049 - diff: 18.71mlTrain batch 11/31 - 238.3ms/batch - loss: 39.27379 - diff: 18.19mlTrain batch 12/31 - 240.0ms/batch - loss: 37.14846 - diff: 17.68mlTrain batch 13/31 - 237.9ms/batch - loss: 36.06670 - diff: 17.33mlTrain batch 14/31 - 239.8ms/batch - loss: 34.96304 - diff: 17.14mlTrain batch 15/31 - 237.9ms/batch - loss: 34.15344 - diff: 16.98mlTrain batch 16/31 - 239.9ms/batch - loss: 32.20418 - diff: 16.24mlTrain batch 17/31 - 237.9ms/batch - loss: 30.93278 - diff: 15.80mlTrain batch 18/31 - 240.1ms/batch - loss: 29.94270 - diff: 15.63mlTrain batch 19/31 - 244.9ms/batch - loss: 30.73999 - diff: 15.80mlTrain batch 20/31 - 237.7ms/batch - loss: 30.79299 - diff: 15.80mlTrain batch 21/31 - 238.0ms/batch - loss: 30.71061 - diff: 15.84mlTrain batch 22/31 - 240.2ms/batch - loss: 30.10789 - diff: 15.64mlTrain batch 23/31 - 244.3ms/batch - loss: 32.52772 - diff: 16.26mlTrain batch 24/31 - 238.4ms/batch - loss: 32.92562 - diff: 16.39mlTrain batch 25/31 - 237.8ms/batch - loss: 32.50485 - diff: 16.32mlTrain batch 26/31 - 238.0ms/batch - loss: 32.24041 - diff: 16.36mlTrain batch 27/31 - 237.9ms/batch - loss: 31.52430 - diff: 16.24mlTrain batch 28/31 - 239.0ms/batch - loss: 31.33054 - diff: 16.26mlTrain batch 29/31 - 238.9ms/batch - loss: 31.01500 - diff: 16.19mlTrain batch 30/31 - 240.2ms/batch - loss: 30.43612 - diff: 16.04mlTrain batch 31/31 - 124.5ms/batch - loss: 30.68157 - diff: 16.05mlTrain batch 31/31 - 11.4s 124.5ms/batch - loss: 30.68157 - diff: 16.05ml
Test 1.1s: val_loss: 37.43014 - diff: 17.44ml

Epoch 107: current best loss = 35.62473, at epoch 100
Train batch 1/31 - 237.3ms/batch - loss: 35.44921 - diff: 14.40mlTrain batch 2/31 - 239.0ms/batch - loss: 30.06479 - diff: 15.38mlTrain batch 3/31 - 237.1ms/batch - loss: 27.94892 - diff: 15.66mlTrain batch 4/31 - 239.6ms/batch - loss: 25.61150 - diff: 15.04mlTrain batch 5/31 - 238.7ms/batch - loss: 24.56026 - diff: 15.25mlTrain batch 6/31 - 239.8ms/batch - loss: 23.39429 - diff: 15.14mlTrain batch 7/31 - 237.9ms/batch - loss: 24.16004 - diff: 15.66mlTrain batch 8/31 - 239.8ms/batch - loss: 22.60624 - diff: 15.00mlTrain batch 9/31 - 238.3ms/batch - loss: 22.15633 - diff: 14.99mlTrain batch 10/31 - 239.8ms/batch - loss: 22.26596 - diff: 14.97mlTrain batch 11/31 - 237.5ms/batch - loss: 21.01794 - diff: 14.49mlTrain batch 12/31 - 240.2ms/batch - loss: 21.66565 - diff: 14.53mlTrain batch 13/31 - 239.1ms/batch - loss: 22.47111 - diff: 14.87mlTrain batch 14/31 - 238.3ms/batch - loss: 22.08079 - diff: 14.76mlTrain batch 15/31 - 238.2ms/batch - loss: 22.17455 - diff: 14.82mlTrain batch 16/31 - 239.6ms/batch - loss: 22.37525 - diff: 14.87mlTrain batch 17/31 - 237.2ms/batch - loss: 22.10524 - diff: 14.77mlTrain batch 18/31 - 240.2ms/batch - loss: 22.42355 - diff: 14.90mlTrain batch 19/31 - 237.6ms/batch - loss: 22.73069 - diff: 15.01mlTrain batch 20/31 - 240.0ms/batch - loss: 22.30458 - diff: 14.83mlTrain batch 21/31 - 237.0ms/batch - loss: 22.32737 - diff: 14.75mlTrain batch 22/31 - 240.3ms/batch - loss: 21.77596 - diff: 14.50mlTrain batch 23/31 - 237.4ms/batch - loss: 21.10821 - diff: 14.27mlTrain batch 24/31 - 239.2ms/batch - loss: 25.31022 - diff: 15.10mlTrain batch 25/31 - 237.9ms/batch - loss: 25.24124 - diff: 15.06mlTrain batch 26/31 - 240.2ms/batch - loss: 24.99108 - diff: 15.00mlTrain batch 27/31 - 239.8ms/batch - loss: 25.05127 - diff: 15.10mlTrain batch 28/31 - 237.8ms/batch - loss: 25.03134 - diff: 15.05mlTrain batch 29/31 - 237.6ms/batch - loss: 24.74234 - diff: 15.02mlTrain batch 30/31 - 240.3ms/batch - loss: 24.56956 - diff: 15.05mlTrain batch 31/31 - 124.9ms/batch - loss: 25.25854 - diff: 15.07mlTrain batch 31/31 - 11.4s 124.9ms/batch - loss: 25.25854 - diff: 15.07ml
Test 1.2s: val_loss: 60.73765 - diff: 22.01ml

Epoch 108: current best loss = 35.62473, at epoch 100
Train batch 1/31 - 237.2ms/batch - loss: 33.26918 - diff: 14.35mlTrain batch 2/31 - 237.8ms/batch - loss: 30.32685 - diff: 15.37mlTrain batch 3/31 - 237.3ms/batch - loss: 34.44599 - diff: 17.51mlTrain batch 4/31 - 237.3ms/batch - loss: 29.33425 - diff: 15.76mlTrain batch 5/31 - 239.8ms/batch - loss: 38.55324 - diff: 17.74mlTrain batch 6/31 - 237.8ms/batch - loss: 36.09538 - diff: 17.31mlTrain batch 7/31 - 237.9ms/batch - loss: 34.94950 - diff: 17.19mlTrain batch 8/31 - 237.1ms/batch - loss: 31.40991 - diff: 16.06mlTrain batch 9/31 - 238.1ms/batch - loss: 30.14583 - diff: 15.73mlTrain batch 10/31 - 237.3ms/batch - loss: 28.40684 - diff: 15.28mlTrain batch 11/31 - 238.0ms/batch - loss: 27.45716 - diff: 15.05mlTrain batch 12/31 - 237.2ms/batch - loss: 25.77589 - diff: 14.57mlTrain batch 13/31 - 237.6ms/batch - loss: 25.80438 - diff: 14.76mlTrain batch 14/31 - 237.7ms/batch - loss: 25.94513 - diff: 14.90mlTrain batch 15/31 - 239.8ms/batch - loss: 24.77195 - diff: 14.57mlTrain batch 16/31 - 237.0ms/batch - loss: 24.28831 - diff: 14.48mlTrain batch 17/31 - 237.6ms/batch - loss: 23.84191 - diff: 14.39mlTrain batch 18/31 - 238.6ms/batch - loss: 23.10629 - diff: 14.12mlTrain batch 19/31 - 239.3ms/batch - loss: 23.87913 - diff: 14.35mlTrain batch 20/31 - 237.4ms/batch - loss: 23.57383 - diff: 14.25mlTrain batch 21/31 - 237.6ms/batch - loss: 23.58953 - diff: 14.26mlTrain batch 22/31 - 237.3ms/batch - loss: 26.46152 - diff: 14.85mlTrain batch 23/31 - 238.0ms/batch - loss: 26.12214 - diff: 14.82mlTrain batch 24/31 - 237.6ms/batch - loss: 25.99451 - diff: 14.87mlTrain batch 25/31 - 240.3ms/batch - loss: 25.48898 - diff: 14.79mlTrain batch 26/31 - 237.3ms/batch - loss: 26.69683 - diff: 15.11mlTrain batch 27/31 - 238.1ms/batch - loss: 27.27131 - diff: 15.26mlTrain batch 28/31 - 237.7ms/batch - loss: 26.97978 - diff: 15.23mlTrain batch 29/31 - 239.9ms/batch - loss: 27.16525 - diff: 15.32mlTrain batch 30/31 - 237.1ms/batch - loss: 27.22874 - diff: 15.47mlTrain batch 31/31 - 122.1ms/batch - loss: 28.16300 - diff: 15.52mlTrain batch 31/31 - 12.3s 122.1ms/batch - loss: 28.16300 - diff: 15.52ml
Test 1.2s: val_loss: 49.01908 - diff: 21.01ml

Epoch 109: current best loss = 35.62473, at epoch 100
Train batch 1/31 - 237.0ms/batch - loss: 21.34455 - diff: 12.73mlTrain batch 2/31 - 237.5ms/batch - loss: 22.33839 - diff: 12.76mlTrain batch 3/31 - 237.0ms/batch - loss: 17.89933 - diff: 11.69mlTrain batch 4/31 - 238.3ms/batch - loss: 22.60186 - diff: 13.32mlTrain batch 5/31 - 237.3ms/batch - loss: 23.84513 - diff: 13.32mlTrain batch 6/31 - 237.7ms/batch - loss: 26.15799 - diff: 14.30mlTrain batch 7/31 - 237.4ms/batch - loss: 24.62634 - diff: 14.16mlTrain batch 8/31 - 239.7ms/batch - loss: 23.31944 - diff: 13.79mlTrain batch 9/31 - 237.6ms/batch - loss: 21.81634 - diff: 13.47mlTrain batch 10/31 - 240.0ms/batch - loss: 21.54241 - diff: 13.61mlTrain batch 11/31 - 237.6ms/batch - loss: 20.88511 - diff: 13.57mlTrain batch 12/31 - 240.1ms/batch - loss: 23.01028 - diff: 14.00mlTrain batch 13/31 - 237.4ms/batch - loss: 22.95848 - diff: 14.14mlTrain batch 14/31 - 239.2ms/batch - loss: 29.25271 - diff: 14.80mlTrain batch 15/31 - 237.2ms/batch - loss: 28.34625 - diff: 14.71mlTrain batch 16/31 - 238.7ms/batch - loss: 28.28500 - diff: 14.79mlTrain batch 17/31 - 237.5ms/batch - loss: 29.48889 - diff: 14.76mlTrain batch 18/31 - 239.9ms/batch - loss: 29.03186 - diff: 14.78mlTrain batch 19/31 - 239.6ms/batch - loss: 29.21482 - diff: 14.93mlTrain batch 20/31 - 237.2ms/batch - loss: 29.33963 - diff: 15.18mlTrain batch 21/31 - 237.2ms/batch - loss: 29.24194 - diff: 15.31mlTrain batch 22/31 - 237.8ms/batch - loss: 28.78953 - diff: 15.26mlTrain batch 23/31 - 237.1ms/batch - loss: 28.32761 - diff: 15.15mlTrain batch 24/31 - 237.5ms/batch - loss: 28.00028 - diff: 15.07mlTrain batch 25/31 - 237.5ms/batch - loss: 28.98775 - diff: 15.41mlTrain batch 26/31 - 239.7ms/batch - loss: 28.34270 - diff: 15.23mlTrain batch 27/31 - 237.0ms/batch - loss: 28.64795 - diff: 15.39mlTrain batch 28/31 - 237.8ms/batch - loss: 28.99891 - diff: 15.42mlTrain batch 29/31 - 237.8ms/batch - loss: 28.85521 - diff: 15.47mlTrain batch 30/31 - 239.8ms/batch - loss: 28.24190 - diff: 15.30mlTrain batch 31/31 - 123.4ms/batch - loss: 28.13090 - diff: 15.21mlTrain batch 31/31 - 11.8s 123.4ms/batch - loss: 28.13090 - diff: 15.21ml
Test 1.1s: val_loss: 58.40014 - diff: 20.56ml

Epoch 110: current best loss = 35.62473, at epoch 100
Train batch 1/31 - 236.9ms/batch - loss: 27.84277 - diff: 18.71mlTrain batch 2/31 - 237.8ms/batch - loss: 30.64736 - diff: 16.57mlTrain batch 3/31 - 236.7ms/batch - loss: 26.85201 - diff: 16.20mlTrain batch 4/31 - 237.7ms/batch - loss: 24.61534 - diff: 14.76mlTrain batch 5/31 - 237.9ms/batch - loss: 28.61641 - diff: 15.38mlTrain batch 6/31 - 238.1ms/batch - loss: 27.27231 - diff: 15.26mlTrain batch 7/31 - 237.5ms/batch - loss: 26.71804 - diff: 15.14mlTrain batch 8/31 - 238.0ms/batch - loss: 25.20364 - diff: 14.99mlTrain batch 9/31 - 237.7ms/batch - loss: 25.23781 - diff: 14.78mlTrain batch 10/31 - 240.2ms/batch - loss: 25.26274 - diff: 15.10mlTrain batch 11/31 - 238.0ms/batch - loss: 24.17240 - diff: 14.67mlTrain batch 12/31 - 238.1ms/batch - loss: 23.54108 - diff: 14.46mlTrain batch 13/31 - 240.0ms/batch - loss: 23.66556 - diff: 14.59mlTrain batch 14/31 - 237.7ms/batch - loss: 23.46477 - diff: 14.65mlTrain batch 15/31 - 239.4ms/batch - loss: 23.02723 - diff: 14.55mlTrain batch 16/31 - 237.2ms/batch - loss: 22.13434 - diff: 14.20mlTrain batch 17/31 - 237.7ms/batch - loss: 22.85942 - diff: 14.53mlTrain batch 18/31 - 237.4ms/batch - loss: 22.24351 - diff: 14.33mlTrain batch 19/31 - 237.3ms/batch - loss: 25.38930 - diff: 14.94mlTrain batch 20/31 - 238.0ms/batch - loss: 25.58029 - diff: 15.08mlTrain batch 21/31 - 238.5ms/batch - loss: 25.15675 - diff: 14.98mlTrain batch 22/31 - 237.0ms/batch - loss: 24.82392 - diff: 14.91mlTrain batch 23/31 - 238.2ms/batch - loss: 25.09498 - diff: 14.95mlTrain batch 24/31 - 237.4ms/batch - loss: 24.85121 - diff: 14.92mlTrain batch 25/31 - 237.6ms/batch - loss: 26.63111 - diff: 15.22mlTrain batch 26/31 - 237.6ms/batch - loss: 26.03111 - diff: 15.05mlTrain batch 27/31 - 239.9ms/batch - loss: 26.36902 - diff: 15.08mlTrain batch 28/31 - 236.9ms/batch - loss: 25.88834 - diff: 14.94mlTrain batch 29/31 - 237.5ms/batch - loss: 25.39777 - diff: 14.82mlTrain batch 30/31 - 237.5ms/batch - loss: 25.32109 - diff: 14.77mlTrain batch 31/31 - 123.8ms/batch - loss: 25.22618 - diff: 14.70mlTrain batch 31/31 - 11.9s 123.8ms/batch - loss: 25.22618 - diff: 14.70ml
Test 1.1s: val_loss: 39.65355 - diff: 16.93ml

Epoch 111: current best loss = 35.62473, at epoch 100
Train batch 1/31 - 236.9ms/batch - loss: 61.30124 - diff: 23.73mlTrain batch 2/31 - 237.9ms/batch - loss: 39.34838 - diff: 16.99mlTrain batch 3/31 - 237.5ms/batch - loss: 31.36394 - diff: 14.88mlTrain batch 4/31 - 239.6ms/batch - loss: 32.72039 - diff: 15.51mlTrain batch 5/31 - 237.5ms/batch - loss: 29.36706 - diff: 14.89mlTrain batch 6/31 - 239.2ms/batch - loss: 28.82447 - diff: 14.95mlTrain batch 7/31 - 246.7ms/batch - loss: 25.91229 - diff: 14.23mlTrain batch 8/31 - 240.0ms/batch - loss: 26.39216 - diff: 14.54mlTrain batch 9/31 - 237.6ms/batch - loss: 24.37219 - diff: 14.06mlTrain batch 10/31 - 237.5ms/batch - loss: 23.52016 - diff: 13.80mlTrain batch 11/31 - 237.4ms/batch - loss: 24.19065 - diff: 13.99mlTrain batch 12/31 - 238.3ms/batch - loss: 23.37001 - diff: 13.81mlTrain batch 13/31 - 237.9ms/batch - loss: 23.39919 - diff: 13.93mlTrain batch 14/31 - 238.2ms/batch - loss: 23.81778 - diff: 14.05mlTrain batch 15/31 - 238.0ms/batch - loss: 25.12760 - diff: 14.62mlTrain batch 16/31 - 238.0ms/batch - loss: 24.92705 - diff: 14.60mlTrain batch 17/31 - 240.3ms/batch - loss: 24.57293 - diff: 14.49mlTrain batch 18/31 - 238.0ms/batch - loss: 24.40540 - diff: 14.54mlTrain batch 19/31 - 240.1ms/batch - loss: 23.78147 - diff: 14.42mlTrain batch 20/31 - 241.2ms/batch - loss: 24.02869 - diff: 14.56mlTrain batch 21/31 - 238.1ms/batch - loss: 26.07168 - diff: 15.01mlTrain batch 22/31 - 237.5ms/batch - loss: 26.54801 - diff: 15.12mlTrain batch 23/31 - 239.4ms/batch - loss: 27.05742 - diff: 15.37mlTrain batch 24/31 - 237.7ms/batch - loss: 26.41802 - diff: 15.20mlTrain batch 25/31 - 237.9ms/batch - loss: 25.80578 - diff: 15.03mlTrain batch 26/31 - 238.6ms/batch - loss: 26.41251 - diff: 15.17mlTrain batch 27/31 - 237.5ms/batch - loss: 26.13926 - diff: 15.09mlTrain batch 28/31 - 239.1ms/batch - loss: 25.85511 - diff: 15.02mlTrain batch 29/31 - 237.5ms/batch - loss: 26.12023 - diff: 15.21mlTrain batch 30/31 - 237.8ms/batch - loss: 25.88773 - diff: 15.18mlTrain batch 31/31 - 123.7ms/batch - loss: 27.17956 - diff: 15.26mlTrain batch 31/31 - 11.1s 123.7ms/batch - loss: 27.17956 - diff: 15.26ml
Test 1.1s: val_loss: 43.51888 - diff: 17.54ml
Epoch   112: reducing learning rate of group 0 to 1.2500e-04.

Epoch 112: current best loss = 35.62473, at epoch 100
Train batch 1/31 - 237.0ms/batch - loss: 13.82602 - diff: 12.30mlTrain batch 2/31 - 237.8ms/batch - loss: 24.55710 - diff: 14.24mlTrain batch 3/31 - 237.2ms/batch - loss: 21.35763 - diff: 13.18mlTrain batch 4/31 - 237.3ms/batch - loss: 18.52716 - diff: 12.42mlTrain batch 5/31 - 237.4ms/batch - loss: 18.26342 - diff: 12.64mlTrain batch 6/31 - 238.1ms/batch - loss: 16.73478 - diff: 12.08mlTrain batch 7/31 - 237.2ms/batch - loss: 15.95830 - diff: 11.99mlTrain batch 8/31 - 238.5ms/batch - loss: 17.84949 - diff: 12.79mlTrain batch 9/31 - 237.7ms/batch - loss: 19.02351 - diff: 13.27mlTrain batch 10/31 - 238.5ms/batch - loss: 19.09160 - diff: 13.55mlTrain batch 11/31 - 237.6ms/batch - loss: 20.99538 - diff: 14.06mlTrain batch 12/31 - 239.0ms/batch - loss: 20.89819 - diff: 14.02mlTrain batch 13/31 - 238.2ms/batch - loss: 21.05804 - diff: 14.14mlTrain batch 14/31 - 238.4ms/batch - loss: 26.20900 - diff: 15.05mlTrain batch 15/31 - 240.0ms/batch - loss: 27.56987 - diff: 15.49mlTrain batch 16/31 - 238.0ms/batch - loss: 28.78400 - diff: 15.72mlTrain batch 17/31 - 238.1ms/batch - loss: 28.32784 - diff: 15.73mlTrain batch 18/31 - 238.0ms/batch - loss: 27.22360 - diff: 15.37mlTrain batch 19/31 - 238.8ms/batch - loss: 26.38814 - diff: 15.13mlTrain batch 20/31 - 239.8ms/batch - loss: 26.84609 - diff: 15.18mlTrain batch 21/31 - 238.3ms/batch - loss: 26.16963 - diff: 14.99mlTrain batch 22/31 - 238.3ms/batch - loss: 25.34011 - diff: 14.66mlTrain batch 23/31 - 239.4ms/batch - loss: 25.10318 - diff: 14.55mlTrain batch 24/31 - 237.5ms/batch - loss: 24.70406 - diff: 14.43mlTrain batch 25/31 - 238.3ms/batch - loss: 24.80381 - diff: 14.48mlTrain batch 26/31 - 238.3ms/batch - loss: 24.92101 - diff: 14.42mlTrain batch 27/31 - 239.2ms/batch - loss: 24.84947 - diff: 14.42mlTrain batch 28/31 - 237.4ms/batch - loss: 24.94743 - diff: 14.48mlTrain batch 29/31 - 240.0ms/batch - loss: 25.31347 - diff: 14.55mlTrain batch 30/31 - 237.4ms/batch - loss: 24.90442 - diff: 14.47mlTrain batch 31/31 - 124.4ms/batch - loss: 25.51402 - diff: 14.48mlTrain batch 31/31 - 11.4s 124.4ms/batch - loss: 25.51402 - diff: 14.48ml
Test 1.1s: val_loss: 36.93859 - diff: 16.49ml

Epoch 113: current best loss = 35.62473, at epoch 100
Train batch 1/31 - 237.0ms/batch - loss: 34.82946 - diff: 18.76mlTrain batch 2/31 - 236.9ms/batch - loss: 24.36340 - diff: 16.00mlTrain batch 3/31 - 237.9ms/batch - loss: 17.55677 - diff: 12.95mlTrain batch 4/31 - 239.9ms/batch - loss: 15.74382 - diff: 12.50mlTrain batch 5/31 - 237.0ms/batch - loss: 22.25844 - diff: 14.28mlTrain batch 6/31 - 238.5ms/batch - loss: 22.30793 - diff: 14.61mlTrain batch 7/31 - 237.2ms/batch - loss: 23.05795 - diff: 14.53mlTrain batch 8/31 - 239.1ms/batch - loss: 21.16899 - diff: 13.79mlTrain batch 9/31 - 237.6ms/batch - loss: 20.36717 - diff: 13.72mlTrain batch 10/31 - 237.7ms/batch - loss: 19.96272 - diff: 13.70mlTrain batch 11/31 - 238.0ms/batch - loss: 18.95913 - diff: 13.37mlTrain batch 12/31 - 240.3ms/batch - loss: 18.26461 - diff: 13.22mlTrain batch 13/31 - 237.8ms/batch - loss: 17.77268 - diff: 13.06mlTrain batch 14/31 - 239.3ms/batch - loss: 17.28775 - diff: 12.88mlTrain batch 15/31 - 237.9ms/batch - loss: 17.03844 - diff: 12.81mlTrain batch 16/31 - 240.2ms/batch - loss: 16.99471 - diff: 12.87mlTrain batch 17/31 - 237.5ms/batch - loss: 16.84776 - diff: 12.88mlTrain batch 18/31 - 237.9ms/batch - loss: 16.66714 - diff: 12.88mlTrain batch 19/31 - 237.6ms/batch - loss: 17.21330 - diff: 13.13mlTrain batch 20/31 - 238.9ms/batch - loss: 17.16793 - diff: 13.13mlTrain batch 21/31 - 237.6ms/batch - loss: 18.78635 - diff: 13.58mlTrain batch 22/31 - 240.1ms/batch - loss: 18.63607 - diff: 13.47mlTrain batch 23/31 - 237.6ms/batch - loss: 18.21426 - diff: 13.28mlTrain batch 24/31 - 237.7ms/batch - loss: 17.98341 - diff: 13.25mlTrain batch 25/31 - 238.5ms/batch - loss: 17.97194 - diff: 13.25mlTrain batch 26/31 - 238.6ms/batch - loss: 17.91131 - diff: 13.26mlTrain batch 27/31 - 237.4ms/batch - loss: 17.67187 - diff: 13.14mlTrain batch 28/31 - 239.7ms/batch - loss: 18.51478 - diff: 13.24mlTrain batch 29/31 - 237.2ms/batch - loss: 18.38871 - diff: 13.22mlTrain batch 30/31 - 238.8ms/batch - loss: 18.35102 - diff: 13.21mlTrain batch 31/31 - 124.7ms/batch - loss: 18.84019 - diff: 13.27mlTrain batch 31/31 - 11.9s 124.7ms/batch - loss: 18.84019 - diff: 13.27ml
Test 1.1s: val_loss: 35.98026 - diff: 16.06ml

Epoch 114: current best loss = 35.62473, at epoch 100
Train batch 1/31 - 237.2ms/batch - loss: 28.15812 - diff: 16.61mlTrain batch 2/31 - 238.0ms/batch - loss: 23.28179 - diff: 15.87mlTrain batch 3/31 - 238.0ms/batch - loss: 20.82183 - diff: 15.00mlTrain batch 4/31 - 238.5ms/batch - loss: 18.83465 - diff: 14.19mlTrain batch 5/31 - 237.6ms/batch - loss: 19.95723 - diff: 14.90mlTrain batch 6/31 - 239.6ms/batch - loss: 17.94247 - diff: 13.85mlTrain batch 7/31 - 237.7ms/batch - loss: 17.48117 - diff: 13.65mlTrain batch 8/31 - 237.9ms/batch - loss: 18.29961 - diff: 13.76mlTrain batch 9/31 - 237.8ms/batch - loss: 17.91504 - diff: 13.68mlTrain batch 10/31 - 240.2ms/batch - loss: 18.11557 - diff: 13.77mlTrain batch 11/31 - 238.1ms/batch - loss: 16.86692 - diff: 13.11mlTrain batch 12/31 - 238.7ms/batch - loss: 16.71887 - diff: 12.99mlTrain batch 13/31 - 237.9ms/batch - loss: 16.56908 - diff: 12.99mlTrain batch 14/31 - 239.6ms/batch - loss: 16.61417 - diff: 12.97mlTrain batch 15/31 - 237.7ms/batch - loss: 16.47417 - diff: 12.88mlTrain batch 16/31 - 240.1ms/batch - loss: 16.25492 - diff: 12.78mlTrain batch 17/31 - 237.8ms/batch - loss: 16.08051 - diff: 12.66mlTrain batch 18/31 - 240.1ms/batch - loss: 16.13948 - diff: 12.72mlTrain batch 19/31 - 238.1ms/batch - loss: 15.88492 - diff: 12.63mlTrain batch 20/31 - 239.7ms/batch - loss: 15.51266 - diff: 12.50mlTrain batch 21/31 - 237.9ms/batch - loss: 16.83720 - diff: 12.78mlTrain batch 22/31 - 239.0ms/batch - loss: 17.18081 - diff: 12.87mlTrain batch 23/31 - 237.6ms/batch - loss: 17.52715 - diff: 13.05mlTrain batch 24/31 - 239.5ms/batch - loss: 18.31830 - diff: 13.24mlTrain batch 25/31 - 237.8ms/batch - loss: 18.16285 - diff: 13.19mlTrain batch 26/31 - 240.3ms/batch - loss: 19.53836 - diff: 13.59mlTrain batch 27/31 - 238.4ms/batch - loss: 19.49429 - diff: 13.53mlTrain batch 28/31 - 238.2ms/batch - loss: 19.17511 - diff: 13.38mlTrain batch 29/31 - 237.4ms/batch - loss: 19.06016 - diff: 13.36mlTrain batch 30/31 - 238.8ms/batch - loss: 19.23854 - diff: 13.45mlTrain batch 31/31 - 124.5ms/batch - loss: 19.65431 - diff: 13.45mlTrain batch 31/31 - 11.4s 124.5ms/batch - loss: 19.65431 - diff: 13.45ml
Test 1.1s: val_loss: 33.93895 - diff: 15.85ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Systole_WideResNet50_0_Adam-0.001_MSE_DA3_best

Epoch 115: current best loss = 33.93895, at epoch 114
Train batch 1/31 - 236.8ms/batch - loss: 13.73919 - diff: 11.63mlTrain batch 2/31 - 237.2ms/batch - loss: 17.00354 - diff: 13.69mlTrain batch 3/31 - 237.6ms/batch - loss: 16.14059 - diff: 13.37mlTrain batch 4/31 - 238.8ms/batch - loss: 18.62622 - diff: 14.25mlTrain batch 5/31 - 237.5ms/batch - loss: 16.48468 - diff: 13.12mlTrain batch 6/31 - 238.0ms/batch - loss: 17.24846 - diff: 13.21mlTrain batch 7/31 - 237.6ms/batch - loss: 15.97882 - diff: 12.74mlTrain batch 8/31 - 238.3ms/batch - loss: 17.66697 - diff: 12.91mlTrain batch 9/31 - 237.8ms/batch - loss: 18.17342 - diff: 13.31mlTrain batch 10/31 - 238.0ms/batch - loss: 17.71364 - diff: 13.22mlTrain batch 11/31 - 237.8ms/batch - loss: 17.61132 - diff: 13.15mlTrain batch 12/31 - 240.1ms/batch - loss: 17.84172 - diff: 13.17mlTrain batch 13/31 - 239.3ms/batch - loss: 19.90567 - diff: 13.71mlTrain batch 14/31 - 238.0ms/batch - loss: 19.45188 - diff: 13.63mlTrain batch 15/31 - 237.5ms/batch - loss: 19.33774 - diff: 13.68mlTrain batch 16/31 - 240.1ms/batch - loss: 18.86463 - diff: 13.57mlTrain batch 17/31 - 237.8ms/batch - loss: 18.41528 - diff: 13.39mlTrain batch 18/31 - 238.0ms/batch - loss: 19.68184 - diff: 13.82mlTrain batch 19/31 - 240.9ms/batch - loss: 19.21709 - diff: 13.66mlTrain batch 20/31 - 239.0ms/batch - loss: 18.80194 - diff: 13.47mlTrain batch 21/31 - 237.7ms/batch - loss: 19.39858 - diff: 13.49mlTrain batch 22/31 - 240.2ms/batch - loss: 19.48509 - diff: 13.48mlTrain batch 23/31 - 238.2ms/batch - loss: 19.74705 - diff: 13.59mlTrain batch 24/31 - 237.9ms/batch - loss: 19.42885 - diff: 13.47mlTrain batch 25/31 - 237.9ms/batch - loss: 19.49645 - diff: 13.53mlTrain batch 26/31 - 239.1ms/batch - loss: 19.70161 - diff: 13.69mlTrain batch 27/31 - 238.6ms/batch - loss: 19.58684 - diff: 13.72mlTrain batch 28/31 - 236.6ms/batch - loss: 19.28587 - diff: 13.59mlTrain batch 29/31 - 237.6ms/batch - loss: 19.57678 - diff: 13.63mlTrain batch 30/31 - 239.6ms/batch - loss: 19.27447 - diff: 13.54mlTrain batch 31/31 - 123.2ms/batch - loss: 19.50332 - diff: 13.51mlTrain batch 31/31 - 11.2s 123.2ms/batch - loss: 19.50332 - diff: 13.51ml
Test 1.1s: val_loss: 32.96686 - diff: 15.85ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Systole_WideResNet50_0_Adam-0.001_MSE_DA3_best

Epoch 116: current best loss = 32.96686, at epoch 115
Train batch 1/31 - 237.0ms/batch - loss: 17.80814 - diff: 12.44mlTrain batch 2/31 - 237.6ms/batch - loss: 15.07608 - diff: 11.15mlTrain batch 3/31 - 237.0ms/batch - loss: 14.34413 - diff: 11.22mlTrain batch 4/31 - 237.8ms/batch - loss: 13.83912 - diff: 10.71mlTrain batch 5/31 - 237.7ms/batch - loss: 13.95381 - diff: 11.16mlTrain batch 6/31 - 238.8ms/batch - loss: 15.53376 - diff: 11.89mlTrain batch 7/31 - 238.5ms/batch - loss: 18.33412 - diff: 12.60mlTrain batch 8/31 - 238.7ms/batch - loss: 17.63155 - diff: 12.51mlTrain batch 9/31 - 237.8ms/batch - loss: 16.90328 - diff: 12.23mlTrain batch 10/31 - 241.4ms/batch - loss: 16.90617 - diff: 12.40mlTrain batch 11/31 - 238.3ms/batch - loss: 16.27578 - diff: 12.31mlTrain batch 12/31 - 237.4ms/batch - loss: 16.54943 - diff: 12.48mlTrain batch 13/31 - 238.1ms/batch - loss: 16.41810 - diff: 12.51mlTrain batch 14/31 - 237.4ms/batch - loss: 16.48750 - diff: 12.44mlTrain batch 15/31 - 237.8ms/batch - loss: 17.26215 - diff: 12.76mlTrain batch 16/31 - 237.3ms/batch - loss: 16.80279 - diff: 12.60mlTrain batch 17/31 - 238.5ms/batch - loss: 16.75773 - diff: 12.66mlTrain batch 18/31 - 237.9ms/batch - loss: 16.91399 - diff: 12.80mlTrain batch 19/31 - 238.3ms/batch - loss: 21.12491 - diff: 13.53mlTrain batch 20/31 - 237.3ms/batch - loss: 20.94807 - diff: 13.48mlTrain batch 21/31 - 240.3ms/batch - loss: 20.66459 - diff: 13.43mlTrain batch 22/31 - 239.8ms/batch - loss: 21.03398 - diff: 13.57mlTrain batch 23/31 - 238.3ms/batch - loss: 20.48938 - diff: 13.41mlTrain batch 24/31 - 237.2ms/batch - loss: 19.97199 - diff: 13.25mlTrain batch 25/31 - 238.4ms/batch - loss: 19.56589 - diff: 13.14mlTrain batch 26/31 - 238.0ms/batch - loss: 19.22745 - diff: 13.03mlTrain batch 27/31 - 240.2ms/batch - loss: 19.04343 - diff: 12.99mlTrain batch 28/31 - 238.8ms/batch - loss: 18.77566 - diff: 12.94mlTrain batch 29/31 - 237.8ms/batch - loss: 18.62540 - diff: 12.90mlTrain batch 30/31 - 237.8ms/batch - loss: 18.85143 - diff: 12.97mlTrain batch 31/31 - 124.8ms/batch - loss: 19.02655 - diff: 12.96mlTrain batch 31/31 - 11.4s 124.8ms/batch - loss: 19.02655 - diff: 12.96ml
Test 1.2s: val_loss: 37.08973 - diff: 16.19ml

Epoch 117: current best loss = 32.96686, at epoch 115
Train batch 1/31 - 236.7ms/batch - loss: 43.57943 - diff: 20.75mlTrain batch 2/31 - 237.7ms/batch - loss: 31.76891 - diff: 16.35mlTrain batch 3/31 - 238.1ms/batch - loss: 27.67363 - diff: 15.86mlTrain batch 4/31 - 238.7ms/batch - loss: 23.97797 - diff: 14.47mlTrain batch 5/31 - 237.2ms/batch - loss: 21.95152 - diff: 13.89mlTrain batch 6/31 - 240.1ms/batch - loss: 20.52635 - diff: 13.77mlTrain batch 7/31 - 237.7ms/batch - loss: 20.93564 - diff: 13.95mlTrain batch 8/31 - 239.9ms/batch - loss: 24.00474 - diff: 14.71mlTrain batch 9/31 - 237.8ms/batch - loss: 22.83521 - diff: 14.47mlTrain batch 10/31 - 240.4ms/batch - loss: 21.52206 - diff: 14.05mlTrain batch 11/31 - 238.0ms/batch - loss: 20.82583 - diff: 13.87mlTrain batch 12/31 - 238.9ms/batch - loss: 20.78450 - diff: 13.91mlTrain batch 13/31 - 238.3ms/batch - loss: 21.25862 - diff: 13.82mlTrain batch 14/31 - 238.2ms/batch - loss: 21.45347 - diff: 13.82mlTrain batch 15/31 - 237.9ms/batch - loss: 20.64200 - diff: 13.54mlTrain batch 16/31 - 238.4ms/batch - loss: 20.19072 - diff: 13.44mlTrain batch 17/31 - 238.1ms/batch - loss: 19.90487 - diff: 13.39mlTrain batch 18/31 - 239.4ms/batch - loss: 19.68404 - diff: 13.42mlTrain batch 19/31 - 237.5ms/batch - loss: 19.38809 - diff: 13.33mlTrain batch 20/31 - 240.3ms/batch - loss: 20.08646 - diff: 13.64mlTrain batch 21/31 - 237.9ms/batch - loss: 19.52307 - diff: 13.42mlTrain batch 22/31 - 240.1ms/batch - loss: 18.96667 - diff: 13.19mlTrain batch 23/31 - 238.1ms/batch - loss: 18.93749 - diff: 13.11mlTrain batch 24/31 - 240.3ms/batch - loss: 19.24059 - diff: 13.25mlTrain batch 25/31 - 238.2ms/batch - loss: 19.30019 - diff: 13.25mlTrain batch 26/31 - 240.1ms/batch - loss: 19.09826 - diff: 13.19mlTrain batch 27/31 - 238.7ms/batch - loss: 18.87612 - diff: 13.14mlTrain batch 28/31 - 239.8ms/batch - loss: 18.72068 - diff: 13.13mlTrain batch 29/31 - 238.4ms/batch - loss: 18.98954 - diff: 13.25mlTrain batch 30/31 - 239.1ms/batch - loss: 18.81976 - diff: 13.24mlTrain batch 31/31 - 123.0ms/batch - loss: 18.74780 - diff: 13.17mlTrain batch 31/31 - 10.7s 123.0ms/batch - loss: 18.74780 - diff: 13.17ml
Test 1.1s: val_loss: 34.47942 - diff: 15.97ml

Epoch 118: current best loss = 32.96686, at epoch 115
Train batch 1/31 - 237.3ms/batch - loss: 10.73996 - diff: 10.01mlTrain batch 2/31 - 237.1ms/batch - loss: 21.79529 - diff: 12.26mlTrain batch 3/31 - 237.2ms/batch - loss: 24.29539 - diff: 13.65mlTrain batch 4/31 - 239.9ms/batch - loss: 24.67209 - diff: 14.39mlTrain batch 5/31 - 238.3ms/batch - loss: 23.02240 - diff: 14.14mlTrain batch 6/31 - 238.8ms/batch - loss: 20.87958 - diff: 13.34mlTrain batch 7/31 - 237.7ms/batch - loss: 21.09800 - diff: 13.66mlTrain batch 8/31 - 240.1ms/batch - loss: 19.59453 - diff: 13.25mlTrain batch 9/31 - 238.2ms/batch - loss: 19.03077 - diff: 13.16mlTrain batch 10/31 - 238.9ms/batch - loss: 18.95120 - diff: 13.17mlTrain batch 11/31 - 238.0ms/batch - loss: 19.83909 - diff: 13.20mlTrain batch 12/31 - 239.8ms/batch - loss: 19.80573 - diff: 13.17mlTrain batch 13/31 - 237.7ms/batch - loss: 19.59885 - diff: 13.12mlTrain batch 14/31 - 240.1ms/batch - loss: 19.70344 - diff: 13.23mlTrain batch 15/31 - 238.1ms/batch - loss: 20.38386 - diff: 13.42mlTrain batch 16/31 - 240.4ms/batch - loss: 20.81065 - diff: 13.66mlTrain batch 17/31 - 238.0ms/batch - loss: 20.15119 - diff: 13.47mlTrain batch 18/31 - 240.2ms/batch - loss: 20.31450 - diff: 13.66mlTrain batch 19/31 - 236.9ms/batch - loss: 20.28032 - diff: 13.68mlTrain batch 20/31 - 240.1ms/batch - loss: 19.94222 - diff: 13.52mlTrain batch 21/31 - 237.4ms/batch - loss: 19.80141 - diff: 13.52mlTrain batch 22/31 - 239.6ms/batch - loss: 19.85911 - diff: 13.60mlTrain batch 23/31 - 238.0ms/batch - loss: 21.16799 - diff: 13.97mlTrain batch 24/31 - 239.0ms/batch - loss: 20.60785 - diff: 13.78mlTrain batch 25/31 - 237.9ms/batch - loss: 19.90986 - diff: 13.45mlTrain batch 26/31 - 240.2ms/batch - loss: 19.58706 - diff: 13.35mlTrain batch 27/31 - 238.0ms/batch - loss: 19.26280 - diff: 13.17mlTrain batch 28/31 - 240.1ms/batch - loss: 19.63357 - diff: 13.35mlTrain batch 29/31 - 237.7ms/batch - loss: 19.07699 - diff: 13.10mlTrain batch 30/31 - 240.1ms/batch - loss: 20.21276 - diff: 13.41mlTrain batch 31/31 - 124.7ms/batch - loss: 20.33956 - diff: 13.38mlTrain batch 31/31 - 11.3s 124.7ms/batch - loss: 20.33956 - diff: 13.38ml
Test 1.2s: val_loss: 37.21172 - diff: 16.13ml

Epoch 119: current best loss = 32.96686, at epoch 115
Train batch 1/31 - 237.3ms/batch - loss: 20.49909 - diff: 11.64mlTrain batch 2/31 - 240.2ms/batch - loss: 16.78702 - diff: 11.47mlTrain batch 3/31 - 238.5ms/batch - loss: 13.52678 - diff: 10.49mlTrain batch 4/31 - 239.9ms/batch - loss: 11.73064 - diff: 9.87mlTrain batch 5/31 - 237.9ms/batch - loss: 12.76017 - diff: 10.43mlTrain batch 6/31 - 240.0ms/batch - loss: 12.62880 - diff: 10.57mlTrain batch 7/31 - 237.7ms/batch - loss: 13.52563 - diff: 10.84mlTrain batch 8/31 - 240.1ms/batch - loss: 13.35356 - diff: 10.69mlTrain batch 9/31 - 237.8ms/batch - loss: 12.48080 - diff: 10.34mlTrain batch 10/31 - 240.1ms/batch - loss: 12.97350 - diff: 10.50mlTrain batch 11/31 - 237.7ms/batch - loss: 12.59011 - diff: 10.50mlTrain batch 12/31 - 239.3ms/batch - loss: 12.16198 - diff: 10.42mlTrain batch 13/31 - 238.0ms/batch - loss: 12.38882 - diff: 10.49mlTrain batch 14/31 - 239.6ms/batch - loss: 12.61941 - diff: 10.54mlTrain batch 15/31 - 237.8ms/batch - loss: 13.28858 - diff: 10.74mlTrain batch 16/31 - 240.2ms/batch - loss: 13.05550 - diff: 10.72mlTrain batch 17/31 - 238.2ms/batch - loss: 14.06145 - diff: 11.06mlTrain batch 18/31 - 239.9ms/batch - loss: 14.06523 - diff: 11.10mlTrain batch 19/31 - 237.8ms/batch - loss: 14.22884 - diff: 11.18mlTrain batch 20/31 - 240.1ms/batch - loss: 14.43693 - diff: 11.33mlTrain batch 21/31 - 237.7ms/batch - loss: 14.44021 - diff: 11.32mlTrain batch 22/31 - 240.1ms/batch - loss: 14.19586 - diff: 11.25mlTrain batch 23/31 - 238.3ms/batch - loss: 14.54332 - diff: 11.40mlTrain batch 24/31 - 237.6ms/batch - loss: 14.65453 - diff: 11.51mlTrain batch 25/31 - 237.7ms/batch - loss: 14.59780 - diff: 11.51mlTrain batch 26/31 - 240.1ms/batch - loss: 15.90236 - diff: 11.83mlTrain batch 27/31 - 238.5ms/batch - loss: 16.40098 - diff: 12.00mlTrain batch 28/31 - 239.8ms/batch - loss: 16.14575 - diff: 11.90mlTrain batch 29/31 - 237.7ms/batch - loss: 16.06834 - diff: 11.86mlTrain batch 30/31 - 238.3ms/batch - loss: 16.28720 - diff: 11.93mlTrain batch 31/31 - 125.0ms/batch - loss: 17.38215 - diff: 12.00mlTrain batch 31/31 - 11.1s 125.0ms/batch - loss: 17.38215 - diff: 12.00ml
Test 1.2s: val_loss: 39.76760 - diff: 15.83ml

Epoch 120: current best loss = 32.96686, at epoch 115
Train batch 1/31 - 236.8ms/batch - loss: 19.91381 - diff: 11.94mlTrain batch 2/31 - 240.2ms/batch - loss: 21.92589 - diff: 13.84mlTrain batch 3/31 - 237.6ms/batch - loss: 17.01856 - diff: 12.23mlTrain batch 4/31 - 242.7ms/batch - loss: 19.61569 - diff: 13.34mlTrain batch 5/31 - 237.3ms/batch - loss: 18.38958 - diff: 12.54mlTrain batch 6/31 - 237.2ms/batch - loss: 18.93249 - diff: 12.67mlTrain batch 7/31 - 243.6ms/batch - loss: 19.88030 - diff: 13.16mlTrain batch 8/31 - 238.9ms/batch - loss: 18.73346 - diff: 12.72mlTrain batch 9/31 - 239.0ms/batch - loss: 20.56945 - diff: 13.64mlTrain batch 10/31 - 238.9ms/batch - loss: 21.57472 - diff: 13.90mlTrain batch 11/31 - 237.2ms/batch - loss: 21.34409 - diff: 13.70mlTrain batch 12/31 - 238.5ms/batch - loss: 20.05028 - diff: 13.18mlTrain batch 13/31 - 238.4ms/batch - loss: 19.05459 - diff: 12.83mlTrain batch 14/31 - 240.2ms/batch - loss: 18.48435 - diff: 12.65mlTrain batch 15/31 - 237.9ms/batch - loss: 18.37844 - diff: 12.71mlTrain batch 16/31 - 240.0ms/batch - loss: 18.26809 - diff: 12.77mlTrain batch 17/31 - 238.0ms/batch - loss: 18.06412 - diff: 12.74mlTrain batch 18/31 - 240.1ms/batch - loss: 18.16738 - diff: 12.75mlTrain batch 19/31 - 237.9ms/batch - loss: 17.79874 - diff: 12.62mlTrain batch 20/31 - 239.2ms/batch - loss: 17.38457 - diff: 12.49mlTrain batch 21/31 - 237.6ms/batch - loss: 17.03453 - diff: 12.39mlTrain batch 22/31 - 238.3ms/batch - loss: 17.11599 - diff: 12.39mlTrain batch 23/31 - 238.3ms/batch - loss: 16.75710 - diff: 12.25mlTrain batch 24/31 - 239.9ms/batch - loss: 16.80716 - diff: 12.25mlTrain batch 25/31 - 238.0ms/batch - loss: 17.99909 - diff: 12.60mlTrain batch 26/31 - 240.3ms/batch - loss: 17.63187 - diff: 12.49mlTrain batch 27/31 - 238.5ms/batch - loss: 17.59389 - diff: 12.50mlTrain batch 28/31 - 240.0ms/batch - loss: 17.26091 - diff: 12.39mlTrain batch 29/31 - 237.9ms/batch - loss: 16.96525 - diff: 12.29mlTrain batch 30/31 - 239.6ms/batch - loss: 17.19510 - diff: 12.37mlTrain batch 31/31 - 124.4ms/batch - loss: 17.46906 - diff: 12.36mlTrain batch 31/31 - 11.8s 124.4ms/batch - loss: 17.46906 - diff: 12.36ml
Test 1.2s: val_loss: 35.74509 - diff: 15.59ml

Epoch 121: current best loss = 32.96686, at epoch 115
Train batch 1/31 - 237.6ms/batch - loss: 4.22107 - diff: 6.71mlTrain batch 2/31 - 239.9ms/batch - loss: 11.75840 - diff: 11.02mlTrain batch 3/31 - 237.3ms/batch - loss: 15.80975 - diff: 12.38mlTrain batch 4/31 - 238.2ms/batch - loss: 15.14772 - diff: 11.98mlTrain batch 5/31 - 238.0ms/batch - loss: 14.12354 - diff: 11.68mlTrain batch 6/31 - 239.7ms/batch - loss: 17.56022 - diff: 12.88mlTrain batch 7/31 - 237.8ms/batch - loss: 19.28928 - diff: 13.45mlTrain batch 8/31 - 239.0ms/batch - loss: 19.63805 - diff: 13.55mlTrain batch 9/31 - 237.6ms/batch - loss: 19.33003 - diff: 13.44mlTrain batch 10/31 - 237.5ms/batch - loss: 18.38413 - diff: 13.05mlTrain batch 11/31 - 240.0ms/batch - loss: 18.65562 - diff: 12.98mlTrain batch 12/31 - 240.4ms/batch - loss: 18.25185 - diff: 12.83mlTrain batch 13/31 - 238.7ms/batch - loss: 19.02332 - diff: 13.09mlTrain batch 14/31 - 237.6ms/batch - loss: 18.29465 - diff: 12.83mlTrain batch 15/31 - 238.3ms/batch - loss: 17.47437 - diff: 12.51mlTrain batch 16/31 - 239.7ms/batch - loss: 17.04255 - diff: 12.37mlTrain batch 17/31 - 238.7ms/batch - loss: 16.83297 - diff: 12.29mlTrain batch 18/31 - 237.5ms/batch - loss: 16.78122 - diff: 12.36mlTrain batch 19/31 - 240.1ms/batch - loss: 21.75986 - diff: 13.28mlTrain batch 20/31 - 239.7ms/batch - loss: 21.57953 - diff: 13.21mlTrain batch 21/31 - 238.3ms/batch - loss: 20.97953 - diff: 13.05mlTrain batch 22/31 - 237.8ms/batch - loss: 20.37324 - diff: 12.85mlTrain batch 23/31 - 240.0ms/batch - loss: 20.16430 - diff: 12.87mlTrain batch 24/31 - 240.4ms/batch - loss: 19.53169 - diff: 12.61mlTrain batch 25/31 - 237.8ms/batch - loss: 19.54014 - diff: 12.69mlTrain batch 26/31 - 237.3ms/batch - loss: 19.06439 - diff: 12.52mlTrain batch 27/31 - 240.2ms/batch - loss: 19.00014 - diff: 12.51mlTrain batch 28/31 - 237.9ms/batch - loss: 18.52842 - diff: 12.33mlTrain batch 29/31 - 239.8ms/batch - loss: 18.34052 - diff: 12.30mlTrain batch 30/31 - 238.3ms/batch - loss: 18.21084 - diff: 12.32mlTrain batch 31/31 - 123.7ms/batch - loss: 18.10100 - diff: 12.25mlTrain batch 31/31 - 11.7s 123.7ms/batch - loss: 18.10100 - diff: 12.25ml
Test 1.1s: val_loss: 35.04895 - diff: 15.79ml

Epoch 122: current best loss = 32.96686, at epoch 115
Train batch 1/31 - 237.2ms/batch - loss: 24.78453 - diff: 13.09mlTrain batch 2/31 - 239.8ms/batch - loss: 20.28250 - diff: 13.18mlTrain batch 3/31 - 237.4ms/batch - loss: 20.10645 - diff: 13.97mlTrain batch 4/31 - 238.3ms/batch - loss: 19.12753 - diff: 14.10mlTrain batch 5/31 - 237.2ms/batch - loss: 17.29674 - diff: 13.22mlTrain batch 6/31 - 238.9ms/batch - loss: 17.46918 - diff: 13.08mlTrain batch 7/31 - 238.2ms/batch - loss: 16.13092 - diff: 12.45mlTrain batch 8/31 - 239.9ms/batch - loss: 17.52369 - diff: 12.75mlTrain batch 9/31 - 238.0ms/batch - loss: 16.66652 - diff: 12.40mlTrain batch 10/31 - 239.0ms/batch - loss: 16.14935 - diff: 12.21mlTrain batch 11/31 - 237.9ms/batch - loss: 15.59643 - diff: 11.97mlTrain batch 12/31 - 238.8ms/batch - loss: 15.62681 - diff: 12.20mlTrain batch 13/31 - 238.0ms/batch - loss: 16.82388 - diff: 12.54mlTrain batch 14/31 - 240.2ms/batch - loss: 17.78979 - diff: 12.85mlTrain batch 15/31 - 237.9ms/batch - loss: 18.35537 - diff: 13.08mlTrain batch 16/31 - 240.1ms/batch - loss: 18.00617 - diff: 12.98mlTrain batch 17/31 - 238.1ms/batch - loss: 17.40210 - diff: 12.79mlTrain batch 18/31 - 239.8ms/batch - loss: 17.55686 - diff: 12.88mlTrain batch 19/31 - 238.2ms/batch - loss: 18.03008 - diff: 12.87mlTrain batch 20/31 - 240.3ms/batch - loss: 17.38133 - diff: 12.58mlTrain batch 21/31 - 237.6ms/batch - loss: 17.03002 - diff: 12.47mlTrain batch 22/31 - 239.0ms/batch - loss: 17.06806 - diff: 12.47mlTrain batch 23/31 - 237.4ms/batch - loss: 16.56568 - diff: 12.27mlTrain batch 24/31 - 240.3ms/batch - loss: 17.06429 - diff: 12.48mlTrain batch 25/31 - 237.4ms/batch - loss: 16.85319 - diff: 12.37mlTrain batch 26/31 - 239.3ms/batch - loss: 16.76001 - diff: 12.39mlTrain batch 27/31 - 237.9ms/batch - loss: 18.29488 - diff: 12.66mlTrain batch 28/31 - 240.1ms/batch - loss: 18.03960 - diff: 12.63mlTrain batch 29/31 - 237.7ms/batch - loss: 17.90871 - diff: 12.61mlTrain batch 30/31 - 240.3ms/batch - loss: 17.69698 - diff: 12.53mlTrain batch 31/31 - 124.7ms/batch - loss: 17.70669 - diff: 12.48mlTrain batch 31/31 - 11.3s 124.7ms/batch - loss: 17.70669 - diff: 12.48ml
Test 1.2s: val_loss: 39.60420 - diff: 15.76ml

Epoch 123: current best loss = 32.96686, at epoch 115
Train batch 1/31 - 237.0ms/batch - loss: 17.58825 - diff: 13.52mlTrain batch 2/31 - 238.4ms/batch - loss: 15.83856 - diff: 12.43mlTrain batch 3/31 - 238.3ms/batch - loss: 14.29476 - diff: 11.96mlTrain batch 4/31 - 239.9ms/batch - loss: 15.35278 - diff: 12.68mlTrain batch 5/31 - 238.0ms/batch - loss: 15.03651 - diff: 12.58mlTrain batch 6/31 - 239.9ms/batch - loss: 13.95292 - diff: 12.10mlTrain batch 7/31 - 238.5ms/batch - loss: 13.65647 - diff: 12.04mlTrain batch 8/31 - 239.3ms/batch - loss: 16.32315 - diff: 12.40mlTrain batch 9/31 - 238.3ms/batch - loss: 17.17962 - diff: 12.78mlTrain batch 10/31 - 239.4ms/batch - loss: 16.99137 - diff: 12.87mlTrain batch 11/31 - 237.7ms/batch - loss: 16.81123 - diff: 12.89mlTrain batch 12/31 - 240.1ms/batch - loss: 16.80093 - diff: 12.95mlTrain batch 13/31 - 237.7ms/batch - loss: 16.23125 - diff: 12.64mlTrain batch 14/31 - 240.2ms/batch - loss: 15.89329 - diff: 12.53mlTrain batch 15/31 - 238.0ms/batch - loss: 15.31674 - diff: 12.34mlTrain batch 16/31 - 240.4ms/batch - loss: 15.18777 - diff: 12.29mlTrain batch 17/31 - 238.6ms/batch - loss: 15.27402 - diff: 12.28mlTrain batch 18/31 - 240.2ms/batch - loss: 15.10548 - diff: 12.19mlTrain batch 19/31 - 238.0ms/batch - loss: 14.83345 - diff: 12.09mlTrain batch 20/31 - 240.0ms/batch - loss: 15.42998 - diff: 12.29mlTrain batch 21/31 - 238.4ms/batch - loss: 15.46177 - diff: 12.26mlTrain batch 22/31 - 239.9ms/batch - loss: 15.33113 - diff: 12.18mlTrain batch 23/31 - 237.9ms/batch - loss: 15.29858 - diff: 12.19mlTrain batch 24/31 - 239.4ms/batch - loss: 15.73682 - diff: 12.45mlTrain batch 25/31 - 237.9ms/batch - loss: 15.81911 - diff: 12.51mlTrain batch 26/31 - 241.3ms/batch - loss: 15.47090 - diff: 12.36mlTrain batch 27/31 - 245.3ms/batch - loss: 15.40907 - diff: 12.34mlTrain batch 28/31 - 237.9ms/batch - loss: 15.30695 - diff: 12.34mlTrain batch 29/31 - 237.8ms/batch - loss: 15.13250 - diff: 12.25mlTrain batch 30/31 - 239.9ms/batch - loss: 15.57394 - diff: 12.34mlTrain batch 31/31 - 124.9ms/batch - loss: 15.99286 - diff: 12.35mlTrain batch 31/31 - 10.7s 124.9ms/batch - loss: 15.99286 - diff: 12.35ml
Test 1.1s: val_loss: 33.89290 - diff: 15.58ml

Epoch 124: current best loss = 32.96686, at epoch 115
Train batch 1/31 - 237.9ms/batch - loss: 10.22197 - diff: 9.62mlTrain batch 2/31 - 239.6ms/batch - loss: 13.55023 - diff: 11.19mlTrain batch 3/31 - 239.7ms/batch - loss: 17.93486 - diff: 12.76mlTrain batch 4/31 - 240.3ms/batch - loss: 15.02354 - diff: 11.72mlTrain batch 5/31 - 237.5ms/batch - loss: 14.01067 - diff: 11.37mlTrain batch 6/31 - 239.7ms/batch - loss: 13.21513 - diff: 11.28mlTrain batch 7/31 - 244.5ms/batch - loss: 12.87324 - diff: 11.10mlTrain batch 8/31 - 237.9ms/batch - loss: 13.82795 - diff: 11.38mlTrain batch 9/31 - 240.3ms/batch - loss: 14.08097 - diff: 11.55mlTrain batch 10/31 - 237.8ms/batch - loss: 14.57117 - diff: 11.60mlTrain batch 11/31 - 238.0ms/batch - loss: 14.28462 - diff: 11.57mlTrain batch 12/31 - 240.2ms/batch - loss: 13.78391 - diff: 11.27mlTrain batch 13/31 - 239.2ms/batch - loss: 14.39573 - diff: 11.46mlTrain batch 14/31 - 239.6ms/batch - loss: 14.25545 - diff: 11.45mlTrain batch 15/31 - 237.7ms/batch - loss: 15.95094 - diff: 11.99mlTrain batch 16/31 - 238.2ms/batch - loss: 15.31524 - diff: 11.70mlTrain batch 17/31 - 237.6ms/batch - loss: 15.61450 - diff: 11.84mlTrain batch 18/31 - 240.3ms/batch - loss: 15.48375 - diff: 11.70mlTrain batch 19/31 - 237.6ms/batch - loss: 16.39909 - diff: 12.03mlTrain batch 20/31 - 239.6ms/batch - loss: 15.76227 - diff: 11.70mlTrain batch 21/31 - 238.3ms/batch - loss: 15.77761 - diff: 11.70mlTrain batch 22/31 - 240.1ms/batch - loss: 15.68913 - diff: 11.75mlTrain batch 23/31 - 238.6ms/batch - loss: 16.03891 - diff: 11.97mlTrain batch 24/31 - 239.7ms/batch - loss: 15.72724 - diff: 11.88mlTrain batch 25/31 - 237.6ms/batch - loss: 16.00942 - diff: 11.98mlTrain batch 26/31 - 240.0ms/batch - loss: 16.00932 - diff: 12.04mlTrain batch 27/31 - 240.5ms/batch - loss: 15.70822 - diff: 11.91mlTrain batch 28/31 - 240.3ms/batch - loss: 15.32933 - diff: 11.75mlTrain batch 29/31 - 238.4ms/batch - loss: 15.48616 - diff: 11.88mlTrain batch 30/31 - 237.9ms/batch - loss: 15.52866 - diff: 11.90mlTrain batch 31/31 - 124.7ms/batch - loss: 15.82676 - diff: 11.93mlTrain batch 31/31 - 11.2s 124.7ms/batch - loss: 15.82676 - diff: 11.93ml
Test 1.1s: val_loss: 35.77671 - diff: 16.66ml

Epoch 125: current best loss = 32.96686, at epoch 115
Train batch 1/31 - 237.5ms/batch - loss: 12.78582 - diff: 11.23mlTrain batch 2/31 - 238.1ms/batch - loss: 11.58552 - diff: 10.83mlTrain batch 3/31 - 238.1ms/batch - loss: 11.53490 - diff: 10.92mlTrain batch 4/31 - 238.0ms/batch - loss: 10.78332 - diff: 10.64mlTrain batch 5/31 - 238.5ms/batch - loss: 12.98028 - diff: 10.98mlTrain batch 6/31 - 247.2ms/batch - loss: 12.75531 - diff: 10.77mlTrain batch 7/31 - 237.8ms/batch - loss: 14.10170 - diff: 11.42mlTrain batch 8/31 - 239.9ms/batch - loss: 15.48526 - diff: 11.92mlTrain batch 9/31 - 237.4ms/batch - loss: 14.67857 - diff: 11.56mlTrain batch 10/31 - 238.3ms/batch - loss: 14.71012 - diff: 11.50mlTrain batch 11/31 - 239.8ms/batch - loss: 15.59845 - diff: 11.52mlTrain batch 12/31 - 237.4ms/batch - loss: 14.79639 - diff: 11.23mlTrain batch 13/31 - 241.5ms/batch - loss: 14.47375 - diff: 11.24mlTrain batch 14/31 - 237.5ms/batch - loss: 15.17453 - diff: 11.48mlTrain batch 15/31 - 238.0ms/batch - loss: 14.67020 - diff: 11.28mlTrain batch 16/31 - 238.2ms/batch - loss: 14.31735 - diff: 11.16mlTrain batch 17/31 - 238.8ms/batch - loss: 14.08596 - diff: 11.15mlTrain batch 18/31 - 238.2ms/batch - loss: 14.54816 - diff: 11.41mlTrain batch 19/31 - 239.6ms/batch - loss: 14.15893 - diff: 11.25mlTrain batch 20/31 - 237.3ms/batch - loss: 15.04013 - diff: 11.56mlTrain batch 21/31 - 239.9ms/batch - loss: 14.94888 - diff: 11.56mlTrain batch 22/31 - 238.9ms/batch - loss: 16.20691 - diff: 11.91mlTrain batch 23/31 - 240.5ms/batch - loss: 16.24973 - diff: 12.04mlTrain batch 24/31 - 239.1ms/batch - loss: 16.31938 - diff: 12.07mlTrain batch 25/31 - 240.5ms/batch - loss: 16.13240 - diff: 12.00mlTrain batch 26/31 - 237.9ms/batch - loss: 15.74304 - diff: 11.81mlTrain batch 27/31 - 240.5ms/batch - loss: 15.81614 - diff: 11.90mlTrain batch 28/31 - 238.1ms/batch - loss: 15.65719 - diff: 11.85mlTrain batch 29/31 - 240.0ms/batch - loss: 16.01560 - diff: 12.00mlTrain batch 30/31 - 238.2ms/batch - loss: 15.66077 - diff: 11.84mlTrain batch 31/31 - 123.6ms/batch - loss: 16.03360 - diff: 11.89mlTrain batch 31/31 - 11.0s 123.6ms/batch - loss: 16.03360 - diff: 11.89ml
Test 1.1s: val_loss: 40.44585 - diff: 16.33ml

Epoch 126: current best loss = 32.96686, at epoch 115
Train batch 1/31 - 237.8ms/batch - loss: 9.29015 - diff: 9.56mlTrain batch 2/31 - 239.0ms/batch - loss: 7.51399 - diff: 8.82mlTrain batch 3/31 - 238.5ms/batch - loss: 9.29594 - diff: 9.91mlTrain batch 4/31 - 240.1ms/batch - loss: 8.59130 - diff: 9.50mlTrain batch 5/31 - 237.6ms/batch - loss: 9.84211 - diff: 10.14mlTrain batch 6/31 - 240.3ms/batch - loss: 8.79590 - diff: 9.48mlTrain batch 7/31 - 242.3ms/batch - loss: 9.13401 - diff: 9.68mlTrain batch 8/31 - 237.8ms/batch - loss: 10.69734 - diff: 10.24mlTrain batch 9/31 - 237.6ms/batch - loss: 10.89419 - diff: 10.14mlTrain batch 10/31 - 238.5ms/batch - loss: 11.41956 - diff: 10.45mlTrain batch 11/31 - 238.1ms/batch - loss: 11.02572 - diff: 10.24mlTrain batch 12/31 - 243.9ms/batch - loss: 11.04290 - diff: 10.38mlTrain batch 13/31 - 237.8ms/batch - loss: 11.43475 - diff: 10.41mlTrain batch 14/31 - 239.8ms/batch - loss: 11.32224 - diff: 10.34mlTrain batch 15/31 - 240.0ms/batch - loss: 12.01486 - diff: 10.71mlTrain batch 16/31 - 238.7ms/batch - loss: 12.44393 - diff: 10.97mlTrain batch 17/31 - 240.2ms/batch - loss: 12.44023 - diff: 10.99mlTrain batch 18/31 - 238.2ms/batch - loss: 12.11594 - diff: 10.86mlTrain batch 19/31 - 238.6ms/batch - loss: 12.00848 - diff: 10.83mlTrain batch 20/31 - 237.9ms/batch - loss: 11.95947 - diff: 10.83mlTrain batch 21/31 - 244.6ms/batch - loss: 12.54950 - diff: 11.02mlTrain batch 22/31 - 237.9ms/batch - loss: 14.34037 - diff: 11.54mlTrain batch 23/31 - 240.5ms/batch - loss: 14.89147 - diff: 11.75mlTrain batch 24/31 - 237.9ms/batch - loss: 15.97689 - diff: 12.17mlTrain batch 25/31 - 240.2ms/batch - loss: 16.11282 - diff: 12.27mlTrain batch 26/31 - 243.0ms/batch - loss: 16.04835 - diff: 12.28mlTrain batch 27/31 - 236.5ms/batch - loss: 16.43512 - diff: 12.45mlTrain batch 28/31 - 238.6ms/batch - loss: 16.53458 - diff: 12.46mlTrain batch 29/31 - 238.6ms/batch - loss: 17.11263 - diff: 12.51mlTrain batch 30/31 - 238.8ms/batch - loss: 16.93761 - diff: 12.43mlTrain batch 31/31 - 123.9ms/batch - loss: 16.82944 - diff: 12.35mlTrain batch 31/31 - 11.5s 123.9ms/batch - loss: 16.82944 - diff: 12.35ml
Test 1.1s: val_loss: 37.60072 - diff: 16.10ml
Epoch   127: reducing learning rate of group 0 to 6.2500e-05.

Epoch 127: current best loss = 32.96686, at epoch 115
Train batch 1/31 - 238.8ms/batch - loss: 9.13860 - diff: 10.17mlTrain batch 2/31 - 239.9ms/batch - loss: 13.29644 - diff: 11.91mlTrain batch 3/31 - 237.7ms/batch - loss: 11.81012 - diff: 11.39mlTrain batch 4/31 - 240.6ms/batch - loss: 11.65646 - diff: 11.40mlTrain batch 5/31 - 238.2ms/batch - loss: 12.59090 - diff: 11.92mlTrain batch 6/31 - 239.9ms/batch - loss: 11.74282 - diff: 11.33mlTrain batch 7/31 - 238.2ms/batch - loss: 13.00938 - diff: 11.74mlTrain batch 8/31 - 238.1ms/batch - loss: 12.88909 - diff: 11.75mlTrain batch 9/31 - 240.1ms/batch - loss: 12.74791 - diff: 11.65mlTrain batch 10/31 - 238.3ms/batch - loss: 13.04118 - diff: 11.62mlTrain batch 11/31 - 237.9ms/batch - loss: 12.66668 - diff: 11.51mlTrain batch 12/31 - 238.4ms/batch - loss: 12.37376 - diff: 11.32mlTrain batch 13/31 - 238.5ms/batch - loss: 12.41411 - diff: 11.26mlTrain batch 14/31 - 238.8ms/batch - loss: 12.35003 - diff: 11.19mlTrain batch 15/31 - 240.4ms/batch - loss: 12.12909 - diff: 11.10mlTrain batch 16/31 - 239.1ms/batch - loss: 12.00793 - diff: 11.09mlTrain batch 17/31 - 238.0ms/batch - loss: 11.65966 - diff: 10.92mlTrain batch 18/31 - 240.3ms/batch - loss: 11.39874 - diff: 10.77mlTrain batch 19/31 - 238.9ms/batch - loss: 11.34573 - diff: 10.75mlTrain batch 20/31 - 239.9ms/batch - loss: 11.76428 - diff: 10.99mlTrain batch 21/31 - 237.8ms/batch - loss: 11.60330 - diff: 10.91mlTrain batch 22/31 - 240.1ms/batch - loss: 11.61781 - diff: 10.93mlTrain batch 23/31 - 237.5ms/batch - loss: 12.07302 - diff: 11.06mlTrain batch 24/31 - 244.8ms/batch - loss: 12.15048 - diff: 11.12mlTrain batch 25/31 - 239.2ms/batch - loss: 11.87887 - diff: 10.98mlTrain batch 26/31 - 247.4ms/batch - loss: 12.20915 - diff: 11.16mlTrain batch 27/31 - 238.4ms/batch - loss: 12.14793 - diff: 11.12mlTrain batch 28/31 - 240.1ms/batch - loss: 12.40090 - diff: 11.25mlTrain batch 29/31 - 239.1ms/batch - loss: 12.43934 - diff: 11.27mlTrain batch 30/31 - 237.8ms/batch - loss: 12.45580 - diff: 11.27mlTrain batch 31/31 - 124.7ms/batch - loss: 13.32444 - diff: 11.40mlTrain batch 31/31 - 11.4s 124.7ms/batch - loss: 13.32444 - diff: 11.40ml
Test 1.1s: val_loss: 33.29195 - diff: 15.42ml

Epoch 128: current best loss = 32.96686, at epoch 115
Train batch 1/31 - 237.3ms/batch - loss: 7.96624 - diff: 9.44mlTrain batch 2/31 - 239.4ms/batch - loss: 10.46540 - diff: 10.73mlTrain batch 3/31 - 237.4ms/batch - loss: 12.04616 - diff: 11.71mlTrain batch 4/31 - 237.8ms/batch - loss: 16.52778 - diff: 12.51mlTrain batch 5/31 - 237.1ms/batch - loss: 15.02980 - diff: 12.13mlTrain batch 6/31 - 240.4ms/batch - loss: 13.57017 - diff: 11.44mlTrain batch 7/31 - 237.8ms/batch - loss: 12.63528 - diff: 10.97mlTrain batch 8/31 - 238.0ms/batch - loss: 12.97019 - diff: 11.07mlTrain batch 9/31 - 237.7ms/batch - loss: 13.27886 - diff: 11.39mlTrain batch 10/31 - 237.7ms/batch - loss: 13.23171 - diff: 11.42mlTrain batch 11/31 - 240.1ms/batch - loss: 13.45973 - diff: 11.52mlTrain batch 12/31 - 237.3ms/batch - loss: 13.92411 - diff: 11.58mlTrain batch 13/31 - 241.9ms/batch - loss: 14.06290 - diff: 11.65mlTrain batch 14/31 - 237.2ms/batch - loss: 13.74052 - diff: 11.54mlTrain batch 15/31 - 239.7ms/batch - loss: 13.88347 - diff: 11.65mlTrain batch 16/31 - 240.8ms/batch - loss: 14.05537 - diff: 11.74mlTrain batch 17/31 - 241.2ms/batch - loss: 14.39155 - diff: 11.86mlTrain batch 18/31 - 237.6ms/batch - loss: 14.04115 - diff: 11.75mlTrain batch 19/31 - 240.3ms/batch - loss: 13.97687 - diff: 11.71mlTrain batch 20/31 - 239.4ms/batch - loss: 14.19872 - diff: 11.74mlTrain batch 21/31 - 237.8ms/batch - loss: 13.94120 - diff: 11.56mlTrain batch 22/31 - 238.2ms/batch - loss: 13.87049 - diff: 11.51mlTrain batch 23/31 - 239.9ms/batch - loss: 13.58417 - diff: 11.37mlTrain batch 24/31 - 239.4ms/batch - loss: 13.87894 - diff: 11.52mlTrain batch 25/31 - 239.6ms/batch - loss: 13.82237 - diff: 11.52mlTrain batch 26/31 - 239.3ms/batch - loss: 13.59890 - diff: 11.45mlTrain batch 27/31 - 240.5ms/batch - loss: 13.63151 - diff: 11.49mlTrain batch 28/31 - 237.5ms/batch - loss: 13.45833 - diff: 11.42mlTrain batch 29/31 - 240.0ms/batch - loss: 13.39161 - diff: 11.41mlTrain batch 30/31 - 238.0ms/batch - loss: 13.18268 - diff: 11.32mlTrain batch 31/31 - 124.5ms/batch - loss: 13.62560 - diff: 11.38mlTrain batch 31/31 - 11.6s 124.5ms/batch - loss: 13.62560 - diff: 11.38ml
Test 1.1s: val_loss: 32.78780 - diff: 15.60ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Systole_WideResNet50_0_Adam-0.001_MSE_DA3_best

Epoch 129: current best loss = 32.78780, at epoch 128
Train batch 1/31 - 242.7ms/batch - loss: 5.97269 - diff: 8.52mlTrain batch 2/31 - 237.4ms/batch - loss: 7.92320 - diff: 8.95mlTrain batch 3/31 - 243.6ms/batch - loss: 9.21650 - diff: 9.42mlTrain batch 4/31 - 237.4ms/batch - loss: 10.52625 - diff: 10.25mlTrain batch 5/31 - 239.7ms/batch - loss: 17.46359 - diff: 12.74mlTrain batch 6/31 - 241.5ms/batch - loss: 15.63204 - diff: 11.96mlTrain batch 7/31 - 238.3ms/batch - loss: 15.41258 - diff: 11.92mlTrain batch 8/31 - 237.3ms/batch - loss: 15.43639 - diff: 12.07mlTrain batch 9/31 - 237.0ms/batch - loss: 15.31997 - diff: 11.96mlTrain batch 10/31 - 237.3ms/batch - loss: 15.50800 - diff: 11.96mlTrain batch 11/31 - 238.8ms/batch - loss: 15.84103 - diff: 11.95mlTrain batch 12/31 - 238.2ms/batch - loss: 15.41788 - diff: 11.90mlTrain batch 13/31 - 238.6ms/batch - loss: 15.23694 - diff: 11.86mlTrain batch 14/31 - 237.7ms/batch - loss: 14.72896 - diff: 11.67mlTrain batch 15/31 - 240.1ms/batch - loss: 14.25803 - diff: 11.50mlTrain batch 16/31 - 237.4ms/batch - loss: 14.83985 - diff: 11.87mlTrain batch 17/31 - 240.0ms/batch - loss: 14.35946 - diff: 11.67mlTrain batch 18/31 - 238.2ms/batch - loss: 14.00049 - diff: 11.45mlTrain batch 19/31 - 238.6ms/batch - loss: 13.87699 - diff: 11.39mlTrain batch 20/31 - 237.8ms/batch - loss: 13.46372 - diff: 11.20mlTrain batch 21/31 - 240.3ms/batch - loss: 13.40266 - diff: 11.21mlTrain batch 22/31 - 237.9ms/batch - loss: 13.27667 - diff: 11.15mlTrain batch 23/31 - 239.9ms/batch - loss: 13.22611 - diff: 11.20mlTrain batch 24/31 - 238.5ms/batch - loss: 12.99412 - diff: 11.09mlTrain batch 25/31 - 240.3ms/batch - loss: 13.93910 - diff: 11.36mlTrain batch 26/31 - 238.3ms/batch - loss: 13.85236 - diff: 11.31mlTrain batch 27/31 - 240.2ms/batch - loss: 13.91330 - diff: 11.28mlTrain batch 28/31 - 240.7ms/batch - loss: 15.18112 - diff: 11.75mlTrain batch 29/31 - 240.4ms/batch - loss: 15.20548 - diff: 11.79mlTrain batch 30/31 - 237.5ms/batch - loss: 15.02499 - diff: 11.77mlTrain batch 31/31 - 122.6ms/batch - loss: 14.88709 - diff: 11.68mlTrain batch 31/31 - 10.9s 122.6ms/batch - loss: 14.88709 - diff: 11.68ml
Test 1.2s: val_loss: 42.34737 - diff: 15.40ml

Epoch 130: current best loss = 32.78780, at epoch 128
Train batch 1/31 - 237.4ms/batch - loss: 10.66947 - diff: 8.92mlTrain batch 2/31 - 240.0ms/batch - loss: 11.46390 - diff: 10.16mlTrain batch 3/31 - 237.0ms/batch - loss: 16.33319 - diff: 12.00mlTrain batch 4/31 - 240.1ms/batch - loss: 16.62168 - diff: 12.27mlTrain batch 5/31 - 238.1ms/batch - loss: 17.31333 - diff: 12.47mlTrain batch 6/31 - 236.3ms/batch - loss: 16.69088 - diff: 12.48mlTrain batch 7/31 - 237.6ms/batch - loss: 15.14036 - diff: 11.81mlTrain batch 8/31 - 241.3ms/batch - loss: 14.37991 - diff: 11.52mlTrain batch 9/31 - 237.3ms/batch - loss: 13.87321 - diff: 11.37mlTrain batch 10/31 - 237.4ms/batch - loss: 14.86679 - diff: 11.84mlTrain batch 11/31 - 237.6ms/batch - loss: 14.59460 - diff: 11.79mlTrain batch 12/31 - 239.9ms/batch - loss: 14.28758 - diff: 11.73mlTrain batch 13/31 - 237.0ms/batch - loss: 15.36506 - diff: 12.15mlTrain batch 14/31 - 237.7ms/batch - loss: 14.71946 - diff: 11.90mlTrain batch 15/31 - 237.1ms/batch - loss: 14.94692 - diff: 11.77mlTrain batch 16/31 - 239.4ms/batch - loss: 15.32586 - diff: 11.89mlTrain batch 17/31 - 237.2ms/batch - loss: 14.93589 - diff: 11.76mlTrain batch 18/31 - 238.7ms/batch - loss: 14.71637 - diff: 11.75mlTrain batch 19/31 - 237.1ms/batch - loss: 15.08508 - diff: 11.76mlTrain batch 20/31 - 240.1ms/batch - loss: 15.05236 - diff: 11.76mlTrain batch 21/31 - 238.4ms/batch - loss: 14.94506 - diff: 11.76mlTrain batch 22/31 - 239.6ms/batch - loss: 15.26840 - diff: 11.81mlTrain batch 23/31 - 237.4ms/batch - loss: 14.81828 - diff: 11.64mlTrain batch 24/31 - 238.1ms/batch - loss: 14.60716 - diff: 11.55mlTrain batch 25/31 - 237.6ms/batch - loss: 14.52563 - diff: 11.52mlTrain batch 26/31 - 240.3ms/batch - loss: 15.38838 - diff: 11.84mlTrain batch 27/31 - 237.5ms/batch - loss: 15.17681 - diff: 11.73mlTrain batch 28/31 - 240.4ms/batch - loss: 14.75883 - diff: 11.53mlTrain batch 29/31 - 237.5ms/batch - loss: 14.54515 - diff: 11.43mlTrain batch 30/31 - 240.2ms/batch - loss: 14.31552 - diff: 11.34mlTrain batch 31/31 - 124.6ms/batch - loss: 16.96292 - diff: 11.62mlTrain batch 31/31 - 11.3s 124.6ms/batch - loss: 16.96292 - diff: 11.62ml
Test 1.1s: val_loss: 34.14911 - diff: 15.65ml

Epoch 131: current best loss = 32.78780, at epoch 128
Train batch 1/31 - 236.9ms/batch - loss: 15.36109 - diff: 11.82mlTrain batch 2/31 - 250.2ms/batch - loss: 31.77598 - diff: 16.52mlTrain batch 3/31 - 237.4ms/batch - loss: 24.60295 - diff: 14.28mlTrain batch 4/31 - 240.2ms/batch - loss: 21.80736 - diff: 13.64mlTrain batch 5/31 - 237.9ms/batch - loss: 20.85405 - diff: 13.37mlTrain batch 6/31 - 238.7ms/batch - loss: 21.04507 - diff: 13.80mlTrain batch 7/31 - 237.2ms/batch - loss: 19.49305 - diff: 13.21mlTrain batch 8/31 - 240.3ms/batch - loss: 18.16345 - diff: 12.87mlTrain batch 9/31 - 238.0ms/batch - loss: 18.11334 - diff: 12.67mlTrain batch 10/31 - 239.1ms/batch - loss: 16.95525 - diff: 12.18mlTrain batch 11/31 - 237.8ms/batch - loss: 17.54705 - diff: 12.46mlTrain batch 12/31 - 237.9ms/batch - loss: 16.63304 - diff: 12.12mlTrain batch 13/31 - 237.2ms/batch - loss: 16.45166 - diff: 12.17mlTrain batch 14/31 - 240.2ms/batch - loss: 16.17624 - diff: 12.18mlTrain batch 15/31 - 237.6ms/batch - loss: 15.80297 - diff: 12.07mlTrain batch 16/31 - 240.1ms/batch - loss: 15.19309 - diff: 11.84mlTrain batch 17/31 - 237.6ms/batch - loss: 15.12040 - diff: 11.88mlTrain batch 18/31 - 239.1ms/batch - loss: 14.90130 - diff: 11.75mlTrain batch 19/31 - 237.8ms/batch - loss: 15.30650 - diff: 11.92mlTrain batch 20/31 - 240.2ms/batch - loss: 15.03139 - diff: 11.82mlTrain batch 21/31 - 238.0ms/batch - loss: 14.56650 - diff: 11.61mlTrain batch 22/31 - 240.2ms/batch - loss: 14.56291 - diff: 11.70mlTrain batch 23/31 - 237.5ms/batch - loss: 14.26172 - diff: 11.58mlTrain batch 24/31 - 238.8ms/batch - loss: 13.93406 - diff: 11.44mlTrain batch 25/31 - 238.2ms/batch - loss: 13.78406 - diff: 11.40mlTrain batch 26/31 - 239.9ms/batch - loss: 13.79261 - diff: 11.44mlTrain batch 27/31 - 238.2ms/batch - loss: 13.65203 - diff: 11.37mlTrain batch 28/31 - 239.9ms/batch - loss: 13.65419 - diff: 11.40mlTrain batch 29/31 - 237.3ms/batch - loss: 13.76617 - diff: 11.49mlTrain batch 30/31 - 238.6ms/batch - loss: 13.59914 - diff: 11.43mlTrain batch 31/31 - 124.5ms/batch - loss: 13.57216 - diff: 11.37mlTrain batch 31/31 - 11.1s 124.5ms/batch - loss: 13.57216 - diff: 11.37ml
Test 1.2s: val_loss: 34.31945 - diff: 15.37ml

Epoch 132: current best loss = 32.78780, at epoch 128
Train batch 1/31 - 237.6ms/batch - loss: 9.30035 - diff: 9.70mlTrain batch 2/31 - 239.6ms/batch - loss: 10.38469 - diff: 10.51mlTrain batch 3/31 - 237.3ms/batch - loss: 11.60191 - diff: 10.83mlTrain batch 4/31 - 239.1ms/batch - loss: 10.57586 - diff: 10.38mlTrain batch 5/31 - 237.5ms/batch - loss: 10.36412 - diff: 10.32mlTrain batch 6/31 - 240.1ms/batch - loss: 12.98894 - diff: 11.11mlTrain batch 7/31 - 237.8ms/batch - loss: 12.40991 - diff: 10.99mlTrain batch 8/31 - 239.8ms/batch - loss: 12.52594 - diff: 10.94mlTrain batch 9/31 - 239.0ms/batch - loss: 12.30986 - diff: 10.96mlTrain batch 10/31 - 237.6ms/batch - loss: 14.34230 - diff: 11.83mlTrain batch 11/31 - 237.6ms/batch - loss: 13.63000 - diff: 11.57mlTrain batch 12/31 - 239.6ms/batch - loss: 13.21473 - diff: 11.41mlTrain batch 13/31 - 238.1ms/batch - loss: 12.93683 - diff: 11.33mlTrain batch 14/31 - 237.8ms/batch - loss: 12.70883 - diff: 11.28mlTrain batch 15/31 - 237.6ms/batch - loss: 13.22855 - diff: 11.43mlTrain batch 16/31 - 240.2ms/batch - loss: 12.98151 - diff: 11.32mlTrain batch 17/31 - 237.2ms/batch - loss: 12.61018 - diff: 11.15mlTrain batch 18/31 - 239.1ms/batch - loss: 13.49942 - diff: 11.45mlTrain batch 19/31 - 237.6ms/batch - loss: 13.37452 - diff: 11.36mlTrain batch 20/31 - 238.3ms/batch - loss: 13.06976 - diff: 11.19mlTrain batch 21/31 - 237.7ms/batch - loss: 13.29754 - diff: 11.33mlTrain batch 22/31 - 240.1ms/batch - loss: 14.30488 - diff: 11.65mlTrain batch 23/31 - 237.4ms/batch - loss: 14.02664 - diff: 11.54mlTrain batch 24/31 - 240.9ms/batch - loss: 14.05444 - diff: 11.49mlTrain batch 25/31 - 239.7ms/batch - loss: 13.94485 - diff: 11.47mlTrain batch 26/31 - 238.6ms/batch - loss: 13.74780 - diff: 11.43mlTrain batch 27/31 - 241.4ms/batch - loss: 13.46979 - diff: 11.29mlTrain batch 28/31 - 239.6ms/batch - loss: 13.47864 - diff: 11.30mlTrain batch 29/31 - 249.3ms/batch - loss: 13.56609 - diff: 11.27mlTrain batch 30/31 - 237.9ms/batch - loss: 13.57912 - diff: 11.25mlTrain batch 31/31 - 124.5ms/batch - loss: 14.30621 - diff: 11.33mlTrain batch 31/31 - 11.0s 124.5ms/batch - loss: 14.30621 - diff: 11.33ml
Test 1.1s: val_loss: 34.60793 - diff: 15.55ml

Epoch 133: current best loss = 32.78780, at epoch 128
Train batch 1/31 - 237.6ms/batch - loss: 19.27296 - diff: 11.10mlTrain batch 2/31 - 237.8ms/batch - loss: 17.21162 - diff: 12.19mlTrain batch 3/31 - 238.9ms/batch - loss: 15.03360 - diff: 11.19mlTrain batch 4/31 - 239.4ms/batch - loss: 12.22560 - diff: 9.83mlTrain batch 5/31 - 238.2ms/batch - loss: 14.42460 - diff: 11.20mlTrain batch 6/31 - 237.7ms/batch - loss: 13.43424 - diff: 10.83mlTrain batch 7/31 - 240.1ms/batch - loss: 12.23479 - diff: 10.37mlTrain batch 8/31 - 237.4ms/batch - loss: 11.58423 - diff: 10.15mlTrain batch 9/31 - 239.9ms/batch - loss: 12.43732 - diff: 10.63mlTrain batch 10/31 - 238.9ms/batch - loss: 12.22343 - diff: 10.48mlTrain batch 11/31 - 239.1ms/batch - loss: 11.98726 - diff: 10.43mlTrain batch 12/31 - 237.7ms/batch - loss: 12.04857 - diff: 10.58mlTrain batch 13/31 - 240.0ms/batch - loss: 11.75105 - diff: 10.50mlTrain batch 14/31 - 237.2ms/batch - loss: 11.54647 - diff: 10.39mlTrain batch 15/31 - 239.5ms/batch - loss: 11.38696 - diff: 10.39mlTrain batch 16/31 - 238.1ms/batch - loss: 11.84610 - diff: 10.59mlTrain batch 17/31 - 240.2ms/batch - loss: 13.41895 - diff: 11.15mlTrain batch 18/31 - 237.6ms/batch - loss: 13.00081 - diff: 10.98mlTrain batch 19/31 - 239.9ms/batch - loss: 12.95878 - diff: 11.01mlTrain batch 20/31 - 238.3ms/batch - loss: 12.80020 - diff: 10.98mlTrain batch 21/31 - 240.4ms/batch - loss: 12.70490 - diff: 10.97mlTrain batch 22/31 - 238.7ms/batch - loss: 12.62396 - diff: 10.98mlTrain batch 23/31 - 239.9ms/batch - loss: 12.64902 - diff: 10.96mlTrain batch 24/31 - 238.7ms/batch - loss: 12.59412 - diff: 10.97mlTrain batch 25/31 - 240.0ms/batch - loss: 12.50471 - diff: 10.94mlTrain batch 26/31 - 238.4ms/batch - loss: 12.40151 - diff: 10.93mlTrain batch 27/31 - 240.1ms/batch - loss: 12.40028 - diff: 10.98mlTrain batch 28/31 - 238.2ms/batch - loss: 12.47069 - diff: 11.05mlTrain batch 29/31 - 239.9ms/batch - loss: 12.35929 - diff: 10.98mlTrain batch 30/31 - 238.7ms/batch - loss: 12.37927 - diff: 11.01mlTrain batch 31/31 - 123.5ms/batch - loss: 12.75546 - diff: 11.04mlTrain batch 31/31 - 11.0s 123.5ms/batch - loss: 12.75546 - diff: 11.04ml
Test 1.1s: val_loss: 33.70390 - diff: 15.79ml

Epoch 134: current best loss = 32.78780, at epoch 128
Train batch 1/31 - 237.2ms/batch - loss: 7.59500 - diff: 8.89mlTrain batch 2/31 - 236.8ms/batch - loss: 11.24265 - diff: 10.92mlTrain batch 3/31 - 237.7ms/batch - loss: 11.21579 - diff: 10.80mlTrain batch 4/31 - 240.1ms/batch - loss: 10.38472 - diff: 10.04mlTrain batch 5/31 - 249.0ms/batch - loss: 11.33024 - diff: 10.00mlTrain batch 6/31 - 238.3ms/batch - loss: 17.81315 - diff: 11.19mlTrain batch 7/31 - 238.2ms/batch - loss: 17.13786 - diff: 11.32mlTrain batch 8/31 - 238.0ms/batch - loss: 16.92195 - diff: 11.31mlTrain batch 9/31 - 240.1ms/batch - loss: 16.57435 - diff: 11.28mlTrain batch 10/31 - 237.7ms/batch - loss: 15.84342 - diff: 11.12mlTrain batch 11/31 - 238.2ms/batch - loss: 14.94770 - diff: 10.85mlTrain batch 12/31 - 236.8ms/batch - loss: 14.79208 - diff: 10.99mlTrain batch 13/31 - 239.8ms/batch - loss: 14.29531 - diff: 10.91mlTrain batch 14/31 - 237.8ms/batch - loss: 13.91468 - diff: 10.85mlTrain batch 15/31 - 240.1ms/batch - loss: 13.64858 - diff: 10.75mlTrain batch 16/31 - 237.8ms/batch - loss: 13.75126 - diff: 10.86mlTrain batch 17/31 - 240.3ms/batch - loss: 13.50921 - diff: 10.85mlTrain batch 18/31 - 237.6ms/batch - loss: 13.49278 - diff: 10.89mlTrain batch 19/31 - 239.8ms/batch - loss: 13.25469 - diff: 10.83mlTrain batch 20/31 - 238.0ms/batch - loss: 12.76577 - diff: 10.60mlTrain batch 21/31 - 240.2ms/batch - loss: 13.36538 - diff: 10.80mlTrain batch 22/31 - 238.1ms/batch - loss: 13.32338 - diff: 10.81mlTrain batch 23/31 - 240.2ms/batch - loss: 13.73364 - diff: 10.99mlTrain batch 24/31 - 237.8ms/batch - loss: 13.44395 - diff: 10.91mlTrain batch 25/31 - 240.2ms/batch - loss: 13.20393 - diff: 10.84mlTrain batch 26/31 - 239.3ms/batch - loss: 13.36306 - diff: 10.93mlTrain batch 27/31 - 252.5ms/batch - loss: 16.39541 - diff: 11.83mlTrain batch 28/31 - 241.2ms/batch - loss: 17.20125 - diff: 12.12mlTrain batch 29/31 - 241.6ms/batch - loss: 17.02388 - diff: 12.11mlTrain batch 30/31 - 237.1ms/batch - loss: 17.27835 - diff: 12.18mlTrain batch 31/31 - 124.4ms/batch - loss: 17.40477 - diff: 12.19mlTrain batch 31/31 - 11.4s 124.4ms/batch - loss: 17.40477 - diff: 12.19ml
Test 1.1s: val_loss: 33.16693 - diff: 15.41ml

Epoch 135: current best loss = 32.78780, at epoch 128
Train batch 1/31 - 237.3ms/batch - loss: 6.87361 - diff: 7.90mlTrain batch 2/31 - 241.6ms/batch - loss: 10.40476 - diff: 10.24mlTrain batch 3/31 - 237.1ms/batch - loss: 15.19209 - diff: 11.64mlTrain batch 4/31 - 240.4ms/batch - loss: 13.68386 - diff: 11.01mlTrain batch 5/31 - 245.5ms/batch - loss: 13.63630 - diff: 11.35mlTrain batch 6/31 - 237.6ms/batch - loss: 12.33188 - diff: 10.62mlTrain batch 7/31 - 237.4ms/batch - loss: 13.91336 - diff: 11.53mlTrain batch 8/31 - 239.7ms/batch - loss: 13.19753 - diff: 11.33mlTrain batch 9/31 - 238.9ms/batch - loss: 13.65755 - diff: 11.64mlTrain batch 10/31 - 238.3ms/batch - loss: 14.26653 - diff: 11.75mlTrain batch 11/31 - 238.8ms/batch - loss: 14.48011 - diff: 11.62mlTrain batch 12/31 - 239.8ms/batch - loss: 15.58479 - diff: 11.99mlTrain batch 13/31 - 237.2ms/batch - loss: 15.64616 - diff: 12.02mlTrain batch 14/31 - 240.7ms/batch - loss: 15.84420 - diff: 12.21mlTrain batch 15/31 - 237.9ms/batch - loss: 15.58414 - diff: 12.18mlTrain batch 16/31 - 240.1ms/batch - loss: 15.79996 - diff: 12.30mlTrain batch 17/31 - 238.5ms/batch - loss: 15.41891 - diff: 12.16mlTrain batch 18/31 - 239.9ms/batch - loss: 14.73967 - diff: 11.85mlTrain batch 19/31 - 238.7ms/batch - loss: 14.64880 - diff: 11.82mlTrain batch 20/31 - 240.2ms/batch - loss: 14.50640 - diff: 11.85mlTrain batch 21/31 - 237.8ms/batch - loss: 14.18249 - diff: 11.67mlTrain batch 22/31 - 240.0ms/batch - loss: 13.88966 - diff: 11.59mlTrain batch 23/31 - 237.9ms/batch - loss: 13.84780 - diff: 11.57mlTrain batch 24/31 - 240.0ms/batch - loss: 13.68545 - diff: 11.55mlTrain batch 25/31 - 237.9ms/batch - loss: 14.15765 - diff: 11.64mlTrain batch 26/31 - 237.7ms/batch - loss: 14.40478 - diff: 11.77mlTrain batch 27/31 - 240.1ms/batch - loss: 14.26039 - diff: 11.73mlTrain batch 28/31 - 237.6ms/batch - loss: 13.92198 - diff: 11.59mlTrain batch 29/31 - 243.0ms/batch - loss: 13.86440 - diff: 11.57mlTrain batch 30/31 - 240.1ms/batch - loss: 13.64783 - diff: 11.47mlTrain batch 31/31 - 122.6ms/batch - loss: 13.92296 - diff: 11.46mlTrain batch 31/31 - 11.8s 122.6ms/batch - loss: 13.92296 - diff: 11.46ml
Test 1.1s: val_loss: 35.28130 - diff: 16.02ml

Epoch 136: current best loss = 32.78780, at epoch 128
Train batch 1/31 - 237.1ms/batch - loss: 11.57612 - diff: 11.27mlTrain batch 2/31 - 240.2ms/batch - loss: 9.07551 - diff: 9.69mlTrain batch 3/31 - 237.3ms/batch - loss: 13.02638 - diff: 11.83mlTrain batch 4/31 - 239.2ms/batch - loss: 12.84462 - diff: 11.58mlTrain batch 5/31 - 238.3ms/batch - loss: 11.87986 - diff: 11.21mlTrain batch 6/31 - 239.4ms/batch - loss: 14.45360 - diff: 12.25mlTrain batch 7/31 - 237.8ms/batch - loss: 14.16901 - diff: 12.17mlTrain batch 8/31 - 238.3ms/batch - loss: 13.71738 - diff: 12.08mlTrain batch 9/31 - 237.3ms/batch - loss: 13.18498 - diff: 11.78mlTrain batch 10/31 - 238.4ms/batch - loss: 13.89128 - diff: 12.05mlTrain batch 11/31 - 239.5ms/batch - loss: 13.89184 - diff: 12.07mlTrain batch 12/31 - 238.1ms/batch - loss: 13.20995 - diff: 11.57mlTrain batch 13/31 - 238.9ms/batch - loss: 12.76970 - diff: 11.34mlTrain batch 14/31 - 239.3ms/batch - loss: 14.06032 - diff: 11.69mlTrain batch 15/31 - 241.9ms/batch - loss: 13.34225 - diff: 11.34mlTrain batch 16/31 - 237.9ms/batch - loss: 13.42069 - diff: 11.42mlTrain batch 17/31 - 238.0ms/batch - loss: 13.15755 - diff: 11.34mlTrain batch 18/31 - 238.2ms/batch - loss: 12.86563 - diff: 11.22mlTrain batch 19/31 - 240.0ms/batch - loss: 13.43385 - diff: 11.48mlTrain batch 20/31 - 237.5ms/batch - loss: 13.19197 - diff: 11.37mlTrain batch 21/31 - 240.1ms/batch - loss: 12.87716 - diff: 11.22mlTrain batch 22/31 - 237.5ms/batch - loss: 14.36394 - diff: 11.57mlTrain batch 23/31 - 240.3ms/batch - loss: 14.26085 - diff: 11.53mlTrain batch 24/31 - 237.2ms/batch - loss: 14.00464 - diff: 11.45mlTrain batch 25/31 - 236.0ms/batch - loss: 13.78350 - diff: 11.34mlTrain batch 26/31 - 238.1ms/batch - loss: 14.10997 - diff: 11.48mlTrain batch 27/31 - 239.5ms/batch - loss: 13.87627 - diff: 11.45mlTrain batch 28/31 - 237.5ms/batch - loss: 14.29023 - diff: 11.63mlTrain batch 29/31 - 239.4ms/batch - loss: 14.52613 - diff: 11.81mlTrain batch 30/31 - 237.6ms/batch - loss: 14.42869 - diff: 11.80mlTrain batch 31/31 - 122.7ms/batch - loss: 14.66217 - diff: 11.81mlTrain batch 31/31 - 12.1s 122.7ms/batch - loss: 14.66217 - diff: 11.81ml
Test 1.2s: val_loss: 34.63087 - diff: 16.62ml

Epoch 137: current best loss = 32.78780, at epoch 128
Train batch 1/31 - 237.6ms/batch - loss: 13.94189 - diff: 12.88mlTrain batch 2/31 - 238.3ms/batch - loss: 11.85499 - diff: 11.61mlTrain batch 3/31 - 238.0ms/batch - loss: 12.12987 - diff: 11.54mlTrain batch 4/31 - 238.0ms/batch - loss: 11.95961 - diff: 11.38mlTrain batch 5/31 - 237.4ms/batch - loss: 13.51994 - diff: 11.83mlTrain batch 6/31 - 237.3ms/batch - loss: 14.15071 - diff: 12.09mlTrain batch 7/31 - 240.1ms/batch - loss: 12.75836 - diff: 11.33mlTrain batch 8/31 - 237.5ms/batch - loss: 12.68047 - diff: 11.35mlTrain batch 9/31 - 237.8ms/batch - loss: 12.80400 - diff: 11.54mlTrain batch 10/31 - 237.4ms/batch - loss: 13.32483 - diff: 11.70mlTrain batch 11/31 - 237.5ms/batch - loss: 14.16932 - diff: 11.85mlTrain batch 12/31 - 237.9ms/batch - loss: 13.63054 - diff: 11.52mlTrain batch 13/31 - 238.8ms/batch - loss: 13.79813 - diff: 11.74mlTrain batch 14/31 - 238.1ms/batch - loss: 13.28903 - diff: 11.50mlTrain batch 15/31 - 238.9ms/batch - loss: 13.57045 - diff: 11.68mlTrain batch 16/31 - 237.7ms/batch - loss: 13.93828 - diff: 11.75mlTrain batch 17/31 - 238.4ms/batch - loss: 14.15450 - diff: 11.87mlTrain batch 18/31 - 237.9ms/batch - loss: 13.95779 - diff: 11.79mlTrain batch 19/31 - 240.2ms/batch - loss: 13.55850 - diff: 11.59mlTrain batch 20/31 - 237.8ms/batch - loss: 13.23394 - diff: 11.45mlTrain batch 21/31 - 237.5ms/batch - loss: 13.32160 - diff: 11.54mlTrain batch 22/31 - 238.8ms/batch - loss: 13.12450 - diff: 11.44mlTrain batch 23/31 - 238.1ms/batch - loss: 13.06394 - diff: 11.47mlTrain batch 24/31 - 238.4ms/batch - loss: 13.11657 - diff: 11.50mlTrain batch 25/31 - 238.2ms/batch - loss: 13.10773 - diff: 11.52mlTrain batch 26/31 - 238.7ms/batch - loss: 13.16339 - diff: 11.51mlTrain batch 27/31 - 238.4ms/batch - loss: 13.40614 - diff: 11.60mlTrain batch 28/31 - 238.3ms/batch - loss: 14.06139 - diff: 11.75mlTrain batch 29/31 - 238.1ms/batch - loss: 13.82288 - diff: 11.64mlTrain batch 30/31 - 237.8ms/batch - loss: 14.01865 - diff: 11.66mlTrain batch 31/31 - 124.7ms/batch - loss: 14.28131 - diff: 11.66mlTrain batch 31/31 - 11.6s 124.7ms/batch - loss: 14.28131 - diff: 11.66ml
Test 1.1s: val_loss: 33.64388 - diff: 16.41ml

Epoch 138: current best loss = 32.78780, at epoch 128
Train batch 1/31 - 237.5ms/batch - loss: 7.25982 - diff: 8.82mlTrain batch 2/31 - 239.7ms/batch - loss: 13.43737 - diff: 12.39mlTrain batch 3/31 - 237.1ms/batch - loss: 14.68102 - diff: 12.31mlTrain batch 4/31 - 238.1ms/batch - loss: 15.09824 - diff: 12.65mlTrain batch 5/31 - 236.7ms/batch - loss: 23.70228 - diff: 14.59mlTrain batch 6/31 - 240.0ms/batch - loss: 28.37409 - diff: 15.35mlTrain batch 7/31 - 237.3ms/batch - loss: 26.69229 - diff: 14.97mlTrain batch 8/31 - 238.6ms/batch - loss: 25.23954 - diff: 14.56mlTrain batch 9/31 - 237.2ms/batch - loss: 23.60970 - diff: 13.91mlTrain batch 10/31 - 237.6ms/batch - loss: 22.51923 - diff: 13.68mlTrain batch 11/31 - 237.9ms/batch - loss: 21.57248 - diff: 13.40mlTrain batch 12/31 - 240.1ms/batch - loss: 20.30084 - diff: 12.97mlTrain batch 13/31 - 237.9ms/batch - loss: 19.22186 - diff: 12.63mlTrain batch 14/31 - 240.3ms/batch - loss: 18.46717 - diff: 12.34mlTrain batch 15/31 - 237.9ms/batch - loss: 17.84341 - diff: 12.11mlTrain batch 16/31 - 240.0ms/batch - loss: 18.72038 - diff: 12.45mlTrain batch 17/31 - 238.3ms/batch - loss: 18.22873 - diff: 12.36mlTrain batch 18/31 - 239.7ms/batch - loss: 18.30598 - diff: 12.43mlTrain batch 19/31 - 238.7ms/batch - loss: 18.63087 - diff: 12.53mlTrain batch 20/31 - 239.3ms/batch - loss: 18.76824 - diff: 12.63mlTrain batch 21/31 - 238.3ms/batch - loss: 20.64342 - diff: 13.37mlTrain batch 22/31 - 239.4ms/batch - loss: 20.03432 - diff: 13.08mlTrain batch 23/31 - 237.6ms/batch - loss: 19.77217 - diff: 13.08mlTrain batch 24/31 - 241.9ms/batch - loss: 19.70948 - diff: 13.14mlTrain batch 25/31 - 238.2ms/batch - loss: 19.30510 - diff: 13.05mlTrain batch 26/31 - 237.4ms/batch - loss: 18.94492 - diff: 12.94mlTrain batch 27/31 - 237.5ms/batch - loss: 18.67169 - diff: 12.86mlTrain batch 28/31 - 237.7ms/batch - loss: 18.49978 - diff: 12.80mlTrain batch 29/31 - 238.4ms/batch - loss: 18.04824 - diff: 12.61mlTrain batch 30/31 - 238.5ms/batch - loss: 17.69308 - diff: 12.50mlTrain batch 31/31 - 123.3ms/batch - loss: 18.52878 - diff: 12.58mlTrain batch 31/31 - 12.1s 123.3ms/batch - loss: 18.52878 - diff: 12.58ml
Test 1.2s: val_loss: 32.93849 - diff: 15.79ml

Epoch 139: current best loss = 32.78780, at epoch 128
Train batch 1/31 - 237.2ms/batch - loss: 12.86744 - diff: 11.51mlTrain batch 2/31 - 237.4ms/batch - loss: 13.23101 - diff: 11.74mlTrain batch 3/31 - 237.1ms/batch - loss: 11.98581 - diff: 11.19mlTrain batch 4/31 - 238.4ms/batch - loss: 10.16358 - diff: 10.25mlTrain batch 5/31 - 238.0ms/batch - loss: 11.87883 - diff: 10.90mlTrain batch 6/31 - 238.7ms/batch - loss: 12.61351 - diff: 11.30mlTrain batch 7/31 - 237.0ms/batch - loss: 12.78266 - diff: 11.25mlTrain batch 8/31 - 238.1ms/batch - loss: 12.15215 - diff: 10.81mlTrain batch 9/31 - 237.9ms/batch - loss: 11.41982 - diff: 10.53mlTrain batch 10/31 - 240.0ms/batch - loss: 11.21501 - diff: 10.58mlTrain batch 11/31 - 237.5ms/batch - loss: 11.80391 - diff: 10.79mlTrain batch 12/31 - 239.8ms/batch - loss: 11.75037 - diff: 10.76mlTrain batch 13/31 - 238.5ms/batch - loss: 11.28992 - diff: 10.62mlTrain batch 14/31 - 239.3ms/batch - loss: 11.82268 - diff: 10.89mlTrain batch 15/31 - 237.3ms/batch - loss: 12.13367 - diff: 11.01mlTrain batch 16/31 - 243.3ms/batch - loss: 12.07076 - diff: 10.90mlTrain batch 17/31 - 237.5ms/batch - loss: 11.97565 - diff: 10.87mlTrain batch 18/31 - 239.1ms/batch - loss: 11.59477 - diff: 10.69mlTrain batch 19/31 - 239.3ms/batch - loss: 12.41538 - diff: 10.88mlTrain batch 20/31 - 238.6ms/batch - loss: 12.32604 - diff: 10.87mlTrain batch 21/31 - 237.7ms/batch - loss: 12.00173 - diff: 10.68mlTrain batch 22/31 - 240.0ms/batch - loss: 12.08595 - diff: 10.72mlTrain batch 23/31 - 238.2ms/batch - loss: 12.52454 - diff: 10.89mlTrain batch 24/31 - 238.3ms/batch - loss: 12.36344 - diff: 10.84mlTrain batch 25/31 - 237.7ms/batch - loss: 12.34237 - diff: 10.87mlTrain batch 26/31 - 240.3ms/batch - loss: 12.08469 - diff: 10.69mlTrain batch 27/31 - 238.2ms/batch - loss: 12.43977 - diff: 10.79mlTrain batch 28/31 - 240.1ms/batch - loss: 12.52314 - diff: 10.81mlTrain batch 29/31 - 238.7ms/batch - loss: 12.36714 - diff: 10.74mlTrain batch 30/31 - 240.0ms/batch - loss: 12.21252 - diff: 10.70mlTrain batch 31/31 - 125.6ms/batch - loss: 12.66074 - diff: 10.77mlTrain batch 31/31 - 10.9s 125.6ms/batch - loss: 12.66074 - diff: 10.77ml
Test 1.1s: val_loss: 34.68964 - diff: 16.01ml
Epoch   140: reducing learning rate of group 0 to 3.1250e-05.

Epoch 140: current best loss = 32.78780, at epoch 128
Train batch 1/31 - 236.7ms/batch - loss: 18.71608 - diff: 13.52mlTrain batch 2/31 - 241.1ms/batch - loss: 13.29437 - diff: 11.13mlTrain batch 3/31 - 239.1ms/batch - loss: 12.82285 - diff: 10.97mlTrain batch 4/31 - 238.1ms/batch - loss: 13.68507 - diff: 11.31mlTrain batch 5/31 - 237.5ms/batch - loss: 13.88308 - diff: 11.21mlTrain batch 6/31 - 237.4ms/batch - loss: 13.13985 - diff: 11.08mlTrain batch 7/31 - 243.7ms/batch - loss: 13.16175 - diff: 10.99mlTrain batch 8/31 - 238.4ms/batch - loss: 12.90889 - diff: 11.01mlTrain batch 9/31 - 237.9ms/batch - loss: 12.96669 - diff: 11.07mlTrain batch 10/31 - 239.8ms/batch - loss: 13.42324 - diff: 11.17mlTrain batch 11/31 - 237.5ms/batch - loss: 12.57318 - diff: 10.71mlTrain batch 12/31 - 239.1ms/batch - loss: 12.76153 - diff: 10.80mlTrain batch 13/31 - 238.4ms/batch - loss: 12.40665 - diff: 10.63mlTrain batch 14/31 - 240.1ms/batch - loss: 12.20372 - diff: 10.58mlTrain batch 15/31 - 238.4ms/batch - loss: 12.78412 - diff: 10.86mlTrain batch 16/31 - 240.1ms/batch - loss: 12.65844 - diff: 10.85mlTrain batch 17/31 - 238.5ms/batch - loss: 13.10427 - diff: 11.09mlTrain batch 18/31 - 239.3ms/batch - loss: 12.84363 - diff: 11.01mlTrain batch 19/31 - 238.1ms/batch - loss: 12.66816 - diff: 10.94mlTrain batch 20/31 - 239.5ms/batch - loss: 12.65946 - diff: 10.99mlTrain batch 21/31 - 237.8ms/batch - loss: 12.86961 - diff: 11.02mlTrain batch 22/31 - 239.7ms/batch - loss: 12.68136 - diff: 10.93mlTrain batch 23/31 - 237.9ms/batch - loss: 12.62309 - diff: 10.91mlTrain batch 24/31 - 240.1ms/batch - loss: 12.84824 - diff: 10.96mlTrain batch 25/31 - 238.2ms/batch - loss: 12.70209 - diff: 10.93mlTrain batch 26/31 - 240.2ms/batch - loss: 12.78092 - diff: 10.98mlTrain batch 27/31 - 237.7ms/batch - loss: 13.08677 - diff: 11.06mlTrain batch 28/31 - 239.9ms/batch - loss: 12.80965 - diff: 10.93mlTrain batch 29/31 - 238.2ms/batch - loss: 12.75751 - diff: 10.94mlTrain batch 30/31 - 239.0ms/batch - loss: 12.54474 - diff: 10.84mlTrain batch 31/31 - 124.2ms/batch - loss: 13.05994 - diff: 10.90mlTrain batch 31/31 - 11.0s 124.2ms/batch - loss: 13.05994 - diff: 10.90ml
Test 1.1s: val_loss: 37.67160 - diff: 15.55ml

Epoch 141: current best loss = 32.78780, at epoch 128
Train batch 1/31 - 237.5ms/batch - loss: 108.31590 - diff: 24.54mlTrain batch 2/31 - 239.9ms/batch - loss: 61.27143 - diff: 17.40mlTrain batch 3/31 - 237.7ms/batch - loss: 43.74236 - diff: 14.58mlTrain batch 4/31 - 239.5ms/batch - loss: 34.57982 - diff: 13.16mlTrain batch 5/31 - 239.3ms/batch - loss: 28.75869 - diff: 11.84mlTrain batch 6/31 - 238.9ms/batch - loss: 24.62648 - diff: 10.89mlTrain batch 7/31 - 237.2ms/batch - loss: 22.19894 - diff: 10.54mlTrain batch 8/31 - 237.6ms/batch - loss: 20.56806 - diff: 10.53mlTrain batch 9/31 - 238.0ms/batch - loss: 19.19039 - diff: 10.38mlTrain batch 10/31 - 238.8ms/batch - loss: 18.95898 - diff: 10.63mlTrain batch 11/31 - 239.2ms/batch - loss: 17.82176 - diff: 10.40mlTrain batch 12/31 - 238.3ms/batch - loss: 17.35398 - diff: 10.44mlTrain batch 13/31 - 237.9ms/batch - loss: 17.52963 - diff: 10.78mlTrain batch 14/31 - 238.3ms/batch - loss: 17.36627 - diff: 10.90mlTrain batch 15/31 - 245.2ms/batch - loss: 17.02513 - diff: 10.96mlTrain batch 16/31 - 238.2ms/batch - loss: 16.44547 - diff: 10.88mlTrain batch 17/31 - 238.3ms/batch - loss: 16.24477 - diff: 10.82mlTrain batch 18/31 - 239.1ms/batch - loss: 16.42491 - diff: 10.94mlTrain batch 19/31 - 237.8ms/batch - loss: 15.80083 - diff: 10.76mlTrain batch 20/31 - 241.3ms/batch - loss: 15.86239 - diff: 10.87mlTrain batch 21/31 - 237.8ms/batch - loss: 15.75702 - diff: 10.84mlTrain batch 22/31 - 239.8ms/batch - loss: 15.37739 - diff: 10.70mlTrain batch 23/31 - 238.0ms/batch - loss: 14.90845 - diff: 10.52mlTrain batch 24/31 - 240.4ms/batch - loss: 14.81316 - diff: 10.62mlTrain batch 25/31 - 238.7ms/batch - loss: 14.60733 - diff: 10.59mlTrain batch 26/31 - 239.8ms/batch - loss: 14.28031 - diff: 10.48mlTrain batch 27/31 - 238.7ms/batch - loss: 14.09524 - diff: 10.45mlTrain batch 28/31 - 239.9ms/batch - loss: 13.95349 - diff: 10.41mlTrain batch 29/31 - 238.8ms/batch - loss: 13.99917 - diff: 10.47mlTrain batch 30/31 - 240.2ms/batch - loss: 14.13918 - diff: 10.55mlTrain batch 31/31 - 125.3ms/batch - loss: 14.88853 - diff: 10.61mlTrain batch 31/31 - 11.4s 125.3ms/batch - loss: 14.88853 - diff: 10.61ml
Test 1.2s: val_loss: 32.57638 - diff: 15.71ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Systole_WideResNet50_0_Adam-0.001_MSE_DA3_best

Epoch 142: current best loss = 32.57638, at epoch 141
Train batch 1/31 - 236.8ms/batch - loss: 4.78646 - diff: 6.65mlTrain batch 2/31 - 238.6ms/batch - loss: 6.81198 - diff: 8.11mlTrain batch 3/31 - 237.2ms/batch - loss: 6.79968 - diff: 8.28mlTrain batch 4/31 - 239.6ms/batch - loss: 8.94148 - diff: 9.65mlTrain batch 5/31 - 237.4ms/batch - loss: 9.48261 - diff: 10.01mlTrain batch 6/31 - 239.6ms/batch - loss: 10.80650 - diff: 10.35mlTrain batch 7/31 - 237.6ms/batch - loss: 10.40079 - diff: 10.29mlTrain batch 8/31 - 239.8ms/batch - loss: 11.07891 - diff: 10.61mlTrain batch 9/31 - 238.3ms/batch - loss: 10.56893 - diff: 10.29mlTrain batch 10/31 - 237.8ms/batch - loss: 10.60027 - diff: 10.33mlTrain batch 11/31 - 237.7ms/batch - loss: 11.02669 - diff: 10.61mlTrain batch 12/31 - 238.5ms/batch - loss: 11.01734 - diff: 10.55mlTrain batch 13/31 - 238.0ms/batch - loss: 10.84707 - diff: 10.53mlTrain batch 14/31 - 240.0ms/batch - loss: 10.77247 - diff: 10.53mlTrain batch 15/31 - 239.4ms/batch - loss: 10.46240 - diff: 10.36mlTrain batch 16/31 - 240.0ms/batch - loss: 10.63019 - diff: 10.45mlTrain batch 17/31 - 238.2ms/batch - loss: 10.66722 - diff: 10.40mlTrain batch 18/31 - 240.0ms/batch - loss: 10.33966 - diff: 10.21mlTrain batch 19/31 - 238.8ms/batch - loss: 10.46592 - diff: 10.29mlTrain batch 20/31 - 240.0ms/batch - loss: 10.81231 - diff: 10.31mlTrain batch 21/31 - 240.9ms/batch - loss: 11.03674 - diff: 10.39mlTrain batch 22/31 - 238.7ms/batch - loss: 11.04079 - diff: 10.38mlTrain batch 23/31 - 238.9ms/batch - loss: 10.92307 - diff: 10.33mlTrain batch 24/31 - 239.2ms/batch - loss: 11.28473 - diff: 10.38mlTrain batch 25/31 - 238.0ms/batch - loss: 12.27381 - diff: 10.67mlTrain batch 26/31 - 239.8ms/batch - loss: 12.28172 - diff: 10.68mlTrain batch 27/31 - 237.5ms/batch - loss: 12.00479 - diff: 10.56mlTrain batch 28/31 - 240.1ms/batch - loss: 12.37525 - diff: 10.70mlTrain batch 29/31 - 237.9ms/batch - loss: 12.31270 - diff: 10.65mlTrain batch 30/31 - 238.1ms/batch - loss: 12.28404 - diff: 10.62mlTrain batch 31/31 - 125.0ms/batch - loss: 14.91820 - diff: 10.88mlTrain batch 31/31 - 11.3s 125.0ms/batch - loss: 14.91820 - diff: 10.88ml
Test 1.1s: val_loss: 32.06247 - diff: 15.19ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Systole_WideResNet50_0_Adam-0.001_MSE_DA3_best

Epoch 143: current best loss = 32.06247, at epoch 142
Train batch 1/31 - 237.2ms/batch - loss: 9.98610 - diff: 11.42mlTrain batch 2/31 - 237.4ms/batch - loss: 7.28265 - diff: 9.32mlTrain batch 3/31 - 237.8ms/batch - loss: 6.71113 - diff: 8.69mlTrain batch 4/31 - 237.3ms/batch - loss: 10.76201 - diff: 10.02mlTrain batch 5/31 - 238.8ms/batch - loss: 12.61647 - diff: 10.57mlTrain batch 6/31 - 239.8ms/batch - loss: 11.65754 - diff: 10.17mlTrain batch 7/31 - 238.0ms/batch - loss: 12.41186 - diff: 10.45mlTrain batch 8/31 - 239.8ms/batch - loss: 12.09004 - diff: 10.49mlTrain batch 9/31 - 238.4ms/batch - loss: 11.77891 - diff: 10.32mlTrain batch 10/31 - 239.3ms/batch - loss: 11.56051 - diff: 10.34mlTrain batch 11/31 - 238.1ms/batch - loss: 11.45537 - diff: 10.29mlTrain batch 12/31 - 239.4ms/batch - loss: 12.57364 - diff: 10.92mlTrain batch 13/31 - 237.4ms/batch - loss: 13.51397 - diff: 11.42mlTrain batch 14/31 - 237.8ms/batch - loss: 13.09253 - diff: 11.27mlTrain batch 15/31 - 237.9ms/batch - loss: 14.80304 - diff: 11.97mlTrain batch 16/31 - 240.2ms/batch - loss: 14.49911 - diff: 11.90mlTrain batch 17/31 - 238.6ms/batch - loss: 14.25517 - diff: 11.73mlTrain batch 18/31 - 239.6ms/batch - loss: 14.05444 - diff: 11.70mlTrain batch 19/31 - 237.6ms/batch - loss: 14.40042 - diff: 11.81mlTrain batch 20/31 - 238.7ms/batch - loss: 14.28108 - diff: 11.78mlTrain batch 21/31 - 237.5ms/batch - loss: 14.05003 - diff: 11.67mlTrain batch 22/31 - 238.9ms/batch - loss: 13.91216 - diff: 11.64mlTrain batch 23/31 - 237.5ms/batch - loss: 13.78260 - diff: 11.59mlTrain batch 24/31 - 238.1ms/batch - loss: 13.44930 - diff: 11.44mlTrain batch 25/31 - 237.9ms/batch - loss: 13.19615 - diff: 11.34mlTrain batch 26/31 - 239.9ms/batch - loss: 13.08877 - diff: 11.27mlTrain batch 27/31 - 237.5ms/batch - loss: 13.27433 - diff: 11.38mlTrain batch 28/31 - 239.8ms/batch - loss: 13.53157 - diff: 11.40mlTrain batch 29/31 - 237.8ms/batch - loss: 14.16434 - diff: 11.61mlTrain batch 30/31 - 239.9ms/batch - loss: 13.98423 - diff: 11.54mlTrain batch 31/31 - 124.3ms/batch - loss: 14.34060 - diff: 11.57mlTrain batch 31/31 - 11.6s 124.3ms/batch - loss: 14.34060 - diff: 11.57ml
Test 1.1s: val_loss: 35.06249 - diff: 15.67ml

Epoch 144: current best loss = 32.06247, at epoch 142
Train batch 1/31 - 237.0ms/batch - loss: 4.30459 - diff: 6.99mlTrain batch 2/31 - 240.5ms/batch - loss: 7.16735 - diff: 8.12mlTrain batch 3/31 - 237.6ms/batch - loss: 6.66178 - diff: 8.07mlTrain batch 4/31 - 239.1ms/batch - loss: 11.02509 - diff: 9.44mlTrain batch 5/31 - 237.7ms/batch - loss: 11.09312 - diff: 9.62mlTrain batch 6/31 - 240.1ms/batch - loss: 11.51205 - diff: 9.91mlTrain batch 7/31 - 237.8ms/batch - loss: 15.92805 - diff: 11.91mlTrain batch 8/31 - 239.9ms/batch - loss: 15.09354 - diff: 11.75mlTrain batch 9/31 - 237.5ms/batch - loss: 14.05666 - diff: 11.32mlTrain batch 10/31 - 237.7ms/batch - loss: 13.54406 - diff: 11.20mlTrain batch 11/31 - 237.3ms/batch - loss: 13.34480 - diff: 11.10mlTrain batch 12/31 - 237.4ms/batch - loss: 12.52496 - diff: 10.71mlTrain batch 13/31 - 239.9ms/batch - loss: 12.29110 - diff: 10.65mlTrain batch 14/31 - 238.3ms/batch - loss: 13.32245 - diff: 10.99mlTrain batch 15/31 - 240.1ms/batch - loss: 13.27166 - diff: 10.99mlTrain batch 16/31 - 238.6ms/batch - loss: 12.72372 - diff: 10.73mlTrain batch 17/31 - 239.0ms/batch - loss: 12.90959 - diff: 10.82mlTrain batch 18/31 - 238.7ms/batch - loss: 12.43525 - diff: 10.59mlTrain batch 19/31 - 240.0ms/batch - loss: 12.45448 - diff: 10.58mlTrain batch 20/31 - 237.9ms/batch - loss: 12.26364 - diff: 10.50mlTrain batch 21/31 - 240.0ms/batch - loss: 13.19685 - diff: 10.79mlTrain batch 22/31 - 237.8ms/batch - loss: 12.84134 - diff: 10.65mlTrain batch 23/31 - 240.2ms/batch - loss: 12.74220 - diff: 10.63mlTrain batch 24/31 - 237.5ms/batch - loss: 12.81238 - diff: 10.72mlTrain batch 25/31 - 240.2ms/batch - loss: 12.72335 - diff: 10.70mlTrain batch 26/31 - 238.2ms/batch - loss: 12.49120 - diff: 10.62mlTrain batch 27/31 - 240.2ms/batch - loss: 12.61994 - diff: 10.67mlTrain batch 28/31 - 238.2ms/batch - loss: 12.44833 - diff: 10.64mlTrain batch 29/31 - 238.4ms/batch - loss: 12.38162 - diff: 10.61mlTrain batch 30/31 - 240.1ms/batch - loss: 12.18080 - diff: 10.53mlTrain batch 31/31 - 124.8ms/batch - loss: 12.15643 - diff: 10.49mlTrain batch 31/31 - 10.7s 124.8ms/batch - loss: 12.15643 - diff: 10.49ml
Test 1.2s: val_loss: 35.35828 - diff: 15.55ml

Epoch 145: current best loss = 32.06247, at epoch 142
Train batch 1/31 - 237.0ms/batch - loss: 7.04535 - diff: 7.88mlTrain batch 2/31 - 249.1ms/batch - loss: 7.42491 - diff: 8.57mlTrain batch 3/31 - 237.3ms/batch - loss: 8.76050 - diff: 9.46mlTrain batch 4/31 - 242.6ms/batch - loss: 8.05301 - diff: 8.83mlTrain batch 5/31 - 238.2ms/batch - loss: 8.40854 - diff: 9.00mlTrain batch 6/31 - 239.5ms/batch - loss: 7.97278 - diff: 8.76mlTrain batch 7/31 - 240.1ms/batch - loss: 7.91773 - diff: 8.80mlTrain batch 8/31 - 238.0ms/batch - loss: 8.12335 - diff: 8.85mlTrain batch 9/31 - 239.2ms/batch - loss: 8.80868 - diff: 9.20mlTrain batch 10/31 - 240.2ms/batch - loss: 8.81169 - diff: 9.22mlTrain batch 11/31 - 237.3ms/batch - loss: 8.60333 - diff: 9.23mlTrain batch 12/31 - 239.3ms/batch - loss: 13.64873 - diff: 10.53mlTrain batch 13/31 - 237.7ms/batch - loss: 13.99295 - diff: 10.58mlTrain batch 14/31 - 237.4ms/batch - loss: 14.46993 - diff: 10.65mlTrain batch 15/31 - 237.5ms/batch - loss: 14.64135 - diff: 10.85mlTrain batch 16/31 - 239.8ms/batch - loss: 14.37637 - diff: 10.78mlTrain batch 17/31 - 237.8ms/batch - loss: 13.87946 - diff: 10.65mlTrain batch 18/31 - 239.2ms/batch - loss: 13.95591 - diff: 10.70mlTrain batch 19/31 - 238.3ms/batch - loss: 13.71954 - diff: 10.70mlTrain batch 20/31 - 239.9ms/batch - loss: 13.51123 - diff: 10.67mlTrain batch 21/31 - 240.3ms/batch - loss: 13.19295 - diff: 10.54mlTrain batch 22/31 - 238.6ms/batch - loss: 13.06314 - diff: 10.57mlTrain batch 23/31 - 238.1ms/batch - loss: 13.00481 - diff: 10.60mlTrain batch 24/31 - 240.0ms/batch - loss: 12.73646 - diff: 10.49mlTrain batch 25/31 - 237.5ms/batch - loss: 12.63843 - diff: 10.49mlTrain batch 26/31 - 240.1ms/batch - loss: 12.48347 - diff: 10.39mlTrain batch 27/31 - 237.7ms/batch - loss: 12.27685 - diff: 10.32mlTrain batch 28/31 - 240.1ms/batch - loss: 12.55643 - diff: 10.46mlTrain batch 29/31 - 237.4ms/batch - loss: 12.38507 - diff: 10.40mlTrain batch 30/31 - 239.6ms/batch - loss: 12.53211 - diff: 10.51mlTrain batch 31/31 - 124.8ms/batch - loss: 12.45936 - diff: 10.44mlTrain batch 31/31 - 11.2s 124.8ms/batch - loss: 12.45936 - diff: 10.44ml
Test 1.1s: val_loss: 33.05041 - diff: 15.50ml

Epoch 146: current best loss = 32.06247, at epoch 142
Train batch 1/31 - 237.3ms/batch - loss: 15.47593 - diff: 10.35mlTrain batch 2/31 - 239.1ms/batch - loss: 12.94981 - diff: 10.41mlTrain batch 3/31 - 237.4ms/batch - loss: 12.22756 - diff: 10.39mlTrain batch 4/31 - 238.6ms/batch - loss: 20.16091 - diff: 13.61mlTrain batch 5/31 - 238.0ms/batch - loss: 18.26730 - diff: 13.08mlTrain batch 6/31 - 237.2ms/batch - loss: 16.92105 - diff: 12.68mlTrain batch 7/31 - 237.8ms/batch - loss: 15.81098 - diff: 11.97mlTrain batch 8/31 - 240.9ms/batch - loss: 15.27386 - diff: 11.84mlTrain batch 9/31 - 238.1ms/batch - loss: 14.78002 - diff: 11.64mlTrain batch 10/31 - 239.9ms/batch - loss: 15.22462 - diff: 11.90mlTrain batch 11/31 - 238.0ms/batch - loss: 15.16429 - diff: 12.00mlTrain batch 12/31 - 237.8ms/batch - loss: 14.27452 - diff: 11.52mlTrain batch 13/31 - 241.1ms/batch - loss: 13.90420 - diff: 11.46mlTrain batch 14/31 - 237.3ms/batch - loss: 13.45083 - diff: 11.26mlTrain batch 15/31 - 238.0ms/batch - loss: 13.55294 - diff: 11.36mlTrain batch 16/31 - 238.2ms/batch - loss: 13.29163 - diff: 11.26mlTrain batch 17/31 - 239.6ms/batch - loss: 12.94382 - diff: 11.12mlTrain batch 18/31 - 237.8ms/batch - loss: 12.66297 - diff: 11.01mlTrain batch 19/31 - 237.9ms/batch - loss: 12.37892 - diff: 10.93mlTrain batch 20/31 - 238.1ms/batch - loss: 12.29727 - diff: 10.85mlTrain batch 21/31 - 239.7ms/batch - loss: 12.36703 - diff: 10.95mlTrain batch 22/31 - 237.6ms/batch - loss: 12.11823 - diff: 10.85mlTrain batch 23/31 - 240.1ms/batch - loss: 11.80078 - diff: 10.69mlTrain batch 24/31 - 237.9ms/batch - loss: 11.80052 - diff: 10.71mlTrain batch 25/31 - 240.1ms/batch - loss: 12.38114 - diff: 10.93mlTrain batch 26/31 - 238.0ms/batch - loss: 12.42473 - diff: 10.98mlTrain batch 27/31 - 239.8ms/batch - loss: 13.13171 - diff: 11.20mlTrain batch 28/31 - 238.4ms/batch - loss: 13.07908 - diff: 11.16mlTrain batch 29/31 - 240.0ms/batch - loss: 13.27915 - diff: 11.28mlTrain batch 30/31 - 238.3ms/batch - loss: 13.28175 - diff: 11.29mlTrain batch 31/31 - 124.0ms/batch - loss: 13.22856 - diff: 11.22mlTrain batch 31/31 - 11.7s 124.0ms/batch - loss: 13.22856 - diff: 11.22ml
Test 1.1s: val_loss: 32.87816 - diff: 15.54ml

Epoch 147: current best loss = 32.06247, at epoch 142
Train batch 1/31 - 237.0ms/batch - loss: 2.91186 - diff: 6.15mlTrain batch 2/31 - 239.1ms/batch - loss: 28.77646 - diff: 14.65mlTrain batch 3/31 - 237.1ms/batch - loss: 21.78606 - diff: 12.85mlTrain batch 4/31 - 239.3ms/batch - loss: 17.71379 - diff: 11.34mlTrain batch 5/31 - 237.2ms/batch - loss: 18.72194 - diff: 12.21mlTrain batch 6/31 - 237.1ms/batch - loss: 19.09438 - diff: 12.33mlTrain batch 7/31 - 242.3ms/batch - loss: 17.35178 - diff: 11.67mlTrain batch 8/31 - 240.2ms/batch - loss: 16.29700 - diff: 11.32mlTrain batch 9/31 - 238.4ms/batch - loss: 15.74138 - diff: 11.25mlTrain batch 10/31 - 239.0ms/batch - loss: 15.40926 - diff: 11.33mlTrain batch 11/31 - 239.9ms/batch - loss: 14.52134 - diff: 11.00mlTrain batch 12/31 - 237.5ms/batch - loss: 14.11169 - diff: 11.00mlTrain batch 13/31 - 242.2ms/batch - loss: 13.79860 - diff: 10.85mlTrain batch 14/31 - 237.7ms/batch - loss: 13.06769 - diff: 10.52mlTrain batch 15/31 - 238.9ms/batch - loss: 12.86468 - diff: 10.39mlTrain batch 16/31 - 238.5ms/batch - loss: 12.75330 - diff: 10.40mlTrain batch 17/31 - 239.9ms/batch - loss: 12.63196 - diff: 10.42mlTrain batch 18/31 - 238.3ms/batch - loss: 12.79131 - diff: 10.61mlTrain batch 19/31 - 239.9ms/batch - loss: 13.57618 - diff: 10.92mlTrain batch 20/31 - 237.5ms/batch - loss: 13.12984 - diff: 10.71mlTrain batch 21/31 - 240.2ms/batch - loss: 12.66075 - diff: 10.44mlTrain batch 22/31 - 238.1ms/batch - loss: 12.37872 - diff: 10.33mlTrain batch 23/31 - 240.5ms/batch - loss: 12.25333 - diff: 10.28mlTrain batch 24/31 - 237.8ms/batch - loss: 12.13729 - diff: 10.29mlTrain batch 25/31 - 238.8ms/batch - loss: 12.30147 - diff: 10.38mlTrain batch 26/31 - 238.7ms/batch - loss: 12.46330 - diff: 10.49mlTrain batch 27/31 - 239.7ms/batch - loss: 12.17493 - diff: 10.38mlTrain batch 28/31 - 238.0ms/batch - loss: 11.90328 - diff: 10.29mlTrain batch 29/31 - 239.9ms/batch - loss: 12.01345 - diff: 10.33mlTrain batch 30/31 - 238.5ms/batch - loss: 11.81083 - diff: 10.26mlTrain batch 31/31 - 123.5ms/batch - loss: 12.11489 - diff: 10.28mlTrain batch 31/31 - 11.2s 123.5ms/batch - loss: 12.11489 - diff: 10.28ml
Test 1.1s: val_loss: 38.17145 - diff: 15.64ml

Epoch 148: current best loss = 32.06247, at epoch 142
Train batch 1/31 - 237.7ms/batch - loss: 6.67574 - diff: 7.88mlTrain batch 2/31 - 238.1ms/batch - loss: 5.86970 - diff: 7.68mlTrain batch 3/31 - 237.9ms/batch - loss: 6.19143 - diff: 7.79mlTrain batch 4/31 - 239.1ms/batch - loss: 6.53072 - diff: 8.08mlTrain batch 5/31 - 237.7ms/batch - loss: 8.18835 - diff: 9.02mlTrain batch 6/31 - 240.0ms/batch - loss: 9.16832 - diff: 9.42mlTrain batch 7/31 - 238.1ms/batch - loss: 10.06527 - diff: 9.92mlTrain batch 8/31 - 237.7ms/batch - loss: 9.49558 - diff: 9.58mlTrain batch 9/31 - 237.6ms/batch - loss: 9.55989 - diff: 9.60mlTrain batch 10/31 - 240.0ms/batch - loss: 9.50550 - diff: 9.60mlTrain batch 11/31 - 237.9ms/batch - loss: 10.18633 - diff: 9.92mlTrain batch 12/31 - 240.3ms/batch - loss: 10.58082 - diff: 10.14mlTrain batch 13/31 - 238.3ms/batch - loss: 10.13089 - diff: 9.85mlTrain batch 14/31 - 240.3ms/batch - loss: 9.73361 - diff: 9.65mlTrain batch 15/31 - 237.9ms/batch - loss: 9.65938 - diff: 9.60mlTrain batch 16/31 - 239.7ms/batch - loss: 9.60948 - diff: 9.58mlTrain batch 17/31 - 238.6ms/batch - loss: 9.60366 - diff: 9.64mlTrain batch 18/31 - 239.4ms/batch - loss: 10.15332 - diff: 9.89mlTrain batch 19/31 - 237.9ms/batch - loss: 10.32064 - diff: 10.02mlTrain batch 20/31 - 239.6ms/batch - loss: 10.55446 - diff: 10.12mlTrain batch 21/31 - 238.0ms/batch - loss: 10.35737 - diff: 9.98mlTrain batch 22/31 - 240.0ms/batch - loss: 10.51371 - diff: 10.04mlTrain batch 23/31 - 237.9ms/batch - loss: 10.54062 - diff: 10.09mlTrain batch 24/31 - 240.3ms/batch - loss: 10.63530 - diff: 10.12mlTrain batch 25/31 - 238.2ms/batch - loss: 10.66162 - diff: 10.12mlTrain batch 26/31 - 240.2ms/batch - loss: 10.54727 - diff: 10.04mlTrain batch 27/31 - 238.4ms/batch - loss: 10.56761 - diff: 10.07mlTrain batch 28/31 - 240.3ms/batch - loss: 10.41568 - diff: 9.97mlTrain batch 29/31 - 237.6ms/batch - loss: 10.28604 - diff: 9.90mlTrain batch 30/31 - 239.5ms/batch - loss: 10.22736 - diff: 9.86mlTrain batch 31/31 - 124.5ms/batch - loss: 10.40603 - diff: 9.87mlTrain batch 31/31 - 10.3s 124.5ms/batch - loss: 10.40603 - diff: 9.87ml
Test 1.1s: val_loss: 37.75424 - diff: 15.75ml

Epoch 149: current best loss = 32.06247, at epoch 142
Train batch 1/31 - 237.0ms/batch - loss: 26.80903 - diff: 18.52mlTrain batch 2/31 - 239.7ms/batch - loss: 15.89982 - diff: 12.78mlTrain batch 3/31 - 238.3ms/batch - loss: 14.40683 - diff: 12.53mlTrain batch 4/31 - 239.2ms/batch - loss: 12.88063 - diff: 11.52mlTrain batch 5/31 - 237.9ms/batch - loss: 12.63191 - diff: 11.45mlTrain batch 6/31 - 240.0ms/batch - loss: 11.35229 - diff: 10.59mlTrain batch 7/31 - 238.3ms/batch - loss: 11.03786 - diff: 10.31mlTrain batch 8/31 - 240.2ms/batch - loss: 11.14141 - diff: 10.36mlTrain batch 9/31 - 237.8ms/batch - loss: 11.00427 - diff: 10.25mlTrain batch 10/31 - 238.8ms/batch - loss: 10.94969 - diff: 10.32mlTrain batch 11/31 - 237.8ms/batch - loss: 10.65650 - diff: 10.21mlTrain batch 12/31 - 238.5ms/batch - loss: 10.53080 - diff: 10.12mlTrain batch 13/31 - 237.8ms/batch - loss: 10.33010 - diff: 10.08mlTrain batch 14/31 - 237.5ms/batch - loss: 10.24797 - diff: 10.07mlTrain batch 15/31 - 240.0ms/batch - loss: 10.10241 - diff: 10.01mlTrain batch 16/31 - 237.8ms/batch - loss: 10.02933 - diff: 10.01mlTrain batch 17/31 - 240.2ms/batch - loss: 9.96589 - diff: 9.95mlTrain batch 18/31 - 237.8ms/batch - loss: 9.96313 - diff: 9.96mlTrain batch 19/31 - 239.6ms/batch - loss: 9.72710 - diff: 9.85mlTrain batch 20/31 - 237.9ms/batch - loss: 9.63429 - diff: 9.82mlTrain batch 21/31 - 239.7ms/batch - loss: 9.51150 - diff: 9.72mlTrain batch 22/31 - 238.5ms/batch - loss: 9.55004 - diff: 9.77mlTrain batch 23/31 - 239.9ms/batch - loss: 9.79795 - diff: 9.88mlTrain batch 24/31 - 238.1ms/batch - loss: 9.53401 - diff: 9.73mlTrain batch 25/31 - 239.1ms/batch - loss: 9.96613 - diff: 9.91mlTrain batch 26/31 - 238.3ms/batch - loss: 9.85014 - diff: 9.84mlTrain batch 27/31 - 239.2ms/batch - loss: 9.77113 - diff: 9.81mlTrain batch 28/31 - 238.7ms/batch - loss: 9.87585 - diff: 9.88mlTrain batch 29/31 - 240.0ms/batch - loss: 9.72274 - diff: 9.80mlTrain batch 30/31 - 240.1ms/batch - loss: 10.12041 - diff: 9.96mlTrain batch 31/31 - 124.5ms/batch - loss: 10.24482 - diff: 9.94mlTrain batch 31/31 - 10.3s 124.5ms/batch - loss: 10.24482 - diff: 9.94ml
Test 1.1s: val_loss: 36.07731 - diff: 15.58ml

