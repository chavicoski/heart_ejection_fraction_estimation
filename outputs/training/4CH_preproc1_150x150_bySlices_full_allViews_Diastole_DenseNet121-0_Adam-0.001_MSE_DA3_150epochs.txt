nohup: ignoring input
Downloading: "https://download.pytorch.org/models/densenet121-a639ec97.pth" to /home/allochi/.cache/torch/hub/checkpoints/densenet121-a639ec97.pth
  0%|          | 0.00/30.8M [00:00<?, ?B/s]  0%|          | 56.0k/30.8M [00:00<01:22, 393kB/s]  1%|          | 272k/30.8M [00:00<01:02, 517kB/s]   2%|▏         | 600k/30.8M [00:00<00:46, 688kB/s]  8%|▊         | 2.33M/30.8M [00:00<00:30, 965kB/s] 16%|█▌        | 4.83M/30.8M [00:00<00:20, 1.36MB/s] 28%|██▊       | 8.73M/30.8M [00:00<00:12, 1.91MB/s] 40%|███▉      | 12.3M/30.8M [00:00<00:07, 2.65MB/s] 54%|█████▍    | 16.6M/30.8M [00:00<00:04, 3.70MB/s] 64%|██████▍   | 19.8M/30.8M [00:01<00:02, 4.99MB/s] 76%|███████▋  | 23.6M/30.8M [00:01<00:01, 6.77MB/s] 89%|████████▊ | 27.3M/30.8M [00:01<00:00, 8.84MB/s]100%|██████████| 30.8M/30.8M [00:01<00:00, 23.7MB/s]Running experiment 4CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_DenseNet121_0_Adam-0.001_MSE_DA3
Going to train with the GPU in the slot 1 -> device model: GeForce GTX 1080
Model architecture:
 DenseNet121_0(
  (first_conv): Sequential(
    (0): Conv2d(30, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (pretrained_block): Sequential(
    (0): _DenseBlock(
      (denselayer1): _DenseLayer(
        (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer2): _DenseLayer(
        (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer3): _DenseLayer(
        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer4): _DenseLayer(
        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer5): _DenseLayer(
        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer6): _DenseLayer(
        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
    (1): _Transition(
      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)
    )
    (2): _DenseBlock(
      (denselayer1): _DenseLayer(
        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer2): _DenseLayer(
        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer3): _DenseLayer(
        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer4): _DenseLayer(
        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer5): _DenseLayer(
        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer6): _DenseLayer(
        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer7): _DenseLayer(
        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer8): _DenseLayer(
        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer9): _DenseLayer(
        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer10): _DenseLayer(
        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer11): _DenseLayer(
        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer12): _DenseLayer(
        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
    (3): _Transition(
      (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)
    )
    (4): _DenseBlock(
      (denselayer1): _DenseLayer(
        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer2): _DenseLayer(
        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer3): _DenseLayer(
        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer4): _DenseLayer(
        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer5): _DenseLayer(
        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer6): _DenseLayer(
        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer7): _DenseLayer(
        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer8): _DenseLayer(
        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer9): _DenseLayer(
        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer10): _DenseLayer(
        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer11): _DenseLayer(
        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer12): _DenseLayer(
        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer13): _DenseLayer(
        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer14): _DenseLayer(
        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer15): _DenseLayer(
        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer16): _DenseLayer(
        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer17): _DenseLayer(
        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer18): _DenseLayer(
        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer19): _DenseLayer(
        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer20): _DenseLayer(
        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer21): _DenseLayer(
        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer22): _DenseLayer(
        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer23): _DenseLayer(
        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer24): _DenseLayer(
        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
    (5): _Transition(
      (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)
    )
    (6): _DenseBlock(
      (denselayer1): _DenseLayer(
        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer2): _DenseLayer(
        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer3): _DenseLayer(
        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer4): _DenseLayer(
        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer5): _DenseLayer(
        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer6): _DenseLayer(
        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer7): _DenseLayer(
        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer8): _DenseLayer(
        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer9): _DenseLayer(
        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer10): _DenseLayer(
        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer11): _DenseLayer(
        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer12): _DenseLayer(
        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer13): _DenseLayer(
        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer14): _DenseLayer(
        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer15): _DenseLayer(
        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer16): _DenseLayer(
        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
    (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (reduction_block): Sequential(
    (0): AdaptiveAvgPool2d(output_size=(1, 1))
    (1): Flatten()
  )
  (dense_block): Sequential(
    (0): Linear(in_features=1024, out_features=512, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.4, inplace=False)
    (3): Linear(in_features=512, out_features=1, bias=True)
  )
) 


############################
# TRAIN PHASE:  150 epochs #
############################

Epoch 0: 

Train batch 1/31 - 1682.2ms/batch - loss: 2102.60107 - diff: 176.08mlTrain batch 2/31 - 80.8ms/batch - loss: 1885.04443 - diff: 165.31mlTrain batch 3/31 - 80.3ms/batch - loss: 1904.42887 - diff: 165.20mlTrain batch 4/31 - 78.9ms/batch - loss: 1833.16656 - diff: 161.88mlTrain batch 5/31 - 78.8ms/batch - loss: 1761.21108 - diff: 159.02mlTrain batch 6/31 - 77.4ms/batch - loss: 1779.70900 - diff: 160.53mlTrain batch 7/31 - 78.0ms/batch - loss: 1798.05540 - diff: 160.36mlTrain batch 8/31 - 77.7ms/batch - loss: 1803.31416 - diff: 159.61mlTrain batch 9/31 - 78.2ms/batch - loss: 1746.27257 - diff: 157.10mlTrain batch 10/31 - 77.6ms/batch - loss: 1772.98846 - diff: 158.60mlTrain batch 11/31 - 78.4ms/batch - loss: 1812.67106 - diff: 159.85mlTrain batch 12/31 - 77.7ms/batch - loss: 1762.19992 - diff: 157.30mlTrain batch 13/31 - 77.9ms/batch - loss: 1733.63955 - diff: 156.01mlTrain batch 14/31 - 77.3ms/batch - loss: 1698.30370 - diff: 154.02mlTrain batch 15/31 - 78.0ms/batch - loss: 1673.99405 - diff: 153.01mlTrain batch 16/31 - 77.4ms/batch - loss: 1636.12559 - diff: 151.40mlTrain batch 17/31 - 77.8ms/batch - loss: 1607.53863 - diff: 150.00mlTrain batch 18/31 - 77.5ms/batch - loss: 1599.36437 - diff: 149.58mlTrain batch 19/31 - 77.7ms/batch - loss: 1602.15450 - diff: 149.37mlTrain batch 20/31 - 77.8ms/batch - loss: 1571.71842 - diff: 147.55mlTrain batch 21/31 - 78.0ms/batch - loss: 1563.65769 - diff: 146.85mlTrain batch 22/31 - 77.8ms/batch - loss: 1544.37188 - diff: 146.07mlTrain batch 23/31 - 77.9ms/batch - loss: 1530.43191 - diff: 144.98mlTrain batch 24/31 - 77.6ms/batch - loss: 1516.97270 - diff: 144.03mlTrain batch 25/31 - 77.8ms/batch - loss: 1504.76435 - diff: 143.44mlTrain batch 26/31 - 77.5ms/batch - loss: 1473.07932 - diff: 141.40mlTrain batch 27/31 - 77.8ms/batch - loss: 1439.67574 - diff: 139.48mlTrain batch 28/31 - 77.4ms/batch - loss: 1406.95917 - diff: 137.53mlTrain batch 29/31 - 77.7ms/batch - loss: 1419.44478 - diff: 137.06mlTrain batch 30/31 - 77.1ms/batch - loss: 1393.16759 - diff: 135.34mlTrain batch 31/31 - 40.0ms/batch - loss: 1384.72381 - diff: 134.26mlTrain batch 31/31 - 10.1s 40.0ms/batch - loss: 1384.72381 - diff: 134.26ml
Test 0.7s: val_loss: 656.85471 - diff: 86.57ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_DenseNet121_0_Adam-0.001_MSE_DA3_best

Epoch 1: current best loss = 656.85471, at epoch 0
Train batch 1/31 - 80.0ms/batch - loss: 666.88550 - diff: 86.62mlTrain batch 2/31 - 77.6ms/batch - loss: 581.31134 - diff: 80.10mlTrain batch 3/31 - 79.9ms/batch - loss: 640.95435 - diff: 81.03mlTrain batch 4/31 - 77.6ms/batch - loss: 580.39093 - diff: 76.67mlTrain batch 5/31 - 79.9ms/batch - loss: 553.76409 - diff: 75.77mlTrain batch 6/31 - 77.2ms/batch - loss: 565.19727 - diff: 76.68mlTrain batch 7/31 - 79.9ms/batch - loss: 550.53404 - diff: 74.92mlTrain batch 8/31 - 77.5ms/batch - loss: 540.94241 - diff: 74.06mlTrain batch 9/31 - 80.0ms/batch - loss: 516.57416 - diff: 70.94mlTrain batch 10/31 - 77.3ms/batch - loss: 487.57368 - diff: 68.51mlTrain batch 11/31 - 77.9ms/batch - loss: 481.58838 - diff: 68.22mlTrain batch 12/31 - 77.5ms/batch - loss: 490.98834 - diff: 68.87mlTrain batch 13/31 - 77.7ms/batch - loss: 473.25592 - diff: 67.29mlTrain batch 14/31 - 77.9ms/batch - loss: 467.73967 - diff: 67.23mlTrain batch 15/31 - 77.8ms/batch - loss: 464.89672 - diff: 67.63mlTrain batch 16/31 - 77.6ms/batch - loss: 464.30364 - diff: 66.90mlTrain batch 17/31 - 77.5ms/batch - loss: 453.19398 - diff: 65.93mlTrain batch 18/31 - 77.7ms/batch - loss: 437.89530 - diff: 64.65mlTrain batch 19/31 - 77.5ms/batch - loss: 429.26493 - diff: 64.02mlTrain batch 20/31 - 77.2ms/batch - loss: 416.64729 - diff: 63.16mlTrain batch 21/31 - 77.4ms/batch - loss: 410.52090 - diff: 62.83mlTrain batch 22/31 - 77.5ms/batch - loss: 410.47200 - diff: 62.93mlTrain batch 23/31 - 77.4ms/batch - loss: 401.31120 - diff: 62.18mlTrain batch 24/31 - 77.5ms/batch - loss: 403.31703 - diff: 62.62mlTrain batch 25/31 - 77.5ms/batch - loss: 417.18279 - diff: 63.42mlTrain batch 26/31 - 77.6ms/batch - loss: 410.61789 - diff: 62.55mlTrain batch 27/31 - 77.4ms/batch - loss: 402.43636 - diff: 61.90mlTrain batch 28/31 - 77.4ms/batch - loss: 401.42674 - diff: 61.79mlTrain batch 29/31 - 77.2ms/batch - loss: 398.19418 - diff: 61.58mlTrain batch 30/31 - 77.0ms/batch - loss: 394.06409 - diff: 61.27mlTrain batch 31/31 - 39.7ms/batch - loss: 394.98177 - diff: 61.06mlTrain batch 31/31 - 9.2s 39.7ms/batch - loss: 394.98177 - diff: 61.06ml
Test 0.7s: val_loss: 668.87429 - diff: 80.21ml

Epoch 2: current best loss = 656.85471, at epoch 0
Train batch 1/31 - 78.2ms/batch - loss: 128.24475 - diff: 36.60mlTrain batch 2/31 - 77.7ms/batch - loss: 330.61902 - diff: 52.78mlTrain batch 3/31 - 77.7ms/batch - loss: 307.34440 - diff: 52.08mlTrain batch 4/31 - 77.8ms/batch - loss: 323.69859 - diff: 54.30mlTrain batch 5/31 - 77.5ms/batch - loss: 309.20390 - diff: 54.44mlTrain batch 6/31 - 91.7ms/batch - loss: 324.42893 - diff: 54.94mlTrain batch 7/31 - 77.3ms/batch - loss: 314.30612 - diff: 53.95mlTrain batch 8/31 - 77.4ms/batch - loss: 305.33622 - diff: 53.17mlTrain batch 9/31 - 77.5ms/batch - loss: 282.38712 - diff: 51.20mlTrain batch 10/31 - 104.7ms/batch - loss: 341.52524 - diff: 54.09mlTrain batch 11/31 - 77.8ms/batch - loss: 345.70985 - diff: 54.72mlTrain batch 12/31 - 77.9ms/batch - loss: 340.86780 - diff: 54.48mlTrain batch 13/31 - 80.7ms/batch - loss: 337.51472 - diff: 54.28mlTrain batch 14/31 - 78.2ms/batch - loss: 334.14958 - diff: 54.09mlTrain batch 15/31 - 83.2ms/batch - loss: 333.27716 - diff: 54.52mlTrain batch 16/31 - 79.5ms/batch - loss: 325.45373 - diff: 54.04mlTrain batch 17/31 - 80.4ms/batch - loss: 315.94400 - diff: 53.27mlTrain batch 18/31 - 79.5ms/batch - loss: 316.03343 - diff: 53.67mlTrain batch 19/31 - 78.6ms/batch - loss: 308.65750 - diff: 53.04mlTrain batch 20/31 - 78.6ms/batch - loss: 307.48368 - diff: 53.20mlTrain batch 21/31 - 77.8ms/batch - loss: 301.14869 - diff: 52.76mlTrain batch 22/31 - 78.1ms/batch - loss: 294.49020 - diff: 52.18mlTrain batch 23/31 - 77.5ms/batch - loss: 288.81332 - diff: 51.60mlTrain batch 24/31 - 77.7ms/batch - loss: 285.97696 - diff: 51.54mlTrain batch 25/31 - 77.9ms/batch - loss: 278.54542 - diff: 50.72mlTrain batch 26/31 - 77.7ms/batch - loss: 275.58082 - diff: 50.53mlTrain batch 27/31 - 77.7ms/batch - loss: 279.58864 - diff: 51.01mlTrain batch 28/31 - 77.3ms/batch - loss: 284.63364 - diff: 51.76mlTrain batch 29/31 - 77.8ms/batch - loss: 287.68456 - diff: 51.96mlTrain batch 30/31 - 77.9ms/batch - loss: 288.08453 - diff: 52.13mlTrain batch 31/31 - 40.8ms/batch - loss: 318.56207 - diff: 52.81mlTrain batch 31/31 - 9.7s 40.8ms/batch - loss: 318.56207 - diff: 52.81ml
Test 0.8s: val_loss: 377.37470 - diff: 60.69ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_DenseNet121_0_Adam-0.001_MSE_DA3_best

Epoch 3: current best loss = 377.37470, at epoch 2
Train batch 1/31 - 80.5ms/batch - loss: 205.11261 - diff: 46.21mlTrain batch 2/31 - 80.1ms/batch - loss: 178.35786 - diff: 40.14mlTrain batch 3/31 - 81.3ms/batch - loss: 258.59344 - diff: 47.56mlTrain batch 4/31 - 78.5ms/batch - loss: 271.74125 - diff: 50.33mlTrain batch 5/31 - 81.4ms/batch - loss: 280.66270 - diff: 50.89mlTrain batch 6/31 - 78.7ms/batch - loss: 267.76037 - diff: 49.88mlTrain batch 7/31 - 84.5ms/batch - loss: 257.43330 - diff: 48.61mlTrain batch 8/31 - 77.7ms/batch - loss: 254.09701 - diff: 48.64mlTrain batch 9/31 - 80.9ms/batch - loss: 268.24889 - diff: 49.46mlTrain batch 10/31 - 79.0ms/batch - loss: 266.25068 - diff: 49.23mlTrain batch 11/31 - 78.3ms/batch - loss: 258.51756 - diff: 48.59mlTrain batch 12/31 - 83.0ms/batch - loss: 257.79885 - diff: 48.39mlTrain batch 13/31 - 84.7ms/batch - loss: 258.01805 - diff: 48.78mlTrain batch 14/31 - 79.2ms/batch - loss: 260.26068 - diff: 49.86mlTrain batch 15/31 - 82.9ms/batch - loss: 287.74350 - diff: 50.31mlTrain batch 16/31 - 80.3ms/batch - loss: 281.91953 - diff: 50.16mlTrain batch 17/31 - 90.9ms/batch - loss: 271.99591 - diff: 49.20mlTrain batch 18/31 - 87.0ms/batch - loss: 265.39662 - diff: 48.86mlTrain batch 19/31 - 81.8ms/batch - loss: 254.28466 - diff: 47.64mlTrain batch 20/31 - 78.1ms/batch - loss: 249.24246 - diff: 47.36mlTrain batch 21/31 - 78.0ms/batch - loss: 247.19753 - diff: 47.43mlTrain batch 22/31 - 78.5ms/batch - loss: 246.71278 - diff: 47.46mlTrain batch 23/31 - 77.8ms/batch - loss: 242.16388 - diff: 46.69mlTrain batch 24/31 - 77.9ms/batch - loss: 236.75442 - diff: 46.06mlTrain batch 25/31 - 77.8ms/batch - loss: 238.32173 - diff: 46.48mlTrain batch 26/31 - 78.2ms/batch - loss: 251.14071 - diff: 47.57mlTrain batch 27/31 - 77.6ms/batch - loss: 252.96506 - diff: 47.76mlTrain batch 28/31 - 77.5ms/batch - loss: 250.26875 - diff: 47.58mlTrain batch 29/31 - 80.8ms/batch - loss: 251.03605 - diff: 47.40mlTrain batch 30/31 - 77.9ms/batch - loss: 249.92540 - diff: 47.39mlTrain batch 31/31 - 42.0ms/batch - loss: 259.33961 - diff: 47.74mlTrain batch 31/31 - 9.7s 42.0ms/batch - loss: 259.33961 - diff: 47.74ml
Test 0.8s: val_loss: 237.77810 - diff: 46.24ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_DenseNet121_0_Adam-0.001_MSE_DA3_best

Epoch 4: current best loss = 237.77810, at epoch 3
Train batch 1/31 - 78.7ms/batch - loss: 355.65588 - diff: 59.73mlTrain batch 2/31 - 78.5ms/batch - loss: 220.91040 - diff: 43.08mlTrain batch 3/31 - 78.4ms/batch - loss: 219.95069 - diff: 44.25mlTrain batch 4/31 - 78.5ms/batch - loss: 223.20586 - diff: 46.18mlTrain batch 5/31 - 78.1ms/batch - loss: 236.06581 - diff: 48.33mlTrain batch 6/31 - 78.3ms/batch - loss: 227.34711 - diff: 47.87mlTrain batch 7/31 - 77.9ms/batch - loss: 257.53524 - diff: 50.98mlTrain batch 8/31 - 78.3ms/batch - loss: 238.45442 - diff: 48.92mlTrain batch 9/31 - 77.5ms/batch - loss: 228.75375 - diff: 47.89mlTrain batch 10/31 - 77.5ms/batch - loss: 239.09428 - diff: 49.06mlTrain batch 11/31 - 78.7ms/batch - loss: 236.08177 - diff: 49.28mlTrain batch 12/31 - 77.9ms/batch - loss: 235.53453 - diff: 48.83mlTrain batch 13/31 - 78.1ms/batch - loss: 241.45963 - diff: 48.91mlTrain batch 14/31 - 78.7ms/batch - loss: 233.14548 - diff: 48.05mlTrain batch 15/31 - 79.1ms/batch - loss: 228.80716 - diff: 47.60mlTrain batch 16/31 - 85.0ms/batch - loss: 225.63919 - diff: 47.18mlTrain batch 17/31 - 79.8ms/batch - loss: 224.86598 - diff: 47.23mlTrain batch 18/31 - 77.9ms/batch - loss: 246.81261 - diff: 48.34mlTrain batch 19/31 - 78.1ms/batch - loss: 237.58013 - diff: 47.23mlTrain batch 20/31 - 82.0ms/batch - loss: 240.94592 - diff: 47.68mlTrain batch 21/31 - 78.2ms/batch - loss: 244.38506 - diff: 48.04mlTrain batch 22/31 - 83.8ms/batch - loss: 269.16950 - diff: 48.80mlTrain batch 23/31 - 77.7ms/batch - loss: 269.81376 - diff: 48.84mlTrain batch 24/31 - 82.6ms/batch - loss: 264.50972 - diff: 48.37mlTrain batch 25/31 - 78.0ms/batch - loss: 257.96033 - diff: 47.80mlTrain batch 26/31 - 81.6ms/batch - loss: 255.69677 - diff: 47.63mlTrain batch 27/31 - 78.7ms/batch - loss: 251.20991 - diff: 47.19mlTrain batch 28/31 - 78.5ms/batch - loss: 247.16782 - diff: 46.91mlTrain batch 29/31 - 77.6ms/batch - loss: 252.98297 - diff: 47.41mlTrain batch 30/31 - 81.9ms/batch - loss: 256.93037 - diff: 47.70mlTrain batch 31/31 - 41.4ms/batch - loss: 257.52572 - diff: 47.47mlTrain batch 31/31 - 9.7s 41.4ms/batch - loss: 257.52572 - diff: 47.47ml
Test 0.8s: val_loss: 210.16543 - diff: 46.31ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_DenseNet121_0_Adam-0.001_MSE_DA3_best

Epoch 5: current best loss = 210.16543, at epoch 4
Train batch 1/31 - 87.2ms/batch - loss: 200.38037 - diff: 45.32mlTrain batch 2/31 - 78.1ms/batch - loss: 188.38998 - diff: 46.05mlTrain batch 3/31 - 80.0ms/batch - loss: 195.71391 - diff: 44.29mlTrain batch 4/31 - 78.2ms/batch - loss: 186.78055 - diff: 44.02mlTrain batch 5/31 - 81.3ms/batch - loss: 181.68293 - diff: 44.11mlTrain batch 6/31 - 77.8ms/batch - loss: 176.16230 - diff: 43.10mlTrain batch 7/31 - 77.5ms/batch - loss: 166.61209 - diff: 41.93mlTrain batch 8/31 - 77.4ms/batch - loss: 156.77344 - diff: 40.30mlTrain batch 9/31 - 78.5ms/batch - loss: 220.85488 - diff: 42.86mlTrain batch 10/31 - 78.4ms/batch - loss: 210.57375 - diff: 42.37mlTrain batch 11/31 - 78.6ms/batch - loss: 224.27356 - diff: 43.65mlTrain batch 12/31 - 78.3ms/batch - loss: 230.12663 - diff: 44.77mlTrain batch 13/31 - 80.5ms/batch - loss: 221.24883 - diff: 44.13mlTrain batch 14/31 - 77.6ms/batch - loss: 211.49959 - diff: 43.05mlTrain batch 15/31 - 93.6ms/batch - loss: 215.51471 - diff: 43.02mlTrain batch 16/31 - 81.7ms/batch - loss: 205.90541 - diff: 42.01mlTrain batch 17/31 - 79.4ms/batch - loss: 215.31053 - diff: 42.91mlTrain batch 18/31 - 78.1ms/batch - loss: 229.70699 - diff: 44.32mlTrain batch 19/31 - 78.9ms/batch - loss: 227.56791 - diff: 44.23mlTrain batch 20/31 - 78.6ms/batch - loss: 223.41160 - diff: 43.93mlTrain batch 21/31 - 79.4ms/batch - loss: 230.63149 - diff: 44.38mlTrain batch 22/31 - 79.0ms/batch - loss: 237.34696 - diff: 44.84mlTrain batch 23/31 - 79.5ms/batch - loss: 239.70604 - diff: 45.37mlTrain batch 24/31 - 78.1ms/batch - loss: 234.28726 - diff: 45.04mlTrain batch 25/31 - 79.2ms/batch - loss: 229.35342 - diff: 44.48mlTrain batch 26/31 - 78.2ms/batch - loss: 227.15681 - diff: 44.19mlTrain batch 27/31 - 79.0ms/batch - loss: 224.95050 - diff: 44.23mlTrain batch 28/31 - 78.1ms/batch - loss: 227.05646 - diff: 44.62mlTrain batch 29/31 - 79.7ms/batch - loss: 223.15400 - diff: 44.24mlTrain batch 30/31 - 78.5ms/batch - loss: 220.25138 - diff: 43.90mlTrain batch 31/31 - 41.6ms/batch - loss: 225.99870 - diff: 44.13mlTrain batch 31/31 - 9.7s 41.6ms/batch - loss: 225.99870 - diff: 44.13ml
Test 0.8s: val_loss: 242.70476 - diff: 49.35ml

Epoch 6: current best loss = 210.16543, at epoch 4
Train batch 1/31 - 78.6ms/batch - loss: 110.54343 - diff: 33.56mlTrain batch 2/31 - 77.4ms/batch - loss: 108.98732 - diff: 34.36mlTrain batch 3/31 - 78.3ms/batch - loss: 151.08516 - diff: 34.74mlTrain batch 4/31 - 78.1ms/batch - loss: 129.87172 - diff: 31.78mlTrain batch 5/31 - 78.3ms/batch - loss: 125.29358 - diff: 32.70mlTrain batch 6/31 - 78.2ms/batch - loss: 125.03443 - diff: 33.73mlTrain batch 7/31 - 78.6ms/batch - loss: 121.34367 - diff: 34.00mlTrain batch 8/31 - 78.7ms/batch - loss: 128.09210 - diff: 34.57mlTrain batch 9/31 - 78.7ms/batch - loss: 121.19663 - diff: 33.59mlTrain batch 10/31 - 79.1ms/batch - loss: 122.40886 - diff: 34.13mlTrain batch 11/31 - 78.0ms/batch - loss: 133.24316 - diff: 35.32mlTrain batch 12/31 - 78.1ms/batch - loss: 151.84592 - diff: 37.32mlTrain batch 13/31 - 78.3ms/batch - loss: 153.62076 - diff: 37.50mlTrain batch 14/31 - 78.0ms/batch - loss: 158.74616 - diff: 37.74mlTrain batch 15/31 - 78.5ms/batch - loss: 163.09231 - diff: 37.71mlTrain batch 16/31 - 77.9ms/batch - loss: 180.54115 - diff: 39.69mlTrain batch 17/31 - 78.3ms/batch - loss: 173.98535 - diff: 38.95mlTrain batch 18/31 - 78.2ms/batch - loss: 178.15780 - diff: 39.60mlTrain batch 19/31 - 78.0ms/batch - loss: 179.53906 - diff: 39.56mlTrain batch 20/31 - 77.8ms/batch - loss: 177.88013 - diff: 39.61mlTrain batch 21/31 - 77.5ms/batch - loss: 182.58105 - diff: 40.43mlTrain batch 22/31 - 77.4ms/batch - loss: 181.95170 - diff: 40.51mlTrain batch 23/31 - 77.3ms/batch - loss: 185.73348 - diff: 40.82mlTrain batch 24/31 - 77.5ms/batch - loss: 186.44234 - diff: 40.89mlTrain batch 25/31 - 78.4ms/batch - loss: 183.05299 - diff: 40.70mlTrain batch 26/31 - 77.3ms/batch - loss: 180.13893 - diff: 40.37mlTrain batch 27/31 - 78.0ms/batch - loss: 198.94373 - diff: 41.06mlTrain batch 28/31 - 77.6ms/batch - loss: 195.38612 - diff: 40.70mlTrain batch 29/31 - 77.3ms/batch - loss: 196.78274 - diff: 40.75mlTrain batch 30/31 - 77.8ms/batch - loss: 192.94960 - diff: 40.38mlTrain batch 31/31 - 41.2ms/batch - loss: 194.12992 - diff: 40.19mlTrain batch 31/31 - 9.7s 41.2ms/batch - loss: 194.12992 - diff: 40.19ml
Test 0.8s: val_loss: 211.91823 - diff: 43.56ml

Epoch 7: current best loss = 210.16543, at epoch 4
Train batch 1/31 - 78.8ms/batch - loss: 122.01023 - diff: 36.62mlTrain batch 2/31 - 78.8ms/batch - loss: 141.74234 - diff: 38.54mlTrain batch 3/31 - 81.1ms/batch - loss: 170.88663 - diff: 43.02mlTrain batch 4/31 - 78.4ms/batch - loss: 177.12925 - diff: 42.64mlTrain batch 5/31 - 80.3ms/batch - loss: 176.05090 - diff: 43.26mlTrain batch 6/31 - 78.1ms/batch - loss: 153.56716 - diff: 39.57mlTrain batch 7/31 - 80.5ms/batch - loss: 150.13219 - diff: 39.49mlTrain batch 8/31 - 77.8ms/batch - loss: 156.84280 - diff: 40.09mlTrain batch 9/31 - 80.8ms/batch - loss: 158.83874 - diff: 40.34mlTrain batch 10/31 - 78.2ms/batch - loss: 204.23516 - diff: 42.22mlTrain batch 11/31 - 80.5ms/batch - loss: 198.09590 - diff: 41.87mlTrain batch 12/31 - 78.2ms/batch - loss: 191.28018 - diff: 41.17mlTrain batch 13/31 - 80.4ms/batch - loss: 195.23728 - diff: 41.78mlTrain batch 14/31 - 78.3ms/batch - loss: 194.09549 - diff: 42.21mlTrain batch 15/31 - 78.8ms/batch - loss: 189.08476 - diff: 41.85mlTrain batch 16/31 - 78.6ms/batch - loss: 195.65003 - diff: 42.73mlTrain batch 17/31 - 81.2ms/batch - loss: 190.31226 - diff: 42.04mlTrain batch 18/31 - 77.6ms/batch - loss: 186.87730 - diff: 41.76mlTrain batch 19/31 - 80.5ms/batch - loss: 185.34846 - diff: 41.64mlTrain batch 20/31 - 78.6ms/batch - loss: 197.81862 - diff: 42.73mlTrain batch 21/31 - 77.6ms/batch - loss: 197.56733 - diff: 42.74mlTrain batch 22/31 - 77.4ms/batch - loss: 199.47599 - diff: 43.32mlTrain batch 23/31 - 77.7ms/batch - loss: 197.46954 - diff: 43.16mlTrain batch 24/31 - 77.4ms/batch - loss: 194.23025 - diff: 42.92mlTrain batch 25/31 - 77.7ms/batch - loss: 194.06683 - diff: 42.73mlTrain batch 26/31 - 77.6ms/batch - loss: 192.42970 - diff: 42.69mlTrain batch 27/31 - 77.7ms/batch - loss: 194.61746 - diff: 43.01mlTrain batch 28/31 - 77.7ms/batch - loss: 195.38383 - diff: 43.21mlTrain batch 29/31 - 80.9ms/batch - loss: 194.59537 - diff: 43.24mlTrain batch 30/31 - 78.3ms/batch - loss: 201.57464 - diff: 43.95mlTrain batch 31/31 - 42.2ms/batch - loss: 206.91065 - diff: 44.06mlTrain batch 31/31 - 9.7s 42.2ms/batch - loss: 206.91065 - diff: 44.06ml
Test 0.8s: val_loss: 226.68257 - diff: 44.21ml

Epoch 8: current best loss = 210.16543, at epoch 4
Train batch 1/31 - 79.7ms/batch - loss: 154.89459 - diff: 35.40mlTrain batch 2/31 - 77.8ms/batch - loss: 140.45779 - diff: 36.90mlTrain batch 3/31 - 78.4ms/batch - loss: 147.91375 - diff: 39.11mlTrain batch 4/31 - 79.3ms/batch - loss: 161.19151 - diff: 40.90mlTrain batch 5/31 - 81.2ms/batch - loss: 163.41537 - diff: 42.15mlTrain batch 6/31 - 78.5ms/batch - loss: 153.76268 - diff: 40.66mlTrain batch 7/31 - 79.1ms/batch - loss: 151.75150 - diff: 40.72mlTrain batch 8/31 - 78.0ms/batch - loss: 241.79342 - diff: 44.57mlTrain batch 9/31 - 81.4ms/batch - loss: 252.00862 - diff: 44.82mlTrain batch 10/31 - 77.6ms/batch - loss: 234.51902 - diff: 43.43mlTrain batch 11/31 - 78.2ms/batch - loss: 238.38928 - diff: 44.86mlTrain batch 12/31 - 77.6ms/batch - loss: 229.89343 - diff: 44.29mlTrain batch 13/31 - 83.4ms/batch - loss: 225.80902 - diff: 44.11mlTrain batch 14/31 - 78.9ms/batch - loss: 225.01480 - diff: 44.07mlTrain batch 15/31 - 82.1ms/batch - loss: 223.36186 - diff: 44.37mlTrain batch 16/31 - 77.6ms/batch - loss: 216.97883 - diff: 43.98mlTrain batch 17/31 - 79.9ms/batch - loss: 213.32852 - diff: 43.95mlTrain batch 18/31 - 77.6ms/batch - loss: 211.51528 - diff: 43.92mlTrain batch 19/31 - 77.9ms/batch - loss: 204.86062 - diff: 43.30mlTrain batch 20/31 - 77.4ms/batch - loss: 199.78478 - diff: 42.59mlTrain batch 21/31 - 78.4ms/batch - loss: 199.23049 - diff: 42.51mlTrain batch 22/31 - 77.3ms/batch - loss: 195.86093 - diff: 42.18mlTrain batch 23/31 - 80.4ms/batch - loss: 193.39984 - diff: 41.96mlTrain batch 24/31 - 77.7ms/batch - loss: 196.57401 - diff: 42.12mlTrain batch 25/31 - 78.7ms/batch - loss: 195.41071 - diff: 42.20mlTrain batch 26/31 - 78.1ms/batch - loss: 195.92703 - diff: 42.51mlTrain batch 27/31 - 79.6ms/batch - loss: 191.84910 - diff: 42.17mlTrain batch 28/31 - 78.0ms/batch - loss: 189.05053 - diff: 42.02mlTrain batch 29/31 - 81.0ms/batch - loss: 189.28886 - diff: 42.02mlTrain batch 30/31 - 78.6ms/batch - loss: 185.44860 - diff: 41.45mlTrain batch 31/31 - 41.7ms/batch - loss: 199.46475 - diff: 41.93mlTrain batch 31/31 - 9.7s 41.7ms/batch - loss: 199.46475 - diff: 41.93ml
Test 0.8s: val_loss: 172.39719 - diff: 40.52ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_DenseNet121_0_Adam-0.001_MSE_DA3_best

Epoch 9: current best loss = 172.39719, at epoch 8
Train batch 1/31 - 80.9ms/batch - loss: 183.08150 - diff: 43.45mlTrain batch 2/31 - 77.9ms/batch - loss: 137.25409 - diff: 38.10mlTrain batch 3/31 - 78.1ms/batch - loss: 137.47760 - diff: 38.86mlTrain batch 4/31 - 78.6ms/batch - loss: 188.54676 - diff: 42.21mlTrain batch 5/31 - 78.2ms/batch - loss: 183.10480 - diff: 41.56mlTrain batch 6/31 - 80.1ms/batch - loss: 181.34595 - diff: 41.74mlTrain batch 7/31 - 78.6ms/batch - loss: 211.17690 - diff: 43.78mlTrain batch 8/31 - 83.7ms/batch - loss: 218.37290 - diff: 44.47mlTrain batch 9/31 - 78.1ms/batch - loss: 210.75383 - diff: 43.94mlTrain batch 10/31 - 82.4ms/batch - loss: 205.34719 - diff: 43.65mlTrain batch 11/31 - 77.4ms/batch - loss: 245.95596 - diff: 44.93mlTrain batch 12/31 - 79.3ms/batch - loss: 240.28208 - diff: 44.93mlTrain batch 13/31 - 87.3ms/batch - loss: 234.63745 - diff: 44.80mlTrain batch 14/31 - 88.5ms/batch - loss: 232.09566 - diff: 44.89mlTrain batch 15/31 - 77.4ms/batch - loss: 225.90991 - diff: 44.37mlTrain batch 16/31 - 77.4ms/batch - loss: 222.01002 - diff: 44.35mlTrain batch 17/31 - 78.4ms/batch - loss: 212.97000 - diff: 43.20mlTrain batch 18/31 - 77.7ms/batch - loss: 206.24131 - diff: 42.68mlTrain batch 19/31 - 77.7ms/batch - loss: 208.50697 - diff: 43.12mlTrain batch 20/31 - 78.0ms/batch - loss: 201.90875 - diff: 42.25mlTrain batch 21/31 - 77.7ms/batch - loss: 199.03035 - diff: 42.07mlTrain batch 22/31 - 77.4ms/batch - loss: 202.20523 - diff: 42.46mlTrain batch 23/31 - 77.6ms/batch - loss: 198.54038 - diff: 42.01mlTrain batch 24/31 - 77.4ms/batch - loss: 196.49928 - diff: 41.65mlTrain batch 25/31 - 77.3ms/batch - loss: 195.05281 - diff: 41.63mlTrain batch 26/31 - 77.3ms/batch - loss: 195.05348 - diff: 41.61mlTrain batch 27/31 - 77.4ms/batch - loss: 193.12793 - diff: 41.54mlTrain batch 28/31 - 77.4ms/batch - loss: 198.16635 - diff: 41.96mlTrain batch 29/31 - 77.2ms/batch - loss: 202.85275 - diff: 42.20mlTrain batch 30/31 - 77.9ms/batch - loss: 199.16572 - diff: 41.81mlTrain batch 31/31 - 41.2ms/batch - loss: 198.05327 - diff: 41.56mlTrain batch 31/31 - 9.7s 41.2ms/batch - loss: 198.05327 - diff: 41.56ml
Test 0.8s: val_loss: 187.42125 - diff: 40.90ml

Epoch 10: current best loss = 172.39719, at epoch 8
Train batch 1/31 - 80.5ms/batch - loss: 66.93776 - diff: 26.64mlTrain batch 2/31 - 77.5ms/batch - loss: 181.21325 - diff: 37.93mlTrain batch 3/31 - 78.7ms/batch - loss: 136.76717 - diff: 33.05mlTrain batch 4/31 - 78.0ms/batch - loss: 135.05891 - diff: 34.06mlTrain batch 5/31 - 79.1ms/batch - loss: 124.29790 - diff: 32.92mlTrain batch 6/31 - 78.1ms/batch - loss: 132.46516 - diff: 33.39mlTrain batch 7/31 - 77.4ms/batch - loss: 139.88752 - diff: 34.11mlTrain batch 8/31 - 77.7ms/batch - loss: 132.66167 - diff: 33.08mlTrain batch 9/31 - 77.7ms/batch - loss: 133.26396 - diff: 33.70mlTrain batch 10/31 - 78.0ms/batch - loss: 139.29609 - diff: 34.85mlTrain batch 11/31 - 77.4ms/batch - loss: 139.73953 - diff: 35.31mlTrain batch 12/31 - 77.4ms/batch - loss: 139.86696 - diff: 35.68mlTrain batch 13/31 - 78.4ms/batch - loss: 143.79174 - diff: 36.18mlTrain batch 14/31 - 78.4ms/batch - loss: 143.09359 - diff: 36.02mlTrain batch 15/31 - 78.4ms/batch - loss: 144.04974 - diff: 36.07mlTrain batch 16/31 - 80.5ms/batch - loss: 145.66697 - diff: 36.35mlTrain batch 17/31 - 78.6ms/batch - loss: 142.33040 - diff: 36.16mlTrain batch 18/31 - 81.6ms/batch - loss: 143.51583 - diff: 36.42mlTrain batch 19/31 - 77.5ms/batch - loss: 157.30145 - diff: 38.14mlTrain batch 20/31 - 79.8ms/batch - loss: 179.48555 - diff: 39.16mlTrain batch 21/31 - 77.9ms/batch - loss: 175.52850 - diff: 38.86mlTrain batch 22/31 - 79.2ms/batch - loss: 172.50261 - diff: 38.66mlTrain batch 23/31 - 77.8ms/batch - loss: 171.93608 - diff: 38.62mlTrain batch 24/31 - 81.0ms/batch - loss: 171.59729 - diff: 38.73mlTrain batch 25/31 - 78.0ms/batch - loss: 173.34495 - diff: 38.97mlTrain batch 26/31 - 79.3ms/batch - loss: 171.28787 - diff: 38.86mlTrain batch 27/31 - 77.8ms/batch - loss: 169.69327 - diff: 38.75mlTrain batch 28/31 - 77.6ms/batch - loss: 168.15453 - diff: 38.71mlTrain batch 29/31 - 77.6ms/batch - loss: 173.16222 - diff: 39.41mlTrain batch 30/31 - 79.1ms/batch - loss: 171.24556 - diff: 39.22mlTrain batch 31/31 - 41.4ms/batch - loss: 171.18924 - diff: 39.07mlTrain batch 31/31 - 9.7s 41.4ms/batch - loss: 171.18924 - diff: 39.07ml
Test 0.8s: val_loss: 148.57374 - diff: 36.91ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_DenseNet121_0_Adam-0.001_MSE_DA3_best

Epoch 11: current best loss = 148.57374, at epoch 10
Train batch 1/31 - 86.3ms/batch - loss: 41.27359 - diff: 18.82mlTrain batch 2/31 - 78.8ms/batch - loss: 128.36542 - diff: 32.16mlTrain batch 3/31 - 83.1ms/batch - loss: 157.88659 - diff: 38.06mlTrain batch 4/31 - 78.8ms/batch - loss: 145.70177 - diff: 37.15mlTrain batch 5/31 - 89.4ms/batch - loss: 143.80188 - diff: 37.01mlTrain batch 6/31 - 79.0ms/batch - loss: 160.66029 - diff: 38.51mlTrain batch 7/31 - 99.4ms/batch - loss: 157.26525 - diff: 38.58mlTrain batch 8/31 - 78.3ms/batch - loss: 155.83454 - diff: 38.54mlTrain batch 9/31 - 80.0ms/batch - loss: 154.74277 - diff: 38.79mlTrain batch 10/31 - 78.6ms/batch - loss: 144.84734 - diff: 37.39mlTrain batch 11/31 - 101.6ms/batch - loss: 148.19664 - diff: 37.78mlTrain batch 12/31 - 81.4ms/batch - loss: 183.86108 - diff: 38.82mlTrain batch 13/31 - 78.8ms/batch - loss: 183.10097 - diff: 39.11mlTrain batch 14/31 - 78.2ms/batch - loss: 191.03603 - diff: 39.68mlTrain batch 15/31 - 78.7ms/batch - loss: 193.28069 - diff: 39.83mlTrain batch 16/31 - 77.7ms/batch - loss: 190.48704 - diff: 39.54mlTrain batch 17/31 - 78.3ms/batch - loss: 183.98483 - diff: 38.76mlTrain batch 18/31 - 78.1ms/batch - loss: 180.74426 - diff: 38.65mlTrain batch 19/31 - 78.1ms/batch - loss: 177.78897 - diff: 38.36mlTrain batch 20/31 - 77.9ms/batch - loss: 177.52681 - diff: 38.47mlTrain batch 21/31 - 77.4ms/batch - loss: 174.01451 - diff: 38.11mlTrain batch 22/31 - 79.0ms/batch - loss: 172.55949 - diff: 37.99mlTrain batch 23/31 - 77.6ms/batch - loss: 173.93345 - diff: 38.22mlTrain batch 24/31 - 79.1ms/batch - loss: 171.55346 - diff: 38.10mlTrain batch 25/31 - 78.3ms/batch - loss: 172.51526 - diff: 38.34mlTrain batch 26/31 - 77.9ms/batch - loss: 169.99620 - diff: 38.21mlTrain batch 27/31 - 78.3ms/batch - loss: 175.03982 - diff: 38.71mlTrain batch 28/31 - 77.4ms/batch - loss: 173.24301 - diff: 38.66mlTrain batch 29/31 - 77.5ms/batch - loss: 170.35291 - diff: 38.37mlTrain batch 30/31 - 77.4ms/batch - loss: 169.48860 - diff: 38.18mlTrain batch 31/31 - 41.2ms/batch - loss: 170.42773 - diff: 38.12mlTrain batch 31/31 - 9.7s 41.2ms/batch - loss: 170.42773 - diff: 38.12ml
Test 0.8s: val_loss: 179.41023 - diff: 36.82ml

Epoch 12: current best loss = 148.57374, at epoch 10
Train batch 1/31 - 78.0ms/batch - loss: 154.74405 - diff: 37.54mlTrain batch 2/31 - 77.8ms/batch - loss: 146.25728 - diff: 36.98mlTrain batch 3/31 - 78.1ms/batch - loss: 141.81799 - diff: 37.27mlTrain batch 4/31 - 78.1ms/batch - loss: 132.35832 - diff: 36.30mlTrain batch 5/31 - 79.3ms/batch - loss: 157.54398 - diff: 39.33mlTrain batch 6/31 - 77.8ms/batch - loss: 140.94549 - diff: 37.05mlTrain batch 7/31 - 78.6ms/batch - loss: 137.63040 - diff: 36.97mlTrain batch 8/31 - 78.4ms/batch - loss: 138.65645 - diff: 37.20mlTrain batch 9/31 - 78.2ms/batch - loss: 141.29718 - diff: 38.16mlTrain batch 10/31 - 77.6ms/batch - loss: 134.17235 - diff: 37.00mlTrain batch 11/31 - 77.8ms/batch - loss: 140.10409 - diff: 37.87mlTrain batch 12/31 - 77.5ms/batch - loss: 136.66062 - diff: 37.59mlTrain batch 13/31 - 77.8ms/batch - loss: 134.15927 - diff: 37.44mlTrain batch 14/31 - 81.1ms/batch - loss: 176.19122 - diff: 39.30mlTrain batch 15/31 - 78.1ms/batch - loss: 172.98513 - diff: 39.18mlTrain batch 16/31 - 83.3ms/batch - loss: 168.76979 - diff: 38.83mlTrain batch 17/31 - 78.4ms/batch - loss: 166.40040 - diff: 38.64mlTrain batch 18/31 - 83.3ms/batch - loss: 161.14730 - diff: 37.88mlTrain batch 19/31 - 77.6ms/batch - loss: 164.98004 - diff: 38.60mlTrain batch 20/31 - 82.0ms/batch - loss: 165.85734 - diff: 38.86mlTrain batch 21/31 - 77.6ms/batch - loss: 163.67017 - diff: 38.83mlTrain batch 22/31 - 79.1ms/batch - loss: 160.62432 - diff: 38.54mlTrain batch 23/31 - 77.8ms/batch - loss: 170.08941 - diff: 39.28mlTrain batch 24/31 - 82.6ms/batch - loss: 168.80008 - diff: 39.16mlTrain batch 25/31 - 78.4ms/batch - loss: 167.64941 - diff: 39.15mlTrain batch 26/31 - 79.1ms/batch - loss: 171.98329 - diff: 39.64mlTrain batch 27/31 - 77.9ms/batch - loss: 169.24160 - diff: 39.40mlTrain batch 28/31 - 77.9ms/batch - loss: 165.90900 - diff: 38.95mlTrain batch 29/31 - 77.5ms/batch - loss: 166.25425 - diff: 39.08mlTrain batch 30/31 - 78.2ms/batch - loss: 165.19225 - diff: 39.04mlTrain batch 31/31 - 41.7ms/batch - loss: 171.36843 - diff: 39.22mlTrain batch 31/31 - 9.7s 41.7ms/batch - loss: 171.36843 - diff: 39.22ml
Test 0.8s: val_loss: 165.97817 - diff: 39.80ml

Epoch 13: current best loss = 148.57374, at epoch 10
Train batch 1/31 - 82.3ms/batch - loss: 147.88101 - diff: 35.98mlTrain batch 2/31 - 78.4ms/batch - loss: 125.46053 - diff: 33.66mlTrain batch 3/31 - 82.0ms/batch - loss: 117.02515 - diff: 32.90mlTrain batch 4/31 - 79.1ms/batch - loss: 144.18750 - diff: 35.21mlTrain batch 5/31 - 78.1ms/batch - loss: 153.67646 - diff: 37.93mlTrain batch 6/31 - 78.6ms/batch - loss: 150.47180 - diff: 37.87mlTrain batch 7/31 - 80.9ms/batch - loss: 158.27207 - diff: 38.31mlTrain batch 8/31 - 78.5ms/batch - loss: 157.06249 - diff: 37.60mlTrain batch 9/31 - 87.5ms/batch - loss: 152.32040 - diff: 37.24mlTrain batch 10/31 - 82.9ms/batch - loss: 149.67933 - diff: 36.09mlTrain batch 11/31 - 82.3ms/batch - loss: 140.67972 - diff: 34.79mlTrain batch 12/31 - 78.2ms/batch - loss: 140.66659 - diff: 35.35mlTrain batch 13/31 - 81.4ms/batch - loss: 139.61871 - diff: 35.34mlTrain batch 14/31 - 78.6ms/batch - loss: 167.39778 - diff: 36.77mlTrain batch 15/31 - 82.0ms/batch - loss: 160.84771 - diff: 36.08mlTrain batch 16/31 - 78.5ms/batch - loss: 161.48136 - diff: 36.43mlTrain batch 17/31 - 78.3ms/batch - loss: 163.26881 - diff: 36.90mlTrain batch 18/31 - 78.2ms/batch - loss: 169.17620 - diff: 37.76mlTrain batch 19/31 - 77.4ms/batch - loss: 166.46928 - diff: 37.76mlTrain batch 20/31 - 77.8ms/batch - loss: 169.70764 - diff: 38.08mlTrain batch 21/31 - 79.3ms/batch - loss: 172.58735 - diff: 38.63mlTrain batch 22/31 - 78.9ms/batch - loss: 168.83583 - diff: 38.39mlTrain batch 23/31 - 78.2ms/batch - loss: 172.19728 - diff: 38.93mlTrain batch 24/31 - 77.8ms/batch - loss: 170.28476 - diff: 38.74mlTrain batch 25/31 - 78.0ms/batch - loss: 168.76144 - diff: 38.69mlTrain batch 26/31 - 77.8ms/batch - loss: 166.50196 - diff: 38.40mlTrain batch 27/31 - 77.7ms/batch - loss: 164.28406 - diff: 38.24mlTrain batch 28/31 - 78.0ms/batch - loss: 167.26531 - diff: 38.42mlTrain batch 29/31 - 77.3ms/batch - loss: 168.72165 - diff: 38.62mlTrain batch 30/31 - 77.7ms/batch - loss: 166.02841 - diff: 38.42mlTrain batch 31/31 - 41.1ms/batch - loss: 169.36639 - diff: 38.41mlTrain batch 31/31 - 9.7s 41.1ms/batch - loss: 169.36639 - diff: 38.41ml
Test 0.8s: val_loss: 143.10377 - diff: 36.74ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_DenseNet121_0_Adam-0.001_MSE_DA3_best

Epoch 14: current best loss = 143.10377, at epoch 13
Train batch 1/31 - 77.7ms/batch - loss: 142.24144 - diff: 38.08mlTrain batch 2/31 - 77.5ms/batch - loss: 136.01104 - diff: 38.78mlTrain batch 3/31 - 78.8ms/batch - loss: 140.44209 - diff: 37.83mlTrain batch 4/31 - 78.8ms/batch - loss: 168.78339 - diff: 41.10mlTrain batch 5/31 - 79.5ms/batch - loss: 170.33915 - diff: 40.85mlTrain batch 6/31 - 78.3ms/batch - loss: 155.47157 - diff: 39.09mlTrain batch 7/31 - 83.0ms/batch - loss: 160.24306 - diff: 39.29mlTrain batch 8/31 - 85.1ms/batch - loss: 151.72421 - diff: 38.31mlTrain batch 9/31 - 78.3ms/batch - loss: 142.29464 - diff: 36.69mlTrain batch 10/31 - 77.8ms/batch - loss: 139.24819 - diff: 36.35mlTrain batch 11/31 - 78.6ms/batch - loss: 138.36706 - diff: 36.44mlTrain batch 12/31 - 77.9ms/batch - loss: 135.06041 - diff: 35.66mlTrain batch 13/31 - 78.9ms/batch - loss: 137.68679 - diff: 36.11mlTrain batch 14/31 - 78.3ms/batch - loss: 138.27963 - diff: 36.14mlTrain batch 15/31 - 77.5ms/batch - loss: 136.96383 - diff: 36.18mlTrain batch 16/31 - 78.1ms/batch - loss: 135.63810 - diff: 36.19mlTrain batch 17/31 - 78.0ms/batch - loss: 172.42879 - diff: 38.26mlTrain batch 18/31 - 78.1ms/batch - loss: 169.50436 - diff: 38.00mlTrain batch 19/31 - 79.7ms/batch - loss: 172.43711 - diff: 38.47mlTrain batch 20/31 - 77.8ms/batch - loss: 173.98703 - diff: 38.74mlTrain batch 21/31 - 79.5ms/batch - loss: 183.89196 - diff: 39.75mlTrain batch 22/31 - 77.4ms/batch - loss: 180.73677 - diff: 39.77mlTrain batch 23/31 - 77.4ms/batch - loss: 176.11422 - diff: 39.16mlTrain batch 24/31 - 77.5ms/batch - loss: 174.71667 - diff: 39.03mlTrain batch 25/31 - 77.8ms/batch - loss: 173.21009 - diff: 38.94mlTrain batch 26/31 - 79.0ms/batch - loss: 170.29682 - diff: 38.66mlTrain batch 27/31 - 78.6ms/batch - loss: 168.41542 - diff: 38.46mlTrain batch 28/31 - 78.7ms/batch - loss: 165.03866 - diff: 38.05mlTrain batch 29/31 - 77.4ms/batch - loss: 167.29514 - diff: 38.25mlTrain batch 30/31 - 77.9ms/batch - loss: 166.28237 - diff: 38.25mlTrain batch 31/31 - 41.2ms/batch - loss: 169.28442 - diff: 38.29mlTrain batch 31/31 - 9.7s 41.2ms/batch - loss: 169.28442 - diff: 38.29ml
Test 0.8s: val_loss: 171.25690 - diff: 37.50ml

Epoch 15: current best loss = 143.10377, at epoch 13
Train batch 1/31 - 78.4ms/batch - loss: 112.62257 - diff: 35.81mlTrain batch 2/31 - 78.3ms/batch - loss: 161.73775 - diff: 42.17mlTrain batch 3/31 - 78.5ms/batch - loss: 182.55405 - diff: 41.15mlTrain batch 4/31 - 78.4ms/batch - loss: 171.72286 - diff: 40.29mlTrain batch 5/31 - 78.1ms/batch - loss: 185.54040 - diff: 41.28mlTrain batch 6/31 - 77.8ms/batch - loss: 170.23735 - diff: 39.60mlTrain batch 7/31 - 89.1ms/batch - loss: 163.34983 - diff: 39.16mlTrain batch 8/31 - 81.7ms/batch - loss: 157.44192 - diff: 38.33mlTrain batch 9/31 - 78.1ms/batch - loss: 158.02175 - diff: 38.77mlTrain batch 10/31 - 77.7ms/batch - loss: 160.94919 - diff: 39.61mlTrain batch 11/31 - 79.3ms/batch - loss: 162.08764 - diff: 39.85mlTrain batch 12/31 - 78.4ms/batch - loss: 160.26788 - diff: 39.71mlTrain batch 13/31 - 79.6ms/batch - loss: 161.90911 - diff: 40.01mlTrain batch 14/31 - 78.5ms/batch - loss: 155.09712 - diff: 39.23mlTrain batch 15/31 - 78.3ms/batch - loss: 153.43255 - diff: 39.08mlTrain batch 16/31 - 77.8ms/batch - loss: 160.50443 - diff: 40.00mlTrain batch 17/31 - 78.6ms/batch - loss: 160.93940 - diff: 40.11mlTrain batch 18/31 - 78.0ms/batch - loss: 164.32236 - diff: 40.67mlTrain batch 19/31 - 78.6ms/batch - loss: 163.71418 - diff: 40.62mlTrain batch 20/31 - 77.5ms/batch - loss: 162.98098 - diff: 40.66mlTrain batch 21/31 - 78.0ms/batch - loss: 162.45885 - diff: 40.59mlTrain batch 22/31 - 77.4ms/batch - loss: 164.60515 - diff: 40.25mlTrain batch 23/31 - 77.8ms/batch - loss: 161.32189 - diff: 39.75mlTrain batch 24/31 - 77.9ms/batch - loss: 157.27457 - diff: 39.14mlTrain batch 25/31 - 77.9ms/batch - loss: 177.18548 - diff: 39.98mlTrain batch 26/31 - 77.8ms/batch - loss: 173.30611 - diff: 39.59mlTrain batch 27/31 - 77.7ms/batch - loss: 172.91737 - diff: 39.53mlTrain batch 28/31 - 79.0ms/batch - loss: 174.72017 - diff: 39.69mlTrain batch 29/31 - 78.3ms/batch - loss: 174.19515 - diff: 39.85mlTrain batch 30/31 - 78.2ms/batch - loss: 173.45051 - diff: 39.84mlTrain batch 31/31 - 41.6ms/batch - loss: 173.05079 - diff: 39.69mlTrain batch 31/31 - 9.7s 41.6ms/batch - loss: 173.05079 - diff: 39.69ml
Test 0.8s: val_loss: 151.34488 - diff: 38.44ml

Epoch 16: current best loss = 143.10377, at epoch 13
Train batch 1/31 - 77.5ms/batch - loss: 89.65926 - diff: 30.90mlTrain batch 2/31 - 77.4ms/batch - loss: 85.29372 - diff: 29.79mlTrain batch 3/31 - 77.8ms/batch - loss: 134.54189 - diff: 34.35mlTrain batch 4/31 - 77.3ms/batch - loss: 158.88147 - diff: 37.54mlTrain batch 5/31 - 77.8ms/batch - loss: 142.44392 - diff: 35.91mlTrain batch 6/31 - 77.7ms/batch - loss: 127.64075 - diff: 34.01mlTrain batch 7/31 - 77.6ms/batch - loss: 115.85378 - diff: 32.25mlTrain batch 8/31 - 78.4ms/batch - loss: 115.35194 - diff: 31.69mlTrain batch 9/31 - 77.9ms/batch - loss: 112.74337 - diff: 31.62mlTrain batch 10/31 - 77.7ms/batch - loss: 123.05158 - diff: 32.49mlTrain batch 11/31 - 78.4ms/batch - loss: 140.79536 - diff: 34.50mlTrain batch 12/31 - 78.2ms/batch - loss: 151.42545 - diff: 35.47mlTrain batch 13/31 - 77.9ms/batch - loss: 147.74552 - diff: 35.56mlTrain batch 14/31 - 78.4ms/batch - loss: 153.05327 - diff: 35.68mlTrain batch 15/31 - 77.6ms/batch - loss: 149.49018 - diff: 35.71mlTrain batch 16/31 - 77.5ms/batch - loss: 147.75041 - diff: 35.26mlTrain batch 17/31 - 77.8ms/batch - loss: 144.90232 - diff: 35.23mlTrain batch 18/31 - 77.8ms/batch - loss: 143.60271 - diff: 35.40mlTrain batch 19/31 - 77.8ms/batch - loss: 143.27357 - diff: 35.70mlTrain batch 20/31 - 78.2ms/batch - loss: 145.13650 - diff: 36.12mlTrain batch 21/31 - 78.3ms/batch - loss: 147.78911 - diff: 36.48mlTrain batch 22/31 - 78.1ms/batch - loss: 148.31764 - diff: 36.57mlTrain batch 23/31 - 79.2ms/batch - loss: 147.57288 - diff: 36.81mlTrain batch 24/31 - 78.8ms/batch - loss: 147.50813 - diff: 36.84mlTrain batch 25/31 - 79.5ms/batch - loss: 163.97563 - diff: 37.48mlTrain batch 26/31 - 79.1ms/batch - loss: 163.84419 - diff: 37.50mlTrain batch 27/31 - 79.3ms/batch - loss: 164.73953 - diff: 37.88mlTrain batch 28/31 - 79.0ms/batch - loss: 165.76048 - diff: 38.07mlTrain batch 29/31 - 78.1ms/batch - loss: 162.96439 - diff: 37.83mlTrain batch 30/31 - 78.7ms/batch - loss: 162.74594 - diff: 37.93mlTrain batch 31/31 - 41.6ms/batch - loss: 162.13923 - diff: 37.77mlTrain batch 31/31 - 9.7s 41.6ms/batch - loss: 162.13923 - diff: 37.77ml
Test 0.8s: val_loss: 200.57148 - diff: 46.00ml

Epoch 17: current best loss = 143.10377, at epoch 13
Train batch 1/31 - 79.3ms/batch - loss: 180.17947 - diff: 39.31mlTrain batch 2/31 - 78.5ms/batch - loss: 145.30013 - diff: 36.69mlTrain batch 3/31 - 79.1ms/batch - loss: 157.75410 - diff: 40.00mlTrain batch 4/31 - 78.4ms/batch - loss: 142.99417 - diff: 38.04mlTrain batch 5/31 - 78.2ms/batch - loss: 147.90700 - diff: 38.43mlTrain batch 6/31 - 79.0ms/batch - loss: 131.95870 - diff: 35.33mlTrain batch 7/31 - 78.7ms/batch - loss: 182.92096 - diff: 37.89mlTrain batch 8/31 - 78.6ms/batch - loss: 175.85939 - diff: 37.50mlTrain batch 9/31 - 78.0ms/batch - loss: 189.69488 - diff: 40.18mlTrain batch 10/31 - 82.9ms/batch - loss: 183.65894 - diff: 39.92mlTrain batch 11/31 - 77.9ms/batch - loss: 188.43434 - diff: 41.02mlTrain batch 12/31 - 79.1ms/batch - loss: 186.80092 - diff: 40.34mlTrain batch 13/31 - 78.2ms/batch - loss: 191.33346 - diff: 40.59mlTrain batch 14/31 - 81.3ms/batch - loss: 185.92672 - diff: 39.95mlTrain batch 15/31 - 78.3ms/batch - loss: 181.21614 - diff: 39.73mlTrain batch 16/31 - 79.8ms/batch - loss: 174.70747 - diff: 39.19mlTrain batch 17/31 - 77.4ms/batch - loss: 170.75730 - diff: 38.80mlTrain batch 18/31 - 78.8ms/batch - loss: 168.16219 - diff: 38.45mlTrain batch 19/31 - 79.8ms/batch - loss: 163.55384 - diff: 37.87mlTrain batch 20/31 - 78.5ms/batch - loss: 161.56725 - diff: 37.66mlTrain batch 21/31 - 77.8ms/batch - loss: 163.70643 - diff: 37.75mlTrain batch 22/31 - 78.1ms/batch - loss: 165.07981 - diff: 37.98mlTrain batch 23/31 - 78.0ms/batch - loss: 162.74076 - diff: 37.88mlTrain batch 24/31 - 77.5ms/batch - loss: 160.89915 - diff: 37.73mlTrain batch 25/31 - 78.5ms/batch - loss: 165.67833 - diff: 38.15mlTrain batch 26/31 - 77.7ms/batch - loss: 165.26048 - diff: 38.09mlTrain batch 27/31 - 78.1ms/batch - loss: 167.27779 - diff: 38.46mlTrain batch 28/31 - 77.7ms/batch - loss: 164.27302 - diff: 38.07mlTrain batch 29/31 - 78.4ms/batch - loss: 161.61058 - diff: 37.80mlTrain batch 30/31 - 77.6ms/batch - loss: 164.01086 - diff: 38.05mlTrain batch 31/31 - 41.2ms/batch - loss: 163.38152 - diff: 37.88mlTrain batch 31/31 - 9.7s 41.2ms/batch - loss: 163.38152 - diff: 37.88ml
Test 0.8s: val_loss: 214.06567 - diff: 42.69ml

Epoch 18: current best loss = 143.10377, at epoch 13
Train batch 1/31 - 80.6ms/batch - loss: 75.10966 - diff: 27.07mlTrain batch 2/31 - 78.4ms/batch - loss: 106.92530 - diff: 31.16mlTrain batch 3/31 - 82.1ms/batch - loss: 106.85459 - diff: 32.72mlTrain batch 4/31 - 79.1ms/batch - loss: 107.56886 - diff: 32.81mlTrain batch 5/31 - 117.1ms/batch - loss: 122.05768 - diff: 34.14mlTrain batch 6/31 - 86.7ms/batch - loss: 116.15578 - diff: 33.13mlTrain batch 7/31 - 80.0ms/batch - loss: 114.23325 - diff: 32.52mlTrain batch 8/31 - 77.7ms/batch - loss: 123.11666 - diff: 33.86mlTrain batch 9/31 - 80.1ms/batch - loss: 136.01526 - diff: 35.99mlTrain batch 10/31 - 77.8ms/batch - loss: 135.75384 - diff: 36.23mlTrain batch 11/31 - 80.3ms/batch - loss: 143.12464 - diff: 37.20mlTrain batch 12/31 - 77.9ms/batch - loss: 162.19895 - diff: 38.23mlTrain batch 13/31 - 81.5ms/batch - loss: 160.30364 - diff: 37.77mlTrain batch 14/31 - 78.4ms/batch - loss: 155.01498 - diff: 37.11mlTrain batch 15/31 - 82.4ms/batch - loss: 151.05517 - diff: 36.92mlTrain batch 16/31 - 78.7ms/batch - loss: 150.02363 - diff: 36.69mlTrain batch 17/31 - 81.9ms/batch - loss: 148.35609 - diff: 36.36mlTrain batch 18/31 - 78.7ms/batch - loss: 149.64953 - diff: 36.75mlTrain batch 19/31 - 78.9ms/batch - loss: 171.98821 - diff: 37.48mlTrain batch 20/31 - 77.5ms/batch - loss: 167.27832 - diff: 37.17mlTrain batch 21/31 - 81.1ms/batch - loss: 164.16880 - diff: 36.88mlTrain batch 22/31 - 78.6ms/batch - loss: 163.23281 - diff: 36.81mlTrain batch 23/31 - 79.1ms/batch - loss: 165.54591 - diff: 37.35mlTrain batch 24/31 - 78.4ms/batch - loss: 163.23875 - diff: 36.92mlTrain batch 25/31 - 81.0ms/batch - loss: 158.43820 - diff: 36.32mlTrain batch 26/31 - 78.3ms/batch - loss: 156.72587 - diff: 36.28mlTrain batch 27/31 - 79.7ms/batch - loss: 155.59841 - diff: 36.23mlTrain batch 28/31 - 78.6ms/batch - loss: 152.82312 - diff: 35.97mlTrain batch 29/31 - 81.9ms/batch - loss: 151.95912 - diff: 36.07mlTrain batch 30/31 - 78.0ms/batch - loss: 153.31198 - diff: 36.33mlTrain batch 31/31 - 41.6ms/batch - loss: 160.60153 - diff: 36.67mlTrain batch 31/31 - 9.7s 41.6ms/batch - loss: 160.60153 - diff: 36.67ml
Test 0.8s: val_loss: 167.79545 - diff: 41.42ml

Epoch 19: current best loss = 143.10377, at epoch 13
Train batch 1/31 - 78.9ms/batch - loss: 227.08707 - diff: 41.14mlTrain batch 2/31 - 78.6ms/batch - loss: 187.23441 - diff: 41.72mlTrain batch 3/31 - 77.7ms/batch - loss: 163.58490 - diff: 39.52mlTrain batch 4/31 - 77.8ms/batch - loss: 136.71438 - diff: 35.90mlTrain batch 5/31 - 77.5ms/batch - loss: 143.25651 - diff: 37.40mlTrain batch 6/31 - 78.1ms/batch - loss: 140.88188 - diff: 37.41mlTrain batch 7/31 - 77.7ms/batch - loss: 139.44828 - diff: 36.89mlTrain batch 8/31 - 78.4ms/batch - loss: 156.60104 - diff: 38.45mlTrain batch 9/31 - 77.5ms/batch - loss: 160.38104 - diff: 38.35mlTrain batch 10/31 - 77.6ms/batch - loss: 155.66806 - diff: 37.71mlTrain batch 11/31 - 77.5ms/batch - loss: 153.63040 - diff: 37.78mlTrain batch 12/31 - 78.0ms/batch - loss: 156.14204 - diff: 38.58mlTrain batch 13/31 - 77.5ms/batch - loss: 162.50362 - diff: 39.28mlTrain batch 14/31 - 78.5ms/batch - loss: 159.62616 - diff: 38.96mlTrain batch 15/31 - 77.8ms/batch - loss: 171.17198 - diff: 39.85mlTrain batch 16/31 - 77.9ms/batch - loss: 191.49243 - diff: 41.44mlTrain batch 17/31 - 77.5ms/batch - loss: 185.21643 - diff: 40.86mlTrain batch 18/31 - 78.1ms/batch - loss: 184.63601 - diff: 40.66mlTrain batch 19/31 - 78.0ms/batch - loss: 185.32597 - diff: 40.59mlTrain batch 20/31 - 78.7ms/batch - loss: 179.83660 - diff: 40.02mlTrain batch 21/31 - 77.8ms/batch - loss: 178.00981 - diff: 40.10mlTrain batch 22/31 - 77.7ms/batch - loss: 178.17063 - diff: 40.22mlTrain batch 23/31 - 77.4ms/batch - loss: 175.85261 - diff: 39.97mlTrain batch 24/31 - 79.2ms/batch - loss: 176.98320 - diff: 40.01mlTrain batch 25/31 - 77.8ms/batch - loss: 174.72263 - diff: 39.82mlTrain batch 26/31 - 78.2ms/batch - loss: 173.07370 - diff: 39.58mlTrain batch 27/31 - 77.9ms/batch - loss: 169.13365 - diff: 39.09mlTrain batch 28/31 - 78.1ms/batch - loss: 168.97674 - diff: 39.15mlTrain batch 29/31 - 77.5ms/batch - loss: 166.63353 - diff: 38.90mlTrain batch 30/31 - 77.7ms/batch - loss: 164.61694 - diff: 38.72mlTrain batch 31/31 - 43.0ms/batch - loss: 164.18080 - diff: 38.53mlTrain batch 31/31 - 9.7s 43.0ms/batch - loss: 164.18080 - diff: 38.53ml
Test 0.8s: val_loss: 152.02109 - diff: 38.75ml

Epoch 20: current best loss = 143.10377, at epoch 13
Train batch 1/31 - 79.3ms/batch - loss: 170.80797 - diff: 39.23mlTrain batch 2/31 - 78.7ms/batch - loss: 177.91618 - diff: 42.33mlTrain batch 3/31 - 79.5ms/batch - loss: 142.44799 - diff: 36.61mlTrain batch 4/31 - 85.6ms/batch - loss: 140.33876 - diff: 36.36mlTrain batch 5/31 - 79.4ms/batch - loss: 147.97066 - diff: 37.95mlTrain batch 6/31 - 79.9ms/batch - loss: 146.62260 - diff: 38.12mlTrain batch 7/31 - 78.3ms/batch - loss: 135.08576 - diff: 36.89mlTrain batch 8/31 - 78.2ms/batch - loss: 134.96201 - diff: 36.39mlTrain batch 9/31 - 79.5ms/batch - loss: 155.25142 - diff: 37.49mlTrain batch 10/31 - 78.0ms/batch - loss: 150.52224 - diff: 36.75mlTrain batch 11/31 - 83.9ms/batch - loss: 145.33909 - diff: 35.99mlTrain batch 12/31 - 78.2ms/batch - loss: 139.20915 - diff: 35.29mlTrain batch 13/31 - 78.3ms/batch - loss: 137.44091 - diff: 35.37mlTrain batch 14/31 - 77.7ms/batch - loss: 142.60886 - diff: 35.55mlTrain batch 15/31 - 78.5ms/batch - loss: 140.97116 - diff: 35.50mlTrain batch 16/31 - 78.2ms/batch - loss: 146.28438 - diff: 36.10mlTrain batch 17/31 - 79.0ms/batch - loss: 149.59449 - diff: 36.39mlTrain batch 18/31 - 77.9ms/batch - loss: 169.55846 - diff: 37.09mlTrain batch 19/31 - 78.0ms/batch - loss: 170.41672 - diff: 37.22mlTrain batch 20/31 - 77.8ms/batch - loss: 167.95506 - diff: 37.11mlTrain batch 21/31 - 82.0ms/batch - loss: 164.29616 - diff: 36.70mlTrain batch 22/31 - 77.8ms/batch - loss: 162.23891 - diff: 36.46mlTrain batch 23/31 - 81.1ms/batch - loss: 161.25958 - diff: 36.46mlTrain batch 24/31 - 78.1ms/batch - loss: 159.30560 - diff: 36.41mlTrain batch 25/31 - 80.4ms/batch - loss: 156.40985 - diff: 35.93mlTrain batch 26/31 - 78.5ms/batch - loss: 156.34097 - diff: 36.09mlTrain batch 27/31 - 81.5ms/batch - loss: 154.52314 - diff: 35.97mlTrain batch 28/31 - 78.4ms/batch - loss: 152.41088 - diff: 35.87mlTrain batch 29/31 - 82.0ms/batch - loss: 151.75817 - diff: 35.89mlTrain batch 30/31 - 77.6ms/batch - loss: 149.98586 - diff: 35.81mlTrain batch 31/31 - 41.3ms/batch - loss: 150.60700 - diff: 35.74mlTrain batch 31/31 - 9.7s 41.3ms/batch - loss: 150.60700 - diff: 35.74ml
Test 0.8s: val_loss: 154.79348 - diff: 39.41ml

Epoch 21: current best loss = 143.10377, at epoch 13
Train batch 1/31 - 80.2ms/batch - loss: 127.07678 - diff: 38.42mlTrain batch 2/31 - 78.0ms/batch - loss: 186.98827 - diff: 45.52mlTrain batch 3/31 - 87.2ms/batch - loss: 176.70491 - diff: 42.46mlTrain batch 4/31 - 79.7ms/batch - loss: 157.00322 - diff: 39.42mlTrain batch 5/31 - 77.6ms/batch - loss: 212.51807 - diff: 41.08mlTrain batch 6/31 - 77.5ms/batch - loss: 208.86979 - diff: 40.91mlTrain batch 7/31 - 78.5ms/batch - loss: 194.51231 - diff: 40.15mlTrain batch 8/31 - 77.6ms/batch - loss: 188.87969 - diff: 39.93mlTrain batch 9/31 - 77.8ms/batch - loss: 191.47567 - diff: 40.27mlTrain batch 10/31 - 78.3ms/batch - loss: 186.11936 - diff: 40.30mlTrain batch 11/31 - 78.1ms/batch - loss: 185.20984 - diff: 39.71mlTrain batch 12/31 - 78.0ms/batch - loss: 180.91463 - diff: 39.70mlTrain batch 13/31 - 78.3ms/batch - loss: 175.91679 - diff: 39.37mlTrain batch 14/31 - 78.3ms/batch - loss: 175.92434 - diff: 39.82mlTrain batch 15/31 - 78.6ms/batch - loss: 174.10138 - diff: 39.81mlTrain batch 16/31 - 78.5ms/batch - loss: 173.66593 - diff: 39.66mlTrain batch 17/31 - 77.8ms/batch - loss: 170.50926 - diff: 39.51mlTrain batch 18/31 - 77.3ms/batch - loss: 167.28823 - diff: 39.35mlTrain batch 19/31 - 77.9ms/batch - loss: 167.11593 - diff: 39.34mlTrain batch 20/31 - 77.8ms/batch - loss: 167.44305 - diff: 39.25mlTrain batch 21/31 - 77.8ms/batch - loss: 164.86885 - diff: 38.94mlTrain batch 22/31 - 77.8ms/batch - loss: 162.25768 - diff: 38.54mlTrain batch 23/31 - 78.4ms/batch - loss: 159.53567 - diff: 38.17mlTrain batch 24/31 - 78.4ms/batch - loss: 158.44862 - diff: 38.12mlTrain batch 25/31 - 79.0ms/batch - loss: 158.02181 - diff: 38.05mlTrain batch 26/31 - 78.5ms/batch - loss: 155.98924 - diff: 37.92mlTrain batch 27/31 - 78.2ms/batch - loss: 157.79616 - diff: 38.07mlTrain batch 28/31 - 77.7ms/batch - loss: 154.05216 - diff: 37.58mlTrain batch 29/31 - 77.9ms/batch - loss: 153.49701 - diff: 37.45mlTrain batch 30/31 - 77.7ms/batch - loss: 150.50586 - diff: 37.08mlTrain batch 31/31 - 41.4ms/batch - loss: 154.53468 - diff: 37.17mlTrain batch 31/31 - 9.7s 41.4ms/batch - loss: 154.53468 - diff: 37.17ml
Test 0.8s: val_loss: 141.24043 - diff: 35.66ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_DenseNet121_0_Adam-0.001_MSE_DA3_best

Epoch 22: current best loss = 141.24043, at epoch 21
Train batch 1/31 - 80.7ms/batch - loss: 93.65503 - diff: 28.53mlTrain batch 2/31 - 80.2ms/batch - loss: 106.77737 - diff: 29.78mlTrain batch 3/31 - 80.1ms/batch - loss: 127.14822 - diff: 33.49mlTrain batch 4/31 - 77.3ms/batch - loss: 140.55576 - diff: 35.43mlTrain batch 5/31 - 83.3ms/batch - loss: 144.61112 - diff: 36.56mlTrain batch 6/31 - 79.9ms/batch - loss: 137.89932 - diff: 36.29mlTrain batch 7/31 - 78.4ms/batch - loss: 150.03078 - diff: 37.31mlTrain batch 8/31 - 77.9ms/batch - loss: 158.02508 - diff: 38.83mlTrain batch 9/31 - 82.6ms/batch - loss: 154.49307 - diff: 38.66mlTrain batch 10/31 - 78.7ms/batch - loss: 147.91172 - diff: 37.68mlTrain batch 11/31 - 79.8ms/batch - loss: 142.75556 - diff: 37.02mlTrain batch 12/31 - 77.5ms/batch - loss: 142.84478 - diff: 36.94mlTrain batch 13/31 - 78.6ms/batch - loss: 140.36232 - diff: 36.81mlTrain batch 14/31 - 79.0ms/batch - loss: 144.40107 - diff: 37.50mlTrain batch 15/31 - 88.1ms/batch - loss: 142.63351 - diff: 37.22mlTrain batch 16/31 - 78.3ms/batch - loss: 148.68445 - diff: 37.63mlTrain batch 17/31 - 95.1ms/batch - loss: 150.25720 - diff: 37.69mlTrain batch 18/31 - 78.9ms/batch - loss: 150.18379 - diff: 37.54mlTrain batch 19/31 - 78.5ms/batch - loss: 148.16816 - diff: 37.32mlTrain batch 20/31 - 81.0ms/batch - loss: 151.82453 - diff: 37.93mlTrain batch 21/31 - 83.5ms/batch - loss: 148.90028 - diff: 37.66mlTrain batch 22/31 - 80.2ms/batch - loss: 159.11370 - diff: 38.24mlTrain batch 23/31 - 80.9ms/batch - loss: 156.88350 - diff: 37.98mlTrain batch 24/31 - 80.4ms/batch - loss: 153.04973 - diff: 37.57mlTrain batch 25/31 - 77.8ms/batch - loss: 173.93495 - diff: 38.73mlTrain batch 26/31 - 80.2ms/batch - loss: 171.40456 - diff: 38.45mlTrain batch 27/31 - 78.4ms/batch - loss: 168.47207 - diff: 38.28mlTrain batch 28/31 - 83.0ms/batch - loss: 167.29255 - diff: 38.13mlTrain batch 29/31 - 79.5ms/batch - loss: 164.17729 - diff: 37.82mlTrain batch 30/31 - 78.9ms/batch - loss: 161.22776 - diff: 37.47mlTrain batch 31/31 - 41.3ms/batch - loss: 161.20065 - diff: 37.32mlTrain batch 31/31 - 9.7s 41.3ms/batch - loss: 161.20065 - diff: 37.32ml
Test 0.8s: val_loss: 146.70067 - diff: 37.91ml

Epoch 23: current best loss = 141.24043, at epoch 21
Train batch 1/31 - 82.1ms/batch - loss: 77.90662 - diff: 29.24mlTrain batch 2/31 - 85.8ms/batch - loss: 76.62803 - diff: 28.12mlTrain batch 3/31 - 78.7ms/batch - loss: 73.78355 - diff: 28.42mlTrain batch 4/31 - 78.4ms/batch - loss: 93.39467 - diff: 31.62mlTrain batch 5/31 - 80.0ms/batch - loss: 96.75209 - diff: 32.03mlTrain batch 6/31 - 78.0ms/batch - loss: 105.86048 - diff: 33.18mlTrain batch 7/31 - 79.8ms/batch - loss: 106.80437 - diff: 33.01mlTrain batch 8/31 - 77.4ms/batch - loss: 108.54537 - diff: 33.36mlTrain batch 9/31 - 80.3ms/batch - loss: 109.56195 - diff: 34.06mlTrain batch 10/31 - 77.3ms/batch - loss: 107.23560 - diff: 34.04mlTrain batch 11/31 - 80.2ms/batch - loss: 103.18751 - diff: 33.44mlTrain batch 12/31 - 77.4ms/batch - loss: 107.62992 - diff: 33.94mlTrain batch 13/31 - 80.6ms/batch - loss: 111.65526 - diff: 34.39mlTrain batch 14/31 - 79.1ms/batch - loss: 107.02555 - diff: 33.61mlTrain batch 15/31 - 78.3ms/batch - loss: 108.31227 - diff: 33.73mlTrain batch 16/31 - 77.9ms/batch - loss: 109.97115 - diff: 34.02mlTrain batch 17/31 - 78.0ms/batch - loss: 117.03420 - diff: 35.06mlTrain batch 18/31 - 78.0ms/batch - loss: 115.26752 - diff: 34.80mlTrain batch 19/31 - 78.4ms/batch - loss: 115.70717 - diff: 34.73mlTrain batch 20/31 - 77.6ms/batch - loss: 116.20471 - diff: 34.65mlTrain batch 21/31 - 77.7ms/batch - loss: 119.25449 - diff: 34.62mlTrain batch 22/31 - 77.5ms/batch - loss: 126.64682 - diff: 34.99mlTrain batch 23/31 - 77.9ms/batch - loss: 128.31746 - diff: 35.40mlTrain batch 24/31 - 77.5ms/batch - loss: 128.81797 - diff: 35.44mlTrain batch 25/31 - 78.2ms/batch - loss: 133.47848 - diff: 35.83mlTrain batch 26/31 - 77.4ms/batch - loss: 138.87326 - diff: 36.21mlTrain batch 27/31 - 78.5ms/batch - loss: 135.34161 - diff: 35.70mlTrain batch 28/31 - 77.8ms/batch - loss: 137.23424 - diff: 35.99mlTrain batch 29/31 - 77.8ms/batch - loss: 140.34525 - diff: 36.36mlTrain batch 30/31 - 77.6ms/batch - loss: 141.59273 - diff: 36.61mlTrain batch 31/31 - 41.5ms/batch - loss: 170.50107 - diff: 36.89mlTrain batch 31/31 - 9.7s 41.5ms/batch - loss: 170.50107 - diff: 36.89ml
Test 0.8s: val_loss: 157.97865 - diff: 38.38ml

Epoch 24: current best loss = 141.24043, at epoch 21
Train batch 1/31 - 122.6ms/batch - loss: 241.24463 - diff: 48.71mlTrain batch 2/31 - 77.6ms/batch - loss: 222.59398 - diff: 48.67mlTrain batch 3/31 - 78.3ms/batch - loss: 182.15542 - diff: 42.17mlTrain batch 4/31 - 77.6ms/batch - loss: 174.75766 - diff: 39.82mlTrain batch 5/31 - 77.8ms/batch - loss: 166.99520 - diff: 39.58mlTrain batch 6/31 - 77.5ms/batch - loss: 152.88983 - diff: 37.97mlTrain batch 7/31 - 78.1ms/batch - loss: 197.46531 - diff: 40.97mlTrain batch 8/31 - 77.5ms/batch - loss: 184.39242 - diff: 39.19mlTrain batch 9/31 - 79.9ms/batch - loss: 177.68174 - diff: 38.77mlTrain batch 10/31 - 79.1ms/batch - loss: 181.70232 - diff: 40.12mlTrain batch 11/31 - 78.1ms/batch - loss: 175.30270 - diff: 39.60mlTrain batch 12/31 - 77.5ms/batch - loss: 167.84146 - diff: 38.91mlTrain batch 13/31 - 79.6ms/batch - loss: 162.05188 - diff: 38.44mlTrain batch 14/31 - 78.4ms/batch - loss: 151.84633 - diff: 36.77mlTrain batch 15/31 - 79.7ms/batch - loss: 158.15193 - diff: 37.73mlTrain batch 16/31 - 78.8ms/batch - loss: 159.75587 - diff: 37.61mlTrain batch 17/31 - 79.3ms/batch - loss: 158.70549 - diff: 37.68mlTrain batch 18/31 - 78.1ms/batch - loss: 162.22883 - diff: 38.39mlTrain batch 19/31 - 79.2ms/batch - loss: 160.82073 - diff: 38.12mlTrain batch 20/31 - 78.2ms/batch - loss: 160.77153 - diff: 38.23mlTrain batch 21/31 - 79.5ms/batch - loss: 162.25112 - diff: 38.65mlTrain batch 22/31 - 79.3ms/batch - loss: 160.83359 - diff: 38.67mlTrain batch 23/31 - 78.0ms/batch - loss: 160.33110 - diff: 38.75mlTrain batch 24/31 - 77.8ms/batch - loss: 158.43130 - diff: 38.40mlTrain batch 25/31 - 77.8ms/batch - loss: 155.08783 - diff: 38.08mlTrain batch 26/31 - 77.4ms/batch - loss: 152.93904 - diff: 37.78mlTrain batch 27/31 - 78.7ms/batch - loss: 151.78031 - diff: 37.70mlTrain batch 28/31 - 78.1ms/batch - loss: 150.67712 - diff: 37.53mlTrain batch 29/31 - 78.5ms/batch - loss: 148.52110 - diff: 37.15mlTrain batch 30/31 - 78.0ms/batch - loss: 148.62556 - diff: 37.18mlTrain batch 31/31 - 42.7ms/batch - loss: 152.78673 - diff: 37.19mlTrain batch 31/31 - 9.8s 42.7ms/batch - loss: 152.78673 - diff: 37.19ml
Test 0.8s: val_loss: 141.10804 - diff: 36.45ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_DenseNet121_0_Adam-0.001_MSE_DA3_best

Epoch 25: current best loss = 141.10804, at epoch 24
Train batch 1/31 - 78.0ms/batch - loss: 168.88779 - diff: 41.76mlTrain batch 2/31 - 77.8ms/batch - loss: 158.13092 - diff: 39.80mlTrain batch 3/31 - 77.8ms/batch - loss: 145.71285 - diff: 38.50mlTrain batch 4/31 - 77.8ms/batch - loss: 145.42090 - diff: 38.59mlTrain batch 5/31 - 78.3ms/batch - loss: 126.62961 - diff: 34.95mlTrain batch 6/31 - 77.7ms/batch - loss: 136.61906 - diff: 35.29mlTrain batch 7/31 - 77.8ms/batch - loss: 130.63533 - diff: 34.74mlTrain batch 8/31 - 77.9ms/batch - loss: 141.76368 - diff: 36.48mlTrain batch 9/31 - 77.9ms/batch - loss: 132.69321 - diff: 35.29mlTrain batch 10/31 - 77.7ms/batch - loss: 129.98899 - diff: 35.39mlTrain batch 11/31 - 78.4ms/batch - loss: 124.70304 - diff: 34.48mlTrain batch 12/31 - 78.5ms/batch - loss: 121.69602 - diff: 34.35mlTrain batch 13/31 - 78.2ms/batch - loss: 122.63329 - diff: 34.45mlTrain batch 14/31 - 78.5ms/batch - loss: 125.07048 - diff: 34.41mlTrain batch 15/31 - 77.8ms/batch - loss: 122.96447 - diff: 34.33mlTrain batch 16/31 - 78.3ms/batch - loss: 149.79110 - diff: 35.47mlTrain batch 17/31 - 77.4ms/batch - loss: 148.79856 - diff: 35.39mlTrain batch 18/31 - 77.4ms/batch - loss: 151.30109 - diff: 35.75mlTrain batch 19/31 - 77.3ms/batch - loss: 151.01059 - diff: 35.48mlTrain batch 20/31 - 78.0ms/batch - loss: 151.07991 - diff: 35.63mlTrain batch 21/31 - 77.5ms/batch - loss: 148.72380 - diff: 35.46mlTrain batch 22/31 - 77.8ms/batch - loss: 146.76487 - diff: 35.41mlTrain batch 23/31 - 77.6ms/batch - loss: 146.04930 - diff: 35.52mlTrain batch 24/31 - 78.0ms/batch - loss: 147.82780 - diff: 35.90mlTrain batch 25/31 - 77.8ms/batch - loss: 147.29048 - diff: 35.79mlTrain batch 26/31 - 78.0ms/batch - loss: 152.74930 - diff: 36.69mlTrain batch 27/31 - 77.7ms/batch - loss: 150.79802 - diff: 36.49mlTrain batch 28/31 - 78.3ms/batch - loss: 149.36695 - diff: 36.43mlTrain batch 29/31 - 77.8ms/batch - loss: 147.27725 - diff: 36.31mlTrain batch 30/31 - 77.7ms/batch - loss: 144.80988 - diff: 36.11mlTrain batch 31/31 - 41.7ms/batch - loss: 145.47487 - diff: 35.99mlTrain batch 31/31 - 9.8s 41.7ms/batch - loss: 145.47487 - diff: 35.99ml
Test 0.9s: val_loss: 128.44392 - diff: 34.98ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_DenseNet121_0_Adam-0.001_MSE_DA3_best

Epoch 26: current best loss = 128.44392, at epoch 25
Train batch 1/31 - 84.1ms/batch - loss: 221.71078 - diff: 47.40mlTrain batch 2/31 - 77.6ms/batch - loss: 168.94288 - diff: 39.42mlTrain batch 3/31 - 78.3ms/batch - loss: 139.38938 - diff: 36.34mlTrain batch 4/31 - 77.4ms/batch - loss: 148.48713 - diff: 37.88mlTrain batch 5/31 - 78.7ms/batch - loss: 146.83943 - diff: 37.80mlTrain batch 6/31 - 78.7ms/batch - loss: 135.84759 - diff: 35.87mlTrain batch 7/31 - 78.7ms/batch - loss: 140.37282 - diff: 36.18mlTrain batch 8/31 - 77.6ms/batch - loss: 135.03128 - diff: 35.98mlTrain batch 9/31 - 78.6ms/batch - loss: 133.42560 - diff: 35.92mlTrain batch 10/31 - 78.9ms/batch - loss: 124.71638 - diff: 34.41mlTrain batch 11/31 - 77.9ms/batch - loss: 137.22848 - diff: 35.22mlTrain batch 12/31 - 77.8ms/batch - loss: 136.93414 - diff: 35.13mlTrain batch 13/31 - 77.9ms/batch - loss: 134.38041 - diff: 34.68mlTrain batch 14/31 - 77.6ms/batch - loss: 132.97662 - diff: 34.64mlTrain batch 15/31 - 77.6ms/batch - loss: 134.35834 - diff: 34.95mlTrain batch 16/31 - 77.8ms/batch - loss: 132.50511 - diff: 34.82mlTrain batch 17/31 - 78.8ms/batch - loss: 133.02256 - diff: 35.09mlTrain batch 18/31 - 77.8ms/batch - loss: 130.61796 - diff: 34.72mlTrain batch 19/31 - 78.6ms/batch - loss: 132.50870 - diff: 35.07mlTrain batch 20/31 - 78.6ms/batch - loss: 130.24003 - diff: 34.81mlTrain batch 21/31 - 78.8ms/batch - loss: 162.22573 - diff: 36.76mlTrain batch 22/31 - 79.4ms/batch - loss: 158.42753 - diff: 36.41mlTrain batch 23/31 - 78.1ms/batch - loss: 158.50314 - diff: 36.42mlTrain batch 24/31 - 78.7ms/batch - loss: 156.90897 - diff: 36.45mlTrain batch 25/31 - 77.8ms/batch - loss: 153.86575 - diff: 36.23mlTrain batch 26/31 - 77.6ms/batch - loss: 155.64073 - diff: 36.60mlTrain batch 27/31 - 77.3ms/batch - loss: 153.40738 - diff: 36.35mlTrain batch 28/31 - 77.8ms/batch - loss: 150.12710 - diff: 36.04mlTrain batch 29/31 - 77.4ms/batch - loss: 148.09295 - diff: 35.81mlTrain batch 30/31 - 77.8ms/batch - loss: 149.82525 - diff: 35.92mlTrain batch 31/31 - 43.5ms/batch - loss: 152.76807 - diff: 36.04mlTrain batch 31/31 - 9.7s 43.5ms/batch - loss: 152.76807 - diff: 36.04ml
Test 0.9s: val_loss: 165.54825 - diff: 36.66ml

Epoch 27: current best loss = 128.44392, at epoch 25
Train batch 1/31 - 82.4ms/batch - loss: 319.43988 - diff: 53.32mlTrain batch 2/31 - 77.7ms/batch - loss: 264.27275 - diff: 49.15mlTrain batch 3/31 - 78.3ms/batch - loss: 204.13627 - diff: 42.60mlTrain batch 4/31 - 77.4ms/batch - loss: 178.17736 - diff: 39.35mlTrain batch 5/31 - 80.3ms/batch - loss: 164.13632 - diff: 37.92mlTrain batch 6/31 - 77.8ms/batch - loss: 171.17615 - diff: 38.89mlTrain batch 7/31 - 81.4ms/batch - loss: 163.76707 - diff: 37.83mlTrain batch 8/31 - 78.2ms/batch - loss: 148.64081 - diff: 35.71mlTrain batch 9/31 - 81.1ms/batch - loss: 137.61502 - diff: 34.56mlTrain batch 10/31 - 78.5ms/batch - loss: 149.54977 - diff: 35.34mlTrain batch 11/31 - 80.2ms/batch - loss: 143.92736 - diff: 34.69mlTrain batch 12/31 - 78.9ms/batch - loss: 146.75001 - diff: 35.42mlTrain batch 13/31 - 78.8ms/batch - loss: 142.13992 - diff: 35.26mlTrain batch 14/31 - 77.8ms/batch - loss: 162.43092 - diff: 36.16mlTrain batch 15/31 - 78.3ms/batch - loss: 159.68785 - diff: 36.03mlTrain batch 16/31 - 77.8ms/batch - loss: 161.00098 - diff: 36.45mlTrain batch 17/31 - 77.8ms/batch - loss: 162.12501 - diff: 36.84mlTrain batch 18/31 - 78.1ms/batch - loss: 157.29496 - diff: 36.29mlTrain batch 19/31 - 77.6ms/batch - loss: 158.73683 - diff: 36.61mlTrain batch 20/31 - 78.2ms/batch - loss: 156.90670 - diff: 36.65mlTrain batch 21/31 - 77.8ms/batch - loss: 155.44246 - diff: 36.77mlTrain batch 22/31 - 78.3ms/batch - loss: 152.99174 - diff: 36.47mlTrain batch 23/31 - 77.5ms/batch - loss: 150.83598 - diff: 36.22mlTrain batch 24/31 - 77.8ms/batch - loss: 152.02248 - diff: 36.49mlTrain batch 25/31 - 77.7ms/batch - loss: 148.49279 - diff: 36.13mlTrain batch 26/31 - 78.2ms/batch - loss: 152.28682 - diff: 36.51mlTrain batch 27/31 - 79.3ms/batch - loss: 153.30042 - diff: 36.81mlTrain batch 28/31 - 78.2ms/batch - loss: 151.92607 - diff: 36.86mlTrain batch 29/31 - 82.8ms/batch - loss: 149.92621 - diff: 36.83mlTrain batch 30/31 - 78.9ms/batch - loss: 148.40162 - diff: 36.76mlTrain batch 31/31 - 53.3ms/batch - loss: 147.90705 - diff: 36.47mlTrain batch 31/31 - 9.7s 53.3ms/batch - loss: 147.90705 - diff: 36.47ml
Test 0.8s: val_loss: 130.67322 - diff: 34.83ml

Epoch 28: current best loss = 128.44392, at epoch 25
Train batch 1/31 - 79.5ms/batch - loss: 535.34991 - diff: 47.99mlTrain batch 2/31 - 79.2ms/batch - loss: 391.29549 - diff: 48.32mlTrain batch 3/31 - 82.1ms/batch - loss: 348.67743 - diff: 49.40mlTrain batch 4/31 - 78.9ms/batch - loss: 303.70618 - diff: 47.22mlTrain batch 5/31 - 92.9ms/batch - loss: 262.19626 - diff: 43.50mlTrain batch 6/31 - 79.0ms/batch - loss: 254.40845 - diff: 43.54mlTrain batch 7/31 - 78.8ms/batch - loss: 233.16864 - diff: 41.98mlTrain batch 8/31 - 81.8ms/batch - loss: 223.91596 - diff: 42.04mlTrain batch 9/31 - 80.2ms/batch - loss: 211.97408 - diff: 41.48mlTrain batch 10/31 - 81.9ms/batch - loss: 195.04987 - diff: 39.60mlTrain batch 11/31 - 78.9ms/batch - loss: 183.61727 - diff: 38.69mlTrain batch 12/31 - 80.9ms/batch - loss: 186.67012 - diff: 39.04mlTrain batch 13/31 - 78.7ms/batch - loss: 188.13115 - diff: 39.32mlTrain batch 14/31 - 78.6ms/batch - loss: 182.72507 - diff: 38.81mlTrain batch 15/31 - 81.4ms/batch - loss: 176.09706 - diff: 38.39mlTrain batch 16/31 - 82.5ms/batch - loss: 172.31540 - diff: 38.45mlTrain batch 17/31 - 81.9ms/batch - loss: 170.11981 - diff: 38.26mlTrain batch 18/31 - 83.2ms/batch - loss: 165.31519 - diff: 37.74mlTrain batch 19/31 - 80.2ms/batch - loss: 163.84139 - diff: 37.57mlTrain batch 20/31 - 82.3ms/batch - loss: 160.92961 - diff: 37.41mlTrain batch 21/31 - 81.8ms/batch - loss: 155.95431 - diff: 36.83mlTrain batch 22/31 - 81.1ms/batch - loss: 151.33386 - diff: 36.13mlTrain batch 23/31 - 80.3ms/batch - loss: 151.76473 - diff: 36.44mlTrain batch 24/31 - 80.2ms/batch - loss: 148.37309 - diff: 36.04mlTrain batch 25/31 - 80.6ms/batch - loss: 146.92779 - diff: 36.03mlTrain batch 26/31 - 80.4ms/batch - loss: 143.62739 - diff: 35.66mlTrain batch 27/31 - 78.9ms/batch - loss: 140.47249 - diff: 35.27mlTrain batch 28/31 - 80.5ms/batch - loss: 142.10441 - diff: 35.38mlTrain batch 29/31 - 95.4ms/batch - loss: 140.83511 - diff: 35.18mlTrain batch 30/31 - 85.8ms/batch - loss: 141.54181 - diff: 35.34mlTrain batch 31/31 - 42.4ms/batch - loss: 142.40278 - diff: 35.19mlTrain batch 31/31 - 9.7s 42.4ms/batch - loss: 142.40278 - diff: 35.19ml
Test 0.8s: val_loss: 138.53343 - diff: 34.79ml

Epoch 29: current best loss = 128.44392, at epoch 25
Train batch 1/31 - 80.4ms/batch - loss: 172.77911 - diff: 37.80mlTrain batch 2/31 - 78.1ms/batch - loss: 165.38591 - diff: 41.24mlTrain batch 3/31 - 80.3ms/batch - loss: 151.27678 - diff: 39.59mlTrain batch 4/31 - 77.8ms/batch - loss: 246.91541 - diff: 41.87mlTrain batch 5/31 - 80.5ms/batch - loss: 214.44800 - diff: 40.25mlTrain batch 6/31 - 78.1ms/batch - loss: 200.86025 - diff: 39.42mlTrain batch 7/31 - 79.2ms/batch - loss: 189.11837 - diff: 38.86mlTrain batch 8/31 - 77.9ms/batch - loss: 178.90895 - diff: 37.90mlTrain batch 9/31 - 81.3ms/batch - loss: 166.24035 - diff: 36.57mlTrain batch 10/31 - 77.8ms/batch - loss: 154.91466 - diff: 34.94mlTrain batch 11/31 - 81.5ms/batch - loss: 153.73738 - diff: 35.15mlTrain batch 12/31 - 78.8ms/batch - loss: 151.29754 - diff: 34.91mlTrain batch 13/31 - 78.8ms/batch - loss: 148.67922 - diff: 34.90mlTrain batch 14/31 - 78.7ms/batch - loss: 148.28210 - diff: 35.43mlTrain batch 15/31 - 79.4ms/batch - loss: 144.52643 - diff: 34.95mlTrain batch 16/31 - 78.5ms/batch - loss: 147.47601 - diff: 35.14mlTrain batch 17/31 - 77.9ms/batch - loss: 150.70159 - diff: 35.70mlTrain batch 18/31 - 77.4ms/batch - loss: 151.74147 - diff: 35.94mlTrain batch 19/31 - 77.8ms/batch - loss: 157.66757 - diff: 36.69mlTrain batch 20/31 - 77.6ms/batch - loss: 157.18743 - diff: 36.77mlTrain batch 21/31 - 83.8ms/batch - loss: 154.68805 - diff: 36.37mlTrain batch 22/31 - 78.1ms/batch - loss: 149.46308 - diff: 35.66mlTrain batch 23/31 - 77.6ms/batch - loss: 147.17916 - diff: 35.45mlTrain batch 24/31 - 79.5ms/batch - loss: 146.32223 - diff: 35.52mlTrain batch 25/31 - 77.8ms/batch - loss: 145.59102 - diff: 35.52mlTrain batch 26/31 - 79.4ms/batch - loss: 142.37216 - diff: 35.18mlTrain batch 27/31 - 77.8ms/batch - loss: 138.91022 - diff: 34.68mlTrain batch 28/31 - 77.7ms/batch - loss: 137.47296 - diff: 34.58mlTrain batch 29/31 - 81.1ms/batch - loss: 138.82032 - diff: 34.84mlTrain batch 30/31 - 77.8ms/batch - loss: 140.41817 - diff: 34.93mlTrain batch 31/31 - 40.6ms/batch - loss: 140.75460 - diff: 34.79mlTrain batch 31/31 - 9.7s 40.6ms/batch - loss: 140.75460 - diff: 34.79ml
Test 0.8s: val_loss: 148.88088 - diff: 35.75ml

Epoch 30: current best loss = 128.44392, at epoch 25
Train batch 1/31 - 78.4ms/batch - loss: 51.68422 - diff: 19.39mlTrain batch 2/31 - 77.7ms/batch - loss: 71.76484 - diff: 24.63mlTrain batch 3/31 - 78.1ms/batch - loss: 84.87611 - diff: 27.48mlTrain batch 4/31 - 77.7ms/batch - loss: 101.46123 - diff: 30.46mlTrain batch 5/31 - 78.4ms/batch - loss: 110.75486 - diff: 32.12mlTrain batch 6/31 - 78.0ms/batch - loss: 104.00543 - diff: 31.19mlTrain batch 7/31 - 77.8ms/batch - loss: 106.47365 - diff: 31.95mlTrain batch 8/31 - 77.3ms/batch - loss: 107.39782 - diff: 31.93mlTrain batch 9/31 - 78.2ms/batch - loss: 105.91520 - diff: 32.17mlTrain batch 10/31 - 77.8ms/batch - loss: 116.58134 - diff: 33.65mlTrain batch 11/31 - 77.8ms/batch - loss: 113.95733 - diff: 33.33mlTrain batch 12/31 - 77.2ms/batch - loss: 114.44462 - diff: 33.45mlTrain batch 13/31 - 79.3ms/batch - loss: 118.83779 - diff: 33.79mlTrain batch 14/31 - 78.8ms/batch - loss: 114.66097 - diff: 33.26mlTrain batch 15/31 - 78.5ms/batch - loss: 115.06443 - diff: 33.65mlTrain batch 16/31 - 78.1ms/batch - loss: 111.68257 - diff: 33.20mlTrain batch 17/31 - 78.1ms/batch - loss: 117.83898 - diff: 33.77mlTrain batch 18/31 - 78.6ms/batch - loss: 124.16870 - diff: 34.65mlTrain batch 19/31 - 78.1ms/batch - loss: 125.29238 - diff: 34.89mlTrain batch 20/31 - 78.5ms/batch - loss: 121.05311 - diff: 34.21mlTrain batch 21/31 - 77.7ms/batch - loss: 119.54336 - diff: 34.12mlTrain batch 22/31 - 78.2ms/batch - loss: 119.15489 - diff: 33.96mlTrain batch 23/31 - 77.8ms/batch - loss: 118.00174 - diff: 33.62mlTrain batch 24/31 - 78.1ms/batch - loss: 133.71724 - diff: 34.64mlTrain batch 25/31 - 78.2ms/batch - loss: 133.19635 - diff: 34.67mlTrain batch 26/31 - 78.5ms/batch - loss: 129.60057 - diff: 34.16mlTrain batch 27/31 - 77.7ms/batch - loss: 130.78768 - diff: 34.31mlTrain batch 28/31 - 77.9ms/batch - loss: 131.18990 - diff: 34.54mlTrain batch 29/31 - 77.5ms/batch - loss: 128.67672 - diff: 34.25mlTrain batch 30/31 - 78.0ms/batch - loss: 126.64432 - diff: 34.05mlTrain batch 31/31 - 41.5ms/batch - loss: 127.70072 - diff: 33.99mlTrain batch 31/31 - 9.7s 41.5ms/batch - loss: 127.70072 - diff: 33.99ml
Test 0.8s: val_loss: 123.83988 - diff: 33.63ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_DenseNet121_0_Adam-0.001_MSE_DA3_best

Epoch 31: current best loss = 123.83988, at epoch 30
Train batch 1/31 - 79.2ms/batch - loss: 39.32460 - diff: 21.42mlTrain batch 2/31 - 80.7ms/batch - loss: 76.97333 - diff: 26.95mlTrain batch 3/31 - 82.4ms/batch - loss: 92.20279 - diff: 30.03mlTrain batch 4/31 - 80.5ms/batch - loss: 85.10999 - diff: 28.68mlTrain batch 5/31 - 82.2ms/batch - loss: 93.89343 - diff: 30.82mlTrain batch 6/31 - 80.5ms/batch - loss: 91.14590 - diff: 30.74mlTrain batch 7/31 - 82.3ms/batch - loss: 88.07660 - diff: 30.80mlTrain batch 8/31 - 88.4ms/batch - loss: 85.28762 - diff: 30.14mlTrain batch 9/31 - 83.0ms/batch - loss: 98.29865 - diff: 31.14mlTrain batch 10/31 - 81.3ms/batch - loss: 97.78624 - diff: 31.46mlTrain batch 11/31 - 80.1ms/batch - loss: 93.71187 - diff: 30.79mlTrain batch 12/31 - 79.8ms/batch - loss: 95.36920 - diff: 31.06mlTrain batch 13/31 - 80.1ms/batch - loss: 95.33551 - diff: 30.99mlTrain batch 14/31 - 82.6ms/batch - loss: 101.05646 - diff: 31.90mlTrain batch 15/31 - 77.9ms/batch - loss: 98.86908 - diff: 31.36mlTrain batch 16/31 - 79.8ms/batch - loss: 98.71212 - diff: 31.44mlTrain batch 17/31 - 77.8ms/batch - loss: 101.58670 - diff: 31.92mlTrain batch 18/31 - 81.9ms/batch - loss: 102.82777 - diff: 32.28mlTrain batch 19/31 - 77.9ms/batch - loss: 103.53338 - diff: 32.31mlTrain batch 20/31 - 79.3ms/batch - loss: 102.58832 - diff: 32.08mlTrain batch 21/31 - 78.1ms/batch - loss: 99.83677 - diff: 31.60mlTrain batch 22/31 - 78.7ms/batch - loss: 100.65874 - diff: 31.76mlTrain batch 23/31 - 78.4ms/batch - loss: 102.92936 - diff: 32.06mlTrain batch 24/31 - 80.0ms/batch - loss: 100.05756 - diff: 31.60mlTrain batch 25/31 - 77.7ms/batch - loss: 110.07988 - diff: 32.73mlTrain batch 26/31 - 80.5ms/batch - loss: 111.85420 - diff: 32.90mlTrain batch 27/31 - 99.7ms/batch - loss: 111.39318 - diff: 32.82mlTrain batch 28/31 - 82.5ms/batch - loss: 110.73537 - diff: 32.84mlTrain batch 29/31 - 79.5ms/batch - loss: 109.74999 - diff: 32.81mlTrain batch 30/31 - 77.6ms/batch - loss: 111.03886 - diff: 32.93mlTrain batch 31/31 - 41.7ms/batch - loss: 140.23585 - diff: 33.66mlTrain batch 31/31 - 9.8s 41.7ms/batch - loss: 140.23585 - diff: 33.66ml
Test 0.8s: val_loss: 125.31616 - diff: 33.73ml

Epoch 32: current best loss = 123.83988, at epoch 30
Train batch 1/31 - 79.6ms/batch - loss: 70.62215 - diff: 27.53mlTrain batch 2/31 - 79.0ms/batch - loss: 138.59941 - diff: 36.78mlTrain batch 3/31 - 78.2ms/batch - loss: 164.23639 - diff: 39.07mlTrain batch 4/31 - 79.2ms/batch - loss: 150.41329 - diff: 37.17mlTrain batch 5/31 - 81.1ms/batch - loss: 144.76136 - diff: 36.71mlTrain batch 6/31 - 77.8ms/batch - loss: 142.98713 - diff: 36.39mlTrain batch 7/31 - 80.6ms/batch - loss: 137.40123 - diff: 35.48mlTrain batch 8/31 - 78.3ms/batch - loss: 132.45885 - diff: 35.49mlTrain batch 9/31 - 81.2ms/batch - loss: 140.84642 - diff: 36.15mlTrain batch 10/31 - 78.3ms/batch - loss: 135.25933 - diff: 35.56mlTrain batch 11/31 - 78.7ms/batch - loss: 136.68706 - diff: 36.11mlTrain batch 12/31 - 78.2ms/batch - loss: 137.96755 - diff: 36.26mlTrain batch 13/31 - 81.0ms/batch - loss: 132.21763 - diff: 35.47mlTrain batch 14/31 - 78.1ms/batch - loss: 139.91051 - diff: 36.74mlTrain batch 15/31 - 82.2ms/batch - loss: 139.49102 - diff: 36.76mlTrain batch 16/31 - 78.4ms/batch - loss: 142.14054 - diff: 37.31mlTrain batch 17/31 - 80.5ms/batch - loss: 142.50746 - diff: 37.21mlTrain batch 18/31 - 78.3ms/batch - loss: 137.48065 - diff: 36.46mlTrain batch 19/31 - 80.5ms/batch - loss: 137.06791 - diff: 36.16mlTrain batch 20/31 - 78.1ms/batch - loss: 139.25769 - diff: 36.26mlTrain batch 21/31 - 81.1ms/batch - loss: 140.42800 - diff: 36.52mlTrain batch 22/31 - 77.9ms/batch - loss: 139.00435 - diff: 36.57mlTrain batch 23/31 - 81.3ms/batch - loss: 140.26602 - diff: 36.79mlTrain batch 24/31 - 78.2ms/batch - loss: 141.99479 - diff: 37.04mlTrain batch 25/31 - 78.5ms/batch - loss: 141.74278 - diff: 36.96mlTrain batch 26/31 - 78.1ms/batch - loss: 140.09190 - diff: 36.76mlTrain batch 27/31 - 79.5ms/batch - loss: 137.27490 - diff: 36.36mlTrain batch 28/31 - 78.4ms/batch - loss: 135.98190 - diff: 36.28mlTrain batch 29/31 - 79.2ms/batch - loss: 148.52350 - diff: 36.79mlTrain batch 30/31 - 78.2ms/batch - loss: 148.60718 - diff: 36.87mlTrain batch 31/31 - 41.5ms/batch - loss: 149.93813 - diff: 36.84mlTrain batch 31/31 - 9.7s 41.5ms/batch - loss: 149.93813 - diff: 36.84ml
Test 0.8s: val_loss: 140.30033 - diff: 35.24ml

Epoch 33: current best loss = 123.83988, at epoch 30
Train batch 1/31 - 79.6ms/batch - loss: 152.15741 - diff: 40.50mlTrain batch 2/31 - 78.5ms/batch - loss: 131.45271 - diff: 36.98mlTrain batch 3/31 - 78.4ms/batch - loss: 112.07394 - diff: 34.29mlTrain batch 4/31 - 77.9ms/batch - loss: 158.24696 - diff: 38.14mlTrain batch 5/31 - 81.2ms/batch - loss: 148.45978 - diff: 37.80mlTrain batch 6/31 - 77.7ms/batch - loss: 139.64482 - diff: 36.52mlTrain batch 7/31 - 79.4ms/batch - loss: 135.11727 - diff: 36.20mlTrain batch 8/31 - 79.1ms/batch - loss: 132.43399 - diff: 35.61mlTrain batch 9/31 - 79.1ms/batch - loss: 128.66445 - diff: 35.47mlTrain batch 10/31 - 78.5ms/batch - loss: 121.72408 - diff: 33.96mlTrain batch 11/31 - 78.4ms/batch - loss: 121.38866 - diff: 34.32mlTrain batch 12/31 - 78.1ms/batch - loss: 118.92159 - diff: 34.46mlTrain batch 13/31 - 77.5ms/batch - loss: 117.27643 - diff: 34.41mlTrain batch 14/31 - 77.7ms/batch - loss: 116.76177 - diff: 34.04mlTrain batch 15/31 - 77.5ms/batch - loss: 117.78204 - diff: 34.15mlTrain batch 16/31 - 77.6ms/batch - loss: 119.63193 - diff: 34.51mlTrain batch 17/31 - 77.7ms/batch - loss: 116.95565 - diff: 34.02mlTrain batch 18/31 - 78.1ms/batch - loss: 115.56870 - diff: 34.02mlTrain batch 19/31 - 77.7ms/batch - loss: 113.42214 - diff: 33.77mlTrain batch 20/31 - 77.9ms/batch - loss: 114.03358 - diff: 33.78mlTrain batch 21/31 - 77.9ms/batch - loss: 112.95643 - diff: 33.37mlTrain batch 22/31 - 77.8ms/batch - loss: 112.74892 - diff: 33.57mlTrain batch 23/31 - 77.6ms/batch - loss: 132.94170 - diff: 34.87mlTrain batch 24/31 - 78.1ms/batch - loss: 130.23983 - diff: 34.55mlTrain batch 25/31 - 84.9ms/batch - loss: 133.17067 - diff: 34.61mlTrain batch 26/31 - 84.5ms/batch - loss: 135.17543 - diff: 35.09mlTrain batch 27/31 - 79.0ms/batch - loss: 133.62758 - diff: 34.94mlTrain batch 28/31 - 78.4ms/batch - loss: 131.87635 - diff: 34.67mlTrain batch 29/31 - 77.9ms/batch - loss: 130.72819 - diff: 34.62mlTrain batch 30/31 - 78.5ms/batch - loss: 127.54709 - diff: 34.12mlTrain batch 31/31 - 41.9ms/batch - loss: 129.69923 - diff: 34.19mlTrain batch 31/31 - 9.8s 41.9ms/batch - loss: 129.69923 - diff: 34.19ml
Test 0.8s: val_loss: 129.26109 - diff: 34.65ml

Epoch 34: current best loss = 123.83988, at epoch 30
Train batch 1/31 - 81.6ms/batch - loss: 94.71925 - diff: 30.58mlTrain batch 2/31 - 78.4ms/batch - loss: 74.51254 - diff: 27.63mlTrain batch 3/31 - 85.3ms/batch - loss: 74.51680 - diff: 27.00mlTrain batch 4/31 - 78.6ms/batch - loss: 79.04728 - diff: 27.70mlTrain batch 5/31 - 104.0ms/batch - loss: 74.05946 - diff: 27.38mlTrain batch 6/31 - 77.3ms/batch - loss: 79.66168 - diff: 28.45mlTrain batch 7/31 - 94.5ms/batch - loss: 82.43716 - diff: 28.18mlTrain batch 8/31 - 79.2ms/batch - loss: 80.46255 - diff: 28.19mlTrain batch 9/31 - 80.9ms/batch - loss: 88.13731 - diff: 29.16mlTrain batch 10/31 - 80.7ms/batch - loss: 91.83791 - diff: 30.12mlTrain batch 11/31 - 85.5ms/batch - loss: 91.18952 - diff: 30.15mlTrain batch 12/31 - 77.6ms/batch - loss: 88.33635 - diff: 29.76mlTrain batch 13/31 - 78.1ms/batch - loss: 88.88156 - diff: 29.75mlTrain batch 14/31 - 81.5ms/batch - loss: 122.49297 - diff: 31.75mlTrain batch 15/31 - 80.1ms/batch - loss: 122.53063 - diff: 31.88mlTrain batch 16/31 - 80.6ms/batch - loss: 121.38784 - diff: 32.12mlTrain batch 17/31 - 78.7ms/batch - loss: 125.44968 - diff: 33.01mlTrain batch 18/31 - 81.1ms/batch - loss: 130.22570 - diff: 33.72mlTrain batch 19/31 - 79.2ms/batch - loss: 131.18859 - diff: 33.92mlTrain batch 20/31 - 81.3ms/batch - loss: 128.99534 - diff: 33.51mlTrain batch 21/31 - 81.7ms/batch - loss: 129.41077 - diff: 33.52mlTrain batch 22/31 - 81.2ms/batch - loss: 130.93460 - diff: 33.88mlTrain batch 23/31 - 79.3ms/batch - loss: 129.54955 - diff: 33.82mlTrain batch 24/31 - 80.6ms/batch - loss: 128.04572 - diff: 33.73mlTrain batch 25/31 - 86.1ms/batch - loss: 125.53362 - diff: 33.45mlTrain batch 26/31 - 87.5ms/batch - loss: 124.38197 - diff: 33.40mlTrain batch 27/31 - 77.5ms/batch - loss: 124.07328 - diff: 33.46mlTrain batch 28/31 - 78.7ms/batch - loss: 127.71073 - diff: 34.13mlTrain batch 29/31 - 79.4ms/batch - loss: 126.25353 - diff: 33.93mlTrain batch 30/31 - 77.8ms/batch - loss: 127.40592 - diff: 34.16mlTrain batch 31/31 - 41.7ms/batch - loss: 130.89781 - diff: 34.10mlTrain batch 31/31 - 9.7s 41.7ms/batch - loss: 130.89781 - diff: 34.10ml
Test 0.8s: val_loss: 110.11006 - diff: 32.32ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_DenseNet121_0_Adam-0.001_MSE_DA3_best

Epoch 35: current best loss = 110.11006, at epoch 34
Train batch 1/31 - 78.9ms/batch - loss: 103.08769 - diff: 33.87mlTrain batch 2/31 - 77.4ms/batch - loss: 96.63684 - diff: 32.34mlTrain batch 3/31 - 80.5ms/batch - loss: 172.60726 - diff: 40.05mlTrain batch 4/31 - 78.2ms/batch - loss: 153.28547 - diff: 37.71mlTrain batch 5/31 - 80.7ms/batch - loss: 152.07810 - diff: 36.48mlTrain batch 6/31 - 77.8ms/batch - loss: 155.85607 - diff: 36.81mlTrain batch 7/31 - 78.6ms/batch - loss: 144.76617 - diff: 35.29mlTrain batch 8/31 - 78.2ms/batch - loss: 136.42140 - diff: 34.71mlTrain batch 9/31 - 78.0ms/batch - loss: 129.34876 - diff: 33.99mlTrain batch 10/31 - 77.6ms/batch - loss: 124.20280 - diff: 33.03mlTrain batch 11/31 - 78.6ms/batch - loss: 123.75511 - diff: 32.88mlTrain batch 12/31 - 78.2ms/batch - loss: 118.76121 - diff: 32.13mlTrain batch 13/31 - 78.7ms/batch - loss: 122.14712 - diff: 32.74mlTrain batch 14/31 - 78.3ms/batch - loss: 116.80723 - diff: 32.16mlTrain batch 15/31 - 78.5ms/batch - loss: 118.15241 - diff: 32.53mlTrain batch 16/31 - 78.3ms/batch - loss: 123.79628 - diff: 32.99mlTrain batch 17/31 - 77.7ms/batch - loss: 154.60562 - diff: 34.97mlTrain batch 18/31 - 77.8ms/batch - loss: 157.38123 - diff: 35.51mlTrain batch 19/31 - 77.8ms/batch - loss: 153.78583 - diff: 35.28mlTrain batch 20/31 - 77.7ms/batch - loss: 152.51208 - diff: 35.25mlTrain batch 21/31 - 80.1ms/batch - loss: 148.48693 - diff: 34.85mlTrain batch 22/31 - 78.5ms/batch - loss: 150.06075 - diff: 35.26mlTrain batch 23/31 - 77.7ms/batch - loss: 148.40713 - diff: 35.18mlTrain batch 24/31 - 78.9ms/batch - loss: 147.28733 - diff: 35.40mlTrain batch 25/31 - 78.3ms/batch - loss: 146.05808 - diff: 35.47mlTrain batch 26/31 - 77.6ms/batch - loss: 144.58068 - diff: 35.18mlTrain batch 27/31 - 91.5ms/batch - loss: 143.35680 - diff: 35.02mlTrain batch 28/31 - 77.8ms/batch - loss: 141.28849 - diff: 34.77mlTrain batch 29/31 - 83.6ms/batch - loss: 140.16869 - diff: 34.66mlTrain batch 30/31 - 78.1ms/batch - loss: 138.87243 - diff: 34.43mlTrain batch 31/31 - 41.8ms/batch - loss: 141.15201 - diff: 34.56mlTrain batch 31/31 - 9.7s 41.8ms/batch - loss: 141.15201 - diff: 34.56ml
Test 0.8s: val_loss: 152.43707 - diff: 36.70ml

Epoch 36: current best loss = 110.11006, at epoch 34
Train batch 1/31 - 78.7ms/batch - loss: 196.00473 - diff: 43.41mlTrain batch 2/31 - 82.5ms/batch - loss: 164.36588 - diff: 41.57mlTrain batch 3/31 - 81.1ms/batch - loss: 150.90660 - diff: 39.06mlTrain batch 4/31 - 78.4ms/batch - loss: 135.40948 - diff: 37.03mlTrain batch 5/31 - 78.8ms/batch - loss: 128.15089 - diff: 36.03mlTrain batch 6/31 - 81.1ms/batch - loss: 126.43505 - diff: 35.86mlTrain batch 7/31 - 78.1ms/batch - loss: 119.66524 - diff: 34.62mlTrain batch 8/31 - 78.1ms/batch - loss: 113.58379 - diff: 33.90mlTrain batch 9/31 - 78.4ms/batch - loss: 109.00944 - diff: 33.08mlTrain batch 10/31 - 80.0ms/batch - loss: 105.41468 - diff: 32.36mlTrain batch 11/31 - 78.1ms/batch - loss: 109.61405 - diff: 32.71mlTrain batch 12/31 - 80.7ms/batch - loss: 107.78660 - diff: 32.17mlTrain batch 13/31 - 78.9ms/batch - loss: 140.41818 - diff: 33.85mlTrain batch 14/31 - 81.9ms/batch - loss: 139.08855 - diff: 33.39mlTrain batch 15/31 - 81.7ms/batch - loss: 137.54333 - diff: 33.53mlTrain batch 16/31 - 78.5ms/batch - loss: 135.05203 - diff: 33.38mlTrain batch 17/31 - 81.1ms/batch - loss: 135.66020 - diff: 33.80mlTrain batch 18/31 - 82.1ms/batch - loss: 130.37253 - diff: 33.12mlTrain batch 19/31 - 81.6ms/batch - loss: 131.94015 - diff: 33.44mlTrain batch 20/31 - 83.1ms/batch - loss: 128.67152 - diff: 33.14mlTrain batch 21/31 - 81.3ms/batch - loss: 133.31336 - diff: 33.47mlTrain batch 22/31 - 80.9ms/batch - loss: 131.08479 - diff: 33.35mlTrain batch 23/31 - 99.3ms/batch - loss: 128.25461 - diff: 33.03mlTrain batch 24/31 - 84.1ms/batch - loss: 130.27276 - diff: 33.47mlTrain batch 25/31 - 81.0ms/batch - loss: 128.17595 - diff: 33.38mlTrain batch 26/31 - 77.9ms/batch - loss: 126.35964 - diff: 33.13mlTrain batch 27/31 - 78.9ms/batch - loss: 125.44176 - diff: 33.15mlTrain batch 28/31 - 78.7ms/batch - loss: 124.34815 - diff: 33.15mlTrain batch 29/31 - 81.4ms/batch - loss: 128.63470 - diff: 33.61mlTrain batch 30/31 - 78.0ms/batch - loss: 127.36567 - diff: 33.53mlTrain batch 31/31 - 41.5ms/batch - loss: 130.49082 - diff: 33.65mlTrain batch 31/31 - 9.7s 41.5ms/batch - loss: 130.49082 - diff: 33.65ml
Test 0.8s: val_loss: 122.45623 - diff: 32.92ml

Epoch 37: current best loss = 110.11006, at epoch 34
Train batch 1/31 - 80.4ms/batch - loss: 98.74065 - diff: 31.36mlTrain batch 2/31 - 77.8ms/batch - loss: 98.10958 - diff: 31.44mlTrain batch 3/31 - 80.6ms/batch - loss: 100.32896 - diff: 32.22mlTrain batch 4/31 - 78.0ms/batch - loss: 122.52633 - diff: 32.75mlTrain batch 5/31 - 79.0ms/batch - loss: 129.57749 - diff: 34.46mlTrain batch 6/31 - 79.3ms/batch - loss: 130.86827 - diff: 35.39mlTrain batch 7/31 - 81.3ms/batch - loss: 142.14847 - diff: 36.98mlTrain batch 8/31 - 78.0ms/batch - loss: 128.92710 - diff: 34.83mlTrain batch 9/31 - 78.8ms/batch - loss: 136.85887 - diff: 35.96mlTrain batch 10/31 - 78.9ms/batch - loss: 138.47744 - diff: 36.25mlTrain batch 11/31 - 80.1ms/batch - loss: 129.77260 - diff: 34.91mlTrain batch 12/31 - 77.8ms/batch - loss: 125.97067 - diff: 34.26mlTrain batch 13/31 - 79.5ms/batch - loss: 123.15852 - diff: 33.94mlTrain batch 14/31 - 79.0ms/batch - loss: 122.11135 - diff: 33.67mlTrain batch 15/31 - 77.7ms/batch - loss: 121.81424 - diff: 33.85mlTrain batch 16/31 - 77.9ms/batch - loss: 123.00836 - diff: 33.81mlTrain batch 17/31 - 77.5ms/batch - loss: 124.81136 - diff: 33.99mlTrain batch 18/31 - 77.8ms/batch - loss: 124.74549 - diff: 34.18mlTrain batch 19/31 - 77.5ms/batch - loss: 124.23779 - diff: 34.16mlTrain batch 20/31 - 77.7ms/batch - loss: 125.53623 - diff: 34.59mlTrain batch 21/31 - 77.6ms/batch - loss: 122.94602 - diff: 34.28mlTrain batch 22/31 - 79.3ms/batch - loss: 122.11546 - diff: 34.23mlTrain batch 23/31 - 78.2ms/batch - loss: 120.21356 - diff: 33.97mlTrain batch 24/31 - 78.8ms/batch - loss: 117.46969 - diff: 33.45mlTrain batch 25/31 - 78.2ms/batch - loss: 117.63876 - diff: 33.53mlTrain batch 26/31 - 78.5ms/batch - loss: 117.66116 - diff: 33.54mlTrain batch 27/31 - 78.8ms/batch - loss: 119.61181 - diff: 33.72mlTrain batch 28/31 - 79.2ms/batch - loss: 118.85956 - diff: 33.69mlTrain batch 29/31 - 78.0ms/batch - loss: 119.72347 - diff: 33.78mlTrain batch 30/31 - 78.4ms/batch - loss: 118.48397 - diff: 33.72mlTrain batch 31/31 - 41.3ms/batch - loss: 154.04364 - diff: 34.36mlTrain batch 31/31 - 9.7s 41.3ms/batch - loss: 154.04364 - diff: 34.36ml
Test 0.8s: val_loss: 110.47327 - diff: 32.57ml

Epoch 38: current best loss = 110.11006, at epoch 34
Train batch 1/31 - 78.2ms/batch - loss: 172.85410 - diff: 45.59mlTrain batch 2/31 - 78.4ms/batch - loss: 173.56550 - diff: 36.71mlTrain batch 3/31 - 78.4ms/batch - loss: 152.74843 - diff: 36.32mlTrain batch 4/31 - 78.0ms/batch - loss: 143.08531 - diff: 35.69mlTrain batch 5/31 - 77.8ms/batch - loss: 164.95402 - diff: 38.07mlTrain batch 6/31 - 77.3ms/batch - loss: 156.94125 - diff: 38.18mlTrain batch 7/31 - 77.4ms/batch - loss: 149.18211 - diff: 37.69mlTrain batch 8/31 - 78.1ms/batch - loss: 140.67044 - diff: 36.65mlTrain batch 9/31 - 77.9ms/batch - loss: 149.26106 - diff: 37.72mlTrain batch 10/31 - 78.6ms/batch - loss: 147.44569 - diff: 37.68mlTrain batch 11/31 - 78.3ms/batch - loss: 138.53935 - diff: 35.98mlTrain batch 12/31 - 77.9ms/batch - loss: 135.35451 - diff: 35.56mlTrain batch 13/31 - 77.7ms/batch - loss: 140.28867 - diff: 36.34mlTrain batch 14/31 - 78.1ms/batch - loss: 145.78585 - diff: 36.69mlTrain batch 15/31 - 77.6ms/batch - loss: 170.37979 - diff: 38.20mlTrain batch 16/31 - 77.9ms/batch - loss: 164.80509 - diff: 37.60mlTrain batch 17/31 - 78.1ms/batch - loss: 160.09012 - diff: 37.23mlTrain batch 18/31 - 77.9ms/batch - loss: 154.70318 - diff: 36.70mlTrain batch 19/31 - 78.0ms/batch - loss: 152.54430 - diff: 36.71mlTrain batch 20/31 - 78.5ms/batch - loss: 150.42965 - diff: 36.60mlTrain batch 21/31 - 79.7ms/batch - loss: 149.57754 - diff: 36.60mlTrain batch 22/31 - 87.1ms/batch - loss: 149.12750 - diff: 36.73mlTrain batch 23/31 - 77.5ms/batch - loss: 148.93157 - diff: 36.89mlTrain batch 24/31 - 78.1ms/batch - loss: 152.32053 - diff: 37.40mlTrain batch 25/31 - 78.0ms/batch - loss: 149.91486 - diff: 37.22mlTrain batch 26/31 - 78.4ms/batch - loss: 149.70061 - diff: 37.20mlTrain batch 27/31 - 78.5ms/batch - loss: 149.35935 - diff: 37.16mlTrain batch 28/31 - 77.8ms/batch - loss: 146.83869 - diff: 36.96mlTrain batch 29/31 - 78.5ms/batch - loss: 143.51324 - diff: 36.51mlTrain batch 30/31 - 77.3ms/batch - loss: 141.85313 - diff: 36.14mlTrain batch 31/31 - 41.9ms/batch - loss: 144.10474 - diff: 36.21mlTrain batch 31/31 - 9.7s 41.9ms/batch - loss: 144.10474 - diff: 36.21ml
Test 0.8s: val_loss: 123.77800 - diff: 33.67ml

Epoch 39: current best loss = 110.11006, at epoch 34
Train batch 1/31 - 82.9ms/batch - loss: 93.46700 - diff: 34.09mlTrain batch 2/31 - 78.2ms/batch - loss: 83.58161 - diff: 30.40mlTrain batch 3/31 - 82.1ms/batch - loss: 99.08298 - diff: 32.29mlTrain batch 4/31 - 77.9ms/batch - loss: 126.13375 - diff: 34.18mlTrain batch 5/31 - 80.3ms/batch - loss: 117.88188 - diff: 33.73mlTrain batch 6/31 - 79.9ms/batch - loss: 120.47426 - diff: 33.80mlTrain batch 7/31 - 79.7ms/batch - loss: 122.27449 - diff: 33.70mlTrain batch 8/31 - 78.6ms/batch - loss: 120.62394 - diff: 33.83mlTrain batch 9/31 - 80.2ms/batch - loss: 122.90547 - diff: 34.42mlTrain batch 10/31 - 78.7ms/batch - loss: 137.08087 - diff: 35.17mlTrain batch 11/31 - 82.1ms/batch - loss: 132.27734 - diff: 34.88mlTrain batch 12/31 - 79.1ms/batch - loss: 130.55131 - diff: 34.59mlTrain batch 13/31 - 82.3ms/batch - loss: 125.36602 - diff: 34.06mlTrain batch 14/31 - 81.7ms/batch - loss: 122.49933 - diff: 33.86mlTrain batch 15/31 - 79.7ms/batch - loss: 119.98361 - diff: 33.78mlTrain batch 16/31 - 78.6ms/batch - loss: 116.58965 - diff: 33.25mlTrain batch 17/31 - 78.3ms/batch - loss: 120.20709 - diff: 33.65mlTrain batch 18/31 - 77.5ms/batch - loss: 119.52279 - diff: 33.53mlTrain batch 19/31 - 80.4ms/batch - loss: 120.05714 - diff: 33.82mlTrain batch 20/31 - 77.7ms/batch - loss: 119.36024 - diff: 33.84mlTrain batch 21/31 - 86.9ms/batch - loss: 126.28868 - diff: 34.56mlTrain batch 22/31 - 78.3ms/batch - loss: 122.30039 - diff: 33.79mlTrain batch 23/31 - 77.4ms/batch - loss: 120.15750 - diff: 33.54mlTrain batch 24/31 - 77.7ms/batch - loss: 118.66795 - diff: 33.37mlTrain batch 25/31 - 77.4ms/batch - loss: 118.03115 - diff: 33.31mlTrain batch 26/31 - 77.6ms/batch - loss: 119.33017 - diff: 33.46mlTrain batch 27/31 - 77.9ms/batch - loss: 119.91618 - diff: 33.54mlTrain batch 28/31 - 77.7ms/batch - loss: 117.81327 - diff: 33.13mlTrain batch 29/31 - 77.7ms/batch - loss: 117.19730 - diff: 33.00mlTrain batch 30/31 - 78.1ms/batch - loss: 117.17751 - diff: 33.13mlTrain batch 31/31 - 44.5ms/batch - loss: 120.38227 - diff: 33.25mlTrain batch 31/31 - 9.8s 44.5ms/batch - loss: 120.38227 - diff: 33.25ml
Test 0.8s: val_loss: 131.52746 - diff: 33.44ml

Epoch 40: current best loss = 110.11006, at epoch 34
Train batch 1/31 - 82.2ms/batch - loss: 155.35419 - diff: 41.13mlTrain batch 2/31 - 78.6ms/batch - loss: 134.44595 - diff: 37.38mlTrain batch 3/31 - 78.5ms/batch - loss: 135.08688 - diff: 36.73mlTrain batch 4/31 - 78.2ms/batch - loss: 126.71135 - diff: 35.69mlTrain batch 5/31 - 78.6ms/batch - loss: 115.94094 - diff: 33.77mlTrain batch 6/31 - 77.9ms/batch - loss: 109.92074 - diff: 32.50mlTrain batch 7/31 - 78.6ms/batch - loss: 110.57921 - diff: 32.39mlTrain batch 8/31 - 78.5ms/batch - loss: 103.79294 - diff: 31.51mlTrain batch 9/31 - 78.1ms/batch - loss: 104.98459 - diff: 31.59mlTrain batch 10/31 - 78.5ms/batch - loss: 104.39544 - diff: 31.56mlTrain batch 11/31 - 78.3ms/batch - loss: 108.60222 - diff: 32.06mlTrain batch 12/31 - 77.7ms/batch - loss: 108.16117 - diff: 32.41mlTrain batch 13/31 - 77.9ms/batch - loss: 110.73625 - diff: 32.69mlTrain batch 14/31 - 78.8ms/batch - loss: 114.85545 - diff: 33.02mlTrain batch 15/31 - 78.6ms/batch - loss: 112.86071 - diff: 32.72mlTrain batch 16/31 - 78.4ms/batch - loss: 120.36545 - diff: 33.28mlTrain batch 17/31 - 77.9ms/batch - loss: 119.24013 - diff: 33.17mlTrain batch 18/31 - 77.3ms/batch - loss: 119.82030 - diff: 33.38mlTrain batch 19/31 - 78.3ms/batch - loss: 122.11863 - diff: 33.71mlTrain batch 20/31 - 87.8ms/batch - loss: 128.38761 - diff: 34.16mlTrain batch 21/31 - 77.4ms/batch - loss: 127.93726 - diff: 34.17mlTrain batch 22/31 - 77.5ms/batch - loss: 128.11976 - diff: 34.36mlTrain batch 23/31 - 79.1ms/batch - loss: 147.77369 - diff: 35.70mlTrain batch 24/31 - 78.2ms/batch - loss: 144.13526 - diff: 35.27mlTrain batch 25/31 - 80.7ms/batch - loss: 143.13794 - diff: 35.26mlTrain batch 26/31 - 78.5ms/batch - loss: 140.61516 - diff: 35.13mlTrain batch 27/31 - 78.7ms/batch - loss: 140.29631 - diff: 34.90mlTrain batch 28/31 - 78.0ms/batch - loss: 138.37545 - diff: 34.83mlTrain batch 29/31 - 78.9ms/batch - loss: 136.53235 - diff: 34.59mlTrain batch 30/31 - 78.1ms/batch - loss: 134.99521 - diff: 34.45mlTrain batch 31/31 - 42.4ms/batch - loss: 135.76726 - diff: 34.41mlTrain batch 31/31 - 9.8s 42.4ms/batch - loss: 135.76726 - diff: 34.41ml
Test 0.8s: val_loss: 139.03364 - diff: 37.46ml

Epoch 41: current best loss = 110.11006, at epoch 34
Train batch 1/31 - 83.1ms/batch - loss: 137.64928 - diff: 37.56mlTrain batch 2/31 - 77.7ms/batch - loss: 139.13302 - diff: 37.56mlTrain batch 3/31 - 80.6ms/batch - loss: 131.41640 - diff: 37.14mlTrain batch 4/31 - 78.4ms/batch - loss: 130.26416 - diff: 37.02mlTrain batch 5/31 - 86.0ms/batch - loss: 142.69675 - diff: 38.36mlTrain batch 6/31 - 77.6ms/batch - loss: 137.29574 - diff: 37.14mlTrain batch 7/31 - 78.0ms/batch - loss: 141.90524 - diff: 37.64mlTrain batch 8/31 - 78.0ms/batch - loss: 141.33902 - diff: 37.82mlTrain batch 9/31 - 82.1ms/batch - loss: 135.55879 - diff: 37.26mlTrain batch 10/31 - 78.2ms/batch - loss: 130.21268 - diff: 36.39mlTrain batch 11/31 - 80.8ms/batch - loss: 125.36392 - diff: 35.75mlTrain batch 12/31 - 78.3ms/batch - loss: 120.18570 - diff: 35.10mlTrain batch 13/31 - 78.1ms/batch - loss: 118.10040 - diff: 34.60mlTrain batch 14/31 - 78.5ms/batch - loss: 117.51347 - diff: 34.69mlTrain batch 15/31 - 79.6ms/batch - loss: 113.75968 - diff: 34.15mlTrain batch 16/31 - 78.7ms/batch - loss: 117.24691 - diff: 34.84mlTrain batch 17/31 - 79.1ms/batch - loss: 138.17326 - diff: 36.36mlTrain batch 18/31 - 77.8ms/batch - loss: 134.20960 - diff: 35.97mlTrain batch 19/31 - 85.6ms/batch - loss: 133.66654 - diff: 35.77mlTrain batch 20/31 - 79.7ms/batch - loss: 130.69564 - diff: 35.42mlTrain batch 21/31 - 77.8ms/batch - loss: 133.64111 - diff: 35.76mlTrain batch 22/31 - 78.2ms/batch - loss: 138.81915 - diff: 36.44mlTrain batch 23/31 - 77.7ms/batch - loss: 136.88323 - diff: 36.00mlTrain batch 24/31 - 77.5ms/batch - loss: 138.11825 - diff: 36.14mlTrain batch 25/31 - 78.1ms/batch - loss: 136.29225 - diff: 35.95mlTrain batch 26/31 - 77.5ms/batch - loss: 133.54782 - diff: 35.38mlTrain batch 27/31 - 77.9ms/batch - loss: 129.99678 - diff: 34.86mlTrain batch 28/31 - 77.8ms/batch - loss: 128.39238 - diff: 34.72mlTrain batch 29/31 - 77.9ms/batch - loss: 126.82644 - diff: 34.55mlTrain batch 30/31 - 77.9ms/batch - loss: 128.89137 - diff: 34.71mlTrain batch 31/31 - 48.0ms/batch - loss: 128.21738 - diff: 34.49mlTrain batch 31/31 - 9.8s 48.0ms/batch - loss: 128.21738 - diff: 34.49ml
Test 0.8s: val_loss: 114.25961 - diff: 32.11ml

Epoch 42: current best loss = 110.11006, at epoch 34
Train batch 1/31 - 78.5ms/batch - loss: 203.49658 - diff: 42.04mlTrain batch 2/31 - 78.3ms/batch - loss: 134.48083 - diff: 34.88mlTrain batch 3/31 - 82.2ms/batch - loss: 113.53763 - diff: 32.67mlTrain batch 4/31 - 78.5ms/batch - loss: 105.82927 - diff: 31.90mlTrain batch 5/31 - 82.3ms/batch - loss: 107.71965 - diff: 32.59mlTrain batch 6/31 - 78.5ms/batch - loss: 112.17538 - diff: 32.92mlTrain batch 7/31 - 82.7ms/batch - loss: 153.56864 - diff: 34.26mlTrain batch 8/31 - 78.8ms/batch - loss: 150.27974 - diff: 34.57mlTrain batch 9/31 - 82.4ms/batch - loss: 146.75982 - diff: 34.66mlTrain batch 10/31 - 79.0ms/batch - loss: 144.64244 - diff: 34.97mlTrain batch 11/31 - 81.3ms/batch - loss: 141.73444 - diff: 35.10mlTrain batch 12/31 - 78.8ms/batch - loss: 139.13053 - diff: 35.24mlTrain batch 13/31 - 78.1ms/batch - loss: 132.63896 - diff: 34.34mlTrain batch 14/31 - 78.3ms/batch - loss: 126.33114 - diff: 33.38mlTrain batch 15/31 - 78.5ms/batch - loss: 127.88688 - diff: 33.58mlTrain batch 16/31 - 77.8ms/batch - loss: 122.26665 - diff: 32.89mlTrain batch 17/31 - 79.9ms/batch - loss: 118.96214 - diff: 32.45mlTrain batch 18/31 - 79.3ms/batch - loss: 120.21509 - diff: 32.67mlTrain batch 19/31 - 81.4ms/batch - loss: 123.19804 - diff: 33.14mlTrain batch 20/31 - 78.1ms/batch - loss: 122.82178 - diff: 33.16mlTrain batch 21/31 - 83.2ms/batch - loss: 120.61259 - diff: 33.05mlTrain batch 22/31 - 82.1ms/batch - loss: 121.68170 - diff: 33.30mlTrain batch 23/31 - 81.5ms/batch - loss: 123.70495 - diff: 33.65mlTrain batch 24/31 - 82.8ms/batch - loss: 121.70590 - diff: 33.49mlTrain batch 25/31 - 80.6ms/batch - loss: 119.78234 - diff: 33.25mlTrain batch 26/31 - 82.8ms/batch - loss: 119.05813 - diff: 33.25mlTrain batch 27/31 - 78.8ms/batch - loss: 118.30651 - diff: 33.21mlTrain batch 28/31 - 81.7ms/batch - loss: 116.91631 - diff: 33.11mlTrain batch 29/31 - 81.4ms/batch - loss: 115.75060 - diff: 33.02mlTrain batch 30/31 - 82.0ms/batch - loss: 114.54402 - diff: 32.84mlTrain batch 31/31 - 42.1ms/batch - loss: 117.66787 - diff: 32.92mlTrain batch 31/31 - 9.7s 42.1ms/batch - loss: 117.66787 - diff: 32.92ml
Test 0.8s: val_loss: 132.02519 - diff: 34.23ml

Epoch 43: current best loss = 110.11006, at epoch 34
Train batch 1/31 - 81.4ms/batch - loss: 101.99923 - diff: 31.46mlTrain batch 2/31 - 78.5ms/batch - loss: 95.52046 - diff: 30.30mlTrain batch 3/31 - 78.8ms/batch - loss: 92.83263 - diff: 30.51mlTrain batch 4/31 - 78.8ms/batch - loss: 81.75029 - diff: 28.95mlTrain batch 5/31 - 78.2ms/batch - loss: 112.25487 - diff: 31.01mlTrain batch 6/31 - 78.7ms/batch - loss: 127.18781 - diff: 33.74mlTrain batch 7/31 - 78.5ms/batch - loss: 114.45160 - diff: 31.92mlTrain batch 8/31 - 78.0ms/batch - loss: 105.29573 - diff: 30.35mlTrain batch 9/31 - 79.0ms/batch - loss: 110.35623 - diff: 31.02mlTrain batch 10/31 - 79.0ms/batch - loss: 114.12410 - diff: 32.11mlTrain batch 11/31 - 81.3ms/batch - loss: 111.43834 - diff: 32.06mlTrain batch 12/31 - 78.2ms/batch - loss: 110.17221 - diff: 32.13mlTrain batch 13/31 - 78.2ms/batch - loss: 107.43303 - diff: 31.69mlTrain batch 14/31 - 78.7ms/batch - loss: 108.66035 - diff: 32.00mlTrain batch 15/31 - 78.2ms/batch - loss: 111.23047 - diff: 32.63mlTrain batch 16/31 - 79.0ms/batch - loss: 110.46456 - diff: 32.52mlTrain batch 17/31 - 99.3ms/batch - loss: 112.68885 - diff: 32.76mlTrain batch 18/31 - 85.3ms/batch - loss: 111.86518 - diff: 32.72mlTrain batch 19/31 - 79.9ms/batch - loss: 111.03797 - diff: 32.71mlTrain batch 20/31 - 78.2ms/batch - loss: 109.08482 - diff: 32.47mlTrain batch 21/31 - 77.7ms/batch - loss: 106.81903 - diff: 32.12mlTrain batch 22/31 - 77.3ms/batch - loss: 108.48230 - diff: 32.38mlTrain batch 23/31 - 79.3ms/batch - loss: 115.33125 - diff: 32.86mlTrain batch 24/31 - 79.1ms/batch - loss: 113.92044 - diff: 32.75mlTrain batch 25/31 - 77.4ms/batch - loss: 116.27717 - diff: 33.10mlTrain batch 26/31 - 77.6ms/batch - loss: 116.26117 - diff: 33.12mlTrain batch 27/31 - 78.7ms/batch - loss: 116.18104 - diff: 33.00mlTrain batch 28/31 - 78.6ms/batch - loss: 117.60631 - diff: 33.11mlTrain batch 29/31 - 78.4ms/batch - loss: 115.64080 - diff: 32.77mlTrain batch 30/31 - 78.6ms/batch - loss: 117.80122 - diff: 33.13mlTrain batch 31/31 - 42.5ms/batch - loss: 119.36350 - diff: 33.13mlTrain batch 31/31 - 9.8s 42.5ms/batch - loss: 119.36350 - diff: 33.13ml
Test 0.8s: val_loss: 105.68036 - diff: 30.59ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_DenseNet121_0_Adam-0.001_MSE_DA3_best

Epoch 44: current best loss = 105.68036, at epoch 43
Train batch 1/31 - 82.4ms/batch - loss: 91.49630 - diff: 30.01mlTrain batch 2/31 - 78.3ms/batch - loss: 86.65519 - diff: 28.97mlTrain batch 3/31 - 81.4ms/batch - loss: 117.96172 - diff: 34.59mlTrain batch 4/31 - 78.4ms/batch - loss: 120.06004 - diff: 35.76mlTrain batch 5/31 - 81.2ms/batch - loss: 127.26034 - diff: 36.76mlTrain batch 6/31 - 78.4ms/batch - loss: 118.91993 - diff: 35.36mlTrain batch 7/31 - 81.0ms/batch - loss: 123.01819 - diff: 36.10mlTrain batch 8/31 - 78.3ms/batch - loss: 114.15049 - diff: 34.74mlTrain batch 9/31 - 77.8ms/batch - loss: 113.85623 - diff: 35.12mlTrain batch 10/31 - 77.3ms/batch - loss: 123.97952 - diff: 35.67mlTrain batch 11/31 - 80.6ms/batch - loss: 117.98098 - diff: 34.83mlTrain batch 12/31 - 78.6ms/batch - loss: 116.42687 - diff: 34.35mlTrain batch 13/31 - 80.7ms/batch - loss: 113.64998 - diff: 33.90mlTrain batch 14/31 - 78.7ms/batch - loss: 110.44894 - diff: 33.27mlTrain batch 15/31 - 82.6ms/batch - loss: 109.42520 - diff: 33.16mlTrain batch 16/31 - 79.8ms/batch - loss: 108.14561 - diff: 33.05mlTrain batch 17/31 - 81.9ms/batch - loss: 106.03830 - diff: 32.70mlTrain batch 18/31 - 78.1ms/batch - loss: 106.95056 - diff: 32.80mlTrain batch 19/31 - 78.0ms/batch - loss: 111.15361 - diff: 33.37mlTrain batch 20/31 - 82.0ms/batch - loss: 110.24718 - diff: 33.45mlTrain batch 21/31 - 82.6ms/batch - loss: 107.84360 - diff: 33.04mlTrain batch 22/31 - 82.5ms/batch - loss: 105.98561 - diff: 32.70mlTrain batch 23/31 - 82.6ms/batch - loss: 105.03697 - diff: 32.63mlTrain batch 24/31 - 81.8ms/batch - loss: 105.79767 - diff: 32.74mlTrain batch 25/31 - 86.6ms/batch - loss: 104.20199 - diff: 32.53mlTrain batch 26/31 - 81.1ms/batch - loss: 113.04427 - diff: 33.32mlTrain batch 27/31 - 78.6ms/batch - loss: 113.84408 - diff: 33.52mlTrain batch 28/31 - 81.2ms/batch - loss: 115.13123 - diff: 33.69mlTrain batch 29/31 - 78.4ms/batch - loss: 117.20024 - diff: 34.00mlTrain batch 30/31 - 80.5ms/batch - loss: 129.60069 - diff: 34.84mlTrain batch 31/31 - 42.2ms/batch - loss: 130.76547 - diff: 34.85mlTrain batch 31/31 - 9.7s 42.2ms/batch - loss: 130.76547 - diff: 34.85ml
Test 0.8s: val_loss: 132.35135 - diff: 32.66ml

Epoch 45: current best loss = 105.68036, at epoch 43
Going to unfreeze the pretrained weights
Train batch 1/31 - 120.9ms/batch - loss: 88.84794 - diff: 30.48mlTrain batch 2/31 - 112.0ms/batch - loss: 198.72158 - diff: 44.83mlTrain batch 3/31 - 111.5ms/batch - loss: 253.56139 - diff: 53.13mlTrain batch 4/31 - 111.8ms/batch - loss: 267.09237 - diff: 55.42mlTrain batch 5/31 - 110.7ms/batch - loss: 264.39516 - diff: 54.51mlTrain batch 6/31 - 114.4ms/batch - loss: 305.49992 - diff: 57.22mlTrain batch 7/31 - 110.3ms/batch - loss: 306.41258 - diff: 56.67mlTrain batch 8/31 - 110.6ms/batch - loss: 302.19494 - diff: 55.61mlTrain batch 9/31 - 110.3ms/batch - loss: 288.00118 - diff: 53.74mlTrain batch 10/31 - 111.1ms/batch - loss: 277.11691 - diff: 52.90mlTrain batch 11/31 - 110.6ms/batch - loss: 276.99396 - diff: 52.25mlTrain batch 12/31 - 110.9ms/batch - loss: 265.49743 - diff: 51.40mlTrain batch 13/31 - 110.3ms/batch - loss: 267.80397 - diff: 51.77mlTrain batch 14/31 - 110.4ms/batch - loss: 270.77724 - diff: 51.98mlTrain batch 15/31 - 117.7ms/batch - loss: 279.55437 - diff: 51.78mlTrain batch 16/31 - 117.4ms/batch - loss: 275.49029 - diff: 51.30mlTrain batch 17/31 - 110.6ms/batch - loss: 270.46434 - diff: 50.91mlTrain batch 18/31 - 110.1ms/batch - loss: 262.25131 - diff: 49.95mlTrain batch 19/31 - 110.5ms/batch - loss: 255.29368 - diff: 49.19mlTrain batch 20/31 - 110.9ms/batch - loss: 247.09808 - diff: 48.18mlTrain batch 21/31 - 111.0ms/batch - loss: 239.29575 - diff: 47.37mlTrain batch 22/31 - 110.6ms/batch - loss: 238.59973 - diff: 47.33mlTrain batch 23/31 - 110.9ms/batch - loss: 234.05541 - diff: 46.96mlTrain batch 24/31 - 109.9ms/batch - loss: 234.22444 - diff: 47.08mlTrain batch 25/31 - 110.2ms/batch - loss: 227.79395 - diff: 46.25mlTrain batch 26/31 - 109.9ms/batch - loss: 225.42720 - diff: 46.02mlTrain batch 27/31 - 110.7ms/batch - loss: 221.55020 - diff: 45.59mlTrain batch 28/31 - 109.7ms/batch - loss: 236.49390 - diff: 45.66mlTrain batch 29/31 - 109.5ms/batch - loss: 231.63163 - diff: 45.11mlTrain batch 30/31 - 109.7ms/batch - loss: 228.02828 - diff: 44.86mlTrain batch 31/31 - 69.5ms/batch - loss: 237.31578 - diff: 45.19mlTrain batch 31/31 - 9.8s 69.5ms/batch - loss: 237.31578 - diff: 45.19ml
Test 0.8s: val_loss: 122.56281 - diff: 33.37ml

Epoch 46: current best loss = 105.68036, at epoch 43
Train batch 1/31 - 115.2ms/batch - loss: 78.06593 - diff: 30.90mlTrain batch 2/31 - 110.5ms/batch - loss: 158.09447 - diff: 41.25mlTrain batch 3/31 - 115.8ms/batch - loss: 158.40598 - diff: 41.17mlTrain batch 4/31 - 110.3ms/batch - loss: 161.45734 - diff: 40.74mlTrain batch 5/31 - 119.5ms/batch - loss: 160.43481 - diff: 40.13mlTrain batch 6/31 - 109.7ms/batch - loss: 149.20862 - diff: 38.63mlTrain batch 7/31 - 118.6ms/batch - loss: 168.68520 - diff: 39.13mlTrain batch 8/31 - 110.3ms/batch - loss: 168.73083 - diff: 39.91mlTrain batch 9/31 - 115.4ms/batch - loss: 160.84791 - diff: 39.29mlTrain batch 10/31 - 110.4ms/batch - loss: 171.35456 - diff: 39.67mlTrain batch 11/31 - 114.1ms/batch - loss: 172.27044 - diff: 39.96mlTrain batch 12/31 - 110.0ms/batch - loss: 172.25497 - diff: 40.10mlTrain batch 13/31 - 109.8ms/batch - loss: 167.68482 - diff: 39.54mlTrain batch 14/31 - 110.6ms/batch - loss: 161.47618 - diff: 38.76mlTrain batch 15/31 - 116.7ms/batch - loss: 166.50542 - diff: 39.29mlTrain batch 16/31 - 110.2ms/batch - loss: 160.97546 - diff: 38.51mlTrain batch 17/31 - 109.9ms/batch - loss: 157.77461 - diff: 37.89mlTrain batch 18/31 - 109.9ms/batch - loss: 157.01305 - diff: 37.98mlTrain batch 19/31 - 110.7ms/batch - loss: 153.70388 - diff: 37.42mlTrain batch 20/31 - 110.0ms/batch - loss: 149.16615 - diff: 36.72mlTrain batch 21/31 - 110.4ms/batch - loss: 146.80470 - diff: 36.56mlTrain batch 22/31 - 109.8ms/batch - loss: 144.08037 - diff: 36.13mlTrain batch 23/31 - 110.9ms/batch - loss: 150.95785 - diff: 36.39mlTrain batch 24/31 - 109.8ms/batch - loss: 152.90252 - diff: 36.60mlTrain batch 25/31 - 113.2ms/batch - loss: 149.79339 - diff: 36.37mlTrain batch 26/31 - 110.5ms/batch - loss: 147.44088 - diff: 36.16mlTrain batch 27/31 - 111.7ms/batch - loss: 149.14607 - diff: 36.56mlTrain batch 28/31 - 110.1ms/batch - loss: 147.01466 - diff: 36.32mlTrain batch 29/31 - 111.3ms/batch - loss: 144.40626 - diff: 36.06mlTrain batch 30/31 - 109.7ms/batch - loss: 142.70926 - diff: 35.88mlTrain batch 31/31 - 74.0ms/batch - loss: 149.67672 - diff: 36.22mlTrain batch 31/31 - 9.8s 74.0ms/batch - loss: 149.67672 - diff: 36.22ml
Test 0.8s: val_loss: 84.58128 - diff: 26.64ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_DenseNet121_0_Adam-0.001_MSE_DA3_best

Epoch 47: current best loss = 84.58128, at epoch 46
Train batch 1/31 - 113.5ms/batch - loss: 87.50454 - diff: 31.34mlTrain batch 2/31 - 109.6ms/batch - loss: 342.33494 - diff: 45.16mlTrain batch 3/31 - 113.1ms/batch - loss: 283.24778 - diff: 43.97mlTrain batch 4/31 - 110.1ms/batch - loss: 229.63164 - diff: 40.15mlTrain batch 5/31 - 112.3ms/batch - loss: 194.23185 - diff: 37.16mlTrain batch 6/31 - 109.9ms/batch - loss: 183.21842 - diff: 36.56mlTrain batch 7/31 - 110.3ms/batch - loss: 170.60279 - diff: 36.13mlTrain batch 8/31 - 111.3ms/batch - loss: 160.69722 - diff: 35.18mlTrain batch 9/31 - 116.6ms/batch - loss: 152.49874 - diff: 34.34mlTrain batch 10/31 - 111.2ms/batch - loss: 150.41928 - diff: 34.19mlTrain batch 11/31 - 111.5ms/batch - loss: 146.43261 - diff: 33.82mlTrain batch 12/31 - 109.5ms/batch - loss: 140.23976 - diff: 33.05mlTrain batch 13/31 - 118.0ms/batch - loss: 137.79075 - diff: 33.21mlTrain batch 14/31 - 115.1ms/batch - loss: 134.50014 - diff: 33.11mlTrain batch 15/31 - 109.7ms/batch - loss: 131.64019 - diff: 33.00mlTrain batch 16/31 - 109.6ms/batch - loss: 126.56569 - diff: 32.41mlTrain batch 17/31 - 110.1ms/batch - loss: 125.12508 - diff: 32.35mlTrain batch 18/31 - 110.4ms/batch - loss: 123.78460 - diff: 32.14mlTrain batch 19/31 - 110.1ms/batch - loss: 123.54236 - diff: 31.92mlTrain batch 20/31 - 110.2ms/batch - loss: 123.44082 - diff: 32.20mlTrain batch 21/31 - 110.3ms/batch - loss: 122.75467 - diff: 32.05mlTrain batch 22/31 - 110.0ms/batch - loss: 122.06313 - diff: 32.19mlTrain batch 23/31 - 109.8ms/batch - loss: 119.57217 - diff: 31.97mlTrain batch 24/31 - 109.8ms/batch - loss: 123.24460 - diff: 32.29mlTrain batch 25/31 - 110.0ms/batch - loss: 121.18697 - diff: 32.07mlTrain batch 26/31 - 109.9ms/batch - loss: 119.82839 - diff: 31.89mlTrain batch 27/31 - 109.7ms/batch - loss: 117.83926 - diff: 31.67mlTrain batch 28/31 - 109.6ms/batch - loss: 118.16567 - diff: 31.74mlTrain batch 29/31 - 109.3ms/batch - loss: 117.45320 - diff: 31.88mlTrain batch 30/31 - 109.1ms/batch - loss: 117.49269 - diff: 32.02mlTrain batch 31/31 - 70.1ms/batch - loss: 116.19777 - diff: 31.69mlTrain batch 31/31 - 9.8s 70.1ms/batch - loss: 116.19777 - diff: 31.69ml
Test 0.8s: val_loss: 100.78715 - diff: 31.03ml

Epoch 48: current best loss = 84.58128, at epoch 46
Train batch 1/31 - 114.3ms/batch - loss: 201.69878 - diff: 44.23mlTrain batch 2/31 - 110.5ms/batch - loss: 157.97533 - diff: 40.81mlTrain batch 3/31 - 113.6ms/batch - loss: 121.01789 - diff: 34.05mlTrain batch 4/31 - 110.4ms/batch - loss: 112.91759 - diff: 33.33mlTrain batch 5/31 - 114.0ms/batch - loss: 110.28551 - diff: 33.37mlTrain batch 6/31 - 110.4ms/batch - loss: 104.42683 - diff: 32.38mlTrain batch 7/31 - 113.9ms/batch - loss: 94.58046 - diff: 30.53mlTrain batch 8/31 - 110.2ms/batch - loss: 91.78957 - diff: 30.26mlTrain batch 9/31 - 113.8ms/batch - loss: 86.30827 - diff: 29.28mlTrain batch 10/31 - 110.5ms/batch - loss: 83.15303 - diff: 28.91mlTrain batch 11/31 - 111.9ms/batch - loss: 98.63773 - diff: 30.31mlTrain batch 12/31 - 111.7ms/batch - loss: 95.06961 - diff: 29.99mlTrain batch 13/31 - 113.1ms/batch - loss: 96.25562 - diff: 30.41mlTrain batch 14/31 - 110.5ms/batch - loss: 104.15815 - diff: 30.88mlTrain batch 15/31 - 114.8ms/batch - loss: 101.42074 - diff: 30.48mlTrain batch 16/31 - 113.6ms/batch - loss: 99.42426 - diff: 30.35mlTrain batch 17/31 - 111.4ms/batch - loss: 96.18430 - diff: 29.79mlTrain batch 18/31 - 118.5ms/batch - loss: 119.40496 - diff: 31.35mlTrain batch 19/31 - 110.5ms/batch - loss: 117.95282 - diff: 31.37mlTrain batch 20/31 - 116.7ms/batch - loss: 114.26519 - diff: 30.82mlTrain batch 21/31 - 111.2ms/batch - loss: 111.66437 - diff: 30.59mlTrain batch 22/31 - 114.1ms/batch - loss: 109.71851 - diff: 30.48mlTrain batch 23/31 - 112.8ms/batch - loss: 107.51822 - diff: 30.24mlTrain batch 24/31 - 117.8ms/batch - loss: 108.15001 - diff: 30.33mlTrain batch 25/31 - 112.5ms/batch - loss: 106.08097 - diff: 30.11mlTrain batch 26/31 - 115.0ms/batch - loss: 105.46818 - diff: 30.14mlTrain batch 27/31 - 111.4ms/batch - loss: 104.95339 - diff: 30.07mlTrain batch 28/31 - 112.8ms/batch - loss: 103.46480 - diff: 29.98mlTrain batch 29/31 - 110.4ms/batch - loss: 103.68215 - diff: 30.13mlTrain batch 30/31 - 110.1ms/batch - loss: 102.88516 - diff: 30.12mlTrain batch 31/31 - 69.8ms/batch - loss: 102.81363 - diff: 30.00mlTrain batch 31/31 - 9.7s 69.8ms/batch - loss: 102.81363 - diff: 30.00ml
Test 0.8s: val_loss: 83.45455 - diff: 27.90ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_DenseNet121_0_Adam-0.001_MSE_DA3_best

Epoch 49: current best loss = 83.45455, at epoch 48
Train batch 1/31 - 113.3ms/batch - loss: 72.36799 - diff: 26.70mlTrain batch 2/31 - 110.8ms/batch - loss: 75.70718 - diff: 27.68mlTrain batch 3/31 - 110.9ms/batch - loss: 83.17955 - diff: 29.88mlTrain batch 4/31 - 110.2ms/batch - loss: 79.20260 - diff: 29.00mlTrain batch 5/31 - 115.6ms/batch - loss: 75.28896 - diff: 27.85mlTrain batch 6/31 - 109.9ms/batch - loss: 76.95987 - diff: 28.30mlTrain batch 7/31 - 115.8ms/batch - loss: 72.65581 - diff: 27.12mlTrain batch 8/31 - 109.8ms/batch - loss: 71.58767 - diff: 27.19mlTrain batch 9/31 - 110.8ms/batch - loss: 71.37868 - diff: 27.48mlTrain batch 10/31 - 110.3ms/batch - loss: 71.33581 - diff: 27.53mlTrain batch 11/31 - 132.1ms/batch - loss: 71.09260 - diff: 27.61mlTrain batch 12/31 - 110.2ms/batch - loss: 70.23686 - diff: 27.45mlTrain batch 13/31 - 109.6ms/batch - loss: 77.89005 - diff: 27.80mlTrain batch 14/31 - 109.3ms/batch - loss: 76.92169 - diff: 27.71mlTrain batch 15/31 - 109.9ms/batch - loss: 75.13343 - diff: 27.39mlTrain batch 16/31 - 110.0ms/batch - loss: 79.74902 - diff: 28.34mlTrain batch 17/31 - 109.8ms/batch - loss: 79.91158 - diff: 28.25mlTrain batch 18/31 - 109.5ms/batch - loss: 79.78606 - diff: 28.26mlTrain batch 19/31 - 109.8ms/batch - loss: 77.40456 - diff: 27.77mlTrain batch 20/31 - 109.5ms/batch - loss: 75.30788 - diff: 27.40mlTrain batch 21/31 - 109.9ms/batch - loss: 77.61531 - diff: 27.45mlTrain batch 22/31 - 110.0ms/batch - loss: 84.33962 - diff: 27.46mlTrain batch 23/31 - 110.2ms/batch - loss: 82.92813 - diff: 27.33mlTrain batch 24/31 - 110.4ms/batch - loss: 84.96029 - diff: 27.82mlTrain batch 25/31 - 110.0ms/batch - loss: 84.52333 - diff: 27.89mlTrain batch 26/31 - 110.1ms/batch - loss: 88.28253 - diff: 28.53mlTrain batch 27/31 - 109.9ms/batch - loss: 86.86956 - diff: 28.23mlTrain batch 28/31 - 109.9ms/batch - loss: 86.90048 - diff: 28.28mlTrain batch 29/31 - 109.8ms/batch - loss: 85.60528 - diff: 28.05mlTrain batch 30/31 - 109.8ms/batch - loss: 85.94562 - diff: 28.24mlTrain batch 31/31 - 71.7ms/batch - loss: 87.74543 - diff: 28.28mlTrain batch 31/31 - 9.8s 71.7ms/batch - loss: 87.74543 - diff: 28.28ml
Test 0.8s: val_loss: 76.92001 - diff: 24.49ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_DenseNet121_0_Adam-0.001_MSE_DA3_best

Epoch 50: current best loss = 76.92001, at epoch 49
Train batch 1/31 - 112.9ms/batch - loss: 109.62791 - diff: 34.74mlTrain batch 2/31 - 111.5ms/batch - loss: 101.18544 - diff: 32.56mlTrain batch 3/31 - 111.3ms/batch - loss: 87.46552 - diff: 30.82mlTrain batch 4/31 - 111.4ms/batch - loss: 80.11529 - diff: 29.23mlTrain batch 5/31 - 111.4ms/batch - loss: 72.97022 - diff: 28.06mlTrain batch 6/31 - 111.7ms/batch - loss: 76.62882 - diff: 28.25mlTrain batch 7/31 - 110.8ms/batch - loss: 76.63952 - diff: 28.61mlTrain batch 8/31 - 112.5ms/batch - loss: 77.00680 - diff: 28.14mlTrain batch 9/31 - 117.4ms/batch - loss: 80.03580 - diff: 28.57mlTrain batch 10/31 - 117.8ms/batch - loss: 80.50093 - diff: 28.28mlTrain batch 11/31 - 111.8ms/batch - loss: 77.50221 - diff: 27.91mlTrain batch 12/31 - 110.1ms/batch - loss: 77.12997 - diff: 27.92mlTrain batch 13/31 - 111.8ms/batch - loss: 76.41729 - diff: 27.67mlTrain batch 14/31 - 112.4ms/batch - loss: 73.17776 - diff: 27.05mlTrain batch 15/31 - 112.7ms/batch - loss: 73.70932 - diff: 27.16mlTrain batch 16/31 - 113.1ms/batch - loss: 73.25574 - diff: 27.09mlTrain batch 17/31 - 114.2ms/batch - loss: 75.10099 - diff: 27.54mlTrain batch 18/31 - 112.9ms/batch - loss: 76.70910 - diff: 27.71mlTrain batch 19/31 - 115.5ms/batch - loss: 75.42209 - diff: 27.39mlTrain batch 20/31 - 113.3ms/batch - loss: 79.80088 - diff: 27.64mlTrain batch 21/31 - 111.3ms/batch - loss: 78.07563 - diff: 27.36mlTrain batch 22/31 - 112.5ms/batch - loss: 78.71023 - diff: 27.38mlTrain batch 23/31 - 111.3ms/batch - loss: 78.83792 - diff: 27.46mlTrain batch 24/31 - 112.3ms/batch - loss: 78.35553 - diff: 27.51mlTrain batch 25/31 - 111.4ms/batch - loss: 79.09085 - diff: 27.65mlTrain batch 26/31 - 112.6ms/batch - loss: 80.13479 - diff: 27.59mlTrain batch 27/31 - 109.9ms/batch - loss: 80.61131 - diff: 27.78mlTrain batch 28/31 - 113.6ms/batch - loss: 81.98786 - diff: 28.03mlTrain batch 29/31 - 109.3ms/batch - loss: 81.49509 - diff: 27.96mlTrain batch 30/31 - 113.5ms/batch - loss: 79.88293 - diff: 27.63mlTrain batch 31/31 - 71.1ms/batch - loss: 84.33584 - diff: 27.79mlTrain batch 31/31 - 9.8s 71.1ms/batch - loss: 84.33584 - diff: 27.79ml
Test 0.8s: val_loss: 3570.57732 - diff: 131.23ml

Epoch 51: current best loss = 76.92001, at epoch 49
Train batch 1/31 - 113.1ms/batch - loss: 60.65941 - diff: 22.85mlTrain batch 2/31 - 110.0ms/batch - loss: 74.48902 - diff: 25.79mlTrain batch 3/31 - 112.4ms/batch - loss: 72.69853 - diff: 26.54mlTrain batch 4/31 - 109.8ms/batch - loss: 87.50523 - diff: 27.20mlTrain batch 5/31 - 112.2ms/batch - loss: 101.45214 - diff: 28.17mlTrain batch 6/31 - 111.2ms/batch - loss: 93.73469 - diff: 27.01mlTrain batch 7/31 - 112.3ms/batch - loss: 86.95849 - diff: 26.52mlTrain batch 8/31 - 110.5ms/batch - loss: 140.60012 - diff: 29.06mlTrain batch 9/31 - 120.4ms/batch - loss: 131.38679 - diff: 28.52mlTrain batch 10/31 - 119.4ms/batch - loss: 130.59036 - diff: 28.96mlTrain batch 11/31 - 110.4ms/batch - loss: 123.00968 - diff: 28.29mlTrain batch 12/31 - 110.1ms/batch - loss: 118.38139 - diff: 27.97mlTrain batch 13/31 - 110.9ms/batch - loss: 115.73795 - diff: 27.82mlTrain batch 14/31 - 116.8ms/batch - loss: 110.66277 - diff: 27.35mlTrain batch 15/31 - 112.5ms/batch - loss: 109.99748 - diff: 27.79mlTrain batch 16/31 - 110.6ms/batch - loss: 109.70687 - diff: 28.08mlTrain batch 17/31 - 112.3ms/batch - loss: 110.80132 - diff: 28.31mlTrain batch 18/31 - 110.8ms/batch - loss: 108.68801 - diff: 28.21mlTrain batch 19/31 - 112.2ms/batch - loss: 106.52570 - diff: 27.99mlTrain batch 20/31 - 110.6ms/batch - loss: 107.80317 - diff: 28.57mlTrain batch 21/31 - 112.7ms/batch - loss: 107.52328 - diff: 28.79mlTrain batch 22/31 - 111.2ms/batch - loss: 107.61073 - diff: 29.08mlTrain batch 23/31 - 110.0ms/batch - loss: 109.48123 - diff: 29.39mlTrain batch 24/31 - 111.0ms/batch - loss: 108.69329 - diff: 29.48mlTrain batch 25/31 - 111.8ms/batch - loss: 108.77720 - diff: 29.48mlTrain batch 26/31 - 111.1ms/batch - loss: 107.10184 - diff: 29.29mlTrain batch 27/31 - 113.1ms/batch - loss: 105.89945 - diff: 29.21mlTrain batch 28/31 - 111.7ms/batch - loss: 105.93004 - diff: 29.35mlTrain batch 29/31 - 112.1ms/batch - loss: 104.72201 - diff: 29.36mlTrain batch 30/31 - 110.9ms/batch - loss: 105.23286 - diff: 29.62mlTrain batch 31/31 - 69.4ms/batch - loss: 107.14181 - diff: 29.67mlTrain batch 31/31 - 9.8s 69.4ms/batch - loss: 107.14181 - diff: 29.67ml
Test 0.8s: val_loss: 80.36796 - diff: 26.59ml

Epoch 52: current best loss = 76.92001, at epoch 49
Train batch 1/31 - 113.8ms/batch - loss: 57.06256 - diff: 25.10mlTrain batch 2/31 - 110.0ms/batch - loss: 57.10531 - diff: 23.91mlTrain batch 3/31 - 113.3ms/batch - loss: 67.38113 - diff: 26.09mlTrain batch 4/31 - 110.4ms/batch - loss: 63.69212 - diff: 25.28mlTrain batch 5/31 - 113.1ms/batch - loss: 73.68978 - diff: 26.81mlTrain batch 6/31 - 110.2ms/batch - loss: 74.23512 - diff: 26.81mlTrain batch 7/31 - 113.4ms/batch - loss: 80.61176 - diff: 28.37mlTrain batch 8/31 - 110.4ms/batch - loss: 81.76156 - diff: 28.50mlTrain batch 9/31 - 115.7ms/batch - loss: 79.85368 - diff: 28.28mlTrain batch 10/31 - 121.8ms/batch - loss: 75.46542 - diff: 27.34mlTrain batch 11/31 - 116.0ms/batch - loss: 78.41353 - diff: 28.12mlTrain batch 12/31 - 110.8ms/batch - loss: 78.75592 - diff: 28.06mlTrain batch 13/31 - 112.9ms/batch - loss: 82.28672 - diff: 28.41mlTrain batch 14/31 - 110.0ms/batch - loss: 86.73601 - diff: 29.10mlTrain batch 15/31 - 111.7ms/batch - loss: 118.61227 - diff: 30.56mlTrain batch 16/31 - 110.2ms/batch - loss: 114.23077 - diff: 30.01mlTrain batch 17/31 - 111.7ms/batch - loss: 110.58294 - diff: 29.29mlTrain batch 18/31 - 110.5ms/batch - loss: 114.37561 - diff: 29.72mlTrain batch 19/31 - 110.1ms/batch - loss: 112.99827 - diff: 29.75mlTrain batch 20/31 - 109.6ms/batch - loss: 110.67231 - diff: 29.59mlTrain batch 21/31 - 109.8ms/batch - loss: 108.86159 - diff: 29.39mlTrain batch 22/31 - 109.4ms/batch - loss: 107.29131 - diff: 29.31mlTrain batch 23/31 - 109.9ms/batch - loss: 107.71415 - diff: 29.36mlTrain batch 24/31 - 109.4ms/batch - loss: 105.36884 - diff: 29.03mlTrain batch 25/31 - 109.8ms/batch - loss: 104.60975 - diff: 28.93mlTrain batch 26/31 - 109.3ms/batch - loss: 101.71746 - diff: 28.48mlTrain batch 27/31 - 109.9ms/batch - loss: 101.97246 - diff: 28.61mlTrain batch 28/31 - 109.5ms/batch - loss: 101.76499 - diff: 28.68mlTrain batch 29/31 - 110.1ms/batch - loss: 99.48325 - diff: 28.41mlTrain batch 30/31 - 109.2ms/batch - loss: 100.24504 - diff: 28.64mlTrain batch 31/31 - 75.7ms/batch - loss: 99.60356 - diff: 28.44mlTrain batch 31/31 - 9.8s 75.7ms/batch - loss: 99.60356 - diff: 28.44ml
Test 0.8s: val_loss: 157.57880 - diff: 41.01ml

Epoch 53: current best loss = 76.92001, at epoch 49
Train batch 1/31 - 110.8ms/batch - loss: 74.48331 - diff: 29.29mlTrain batch 2/31 - 109.9ms/batch - loss: 60.89538 - diff: 26.34mlTrain batch 3/31 - 109.8ms/batch - loss: 53.18500 - diff: 24.10mlTrain batch 4/31 - 109.8ms/batch - loss: 58.29136 - diff: 24.74mlTrain batch 5/31 - 109.8ms/batch - loss: 61.51757 - diff: 25.69mlTrain batch 6/31 - 109.5ms/batch - loss: 63.83856 - diff: 26.15mlTrain batch 7/31 - 109.8ms/batch - loss: 63.62729 - diff: 26.19mlTrain batch 8/31 - 109.4ms/batch - loss: 65.55616 - diff: 26.62mlTrain batch 9/31 - 109.4ms/batch - loss: 66.89495 - diff: 26.90mlTrain batch 10/31 - 113.1ms/batch - loss: 70.71078 - diff: 27.83mlTrain batch 11/31 - 110.3ms/batch - loss: 68.27747 - diff: 27.22mlTrain batch 12/31 - 110.0ms/batch - loss: 66.86683 - diff: 26.88mlTrain batch 13/31 - 115.4ms/batch - loss: 66.10720 - diff: 26.62mlTrain batch 14/31 - 109.7ms/batch - loss: 66.10880 - diff: 26.58mlTrain batch 15/31 - 111.2ms/batch - loss: 68.28863 - diff: 26.41mlTrain batch 16/31 - 110.8ms/batch - loss: 68.04032 - diff: 26.53mlTrain batch 17/31 - 110.7ms/batch - loss: 67.43072 - diff: 26.46mlTrain batch 18/31 - 111.8ms/batch - loss: 65.11276 - diff: 25.91mlTrain batch 19/31 - 110.9ms/batch - loss: 65.51198 - diff: 26.01mlTrain batch 20/31 - 112.9ms/batch - loss: 66.64235 - diff: 26.03mlTrain batch 21/31 - 110.7ms/batch - loss: 67.32895 - diff: 26.25mlTrain batch 22/31 - 112.6ms/batch - loss: 70.76342 - diff: 26.71mlTrain batch 23/31 - 110.1ms/batch - loss: 71.12657 - diff: 26.74mlTrain batch 24/31 - 112.7ms/batch - loss: 69.29680 - diff: 26.34mlTrain batch 25/31 - 110.3ms/batch - loss: 70.85790 - diff: 26.72mlTrain batch 26/31 - 110.2ms/batch - loss: 69.67496 - diff: 26.44mlTrain batch 27/31 - 110.3ms/batch - loss: 68.57206 - diff: 26.14mlTrain batch 28/31 - 114.7ms/batch - loss: 69.46290 - diff: 26.31mlTrain batch 29/31 - 109.5ms/batch - loss: 69.28496 - diff: 26.25mlTrain batch 30/31 - 110.0ms/batch - loss: 71.27133 - diff: 26.35mlTrain batch 31/31 - 69.1ms/batch - loss: 80.60830 - diff: 26.67mlTrain batch 31/31 - 9.8s 69.1ms/batch - loss: 80.60830 - diff: 26.67ml
Test 0.8s: val_loss: 91.88272 - diff: 26.45ml

Epoch 54: current best loss = 76.92001, at epoch 49
Train batch 1/31 - 111.7ms/batch - loss: 62.46161 - diff: 26.43mlTrain batch 2/31 - 111.0ms/batch - loss: 97.13390 - diff: 31.62mlTrain batch 3/31 - 110.9ms/batch - loss: 83.65280 - diff: 28.57mlTrain batch 4/31 - 111.2ms/batch - loss: 75.72200 - diff: 27.15mlTrain batch 5/31 - 113.5ms/batch - loss: 87.57299 - diff: 28.28mlTrain batch 6/31 - 111.2ms/batch - loss: 89.93047 - diff: 28.95mlTrain batch 7/31 - 110.5ms/batch - loss: 87.24960 - diff: 28.68mlTrain batch 8/31 - 111.6ms/batch - loss: 83.27199 - diff: 28.00mlTrain batch 9/31 - 113.5ms/batch - loss: 84.74837 - diff: 28.59mlTrain batch 10/31 - 124.8ms/batch - loss: 80.67221 - diff: 27.76mlTrain batch 11/31 - 110.6ms/batch - loss: 77.71630 - diff: 27.46mlTrain batch 12/31 - 110.1ms/batch - loss: 88.12936 - diff: 28.26mlTrain batch 13/31 - 111.9ms/batch - loss: 87.85819 - diff: 28.43mlTrain batch 14/31 - 111.5ms/batch - loss: 90.29469 - diff: 28.76mlTrain batch 15/31 - 111.0ms/batch - loss: 89.42929 - diff: 28.62mlTrain batch 16/31 - 110.6ms/batch - loss: 87.02164 - diff: 28.37mlTrain batch 17/31 - 109.8ms/batch - loss: 85.92023 - diff: 28.36mlTrain batch 18/31 - 109.8ms/batch - loss: 84.41313 - diff: 28.23mlTrain batch 19/31 - 110.1ms/batch - loss: 82.30626 - diff: 27.87mlTrain batch 20/31 - 109.5ms/batch - loss: 80.92127 - diff: 27.61mlTrain batch 21/31 - 109.6ms/batch - loss: 79.86158 - diff: 27.43mlTrain batch 22/31 - 109.6ms/batch - loss: 79.39330 - diff: 27.26mlTrain batch 23/31 - 114.6ms/batch - loss: 81.24895 - diff: 27.75mlTrain batch 24/31 - 109.9ms/batch - loss: 80.84087 - diff: 27.81mlTrain batch 25/31 - 109.9ms/batch - loss: 80.98586 - diff: 27.68mlTrain batch 26/31 - 109.8ms/batch - loss: 79.21823 - diff: 27.38mlTrain batch 27/31 - 112.2ms/batch - loss: 83.38449 - diff: 27.72mlTrain batch 28/31 - 110.1ms/batch - loss: 82.26858 - diff: 27.54mlTrain batch 29/31 - 109.5ms/batch - loss: 82.75590 - diff: 27.61mlTrain batch 30/31 - 108.9ms/batch - loss: 81.62432 - diff: 27.41mlTrain batch 31/31 - 68.9ms/batch - loss: 81.37651 - diff: 27.26mlTrain batch 31/31 - 9.8s 68.9ms/batch - loss: 81.37651 - diff: 27.26ml
Test 0.8s: val_loss: 81.34392 - diff: 25.76ml

Epoch 55: current best loss = 76.92001, at epoch 49
Train batch 1/31 - 111.1ms/batch - loss: 251.54315 - diff: 37.35mlTrain batch 2/31 - 110.1ms/batch - loss: 159.30979 - diff: 32.44mlTrain batch 3/31 - 110.8ms/batch - loss: 134.68054 - diff: 29.36mlTrain batch 4/31 - 110.2ms/batch - loss: 107.14187 - diff: 26.39mlTrain batch 5/31 - 110.6ms/batch - loss: 94.08457 - diff: 25.50mlTrain batch 6/31 - 110.6ms/batch - loss: 83.25806 - diff: 24.25mlTrain batch 7/31 - 110.1ms/batch - loss: 100.83123 - diff: 27.39mlTrain batch 8/31 - 109.9ms/batch - loss: 94.02973 - diff: 26.70mlTrain batch 9/31 - 113.4ms/batch - loss: 87.57399 - diff: 26.18mlTrain batch 10/31 - 110.3ms/batch - loss: 86.49581 - diff: 26.04mlTrain batch 11/31 - 109.9ms/batch - loss: 83.76893 - diff: 25.86mlTrain batch 12/31 - 109.7ms/batch - loss: 81.41261 - diff: 25.53mlTrain batch 13/31 - 110.0ms/batch - loss: 82.09150 - diff: 25.87mlTrain batch 14/31 - 110.0ms/batch - loss: 78.54423 - diff: 25.29mlTrain batch 15/31 - 110.4ms/batch - loss: 74.69745 - diff: 24.65mlTrain batch 16/31 - 110.4ms/batch - loss: 72.01150 - diff: 24.27mlTrain batch 17/31 - 110.8ms/batch - loss: 74.11265 - diff: 24.93mlTrain batch 18/31 - 110.2ms/batch - loss: 72.22136 - diff: 24.66mlTrain batch 19/31 - 110.3ms/batch - loss: 74.26322 - diff: 25.03mlTrain batch 20/31 - 110.7ms/batch - loss: 73.75552 - diff: 25.08mlTrain batch 21/31 - 110.5ms/batch - loss: 74.99450 - diff: 25.34mlTrain batch 22/31 - 110.6ms/batch - loss: 74.75341 - diff: 25.44mlTrain batch 23/31 - 110.1ms/batch - loss: 73.14588 - diff: 25.23mlTrain batch 24/31 - 110.2ms/batch - loss: 73.23579 - diff: 25.42mlTrain batch 25/31 - 110.2ms/batch - loss: 76.37089 - diff: 26.01mlTrain batch 26/31 - 110.4ms/batch - loss: 76.21918 - diff: 25.76mlTrain batch 27/31 - 110.3ms/batch - loss: 75.98796 - diff: 25.81mlTrain batch 28/31 - 110.3ms/batch - loss: 76.00602 - diff: 25.80mlTrain batch 29/31 - 109.7ms/batch - loss: 76.60223 - diff: 26.06mlTrain batch 30/31 - 109.7ms/batch - loss: 74.77987 - diff: 25.68mlTrain batch 31/31 - 73.1ms/batch - loss: 75.68649 - diff: 25.69mlTrain batch 31/31 - 9.9s 73.1ms/batch - loss: 75.68649 - diff: 25.69ml
Test 0.8s: val_loss: 135.30317 - diff: 32.35ml

Epoch 56: current best loss = 76.92001, at epoch 49
Train batch 1/31 - 114.5ms/batch - loss: 47.53568 - diff: 19.94mlTrain batch 2/31 - 110.2ms/batch - loss: 61.06132 - diff: 23.89mlTrain batch 3/31 - 110.0ms/batch - loss: 75.20632 - diff: 26.37mlTrain batch 4/31 - 110.2ms/batch - loss: 68.92046 - diff: 25.49mlTrain batch 5/31 - 114.6ms/batch - loss: 71.19480 - diff: 26.93mlTrain batch 6/31 - 110.6ms/batch - loss: 85.04343 - diff: 28.45mlTrain batch 7/31 - 112.9ms/batch - loss: 79.00280 - diff: 27.47mlTrain batch 8/31 - 113.2ms/batch - loss: 75.08115 - diff: 27.03mlTrain batch 9/31 - 114.5ms/batch - loss: 72.64054 - diff: 26.42mlTrain batch 10/31 - 110.3ms/batch - loss: 69.02230 - diff: 25.75mlTrain batch 11/31 - 114.8ms/batch - loss: 67.77929 - diff: 25.57mlTrain batch 12/31 - 112.8ms/batch - loss: 66.24990 - diff: 25.27mlTrain batch 13/31 - 113.3ms/batch - loss: 65.09642 - diff: 25.16mlTrain batch 14/31 - 111.8ms/batch - loss: 65.75693 - diff: 25.51mlTrain batch 15/31 - 114.3ms/batch - loss: 63.88337 - diff: 25.21mlTrain batch 16/31 - 112.6ms/batch - loss: 63.01964 - diff: 24.96mlTrain batch 17/31 - 114.3ms/batch - loss: 61.78704 - diff: 24.82mlTrain batch 18/31 - 112.3ms/batch - loss: 61.16298 - diff: 24.76mlTrain batch 19/31 - 111.8ms/batch - loss: 61.33006 - diff: 24.70mlTrain batch 20/31 - 112.4ms/batch - loss: 61.43621 - diff: 24.78mlTrain batch 21/31 - 112.2ms/batch - loss: 61.13386 - diff: 24.84mlTrain batch 22/31 - 113.5ms/batch - loss: 61.53825 - diff: 25.04mlTrain batch 23/31 - 112.4ms/batch - loss: 63.99334 - diff: 25.43mlTrain batch 24/31 - 112.8ms/batch - loss: 74.74356 - diff: 26.57mlTrain batch 25/31 - 111.6ms/batch - loss: 72.31582 - diff: 26.00mlTrain batch 26/31 - 114.4ms/batch - loss: 70.99579 - diff: 25.80mlTrain batch 27/31 - 111.1ms/batch - loss: 72.24985 - diff: 26.07mlTrain batch 28/31 - 114.1ms/batch - loss: 76.12314 - diff: 26.56mlTrain batch 29/31 - 111.1ms/batch - loss: 75.40742 - diff: 26.37mlTrain batch 30/31 - 113.2ms/batch - loss: 74.87260 - diff: 26.19mlTrain batch 31/31 - 69.7ms/batch - loss: 76.22021 - diff: 26.22mlTrain batch 31/31 - 9.7s 69.7ms/batch - loss: 76.22021 - diff: 26.22ml
Test 0.8s: val_loss: 83.99998 - diff: 27.62ml

Epoch 57: current best loss = 76.92001, at epoch 49
Train batch 1/31 - 111.0ms/batch - loss: 62.66428 - diff: 25.31mlTrain batch 2/31 - 112.6ms/batch - loss: 55.86671 - diff: 23.44mlTrain batch 3/31 - 110.1ms/batch - loss: 57.23029 - diff: 23.91mlTrain batch 4/31 - 110.1ms/batch - loss: 76.67970 - diff: 27.03mlTrain batch 5/31 - 110.2ms/batch - loss: 68.76386 - diff: 25.22mlTrain batch 6/31 - 110.2ms/batch - loss: 68.35034 - diff: 25.50mlTrain batch 7/31 - 121.8ms/batch - loss: 68.23886 - diff: 25.63mlTrain batch 8/31 - 119.2ms/batch - loss: 65.94912 - diff: 25.59mlTrain batch 9/31 - 109.6ms/batch - loss: 62.45871 - diff: 25.05mlTrain batch 10/31 - 110.3ms/batch - loss: 62.20836 - diff: 25.10mlTrain batch 11/31 - 109.8ms/batch - loss: 69.62206 - diff: 26.38mlTrain batch 12/31 - 109.9ms/batch - loss: 68.81315 - diff: 26.40mlTrain batch 13/31 - 110.8ms/batch - loss: 65.82129 - diff: 25.81mlTrain batch 14/31 - 109.7ms/batch - loss: 70.03883 - diff: 26.80mlTrain batch 15/31 - 110.7ms/batch - loss: 71.31267 - diff: 27.00mlTrain batch 16/31 - 109.8ms/batch - loss: 70.54644 - diff: 26.56mlTrain batch 17/31 - 110.6ms/batch - loss: 71.60467 - diff: 26.54mlTrain batch 18/31 - 110.1ms/batch - loss: 71.52748 - diff: 26.60mlTrain batch 19/31 - 110.7ms/batch - loss: 71.87280 - diff: 26.68mlTrain batch 20/31 - 109.8ms/batch - loss: 69.86301 - diff: 26.28mlTrain batch 21/31 - 110.9ms/batch - loss: 70.59038 - diff: 26.62mlTrain batch 22/31 - 111.2ms/batch - loss: 69.91559 - diff: 26.52mlTrain batch 23/31 - 110.0ms/batch - loss: 68.73870 - diff: 26.18mlTrain batch 24/31 - 109.9ms/batch - loss: 69.35660 - diff: 26.33mlTrain batch 25/31 - 110.2ms/batch - loss: 67.26890 - diff: 25.85mlTrain batch 26/31 - 110.2ms/batch - loss: 67.28782 - diff: 25.93mlTrain batch 27/31 - 110.3ms/batch - loss: 66.06895 - diff: 25.69mlTrain batch 28/31 - 109.8ms/batch - loss: 65.92081 - diff: 25.56mlTrain batch 29/31 - 109.3ms/batch - loss: 65.20179 - diff: 25.46mlTrain batch 30/31 - 109.0ms/batch - loss: 65.54772 - diff: 25.60mlTrain batch 31/31 - 68.1ms/batch - loss: 67.98409 - diff: 25.66mlTrain batch 31/31 - 9.8s 68.1ms/batch - loss: 67.98409 - diff: 25.66ml
Test 0.8s: val_loss: 51.80109 - diff: 21.84ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_DenseNet121_0_Adam-0.001_MSE_DA3_best

Epoch 58: current best loss = 51.80109, at epoch 57
Train batch 1/31 - 117.9ms/batch - loss: 32.84498 - diff: 20.21mlTrain batch 2/31 - 110.3ms/batch - loss: 62.12372 - diff: 25.42mlTrain batch 3/31 - 110.7ms/batch - loss: 59.74622 - diff: 24.49mlTrain batch 4/31 - 110.3ms/batch - loss: 52.88839 - diff: 23.08mlTrain batch 5/31 - 114.4ms/batch - loss: 56.59973 - diff: 23.86mlTrain batch 6/31 - 113.3ms/batch - loss: 56.71668 - diff: 23.38mlTrain batch 7/31 - 111.1ms/batch - loss: 52.97248 - diff: 22.41mlTrain batch 8/31 - 110.7ms/batch - loss: 53.76225 - diff: 22.45mlTrain batch 9/31 - 110.5ms/batch - loss: 63.59209 - diff: 23.24mlTrain batch 10/31 - 114.1ms/batch - loss: 63.92281 - diff: 23.67mlTrain batch 11/31 - 114.7ms/batch - loss: 60.76749 - diff: 23.24mlTrain batch 12/31 - 111.5ms/batch - loss: 57.86682 - diff: 22.62mlTrain batch 13/31 - 110.9ms/batch - loss: 56.41846 - diff: 22.45mlTrain batch 14/31 - 113.0ms/batch - loss: 59.49832 - diff: 23.28mlTrain batch 15/31 - 115.7ms/batch - loss: 57.90383 - diff: 23.06mlTrain batch 16/31 - 111.4ms/batch - loss: 59.44465 - diff: 23.37mlTrain batch 17/31 - 114.8ms/batch - loss: 58.55098 - diff: 23.23mlTrain batch 18/31 - 112.5ms/batch - loss: 57.76307 - diff: 23.19mlTrain batch 19/31 - 113.7ms/batch - loss: 56.38676 - diff: 22.89mlTrain batch 20/31 - 112.8ms/batch - loss: 56.16958 - diff: 22.90mlTrain batch 21/31 - 113.8ms/batch - loss: 55.01713 - diff: 22.69mlTrain batch 22/31 - 113.8ms/batch - loss: 54.67123 - diff: 22.50mlTrain batch 23/31 - 115.7ms/batch - loss: 55.73373 - diff: 22.66mlTrain batch 24/31 - 112.4ms/batch - loss: 56.02587 - diff: 22.85mlTrain batch 25/31 - 114.3ms/batch - loss: 55.11355 - diff: 22.63mlTrain batch 26/31 - 113.5ms/batch - loss: 54.55523 - diff: 22.45mlTrain batch 27/31 - 111.7ms/batch - loss: 53.69505 - diff: 22.23mlTrain batch 28/31 - 113.8ms/batch - loss: 53.36421 - diff: 22.17mlTrain batch 29/31 - 112.2ms/batch - loss: 53.11279 - diff: 22.26mlTrain batch 30/31 - 113.3ms/batch - loss: 52.13862 - diff: 22.07mlTrain batch 31/31 - 70.5ms/batch - loss: 64.64863 - diff: 22.45mlTrain batch 31/31 - 9.8s 70.5ms/batch - loss: 64.64863 - diff: 22.45ml
Test 0.8s: val_loss: 55.93659 - diff: 21.68ml

Epoch 59: current best loss = 51.80109, at epoch 57
Train batch 1/31 - 112.6ms/batch - loss: 49.76378 - diff: 23.17mlTrain batch 2/31 - 111.7ms/batch - loss: 56.50452 - diff: 24.99mlTrain batch 3/31 - 110.7ms/batch - loss: 53.52336 - diff: 24.95mlTrain batch 4/31 - 110.0ms/batch - loss: 53.27772 - diff: 24.28mlTrain batch 5/31 - 124.1ms/batch - loss: 71.16573 - diff: 25.63mlTrain batch 6/31 - 122.1ms/batch - loss: 84.29098 - diff: 26.99mlTrain batch 7/31 - 113.8ms/batch - loss: 78.57146 - diff: 26.01mlTrain batch 8/31 - 110.0ms/batch - loss: 75.19419 - diff: 25.71mlTrain batch 9/31 - 113.0ms/batch - loss: 71.98787 - diff: 25.40mlTrain batch 10/31 - 109.7ms/batch - loss: 69.45507 - diff: 24.99mlTrain batch 11/31 - 113.2ms/batch - loss: 69.67562 - diff: 24.99mlTrain batch 12/31 - 110.2ms/batch - loss: 68.00123 - diff: 25.00mlTrain batch 13/31 - 112.3ms/batch - loss: 65.11218 - diff: 24.57mlTrain batch 14/31 - 109.9ms/batch - loss: 64.95459 - diff: 24.47mlTrain batch 15/31 - 112.5ms/batch - loss: 63.58852 - diff: 24.37mlTrain batch 16/31 - 109.8ms/batch - loss: 62.82969 - diff: 24.29mlTrain batch 17/31 - 114.5ms/batch - loss: 61.49508 - diff: 24.15mlTrain batch 18/31 - 109.6ms/batch - loss: 61.18639 - diff: 24.05mlTrain batch 19/31 - 111.9ms/batch - loss: 60.97497 - diff: 24.12mlTrain batch 20/31 - 110.7ms/batch - loss: 60.54755 - diff: 24.02mlTrain batch 21/31 - 112.2ms/batch - loss: 59.27820 - diff: 23.77mlTrain batch 22/31 - 110.4ms/batch - loss: 59.68513 - diff: 23.83mlTrain batch 23/31 - 111.4ms/batch - loss: 60.14633 - diff: 24.01mlTrain batch 24/31 - 111.3ms/batch - loss: 59.82337 - diff: 24.01mlTrain batch 25/31 - 110.9ms/batch - loss: 60.45262 - diff: 24.28mlTrain batch 26/31 - 111.1ms/batch - loss: 62.88600 - diff: 24.78mlTrain batch 27/31 - 114.3ms/batch - loss: 62.64057 - diff: 24.78mlTrain batch 28/31 - 110.0ms/batch - loss: 63.29007 - diff: 24.88mlTrain batch 29/31 - 112.3ms/batch - loss: 63.15124 - diff: 24.95mlTrain batch 30/31 - 109.8ms/batch - loss: 63.34087 - diff: 25.08mlTrain batch 31/31 - 69.4ms/batch - loss: 64.01852 - diff: 25.04mlTrain batch 31/31 - 9.8s 69.4ms/batch - loss: 64.01852 - diff: 25.04ml
Test 0.8s: val_loss: 91.10284 - diff: 28.42ml

Epoch 60: current best loss = 51.80109, at epoch 57
Train batch 1/31 - 112.2ms/batch - loss: 52.38773 - diff: 22.28mlTrain batch 2/31 - 111.1ms/batch - loss: 55.57436 - diff: 23.34mlTrain batch 3/31 - 110.3ms/batch - loss: 65.14157 - diff: 24.75mlTrain batch 4/31 - 110.1ms/batch - loss: 81.79740 - diff: 27.13mlTrain batch 5/31 - 119.5ms/batch - loss: 70.73791 - diff: 24.83mlTrain batch 6/31 - 111.7ms/batch - loss: 64.48102 - diff: 23.79mlTrain batch 7/31 - 110.2ms/batch - loss: 60.29913 - diff: 23.17mlTrain batch 8/31 - 109.8ms/batch - loss: 61.48501 - diff: 23.33mlTrain batch 9/31 - 110.6ms/batch - loss: 61.82920 - diff: 23.43mlTrain batch 10/31 - 110.4ms/batch - loss: 70.80660 - diff: 24.37mlTrain batch 11/31 - 110.4ms/batch - loss: 79.21775 - diff: 25.27mlTrain batch 12/31 - 110.3ms/batch - loss: 76.19912 - diff: 24.99mlTrain batch 13/31 - 110.2ms/batch - loss: 72.62752 - diff: 24.52mlTrain batch 14/31 - 110.1ms/batch - loss: 69.17999 - diff: 23.97mlTrain batch 15/31 - 110.3ms/batch - loss: 66.03144 - diff: 23.35mlTrain batch 16/31 - 110.0ms/batch - loss: 64.77812 - diff: 23.23mlTrain batch 17/31 - 110.6ms/batch - loss: 63.21588 - diff: 23.03mlTrain batch 18/31 - 110.9ms/batch - loss: 64.40247 - diff: 23.47mlTrain batch 19/31 - 110.9ms/batch - loss: 68.00334 - diff: 24.32mlTrain batch 20/31 - 110.9ms/batch - loss: 69.36577 - diff: 24.47mlTrain batch 21/31 - 110.1ms/batch - loss: 70.14247 - diff: 24.81mlTrain batch 22/31 - 110.1ms/batch - loss: 68.86262 - diff: 24.73mlTrain batch 23/31 - 109.9ms/batch - loss: 68.81009 - diff: 24.82mlTrain batch 24/31 - 109.9ms/batch - loss: 68.16854 - diff: 24.78mlTrain batch 25/31 - 109.9ms/batch - loss: 69.59741 - diff: 24.93mlTrain batch 26/31 - 110.0ms/batch - loss: 68.69942 - diff: 24.72mlTrain batch 27/31 - 109.5ms/batch - loss: 67.00522 - diff: 24.43mlTrain batch 28/31 - 109.3ms/batch - loss: 67.45322 - diff: 24.59mlTrain batch 29/31 - 109.1ms/batch - loss: 70.42849 - diff: 25.17mlTrain batch 30/31 - 109.3ms/batch - loss: 70.09764 - diff: 25.11mlTrain batch 31/31 - 74.6ms/batch - loss: 69.60372 - diff: 24.92mlTrain batch 31/31 - 9.9s 74.6ms/batch - loss: 69.60372 - diff: 24.92ml
Test 0.8s: val_loss: 50.09222 - diff: 20.95ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_DenseNet121_0_Adam-0.001_MSE_DA3_best

Epoch 61: current best loss = 50.09222, at epoch 60
Train batch 1/31 - 114.7ms/batch - loss: 51.90170 - diff: 24.50mlTrain batch 2/31 - 112.8ms/batch - loss: 45.84978 - diff: 22.87mlTrain batch 3/31 - 120.8ms/batch - loss: 56.80835 - diff: 24.33mlTrain batch 4/31 - 122.3ms/batch - loss: 52.20627 - diff: 23.12mlTrain batch 5/31 - 113.4ms/batch - loss: 46.42523 - diff: 21.89mlTrain batch 6/31 - 109.9ms/batch - loss: 42.86725 - diff: 20.94mlTrain batch 7/31 - 109.8ms/batch - loss: 54.07466 - diff: 23.65mlTrain batch 8/31 - 109.5ms/batch - loss: 52.70708 - diff: 23.54mlTrain batch 9/31 - 120.7ms/batch - loss: 52.73457 - diff: 23.54mlTrain batch 10/31 - 111.2ms/batch - loss: 65.14568 - diff: 24.09mlTrain batch 11/31 - 117.4ms/batch - loss: 66.56944 - diff: 24.82mlTrain batch 12/31 - 110.4ms/batch - loss: 64.14032 - diff: 24.36mlTrain batch 13/31 - 110.4ms/batch - loss: 61.99748 - diff: 24.04mlTrain batch 14/31 - 109.5ms/batch - loss: 63.00472 - diff: 24.25mlTrain batch 15/31 - 109.7ms/batch - loss: 63.87272 - diff: 24.48mlTrain batch 16/31 - 111.0ms/batch - loss: 62.56132 - diff: 24.28mlTrain batch 17/31 - 110.5ms/batch - loss: 62.16423 - diff: 24.25mlTrain batch 18/31 - 109.7ms/batch - loss: 62.85280 - diff: 24.49mlTrain batch 19/31 - 110.1ms/batch - loss: 63.26894 - diff: 24.57mlTrain batch 20/31 - 110.0ms/batch - loss: 67.83412 - diff: 25.36mlTrain batch 21/31 - 110.9ms/batch - loss: 66.49595 - diff: 25.19mlTrain batch 22/31 - 109.9ms/batch - loss: 64.87309 - diff: 24.80mlTrain batch 23/31 - 110.9ms/batch - loss: 66.67842 - diff: 25.09mlTrain batch 24/31 - 109.3ms/batch - loss: 66.17971 - diff: 25.12mlTrain batch 25/31 - 113.2ms/batch - loss: 66.32290 - diff: 25.24mlTrain batch 26/31 - 109.6ms/batch - loss: 64.94329 - diff: 24.95mlTrain batch 27/31 - 112.2ms/batch - loss: 65.26631 - diff: 24.95mlTrain batch 28/31 - 110.0ms/batch - loss: 64.46641 - diff: 24.80mlTrain batch 29/31 - 113.1ms/batch - loss: 63.84020 - diff: 24.74mlTrain batch 30/31 - 109.8ms/batch - loss: 62.26686 - diff: 24.36mlTrain batch 31/31 - 68.8ms/batch - loss: 63.79276 - diff: 24.41mlTrain batch 31/31 - 9.8s 68.8ms/batch - loss: 63.79276 - diff: 24.41ml
Test 0.8s: val_loss: 59.92502 - diff: 22.42ml

Epoch 62: current best loss = 50.09222, at epoch 60
Train batch 1/31 - 113.1ms/batch - loss: 43.46438 - diff: 20.56mlTrain batch 2/31 - 109.4ms/batch - loss: 74.21569 - diff: 26.60mlTrain batch 3/31 - 118.0ms/batch - loss: 67.80561 - diff: 25.23mlTrain batch 4/31 - 110.3ms/batch - loss: 66.85581 - diff: 26.03mlTrain batch 5/31 - 110.4ms/batch - loss: 66.22854 - diff: 26.30mlTrain batch 6/31 - 110.3ms/batch - loss: 58.40555 - diff: 24.14mlTrain batch 7/31 - 111.1ms/batch - loss: 55.25516 - diff: 23.63mlTrain batch 8/31 - 110.5ms/batch - loss: 52.59155 - diff: 22.89mlTrain batch 9/31 - 114.3ms/batch - loss: 71.46458 - diff: 26.04mlTrain batch 10/31 - 110.2ms/batch - loss: 69.99663 - diff: 25.95mlTrain batch 11/31 - 111.7ms/batch - loss: 69.12946 - diff: 26.01mlTrain batch 12/31 - 110.8ms/batch - loss: 66.16699 - diff: 25.30mlTrain batch 13/31 - 110.3ms/batch - loss: 64.41639 - diff: 24.75mlTrain batch 14/31 - 110.2ms/batch - loss: 62.35290 - diff: 24.38mlTrain batch 15/31 - 110.8ms/batch - loss: 60.98104 - diff: 24.15mlTrain batch 16/31 - 110.4ms/batch - loss: 59.92708 - diff: 23.94mlTrain batch 17/31 - 113.7ms/batch - loss: 59.17785 - diff: 23.82mlTrain batch 18/31 - 110.1ms/batch - loss: 57.56749 - diff: 23.58mlTrain batch 19/31 - 111.3ms/batch - loss: 64.91095 - diff: 24.09mlTrain batch 20/31 - 110.9ms/batch - loss: 65.77485 - diff: 24.50mlTrain batch 21/31 - 113.5ms/batch - loss: 64.56674 - diff: 24.30mlTrain batch 22/31 - 111.2ms/batch - loss: 67.29442 - diff: 24.87mlTrain batch 23/31 - 113.7ms/batch - loss: 66.89610 - diff: 24.90mlTrain batch 24/31 - 111.6ms/batch - loss: 66.96493 - diff: 25.00mlTrain batch 25/31 - 110.9ms/batch - loss: 65.90988 - diff: 24.82mlTrain batch 26/31 - 110.8ms/batch - loss: 64.96656 - diff: 24.60mlTrain batch 27/31 - 119.6ms/batch - loss: 67.52419 - diff: 25.18mlTrain batch 28/31 - 110.5ms/batch - loss: 65.80642 - diff: 24.80mlTrain batch 29/31 - 114.3ms/batch - loss: 66.81822 - diff: 25.07mlTrain batch 30/31 - 110.0ms/batch - loss: 65.55345 - diff: 24.88mlTrain batch 31/31 - 69.4ms/batch - loss: 68.09390 - diff: 25.05mlTrain batch 31/31 - 9.8s 69.4ms/batch - loss: 68.09390 - diff: 25.05ml
Test 0.8s: val_loss: 72.26998 - diff: 24.85ml

Epoch 63: current best loss = 50.09222, at epoch 60
Train batch 1/31 - 110.9ms/batch - loss: 61.48678 - diff: 24.40mlTrain batch 2/31 - 110.2ms/batch - loss: 54.78906 - diff: 23.21mlTrain batch 3/31 - 140.3ms/batch - loss: 58.14632 - diff: 24.57mlTrain batch 4/31 - 109.8ms/batch - loss: 48.20775 - diff: 21.59mlTrain batch 5/31 - 110.4ms/batch - loss: 46.17548 - diff: 21.43mlTrain batch 6/31 - 109.5ms/batch - loss: 43.68260 - diff: 20.59mlTrain batch 7/31 - 112.3ms/batch - loss: 39.63285 - diff: 19.47mlTrain batch 8/31 - 109.9ms/batch - loss: 41.29766 - diff: 20.08mlTrain batch 9/31 - 114.8ms/batch - loss: 43.96192 - diff: 20.41mlTrain batch 10/31 - 109.8ms/batch - loss: 42.51183 - diff: 20.09mlTrain batch 11/31 - 110.0ms/batch - loss: 44.76434 - diff: 20.52mlTrain batch 12/31 - 109.8ms/batch - loss: 45.30653 - diff: 20.66mlTrain batch 13/31 - 113.0ms/batch - loss: 44.05364 - diff: 20.32mlTrain batch 14/31 - 109.7ms/batch - loss: 42.99462 - diff: 20.08mlTrain batch 15/31 - 112.3ms/batch - loss: 44.69088 - diff: 20.61mlTrain batch 16/31 - 109.3ms/batch - loss: 43.42509 - diff: 20.30mlTrain batch 17/31 - 110.0ms/batch - loss: 43.99721 - diff: 20.32mlTrain batch 18/31 - 109.5ms/batch - loss: 44.55685 - diff: 20.66mlTrain batch 19/31 - 112.0ms/batch - loss: 44.71185 - diff: 20.80mlTrain batch 20/31 - 110.9ms/batch - loss: 44.42358 - diff: 20.89mlTrain batch 21/31 - 111.2ms/batch - loss: 45.71552 - diff: 21.08mlTrain batch 22/31 - 110.0ms/batch - loss: 48.72619 - diff: 21.78mlTrain batch 23/31 - 110.4ms/batch - loss: 50.91743 - diff: 22.23mlTrain batch 24/31 - 109.8ms/batch - loss: 52.57251 - diff: 22.50mlTrain batch 25/31 - 110.6ms/batch - loss: 52.85919 - diff: 22.55mlTrain batch 26/31 - 110.8ms/batch - loss: 52.89497 - diff: 22.43mlTrain batch 27/31 - 113.8ms/batch - loss: 52.54588 - diff: 22.40mlTrain batch 28/31 - 110.8ms/batch - loss: 51.85735 - diff: 22.26mlTrain batch 29/31 - 111.2ms/batch - loss: 51.99264 - diff: 22.34mlTrain batch 30/31 - 109.1ms/batch - loss: 51.38376 - diff: 22.16mlTrain batch 31/31 - 69.0ms/batch - loss: 52.16439 - diff: 22.20mlTrain batch 31/31 - 9.8s 69.0ms/batch - loss: 52.16439 - diff: 22.20ml
Test 0.8s: val_loss: 74.53657 - diff: 23.04ml

Epoch 64: current best loss = 50.09222, at epoch 60
Train batch 1/31 - 115.8ms/batch - loss: 191.14886 - diff: 46.99mlTrain batch 2/31 - 110.2ms/batch - loss: 122.58926 - diff: 34.65mlTrain batch 3/31 - 144.4ms/batch - loss: 95.29642 - diff: 30.25mlTrain batch 4/31 - 112.7ms/batch - loss: 92.37262 - diff: 29.80mlTrain batch 5/31 - 113.0ms/batch - loss: 76.79404 - diff: 26.23mlTrain batch 6/31 - 109.8ms/batch - loss: 69.57432 - diff: 24.74mlTrain batch 7/31 - 110.1ms/batch - loss: 68.77701 - diff: 24.39mlTrain batch 8/31 - 109.7ms/batch - loss: 64.11886 - diff: 23.74mlTrain batch 9/31 - 113.6ms/batch - loss: 59.47098 - diff: 22.84mlTrain batch 10/31 - 110.3ms/batch - loss: 63.20353 - diff: 23.74mlTrain batch 11/31 - 112.4ms/batch - loss: 60.75496 - diff: 23.52mlTrain batch 12/31 - 109.6ms/batch - loss: 58.90342 - diff: 23.41mlTrain batch 13/31 - 112.8ms/batch - loss: 56.44903 - diff: 22.79mlTrain batch 14/31 - 109.8ms/batch - loss: 61.00870 - diff: 23.61mlTrain batch 15/31 - 110.7ms/batch - loss: 59.15935 - diff: 23.35mlTrain batch 16/31 - 111.0ms/batch - loss: 57.92503 - diff: 23.25mlTrain batch 17/31 - 113.2ms/batch - loss: 56.44406 - diff: 22.97mlTrain batch 18/31 - 109.8ms/batch - loss: 55.63537 - diff: 22.74mlTrain batch 19/31 - 113.1ms/batch - loss: 54.51843 - diff: 22.55mlTrain batch 20/31 - 109.7ms/batch - loss: 57.69323 - diff: 23.12mlTrain batch 21/31 - 111.0ms/batch - loss: 57.19759 - diff: 23.09mlTrain batch 22/31 - 109.9ms/batch - loss: 57.18753 - diff: 23.16mlTrain batch 23/31 - 110.9ms/batch - loss: 55.63157 - diff: 22.79mlTrain batch 24/31 - 109.6ms/batch - loss: 57.64820 - diff: 23.34mlTrain batch 25/31 - 112.6ms/batch - loss: 56.59019 - diff: 23.17mlTrain batch 26/31 - 109.8ms/batch - loss: 58.79156 - diff: 23.58mlTrain batch 27/31 - 110.3ms/batch - loss: 58.49536 - diff: 23.58mlTrain batch 28/31 - 109.8ms/batch - loss: 58.81576 - diff: 23.74mlTrain batch 29/31 - 111.7ms/batch - loss: 61.09042 - diff: 23.91mlTrain batch 30/31 - 109.3ms/batch - loss: 60.24280 - diff: 23.78mlTrain batch 31/31 - 71.9ms/batch - loss: 61.03733 - diff: 23.79mlTrain batch 31/31 - 9.9s 71.9ms/batch - loss: 61.03733 - diff: 23.79ml
Test 0.8s: val_loss: 59.93054 - diff: 21.58ml

Epoch 65: current best loss = 50.09222, at epoch 60
Train batch 1/31 - 111.3ms/batch - loss: 46.17997 - diff: 21.33mlTrain batch 2/31 - 115.8ms/batch - loss: 38.95473 - diff: 20.33mlTrain batch 3/31 - 114.8ms/batch - loss: 50.24831 - diff: 23.59mlTrain batch 4/31 - 110.2ms/batch - loss: 46.33461 - diff: 22.14mlTrain batch 5/31 - 112.2ms/batch - loss: 41.48563 - diff: 20.84mlTrain batch 6/31 - 111.3ms/batch - loss: 50.69472 - diff: 23.33mlTrain batch 7/31 - 113.2ms/batch - loss: 49.65004 - diff: 23.08mlTrain batch 8/31 - 110.6ms/batch - loss: 48.20983 - diff: 22.70mlTrain batch 9/31 - 119.6ms/batch - loss: 46.32933 - diff: 21.97mlTrain batch 10/31 - 110.4ms/batch - loss: 44.46069 - diff: 21.42mlTrain batch 11/31 - 113.6ms/batch - loss: 44.58228 - diff: 21.42mlTrain batch 12/31 - 110.3ms/batch - loss: 49.88742 - diff: 21.90mlTrain batch 13/31 - 113.3ms/batch - loss: 48.05795 - diff: 21.47mlTrain batch 14/31 - 109.7ms/batch - loss: 49.32376 - diff: 21.78mlTrain batch 15/31 - 118.4ms/batch - loss: 49.01664 - diff: 21.72mlTrain batch 16/31 - 112.1ms/batch - loss: 50.27849 - diff: 21.93mlTrain batch 17/31 - 112.0ms/batch - loss: 51.38222 - diff: 22.19mlTrain batch 18/31 - 113.0ms/batch - loss: 51.08370 - diff: 22.25mlTrain batch 19/31 - 113.7ms/batch - loss: 53.04565 - diff: 22.62mlTrain batch 20/31 - 110.8ms/batch - loss: 53.27290 - diff: 22.76mlTrain batch 21/31 - 112.7ms/batch - loss: 52.66514 - diff: 22.55mlTrain batch 22/31 - 113.0ms/batch - loss: 52.30313 - diff: 22.49mlTrain batch 23/31 - 111.0ms/batch - loss: 53.76873 - diff: 22.84mlTrain batch 24/31 - 113.5ms/batch - loss: 53.74424 - diff: 22.81mlTrain batch 25/31 - 112.4ms/batch - loss: 53.65755 - diff: 22.87mlTrain batch 26/31 - 114.5ms/batch - loss: 54.40241 - diff: 22.87mlTrain batch 27/31 - 111.9ms/batch - loss: 54.11063 - diff: 22.90mlTrain batch 28/31 - 114.0ms/batch - loss: 54.12502 - diff: 22.93mlTrain batch 29/31 - 113.5ms/batch - loss: 54.40092 - diff: 22.98mlTrain batch 30/31 - 111.0ms/batch - loss: 53.55558 - diff: 22.82mlTrain batch 31/31 - 69.6ms/batch - loss: 60.43021 - diff: 23.31mlTrain batch 31/31 - 9.8s 69.6ms/batch - loss: 60.43021 - diff: 23.31ml
Test 0.8s: val_loss: 53.95784 - diff: 21.05ml

Epoch 66: current best loss = 50.09222, at epoch 60
Train batch 1/31 - 148.3ms/batch - loss: 39.58314 - diff: 18.62mlTrain batch 2/31 - 130.1ms/batch - loss: 39.77956 - diff: 19.80mlTrain batch 3/31 - 113.9ms/batch - loss: 35.36287 - diff: 18.44mlTrain batch 4/31 - 110.1ms/batch - loss: 36.38625 - diff: 18.72mlTrain batch 5/31 - 111.5ms/batch - loss: 36.15549 - diff: 19.02mlTrain batch 6/31 - 111.4ms/batch - loss: 39.56920 - diff: 19.87mlTrain batch 7/31 - 110.3ms/batch - loss: 37.95030 - diff: 19.41mlTrain batch 8/31 - 110.6ms/batch - loss: 46.77493 - diff: 20.45mlTrain batch 9/31 - 110.6ms/batch - loss: 44.09008 - diff: 19.94mlTrain batch 10/31 - 110.4ms/batch - loss: 47.76289 - diff: 20.78mlTrain batch 11/31 - 109.8ms/batch - loss: 48.21247 - diff: 20.96mlTrain batch 12/31 - 110.1ms/batch - loss: 48.98801 - diff: 21.13mlTrain batch 13/31 - 111.2ms/batch - loss: 48.55505 - diff: 21.13mlTrain batch 14/31 - 110.7ms/batch - loss: 49.82279 - diff: 21.30mlTrain batch 15/31 - 110.2ms/batch - loss: 49.59255 - diff: 21.36mlTrain batch 16/31 - 110.0ms/batch - loss: 48.09071 - diff: 21.04mlTrain batch 17/31 - 109.9ms/batch - loss: 48.17015 - diff: 21.16mlTrain batch 18/31 - 110.0ms/batch - loss: 51.36520 - diff: 21.09mlTrain batch 19/31 - 111.2ms/batch - loss: 54.69245 - diff: 21.82mlTrain batch 20/31 - 110.9ms/batch - loss: 53.57469 - diff: 21.64mlTrain batch 21/31 - 110.1ms/batch - loss: 52.37264 - diff: 21.43mlTrain batch 22/31 - 109.8ms/batch - loss: 51.67712 - diff: 21.41mlTrain batch 23/31 - 109.7ms/batch - loss: 51.88066 - diff: 21.54mlTrain batch 24/31 - 109.7ms/batch - loss: 50.93520 - diff: 21.34mlTrain batch 25/31 - 110.2ms/batch - loss: 50.22160 - diff: 21.19mlTrain batch 26/31 - 110.3ms/batch - loss: 50.75761 - diff: 21.43mlTrain batch 27/31 - 110.4ms/batch - loss: 50.54716 - diff: 21.45mlTrain batch 28/31 - 109.7ms/batch - loss: 50.53590 - diff: 21.52mlTrain batch 29/31 - 109.1ms/batch - loss: 49.85711 - diff: 21.42mlTrain batch 30/31 - 109.2ms/batch - loss: 49.14674 - diff: 21.33mlTrain batch 31/31 - 69.6ms/batch - loss: 49.49088 - diff: 21.28mlTrain batch 31/31 - 9.9s 69.6ms/batch - loss: 49.49088 - diff: 21.28ml
Test 0.9s: val_loss: 54.88120 - diff: 21.89ml

Epoch 67: current best loss = 50.09222, at epoch 60
Train batch 1/31 - 118.6ms/batch - loss: 25.53505 - diff: 16.16mlTrain batch 2/31 - 110.6ms/batch - loss: 29.21614 - diff: 16.74mlTrain batch 3/31 - 112.7ms/batch - loss: 42.70441 - diff: 20.12mlTrain batch 4/31 - 110.6ms/batch - loss: 39.08839 - diff: 20.07mlTrain batch 5/31 - 112.4ms/batch - loss: 36.25655 - diff: 19.19mlTrain batch 6/31 - 110.2ms/batch - loss: 35.46830 - diff: 19.07mlTrain batch 7/31 - 110.2ms/batch - loss: 33.92075 - diff: 18.71mlTrain batch 8/31 - 112.1ms/batch - loss: 35.55534 - diff: 19.19mlTrain batch 9/31 - 112.7ms/batch - loss: 43.59396 - diff: 21.21mlTrain batch 10/31 - 110.9ms/batch - loss: 46.78356 - diff: 21.86mlTrain batch 11/31 - 109.8ms/batch - loss: 50.04533 - diff: 22.90mlTrain batch 12/31 - 110.7ms/batch - loss: 47.19669 - diff: 22.17mlTrain batch 13/31 - 110.1ms/batch - loss: 45.94696 - diff: 21.98mlTrain batch 14/31 - 111.3ms/batch - loss: 45.76952 - diff: 21.97mlTrain batch 15/31 - 110.1ms/batch - loss: 46.07765 - diff: 22.01mlTrain batch 16/31 - 111.2ms/batch - loss: 45.27458 - diff: 21.74mlTrain batch 17/31 - 110.0ms/batch - loss: 46.46014 - diff: 21.74mlTrain batch 18/31 - 110.2ms/batch - loss: 52.34273 - diff: 22.85mlTrain batch 19/31 - 109.7ms/batch - loss: 51.49490 - diff: 22.77mlTrain batch 20/31 - 111.5ms/batch - loss: 56.25725 - diff: 23.05mlTrain batch 21/31 - 110.3ms/batch - loss: 56.69852 - diff: 23.19mlTrain batch 22/31 - 117.0ms/batch - loss: 56.14890 - diff: 23.12mlTrain batch 23/31 - 110.6ms/batch - loss: 56.15274 - diff: 23.10mlTrain batch 24/31 - 115.6ms/batch - loss: 56.52152 - diff: 23.14mlTrain batch 25/31 - 109.7ms/batch - loss: 56.17399 - diff: 23.08mlTrain batch 26/31 - 111.0ms/batch - loss: 55.84452 - diff: 23.17mlTrain batch 27/31 - 110.4ms/batch - loss: 54.65936 - diff: 22.85mlTrain batch 28/31 - 112.9ms/batch - loss: 59.82885 - diff: 23.56mlTrain batch 29/31 - 109.4ms/batch - loss: 60.86121 - diff: 23.58mlTrain batch 30/31 - 110.5ms/batch - loss: 59.96100 - diff: 23.43mlTrain batch 31/31 - 70.8ms/batch - loss: 61.80830 - diff: 23.48mlTrain batch 31/31 - 9.8s 70.8ms/batch - loss: 61.80830 - diff: 23.48ml
Test 0.8s: val_loss: 60.24238 - diff: 23.02ml

Epoch 68: current best loss = 50.09222, at epoch 60
Train batch 1/31 - 112.2ms/batch - loss: 169.26642 - diff: 36.94mlTrain batch 2/31 - 109.6ms/batch - loss: 125.63610 - diff: 33.44mlTrain batch 3/31 - 112.6ms/batch - loss: 94.50937 - diff: 28.96mlTrain batch 4/31 - 110.7ms/batch - loss: 92.82891 - diff: 28.87mlTrain batch 5/31 - 111.1ms/batch - loss: 79.37931 - diff: 26.45mlTrain batch 6/31 - 110.0ms/batch - loss: 73.43430 - diff: 25.65mlTrain batch 7/31 - 111.3ms/batch - loss: 71.01495 - diff: 25.43mlTrain batch 8/31 - 109.9ms/batch - loss: 67.05599 - diff: 24.59mlTrain batch 9/31 - 113.6ms/batch - loss: 64.10266 - diff: 24.31mlTrain batch 10/31 - 110.6ms/batch - loss: 67.61719 - diff: 25.02mlTrain batch 11/31 - 111.5ms/batch - loss: 67.44773 - diff: 25.38mlTrain batch 12/31 - 109.7ms/batch - loss: 67.34644 - diff: 25.43mlTrain batch 13/31 - 111.8ms/batch - loss: 65.37725 - diff: 24.97mlTrain batch 14/31 - 109.8ms/batch - loss: 64.21742 - diff: 24.97mlTrain batch 15/31 - 110.6ms/batch - loss: 63.11742 - diff: 24.88mlTrain batch 16/31 - 109.9ms/batch - loss: 64.52292 - diff: 25.21mlTrain batch 17/31 - 111.4ms/batch - loss: 70.48564 - diff: 25.57mlTrain batch 18/31 - 110.1ms/batch - loss: 67.77828 - diff: 24.92mlTrain batch 19/31 - 110.6ms/batch - loss: 65.74145 - diff: 24.47mlTrain batch 20/31 - 109.6ms/batch - loss: 64.36742 - diff: 24.37mlTrain batch 21/31 - 110.0ms/batch - loss: 65.32847 - diff: 24.47mlTrain batch 22/31 - 109.9ms/batch - loss: 64.07208 - diff: 24.13mlTrain batch 23/31 - 110.5ms/batch - loss: 65.13145 - diff: 24.47mlTrain batch 24/31 - 110.2ms/batch - loss: 63.38269 - diff: 24.08mlTrain batch 25/31 - 112.4ms/batch - loss: 62.39757 - diff: 23.85mlTrain batch 26/31 - 110.3ms/batch - loss: 61.36050 - diff: 23.62mlTrain batch 27/31 - 111.5ms/batch - loss: 61.86961 - diff: 23.73mlTrain batch 28/31 - 109.8ms/batch - loss: 63.04737 - diff: 24.06mlTrain batch 29/31 - 109.0ms/batch - loss: 62.24279 - diff: 23.92mlTrain batch 30/31 - 109.2ms/batch - loss: 62.52597 - diff: 24.03mlTrain batch 31/31 - 68.7ms/batch - loss: 62.72209 - diff: 23.97mlTrain batch 31/31 - 9.8s 68.7ms/batch - loss: 62.72209 - diff: 23.97ml
Test 0.9s: val_loss: 86.35496 - diff: 25.74ml

Epoch 69: current best loss = 50.09222, at epoch 60
Train batch 1/31 - 110.3ms/batch - loss: 69.64642 - diff: 26.11mlTrain batch 2/31 - 110.9ms/batch - loss: 66.86584 - diff: 26.15mlTrain batch 3/31 - 113.7ms/batch - loss: 69.92243 - diff: 27.12mlTrain batch 4/31 - 111.4ms/batch - loss: 79.00138 - diff: 28.91mlTrain batch 5/31 - 113.9ms/batch - loss: 70.85548 - diff: 26.72mlTrain batch 6/31 - 111.9ms/batch - loss: 66.18192 - diff: 25.81mlTrain batch 7/31 - 113.8ms/batch - loss: 71.68688 - diff: 26.98mlTrain batch 8/31 - 111.2ms/batch - loss: 77.94652 - diff: 27.41mlTrain batch 9/31 - 109.4ms/batch - loss: 74.04171 - diff: 26.83mlTrain batch 10/31 - 109.8ms/batch - loss: 68.53886 - diff: 25.41mlTrain batch 11/31 - 112.9ms/batch - loss: 67.38607 - diff: 25.36mlTrain batch 12/31 - 110.2ms/batch - loss: 65.93797 - diff: 24.82mlTrain batch 13/31 - 110.8ms/batch - loss: 63.85101 - diff: 24.52mlTrain batch 14/31 - 113.7ms/batch - loss: 63.68515 - diff: 24.64mlTrain batch 15/31 - 111.9ms/batch - loss: 60.59841 - diff: 23.96mlTrain batch 16/31 - 111.9ms/batch - loss: 57.99350 - diff: 23.31mlTrain batch 17/31 - 111.6ms/batch - loss: 61.97461 - diff: 23.95mlTrain batch 18/31 - 111.9ms/batch - loss: 62.08832 - diff: 23.92mlTrain batch 19/31 - 110.4ms/batch - loss: 60.60909 - diff: 23.69mlTrain batch 20/31 - 110.7ms/batch - loss: 58.75943 - diff: 23.31mlTrain batch 21/31 - 110.7ms/batch - loss: 59.98650 - diff: 23.60mlTrain batch 22/31 - 112.1ms/batch - loss: 59.10642 - diff: 23.53mlTrain batch 23/31 - 110.7ms/batch - loss: 61.89287 - diff: 24.06mlTrain batch 24/31 - 111.5ms/batch - loss: 61.22123 - diff: 23.98mlTrain batch 25/31 - 109.9ms/batch - loss: 60.84044 - diff: 24.00mlTrain batch 26/31 - 111.5ms/batch - loss: 60.48491 - diff: 23.94mlTrain batch 27/31 - 109.9ms/batch - loss: 59.16445 - diff: 23.67mlTrain batch 28/31 - 116.5ms/batch - loss: 58.94511 - diff: 23.71mlTrain batch 29/31 - 109.2ms/batch - loss: 59.32748 - diff: 23.88mlTrain batch 30/31 - 110.4ms/batch - loss: 58.67870 - diff: 23.72mlTrain batch 31/31 - 69.3ms/batch - loss: 59.37655 - diff: 23.73mlTrain batch 31/31 - 9.8s 69.3ms/batch - loss: 59.37655 - diff: 23.73ml
Test 0.9s: val_loss: 77.71145 - diff: 25.39ml

Epoch 70: current best loss = 50.09222, at epoch 60
Train batch 1/31 - 113.9ms/batch - loss: 71.87407 - diff: 28.99mlTrain batch 2/31 - 112.0ms/batch - loss: 54.02974 - diff: 25.12mlTrain batch 3/31 - 120.8ms/batch - loss: 73.48529 - diff: 28.09mlTrain batch 4/31 - 110.9ms/batch - loss: 66.07047 - diff: 26.70mlTrain batch 5/31 - 114.6ms/batch - loss: 58.42486 - diff: 24.70mlTrain batch 6/31 - 110.9ms/batch - loss: 62.32978 - diff: 25.48mlTrain batch 7/31 - 112.4ms/batch - loss: 62.00494 - diff: 25.66mlTrain batch 8/31 - 111.2ms/batch - loss: 62.52887 - diff: 25.18mlTrain batch 9/31 - 112.6ms/batch - loss: 59.72913 - diff: 24.67mlTrain batch 10/31 - 111.8ms/batch - loss: 57.13445 - diff: 24.21mlTrain batch 11/31 - 115.4ms/batch - loss: 59.66583 - diff: 24.56mlTrain batch 12/31 - 111.1ms/batch - loss: 57.35793 - diff: 24.04mlTrain batch 13/31 - 115.4ms/batch - loss: 54.56702 - diff: 23.32mlTrain batch 14/31 - 114.0ms/batch - loss: 53.65961 - diff: 23.10mlTrain batch 15/31 - 112.7ms/batch - loss: 53.98072 - diff: 23.15mlTrain batch 16/31 - 112.7ms/batch - loss: 53.58519 - diff: 23.05mlTrain batch 17/31 - 111.4ms/batch - loss: 52.82016 - diff: 22.83mlTrain batch 18/31 - 111.4ms/batch - loss: 57.62373 - diff: 23.83mlTrain batch 19/31 - 114.1ms/batch - loss: 60.67415 - diff: 24.30mlTrain batch 20/31 - 112.8ms/batch - loss: 60.82831 - diff: 24.21mlTrain batch 21/31 - 113.0ms/batch - loss: 59.45796 - diff: 23.88mlTrain batch 22/31 - 112.8ms/batch - loss: 58.97639 - diff: 23.90mlTrain batch 23/31 - 112.2ms/batch - loss: 60.58205 - diff: 24.31mlTrain batch 24/31 - 114.0ms/batch - loss: 59.88587 - diff: 24.13mlTrain batch 25/31 - 112.0ms/batch - loss: 59.42729 - diff: 23.99mlTrain batch 26/31 - 113.3ms/batch - loss: 57.61146 - diff: 23.53mlTrain batch 27/31 - 112.3ms/batch - loss: 56.69989 - diff: 23.33mlTrain batch 28/31 - 112.2ms/batch - loss: 56.50485 - diff: 23.30mlTrain batch 29/31 - 111.9ms/batch - loss: 55.93873 - diff: 23.26mlTrain batch 30/31 - 110.3ms/batch - loss: 55.88208 - diff: 23.21mlTrain batch 31/31 - 69.3ms/batch - loss: 56.86620 - diff: 23.23mlTrain batch 31/31 - 9.7s 69.3ms/batch - loss: 56.86620 - diff: 23.23ml
Test 0.9s: val_loss: 67.60181 - diff: 24.45ml

Epoch 71: current best loss = 50.09222, at epoch 60
Train batch 1/31 - 133.5ms/batch - loss: 81.76770 - diff: 23.69mlTrain batch 2/31 - 110.6ms/batch - loss: 60.91237 - diff: 20.81mlTrain batch 3/31 - 110.4ms/batch - loss: 53.44964 - diff: 20.30mlTrain batch 4/31 - 110.7ms/batch - loss: 49.51739 - diff: 19.55mlTrain batch 5/31 - 110.5ms/batch - loss: 45.27909 - diff: 18.98mlTrain batch 6/31 - 111.2ms/batch - loss: 45.54039 - diff: 19.41mlTrain batch 7/31 - 111.8ms/batch - loss: 41.78472 - diff: 18.81mlTrain batch 8/31 - 110.5ms/batch - loss: 40.40215 - diff: 18.78mlTrain batch 9/31 - 112.0ms/batch - loss: 40.53711 - diff: 19.08mlTrain batch 10/31 - 110.3ms/batch - loss: 44.59477 - diff: 19.56mlTrain batch 11/31 - 114.0ms/batch - loss: 44.87860 - diff: 19.77mlTrain batch 12/31 - 109.9ms/batch - loss: 50.37908 - diff: 20.41mlTrain batch 13/31 - 113.0ms/batch - loss: 50.76246 - diff: 20.54mlTrain batch 14/31 - 110.6ms/batch - loss: 52.92167 - diff: 21.23mlTrain batch 15/31 - 110.7ms/batch - loss: 50.94027 - diff: 20.85mlTrain batch 16/31 - 111.9ms/batch - loss: 50.09640 - diff: 20.75mlTrain batch 17/31 - 114.8ms/batch - loss: 51.61804 - diff: 20.77mlTrain batch 18/31 - 110.3ms/batch - loss: 51.15776 - diff: 20.72mlTrain batch 19/31 - 111.6ms/batch - loss: 50.26667 - diff: 20.63mlTrain batch 20/31 - 110.8ms/batch - loss: 49.48165 - diff: 20.59mlTrain batch 21/31 - 113.5ms/batch - loss: 52.50451 - diff: 21.22mlTrain batch 22/31 - 111.3ms/batch - loss: 52.34188 - diff: 21.29mlTrain batch 23/31 - 113.9ms/batch - loss: 51.71875 - diff: 21.24mlTrain batch 24/31 - 112.3ms/batch - loss: 55.82511 - diff: 21.80mlTrain batch 25/31 - 112.4ms/batch - loss: 56.33798 - diff: 22.06mlTrain batch 26/31 - 110.3ms/batch - loss: 56.78380 - diff: 22.14mlTrain batch 27/31 - 114.7ms/batch - loss: 56.37680 - diff: 22.20mlTrain batch 28/31 - 110.2ms/batch - loss: 55.98891 - diff: 22.20mlTrain batch 29/31 - 110.1ms/batch - loss: 55.25734 - diff: 22.09mlTrain batch 30/31 - 109.0ms/batch - loss: 54.53715 - diff: 22.04mlTrain batch 31/31 - 70.3ms/batch - loss: 54.54819 - diff: 21.95mlTrain batch 31/31 - 9.8s 70.3ms/batch - loss: 54.54819 - diff: 21.95ml
Test 1.0s: val_loss: 70.32477 - diff: 22.80ml
Epoch    72: reducing learning rate of group 0 to 5.0000e-04.

Epoch 72: current best loss = 50.09222, at epoch 60
Train batch 1/31 - 113.8ms/batch - loss: 45.53848 - diff: 22.37mlTrain batch 2/31 - 109.5ms/batch - loss: 48.90144 - diff: 23.38mlTrain batch 3/31 - 112.6ms/batch - loss: 59.60875 - diff: 27.12mlTrain batch 4/31 - 109.5ms/batch - loss: 53.17015 - diff: 25.08mlTrain batch 5/31 - 110.6ms/batch - loss: 49.55008 - diff: 23.12mlTrain batch 6/31 - 109.3ms/batch - loss: 46.79636 - diff: 22.13mlTrain batch 7/31 - 110.2ms/batch - loss: 47.21750 - diff: 22.16mlTrain batch 8/31 - 109.6ms/batch - loss: 44.63745 - diff: 21.42mlTrain batch 9/31 - 113.3ms/batch - loss: 45.04619 - diff: 21.61mlTrain batch 10/31 - 110.3ms/batch - loss: 43.85976 - diff: 21.24mlTrain batch 11/31 - 112.2ms/batch - loss: 43.16437 - diff: 21.18mlTrain batch 12/31 - 109.7ms/batch - loss: 44.24027 - diff: 21.33mlTrain batch 13/31 - 111.0ms/batch - loss: 44.54801 - diff: 21.36mlTrain batch 14/31 - 110.0ms/batch - loss: 44.43710 - diff: 21.44mlTrain batch 15/31 - 111.6ms/batch - loss: 44.33506 - diff: 21.21mlTrain batch 16/31 - 110.7ms/batch - loss: 43.29176 - diff: 21.03mlTrain batch 17/31 - 110.9ms/batch - loss: 42.44133 - diff: 20.84mlTrain batch 18/31 - 109.7ms/batch - loss: 42.64743 - diff: 20.84mlTrain batch 19/31 - 111.0ms/batch - loss: 43.26289 - diff: 21.08mlTrain batch 20/31 - 110.1ms/batch - loss: 42.78169 - diff: 20.89mlTrain batch 21/31 - 110.1ms/batch - loss: 42.14028 - diff: 20.75mlTrain batch 22/31 - 109.6ms/batch - loss: 41.40447 - diff: 20.53mlTrain batch 23/31 - 110.2ms/batch - loss: 41.82328 - diff: 20.69mlTrain batch 24/31 - 109.5ms/batch - loss: 42.00321 - diff: 20.76mlTrain batch 25/31 - 112.8ms/batch - loss: 41.89893 - diff: 20.81mlTrain batch 26/31 - 109.9ms/batch - loss: 40.90849 - diff: 20.54mlTrain batch 27/31 - 112.5ms/batch - loss: 41.68199 - diff: 20.77mlTrain batch 28/31 - 110.4ms/batch - loss: 41.35701 - diff: 20.67mlTrain batch 29/31 - 110.6ms/batch - loss: 40.49657 - diff: 20.42mlTrain batch 30/31 - 109.8ms/batch - loss: 40.45730 - diff: 20.46mlTrain batch 31/31 - 73.2ms/batch - loss: 43.39293 - diff: 20.61mlTrain batch 31/31 - 9.8s 73.2ms/batch - loss: 43.39293 - diff: 20.61ml
Test 0.9s: val_loss: 40.99396 - diff: 18.48ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_DenseNet121_0_Adam-0.001_MSE_DA3_best

Epoch 73: current best loss = 40.99396, at epoch 72
Train batch 1/31 - 112.1ms/batch - loss: 16.35830 - diff: 13.09mlTrain batch 2/31 - 110.4ms/batch - loss: 42.07310 - diff: 18.33mlTrain batch 3/31 - 109.9ms/batch - loss: 34.86859 - diff: 16.53mlTrain batch 4/31 - 110.7ms/batch - loss: 30.26600 - diff: 15.74mlTrain batch 5/31 - 111.3ms/batch - loss: 29.80349 - diff: 15.60mlTrain batch 6/31 - 111.5ms/batch - loss: 30.28005 - diff: 15.85mlTrain batch 7/31 - 113.5ms/batch - loss: 27.70214 - diff: 15.19mlTrain batch 8/31 - 110.0ms/batch - loss: 29.70410 - diff: 15.93mlTrain batch 9/31 - 111.1ms/batch - loss: 28.43437 - diff: 15.63mlTrain batch 10/31 - 110.7ms/batch - loss: 28.99538 - diff: 16.14mlTrain batch 11/31 - 111.0ms/batch - loss: 29.46719 - diff: 16.36mlTrain batch 12/31 - 110.9ms/batch - loss: 29.49940 - diff: 16.47mlTrain batch 13/31 - 110.5ms/batch - loss: 32.11616 - diff: 17.11mlTrain batch 14/31 - 109.8ms/batch - loss: 31.63258 - diff: 17.12mlTrain batch 15/31 - 110.3ms/batch - loss: 32.67422 - diff: 17.55mlTrain batch 16/31 - 110.1ms/batch - loss: 31.79244 - diff: 17.31mlTrain batch 17/31 - 110.0ms/batch - loss: 32.10971 - diff: 17.53mlTrain batch 18/31 - 109.9ms/batch - loss: 31.72400 - diff: 17.47mlTrain batch 19/31 - 110.0ms/batch - loss: 36.92237 - diff: 18.64mlTrain batch 20/31 - 109.6ms/batch - loss: 37.49905 - diff: 18.88mlTrain batch 21/31 - 110.5ms/batch - loss: 36.59862 - diff: 18.67mlTrain batch 22/31 - 110.8ms/batch - loss: 37.45365 - diff: 18.94mlTrain batch 23/31 - 110.8ms/batch - loss: 37.31289 - diff: 18.92mlTrain batch 24/31 - 110.8ms/batch - loss: 36.55450 - diff: 18.70mlTrain batch 25/31 - 110.4ms/batch - loss: 37.52918 - diff: 18.81mlTrain batch 26/31 - 109.9ms/batch - loss: 37.71370 - diff: 18.92mlTrain batch 27/31 - 111.0ms/batch - loss: 38.20462 - diff: 19.10mlTrain batch 28/31 - 110.5ms/batch - loss: 38.12269 - diff: 19.10mlTrain batch 29/31 - 114.6ms/batch - loss: 38.03625 - diff: 19.11mlTrain batch 30/31 - 110.3ms/batch - loss: 37.80063 - diff: 19.08mlTrain batch 31/31 - 70.9ms/batch - loss: 39.49182 - diff: 19.21mlTrain batch 31/31 - 9.8s 70.9ms/batch - loss: 39.49182 - diff: 19.21ml
Test 0.8s: val_loss: 40.50170 - diff: 18.88ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_DenseNet121_0_Adam-0.001_MSE_DA3_best

Epoch 74: current best loss = 40.50170, at epoch 73
Train batch 1/31 - 127.9ms/batch - loss: 35.57036 - diff: 18.10mlTrain batch 2/31 - 111.2ms/batch - loss: 28.39180 - diff: 16.34mlTrain batch 3/31 - 121.7ms/batch - loss: 30.02047 - diff: 16.62mlTrain batch 4/31 - 112.1ms/batch - loss: 28.29455 - diff: 16.29mlTrain batch 5/31 - 122.8ms/batch - loss: 27.84336 - diff: 16.18mlTrain batch 6/31 - 110.6ms/batch - loss: 25.54486 - diff: 15.32mlTrain batch 7/31 - 115.7ms/batch - loss: 27.34370 - diff: 15.80mlTrain batch 8/31 - 110.3ms/batch - loss: 27.43840 - diff: 16.12mlTrain batch 9/31 - 113.7ms/batch - loss: 27.27083 - diff: 16.16mlTrain batch 10/31 - 111.5ms/batch - loss: 30.10187 - diff: 16.77mlTrain batch 11/31 - 120.2ms/batch - loss: 30.79343 - diff: 17.09mlTrain batch 12/31 - 110.6ms/batch - loss: 32.51305 - diff: 17.39mlTrain batch 13/31 - 111.5ms/batch - loss: 45.83957 - diff: 19.89mlTrain batch 14/31 - 110.9ms/batch - loss: 44.09920 - diff: 19.61mlTrain batch 15/31 - 112.2ms/batch - loss: 42.59473 - diff: 19.33mlTrain batch 16/31 - 111.3ms/batch - loss: 45.12603 - diff: 20.21mlTrain batch 17/31 - 111.2ms/batch - loss: 54.13431 - diff: 21.94mlTrain batch 18/31 - 110.1ms/batch - loss: 52.63542 - diff: 21.63mlTrain batch 19/31 - 114.5ms/batch - loss: 51.86358 - diff: 21.57mlTrain batch 20/31 - 111.0ms/batch - loss: 50.54944 - diff: 21.39mlTrain batch 21/31 - 131.8ms/batch - loss: 49.33980 - diff: 21.08mlTrain batch 22/31 - 111.2ms/batch - loss: 48.63931 - diff: 21.03mlTrain batch 23/31 - 116.3ms/batch - loss: 47.14089 - diff: 20.68mlTrain batch 24/31 - 110.4ms/batch - loss: 46.09827 - diff: 20.37mlTrain batch 25/31 - 121.2ms/batch - loss: 46.24257 - diff: 20.43mlTrain batch 26/31 - 109.5ms/batch - loss: 45.84946 - diff: 20.44mlTrain batch 27/31 - 137.6ms/batch - loss: 45.28271 - diff: 20.28mlTrain batch 28/31 - 110.3ms/batch - loss: 44.32947 - diff: 20.05mlTrain batch 29/31 - 109.5ms/batch - loss: 43.61671 - diff: 19.90mlTrain batch 30/31 - 109.1ms/batch - loss: 43.64133 - diff: 20.02mlTrain batch 31/31 - 68.8ms/batch - loss: 44.15120 - diff: 20.01mlTrain batch 31/31 - 9.9s 68.8ms/batch - loss: 44.15120 - diff: 20.01ml
Test 0.8s: val_loss: 39.91883 - diff: 18.17ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_DenseNet121_0_Adam-0.001_MSE_DA3_best

Epoch 75: current best loss = 39.91883, at epoch 74
Train batch 1/31 - 111.2ms/batch - loss: 22.10368 - diff: 12.91mlTrain batch 2/31 - 110.3ms/batch - loss: 20.67122 - diff: 13.35mlTrain batch 3/31 - 113.0ms/batch - loss: 22.91607 - diff: 14.35mlTrain batch 4/31 - 109.6ms/batch - loss: 23.42839 - diff: 14.37mlTrain batch 5/31 - 113.1ms/batch - loss: 20.48857 - diff: 13.51mlTrain batch 6/31 - 109.6ms/batch - loss: 29.83441 - diff: 15.91mlTrain batch 7/31 - 112.3ms/batch - loss: 30.23992 - diff: 16.40mlTrain batch 8/31 - 109.6ms/batch - loss: 29.03926 - diff: 16.19mlTrain batch 9/31 - 112.9ms/batch - loss: 28.58708 - diff: 16.08mlTrain batch 10/31 - 109.5ms/batch - loss: 28.03099 - diff: 16.08mlTrain batch 11/31 - 111.6ms/batch - loss: 32.37948 - diff: 16.90mlTrain batch 12/31 - 109.9ms/batch - loss: 32.08631 - diff: 17.02mlTrain batch 13/31 - 112.4ms/batch - loss: 32.33394 - diff: 17.32mlTrain batch 14/31 - 109.8ms/batch - loss: 33.41587 - diff: 17.85mlTrain batch 15/31 - 111.2ms/batch - loss: 34.82444 - diff: 18.51mlTrain batch 16/31 - 109.6ms/batch - loss: 34.03974 - diff: 18.27mlTrain batch 17/31 - 112.8ms/batch - loss: 33.91164 - diff: 18.13mlTrain batch 18/31 - 109.7ms/batch - loss: 32.46751 - diff: 17.63mlTrain batch 19/31 - 111.7ms/batch - loss: 32.11499 - diff: 17.50mlTrain batch 20/31 - 109.9ms/batch - loss: 32.16601 - diff: 17.49mlTrain batch 21/31 - 112.4ms/batch - loss: 31.91051 - diff: 17.33mlTrain batch 22/31 - 109.5ms/batch - loss: 31.76678 - diff: 17.34mlTrain batch 23/31 - 112.7ms/batch - loss: 31.76627 - diff: 17.36mlTrain batch 24/31 - 109.6ms/batch - loss: 31.46594 - diff: 17.33mlTrain batch 25/31 - 112.8ms/batch - loss: 31.07253 - diff: 17.23mlTrain batch 26/31 - 113.6ms/batch - loss: 30.94020 - diff: 17.19mlTrain batch 27/31 - 112.3ms/batch - loss: 30.99250 - diff: 17.21mlTrain batch 28/31 - 111.2ms/batch - loss: 31.42524 - diff: 17.36mlTrain batch 29/31 - 112.3ms/batch - loss: 32.87113 - diff: 17.73mlTrain batch 30/31 - 109.4ms/batch - loss: 32.99162 - diff: 17.73mlTrain batch 31/31 - 75.4ms/batch - loss: 33.93932 - diff: 17.79mlTrain batch 31/31 - 9.8s 75.4ms/batch - loss: 33.93932 - diff: 17.79ml
Test 0.8s: val_loss: 38.39519 - diff: 18.67ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_DenseNet121_0_Adam-0.001_MSE_DA3_best

Epoch 76: current best loss = 38.39519, at epoch 75
Train batch 1/31 - 124.0ms/batch - loss: 133.51183 - diff: 31.93mlTrain batch 2/31 - 109.8ms/batch - loss: 85.28798 - diff: 26.03mlTrain batch 3/31 - 118.5ms/batch - loss: 63.60734 - diff: 22.19mlTrain batch 4/31 - 111.6ms/batch - loss: 98.52474 - diff: 29.60mlTrain batch 5/31 - 110.8ms/batch - loss: 83.05476 - diff: 26.42mlTrain batch 6/31 - 110.3ms/batch - loss: 76.27783 - diff: 25.16mlTrain batch 7/31 - 111.0ms/batch - loss: 67.84167 - diff: 23.56mlTrain batch 8/31 - 110.3ms/batch - loss: 61.64880 - diff: 22.36mlTrain batch 9/31 - 110.5ms/batch - loss: 58.29289 - diff: 22.03mlTrain batch 10/31 - 111.3ms/batch - loss: 55.20945 - diff: 21.53mlTrain batch 11/31 - 110.4ms/batch - loss: 53.20712 - diff: 21.24mlTrain batch 12/31 - 110.6ms/batch - loss: 50.51096 - diff: 20.79mlTrain batch 13/31 - 111.0ms/batch - loss: 47.71532 - diff: 20.10mlTrain batch 14/31 - 111.0ms/batch - loss: 47.60562 - diff: 20.20mlTrain batch 15/31 - 111.0ms/batch - loss: 48.03119 - diff: 20.36mlTrain batch 16/31 - 110.9ms/batch - loss: 46.71399 - diff: 20.01mlTrain batch 17/31 - 111.3ms/batch - loss: 46.29897 - diff: 20.05mlTrain batch 18/31 - 112.2ms/batch - loss: 44.63045 - diff: 19.69mlTrain batch 19/31 - 111.2ms/batch - loss: 43.52994 - diff: 19.54mlTrain batch 20/31 - 110.9ms/batch - loss: 43.29571 - diff: 19.45mlTrain batch 21/31 - 111.2ms/batch - loss: 41.81114 - diff: 19.10mlTrain batch 22/31 - 111.4ms/batch - loss: 41.96039 - diff: 19.28mlTrain batch 23/31 - 110.9ms/batch - loss: 41.11071 - diff: 19.13mlTrain batch 24/31 - 110.8ms/batch - loss: 40.15444 - diff: 18.93mlTrain batch 25/31 - 121.6ms/batch - loss: 41.58415 - diff: 19.36mlTrain batch 26/31 - 127.2ms/batch - loss: 40.51491 - diff: 19.06mlTrain batch 27/31 - 111.7ms/batch - loss: 39.66331 - diff: 18.86mlTrain batch 28/31 - 109.8ms/batch - loss: 38.91818 - diff: 18.61mlTrain batch 29/31 - 109.7ms/batch - loss: 38.40456 - diff: 18.55mlTrain batch 30/31 - 109.7ms/batch - loss: 43.28952 - diff: 19.55mlTrain batch 31/31 - 68.8ms/batch - loss: 43.14733 - diff: 19.46mlTrain batch 31/31 - 9.8s 68.8ms/batch - loss: 43.14733 - diff: 19.46ml
Test 0.8s: val_loss: 36.46467 - diff: 17.27ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_DenseNet121_0_Adam-0.001_MSE_DA3_best

Epoch 77: current best loss = 36.46467, at epoch 76
Train batch 1/31 - 111.1ms/batch - loss: 85.97692 - diff: 32.45mlTrain batch 2/31 - 110.0ms/batch - loss: 53.78694 - diff: 24.35mlTrain batch 3/31 - 110.0ms/batch - loss: 39.76130 - diff: 19.36mlTrain batch 4/31 - 110.7ms/batch - loss: 33.52320 - diff: 17.40mlTrain batch 5/31 - 109.9ms/batch - loss: 38.28893 - diff: 18.90mlTrain batch 6/31 - 110.0ms/batch - loss: 38.92747 - diff: 19.34mlTrain batch 7/31 - 109.9ms/batch - loss: 48.20422 - diff: 21.50mlTrain batch 8/31 - 110.3ms/batch - loss: 47.71138 - diff: 21.40mlTrain batch 9/31 - 111.0ms/batch - loss: 44.30828 - diff: 20.47mlTrain batch 10/31 - 110.0ms/batch - loss: 50.36638 - diff: 21.96mlTrain batch 11/31 - 112.6ms/batch - loss: 47.52017 - diff: 21.29mlTrain batch 12/31 - 109.9ms/batch - loss: 45.38403 - diff: 20.84mlTrain batch 13/31 - 111.1ms/batch - loss: 43.17881 - diff: 20.25mlTrain batch 14/31 - 111.3ms/batch - loss: 43.12314 - diff: 20.31mlTrain batch 15/31 - 111.2ms/batch - loss: 43.87255 - diff: 20.50mlTrain batch 16/31 - 110.5ms/batch - loss: 43.52253 - diff: 20.45mlTrain batch 17/31 - 111.2ms/batch - loss: 41.61371 - diff: 19.87mlTrain batch 18/31 - 110.7ms/batch - loss: 41.55615 - diff: 20.02mlTrain batch 19/31 - 110.3ms/batch - loss: 42.75066 - diff: 20.55mlTrain batch 20/31 - 110.1ms/batch - loss: 43.94077 - diff: 20.92mlTrain batch 21/31 - 110.0ms/batch - loss: 42.53940 - diff: 20.55mlTrain batch 22/31 - 110.3ms/batch - loss: 41.38097 - diff: 20.21mlTrain batch 23/31 - 109.8ms/batch - loss: 40.96332 - diff: 20.00mlTrain batch 24/31 - 112.0ms/batch - loss: 40.07907 - diff: 19.73mlTrain batch 25/31 - 113.4ms/batch - loss: 39.39307 - diff: 19.60mlTrain batch 26/31 - 111.5ms/batch - loss: 40.23626 - diff: 19.81mlTrain batch 27/31 - 110.1ms/batch - loss: 39.86787 - diff: 19.73mlTrain batch 28/31 - 109.4ms/batch - loss: 40.86234 - diff: 20.08mlTrain batch 29/31 - 108.6ms/batch - loss: 40.74027 - diff: 20.04mlTrain batch 30/31 - 109.0ms/batch - loss: 41.23508 - diff: 20.27mlTrain batch 31/31 - 68.9ms/batch - loss: 42.00634 - diff: 20.33mlTrain batch 31/31 - 9.8s 68.9ms/batch - loss: 42.00634 - diff: 20.33ml
Test 0.8s: val_loss: 43.49277 - diff: 17.99ml

Epoch 78: current best loss = 36.46467, at epoch 76
Train batch 1/31 - 111.4ms/batch - loss: 78.29302 - diff: 32.25mlTrain batch 2/31 - 109.8ms/batch - loss: 58.48709 - diff: 26.67mlTrain batch 3/31 - 110.4ms/batch - loss: 51.35199 - diff: 24.57mlTrain batch 4/31 - 110.4ms/batch - loss: 41.86714 - diff: 21.26mlTrain batch 5/31 - 110.3ms/batch - loss: 38.41990 - diff: 20.27mlTrain batch 6/31 - 110.5ms/batch - loss: 33.61637 - diff: 18.54mlTrain batch 7/31 - 109.9ms/batch - loss: 34.86188 - diff: 18.64mlTrain batch 8/31 - 109.6ms/batch - loss: 37.23079 - diff: 19.27mlTrain batch 9/31 - 109.8ms/batch - loss: 36.04717 - diff: 19.08mlTrain batch 10/31 - 110.0ms/batch - loss: 34.46090 - diff: 18.64mlTrain batch 11/31 - 109.7ms/batch - loss: 33.53253 - diff: 18.25mlTrain batch 12/31 - 109.7ms/batch - loss: 32.39445 - diff: 18.01mlTrain batch 13/31 - 109.7ms/batch - loss: 32.28186 - diff: 18.05mlTrain batch 14/31 - 109.9ms/batch - loss: 30.87152 - diff: 17.63mlTrain batch 15/31 - 109.9ms/batch - loss: 29.49459 - diff: 17.19mlTrain batch 16/31 - 109.6ms/batch - loss: 29.00135 - diff: 17.02mlTrain batch 17/31 - 110.3ms/batch - loss: 30.05896 - diff: 17.39mlTrain batch 18/31 - 110.2ms/batch - loss: 30.00984 - diff: 17.37mlTrain batch 19/31 - 110.5ms/batch - loss: 29.64519 - diff: 17.26mlTrain batch 20/31 - 110.3ms/batch - loss: 29.49453 - diff: 17.28mlTrain batch 21/31 - 109.6ms/batch - loss: 28.72774 - diff: 17.05mlTrain batch 22/31 - 109.6ms/batch - loss: 29.82539 - diff: 17.40mlTrain batch 23/31 - 109.8ms/batch - loss: 30.89787 - diff: 17.73mlTrain batch 24/31 - 111.1ms/batch - loss: 30.90369 - diff: 17.85mlTrain batch 25/31 - 115.0ms/batch - loss: 30.86313 - diff: 17.88mlTrain batch 26/31 - 110.0ms/batch - loss: 33.23241 - diff: 18.47mlTrain batch 27/31 - 110.2ms/batch - loss: 33.46447 - diff: 18.61mlTrain batch 28/31 - 110.8ms/batch - loss: 32.68183 - diff: 18.36mlTrain batch 29/31 - 109.2ms/batch - loss: 32.69282 - diff: 18.30mlTrain batch 30/31 - 110.7ms/batch - loss: 31.99862 - diff: 18.06mlTrain batch 31/31 - 70.8ms/batch - loss: 35.23115 - diff: 18.34mlTrain batch 31/31 - 9.8s 70.8ms/batch - loss: 35.23115 - diff: 18.34ml
Test 0.8s: val_loss: 45.01717 - diff: 20.34ml

Epoch 79: current best loss = 36.46467, at epoch 76
Train batch 1/31 - 111.4ms/batch - loss: 18.84995 - diff: 13.43mlTrain batch 2/31 - 110.6ms/batch - loss: 21.91852 - diff: 13.83mlTrain batch 3/31 - 110.2ms/batch - loss: 18.39700 - diff: 12.52mlTrain batch 4/31 - 110.8ms/batch - loss: 26.97796 - diff: 15.60mlTrain batch 5/31 - 111.9ms/batch - loss: 35.09141 - diff: 18.03mlTrain batch 6/31 - 110.6ms/batch - loss: 31.24449 - diff: 16.85mlTrain batch 7/31 - 110.1ms/batch - loss: 36.30071 - diff: 18.48mlTrain batch 8/31 - 110.2ms/batch - loss: 33.85072 - diff: 17.94mlTrain batch 9/31 - 112.3ms/batch - loss: 32.49465 - diff: 17.46mlTrain batch 10/31 - 109.9ms/batch - loss: 32.37871 - diff: 17.52mlTrain batch 11/31 - 112.5ms/batch - loss: 32.54096 - diff: 17.72mlTrain batch 12/31 - 109.6ms/batch - loss: 31.58910 - diff: 17.54mlTrain batch 13/31 - 113.4ms/batch - loss: 30.79423 - diff: 17.33mlTrain batch 14/31 - 109.7ms/batch - loss: 31.56851 - diff: 17.60mlTrain batch 15/31 - 112.5ms/batch - loss: 31.22826 - diff: 17.50mlTrain batch 16/31 - 110.4ms/batch - loss: 31.02749 - diff: 17.47mlTrain batch 17/31 - 113.3ms/batch - loss: 31.32617 - diff: 17.60mlTrain batch 18/31 - 110.3ms/batch - loss: 30.09308 - diff: 17.19mlTrain batch 19/31 - 110.8ms/batch - loss: 31.98191 - diff: 17.71mlTrain batch 20/31 - 110.2ms/batch - loss: 31.44499 - diff: 17.57mlTrain batch 21/31 - 110.9ms/batch - loss: 32.48390 - diff: 17.78mlTrain batch 22/31 - 109.8ms/batch - loss: 40.14284 - diff: 19.20mlTrain batch 23/31 - 109.6ms/batch - loss: 39.66352 - diff: 19.16mlTrain batch 24/31 - 113.4ms/batch - loss: 38.50216 - diff: 18.82mlTrain batch 25/31 - 111.1ms/batch - loss: 38.15381 - diff: 18.73mlTrain batch 26/31 - 109.6ms/batch - loss: 37.21088 - diff: 18.50mlTrain batch 27/31 - 110.9ms/batch - loss: 36.58993 - diff: 18.34mlTrain batch 28/31 - 113.8ms/batch - loss: 36.19407 - diff: 18.28mlTrain batch 29/31 - 110.8ms/batch - loss: 37.47869 - diff: 18.64mlTrain batch 30/31 - 112.6ms/batch - loss: 36.90215 - diff: 18.54mlTrain batch 31/31 - 69.2ms/batch - loss: 37.39567 - diff: 18.58mlTrain batch 31/31 - 9.8s 69.2ms/batch - loss: 37.39567 - diff: 18.58ml
Test 0.8s: val_loss: 36.31351 - diff: 18.27ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_DenseNet121_0_Adam-0.001_MSE_DA3_best

Epoch 80: current best loss = 36.31351, at epoch 79
Train batch 1/31 - 120.1ms/batch - loss: 34.93364 - diff: 17.75mlTrain batch 2/31 - 110.4ms/batch - loss: 28.43250 - diff: 17.31mlTrain batch 3/31 - 111.9ms/batch - loss: 26.33652 - diff: 16.30mlTrain batch 4/31 - 110.6ms/batch - loss: 25.10394 - diff: 15.93mlTrain batch 5/31 - 110.9ms/batch - loss: 33.19154 - diff: 18.31mlTrain batch 6/31 - 111.4ms/batch - loss: 29.80016 - diff: 17.11mlTrain batch 7/31 - 112.9ms/batch - loss: 29.12516 - diff: 16.86mlTrain batch 8/31 - 110.1ms/batch - loss: 30.31151 - diff: 17.51mlTrain batch 9/31 - 113.5ms/batch - loss: 29.04383 - diff: 17.12mlTrain batch 10/31 - 109.7ms/batch - loss: 27.74103 - diff: 16.69mlTrain batch 11/31 - 110.7ms/batch - loss: 26.08223 - diff: 15.92mlTrain batch 12/31 - 110.5ms/batch - loss: 26.02572 - diff: 15.99mlTrain batch 13/31 - 110.2ms/batch - loss: 24.76643 - diff: 15.44mlTrain batch 14/31 - 110.8ms/batch - loss: 25.12479 - diff: 15.62mlTrain batch 15/31 - 118.1ms/batch - loss: 24.30633 - diff: 15.38mlTrain batch 16/31 - 110.9ms/batch - loss: 24.03556 - diff: 15.30mlTrain batch 17/31 - 110.7ms/batch - loss: 23.58384 - diff: 15.15mlTrain batch 18/31 - 110.7ms/batch - loss: 26.47260 - diff: 15.97mlTrain batch 19/31 - 115.3ms/batch - loss: 27.09853 - diff: 16.13mlTrain batch 20/31 - 110.6ms/batch - loss: 27.03312 - diff: 16.23mlTrain batch 21/31 - 109.9ms/batch - loss: 28.68132 - diff: 16.54mlTrain batch 22/31 - 109.8ms/batch - loss: 29.08862 - diff: 16.60mlTrain batch 23/31 - 121.0ms/batch - loss: 28.94237 - diff: 16.61mlTrain batch 24/31 - 115.1ms/batch - loss: 28.53221 - diff: 16.55mlTrain batch 25/31 - 110.0ms/batch - loss: 29.84861 - diff: 16.90mlTrain batch 26/31 - 109.7ms/batch - loss: 29.47179 - diff: 16.79mlTrain batch 27/31 - 110.1ms/batch - loss: 29.20860 - diff: 16.72mlTrain batch 28/31 - 109.9ms/batch - loss: 29.55276 - diff: 16.83mlTrain batch 29/31 - 110.0ms/batch - loss: 29.51922 - diff: 16.82mlTrain batch 30/31 - 109.2ms/batch - loss: 29.54549 - diff: 16.88mlTrain batch 31/31 - 68.8ms/batch - loss: 29.51653 - diff: 16.80mlTrain batch 31/31 - 9.8s 68.8ms/batch - loss: 29.51653 - diff: 16.80ml
Test 0.8s: val_loss: 46.36056 - diff: 19.68ml

Epoch 81: current best loss = 36.31351, at epoch 79
Train batch 1/31 - 111.7ms/batch - loss: 65.54024 - diff: 25.37mlTrain batch 2/31 - 111.3ms/batch - loss: 72.98147 - diff: 22.98mlTrain batch 3/31 - 110.4ms/batch - loss: 51.36101 - diff: 18.29mlTrain batch 4/31 - 110.5ms/batch - loss: 47.86350 - diff: 17.93mlTrain batch 5/31 - 109.6ms/batch - loss: 43.70865 - diff: 17.89mlTrain batch 6/31 - 109.4ms/batch - loss: 39.59584 - diff: 17.25mlTrain batch 7/31 - 109.7ms/batch - loss: 40.10344 - diff: 18.25mlTrain batch 8/31 - 109.8ms/batch - loss: 37.31789 - diff: 17.80mlTrain batch 9/31 - 109.4ms/batch - loss: 36.03731 - diff: 17.55mlTrain batch 10/31 - 109.4ms/batch - loss: 36.78466 - diff: 17.81mlTrain batch 11/31 - 109.8ms/batch - loss: 37.24999 - diff: 18.30mlTrain batch 12/31 - 109.6ms/batch - loss: 36.45383 - diff: 18.23mlTrain batch 13/31 - 109.8ms/batch - loss: 35.86850 - diff: 18.23mlTrain batch 14/31 - 109.1ms/batch - loss: 34.54402 - diff: 17.85mlTrain batch 15/31 - 110.1ms/batch - loss: 33.61322 - diff: 17.65mlTrain batch 16/31 - 109.5ms/batch - loss: 34.37367 - diff: 17.76mlTrain batch 17/31 - 110.2ms/batch - loss: 36.42301 - diff: 18.32mlTrain batch 18/31 - 109.8ms/batch - loss: 37.78763 - diff: 18.86mlTrain batch 19/31 - 110.4ms/batch - loss: 38.32777 - diff: 19.01mlTrain batch 20/31 - 110.3ms/batch - loss: 37.71411 - diff: 18.87mlTrain batch 21/31 - 109.5ms/batch - loss: 36.68217 - diff: 18.56mlTrain batch 22/31 - 111.1ms/batch - loss: 38.38660 - diff: 18.92mlTrain batch 23/31 - 109.6ms/batch - loss: 39.16591 - diff: 18.97mlTrain batch 24/31 - 109.6ms/batch - loss: 38.46888 - diff: 18.80mlTrain batch 25/31 - 109.9ms/batch - loss: 39.36553 - diff: 19.11mlTrain batch 26/31 - 109.3ms/batch - loss: 39.58815 - diff: 19.15mlTrain batch 27/31 - 109.9ms/batch - loss: 38.86085 - diff: 19.01mlTrain batch 28/31 - 113.6ms/batch - loss: 39.60566 - diff: 19.18mlTrain batch 29/31 - 109.5ms/batch - loss: 40.08920 - diff: 19.32mlTrain batch 30/31 - 109.9ms/batch - loss: 40.60469 - diff: 19.42mlTrain batch 31/31 - 71.5ms/batch - loss: 41.99912 - diff: 19.56mlTrain batch 31/31 - 9.8s 71.5ms/batch - loss: 41.99912 - diff: 19.56ml
Test 0.8s: val_loss: 44.31523 - diff: 19.54ml

Epoch 82: current best loss = 36.31351, at epoch 79
Train batch 1/31 - 111.7ms/batch - loss: 24.58909 - diff: 16.73mlTrain batch 2/31 - 110.3ms/batch - loss: 20.32031 - diff: 14.48mlTrain batch 3/31 - 113.1ms/batch - loss: 21.86078 - diff: 15.08mlTrain batch 4/31 - 118.3ms/batch - loss: 17.65281 - diff: 13.05mlTrain batch 5/31 - 110.2ms/batch - loss: 16.66930 - diff: 12.67mlTrain batch 6/31 - 111.2ms/batch - loss: 19.90167 - diff: 14.09mlTrain batch 7/31 - 109.9ms/batch - loss: 23.81901 - diff: 15.54mlTrain batch 8/31 - 111.9ms/batch - loss: 23.90503 - diff: 15.34mlTrain batch 9/31 - 109.8ms/batch - loss: 25.58800 - diff: 15.82mlTrain batch 10/31 - 110.8ms/batch - loss: 35.28808 - diff: 17.61mlTrain batch 11/31 - 110.2ms/batch - loss: 34.25138 - diff: 17.44mlTrain batch 12/31 - 112.4ms/batch - loss: 33.40478 - diff: 17.46mlTrain batch 13/31 - 110.2ms/batch - loss: 33.52449 - diff: 17.66mlTrain batch 14/31 - 115.3ms/batch - loss: 33.64485 - diff: 17.78mlTrain batch 15/31 - 111.1ms/batch - loss: 33.49308 - diff: 17.78mlTrain batch 16/31 - 115.1ms/batch - loss: 32.40001 - diff: 17.46mlTrain batch 17/31 - 111.3ms/batch - loss: 32.31963 - diff: 17.44mlTrain batch 18/31 - 111.1ms/batch - loss: 31.41585 - diff: 17.16mlTrain batch 19/31 - 110.6ms/batch - loss: 30.90764 - diff: 17.05mlTrain batch 20/31 - 110.3ms/batch - loss: 30.69752 - diff: 17.04mlTrain batch 21/31 - 122.2ms/batch - loss: 30.66247 - diff: 16.97mlTrain batch 22/31 - 119.3ms/batch - loss: 31.30724 - diff: 17.16mlTrain batch 23/31 - 109.8ms/batch - loss: 31.02452 - diff: 17.10mlTrain batch 24/31 - 109.8ms/batch - loss: 30.57898 - diff: 16.96mlTrain batch 25/31 - 111.0ms/batch - loss: 32.19918 - diff: 17.37mlTrain batch 26/31 - 110.2ms/batch - loss: 31.80679 - diff: 17.24mlTrain batch 27/31 - 111.0ms/batch - loss: 32.01479 - diff: 17.34mlTrain batch 28/31 - 110.1ms/batch - loss: 31.94347 - diff: 17.30mlTrain batch 29/31 - 109.9ms/batch - loss: 31.79433 - diff: 17.27mlTrain batch 30/31 - 109.3ms/batch - loss: 33.51511 - diff: 17.83mlTrain batch 31/31 - 68.9ms/batch - loss: 34.03835 - diff: 17.82mlTrain batch 31/31 - 9.9s 68.9ms/batch - loss: 34.03835 - diff: 17.82ml
Test 0.8s: val_loss: 37.74678 - diff: 18.45ml

Epoch 83: current best loss = 36.31351, at epoch 79
Train batch 1/31 - 118.2ms/batch - loss: 29.09761 - diff: 16.63mlTrain batch 2/31 - 109.7ms/batch - loss: 23.42885 - diff: 14.70mlTrain batch 3/31 - 110.5ms/batch - loss: 23.34305 - diff: 15.21mlTrain batch 4/31 - 109.8ms/batch - loss: 21.88733 - diff: 14.60mlTrain batch 5/31 - 114.1ms/batch - loss: 19.58383 - diff: 13.78mlTrain batch 6/31 - 110.1ms/batch - loss: 20.85083 - diff: 14.14mlTrain batch 7/31 - 113.4ms/batch - loss: 22.70068 - diff: 14.75mlTrain batch 8/31 - 110.1ms/batch - loss: 23.08016 - diff: 14.75mlTrain batch 9/31 - 111.7ms/batch - loss: 29.24090 - diff: 15.62mlTrain batch 10/31 - 109.6ms/batch - loss: 27.78985 - diff: 15.32mlTrain batch 11/31 - 114.7ms/batch - loss: 27.42945 - diff: 15.39mlTrain batch 12/31 - 110.7ms/batch - loss: 26.79897 - diff: 15.37mlTrain batch 13/31 - 114.7ms/batch - loss: 28.28977 - diff: 15.91mlTrain batch 14/31 - 110.0ms/batch - loss: 27.99167 - diff: 15.82mlTrain batch 15/31 - 112.6ms/batch - loss: 28.66618 - diff: 16.24mlTrain batch 16/31 - 109.8ms/batch - loss: 27.77185 - diff: 16.05mlTrain batch 17/31 - 118.9ms/batch - loss: 28.42284 - diff: 16.45mlTrain batch 18/31 - 110.4ms/batch - loss: 29.48060 - diff: 16.91mlTrain batch 19/31 - 109.9ms/batch - loss: 32.62382 - diff: 17.68mlTrain batch 20/31 - 110.1ms/batch - loss: 32.74585 - diff: 17.76mlTrain batch 21/31 - 131.2ms/batch - loss: 32.10338 - diff: 17.66mlTrain batch 22/31 - 110.1ms/batch - loss: 31.85970 - diff: 17.56mlTrain batch 23/31 - 110.9ms/batch - loss: 33.09821 - diff: 17.92mlTrain batch 24/31 - 110.4ms/batch - loss: 33.42513 - diff: 18.10mlTrain batch 25/31 - 111.3ms/batch - loss: 34.39063 - diff: 18.48mlTrain batch 26/31 - 110.0ms/batch - loss: 34.51273 - diff: 18.60mlTrain batch 27/31 - 110.1ms/batch - loss: 34.04942 - diff: 18.40mlTrain batch 28/31 - 110.8ms/batch - loss: 33.47278 - diff: 18.18mlTrain batch 29/31 - 112.7ms/batch - loss: 32.89420 - diff: 18.03mlTrain batch 30/31 - 109.4ms/batch - loss: 36.58366 - diff: 18.84mlTrain batch 31/31 - 69.4ms/batch - loss: 44.07024 - diff: 19.45mlTrain batch 31/31 - 9.8s 69.4ms/batch - loss: 44.07024 - diff: 19.45ml
Test 0.8s: val_loss: 67.14131 - diff: 25.57ml

Epoch 84: current best loss = 36.31351, at epoch 79
Train batch 1/31 - 110.5ms/batch - loss: 26.91992 - diff: 16.12mlTrain batch 2/31 - 110.6ms/batch - loss: 35.85795 - diff: 18.92mlTrain batch 3/31 - 110.4ms/batch - loss: 28.97235 - diff: 16.94mlTrain batch 4/31 - 110.9ms/batch - loss: 42.14824 - diff: 19.88mlTrain batch 5/31 - 110.7ms/batch - loss: 35.17427 - diff: 17.72mlTrain batch 6/31 - 111.5ms/batch - loss: 40.53537 - diff: 19.36mlTrain batch 7/31 - 112.7ms/batch - loss: 36.54150 - diff: 18.18mlTrain batch 8/31 - 110.1ms/batch - loss: 37.74457 - diff: 18.78mlTrain batch 9/31 - 112.0ms/batch - loss: 35.17988 - diff: 18.04mlTrain batch 10/31 - 110.1ms/batch - loss: 35.06985 - diff: 17.88mlTrain batch 11/31 - 114.7ms/batch - loss: 35.53954 - diff: 18.00mlTrain batch 12/31 - 110.1ms/batch - loss: 33.37768 - diff: 17.29mlTrain batch 13/31 - 112.7ms/batch - loss: 34.23152 - diff: 17.58mlTrain batch 14/31 - 110.0ms/batch - loss: 35.84801 - diff: 18.14mlTrain batch 15/31 - 111.8ms/batch - loss: 34.80793 - diff: 17.95mlTrain batch 16/31 - 110.1ms/batch - loss: 34.39568 - diff: 17.94mlTrain batch 17/31 - 111.2ms/batch - loss: 33.14878 - diff: 17.59mlTrain batch 18/31 - 109.5ms/batch - loss: 31.57447 - diff: 16.99mlTrain batch 19/31 - 112.8ms/batch - loss: 31.43822 - diff: 16.90mlTrain batch 20/31 - 110.7ms/batch - loss: 31.34975 - diff: 16.99mlTrain batch 21/31 - 123.7ms/batch - loss: 31.63322 - diff: 17.16mlTrain batch 22/31 - 112.4ms/batch - loss: 34.62407 - diff: 17.99mlTrain batch 23/31 - 110.8ms/batch - loss: 33.48877 - diff: 17.61mlTrain batch 24/31 - 110.2ms/batch - loss: 33.60986 - diff: 17.73mlTrain batch 25/31 - 110.9ms/batch - loss: 34.06906 - diff: 17.95mlTrain batch 26/31 - 110.1ms/batch - loss: 34.35559 - diff: 18.03mlTrain batch 27/31 - 110.6ms/batch - loss: 34.67760 - diff: 18.06mlTrain batch 28/31 - 109.9ms/batch - loss: 34.10553 - diff: 17.95mlTrain batch 29/31 - 109.6ms/batch - loss: 33.86887 - diff: 17.78mlTrain batch 30/31 - 109.5ms/batch - loss: 33.77733 - diff: 17.83mlTrain batch 31/31 - 71.3ms/batch - loss: 33.46331 - diff: 17.68mlTrain batch 31/31 - 9.9s 71.3ms/batch - loss: 33.46331 - diff: 17.68ml
Test 0.8s: val_loss: 44.74152 - diff: 19.19ml

Epoch 85: current best loss = 36.31351, at epoch 79
Train batch 1/31 - 111.7ms/batch - loss: 37.76865 - diff: 21.17mlTrain batch 2/31 - 110.5ms/batch - loss: 32.32460 - diff: 18.84mlTrain batch 3/31 - 114.5ms/batch - loss: 28.32586 - diff: 17.22mlTrain batch 4/31 - 110.5ms/batch - loss: 31.10101 - diff: 17.95mlTrain batch 5/31 - 113.6ms/batch - loss: 26.85121 - diff: 16.45mlTrain batch 6/31 - 110.2ms/batch - loss: 30.44629 - diff: 17.54mlTrain batch 7/31 - 113.4ms/batch - loss: 27.82261 - diff: 16.68mlTrain batch 8/31 - 109.9ms/batch - loss: 29.78250 - diff: 17.45mlTrain batch 9/31 - 111.6ms/batch - loss: 33.54635 - diff: 18.86mlTrain batch 10/31 - 109.8ms/batch - loss: 31.88306 - diff: 18.31mlTrain batch 11/31 - 112.5ms/batch - loss: 32.69231 - diff: 18.49mlTrain batch 12/31 - 109.9ms/batch - loss: 32.31729 - diff: 18.53mlTrain batch 13/31 - 110.9ms/batch - loss: 31.51454 - diff: 18.30mlTrain batch 14/31 - 109.9ms/batch - loss: 31.87528 - diff: 18.32mlTrain batch 15/31 - 111.1ms/batch - loss: 37.51636 - diff: 19.66mlTrain batch 16/31 - 109.8ms/batch - loss: 36.40356 - diff: 19.32mlTrain batch 17/31 - 112.1ms/batch - loss: 35.75824 - diff: 19.20mlTrain batch 18/31 - 110.8ms/batch - loss: 35.01668 - diff: 19.02mlTrain batch 19/31 - 111.5ms/batch - loss: 34.62526 - diff: 18.98mlTrain batch 20/31 - 114.3ms/batch - loss: 34.03302 - diff: 18.72mlTrain batch 21/31 - 111.7ms/batch - loss: 33.84333 - diff: 18.70mlTrain batch 22/31 - 109.9ms/batch - loss: 33.17257 - diff: 18.53mlTrain batch 23/31 - 113.6ms/batch - loss: 32.41690 - diff: 18.28mlTrain batch 24/31 - 111.7ms/batch - loss: 32.45527 - diff: 18.19mlTrain batch 25/31 - 114.0ms/batch - loss: 31.72876 - diff: 17.99mlTrain batch 26/31 - 110.8ms/batch - loss: 32.26473 - diff: 18.18mlTrain batch 27/31 - 112.9ms/batch - loss: 32.29711 - diff: 18.24mlTrain batch 28/31 - 110.7ms/batch - loss: 32.34960 - diff: 18.20mlTrain batch 29/31 - 113.1ms/batch - loss: 31.97310 - diff: 18.11mlTrain batch 30/31 - 109.9ms/batch - loss: 33.82403 - diff: 18.60mlTrain batch 31/31 - 69.8ms/batch - loss: 34.10296 - diff: 18.54mlTrain batch 31/31 - 9.8s 69.8ms/batch - loss: 34.10296 - diff: 18.54ml
Test 0.8s: val_loss: 51.88018 - diff: 21.16ml

Epoch 86: current best loss = 36.31351, at epoch 79
Train batch 1/31 - 112.1ms/batch - loss: 19.04372 - diff: 13.73mlTrain batch 2/31 - 111.0ms/batch - loss: 21.49229 - diff: 13.65mlTrain batch 3/31 - 111.6ms/batch - loss: 19.34341 - diff: 13.71mlTrain batch 4/31 - 109.8ms/batch - loss: 21.21341 - diff: 14.59mlTrain batch 5/31 - 111.3ms/batch - loss: 29.46108 - diff: 16.17mlTrain batch 6/31 - 109.9ms/batch - loss: 34.28481 - diff: 17.96mlTrain batch 7/31 - 111.5ms/batch - loss: 34.21166 - diff: 18.15mlTrain batch 8/31 - 110.6ms/batch - loss: 32.38767 - diff: 17.83mlTrain batch 9/31 - 111.4ms/batch - loss: 29.82567 - diff: 17.04mlTrain batch 10/31 - 115.3ms/batch - loss: 27.58702 - diff: 16.17mlTrain batch 11/31 - 111.0ms/batch - loss: 26.66654 - diff: 15.90mlTrain batch 12/31 - 119.1ms/batch - loss: 25.13435 - diff: 15.34mlTrain batch 13/31 - 110.5ms/batch - loss: 26.35084 - diff: 15.77mlTrain batch 14/31 - 110.9ms/batch - loss: 25.90359 - diff: 15.71mlTrain batch 15/31 - 110.8ms/batch - loss: 28.61229 - diff: 16.48mlTrain batch 16/31 - 111.3ms/batch - loss: 29.40301 - diff: 16.81mlTrain batch 17/31 - 111.1ms/batch - loss: 28.40962 - diff: 16.49mlTrain batch 18/31 - 110.9ms/batch - loss: 27.92842 - diff: 16.37mlTrain batch 19/31 - 122.5ms/batch - loss: 27.19863 - diff: 16.16mlTrain batch 20/31 - 118.8ms/batch - loss: 26.90252 - diff: 16.02mlTrain batch 21/31 - 109.4ms/batch - loss: 26.21680 - diff: 15.79mlTrain batch 22/31 - 109.2ms/batch - loss: 26.44769 - diff: 15.93mlTrain batch 23/31 - 109.9ms/batch - loss: 26.15099 - diff: 15.80mlTrain batch 24/31 - 109.6ms/batch - loss: 26.25874 - diff: 15.79mlTrain batch 25/31 - 112.6ms/batch - loss: 26.12720 - diff: 15.82mlTrain batch 26/31 - 109.8ms/batch - loss: 27.08070 - diff: 16.01mlTrain batch 27/31 - 112.4ms/batch - loss: 28.18580 - diff: 16.28mlTrain batch 28/31 - 110.0ms/batch - loss: 28.02598 - diff: 16.26mlTrain batch 29/31 - 110.7ms/batch - loss: 28.21647 - diff: 16.45mlTrain batch 30/31 - 109.2ms/batch - loss: 28.43716 - diff: 16.58mlTrain batch 31/31 - 69.4ms/batch - loss: 28.57531 - diff: 16.52mlTrain batch 31/31 - 9.8s 69.4ms/batch - loss: 28.57531 - diff: 16.52ml
Test 0.8s: val_loss: 46.25937 - diff: 19.27ml

Epoch 87: current best loss = 36.31351, at epoch 79
Train batch 1/31 - 124.1ms/batch - loss: 39.32089 - diff: 21.59mlTrain batch 2/31 - 111.6ms/batch - loss: 42.79669 - diff: 20.46mlTrain batch 3/31 - 111.1ms/batch - loss: 46.94124 - diff: 22.30mlTrain batch 4/31 - 109.9ms/batch - loss: 39.77953 - diff: 20.31mlTrain batch 5/31 - 110.7ms/batch - loss: 37.28246 - diff: 19.70mlTrain batch 6/31 - 110.2ms/batch - loss: 35.14097 - diff: 18.96mlTrain batch 7/31 - 111.5ms/batch - loss: 32.98468 - diff: 18.07mlTrain batch 8/31 - 109.8ms/batch - loss: 29.75676 - diff: 16.87mlTrain batch 9/31 - 116.4ms/batch - loss: 27.27662 - diff: 15.84mlTrain batch 10/31 - 110.2ms/batch - loss: 26.37711 - diff: 15.60mlTrain batch 11/31 - 111.0ms/batch - loss: 24.90842 - diff: 15.12mlTrain batch 12/31 - 109.7ms/batch - loss: 28.11317 - diff: 16.04mlTrain batch 13/31 - 110.8ms/batch - loss: 26.84409 - diff: 15.69mlTrain batch 14/31 - 110.1ms/batch - loss: 30.39087 - diff: 16.80mlTrain batch 15/31 - 115.5ms/batch - loss: 29.88136 - diff: 16.68mlTrain batch 16/31 - 110.5ms/batch - loss: 30.33365 - diff: 16.98mlTrain batch 17/31 - 111.7ms/batch - loss: 29.79740 - diff: 16.81mlTrain batch 18/31 - 109.7ms/batch - loss: 29.08255 - diff: 16.59mlTrain batch 19/31 - 110.5ms/batch - loss: 28.07795 - diff: 16.28mlTrain batch 20/31 - 113.1ms/batch - loss: 27.75813 - diff: 16.18mlTrain batch 21/31 - 110.3ms/batch - loss: 28.74082 - diff: 16.53mlTrain batch 22/31 - 109.7ms/batch - loss: 27.91456 - diff: 16.29mlTrain batch 23/31 - 110.1ms/batch - loss: 30.11164 - diff: 17.04mlTrain batch 24/31 - 109.5ms/batch - loss: 29.78955 - diff: 16.97mlTrain batch 25/31 - 111.7ms/batch - loss: 29.63009 - diff: 16.96mlTrain batch 26/31 - 110.1ms/batch - loss: 29.58922 - diff: 16.91mlTrain batch 27/31 - 112.2ms/batch - loss: 30.20393 - diff: 17.17mlTrain batch 28/31 - 110.6ms/batch - loss: 30.10748 - diff: 17.19mlTrain batch 29/31 - 111.0ms/batch - loss: 29.72691 - diff: 17.01mlTrain batch 30/31 - 110.0ms/batch - loss: 29.37124 - diff: 16.90mlTrain batch 31/31 - 73.4ms/batch - loss: 32.63541 - diff: 17.16mlTrain batch 31/31 - 9.8s 73.4ms/batch - loss: 32.63541 - diff: 17.16ml
Test 0.8s: val_loss: 40.37164 - diff: 18.65ml

Epoch 88: current best loss = 36.31351, at epoch 79
Train batch 1/31 - 113.5ms/batch - loss: 89.03594 - diff: 31.38mlTrain batch 2/31 - 109.7ms/batch - loss: 51.17737 - diff: 22.29mlTrain batch 3/31 - 112.5ms/batch - loss: 39.97755 - diff: 19.40mlTrain batch 4/31 - 109.7ms/batch - loss: 36.73392 - diff: 18.34mlTrain batch 5/31 - 112.6ms/batch - loss: 32.22757 - diff: 17.31mlTrain batch 6/31 - 110.0ms/batch - loss: 29.11591 - diff: 16.54mlTrain batch 7/31 - 112.2ms/batch - loss: 27.05777 - diff: 15.96mlTrain batch 8/31 - 110.0ms/batch - loss: 27.79775 - diff: 16.35mlTrain batch 9/31 - 110.8ms/batch - loss: 27.20637 - diff: 16.09mlTrain batch 10/31 - 109.7ms/batch - loss: 25.76677 - diff: 15.63mlTrain batch 11/31 - 110.1ms/batch - loss: 27.82562 - diff: 16.38mlTrain batch 12/31 - 109.8ms/batch - loss: 28.12782 - diff: 16.34mlTrain batch 13/31 - 110.2ms/batch - loss: 32.42568 - diff: 17.17mlTrain batch 14/31 - 109.7ms/batch - loss: 36.41724 - diff: 17.41mlTrain batch 15/31 - 110.1ms/batch - loss: 35.90197 - diff: 17.37mlTrain batch 16/31 - 109.9ms/batch - loss: 34.42146 - diff: 16.99mlTrain batch 17/31 - 111.7ms/batch - loss: 33.21871 - diff: 16.70mlTrain batch 18/31 - 111.0ms/batch - loss: 33.08762 - diff: 16.76mlTrain batch 19/31 - 109.6ms/batch - loss: 32.77798 - diff: 16.88mlTrain batch 20/31 - 110.5ms/batch - loss: 32.40383 - diff: 16.90mlTrain batch 21/31 - 109.9ms/batch - loss: 31.22238 - diff: 16.49mlTrain batch 22/31 - 115.4ms/batch - loss: 31.00878 - diff: 16.44mlTrain batch 23/31 - 110.2ms/batch - loss: 31.23705 - diff: 16.58mlTrain batch 24/31 - 110.6ms/batch - loss: 30.88105 - diff: 16.53mlTrain batch 25/31 - 109.8ms/batch - loss: 30.53804 - diff: 16.52mlTrain batch 26/31 - 114.3ms/batch - loss: 29.87437 - diff: 16.35mlTrain batch 27/31 - 109.9ms/batch - loss: 29.15726 - diff: 16.13mlTrain batch 28/31 - 114.8ms/batch - loss: 28.68054 - diff: 16.01mlTrain batch 29/31 - 109.4ms/batch - loss: 28.36159 - diff: 15.88mlTrain batch 30/31 - 109.6ms/batch - loss: 28.23311 - diff: 15.84mlTrain batch 31/31 - 70.2ms/batch - loss: 29.17683 - diff: 15.94mlTrain batch 31/31 - 9.8s 70.2ms/batch - loss: 29.17683 - diff: 15.94ml
Test 0.8s: val_loss: 46.84592 - diff: 20.71ml

Epoch 89: current best loss = 36.31351, at epoch 79
Train batch 1/31 - 111.0ms/batch - loss: 52.17232 - diff: 19.76mlTrain batch 2/31 - 109.9ms/batch - loss: 48.15564 - diff: 21.74mlTrain batch 3/31 - 112.9ms/batch - loss: 37.88146 - diff: 19.24mlTrain batch 4/31 - 110.9ms/batch - loss: 37.15681 - diff: 18.37mlTrain batch 5/31 - 113.7ms/batch - loss: 33.14706 - diff: 17.23mlTrain batch 6/31 - 111.1ms/batch - loss: 32.63411 - diff: 17.37mlTrain batch 7/31 - 112.3ms/batch - loss: 32.67169 - diff: 17.31mlTrain batch 8/31 - 109.7ms/batch - loss: 34.47440 - diff: 18.18mlTrain batch 9/31 - 112.2ms/batch - loss: 33.26118 - diff: 17.96mlTrain batch 10/31 - 110.3ms/batch - loss: 30.68263 - diff: 16.99mlTrain batch 11/31 - 112.3ms/batch - loss: 31.39113 - diff: 17.10mlTrain batch 12/31 - 109.2ms/batch - loss: 30.78348 - diff: 16.75mlTrain batch 13/31 - 111.6ms/batch - loss: 30.66942 - diff: 16.92mlTrain batch 14/31 - 110.2ms/batch - loss: 30.18471 - diff: 16.77mlTrain batch 15/31 - 112.5ms/batch - loss: 29.60973 - diff: 16.64mlTrain batch 16/31 - 109.4ms/batch - loss: 28.92054 - diff: 16.45mlTrain batch 17/31 - 115.3ms/batch - loss: 28.03088 - diff: 16.14mlTrain batch 18/31 - 115.3ms/batch - loss: 27.47321 - diff: 16.04mlTrain batch 19/31 - 114.6ms/batch - loss: 26.58119 - diff: 15.77mlTrain batch 20/31 - 109.8ms/batch - loss: 26.19269 - diff: 15.74mlTrain batch 21/31 - 112.4ms/batch - loss: 27.03827 - diff: 16.03mlTrain batch 22/31 - 111.4ms/batch - loss: 26.55758 - diff: 15.91mlTrain batch 23/31 - 115.1ms/batch - loss: 26.22593 - diff: 15.81mlTrain batch 24/31 - 110.3ms/batch - loss: 27.60604 - diff: 16.08mlTrain batch 25/31 - 114.2ms/batch - loss: 28.66793 - diff: 16.36mlTrain batch 26/31 - 110.2ms/batch - loss: 29.37282 - diff: 16.64mlTrain batch 27/31 - 126.8ms/batch - loss: 29.06287 - diff: 16.59mlTrain batch 28/31 - 114.3ms/batch - loss: 28.57970 - diff: 16.48mlTrain batch 29/31 - 121.6ms/batch - loss: 28.06172 - diff: 16.25mlTrain batch 30/31 - 110.3ms/batch - loss: 29.40174 - diff: 16.68mlTrain batch 31/31 - 69.8ms/batch - loss: 40.85675 - diff: 17.22mlTrain batch 31/31 - 9.8s 69.8ms/batch - loss: 40.85675 - diff: 17.22ml
Test 0.8s: val_loss: 49.35725 - diff: 19.02ml

Epoch 90: current best loss = 36.31351, at epoch 79
Train batch 1/31 - 114.3ms/batch - loss: 42.85787 - diff: 21.80mlTrain batch 2/31 - 110.1ms/batch - loss: 42.58527 - diff: 21.44mlTrain batch 3/31 - 113.5ms/batch - loss: 35.51262 - diff: 19.59mlTrain batch 4/31 - 109.7ms/batch - loss: 33.22056 - diff: 19.20mlTrain batch 5/31 - 133.7ms/batch - loss: 30.41384 - diff: 18.23mlTrain batch 6/31 - 110.3ms/batch - loss: 31.99427 - diff: 18.31mlTrain batch 7/31 - 127.3ms/batch - loss: 30.68539 - diff: 17.91mlTrain batch 8/31 - 111.2ms/batch - loss: 41.24503 - diff: 20.38mlTrain batch 9/31 - 131.0ms/batch - loss: 42.42586 - diff: 20.76mlTrain batch 10/31 - 111.4ms/batch - loss: 42.18482 - diff: 20.75mlTrain batch 11/31 - 127.6ms/batch - loss: 43.54615 - diff: 21.25mlTrain batch 12/31 - 111.1ms/batch - loss: 51.11560 - diff: 23.18mlTrain batch 13/31 - 111.0ms/batch - loss: 49.46480 - diff: 22.80mlTrain batch 14/31 - 110.2ms/batch - loss: 47.78693 - diff: 22.32mlTrain batch 15/31 - 110.4ms/batch - loss: 46.52603 - diff: 21.87mlTrain batch 16/31 - 109.7ms/batch - loss: 44.97492 - diff: 21.43mlTrain batch 17/31 - 122.1ms/batch - loss: 44.45800 - diff: 21.35mlTrain batch 18/31 - 121.3ms/batch - loss: 43.18518 - diff: 21.05mlTrain batch 19/31 - 109.4ms/batch - loss: 44.85496 - diff: 21.45mlTrain batch 20/31 - 109.4ms/batch - loss: 44.12996 - diff: 21.32mlTrain batch 21/31 - 109.7ms/batch - loss: 42.67240 - diff: 20.85mlTrain batch 22/31 - 109.2ms/batch - loss: 42.01098 - diff: 20.64mlTrain batch 23/31 - 110.1ms/batch - loss: 42.61247 - diff: 20.77mlTrain batch 24/31 - 109.8ms/batch - loss: 41.79487 - diff: 20.56mlTrain batch 25/31 - 109.5ms/batch - loss: 40.56880 - diff: 20.18mlTrain batch 26/31 - 109.5ms/batch - loss: 40.04020 - diff: 20.05mlTrain batch 27/31 - 109.6ms/batch - loss: 40.00608 - diff: 20.05mlTrain batch 28/31 - 109.7ms/batch - loss: 39.06205 - diff: 19.75mlTrain batch 29/31 - 109.3ms/batch - loss: 38.39935 - diff: 19.56mlTrain batch 30/31 - 109.0ms/batch - loss: 37.88279 - diff: 19.43mlTrain batch 31/31 - 68.6ms/batch - loss: 38.05360 - diff: 19.34mlTrain batch 31/31 - 9.8s 68.6ms/batch - loss: 38.05360 - diff: 19.34ml
Test 0.9s: val_loss: 53.22244 - diff: 21.68ml
Epoch    91: reducing learning rate of group 0 to 2.5000e-04.

Epoch 91: current best loss = 36.31351, at epoch 79
Train batch 1/31 - 111.8ms/batch - loss: 23.00052 - diff: 16.11mlTrain batch 2/31 - 111.2ms/batch - loss: 17.44170 - diff: 13.63mlTrain batch 3/31 - 112.5ms/batch - loss: 28.89278 - diff: 17.83mlTrain batch 4/31 - 109.6ms/batch - loss: 42.08258 - diff: 21.61mlTrain batch 5/31 - 112.6ms/batch - loss: 34.96456 - diff: 18.95mlTrain batch 6/31 - 109.7ms/batch - loss: 31.47132 - diff: 17.76mlTrain batch 7/31 - 112.7ms/batch - loss: 31.43047 - diff: 17.52mlTrain batch 8/31 - 109.5ms/batch - loss: 31.27262 - diff: 17.66mlTrain batch 9/31 - 113.1ms/batch - loss: 31.66670 - diff: 18.11mlTrain batch 10/31 - 109.8ms/batch - loss: 39.64369 - diff: 20.09mlTrain batch 11/31 - 110.5ms/batch - loss: 37.11805 - diff: 19.13mlTrain batch 12/31 - 110.3ms/batch - loss: 34.63337 - diff: 18.29mlTrain batch 13/31 - 113.8ms/batch - loss: 32.74794 - diff: 17.68mlTrain batch 14/31 - 110.0ms/batch - loss: 31.33423 - diff: 17.23mlTrain batch 15/31 - 113.1ms/batch - loss: 30.26798 - diff: 16.89mlTrain batch 16/31 - 110.1ms/batch - loss: 29.41724 - diff: 16.66mlTrain batch 17/31 - 113.9ms/batch - loss: 29.14112 - diff: 16.70mlTrain batch 18/31 - 109.2ms/batch - loss: 28.65088 - diff: 16.64mlTrain batch 19/31 - 110.3ms/batch - loss: 27.87063 - diff: 16.41mlTrain batch 20/31 - 110.3ms/batch - loss: 29.65562 - diff: 17.07mlTrain batch 21/31 - 109.6ms/batch - loss: 28.97499 - diff: 16.71mlTrain batch 22/31 - 111.9ms/batch - loss: 29.27674 - diff: 16.76mlTrain batch 23/31 - 113.5ms/batch - loss: 28.32814 - diff: 16.41mlTrain batch 24/31 - 112.3ms/batch - loss: 27.55121 - diff: 16.13mlTrain batch 25/31 - 110.9ms/batch - loss: 28.93227 - diff: 16.57mlTrain batch 26/31 - 110.6ms/batch - loss: 29.14879 - diff: 16.65mlTrain batch 27/31 - 113.6ms/batch - loss: 28.96522 - diff: 16.61mlTrain batch 28/31 - 111.0ms/batch - loss: 29.22021 - diff: 16.74mlTrain batch 29/31 - 112.4ms/batch - loss: 28.62956 - diff: 16.57mlTrain batch 30/31 - 110.0ms/batch - loss: 28.61702 - diff: 16.64mlTrain batch 31/31 - 70.4ms/batch - loss: 28.60232 - diff: 16.59mlTrain batch 31/31 - 9.8s 70.4ms/batch - loss: 28.60232 - diff: 16.59ml
Test 0.8s: val_loss: 42.68169 - diff: 18.83ml

Epoch 92: current best loss = 36.31351, at epoch 79
Train batch 1/31 - 112.1ms/batch - loss: 75.78395 - diff: 18.92mlTrain batch 2/31 - 111.5ms/batch - loss: 42.18801 - diff: 14.34mlTrain batch 3/31 - 110.9ms/batch - loss: 37.24410 - diff: 15.86mlTrain batch 4/31 - 114.8ms/batch - loss: 31.64841 - diff: 15.41mlTrain batch 5/31 - 111.4ms/batch - loss: 28.09045 - diff: 14.81mlTrain batch 6/31 - 119.8ms/batch - loss: 26.28048 - diff: 14.66mlTrain batch 7/31 - 114.5ms/batch - loss: 23.85218 - diff: 13.99mlTrain batch 8/31 - 110.8ms/batch - loss: 21.77763 - diff: 13.29mlTrain batch 9/31 - 113.9ms/batch - loss: 22.59378 - diff: 13.48mlTrain batch 10/31 - 110.6ms/batch - loss: 21.46478 - diff: 13.29mlTrain batch 11/31 - 114.3ms/batch - loss: 20.43966 - diff: 13.01mlTrain batch 12/31 - 111.1ms/batch - loss: 19.47333 - diff: 12.69mlTrain batch 13/31 - 110.4ms/batch - loss: 19.01195 - diff: 12.61mlTrain batch 14/31 - 111.7ms/batch - loss: 18.84651 - diff: 12.64mlTrain batch 15/31 - 117.4ms/batch - loss: 19.84964 - diff: 13.02mlTrain batch 16/31 - 119.3ms/batch - loss: 19.40389 - diff: 12.93mlTrain batch 17/31 - 111.8ms/batch - loss: 20.12806 - diff: 13.23mlTrain batch 18/31 - 111.5ms/batch - loss: 19.86013 - diff: 13.24mlTrain batch 19/31 - 110.4ms/batch - loss: 19.69672 - diff: 13.27mlTrain batch 20/31 - 109.8ms/batch - loss: 19.59326 - diff: 13.30mlTrain batch 21/31 - 111.6ms/batch - loss: 19.51176 - diff: 13.35mlTrain batch 22/31 - 110.7ms/batch - loss: 20.78293 - diff: 13.83mlTrain batch 23/31 - 110.8ms/batch - loss: 20.76726 - diff: 13.86mlTrain batch 24/31 - 110.2ms/batch - loss: 22.40852 - diff: 14.34mlTrain batch 25/31 - 110.5ms/batch - loss: 21.98456 - diff: 14.19mlTrain batch 26/31 - 110.7ms/batch - loss: 21.74432 - diff: 14.13mlTrain batch 27/31 - 110.1ms/batch - loss: 21.88441 - diff: 14.28mlTrain batch 28/31 - 109.7ms/batch - loss: 21.54876 - diff: 14.18mlTrain batch 29/31 - 110.2ms/batch - loss: 21.42236 - diff: 14.14mlTrain batch 30/31 - 109.7ms/batch - loss: 22.87624 - diff: 14.56mlTrain batch 31/31 - 68.9ms/batch - loss: 22.86423 - diff: 14.48mlTrain batch 31/31 - 9.9s 68.9ms/batch - loss: 22.86423 - diff: 14.48ml
Test 0.8s: val_loss: 40.81792 - diff: 18.50ml

Epoch 93: current best loss = 36.31351, at epoch 79
Train batch 1/31 - 123.5ms/batch - loss: 11.79395 - diff: 11.46mlTrain batch 2/31 - 110.5ms/batch - loss: 15.00664 - diff: 13.06mlTrain batch 3/31 - 110.7ms/batch - loss: 17.39037 - diff: 13.56mlTrain batch 4/31 - 110.7ms/batch - loss: 15.95745 - diff: 13.04mlTrain batch 5/31 - 112.4ms/batch - loss: 24.91660 - diff: 15.54mlTrain batch 6/31 - 110.7ms/batch - loss: 24.91096 - diff: 15.47mlTrain batch 7/31 - 113.5ms/batch - loss: 24.20637 - diff: 15.47mlTrain batch 8/31 - 111.1ms/batch - loss: 22.28928 - diff: 14.77mlTrain batch 9/31 - 110.1ms/batch - loss: 22.93630 - diff: 15.11mlTrain batch 10/31 - 110.1ms/batch - loss: 21.85519 - diff: 14.79mlTrain batch 11/31 - 112.2ms/batch - loss: 22.69471 - diff: 15.14mlTrain batch 12/31 - 109.9ms/batch - loss: 22.64039 - diff: 15.14mlTrain batch 13/31 - 110.5ms/batch - loss: 22.44286 - diff: 15.05mlTrain batch 14/31 - 109.6ms/batch - loss: 22.54846 - diff: 15.11mlTrain batch 15/31 - 156.6ms/batch - loss: 22.78853 - diff: 15.23mlTrain batch 16/31 - 111.3ms/batch - loss: 22.32711 - diff: 15.07mlTrain batch 17/31 - 111.0ms/batch - loss: 25.70476 - diff: 16.19mlTrain batch 18/31 - 110.0ms/batch - loss: 26.48721 - diff: 16.57mlTrain batch 19/31 - 112.8ms/batch - loss: 25.82125 - diff: 16.30mlTrain batch 20/31 - 110.5ms/batch - loss: 25.06538 - diff: 15.97mlTrain batch 21/31 - 110.7ms/batch - loss: 25.42402 - diff: 16.18mlTrain batch 22/31 - 109.8ms/batch - loss: 25.99586 - diff: 16.36mlTrain batch 23/31 - 110.5ms/batch - loss: 25.33393 - diff: 16.10mlTrain batch 24/31 - 109.8ms/batch - loss: 25.66205 - diff: 16.25mlTrain batch 25/31 - 110.6ms/batch - loss: 24.99850 - diff: 16.01mlTrain batch 26/31 - 109.4ms/batch - loss: 24.38909 - diff: 15.78mlTrain batch 27/31 - 111.0ms/batch - loss: 24.00845 - diff: 15.59mlTrain batch 28/31 - 110.0ms/batch - loss: 23.80732 - diff: 15.46mlTrain batch 29/31 - 110.2ms/batch - loss: 23.51829 - diff: 15.39mlTrain batch 30/31 - 109.2ms/batch - loss: 24.59348 - diff: 15.65mlTrain batch 31/31 - 70.0ms/batch - loss: 26.28660 - diff: 15.84mlTrain batch 31/31 - 9.8s 70.0ms/batch - loss: 26.28660 - diff: 15.84ml
Test 0.8s: val_loss: 40.13718 - diff: 18.19ml

Epoch 94: current best loss = 36.31351, at epoch 79
Train batch 1/31 - 111.0ms/batch - loss: 9.67122 - diff: 9.54mlTrain batch 2/31 - 110.2ms/batch - loss: 10.93556 - diff: 10.25mlTrain batch 3/31 - 113.1ms/batch - loss: 13.80219 - diff: 11.37mlTrain batch 4/31 - 110.0ms/batch - loss: 16.52895 - diff: 12.37mlTrain batch 5/31 - 113.0ms/batch - loss: 27.18701 - diff: 15.55mlTrain batch 6/31 - 109.5ms/batch - loss: 24.14341 - diff: 14.63mlTrain batch 7/31 - 113.7ms/batch - loss: 21.83381 - diff: 13.83mlTrain batch 8/31 - 110.0ms/batch - loss: 22.91475 - diff: 14.52mlTrain batch 9/31 - 113.1ms/batch - loss: 28.60969 - diff: 16.39mlTrain batch 10/31 - 109.9ms/batch - loss: 29.60388 - diff: 17.01mlTrain batch 11/31 - 112.6ms/batch - loss: 28.32917 - diff: 16.52mlTrain batch 12/31 - 109.2ms/batch - loss: 28.77835 - diff: 16.79mlTrain batch 13/31 - 116.3ms/batch - loss: 27.72721 - diff: 16.42mlTrain batch 14/31 - 111.4ms/batch - loss: 26.74744 - diff: 16.09mlTrain batch 15/31 - 111.6ms/batch - loss: 27.09205 - diff: 16.32mlTrain batch 16/31 - 110.7ms/batch - loss: 26.84962 - diff: 16.23mlTrain batch 17/31 - 111.4ms/batch - loss: 29.63848 - diff: 17.01mlTrain batch 18/31 - 113.2ms/batch - loss: 28.58102 - diff: 16.63mlTrain batch 19/31 - 112.0ms/batch - loss: 27.68024 - diff: 16.37mlTrain batch 20/31 - 113.7ms/batch - loss: 27.37219 - diff: 16.20mlTrain batch 21/31 - 111.5ms/batch - loss: 28.18312 - diff: 16.56mlTrain batch 22/31 - 114.5ms/batch - loss: 28.88479 - diff: 16.77mlTrain batch 23/31 - 112.2ms/batch - loss: 28.67073 - diff: 16.69mlTrain batch 24/31 - 113.2ms/batch - loss: 27.88076 - diff: 16.42mlTrain batch 25/31 - 111.3ms/batch - loss: 27.53717 - diff: 16.38mlTrain batch 26/31 - 119.9ms/batch - loss: 27.26743 - diff: 16.35mlTrain batch 27/31 - 110.8ms/batch - loss: 26.50942 - diff: 16.06mlTrain batch 28/31 - 115.9ms/batch - loss: 26.48587 - diff: 16.08mlTrain batch 29/31 - 110.4ms/batch - loss: 26.45967 - diff: 16.07mlTrain batch 30/31 - 114.9ms/batch - loss: 26.57788 - diff: 16.15mlTrain batch 31/31 - 70.2ms/batch - loss: 26.95883 - diff: 16.17mlTrain batch 31/31 - 9.8s 70.2ms/batch - loss: 26.95883 - diff: 16.17ml
Test 0.8s: val_loss: 40.21766 - diff: 18.32ml

Epoch 95: current best loss = 36.31351, at epoch 79
Train batch 1/31 - 113.2ms/batch - loss: 10.45520 - diff: 10.74mlTrain batch 2/31 - 114.9ms/batch - loss: 11.43853 - diff: 11.44mlTrain batch 3/31 - 111.6ms/batch - loss: 14.16615 - diff: 12.09mlTrain batch 4/31 - 115.1ms/batch - loss: 13.08884 - diff: 11.79mlTrain batch 5/31 - 110.5ms/batch - loss: 12.18838 - diff: 11.38mlTrain batch 6/31 - 114.3ms/batch - loss: 11.96703 - diff: 11.14mlTrain batch 7/31 - 110.8ms/batch - loss: 11.50971 - diff: 11.06mlTrain batch 8/31 - 112.4ms/batch - loss: 10.98790 - diff: 10.72mlTrain batch 9/31 - 111.0ms/batch - loss: 10.97988 - diff: 10.64mlTrain batch 10/31 - 112.4ms/batch - loss: 11.42551 - diff: 10.89mlTrain batch 11/31 - 110.4ms/batch - loss: 12.19189 - diff: 11.17mlTrain batch 12/31 - 112.3ms/batch - loss: 13.69767 - diff: 11.74mlTrain batch 13/31 - 119.3ms/batch - loss: 13.65678 - diff: 11.67mlTrain batch 14/31 - 119.3ms/batch - loss: 15.59176 - diff: 12.37mlTrain batch 15/31 - 109.5ms/batch - loss: 16.62830 - diff: 12.82mlTrain batch 16/31 - 109.9ms/batch - loss: 19.95124 - diff: 13.80mlTrain batch 17/31 - 110.1ms/batch - loss: 20.82743 - diff: 14.15mlTrain batch 18/31 - 110.1ms/batch - loss: 20.61640 - diff: 14.13mlTrain batch 19/31 - 109.8ms/batch - loss: 20.54528 - diff: 14.13mlTrain batch 20/31 - 109.9ms/batch - loss: 20.17694 - diff: 14.03mlTrain batch 21/31 - 110.2ms/batch - loss: 19.73194 - diff: 13.88mlTrain batch 22/31 - 109.6ms/batch - loss: 20.24443 - diff: 14.16mlTrain batch 23/31 - 110.2ms/batch - loss: 20.02386 - diff: 14.02mlTrain batch 24/31 - 110.1ms/batch - loss: 19.62683 - diff: 13.89mlTrain batch 25/31 - 110.1ms/batch - loss: 20.00222 - diff: 14.03mlTrain batch 26/31 - 110.2ms/batch - loss: 19.78992 - diff: 13.93mlTrain batch 27/31 - 109.7ms/batch - loss: 23.90629 - diff: 15.02mlTrain batch 28/31 - 109.7ms/batch - loss: 23.66453 - diff: 15.00mlTrain batch 29/31 - 109.0ms/batch - loss: 24.16367 - diff: 15.14mlTrain batch 30/31 - 109.4ms/batch - loss: 24.86430 - diff: 15.40mlTrain batch 31/31 - 69.0ms/batch - loss: 25.12860 - diff: 15.37mlTrain batch 31/31 - 9.8s 69.0ms/batch - loss: 25.12860 - diff: 15.37ml
Test 0.9s: val_loss: 40.04162 - diff: 17.99ml

Epoch 96: current best loss = 36.31351, at epoch 79
Train batch 1/31 - 114.8ms/batch - loss: 21.51067 - diff: 16.59mlTrain batch 2/31 - 109.8ms/batch - loss: 28.60474 - diff: 19.14mlTrain batch 3/31 - 109.8ms/batch - loss: 24.39030 - diff: 17.05mlTrain batch 4/31 - 110.4ms/batch - loss: 20.73331 - diff: 15.37mlTrain batch 5/31 - 113.3ms/batch - loss: 18.31640 - diff: 14.29mlTrain batch 6/31 - 110.2ms/batch - loss: 17.10775 - diff: 13.63mlTrain batch 7/31 - 112.9ms/batch - loss: 16.88632 - diff: 13.42mlTrain batch 8/31 - 109.9ms/batch - loss: 15.68121 - diff: 12.92mlTrain batch 9/31 - 112.8ms/batch - loss: 15.15172 - diff: 12.71mlTrain batch 10/31 - 109.7ms/batch - loss: 16.26484 - diff: 13.11mlTrain batch 11/31 - 112.5ms/batch - loss: 15.73044 - diff: 12.77mlTrain batch 12/31 - 110.8ms/batch - loss: 18.61148 - diff: 13.82mlTrain batch 13/31 - 114.7ms/batch - loss: 22.73134 - diff: 15.09mlTrain batch 14/31 - 110.7ms/batch - loss: 22.34166 - diff: 14.92mlTrain batch 15/31 - 112.0ms/batch - loss: 23.82224 - diff: 15.36mlTrain batch 16/31 - 110.9ms/batch - loss: 22.91149 - diff: 15.00mlTrain batch 17/31 - 112.4ms/batch - loss: 22.44400 - diff: 14.90mlTrain batch 18/31 - 110.1ms/batch - loss: 25.62204 - diff: 15.84mlTrain batch 19/31 - 110.5ms/batch - loss: 24.99608 - diff: 15.62mlTrain batch 20/31 - 111.5ms/batch - loss: 24.35646 - diff: 15.43mlTrain batch 21/31 - 112.2ms/batch - loss: 24.47994 - diff: 15.49mlTrain batch 22/31 - 111.9ms/batch - loss: 24.64049 - diff: 15.54mlTrain batch 23/31 - 110.9ms/batch - loss: 24.74996 - diff: 15.57mlTrain batch 24/31 - 110.6ms/batch - loss: 24.24265 - diff: 15.44mlTrain batch 25/31 - 110.8ms/batch - loss: 24.80526 - diff: 15.52mlTrain batch 26/31 - 110.7ms/batch - loss: 24.54864 - diff: 15.40mlTrain batch 27/31 - 110.1ms/batch - loss: 24.27134 - diff: 15.31mlTrain batch 28/31 - 111.8ms/batch - loss: 23.95128 - diff: 15.18mlTrain batch 29/31 - 110.1ms/batch - loss: 24.08056 - diff: 15.29mlTrain batch 30/31 - 111.0ms/batch - loss: 24.26753 - diff: 15.40mlTrain batch 31/31 - 70.5ms/batch - loss: 24.34807 - diff: 15.35mlTrain batch 31/31 - 9.8s 70.5ms/batch - loss: 24.34807 - diff: 15.35ml
Test 0.8s: val_loss: 43.97629 - diff: 19.63ml

Epoch 97: current best loss = 36.31351, at epoch 79
Train batch 1/31 - 112.0ms/batch - loss: 9.88488 - diff: 10.99mlTrain batch 2/31 - 111.5ms/batch - loss: 14.48357 - diff: 12.70mlTrain batch 3/31 - 110.5ms/batch - loss: 12.25652 - diff: 11.16mlTrain batch 4/31 - 110.1ms/batch - loss: 11.60214 - diff: 10.78mlTrain batch 5/31 - 110.3ms/batch - loss: 13.29279 - diff: 11.59mlTrain batch 6/31 - 111.6ms/batch - loss: 13.90250 - diff: 11.85mlTrain batch 7/31 - 110.0ms/batch - loss: 14.06397 - diff: 11.95mlTrain batch 8/31 - 111.5ms/batch - loss: 13.76186 - diff: 11.86mlTrain batch 9/31 - 110.6ms/batch - loss: 12.76445 - diff: 11.34mlTrain batch 10/31 - 112.9ms/batch - loss: 12.19436 - diff: 11.15mlTrain batch 11/31 - 131.5ms/batch - loss: 11.63064 - diff: 10.73mlTrain batch 12/31 - 139.5ms/batch - loss: 13.27360 - diff: 11.48mlTrain batch 13/31 - 112.7ms/batch - loss: 15.02158 - diff: 12.28mlTrain batch 14/31 - 110.1ms/batch - loss: 15.24742 - diff: 12.35mlTrain batch 15/31 - 114.2ms/batch - loss: 16.84827 - diff: 12.96mlTrain batch 16/31 - 110.0ms/batch - loss: 16.83518 - diff: 13.05mlTrain batch 17/31 - 116.6ms/batch - loss: 17.63340 - diff: 13.30mlTrain batch 18/31 - 110.4ms/batch - loss: 22.63783 - diff: 14.52mlTrain batch 19/31 - 110.1ms/batch - loss: 22.52923 - diff: 14.55mlTrain batch 20/31 - 110.2ms/batch - loss: 22.94834 - diff: 14.66mlTrain batch 21/31 - 110.3ms/batch - loss: 22.88512 - diff: 14.61mlTrain batch 22/31 - 110.2ms/batch - loss: 22.92006 - diff: 14.57mlTrain batch 23/31 - 110.0ms/batch - loss: 22.20734 - diff: 14.33mlTrain batch 24/31 - 110.0ms/batch - loss: 23.44814 - diff: 14.86mlTrain batch 25/31 - 112.4ms/batch - loss: 24.01685 - diff: 15.08mlTrain batch 26/31 - 109.8ms/batch - loss: 23.37606 - diff: 14.83mlTrain batch 27/31 - 113.7ms/batch - loss: 23.01325 - diff: 14.73mlTrain batch 28/31 - 110.1ms/batch - loss: 23.57457 - diff: 14.96mlTrain batch 29/31 - 110.4ms/batch - loss: 23.15692 - diff: 14.82mlTrain batch 30/31 - 109.7ms/batch - loss: 22.88336 - diff: 14.74mlTrain batch 31/31 - 69.2ms/batch - loss: 24.22041 - diff: 14.88mlTrain batch 31/31 - 9.9s 69.2ms/batch - loss: 24.22041 - diff: 14.88ml
Test 0.8s: val_loss: 45.95468 - diff: 18.63ml

Epoch 98: current best loss = 36.31351, at epoch 79
Train batch 1/31 - 119.6ms/batch - loss: 16.47110 - diff: 11.96mlTrain batch 2/31 - 109.6ms/batch - loss: 12.83180 - diff: 10.84mlTrain batch 3/31 - 110.9ms/batch - loss: 11.95276 - diff: 10.63mlTrain batch 4/31 - 109.7ms/batch - loss: 21.46489 - diff: 14.13mlTrain batch 5/31 - 111.6ms/batch - loss: 20.96613 - diff: 14.17mlTrain batch 6/31 - 110.3ms/batch - loss: 18.73142 - diff: 13.47mlTrain batch 7/31 - 109.4ms/batch - loss: 20.08091 - diff: 14.15mlTrain batch 8/31 - 110.0ms/batch - loss: 19.27025 - diff: 13.98mlTrain batch 9/31 - 109.4ms/batch - loss: 19.60028 - diff: 14.20mlTrain batch 10/31 - 109.6ms/batch - loss: 22.41995 - diff: 15.00mlTrain batch 11/31 - 118.6ms/batch - loss: 21.62850 - diff: 14.79mlTrain batch 12/31 - 110.8ms/batch - loss: 23.24943 - diff: 15.26mlTrain batch 13/31 - 109.8ms/batch - loss: 27.30861 - diff: 16.29mlTrain batch 14/31 - 109.7ms/batch - loss: 25.95990 - diff: 15.83mlTrain batch 15/31 - 110.2ms/batch - loss: 25.67662 - diff: 15.73mlTrain batch 16/31 - 109.9ms/batch - loss: 24.98801 - diff: 15.52mlTrain batch 17/31 - 110.3ms/batch - loss: 25.58244 - diff: 15.68mlTrain batch 18/31 - 110.2ms/batch - loss: 24.94778 - diff: 15.53mlTrain batch 19/31 - 110.0ms/batch - loss: 24.56405 - diff: 15.38mlTrain batch 20/31 - 109.9ms/batch - loss: 24.26310 - diff: 15.36mlTrain batch 21/31 - 109.9ms/batch - loss: 23.45631 - diff: 15.05mlTrain batch 22/31 - 109.6ms/batch - loss: 24.05238 - diff: 15.32mlTrain batch 23/31 - 110.0ms/batch - loss: 23.57755 - diff: 15.21mlTrain batch 24/31 - 109.7ms/batch - loss: 23.76656 - diff: 15.30mlTrain batch 25/31 - 110.0ms/batch - loss: 23.46065 - diff: 15.21mlTrain batch 26/31 - 109.8ms/batch - loss: 23.97203 - diff: 15.42mlTrain batch 27/31 - 109.9ms/batch - loss: 23.58283 - diff: 15.24mlTrain batch 28/31 - 109.9ms/batch - loss: 23.23770 - diff: 15.12mlTrain batch 29/31 - 109.5ms/batch - loss: 23.27894 - diff: 15.14mlTrain batch 30/31 - 109.6ms/batch - loss: 22.96716 - diff: 15.06mlTrain batch 31/31 - 76.5ms/batch - loss: 23.31498 - diff: 15.06mlTrain batch 31/31 - 9.8s 76.5ms/batch - loss: 23.31498 - diff: 15.06ml
Test 0.8s: val_loss: 43.88985 - diff: 18.21ml

Epoch 99: current best loss = 36.31351, at epoch 79
Train batch 1/31 - 113.7ms/batch - loss: 62.41396 - diff: 23.87mlTrain batch 2/31 - 110.1ms/batch - loss: 48.17833 - diff: 22.69mlTrain batch 3/31 - 112.7ms/batch - loss: 35.10277 - diff: 18.20mlTrain batch 4/31 - 110.4ms/batch - loss: 31.72408 - diff: 17.54mlTrain batch 5/31 - 110.6ms/batch - loss: 28.55242 - diff: 16.58mlTrain batch 6/31 - 110.3ms/batch - loss: 30.69178 - diff: 17.56mlTrain batch 7/31 - 113.7ms/batch - loss: 27.34007 - diff: 16.13mlTrain batch 8/31 - 110.5ms/batch - loss: 24.70675 - diff: 15.08mlTrain batch 9/31 - 115.9ms/batch - loss: 23.38504 - diff: 14.56mlTrain batch 10/31 - 117.5ms/batch - loss: 22.64885 - diff: 14.38mlTrain batch 11/31 - 114.5ms/batch - loss: 22.01828 - diff: 14.24mlTrain batch 12/31 - 109.8ms/batch - loss: 22.13336 - diff: 14.53mlTrain batch 13/31 - 111.3ms/batch - loss: 24.32805 - diff: 15.20mlTrain batch 14/31 - 113.8ms/batch - loss: 24.08900 - diff: 15.19mlTrain batch 15/31 - 110.2ms/batch - loss: 23.56165 - diff: 15.05mlTrain batch 16/31 - 114.4ms/batch - loss: 23.14595 - diff: 15.03mlTrain batch 17/31 - 111.4ms/batch - loss: 23.11095 - diff: 15.10mlTrain batch 18/31 - 115.6ms/batch - loss: 22.44850 - diff: 14.85mlTrain batch 19/31 - 111.1ms/batch - loss: 24.66536 - diff: 15.56mlTrain batch 20/31 - 113.6ms/batch - loss: 24.37562 - diff: 15.38mlTrain batch 21/31 - 110.6ms/batch - loss: 23.78990 - diff: 15.18mlTrain batch 22/31 - 109.6ms/batch - loss: 23.37889 - diff: 15.08mlTrain batch 23/31 - 110.1ms/batch - loss: 23.48648 - diff: 15.18mlTrain batch 24/31 - 113.7ms/batch - loss: 23.34590 - diff: 15.18mlTrain batch 25/31 - 110.4ms/batch - loss: 23.36051 - diff: 15.09mlTrain batch 26/31 - 116.5ms/batch - loss: 23.48969 - diff: 15.20mlTrain batch 27/31 - 110.1ms/batch - loss: 23.40463 - diff: 15.17mlTrain batch 28/31 - 111.0ms/batch - loss: 23.15731 - diff: 15.14mlTrain batch 29/31 - 109.9ms/batch - loss: 23.18811 - diff: 15.08mlTrain batch 30/31 - 110.8ms/batch - loss: 23.56080 - diff: 15.14mlTrain batch 31/31 - 70.7ms/batch - loss: 23.39450 - diff: 15.04mlTrain batch 31/31 - 9.8s 70.7ms/batch - loss: 23.39450 - diff: 15.04ml
Test 0.8s: val_loss: 39.49543 - diff: 17.90ml

Epoch 100: current best loss = 36.31351, at epoch 79
Train batch 1/31 - 111.7ms/batch - loss: 16.75026 - diff: 12.38mlTrain batch 2/31 - 114.1ms/batch - loss: 12.03818 - diff: 10.19mlTrain batch 3/31 - 110.9ms/batch - loss: 12.15816 - diff: 10.69mlTrain batch 4/31 - 111.0ms/batch - loss: 19.21828 - diff: 13.71mlTrain batch 5/31 - 116.5ms/batch - loss: 17.39902 - diff: 12.88mlTrain batch 6/31 - 113.4ms/batch - loss: 18.66925 - diff: 13.54mlTrain batch 7/31 - 114.5ms/batch - loss: 22.85513 - diff: 15.18mlTrain batch 8/31 - 111.5ms/batch - loss: 22.33392 - diff: 15.06mlTrain batch 9/31 - 148.1ms/batch - loss: 21.00302 - diff: 14.48mlTrain batch 10/31 - 119.5ms/batch - loss: 31.89600 - diff: 16.95mlTrain batch 11/31 - 113.1ms/batch - loss: 30.73759 - diff: 16.74mlTrain batch 12/31 - 110.2ms/batch - loss: 29.44768 - diff: 16.51mlTrain batch 13/31 - 113.6ms/batch - loss: 27.87891 - diff: 15.98mlTrain batch 14/31 - 110.1ms/batch - loss: 26.80307 - diff: 15.70mlTrain batch 15/31 - 113.4ms/batch - loss: 26.21759 - diff: 15.62mlTrain batch 16/31 - 109.8ms/batch - loss: 27.92531 - diff: 16.17mlTrain batch 17/31 - 118.0ms/batch - loss: 26.88553 - diff: 15.72mlTrain batch 18/31 - 110.2ms/batch - loss: 29.15259 - diff: 16.54mlTrain batch 19/31 - 116.7ms/batch - loss: 30.79403 - diff: 17.06mlTrain batch 20/31 - 110.5ms/batch - loss: 30.01957 - diff: 16.83mlTrain batch 21/31 - 113.3ms/batch - loss: 29.84787 - diff: 16.94mlTrain batch 22/31 - 110.0ms/batch - loss: 28.90525 - diff: 16.62mlTrain batch 23/31 - 111.4ms/batch - loss: 29.25556 - diff: 16.79mlTrain batch 24/31 - 110.2ms/batch - loss: 31.21723 - diff: 17.44mlTrain batch 25/31 - 116.2ms/batch - loss: 31.09804 - diff: 17.51mlTrain batch 26/31 - 109.6ms/batch - loss: 30.45654 - diff: 17.25mlTrain batch 27/31 - 114.2ms/batch - loss: 29.98123 - diff: 17.10mlTrain batch 28/31 - 110.7ms/batch - loss: 30.34313 - diff: 17.24mlTrain batch 29/31 - 111.3ms/batch - loss: 30.26882 - diff: 17.24mlTrain batch 30/31 - 109.3ms/batch - loss: 29.83879 - diff: 17.14mlTrain batch 31/31 - 70.1ms/batch - loss: 30.85774 - diff: 17.25mlTrain batch 31/31 - 9.8s 70.1ms/batch - loss: 30.85774 - diff: 17.25ml
Test 0.9s: val_loss: 40.82976 - diff: 18.82ml

Epoch 101: current best loss = 36.31351, at epoch 79
Train batch 1/31 - 112.0ms/batch - loss: 18.32716 - diff: 14.31mlTrain batch 2/31 - 110.5ms/batch - loss: 18.77229 - diff: 13.94mlTrain batch 3/31 - 110.3ms/batch - loss: 28.11140 - diff: 17.42mlTrain batch 4/31 - 110.0ms/batch - loss: 23.89999 - diff: 15.87mlTrain batch 5/31 - 112.9ms/batch - loss: 20.20112 - diff: 14.18mlTrain batch 6/31 - 110.1ms/batch - loss: 20.20326 - diff: 14.19mlTrain batch 7/31 - 110.4ms/batch - loss: 20.19808 - diff: 14.44mlTrain batch 8/31 - 110.4ms/batch - loss: 20.27293 - diff: 14.22mlTrain batch 9/31 - 113.7ms/batch - loss: 18.58550 - diff: 13.41mlTrain batch 10/31 - 110.0ms/batch - loss: 17.69907 - diff: 13.07mlTrain batch 11/31 - 110.4ms/batch - loss: 17.22605 - diff: 12.90mlTrain batch 12/31 - 109.3ms/batch - loss: 16.32197 - diff: 12.52mlTrain batch 13/31 - 111.0ms/batch - loss: 15.74131 - diff: 12.28mlTrain batch 14/31 - 111.4ms/batch - loss: 15.34064 - diff: 12.16mlTrain batch 15/31 - 110.7ms/batch - loss: 16.05062 - diff: 12.45mlTrain batch 16/31 - 113.8ms/batch - loss: 15.98332 - diff: 12.46mlTrain batch 17/31 - 110.3ms/batch - loss: 16.41572 - diff: 12.58mlTrain batch 18/31 - 114.2ms/batch - loss: 17.51152 - diff: 12.86mlTrain batch 19/31 - 110.2ms/batch - loss: 17.24076 - diff: 12.78mlTrain batch 20/31 - 111.8ms/batch - loss: 16.90627 - diff: 12.61mlTrain batch 21/31 - 110.7ms/batch - loss: 17.88231 - diff: 13.01mlTrain batch 22/31 - 113.2ms/batch - loss: 19.37256 - diff: 13.60mlTrain batch 23/31 - 110.7ms/batch - loss: 19.10190 - diff: 13.48mlTrain batch 24/31 - 111.8ms/batch - loss: 19.41531 - diff: 13.58mlTrain batch 25/31 - 110.4ms/batch - loss: 19.09342 - diff: 13.43mlTrain batch 26/31 - 111.7ms/batch - loss: 19.53032 - diff: 13.59mlTrain batch 27/31 - 110.7ms/batch - loss: 20.38191 - diff: 13.94mlTrain batch 28/31 - 111.4ms/batch - loss: 20.87300 - diff: 14.11mlTrain batch 29/31 - 109.6ms/batch - loss: 20.77385 - diff: 14.13mlTrain batch 30/31 - 110.7ms/batch - loss: 20.48551 - diff: 14.03mlTrain batch 31/31 - 70.0ms/batch - loss: 22.02119 - diff: 14.09mlTrain batch 31/31 - 9.9s 70.0ms/batch - loss: 22.02119 - diff: 14.09ml
Test 0.8s: val_loss: 46.45791 - diff: 19.63ml
Epoch   102: reducing learning rate of group 0 to 1.2500e-04.

Epoch 102: current best loss = 36.31351, at epoch 79
Train batch 1/31 - 111.8ms/batch - loss: 22.16169 - diff: 13.68mlTrain batch 2/31 - 112.0ms/batch - loss: 16.88208 - diff: 11.95mlTrain batch 3/31 - 111.4ms/batch - loss: 19.44909 - diff: 13.64mlTrain batch 4/31 - 112.1ms/batch - loss: 20.17755 - diff: 13.98mlTrain batch 5/31 - 110.3ms/batch - loss: 17.63571 - diff: 12.90mlTrain batch 6/31 - 110.4ms/batch - loss: 19.17830 - diff: 13.58mlTrain batch 7/31 - 110.8ms/batch - loss: 18.80229 - diff: 13.18mlTrain batch 8/31 - 119.1ms/batch - loss: 19.08318 - diff: 13.50mlTrain batch 9/31 - 109.7ms/batch - loss: 19.52115 - diff: 13.88mlTrain batch 10/31 - 109.4ms/batch - loss: 18.78909 - diff: 13.54mlTrain batch 11/31 - 110.5ms/batch - loss: 18.27177 - diff: 13.20mlTrain batch 12/31 - 110.3ms/batch - loss: 17.66852 - diff: 12.96mlTrain batch 13/31 - 118.8ms/batch - loss: 17.17783 - diff: 12.82mlTrain batch 14/31 - 113.8ms/batch - loss: 17.18697 - diff: 12.79mlTrain batch 15/31 - 117.3ms/batch - loss: 17.33807 - diff: 12.87mlTrain batch 16/31 - 114.7ms/batch - loss: 17.44170 - diff: 12.91mlTrain batch 17/31 - 111.2ms/batch - loss: 17.21035 - diff: 12.88mlTrain batch 18/31 - 109.8ms/batch - loss: 16.88668 - diff: 12.80mlTrain batch 19/31 - 109.8ms/batch - loss: 16.46945 - diff: 12.66mlTrain batch 20/31 - 109.6ms/batch - loss: 17.58820 - diff: 12.94mlTrain batch 21/31 - 110.5ms/batch - loss: 17.55177 - diff: 12.93mlTrain batch 22/31 - 109.5ms/batch - loss: 17.92520 - diff: 13.15mlTrain batch 23/31 - 110.2ms/batch - loss: 18.96230 - diff: 13.57mlTrain batch 24/31 - 111.5ms/batch - loss: 19.18363 - diff: 13.64mlTrain batch 25/31 - 115.5ms/batch - loss: 19.71640 - diff: 13.89mlTrain batch 26/31 - 110.6ms/batch - loss: 19.57244 - diff: 13.88mlTrain batch 27/31 - 112.8ms/batch - loss: 19.74499 - diff: 13.96mlTrain batch 28/31 - 110.4ms/batch - loss: 19.49795 - diff: 13.91mlTrain batch 29/31 - 110.7ms/batch - loss: 19.20308 - diff: 13.76mlTrain batch 30/31 - 109.5ms/batch - loss: 18.80597 - diff: 13.60mlTrain batch 31/31 - 70.0ms/batch - loss: 18.93812 - diff: 13.59mlTrain batch 31/31 - 9.9s 70.0ms/batch - loss: 18.93812 - diff: 13.59ml
Test 0.8s: val_loss: 39.97083 - diff: 17.66ml

Epoch 103: current best loss = 36.31351, at epoch 79
Train batch 1/31 - 129.1ms/batch - loss: 35.35796 - diff: 21.21mlTrain batch 2/31 - 110.8ms/batch - loss: 23.75456 - diff: 15.78mlTrain batch 3/31 - 110.6ms/batch - loss: 24.02254 - diff: 15.92mlTrain batch 4/31 - 110.2ms/batch - loss: 23.97131 - diff: 15.75mlTrain batch 5/31 - 110.3ms/batch - loss: 27.23440 - diff: 16.60mlTrain batch 6/31 - 109.5ms/batch - loss: 27.80270 - diff: 16.86mlTrain batch 7/31 - 116.1ms/batch - loss: 30.12217 - diff: 17.71mlTrain batch 8/31 - 110.1ms/batch - loss: 28.22511 - diff: 16.94mlTrain batch 9/31 - 110.6ms/batch - loss: 26.19728 - diff: 16.17mlTrain batch 10/31 - 110.3ms/batch - loss: 24.40334 - diff: 15.47mlTrain batch 11/31 - 109.4ms/batch - loss: 24.42014 - diff: 15.55mlTrain batch 12/31 - 109.3ms/batch - loss: 22.90913 - diff: 14.98mlTrain batch 13/31 - 109.8ms/batch - loss: 23.85149 - diff: 15.47mlTrain batch 14/31 - 109.4ms/batch - loss: 23.05661 - diff: 15.11mlTrain batch 15/31 - 109.3ms/batch - loss: 22.69687 - diff: 15.10mlTrain batch 16/31 - 109.5ms/batch - loss: 22.04730 - diff: 14.81mlTrain batch 17/31 - 109.6ms/batch - loss: 24.48629 - diff: 15.60mlTrain batch 18/31 - 109.2ms/batch - loss: 25.79611 - diff: 16.07mlTrain batch 19/31 - 109.7ms/batch - loss: 25.15580 - diff: 15.84mlTrain batch 20/31 - 109.6ms/batch - loss: 24.59238 - diff: 15.67mlTrain batch 21/31 - 109.9ms/batch - loss: 24.69551 - diff: 15.68mlTrain batch 22/31 - 109.8ms/batch - loss: 24.29734 - diff: 15.59mlTrain batch 23/31 - 109.5ms/batch - loss: 23.54103 - diff: 15.28mlTrain batch 24/31 - 109.7ms/batch - loss: 23.49300 - diff: 15.25mlTrain batch 25/31 - 109.5ms/batch - loss: 23.08522 - diff: 15.12mlTrain batch 26/31 - 109.6ms/batch - loss: 22.72905 - diff: 14.96mlTrain batch 27/31 - 109.7ms/batch - loss: 22.37928 - diff: 14.88mlTrain batch 28/31 - 109.3ms/batch - loss: 21.89839 - diff: 14.68mlTrain batch 29/31 - 109.0ms/batch - loss: 22.45298 - diff: 14.91mlTrain batch 30/31 - 109.0ms/batch - loss: 22.15646 - diff: 14.80mlTrain batch 31/31 - 71.5ms/batch - loss: 22.01514 - diff: 14.71mlTrain batch 31/31 - 9.9s 71.5ms/batch - loss: 22.01514 - diff: 14.71ml
Test 0.8s: val_loss: 41.34413 - diff: 19.17ml

Epoch 104: current best loss = 36.31351, at epoch 79
Train batch 1/31 - 111.2ms/batch - loss: 10.58348 - diff: 10.15mlTrain batch 2/31 - 110.6ms/batch - loss: 13.62722 - diff: 11.30mlTrain batch 3/31 - 110.3ms/batch - loss: 12.67608 - diff: 10.76mlTrain batch 4/31 - 110.2ms/batch - loss: 21.94787 - diff: 14.62mlTrain batch 5/31 - 116.3ms/batch - loss: 25.05370 - diff: 16.03mlTrain batch 6/31 - 113.1ms/batch - loss: 23.42652 - diff: 15.56mlTrain batch 7/31 - 109.6ms/batch - loss: 30.53299 - diff: 17.92mlTrain batch 8/31 - 109.9ms/batch - loss: 29.12629 - diff: 17.50mlTrain batch 9/31 - 110.6ms/batch - loss: 26.99151 - diff: 16.67mlTrain batch 10/31 - 110.4ms/batch - loss: 24.93568 - diff: 15.77mlTrain batch 11/31 - 116.9ms/batch - loss: 28.13927 - diff: 16.65mlTrain batch 12/31 - 112.1ms/batch - loss: 29.04147 - diff: 17.18mlTrain batch 13/31 - 111.9ms/batch - loss: 27.73213 - diff: 16.72mlTrain batch 14/31 - 112.4ms/batch - loss: 27.33267 - diff: 16.64mlTrain batch 15/31 - 110.7ms/batch - loss: 26.57042 - diff: 16.40mlTrain batch 16/31 - 112.4ms/batch - loss: 25.94952 - diff: 16.06mlTrain batch 17/31 - 110.4ms/batch - loss: 25.15539 - diff: 15.76mlTrain batch 18/31 - 113.8ms/batch - loss: 24.25589 - diff: 15.47mlTrain batch 19/31 - 110.5ms/batch - loss: 24.66191 - diff: 15.54mlTrain batch 20/31 - 112.8ms/batch - loss: 24.19338 - diff: 15.42mlTrain batch 21/31 - 111.0ms/batch - loss: 23.43170 - diff: 15.16mlTrain batch 22/31 - 112.7ms/batch - loss: 22.79560 - diff: 14.91mlTrain batch 23/31 - 111.3ms/batch - loss: 23.72910 - diff: 15.18mlTrain batch 24/31 - 114.0ms/batch - loss: 23.19751 - diff: 15.03mlTrain batch 25/31 - 110.0ms/batch - loss: 23.79077 - diff: 15.30mlTrain batch 26/31 - 111.3ms/batch - loss: 23.41867 - diff: 15.21mlTrain batch 27/31 - 110.3ms/batch - loss: 22.99881 - diff: 15.07mlTrain batch 28/31 - 110.4ms/batch - loss: 23.07532 - diff: 15.08mlTrain batch 29/31 - 110.5ms/batch - loss: 24.34286 - diff: 15.54mlTrain batch 30/31 - 109.8ms/batch - loss: 24.06987 - diff: 15.46mlTrain batch 31/31 - 70.4ms/batch - loss: 24.92323 - diff: 15.55mlTrain batch 31/31 - 9.8s 70.4ms/batch - loss: 24.92323 - diff: 15.55ml
Test 0.8s: val_loss: 39.33980 - diff: 18.63ml

Epoch 105: current best loss = 36.31351, at epoch 79
Train batch 1/31 - 116.3ms/batch - loss: 19.00332 - diff: 13.72mlTrain batch 2/31 - 110.2ms/batch - loss: 14.92540 - diff: 12.40mlTrain batch 3/31 - 115.2ms/batch - loss: 29.15467 - diff: 17.73mlTrain batch 4/31 - 109.9ms/batch - loss: 28.57930 - diff: 16.58mlTrain batch 5/31 - 129.5ms/batch - loss: 26.05523 - diff: 15.42mlTrain batch 6/31 - 120.8ms/batch - loss: 26.64742 - diff: 15.97mlTrain batch 7/31 - 112.8ms/batch - loss: 24.86481 - diff: 15.46mlTrain batch 8/31 - 109.8ms/batch - loss: 22.91705 - diff: 14.73mlTrain batch 9/31 - 113.8ms/batch - loss: 22.63901 - diff: 14.59mlTrain batch 10/31 - 110.9ms/batch - loss: 22.05905 - diff: 14.33mlTrain batch 11/31 - 120.3ms/batch - loss: 20.90160 - diff: 13.95mlTrain batch 12/31 - 110.4ms/batch - loss: 20.68578 - diff: 13.82mlTrain batch 13/31 - 113.0ms/batch - loss: 19.48354 - diff: 13.31mlTrain batch 14/31 - 110.3ms/batch - loss: 18.95387 - diff: 13.22mlTrain batch 15/31 - 111.1ms/batch - loss: 18.29702 - diff: 13.00mlTrain batch 16/31 - 110.0ms/batch - loss: 18.20536 - diff: 13.03mlTrain batch 17/31 - 110.5ms/batch - loss: 21.13780 - diff: 14.10mlTrain batch 18/31 - 110.1ms/batch - loss: 20.46223 - diff: 13.83mlTrain batch 19/31 - 111.5ms/batch - loss: 20.32830 - diff: 13.81mlTrain batch 20/31 - 110.1ms/batch - loss: 20.15514 - diff: 13.80mlTrain batch 21/31 - 113.0ms/batch - loss: 21.62085 - diff: 14.35mlTrain batch 22/31 - 110.0ms/batch - loss: 21.33727 - diff: 14.30mlTrain batch 23/31 - 113.2ms/batch - loss: 22.48400 - diff: 14.82mlTrain batch 24/31 - 109.8ms/batch - loss: 21.95776 - diff: 14.66mlTrain batch 25/31 - 110.5ms/batch - loss: 21.36720 - diff: 14.42mlTrain batch 26/31 - 111.2ms/batch - loss: 21.99755 - diff: 14.60mlTrain batch 27/31 - 110.4ms/batch - loss: 21.61189 - diff: 14.44mlTrain batch 28/31 - 110.0ms/batch - loss: 21.56682 - diff: 14.41mlTrain batch 29/31 - 112.7ms/batch - loss: 21.36536 - diff: 14.35mlTrain batch 30/31 - 109.0ms/batch - loss: 21.73135 - diff: 14.52mlTrain batch 31/31 - 69.6ms/batch - loss: 21.98080 - diff: 14.54mlTrain batch 31/31 - 9.8s 69.6ms/batch - loss: 21.98080 - diff: 14.54ml
Test 0.8s: val_loss: 44.72399 - diff: 19.24ml

Epoch 106: current best loss = 36.31351, at epoch 79
Train batch 1/31 - 122.6ms/batch - loss: 16.94877 - diff: 13.65mlTrain batch 2/31 - 110.8ms/batch - loss: 15.73926 - diff: 12.56mlTrain batch 3/31 - 113.5ms/batch - loss: 20.84774 - diff: 15.17mlTrain batch 4/31 - 110.6ms/batch - loss: 19.02393 - diff: 14.43mlTrain batch 5/31 - 145.2ms/batch - loss: 18.61329 - diff: 14.12mlTrain batch 6/31 - 114.2ms/batch - loss: 17.87411 - diff: 13.80mlTrain batch 7/31 - 110.2ms/batch - loss: 23.05063 - diff: 15.64mlTrain batch 8/31 - 109.5ms/batch - loss: 22.05421 - diff: 15.42mlTrain batch 9/31 - 113.0ms/batch - loss: 21.13955 - diff: 15.18mlTrain batch 10/31 - 109.9ms/batch - loss: 20.99592 - diff: 15.28mlTrain batch 11/31 - 112.6ms/batch - loss: 21.79467 - diff: 15.25mlTrain batch 12/31 - 109.9ms/batch - loss: 20.68510 - diff: 14.74mlTrain batch 13/31 - 112.6ms/batch - loss: 20.17009 - diff: 14.53mlTrain batch 14/31 - 109.9ms/batch - loss: 20.78739 - diff: 14.85mlTrain batch 15/31 - 111.9ms/batch - loss: 20.75899 - diff: 14.77mlTrain batch 16/31 - 110.2ms/batch - loss: 22.91957 - diff: 15.59mlTrain batch 17/31 - 110.7ms/batch - loss: 22.70937 - diff: 15.53mlTrain batch 18/31 - 110.1ms/batch - loss: 23.61470 - diff: 15.84mlTrain batch 19/31 - 110.8ms/batch - loss: 25.22617 - diff: 16.45mlTrain batch 20/31 - 110.2ms/batch - loss: 24.52735 - diff: 16.18mlTrain batch 21/31 - 110.7ms/batch - loss: 24.20364 - diff: 16.11mlTrain batch 22/31 - 110.1ms/batch - loss: 23.79318 - diff: 15.93mlTrain batch 23/31 - 110.9ms/batch - loss: 23.11078 - diff: 15.62mlTrain batch 24/31 - 110.5ms/batch - loss: 23.13602 - diff: 15.52mlTrain batch 25/31 - 112.8ms/batch - loss: 22.95968 - diff: 15.49mlTrain batch 26/31 - 110.2ms/batch - loss: 22.46884 - diff: 15.27mlTrain batch 27/31 - 113.4ms/batch - loss: 22.09146 - diff: 15.11mlTrain batch 28/31 - 109.9ms/batch - loss: 22.02748 - diff: 15.09mlTrain batch 29/31 - 112.0ms/batch - loss: 21.73673 - diff: 14.98mlTrain batch 30/31 - 109.7ms/batch - loss: 21.40312 - diff: 14.86mlTrain batch 31/31 - 74.5ms/batch - loss: 26.51186 - diff: 15.36mlTrain batch 31/31 - 9.9s 74.5ms/batch - loss: 26.51186 - diff: 15.36ml
Test 0.8s: val_loss: 41.34938 - diff: 19.62ml

Epoch 107: current best loss = 36.31351, at epoch 79
Train batch 1/31 - 112.1ms/batch - loss: 28.52917 - diff: 16.66mlTrain batch 2/31 - 110.1ms/batch - loss: 25.17921 - diff: 15.56mlTrain batch 3/31 - 112.5ms/batch - loss: 19.07790 - diff: 13.34mlTrain batch 4/31 - 112.8ms/batch - loss: 17.46339 - diff: 12.67mlTrain batch 5/31 - 114.4ms/batch - loss: 22.13869 - diff: 14.87mlTrain batch 6/31 - 109.9ms/batch - loss: 23.04300 - diff: 15.35mlTrain batch 7/31 - 114.7ms/batch - loss: 21.49137 - diff: 14.72mlTrain batch 8/31 - 112.8ms/batch - loss: 21.45581 - diff: 14.71mlTrain batch 9/31 - 113.9ms/batch - loss: 22.94032 - diff: 15.38mlTrain batch 10/31 - 111.7ms/batch - loss: 21.83710 - diff: 14.93mlTrain batch 11/31 - 111.5ms/batch - loss: 22.05298 - diff: 14.89mlTrain batch 12/31 - 112.5ms/batch - loss: 22.06875 - diff: 14.92mlTrain batch 13/31 - 115.7ms/batch - loss: 20.84191 - diff: 14.37mlTrain batch 14/31 - 111.9ms/batch - loss: 20.54606 - diff: 14.38mlTrain batch 15/31 - 114.9ms/batch - loss: 19.62062 - diff: 14.05mlTrain batch 16/31 - 112.4ms/batch - loss: 18.98003 - diff: 13.75mlTrain batch 17/31 - 113.3ms/batch - loss: 18.85692 - diff: 13.81mlTrain batch 18/31 - 116.6ms/batch - loss: 19.02191 - diff: 13.81mlTrain batch 19/31 - 111.3ms/batch - loss: 26.91515 - diff: 15.24mlTrain batch 20/31 - 118.1ms/batch - loss: 26.10792 - diff: 15.02mlTrain batch 21/31 - 115.2ms/batch - loss: 25.55597 - diff: 14.87mlTrain batch 22/31 - 113.9ms/batch - loss: 25.23543 - diff: 14.89mlTrain batch 23/31 - 112.4ms/batch - loss: 24.41251 - diff: 14.59mlTrain batch 24/31 - 111.4ms/batch - loss: 23.52255 - diff: 14.21mlTrain batch 25/31 - 111.7ms/batch - loss: 23.00712 - diff: 14.09mlTrain batch 26/31 - 112.7ms/batch - loss: 22.71398 - diff: 14.03mlTrain batch 27/31 - 112.6ms/batch - loss: 22.84495 - diff: 14.05mlTrain batch 28/31 - 113.9ms/batch - loss: 22.53951 - diff: 13.97mlTrain batch 29/31 - 111.6ms/batch - loss: 22.23468 - diff: 13.91mlTrain batch 30/31 - 110.7ms/batch - loss: 21.72708 - diff: 13.71mlTrain batch 31/31 - 69.8ms/batch - loss: 21.97796 - diff: 13.71mlTrain batch 31/31 - 9.8s 69.8ms/batch - loss: 21.97796 - diff: 13.71ml
Test 0.8s: val_loss: 43.55774 - diff: 18.86ml

Epoch 108: current best loss = 36.31351, at epoch 79
Train batch 1/31 - 113.9ms/batch - loss: 8.37915 - diff: 9.64mlTrain batch 2/31 - 111.0ms/batch - loss: 12.88274 - diff: 11.75mlTrain batch 3/31 - 124.0ms/batch - loss: 17.59321 - diff: 13.84mlTrain batch 4/31 - 118.6ms/batch - loss: 25.88214 - diff: 16.93mlTrain batch 5/31 - 112.4ms/batch - loss: 26.22213 - diff: 17.06mlTrain batch 6/31 - 109.7ms/batch - loss: 26.96838 - diff: 17.42mlTrain batch 7/31 - 117.1ms/batch - loss: 26.74922 - diff: 17.36mlTrain batch 8/31 - 113.0ms/batch - loss: 27.34126 - diff: 17.03mlTrain batch 9/31 - 118.9ms/batch - loss: 26.46996 - diff: 16.86mlTrain batch 10/31 - 112.1ms/batch - loss: 26.11656 - diff: 16.65mlTrain batch 11/31 - 117.7ms/batch - loss: 26.07911 - diff: 16.74mlTrain batch 12/31 - 112.6ms/batch - loss: 24.79911 - diff: 16.34mlTrain batch 13/31 - 116.7ms/batch - loss: 23.45503 - diff: 15.70mlTrain batch 14/31 - 111.9ms/batch - loss: 23.50772 - diff: 15.81mlTrain batch 15/31 - 115.9ms/batch - loss: 22.85882 - diff: 15.51mlTrain batch 16/31 - 110.2ms/batch - loss: 21.82465 - diff: 15.03mlTrain batch 17/31 - 119.0ms/batch - loss: 21.49134 - diff: 14.95mlTrain batch 18/31 - 110.7ms/batch - loss: 20.77279 - diff: 14.61mlTrain batch 19/31 - 129.9ms/batch - loss: 20.45323 - diff: 14.51mlTrain batch 20/31 - 114.7ms/batch - loss: 20.34443 - diff: 14.30mlTrain batch 21/31 - 127.8ms/batch - loss: 21.10687 - diff: 14.53mlTrain batch 22/31 - 113.6ms/batch - loss: 21.01659 - diff: 14.49mlTrain batch 23/31 - 127.3ms/batch - loss: 20.83179 - diff: 14.50mlTrain batch 24/31 - 110.3ms/batch - loss: 20.47295 - diff: 14.38mlTrain batch 25/31 - 125.4ms/batch - loss: 20.69351 - diff: 14.51mlTrain batch 26/31 - 109.7ms/batch - loss: 21.19891 - diff: 14.76mlTrain batch 27/31 - 116.0ms/batch - loss: 21.52748 - diff: 14.91mlTrain batch 28/31 - 111.2ms/batch - loss: 21.81265 - diff: 15.01mlTrain batch 29/31 - 111.3ms/batch - loss: 21.44204 - diff: 14.83mlTrain batch 30/31 - 110.0ms/batch - loss: 22.16181 - diff: 15.08mlTrain batch 31/31 - 69.3ms/batch - loss: 23.44800 - diff: 15.21mlTrain batch 31/31 - 9.8s 69.3ms/batch - loss: 23.44800 - diff: 15.21ml
Test 0.8s: val_loss: 36.85362 - diff: 17.84ml

Epoch 109: current best loss = 36.31351, at epoch 79
Train batch 1/31 - 114.4ms/batch - loss: 12.49751 - diff: 10.98mlTrain batch 2/31 - 110.5ms/batch - loss: 15.17429 - diff: 12.44mlTrain batch 3/31 - 127.1ms/batch - loss: 16.97226 - diff: 12.93mlTrain batch 4/31 - 120.5ms/batch - loss: 21.44668 - diff: 14.73mlTrain batch 5/31 - 114.1ms/batch - loss: 21.52916 - diff: 15.05mlTrain batch 6/31 - 110.3ms/batch - loss: 19.53981 - diff: 14.09mlTrain batch 7/31 - 110.9ms/batch - loss: 19.25839 - diff: 14.16mlTrain batch 8/31 - 110.1ms/batch - loss: 18.51652 - diff: 13.91mlTrain batch 9/31 - 114.0ms/batch - loss: 17.36386 - diff: 13.43mlTrain batch 10/31 - 110.5ms/batch - loss: 17.03470 - diff: 13.30mlTrain batch 11/31 - 110.3ms/batch - loss: 16.23493 - diff: 12.99mlTrain batch 12/31 - 110.2ms/batch - loss: 16.14795 - diff: 12.97mlTrain batch 13/31 - 111.6ms/batch - loss: 15.97153 - diff: 12.96mlTrain batch 14/31 - 111.0ms/batch - loss: 16.74633 - diff: 13.32mlTrain batch 15/31 - 110.7ms/batch - loss: 17.55994 - diff: 13.64mlTrain batch 16/31 - 109.9ms/batch - loss: 20.11856 - diff: 14.48mlTrain batch 17/31 - 110.0ms/batch - loss: 20.20865 - diff: 14.58mlTrain batch 18/31 - 109.7ms/batch - loss: 20.38239 - diff: 14.71mlTrain batch 19/31 - 110.5ms/batch - loss: 25.74754 - diff: 16.13mlTrain batch 20/31 - 109.9ms/batch - loss: 25.86079 - diff: 16.13mlTrain batch 21/31 - 110.1ms/batch - loss: 25.37445 - diff: 16.04mlTrain batch 22/31 - 109.9ms/batch - loss: 26.03891 - diff: 16.18mlTrain batch 23/31 - 109.9ms/batch - loss: 25.20046 - diff: 15.81mlTrain batch 24/31 - 109.7ms/batch - loss: 24.97911 - diff: 15.77mlTrain batch 25/31 - 110.7ms/batch - loss: 25.17099 - diff: 15.88mlTrain batch 26/31 - 110.3ms/batch - loss: 24.49843 - diff: 15.61mlTrain batch 27/31 - 110.9ms/batch - loss: 24.36355 - diff: 15.59mlTrain batch 28/31 - 110.5ms/batch - loss: 24.55981 - diff: 15.67mlTrain batch 29/31 - 109.6ms/batch - loss: 24.34561 - diff: 15.63mlTrain batch 30/31 - 109.4ms/batch - loss: 24.04479 - diff: 15.57mlTrain batch 31/31 - 69.1ms/batch - loss: 24.15449 - diff: 15.54mlTrain batch 31/31 - 10.0s 69.1ms/batch - loss: 24.15449 - diff: 15.54ml
Test 0.8s: val_loss: 39.04420 - diff: 17.63ml

Epoch 110: current best loss = 36.31351, at epoch 79
Train batch 1/31 - 110.9ms/batch - loss: 12.61371 - diff: 11.37mlTrain batch 2/31 - 110.0ms/batch - loss: 13.50566 - diff: 11.54mlTrain batch 3/31 - 112.4ms/batch - loss: 13.97190 - diff: 11.20mlTrain batch 4/31 - 110.9ms/batch - loss: 14.55953 - diff: 11.79mlTrain batch 5/31 - 110.5ms/batch - loss: 14.35839 - diff: 12.05mlTrain batch 6/31 - 111.0ms/batch - loss: 14.23849 - diff: 12.10mlTrain batch 7/31 - 110.2ms/batch - loss: 13.57694 - diff: 11.93mlTrain batch 8/31 - 110.2ms/batch - loss: 35.49842 - diff: 16.64mlTrain batch 9/31 - 110.2ms/batch - loss: 39.16837 - diff: 18.19mlTrain batch 10/31 - 110.6ms/batch - loss: 36.91612 - diff: 17.64mlTrain batch 11/31 - 110.8ms/batch - loss: 36.05456 - diff: 17.68mlTrain batch 12/31 - 112.3ms/batch - loss: 35.01577 - diff: 17.62mlTrain batch 13/31 - 111.5ms/batch - loss: 33.81870 - diff: 17.27mlTrain batch 14/31 - 112.5ms/batch - loss: 32.73583 - diff: 17.06mlTrain batch 15/31 - 110.8ms/batch - loss: 32.16954 - diff: 16.95mlTrain batch 16/31 - 110.5ms/batch - loss: 31.63257 - diff: 16.94mlTrain batch 17/31 - 110.1ms/batch - loss: 30.14991 - diff: 16.43mlTrain batch 18/31 - 111.9ms/batch - loss: 29.05209 - diff: 16.02mlTrain batch 19/31 - 110.5ms/batch - loss: 27.89955 - diff: 15.64mlTrain batch 20/31 - 111.4ms/batch - loss: 27.97814 - diff: 15.78mlTrain batch 21/31 - 109.5ms/batch - loss: 26.93993 - diff: 15.39mlTrain batch 22/31 - 111.1ms/batch - loss: 26.87812 - diff: 15.42mlTrain batch 23/31 - 110.2ms/batch - loss: 26.15835 - diff: 15.18mlTrain batch 24/31 - 111.9ms/batch - loss: 25.50040 - diff: 14.97mlTrain batch 25/31 - 110.0ms/batch - loss: 24.77212 - diff: 14.73mlTrain batch 26/31 - 110.1ms/batch - loss: 24.38446 - diff: 14.66mlTrain batch 27/31 - 110.4ms/batch - loss: 25.17227 - diff: 15.05mlTrain batch 28/31 - 110.8ms/batch - loss: 24.52038 - diff: 14.80mlTrain batch 29/31 - 109.9ms/batch - loss: 26.81760 - diff: 15.50mlTrain batch 30/31 - 110.4ms/batch - loss: 26.59177 - diff: 15.46mlTrain batch 31/31 - 71.2ms/batch - loss: 26.65545 - diff: 15.40mlTrain batch 31/31 - 9.9s 71.2ms/batch - loss: 26.65545 - diff: 15.40ml
Test 0.8s: val_loss: 49.72082 - diff: 19.33ml

Epoch 111: current best loss = 36.31351, at epoch 79
Train batch 1/31 - 120.5ms/batch - loss: 10.99452 - diff: 10.24mlTrain batch 2/31 - 118.6ms/batch - loss: 12.64531 - diff: 11.01mlTrain batch 3/31 - 112.9ms/batch - loss: 18.59001 - diff: 13.53mlTrain batch 4/31 - 110.8ms/batch - loss: 15.98750 - diff: 12.38mlTrain batch 5/31 - 119.2ms/batch - loss: 15.48523 - diff: 12.28mlTrain batch 6/31 - 111.8ms/batch - loss: 15.76858 - diff: 12.43mlTrain batch 7/31 - 124.4ms/batch - loss: 15.13243 - diff: 12.34mlTrain batch 8/31 - 111.6ms/batch - loss: 16.30076 - diff: 12.93mlTrain batch 9/31 - 114.6ms/batch - loss: 18.98577 - diff: 14.07mlTrain batch 10/31 - 110.8ms/batch - loss: 17.70919 - diff: 13.46mlTrain batch 11/31 - 117.8ms/batch - loss: 17.87539 - diff: 13.52mlTrain batch 12/31 - 110.5ms/batch - loss: 19.63972 - diff: 14.19mlTrain batch 13/31 - 115.9ms/batch - loss: 18.64630 - diff: 13.77mlTrain batch 14/31 - 109.9ms/batch - loss: 17.97021 - diff: 13.46mlTrain batch 15/31 - 116.1ms/batch - loss: 17.36937 - diff: 13.20mlTrain batch 16/31 - 110.7ms/batch - loss: 16.74562 - diff: 12.99mlTrain batch 17/31 - 115.4ms/batch - loss: 16.39743 - diff: 12.78mlTrain batch 18/31 - 110.7ms/batch - loss: 16.39306 - diff: 12.64mlTrain batch 19/31 - 111.5ms/batch - loss: 15.76278 - diff: 12.34mlTrain batch 20/31 - 110.2ms/batch - loss: 15.46006 - diff: 12.25mlTrain batch 21/31 - 118.0ms/batch - loss: 16.00557 - diff: 12.50mlTrain batch 22/31 - 110.9ms/batch - loss: 15.91944 - diff: 12.47mlTrain batch 23/31 - 111.4ms/batch - loss: 15.56762 - diff: 12.30mlTrain batch 24/31 - 110.7ms/batch - loss: 15.46483 - diff: 12.28mlTrain batch 25/31 - 111.8ms/batch - loss: 15.47257 - diff: 12.23mlTrain batch 26/31 - 109.7ms/batch - loss: 17.39339 - diff: 12.93mlTrain batch 27/31 - 124.1ms/batch - loss: 17.21801 - diff: 12.93mlTrain batch 28/31 - 112.1ms/batch - loss: 18.34409 - diff: 13.16mlTrain batch 29/31 - 110.7ms/batch - loss: 18.44942 - diff: 13.24mlTrain batch 30/31 - 109.8ms/batch - loss: 18.58823 - diff: 13.25mlTrain batch 31/31 - 69.5ms/batch - loss: 18.51608 - diff: 13.18mlTrain batch 31/31 - 9.9s 69.5ms/batch - loss: 18.51608 - diff: 13.18ml
Test 0.8s: val_loss: 40.87379 - diff: 18.82ml

Epoch 112: current best loss = 36.31351, at epoch 79
Train batch 1/31 - 143.6ms/batch - loss: 96.49810 - diff: 38.06mlTrain batch 2/31 - 117.5ms/batch - loss: 55.73651 - diff: 24.76mlTrain batch 3/31 - 112.3ms/batch - loss: 48.96783 - diff: 23.30mlTrain batch 4/31 - 110.3ms/batch - loss: 48.24679 - diff: 23.26mlTrain batch 5/31 - 110.1ms/batch - loss: 41.62210 - diff: 21.01mlTrain batch 6/31 - 109.8ms/batch - loss: 37.62775 - diff: 19.92mlTrain batch 7/31 - 113.8ms/batch - loss: 33.42830 - diff: 18.48mlTrain batch 8/31 - 110.4ms/batch - loss: 30.49847 - diff: 17.55mlTrain batch 9/31 - 112.0ms/batch - loss: 30.49975 - diff: 17.84mlTrain batch 10/31 - 109.9ms/batch - loss: 28.93548 - diff: 17.24mlTrain batch 11/31 - 110.3ms/batch - loss: 27.27835 - diff: 16.69mlTrain batch 12/31 - 110.4ms/batch - loss: 26.25921 - diff: 16.33mlTrain batch 13/31 - 111.2ms/batch - loss: 26.40570 - diff: 16.51mlTrain batch 14/31 - 110.3ms/batch - loss: 28.55143 - diff: 17.40mlTrain batch 15/31 - 111.4ms/batch - loss: 27.04619 - diff: 16.79mlTrain batch 16/31 - 109.6ms/batch - loss: 25.70570 - diff: 16.21mlTrain batch 17/31 - 111.8ms/batch - loss: 24.88594 - diff: 15.94mlTrain batch 18/31 - 109.9ms/batch - loss: 24.01468 - diff: 15.54mlTrain batch 19/31 - 112.7ms/batch - loss: 24.22288 - diff: 15.61mlTrain batch 20/31 - 109.9ms/batch - loss: 24.05774 - diff: 15.53mlTrain batch 21/31 - 111.9ms/batch - loss: 24.45244 - diff: 15.45mlTrain batch 22/31 - 110.8ms/batch - loss: 24.60957 - diff: 15.56mlTrain batch 23/31 - 112.7ms/batch - loss: 23.91407 - diff: 15.27mlTrain batch 24/31 - 110.2ms/batch - loss: 23.46666 - diff: 15.12mlTrain batch 25/31 - 112.7ms/batch - loss: 23.86667 - diff: 15.15mlTrain batch 26/31 - 109.3ms/batch - loss: 23.27384 - diff: 14.96mlTrain batch 27/31 - 111.4ms/batch - loss: 22.92356 - diff: 14.84mlTrain batch 28/31 - 109.8ms/batch - loss: 22.50876 - diff: 14.68mlTrain batch 29/31 - 111.9ms/batch - loss: 22.36197 - diff: 14.65mlTrain batch 30/31 - 109.4ms/batch - loss: 22.83036 - diff: 14.81mlTrain batch 31/31 - 68.9ms/batch - loss: 23.11012 - diff: 14.78mlTrain batch 31/31 - 9.9s 68.9ms/batch - loss: 23.11012 - diff: 14.78ml
Test 0.8s: val_loss: 43.58052 - diff: 18.79ml
Epoch   113: reducing learning rate of group 0 to 6.2500e-05.

Epoch 113: current best loss = 36.31351, at epoch 79
Train batch 1/31 - 112.2ms/batch - loss: 7.77811 - diff: 9.11mlTrain batch 2/31 - 110.8ms/batch - loss: 17.00235 - diff: 13.68mlTrain batch 3/31 - 110.5ms/batch - loss: 17.02479 - diff: 13.74mlTrain batch 4/31 - 110.8ms/batch - loss: 21.61378 - diff: 15.48mlTrain batch 5/31 - 110.1ms/batch - loss: 23.03628 - diff: 16.13mlTrain batch 6/31 - 112.2ms/batch - loss: 20.21009 - diff: 14.81mlTrain batch 7/31 - 109.8ms/batch - loss: 18.88500 - diff: 14.32mlTrain batch 8/31 - 111.6ms/batch - loss: 20.35023 - diff: 14.75mlTrain batch 9/31 - 110.0ms/batch - loss: 19.23106 - diff: 14.36mlTrain batch 10/31 - 111.1ms/batch - loss: 18.85074 - diff: 14.16mlTrain batch 11/31 - 109.6ms/batch - loss: 18.66658 - diff: 14.14mlTrain batch 12/31 - 111.7ms/batch - loss: 18.42991 - diff: 14.02mlTrain batch 13/31 - 109.3ms/batch - loss: 18.45889 - diff: 14.02mlTrain batch 14/31 - 110.6ms/batch - loss: 18.25706 - diff: 13.94mlTrain batch 15/31 - 109.5ms/batch - loss: 17.67651 - diff: 13.63mlTrain batch 16/31 - 110.6ms/batch - loss: 18.26762 - diff: 13.83mlTrain batch 17/31 - 109.7ms/batch - loss: 18.33216 - diff: 13.88mlTrain batch 18/31 - 111.7ms/batch - loss: 17.95601 - diff: 13.72mlTrain batch 19/31 - 110.0ms/batch - loss: 17.96018 - diff: 13.72mlTrain batch 20/31 - 110.9ms/batch - loss: 17.74609 - diff: 13.59mlTrain batch 21/31 - 110.0ms/batch - loss: 17.33659 - diff: 13.43mlTrain batch 22/31 - 110.1ms/batch - loss: 17.04884 - diff: 13.31mlTrain batch 23/31 - 110.0ms/batch - loss: 17.12643 - diff: 13.28mlTrain batch 24/31 - 109.8ms/batch - loss: 17.76599 - diff: 13.44mlTrain batch 25/31 - 109.8ms/batch - loss: 18.48259 - diff: 13.72mlTrain batch 26/31 - 109.8ms/batch - loss: 18.26945 - diff: 13.66mlTrain batch 27/31 - 109.5ms/batch - loss: 17.93642 - diff: 13.51mlTrain batch 28/31 - 109.2ms/batch - loss: 18.19895 - diff: 13.67mlTrain batch 29/31 - 109.3ms/batch - loss: 18.98603 - diff: 13.98mlTrain batch 30/31 - 109.7ms/batch - loss: 18.54647 - diff: 13.73mlTrain batch 31/31 - 70.0ms/batch - loss: 19.19668 - diff: 13.79mlTrain batch 31/31 - 9.9s 70.0ms/batch - loss: 19.19668 - diff: 13.79ml
Test 0.8s: val_loss: 42.10802 - diff: 18.00ml

Epoch 114: current best loss = 36.31351, at epoch 79
Train batch 1/31 - 111.3ms/batch - loss: 15.49262 - diff: 14.04mlTrain batch 2/31 - 110.5ms/batch - loss: 22.75496 - diff: 16.10mlTrain batch 3/31 - 113.1ms/batch - loss: 18.89110 - diff: 14.19mlTrain batch 4/31 - 111.4ms/batch - loss: 17.17260 - diff: 13.45mlTrain batch 5/31 - 110.7ms/batch - loss: 16.04353 - diff: 12.99mlTrain batch 6/31 - 110.6ms/batch - loss: 15.82368 - diff: 12.89mlTrain batch 7/31 - 110.7ms/batch - loss: 14.94731 - diff: 12.59mlTrain batch 8/31 - 110.9ms/batch - loss: 14.03556 - diff: 12.02mlTrain batch 9/31 - 111.0ms/batch - loss: 14.43899 - diff: 11.92mlTrain batch 10/31 - 110.9ms/batch - loss: 13.80400 - diff: 11.58mlTrain batch 11/31 - 110.6ms/batch - loss: 16.70601 - diff: 12.80mlTrain batch 12/31 - 110.3ms/batch - loss: 16.26499 - diff: 12.60mlTrain batch 13/31 - 110.7ms/batch - loss: 17.88649 - diff: 13.27mlTrain batch 14/31 - 111.2ms/batch - loss: 17.46906 - diff: 13.13mlTrain batch 15/31 - 112.6ms/batch - loss: 18.89486 - diff: 13.80mlTrain batch 16/31 - 111.0ms/batch - loss: 18.52538 - diff: 13.66mlTrain batch 17/31 - 112.3ms/batch - loss: 18.56344 - diff: 13.73mlTrain batch 18/31 - 110.1ms/batch - loss: 18.17611 - diff: 13.56mlTrain batch 19/31 - 112.2ms/batch - loss: 17.36732 - diff: 13.14mlTrain batch 20/31 - 110.2ms/batch - loss: 18.65211 - diff: 13.70mlTrain batch 21/31 - 110.7ms/batch - loss: 18.40731 - diff: 13.66mlTrain batch 22/31 - 110.6ms/batch - loss: 21.20486 - diff: 14.51mlTrain batch 23/31 - 110.7ms/batch - loss: 20.80310 - diff: 14.37mlTrain batch 24/31 - 110.6ms/batch - loss: 20.48885 - diff: 14.26mlTrain batch 25/31 - 110.3ms/batch - loss: 20.65482 - diff: 14.34mlTrain batch 26/31 - 110.2ms/batch - loss: 20.40659 - diff: 14.26mlTrain batch 27/31 - 109.8ms/batch - loss: 20.33453 - diff: 14.26mlTrain batch 28/31 - 109.4ms/batch - loss: 21.75444 - diff: 14.65mlTrain batch 29/31 - 109.9ms/batch - loss: 21.37912 - diff: 14.51mlTrain batch 30/31 - 109.7ms/batch - loss: 21.26997 - diff: 14.51mlTrain batch 31/31 - 69.8ms/batch - loss: 22.50492 - diff: 14.67mlTrain batch 31/31 - 9.9s 69.8ms/batch - loss: 22.50492 - diff: 14.67ml
Test 0.9s: val_loss: 46.72726 - diff: 20.08ml

Epoch 115: current best loss = 36.31351, at epoch 79
Train batch 1/31 - 111.8ms/batch - loss: 16.98751 - diff: 13.60mlTrain batch 2/31 - 112.2ms/batch - loss: 18.78553 - diff: 14.45mlTrain batch 3/31 - 110.4ms/batch - loss: 25.85848 - diff: 17.72mlTrain batch 4/31 - 111.6ms/batch - loss: 22.16731 - diff: 16.10mlTrain batch 5/31 - 110.3ms/batch - loss: 34.62764 - diff: 20.01mlTrain batch 6/31 - 110.8ms/batch - loss: 31.37497 - diff: 18.60mlTrain batch 7/31 - 110.3ms/batch - loss: 29.17681 - diff: 17.85mlTrain batch 8/31 - 110.5ms/batch - loss: 27.59994 - diff: 17.05mlTrain batch 9/31 - 110.4ms/batch - loss: 25.68361 - diff: 16.33mlTrain batch 10/31 - 112.1ms/batch - loss: 24.00011 - diff: 15.68mlTrain batch 11/31 - 110.2ms/batch - loss: 22.30092 - diff: 15.00mlTrain batch 12/31 - 113.7ms/batch - loss: 22.14360 - diff: 14.92mlTrain batch 13/31 - 110.2ms/batch - loss: 21.29537 - diff: 14.57mlTrain batch 14/31 - 111.9ms/batch - loss: 20.63969 - diff: 14.35mlTrain batch 15/31 - 109.6ms/batch - loss: 19.88107 - diff: 14.06mlTrain batch 16/31 - 111.6ms/batch - loss: 19.10064 - diff: 13.70mlTrain batch 17/31 - 110.6ms/batch - loss: 19.19855 - diff: 13.65mlTrain batch 18/31 - 111.8ms/batch - loss: 18.65305 - diff: 13.47mlTrain batch 19/31 - 110.3ms/batch - loss: 18.69596 - diff: 13.43mlTrain batch 20/31 - 111.2ms/batch - loss: 18.15748 - diff: 13.21mlTrain batch 21/31 - 110.4ms/batch - loss: 17.60285 - diff: 12.98mlTrain batch 22/31 - 111.2ms/batch - loss: 17.20202 - diff: 12.78mlTrain batch 23/31 - 110.5ms/batch - loss: 17.11361 - diff: 12.81mlTrain batch 24/31 - 111.1ms/batch - loss: 17.47949 - diff: 12.88mlTrain batch 25/31 - 110.0ms/batch - loss: 17.13471 - diff: 12.76mlTrain batch 26/31 - 110.0ms/batch - loss: 16.84725 - diff: 12.64mlTrain batch 27/31 - 110.1ms/batch - loss: 16.42615 - diff: 12.45mlTrain batch 28/31 - 110.6ms/batch - loss: 16.19123 - diff: 12.32mlTrain batch 29/31 - 110.0ms/batch - loss: 16.87256 - diff: 12.63mlTrain batch 30/31 - 109.9ms/batch - loss: 16.57404 - diff: 12.48mlTrain batch 31/31 - 71.6ms/batch - loss: 18.95469 - diff: 12.78mlTrain batch 31/31 - 9.9s 71.6ms/batch - loss: 18.95469 - diff: 12.78ml
Test 0.9s: val_loss: 39.63308 - diff: 18.05ml

Epoch 116: current best loss = 36.31351, at epoch 79
Train batch 1/31 - 112.8ms/batch - loss: 17.02949 - diff: 13.69mlTrain batch 2/31 - 114.3ms/batch - loss: 14.67994 - diff: 12.79mlTrain batch 3/31 - 111.8ms/batch - loss: 12.99368 - diff: 11.81mlTrain batch 4/31 - 112.5ms/batch - loss: 13.16401 - diff: 11.63mlTrain batch 5/31 - 113.2ms/batch - loss: 28.03812 - diff: 13.88mlTrain batch 6/31 - 112.5ms/batch - loss: 25.48936 - diff: 13.38mlTrain batch 7/31 - 113.2ms/batch - loss: 24.63233 - diff: 13.56mlTrain batch 8/31 - 112.9ms/batch - loss: 23.18312 - diff: 13.25mlTrain batch 9/31 - 113.5ms/batch - loss: 22.99080 - diff: 13.39mlTrain batch 10/31 - 113.4ms/batch - loss: 21.56136 - diff: 13.02mlTrain batch 11/31 - 113.2ms/batch - loss: 21.15015 - diff: 13.03mlTrain batch 12/31 - 113.9ms/batch - loss: 20.14313 - diff: 12.70mlTrain batch 13/31 - 113.6ms/batch - loss: 21.86898 - diff: 13.24mlTrain batch 14/31 - 111.1ms/batch - loss: 21.24398 - diff: 13.17mlTrain batch 15/31 - 116.1ms/batch - loss: 20.74442 - diff: 13.09mlTrain batch 16/31 - 111.8ms/batch - loss: 19.87888 - diff: 12.82mlTrain batch 17/31 - 112.3ms/batch - loss: 19.02919 - diff: 12.53mlTrain batch 18/31 - 113.9ms/batch - loss: 18.39165 - diff: 12.33mlTrain batch 19/31 - 113.0ms/batch - loss: 18.02005 - diff: 12.29mlTrain batch 20/31 - 114.6ms/batch - loss: 17.53611 - diff: 12.12mlTrain batch 21/31 - 113.1ms/batch - loss: 17.40047 - diff: 12.14mlTrain batch 22/31 - 112.5ms/batch - loss: 16.81647 - diff: 11.92mlTrain batch 23/31 - 113.8ms/batch - loss: 16.52756 - diff: 11.84mlTrain batch 24/31 - 112.5ms/batch - loss: 16.15544 - diff: 11.67mlTrain batch 25/31 - 113.6ms/batch - loss: 15.90393 - diff: 11.59mlTrain batch 26/31 - 118.2ms/batch - loss: 16.15797 - diff: 11.73mlTrain batch 27/31 - 114.0ms/batch - loss: 16.35685 - diff: 11.82mlTrain batch 28/31 - 112.4ms/batch - loss: 16.22872 - diff: 11.76mlTrain batch 29/31 - 113.8ms/batch - loss: 17.01577 - diff: 12.11mlTrain batch 30/31 - 109.7ms/batch - loss: 17.62410 - diff: 12.31mlTrain batch 31/31 - 69.2ms/batch - loss: 19.88424 - diff: 12.61mlTrain batch 31/31 - 9.8s 69.2ms/batch - loss: 19.88424 - diff: 12.61ml
Test 1.0s: val_loss: 40.05881 - diff: 18.79ml

Epoch 117: current best loss = 36.31351, at epoch 79
Train batch 1/31 - 111.3ms/batch - loss: 7.90670 - diff: 9.52mlTrain batch 2/31 - 110.4ms/batch - loss: 21.66135 - diff: 15.82mlTrain batch 3/31 - 110.1ms/batch - loss: 19.50734 - diff: 14.39mlTrain batch 4/31 - 110.2ms/batch - loss: 22.37299 - diff: 15.90mlTrain batch 5/31 - 113.6ms/batch - loss: 19.69763 - diff: 14.48mlTrain batch 6/31 - 111.3ms/batch - loss: 18.38618 - diff: 13.86mlTrain batch 7/31 - 113.0ms/batch - loss: 17.03659 - diff: 13.30mlTrain batch 8/31 - 110.1ms/batch - loss: 16.84767 - diff: 13.23mlTrain batch 9/31 - 115.7ms/batch - loss: 16.24107 - diff: 13.09mlTrain batch 10/31 - 110.2ms/batch - loss: 16.66372 - diff: 13.22mlTrain batch 11/31 - 111.7ms/batch - loss: 18.95496 - diff: 13.79mlTrain batch 12/31 - 109.9ms/batch - loss: 18.26333 - diff: 13.54mlTrain batch 13/31 - 111.6ms/batch - loss: 17.82704 - diff: 13.29mlTrain batch 14/31 - 109.6ms/batch - loss: 18.75443 - diff: 13.74mlTrain batch 15/31 - 112.5ms/batch - loss: 17.81678 - diff: 13.26mlTrain batch 16/31 - 110.7ms/batch - loss: 17.19650 - diff: 12.99mlTrain batch 17/31 - 114.0ms/batch - loss: 16.96549 - diff: 12.94mlTrain batch 18/31 - 110.1ms/batch - loss: 17.05635 - diff: 13.00mlTrain batch 19/31 - 112.3ms/batch - loss: 16.82496 - diff: 12.97mlTrain batch 20/31 - 110.3ms/batch - loss: 17.10463 - diff: 13.15mlTrain batch 21/31 - 110.3ms/batch - loss: 19.64195 - diff: 13.91mlTrain batch 22/31 - 110.2ms/batch - loss: 21.23824 - diff: 14.53mlTrain batch 23/31 - 110.9ms/batch - loss: 21.20007 - diff: 14.53mlTrain batch 24/31 - 110.4ms/batch - loss: 20.98884 - diff: 14.49mlTrain batch 25/31 - 110.5ms/batch - loss: 20.51604 - diff: 14.27mlTrain batch 26/31 - 111.9ms/batch - loss: 20.25589 - diff: 14.20mlTrain batch 27/31 - 110.8ms/batch - loss: 20.02752 - diff: 14.14mlTrain batch 28/31 - 111.3ms/batch - loss: 19.78744 - diff: 14.05mlTrain batch 29/31 - 115.7ms/batch - loss: 19.78161 - diff: 14.07mlTrain batch 30/31 - 109.4ms/batch - loss: 19.65315 - diff: 14.04mlTrain batch 31/31 - 71.1ms/batch - loss: 19.69764 - diff: 14.00mlTrain batch 31/31 - 9.8s 71.1ms/batch - loss: 19.69764 - diff: 14.00ml
Test 1.0s: val_loss: 41.94108 - diff: 18.85ml

Epoch 118: current best loss = 36.31351, at epoch 79
Train batch 1/31 - 116.2ms/batch - loss: 60.09789 - diff: 28.93mlTrain batch 2/31 - 112.0ms/batch - loss: 32.80130 - diff: 18.13mlTrain batch 3/31 - 113.5ms/batch - loss: 37.14212 - diff: 20.44mlTrain batch 4/31 - 112.4ms/batch - loss: 31.00484 - diff: 18.08mlTrain batch 5/31 - 113.6ms/batch - loss: 30.19012 - diff: 17.76mlTrain batch 6/31 - 111.6ms/batch - loss: 30.69546 - diff: 17.71mlTrain batch 7/31 - 114.2ms/batch - loss: 27.45753 - diff: 16.52mlTrain batch 8/31 - 113.1ms/batch - loss: 30.54674 - diff: 16.57mlTrain batch 9/31 - 109.8ms/batch - loss: 28.58927 - diff: 16.05mlTrain batch 10/31 - 111.6ms/batch - loss: 26.04841 - diff: 15.00mlTrain batch 11/31 - 110.7ms/batch - loss: 24.89617 - diff: 14.71mlTrain batch 12/31 - 111.2ms/batch - loss: 23.40285 - diff: 14.18mlTrain batch 13/31 - 110.3ms/batch - loss: 23.46415 - diff: 14.16mlTrain batch 14/31 - 111.2ms/batch - loss: 24.20045 - diff: 14.67mlTrain batch 15/31 - 109.8ms/batch - loss: 23.22707 - diff: 14.32mlTrain batch 16/31 - 111.3ms/batch - loss: 22.28789 - diff: 13.96mlTrain batch 17/31 - 110.5ms/batch - loss: 22.78007 - diff: 14.26mlTrain batch 18/31 - 110.9ms/batch - loss: 22.20719 - diff: 14.12mlTrain batch 19/31 - 110.2ms/batch - loss: 22.15309 - diff: 14.21mlTrain batch 20/31 - 110.8ms/batch - loss: 21.50543 - diff: 14.02mlTrain batch 21/31 - 110.6ms/batch - loss: 21.25598 - diff: 13.96mlTrain batch 22/31 - 111.3ms/batch - loss: 22.44329 - diff: 14.32mlTrain batch 23/31 - 110.3ms/batch - loss: 21.81828 - diff: 14.07mlTrain batch 24/31 - 110.2ms/batch - loss: 22.05250 - diff: 14.28mlTrain batch 25/31 - 111.3ms/batch - loss: 21.71967 - diff: 14.17mlTrain batch 26/31 - 111.0ms/batch - loss: 21.19996 - diff: 13.99mlTrain batch 27/31 - 110.7ms/batch - loss: 20.67662 - diff: 13.83mlTrain batch 28/31 - 110.2ms/batch - loss: 20.49300 - diff: 13.78mlTrain batch 29/31 - 113.9ms/batch - loss: 20.22505 - diff: 13.70mlTrain batch 30/31 - 119.5ms/batch - loss: 19.79060 - diff: 13.52mlTrain batch 31/31 - 88.4ms/batch - loss: 22.58774 - diff: 13.86mlTrain batch 31/31 - 9.9s 88.4ms/batch - loss: 22.58774 - diff: 13.86ml
Test 0.9s: val_loss: 42.93973 - diff: 18.13ml

Epoch 119: current best loss = 36.31351, at epoch 79
Train batch 1/31 - 129.1ms/batch - loss: 6.01889 - diff: 8.02mlTrain batch 2/31 - 110.0ms/batch - loss: 7.52362 - diff: 8.25mlTrain batch 3/31 - 109.6ms/batch - loss: 8.24219 - diff: 9.08mlTrain batch 4/31 - 110.2ms/batch - loss: 8.25133 - diff: 9.19mlTrain batch 5/31 - 109.9ms/batch - loss: 14.61960 - diff: 12.02mlTrain batch 6/31 - 110.5ms/batch - loss: 13.30185 - diff: 11.41mlTrain batch 7/31 - 110.4ms/batch - loss: 13.00018 - diff: 11.34mlTrain batch 8/31 - 110.5ms/batch - loss: 12.62157 - diff: 11.12mlTrain batch 9/31 - 110.3ms/batch - loss: 12.86789 - diff: 11.34mlTrain batch 10/31 - 110.3ms/batch - loss: 13.58290 - diff: 11.76mlTrain batch 11/31 - 110.3ms/batch - loss: 13.21292 - diff: 11.55mlTrain batch 12/31 - 109.5ms/batch - loss: 13.56876 - diff: 11.53mlTrain batch 13/31 - 110.5ms/batch - loss: 13.47380 - diff: 11.57mlTrain batch 14/31 - 110.4ms/batch - loss: 12.87244 - diff: 11.32mlTrain batch 15/31 - 109.6ms/batch - loss: 14.37215 - diff: 11.92mlTrain batch 16/31 - 109.8ms/batch - loss: 14.32845 - diff: 11.91mlTrain batch 17/31 - 112.4ms/batch - loss: 15.07089 - diff: 12.11mlTrain batch 18/31 - 110.4ms/batch - loss: 15.50371 - diff: 12.39mlTrain batch 19/31 - 109.8ms/batch - loss: 16.58781 - diff: 12.81mlTrain batch 20/31 - 109.8ms/batch - loss: 17.07573 - diff: 13.03mlTrain batch 21/31 - 109.7ms/batch - loss: 17.42257 - diff: 13.18mlTrain batch 22/31 - 109.9ms/batch - loss: 17.38279 - diff: 13.14mlTrain batch 23/31 - 110.1ms/batch - loss: 18.27276 - diff: 13.44mlTrain batch 24/31 - 109.7ms/batch - loss: 19.38678 - diff: 13.84mlTrain batch 25/31 - 109.7ms/batch - loss: 19.79047 - diff: 14.06mlTrain batch 26/31 - 109.9ms/batch - loss: 20.70491 - diff: 14.45mlTrain batch 27/31 - 109.7ms/batch - loss: 20.42020 - diff: 14.35mlTrain batch 28/31 - 109.8ms/batch - loss: 19.94828 - diff: 14.14mlTrain batch 29/31 - 115.9ms/batch - loss: 19.63539 - diff: 14.00mlTrain batch 30/31 - 110.5ms/batch - loss: 19.10663 - diff: 13.73mlTrain batch 31/31 - 70.2ms/batch - loss: 19.67309 - diff: 13.79mlTrain batch 31/31 - 10.0s 70.2ms/batch - loss: 19.67309 - diff: 13.79ml
Test 0.8s: val_loss: 42.67971 - diff: 18.78ml

Epoch 120: current best loss = 36.31351, at epoch 79
Train batch 1/31 - 114.6ms/batch - loss: 19.99628 - diff: 13.61mlTrain batch 2/31 - 110.7ms/batch - loss: 13.98524 - diff: 11.20mlTrain batch 3/31 - 110.5ms/batch - loss: 21.79221 - diff: 14.87mlTrain batch 4/31 - 111.8ms/batch - loss: 19.39091 - diff: 13.64mlTrain batch 5/31 - 110.4ms/batch - loss: 18.37788 - diff: 13.51mlTrain batch 6/31 - 110.7ms/batch - loss: 15.63495 - diff: 11.99mlTrain batch 7/31 - 110.5ms/batch - loss: 15.31208 - diff: 12.00mlTrain batch 8/31 - 110.7ms/batch - loss: 20.37669 - diff: 13.78mlTrain batch 9/31 - 110.3ms/batch - loss: 20.41296 - diff: 14.06mlTrain batch 10/31 - 110.4ms/batch - loss: 20.25426 - diff: 14.23mlTrain batch 11/31 - 110.0ms/batch - loss: 20.14834 - diff: 14.31mlTrain batch 12/31 - 110.1ms/batch - loss: 20.19200 - diff: 14.38mlTrain batch 13/31 - 110.0ms/batch - loss: 20.00831 - diff: 14.39mlTrain batch 14/31 - 110.2ms/batch - loss: 19.70594 - diff: 14.29mlTrain batch 15/31 - 110.0ms/batch - loss: 19.93669 - diff: 14.42mlTrain batch 16/31 - 110.5ms/batch - loss: 19.36604 - diff: 14.19mlTrain batch 17/31 - 109.7ms/batch - loss: 18.86539 - diff: 14.01mlTrain batch 18/31 - 109.7ms/batch - loss: 18.45219 - diff: 13.92mlTrain batch 19/31 - 109.8ms/batch - loss: 18.19554 - diff: 13.85mlTrain batch 20/31 - 109.8ms/batch - loss: 18.67451 - diff: 14.09mlTrain batch 21/31 - 109.3ms/batch - loss: 18.37979 - diff: 13.99mlTrain batch 22/31 - 109.5ms/batch - loss: 17.99486 - diff: 13.84mlTrain batch 23/31 - 109.9ms/batch - loss: 18.46595 - diff: 13.99mlTrain batch 24/31 - 110.0ms/batch - loss: 19.05676 - diff: 14.05mlTrain batch 25/31 - 110.2ms/batch - loss: 19.81758 - diff: 14.37mlTrain batch 26/31 - 109.7ms/batch - loss: 19.61438 - diff: 14.28mlTrain batch 27/31 - 110.7ms/batch - loss: 19.21868 - diff: 14.13mlTrain batch 28/31 - 113.6ms/batch - loss: 18.88136 - diff: 14.01mlTrain batch 29/31 - 110.3ms/batch - loss: 18.58802 - diff: 13.87mlTrain batch 30/31 - 110.4ms/batch - loss: 19.23903 - diff: 14.13mlTrain batch 31/31 - 69.9ms/batch - loss: 19.28459 - diff: 14.07mlTrain batch 31/31 - 9.8s 69.9ms/batch - loss: 19.28459 - diff: 14.07ml
Test 0.9s: val_loss: 40.35279 - diff: 18.39ml

Epoch 121: current best loss = 36.31351, at epoch 79
Train batch 1/31 - 112.1ms/batch - loss: 16.36792 - diff: 12.80mlTrain batch 2/31 - 112.9ms/batch - loss: 16.02570 - diff: 12.41mlTrain batch 3/31 - 114.7ms/batch - loss: 25.83047 - diff: 16.78mlTrain batch 4/31 - 111.3ms/batch - loss: 21.99498 - diff: 15.10mlTrain batch 5/31 - 114.6ms/batch - loss: 24.42599 - diff: 16.31mlTrain batch 6/31 - 113.0ms/batch - loss: 23.93256 - diff: 15.75mlTrain batch 7/31 - 114.1ms/batch - loss: 24.25509 - diff: 15.87mlTrain batch 8/31 - 112.6ms/batch - loss: 22.43095 - diff: 14.96mlTrain batch 9/31 - 114.3ms/batch - loss: 22.58974 - diff: 15.34mlTrain batch 10/31 - 114.2ms/batch - loss: 21.00579 - diff: 14.63mlTrain batch 11/31 - 113.9ms/batch - loss: 19.98887 - diff: 14.24mlTrain batch 12/31 - 114.7ms/batch - loss: 18.90108 - diff: 13.72mlTrain batch 13/31 - 115.6ms/batch - loss: 20.97948 - diff: 14.44mlTrain batch 14/31 - 116.8ms/batch - loss: 21.04603 - diff: 14.56mlTrain batch 15/31 - 112.0ms/batch - loss: 21.19438 - diff: 14.78mlTrain batch 16/31 - 114.4ms/batch - loss: 20.64087 - diff: 14.57mlTrain batch 17/31 - 114.6ms/batch - loss: 20.59989 - diff: 14.47mlTrain batch 18/31 - 113.4ms/batch - loss: 19.97355 - diff: 14.18mlTrain batch 19/31 - 113.6ms/batch - loss: 21.31564 - diff: 14.66mlTrain batch 20/31 - 113.0ms/batch - loss: 20.65764 - diff: 14.38mlTrain batch 21/31 - 115.0ms/batch - loss: 20.23822 - diff: 14.24mlTrain batch 22/31 - 111.5ms/batch - loss: 20.35999 - diff: 14.36mlTrain batch 23/31 - 112.5ms/batch - loss: 19.76177 - diff: 14.11mlTrain batch 24/31 - 114.1ms/batch - loss: 21.69636 - diff: 14.47mlTrain batch 25/31 - 112.4ms/batch - loss: 22.68158 - diff: 14.92mlTrain batch 26/31 - 111.4ms/batch - loss: 22.01616 - diff: 14.61mlTrain batch 27/31 - 139.9ms/batch - loss: 21.74819 - diff: 14.54mlTrain batch 28/31 - 120.9ms/batch - loss: 21.21818 - diff: 14.33mlTrain batch 29/31 - 109.8ms/batch - loss: 22.33062 - diff: 14.74mlTrain batch 30/31 - 109.4ms/batch - loss: 22.46851 - diff: 14.83mlTrain batch 31/31 - 70.5ms/batch - loss: 22.67147 - diff: 14.76mlTrain batch 31/31 - 9.8s 70.5ms/batch - loss: 22.67147 - diff: 14.76ml
Test 0.9s: val_loss: 39.21981 - diff: 17.94ml

Epoch 122: current best loss = 36.31351, at epoch 79
Train batch 1/31 - 111.7ms/batch - loss: 22.92824 - diff: 16.31mlTrain batch 2/31 - 110.5ms/batch - loss: 30.36111 - diff: 19.20mlTrain batch 3/31 - 110.0ms/batch - loss: 30.18538 - diff: 19.47mlTrain batch 4/31 - 110.3ms/batch - loss: 25.14800 - diff: 17.07mlTrain batch 5/31 - 110.4ms/batch - loss: 21.73359 - diff: 15.56mlTrain batch 6/31 - 110.0ms/batch - loss: 19.78892 - diff: 14.78mlTrain batch 7/31 - 124.1ms/batch - loss: 18.84391 - diff: 14.40mlTrain batch 8/31 - 110.9ms/batch - loss: 17.54129 - diff: 13.86mlTrain batch 9/31 - 114.0ms/batch - loss: 16.34415 - diff: 13.18mlTrain batch 10/31 - 110.4ms/batch - loss: 15.34913 - diff: 12.64mlTrain batch 11/31 - 124.7ms/batch - loss: 14.79561 - diff: 12.30mlTrain batch 12/31 - 110.6ms/batch - loss: 14.65066 - diff: 12.21mlTrain batch 13/31 - 120.3ms/batch - loss: 17.79927 - diff: 13.24mlTrain batch 14/31 - 110.8ms/batch - loss: 17.44955 - diff: 13.11mlTrain batch 15/31 - 113.5ms/batch - loss: 17.62461 - diff: 13.20mlTrain batch 16/31 - 109.8ms/batch - loss: 16.90411 - diff: 12.93mlTrain batch 17/31 - 113.9ms/batch - loss: 16.87697 - diff: 12.89mlTrain batch 18/31 - 110.3ms/batch - loss: 16.20163 - diff: 12.58mlTrain batch 19/31 - 112.2ms/batch - loss: 16.34207 - diff: 12.48mlTrain batch 20/31 - 109.4ms/batch - loss: 16.50700 - diff: 12.66mlTrain batch 21/31 - 111.3ms/batch - loss: 16.18850 - diff: 12.51mlTrain batch 22/31 - 110.1ms/batch - loss: 16.00063 - diff: 12.49mlTrain batch 23/31 - 112.6ms/batch - loss: 15.61307 - diff: 12.33mlTrain batch 24/31 - 109.9ms/batch - loss: 15.84939 - diff: 12.53mlTrain batch 25/31 - 112.7ms/batch - loss: 17.37046 - diff: 13.08mlTrain batch 26/31 - 109.1ms/batch - loss: 17.75698 - diff: 13.20mlTrain batch 27/31 - 137.8ms/batch - loss: 17.42552 - diff: 13.06mlTrain batch 28/31 - 113.2ms/batch - loss: 17.12680 - diff: 12.96mlTrain batch 29/31 - 109.0ms/batch - loss: 17.51345 - diff: 13.15mlTrain batch 30/31 - 108.9ms/batch - loss: 17.56990 - diff: 13.20mlTrain batch 31/31 - 71.6ms/batch - loss: 18.80787 - diff: 13.36mlTrain batch 31/31 - 9.8s 71.6ms/batch - loss: 18.80787 - diff: 13.36ml
Test 0.8s: val_loss: 42.54001 - diff: 18.54ml

Epoch 123: current best loss = 36.31351, at epoch 79
Train batch 1/31 - 112.2ms/batch - loss: 14.58716 - diff: 11.58mlTrain batch 2/31 - 110.1ms/batch - loss: 12.61955 - diff: 11.42mlTrain batch 3/31 - 113.5ms/batch - loss: 17.59557 - diff: 13.40mlTrain batch 4/31 - 110.1ms/batch - loss: 19.07619 - diff: 14.23mlTrain batch 5/31 - 110.9ms/batch - loss: 16.10349 - diff: 12.68mlTrain batch 6/31 - 111.0ms/batch - loss: 16.43615 - diff: 12.97mlTrain batch 7/31 - 110.2ms/batch - loss: 16.93480 - diff: 13.13mlTrain batch 8/31 - 110.1ms/batch - loss: 15.94895 - diff: 12.78mlTrain batch 9/31 - 110.3ms/batch - loss: 16.07989 - diff: 13.09mlTrain batch 10/31 - 110.5ms/batch - loss: 16.77881 - diff: 13.52mlTrain batch 11/31 - 109.8ms/batch - loss: 16.62964 - diff: 13.29mlTrain batch 12/31 - 110.0ms/batch - loss: 15.68893 - diff: 12.88mlTrain batch 13/31 - 110.0ms/batch - loss: 15.71304 - diff: 12.75mlTrain batch 14/31 - 109.9ms/batch - loss: 16.18735 - diff: 12.99mlTrain batch 15/31 - 109.7ms/batch - loss: 17.51851 - diff: 13.56mlTrain batch 16/31 - 109.9ms/batch - loss: 19.36626 - diff: 14.16mlTrain batch 17/31 - 110.0ms/batch - loss: 19.79120 - diff: 14.37mlTrain batch 18/31 - 109.6ms/batch - loss: 19.51104 - diff: 14.14mlTrain batch 19/31 - 110.0ms/batch - loss: 19.36691 - diff: 14.07mlTrain batch 20/31 - 110.0ms/batch - loss: 18.68960 - diff: 13.71mlTrain batch 21/31 - 110.2ms/batch - loss: 19.27050 - diff: 13.98mlTrain batch 22/31 - 110.1ms/batch - loss: 18.68346 - diff: 13.72mlTrain batch 23/31 - 109.6ms/batch - loss: 20.51582 - diff: 14.42mlTrain batch 24/31 - 110.2ms/batch - loss: 19.97841 - diff: 14.19mlTrain batch 25/31 - 110.5ms/batch - loss: 21.08827 - diff: 14.58mlTrain batch 26/31 - 112.6ms/batch - loss: 21.96310 - diff: 14.98mlTrain batch 27/31 - 110.1ms/batch - loss: 21.70080 - diff: 14.84mlTrain batch 28/31 - 109.7ms/batch - loss: 21.09730 - diff: 14.58mlTrain batch 29/31 - 110.1ms/batch - loss: 21.29539 - diff: 14.67mlTrain batch 30/31 - 114.8ms/batch - loss: 21.41860 - diff: 14.78mlTrain batch 31/31 - 70.5ms/batch - loss: 22.15503 - diff: 14.86mlTrain batch 31/31 - 9.8s 70.5ms/batch - loss: 22.15503 - diff: 14.86ml
Test 0.8s: val_loss: 41.91558 - diff: 19.03ml
Epoch   124: reducing learning rate of group 0 to 3.1250e-05.

Epoch 124: current best loss = 36.31351, at epoch 79
Train batch 1/31 - 111.5ms/batch - loss: 15.79571 - diff: 14.43mlTrain batch 2/31 - 115.1ms/batch - loss: 12.25892 - diff: 12.09mlTrain batch 3/31 - 112.8ms/batch - loss: 12.67088 - diff: 12.20mlTrain batch 4/31 - 113.7ms/batch - loss: 29.14662 - diff: 16.94mlTrain batch 5/31 - 112.0ms/batch - loss: 27.31128 - diff: 16.09mlTrain batch 6/31 - 113.5ms/batch - loss: 24.48913 - diff: 15.16mlTrain batch 7/31 - 112.3ms/batch - loss: 25.63971 - diff: 15.88mlTrain batch 8/31 - 116.1ms/batch - loss: 24.40640 - diff: 15.47mlTrain batch 9/31 - 112.7ms/batch - loss: 23.61405 - diff: 15.35mlTrain batch 10/31 - 114.3ms/batch - loss: 22.87079 - diff: 15.00mlTrain batch 11/31 - 111.0ms/batch - loss: 22.86221 - diff: 14.94mlTrain batch 12/31 - 115.9ms/batch - loss: 21.62423 - diff: 14.51mlTrain batch 13/31 - 111.2ms/batch - loss: 21.51133 - diff: 14.51mlTrain batch 14/31 - 119.4ms/batch - loss: 21.42652 - diff: 14.51mlTrain batch 15/31 - 110.3ms/batch - loss: 20.73471 - diff: 14.29mlTrain batch 16/31 - 116.5ms/batch - loss: 19.96060 - diff: 13.98mlTrain batch 17/31 - 110.3ms/batch - loss: 19.31315 - diff: 13.73mlTrain batch 18/31 - 112.3ms/batch - loss: 19.19577 - diff: 13.73mlTrain batch 19/31 - 111.5ms/batch - loss: 23.15195 - diff: 14.94mlTrain batch 20/31 - 113.9ms/batch - loss: 22.45167 - diff: 14.68mlTrain batch 21/31 - 110.6ms/batch - loss: 21.76364 - diff: 14.46mlTrain batch 22/31 - 111.9ms/batch - loss: 22.94088 - diff: 14.95mlTrain batch 23/31 - 110.5ms/batch - loss: 22.36236 - diff: 14.73mlTrain batch 24/31 - 110.0ms/batch - loss: 22.53213 - diff: 14.89mlTrain batch 25/31 - 113.5ms/batch - loss: 23.19794 - diff: 15.19mlTrain batch 26/31 - 119.7ms/batch - loss: 23.77742 - diff: 15.39mlTrain batch 27/31 - 110.2ms/batch - loss: 23.05510 - diff: 15.07mlTrain batch 28/31 - 109.8ms/batch - loss: 22.48841 - diff: 14.85mlTrain batch 29/31 - 112.5ms/batch - loss: 22.25061 - diff: 14.82mlTrain batch 30/31 - 110.0ms/batch - loss: 21.71064 - diff: 14.59mlTrain batch 31/31 - 69.1ms/batch - loss: 22.14502 - diff: 14.62mlTrain batch 31/31 - 9.8s 69.1ms/batch - loss: 22.14502 - diff: 14.62ml
Test 0.8s: val_loss: 40.74703 - diff: 18.77ml

Epoch 125: current best loss = 36.31351, at epoch 79
Train batch 1/31 - 128.7ms/batch - loss: 19.62271 - diff: 15.18mlTrain batch 2/31 - 111.4ms/batch - loss: 19.65847 - diff: 15.31mlTrain batch 3/31 - 132.4ms/batch - loss: 19.02890 - diff: 14.86mlTrain batch 4/31 - 110.6ms/batch - loss: 17.01565 - diff: 14.01mlTrain batch 5/31 - 118.0ms/batch - loss: 31.15747 - diff: 18.47mlTrain batch 6/31 - 110.8ms/batch - loss: 29.45875 - diff: 17.79mlTrain batch 7/31 - 112.7ms/batch - loss: 28.04537 - diff: 17.53mlTrain batch 8/31 - 110.1ms/batch - loss: 24.90130 - diff: 16.00mlTrain batch 9/31 - 113.5ms/batch - loss: 24.49979 - diff: 15.98mlTrain batch 10/31 - 110.5ms/batch - loss: 23.02569 - diff: 15.38mlTrain batch 11/31 - 111.1ms/batch - loss: 23.31917 - diff: 15.59mlTrain batch 12/31 - 111.5ms/batch - loss: 22.89748 - diff: 15.47mlTrain batch 13/31 - 110.3ms/batch - loss: 22.49460 - diff: 15.43mlTrain batch 14/31 - 110.3ms/batch - loss: 21.97043 - diff: 15.23mlTrain batch 15/31 - 110.8ms/batch - loss: 20.86816 - diff: 14.75mlTrain batch 16/31 - 110.9ms/batch - loss: 20.33122 - diff: 14.58mlTrain batch 17/31 - 110.3ms/batch - loss: 19.58294 - diff: 14.28mlTrain batch 18/31 - 111.8ms/batch - loss: 18.89710 - diff: 13.98mlTrain batch 19/31 - 111.9ms/batch - loss: 18.87318 - diff: 13.89mlTrain batch 20/31 - 110.6ms/batch - loss: 18.71772 - diff: 13.80mlTrain batch 21/31 - 110.6ms/batch - loss: 18.46916 - diff: 13.67mlTrain batch 22/31 - 110.0ms/batch - loss: 18.00397 - diff: 13.48mlTrain batch 23/31 - 110.4ms/batch - loss: 17.58844 - diff: 13.31mlTrain batch 24/31 - 110.0ms/batch - loss: 17.85693 - diff: 13.40mlTrain batch 25/31 - 119.3ms/batch - loss: 17.63690 - diff: 13.34mlTrain batch 26/31 - 117.0ms/batch - loss: 17.59308 - diff: 13.34mlTrain batch 27/31 - 109.9ms/batch - loss: 18.03092 - diff: 13.55mlTrain batch 28/31 - 109.7ms/batch - loss: 17.68496 - diff: 13.42mlTrain batch 29/31 - 109.6ms/batch - loss: 17.55744 - diff: 13.27mlTrain batch 30/31 - 109.5ms/batch - loss: 17.49957 - diff: 13.24mlTrain batch 31/31 - 69.2ms/batch - loss: 18.36845 - diff: 13.36mlTrain batch 31/31 - 9.9s 69.2ms/batch - loss: 18.36845 - diff: 13.36ml
Test 0.9s: val_loss: 40.05531 - diff: 18.04ml

Epoch 126: current best loss = 36.31351, at epoch 79
Train batch 1/31 - 114.1ms/batch - loss: 25.35213 - diff: 17.55mlTrain batch 2/31 - 109.6ms/batch - loss: 17.88061 - diff: 14.22mlTrain batch 3/31 - 113.7ms/batch - loss: 19.18775 - diff: 14.98mlTrain batch 4/31 - 110.0ms/batch - loss: 16.86046 - diff: 13.78mlTrain batch 5/31 - 113.7ms/batch - loss: 16.78826 - diff: 13.67mlTrain batch 6/31 - 110.2ms/batch - loss: 19.07535 - diff: 14.65mlTrain batch 7/31 - 110.1ms/batch - loss: 18.51944 - diff: 14.43mlTrain batch 8/31 - 110.4ms/batch - loss: 17.40849 - diff: 13.95mlTrain batch 9/31 - 113.7ms/batch - loss: 16.81013 - diff: 13.72mlTrain batch 10/31 - 110.1ms/batch - loss: 18.65683 - diff: 14.44mlTrain batch 11/31 - 113.9ms/batch - loss: 17.70311 - diff: 14.01mlTrain batch 12/31 - 110.7ms/batch - loss: 19.01612 - diff: 14.58mlTrain batch 13/31 - 113.6ms/batch - loss: 18.23941 - diff: 14.26mlTrain batch 14/31 - 110.0ms/batch - loss: 18.24479 - diff: 14.22mlTrain batch 15/31 - 113.5ms/batch - loss: 17.86381 - diff: 14.00mlTrain batch 16/31 - 110.2ms/batch - loss: 17.41449 - diff: 13.84mlTrain batch 17/31 - 109.9ms/batch - loss: 17.53811 - diff: 13.96mlTrain batch 18/31 - 109.9ms/batch - loss: 17.36197 - diff: 13.71mlTrain batch 19/31 - 114.1ms/batch - loss: 17.19900 - diff: 13.64mlTrain batch 20/31 - 110.1ms/batch - loss: 17.34408 - diff: 13.61mlTrain batch 21/31 - 111.6ms/batch - loss: 17.86207 - diff: 13.79mlTrain batch 22/31 - 111.0ms/batch - loss: 17.76176 - diff: 13.76mlTrain batch 23/31 - 113.4ms/batch - loss: 17.69900 - diff: 13.73mlTrain batch 24/31 - 111.3ms/batch - loss: 17.79366 - diff: 13.77mlTrain batch 25/31 - 112.9ms/batch - loss: 17.97235 - diff: 13.88mlTrain batch 26/31 - 109.8ms/batch - loss: 18.37314 - diff: 14.05mlTrain batch 27/31 - 111.8ms/batch - loss: 18.04814 - diff: 13.92mlTrain batch 28/31 - 111.0ms/batch - loss: 17.58552 - diff: 13.70mlTrain batch 29/31 - 112.4ms/batch - loss: 17.43847 - diff: 13.62mlTrain batch 30/31 - 110.8ms/batch - loss: 17.23241 - diff: 13.50mlTrain batch 31/31 - 70.8ms/batch - loss: 17.74847 - diff: 13.53mlTrain batch 31/31 - 9.9s 70.8ms/batch - loss: 17.74847 - diff: 13.53ml
Test 0.9s: val_loss: 42.76972 - diff: 19.03ml

Epoch 127: current best loss = 36.31351, at epoch 79
Train batch 1/31 - 110.9ms/batch - loss: 15.08023 - diff: 12.35mlTrain batch 2/31 - 116.9ms/batch - loss: 9.36863 - diff: 9.21mlTrain batch 3/31 - 110.5ms/batch - loss: 11.51174 - diff: 11.00mlTrain batch 4/31 - 115.4ms/batch - loss: 21.92008 - diff: 14.56mlTrain batch 5/31 - 110.1ms/batch - loss: 22.86786 - diff: 14.68mlTrain batch 6/31 - 119.3ms/batch - loss: 22.22749 - diff: 14.49mlTrain batch 7/31 - 110.5ms/batch - loss: 20.65619 - diff: 13.88mlTrain batch 8/31 - 118.8ms/batch - loss: 19.59148 - diff: 13.55mlTrain batch 9/31 - 110.4ms/batch - loss: 17.95899 - diff: 12.81mlTrain batch 10/31 - 117.1ms/batch - loss: 17.85425 - diff: 12.79mlTrain batch 11/31 - 109.8ms/batch - loss: 17.38216 - diff: 12.60mlTrain batch 12/31 - 111.3ms/batch - loss: 16.92795 - diff: 12.39mlTrain batch 13/31 - 110.2ms/batch - loss: 16.53892 - diff: 12.27mlTrain batch 14/31 - 112.3ms/batch - loss: 15.77428 - diff: 11.96mlTrain batch 15/31 - 111.1ms/batch - loss: 15.03104 - diff: 11.69mlTrain batch 16/31 - 116.0ms/batch - loss: 15.38306 - diff: 11.80mlTrain batch 17/31 - 111.0ms/batch - loss: 15.12479 - diff: 11.70mlTrain batch 18/31 - 117.8ms/batch - loss: 18.94582 - diff: 12.91mlTrain batch 19/31 - 110.4ms/batch - loss: 18.80616 - diff: 12.87mlTrain batch 20/31 - 112.1ms/batch - loss: 19.17053 - diff: 12.79mlTrain batch 21/31 - 110.0ms/batch - loss: 19.42836 - diff: 13.04mlTrain batch 22/31 - 111.1ms/batch - loss: 18.79636 - diff: 12.79mlTrain batch 23/31 - 112.9ms/batch - loss: 18.84193 - diff: 12.92mlTrain batch 24/31 - 120.6ms/batch - loss: 18.71528 - diff: 12.95mlTrain batch 25/31 - 110.0ms/batch - loss: 18.16389 - diff: 12.71mlTrain batch 26/31 - 109.7ms/batch - loss: 19.04702 - diff: 13.08mlTrain batch 27/31 - 113.5ms/batch - loss: 18.83644 - diff: 13.05mlTrain batch 28/31 - 110.1ms/batch - loss: 18.67535 - diff: 12.99mlTrain batch 29/31 - 115.0ms/batch - loss: 18.32616 - diff: 12.85mlTrain batch 30/31 - 109.8ms/batch - loss: 17.89321 - diff: 12.67mlTrain batch 31/31 - 68.9ms/batch - loss: 18.35654 - diff: 12.67mlTrain batch 31/31 - 9.8s 68.9ms/batch - loss: 18.35654 - diff: 12.67ml
Test 0.8s: val_loss: 39.71242 - diff: 18.25ml

Epoch 128: current best loss = 36.31351, at epoch 79
Train batch 1/31 - 115.4ms/batch - loss: 9.38680 - diff: 10.97mlTrain batch 2/31 - 113.1ms/batch - loss: 13.88167 - diff: 12.08mlTrain batch 3/31 - 111.7ms/batch - loss: 15.97802 - diff: 12.99mlTrain batch 4/31 - 113.2ms/batch - loss: 18.40893 - diff: 13.99mlTrain batch 5/31 - 115.1ms/batch - loss: 16.90236 - diff: 13.44mlTrain batch 6/31 - 110.8ms/batch - loss: 17.85936 - diff: 13.89mlTrain batch 7/31 - 113.3ms/batch - loss: 17.89934 - diff: 13.55mlTrain batch 8/31 - 110.1ms/batch - loss: 17.35016 - diff: 13.29mlTrain batch 9/31 - 112.8ms/batch - loss: 16.95085 - diff: 13.10mlTrain batch 10/31 - 110.8ms/batch - loss: 16.48388 - diff: 12.86mlTrain batch 11/31 - 110.9ms/batch - loss: 16.62609 - diff: 12.98mlTrain batch 12/31 - 111.1ms/batch - loss: 16.11109 - diff: 12.80mlTrain batch 13/31 - 110.6ms/batch - loss: 16.69056 - diff: 13.13mlTrain batch 14/31 - 110.8ms/batch - loss: 16.97721 - diff: 13.30mlTrain batch 15/31 - 110.3ms/batch - loss: 16.94205 - diff: 13.12mlTrain batch 16/31 - 110.3ms/batch - loss: 16.11256 - diff: 12.68mlTrain batch 17/31 - 110.5ms/batch - loss: 16.44424 - diff: 12.91mlTrain batch 18/31 - 110.3ms/batch - loss: 15.92698 - diff: 12.65mlTrain batch 19/31 - 110.6ms/batch - loss: 15.52235 - diff: 12.47mlTrain batch 20/31 - 110.0ms/batch - loss: 15.51163 - diff: 12.46mlTrain batch 21/31 - 109.7ms/batch - loss: 15.50080 - diff: 12.46mlTrain batch 22/31 - 109.4ms/batch - loss: 15.15234 - diff: 12.33mlTrain batch 23/31 - 122.3ms/batch - loss: 15.13037 - diff: 12.35mlTrain batch 24/31 - 115.0ms/batch - loss: 15.11641 - diff: 12.33mlTrain batch 25/31 - 109.9ms/batch - loss: 15.42797 - diff: 12.50mlTrain batch 26/31 - 110.1ms/batch - loss: 15.24061 - diff: 12.40mlTrain batch 27/31 - 109.8ms/batch - loss: 15.63979 - diff: 12.61mlTrain batch 28/31 - 109.6ms/batch - loss: 15.76344 - diff: 12.70mlTrain batch 29/31 - 109.0ms/batch - loss: 15.37174 - diff: 12.48mlTrain batch 30/31 - 108.9ms/batch - loss: 15.56679 - diff: 12.60mlTrain batch 31/31 - 70.0ms/batch - loss: 16.04904 - diff: 12.67mlTrain batch 31/31 - 10.0s 70.0ms/batch - loss: 16.04904 - diff: 12.67ml
Test 0.8s: val_loss: 38.05474 - diff: 17.88ml

Epoch 129: current best loss = 36.31351, at epoch 79
Train batch 1/31 - 111.2ms/batch - loss: 13.47003 - diff: 12.14mlTrain batch 2/31 - 110.9ms/batch - loss: 12.41948 - diff: 11.57mlTrain batch 3/31 - 110.4ms/batch - loss: 15.48620 - diff: 12.17mlTrain batch 4/31 - 110.3ms/batch - loss: 15.92037 - diff: 12.80mlTrain batch 5/31 - 110.4ms/batch - loss: 17.93625 - diff: 13.76mlTrain batch 6/31 - 110.2ms/batch - loss: 17.37391 - diff: 13.39mlTrain batch 7/31 - 110.1ms/batch - loss: 16.41509 - diff: 13.06mlTrain batch 8/31 - 109.9ms/batch - loss: 15.63830 - diff: 12.71mlTrain batch 9/31 - 110.3ms/batch - loss: 14.91105 - diff: 12.39mlTrain batch 10/31 - 109.9ms/batch - loss: 14.74797 - diff: 12.31mlTrain batch 11/31 - 109.7ms/batch - loss: 14.25952 - diff: 12.05mlTrain batch 12/31 - 109.8ms/batch - loss: 13.68507 - diff: 11.72mlTrain batch 13/31 - 110.1ms/batch - loss: 17.08204 - diff: 13.01mlTrain batch 14/31 - 109.8ms/batch - loss: 16.91100 - diff: 12.95mlTrain batch 15/31 - 109.7ms/batch - loss: 16.74242 - diff: 12.87mlTrain batch 16/31 - 109.6ms/batch - loss: 16.56770 - diff: 12.87mlTrain batch 17/31 - 109.7ms/batch - loss: 16.26625 - diff: 12.81mlTrain batch 18/31 - 109.7ms/batch - loss: 16.94318 - diff: 13.13mlTrain batch 19/31 - 110.8ms/batch - loss: 19.05702 - diff: 13.88mlTrain batch 20/31 - 110.3ms/batch - loss: 18.71841 - diff: 13.76mlTrain batch 21/31 - 110.6ms/batch - loss: 18.23533 - diff: 13.59mlTrain batch 22/31 - 113.6ms/batch - loss: 18.58132 - diff: 13.77mlTrain batch 23/31 - 110.3ms/batch - loss: 20.92615 - diff: 14.16mlTrain batch 24/31 - 110.5ms/batch - loss: 20.44276 - diff: 13.95mlTrain batch 25/31 - 109.3ms/batch - loss: 19.93404 - diff: 13.73mlTrain batch 26/31 - 111.2ms/batch - loss: 19.43504 - diff: 13.56mlTrain batch 27/31 - 110.0ms/batch - loss: 19.35127 - diff: 13.54mlTrain batch 28/31 - 110.0ms/batch - loss: 19.43910 - diff: 13.54mlTrain batch 29/31 - 109.3ms/batch - loss: 19.19635 - diff: 13.48mlTrain batch 30/31 - 109.7ms/batch - loss: 19.08534 - diff: 13.43mlTrain batch 31/31 - 70.0ms/batch - loss: 19.00327 - diff: 13.36mlTrain batch 31/31 - 9.8s 70.0ms/batch - loss: 19.00327 - diff: 13.36ml
Test 0.8s: val_loss: 38.12212 - diff: 18.03ml

Epoch 130: current best loss = 36.31351, at epoch 79
Train batch 1/31 - 115.4ms/batch - loss: 21.09839 - diff: 13.08mlTrain batch 2/31 - 110.9ms/batch - loss: 11.97353 - diff: 9.31mlTrain batch 3/31 - 112.9ms/batch - loss: 15.18324 - diff: 10.38mlTrain batch 4/31 - 113.3ms/batch - loss: 13.94859 - diff: 10.43mlTrain batch 5/31 - 114.1ms/batch - loss: 12.93765 - diff: 10.18mlTrain batch 6/31 - 115.0ms/batch - loss: 16.86224 - diff: 11.64mlTrain batch 7/31 - 110.4ms/batch - loss: 17.56905 - diff: 12.27mlTrain batch 8/31 - 116.3ms/batch - loss: 16.29885 - diff: 11.77mlTrain batch 9/31 - 109.9ms/batch - loss: 16.24771 - diff: 12.01mlTrain batch 10/31 - 114.4ms/batch - loss: 16.22720 - diff: 12.06mlTrain batch 11/31 - 109.6ms/batch - loss: 15.45319 - diff: 11.80mlTrain batch 12/31 - 113.2ms/batch - loss: 17.68472 - diff: 12.65mlTrain batch 13/31 - 109.5ms/batch - loss: 18.02929 - diff: 12.78mlTrain batch 14/31 - 114.8ms/batch - loss: 18.39128 - diff: 13.07mlTrain batch 15/31 - 109.5ms/batch - loss: 17.72861 - diff: 12.83mlTrain batch 16/31 - 112.2ms/batch - loss: 17.62235 - diff: 12.91mlTrain batch 17/31 - 109.4ms/batch - loss: 17.67176 - diff: 13.07mlTrain batch 18/31 - 115.1ms/batch - loss: 17.24055 - diff: 12.84mlTrain batch 19/31 - 110.0ms/batch - loss: 17.37003 - diff: 12.97mlTrain batch 20/31 - 111.8ms/batch - loss: 18.08196 - diff: 13.17mlTrain batch 21/31 - 116.4ms/batch - loss: 17.49865 - diff: 12.89mlTrain batch 22/31 - 118.4ms/batch - loss: 17.75039 - diff: 12.93mlTrain batch 23/31 - 110.0ms/batch - loss: 19.06414 - diff: 13.43mlTrain batch 24/31 - 109.8ms/batch - loss: 19.14092 - diff: 13.49mlTrain batch 25/31 - 114.2ms/batch - loss: 18.71997 - diff: 13.35mlTrain batch 26/31 - 113.0ms/batch - loss: 18.38100 - diff: 13.19mlTrain batch 27/31 - 116.0ms/batch - loss: 21.82556 - diff: 14.16mlTrain batch 28/31 - 111.5ms/batch - loss: 21.52581 - diff: 14.06mlTrain batch 29/31 - 113.3ms/batch - loss: 21.12899 - diff: 13.93mlTrain batch 30/31 - 109.6ms/batch - loss: 20.67942 - diff: 13.75mlTrain batch 31/31 - 70.0ms/batch - loss: 20.74134 - diff: 13.73mlTrain batch 31/31 - 9.9s 70.0ms/batch - loss: 20.74134 - diff: 13.73ml
Test 0.8s: val_loss: 38.56500 - diff: 17.65ml

Epoch 131: current best loss = 36.31351, at epoch 79
Train batch 1/31 - 115.4ms/batch - loss: 4.79705 - diff: 7.41mlTrain batch 2/31 - 110.1ms/batch - loss: 7.18326 - diff: 8.41mlTrain batch 3/31 - 110.0ms/batch - loss: 12.27382 - diff: 10.89mlTrain batch 4/31 - 109.8ms/batch - loss: 11.81618 - diff: 10.63mlTrain batch 5/31 - 110.9ms/batch - loss: 12.97796 - diff: 11.12mlTrain batch 6/31 - 110.5ms/batch - loss: 12.28130 - diff: 10.76mlTrain batch 7/31 - 109.8ms/batch - loss: 12.07792 - diff: 10.77mlTrain batch 8/31 - 109.6ms/batch - loss: 12.64000 - diff: 11.19mlTrain batch 9/31 - 109.5ms/batch - loss: 11.96427 - diff: 10.94mlTrain batch 10/31 - 109.8ms/batch - loss: 13.89973 - diff: 11.92mlTrain batch 11/31 - 110.0ms/batch - loss: 13.45299 - diff: 11.66mlTrain batch 12/31 - 109.4ms/batch - loss: 16.55866 - diff: 12.41mlTrain batch 13/31 - 113.1ms/batch - loss: 20.80852 - diff: 13.82mlTrain batch 14/31 - 111.0ms/batch - loss: 22.31923 - diff: 14.58mlTrain batch 15/31 - 110.5ms/batch - loss: 21.77891 - diff: 14.43mlTrain batch 16/31 - 110.8ms/batch - loss: 20.86477 - diff: 14.02mlTrain batch 17/31 - 110.2ms/batch - loss: 20.08866 - diff: 13.70mlTrain batch 18/31 - 110.7ms/batch - loss: 20.18081 - diff: 13.83mlTrain batch 19/31 - 110.5ms/batch - loss: 19.66594 - diff: 13.66mlTrain batch 20/31 - 110.7ms/batch - loss: 19.05982 - diff: 13.36mlTrain batch 21/31 - 120.3ms/batch - loss: 19.56413 - diff: 13.60mlTrain batch 22/31 - 114.5ms/batch - loss: 19.00603 - diff: 13.35mlTrain batch 23/31 - 110.0ms/batch - loss: 18.67062 - diff: 13.26mlTrain batch 24/31 - 109.7ms/batch - loss: 20.35152 - diff: 13.84mlTrain batch 25/31 - 109.8ms/batch - loss: 20.36502 - diff: 13.83mlTrain batch 26/31 - 109.7ms/batch - loss: 19.88667 - diff: 13.65mlTrain batch 27/31 - 110.0ms/batch - loss: 20.11065 - diff: 13.84mlTrain batch 28/31 - 109.8ms/batch - loss: 20.79836 - diff: 14.18mlTrain batch 29/31 - 109.5ms/batch - loss: 20.58167 - diff: 14.09mlTrain batch 30/31 - 109.5ms/batch - loss: 20.28881 - diff: 14.02mlTrain batch 31/31 - 69.4ms/batch - loss: 24.41003 - diff: 14.47mlTrain batch 31/31 - 9.9s 69.4ms/batch - loss: 24.41003 - diff: 14.47ml
Test 0.8s: val_loss: 39.18971 - diff: 17.84ml

Epoch 132: current best loss = 36.31351, at epoch 79
Train batch 1/31 - 114.2ms/batch - loss: 6.83146 - diff: 8.66mlTrain batch 2/31 - 110.1ms/batch - loss: 13.20331 - diff: 11.28mlTrain batch 3/31 - 112.7ms/batch - loss: 11.46708 - diff: 10.61mlTrain batch 4/31 - 109.6ms/batch - loss: 21.64004 - diff: 13.98mlTrain batch 5/31 - 110.9ms/batch - loss: 19.77000 - diff: 13.39mlTrain batch 6/31 - 110.9ms/batch - loss: 19.01424 - diff: 13.24mlTrain batch 7/31 - 111.1ms/batch - loss: 17.66444 - diff: 12.80mlTrain batch 8/31 - 110.8ms/batch - loss: 16.86755 - diff: 12.54mlTrain batch 9/31 - 110.5ms/batch - loss: 15.65592 - diff: 12.01mlTrain batch 10/31 - 110.4ms/batch - loss: 15.10717 - diff: 11.81mlTrain batch 11/31 - 113.6ms/batch - loss: 15.39166 - diff: 12.04mlTrain batch 12/31 - 110.1ms/batch - loss: 15.42036 - diff: 12.12mlTrain batch 13/31 - 113.6ms/batch - loss: 14.56077 - diff: 11.68mlTrain batch 14/31 - 110.3ms/batch - loss: 14.39335 - diff: 11.59mlTrain batch 15/31 - 111.1ms/batch - loss: 14.26811 - diff: 11.61mlTrain batch 16/31 - 109.7ms/batch - loss: 14.04142 - diff: 11.53mlTrain batch 17/31 - 113.6ms/batch - loss: 13.74780 - diff: 11.40mlTrain batch 18/31 - 110.2ms/batch - loss: 13.52953 - diff: 11.34mlTrain batch 19/31 - 114.9ms/batch - loss: 13.17384 - diff: 11.17mlTrain batch 20/31 - 111.0ms/batch - loss: 13.17567 - diff: 11.20mlTrain batch 21/31 - 112.3ms/batch - loss: 13.00391 - diff: 11.11mlTrain batch 22/31 - 111.2ms/batch - loss: 13.05140 - diff: 11.12mlTrain batch 23/31 - 114.2ms/batch - loss: 13.37991 - diff: 11.34mlTrain batch 24/31 - 111.3ms/batch - loss: 13.72095 - diff: 11.35mlTrain batch 25/31 - 113.5ms/batch - loss: 13.99847 - diff: 11.56mlTrain batch 26/31 - 110.7ms/batch - loss: 14.67783 - diff: 11.94mlTrain batch 27/31 - 112.3ms/batch - loss: 15.14472 - diff: 12.19mlTrain batch 28/31 - 110.7ms/batch - loss: 15.30876 - diff: 12.35mlTrain batch 29/31 - 111.3ms/batch - loss: 14.99009 - diff: 12.21mlTrain batch 30/31 - 110.0ms/batch - loss: 14.70479 - diff: 12.08mlTrain batch 31/31 - 75.0ms/batch - loss: 18.33310 - diff: 12.47mlTrain batch 31/31 - 9.8s 75.0ms/batch - loss: 18.33310 - diff: 12.47ml
Test 0.8s: val_loss: 37.47659 - diff: 17.70ml

Epoch 133: current best loss = 36.31351, at epoch 79
Train batch 1/31 - 111.8ms/batch - loss: 6.42463 - diff: 7.83mlTrain batch 2/31 - 112.7ms/batch - loss: 10.78827 - diff: 9.85mlTrain batch 3/31 - 113.8ms/batch - loss: 17.68861 - diff: 13.40mlTrain batch 4/31 - 111.8ms/batch - loss: 15.74226 - diff: 12.74mlTrain batch 5/31 - 113.7ms/batch - loss: 15.16232 - diff: 12.41mlTrain batch 6/31 - 111.3ms/batch - loss: 14.67594 - diff: 12.31mlTrain batch 7/31 - 113.7ms/batch - loss: 13.71615 - diff: 11.87mlTrain batch 8/31 - 112.2ms/batch - loss: 13.12128 - diff: 11.57mlTrain batch 9/31 - 110.9ms/batch - loss: 12.44170 - diff: 11.25mlTrain batch 10/31 - 112.3ms/batch - loss: 13.16091 - diff: 11.47mlTrain batch 11/31 - 111.2ms/batch - loss: 15.22814 - diff: 12.28mlTrain batch 12/31 - 111.7ms/batch - loss: 15.56924 - diff: 12.43mlTrain batch 13/31 - 112.8ms/batch - loss: 16.51932 - diff: 12.90mlTrain batch 14/31 - 112.3ms/batch - loss: 17.02802 - diff: 13.09mlTrain batch 15/31 - 112.7ms/batch - loss: 16.84765 - diff: 12.96mlTrain batch 16/31 - 112.3ms/batch - loss: 16.24141 - diff: 12.70mlTrain batch 17/31 - 113.6ms/batch - loss: 17.10931 - diff: 12.96mlTrain batch 18/31 - 111.8ms/batch - loss: 18.49747 - diff: 13.40mlTrain batch 19/31 - 115.2ms/batch - loss: 18.38584 - diff: 13.41mlTrain batch 20/31 - 113.6ms/batch - loss: 18.29916 - diff: 13.37mlTrain batch 21/31 - 114.3ms/batch - loss: 18.31664 - diff: 13.41mlTrain batch 22/31 - 110.2ms/batch - loss: 18.06318 - diff: 13.33mlTrain batch 23/31 - 111.5ms/batch - loss: 17.62921 - diff: 13.13mlTrain batch 24/31 - 111.8ms/batch - loss: 17.33343 - diff: 12.97mlTrain batch 25/31 - 123.5ms/batch - loss: 18.16669 - diff: 13.11mlTrain batch 26/31 - 113.5ms/batch - loss: 17.79235 - diff: 12.99mlTrain batch 27/31 - 110.6ms/batch - loss: 17.43611 - diff: 12.87mlTrain batch 28/31 - 111.4ms/batch - loss: 17.03291 - diff: 12.71mlTrain batch 29/31 - 109.8ms/batch - loss: 16.68692 - diff: 12.59mlTrain batch 30/31 - 109.8ms/batch - loss: 16.45540 - diff: 12.52mlTrain batch 31/31 - 69.2ms/batch - loss: 17.19280 - diff: 12.64mlTrain batch 31/31 - 9.9s 69.2ms/batch - loss: 17.19280 - diff: 12.64ml
Test 0.8s: val_loss: 44.19282 - diff: 17.95ml

Epoch 134: current best loss = 36.31351, at epoch 79
Train batch 1/31 - 115.8ms/batch - loss: 9.62082 - diff: 9.32mlTrain batch 2/31 - 110.9ms/batch - loss: 39.50620 - diff: 19.56mlTrain batch 3/31 - 115.9ms/batch - loss: 29.50333 - diff: 16.27mlTrain batch 4/31 - 111.2ms/batch - loss: 30.32023 - diff: 17.43mlTrain batch 5/31 - 113.3ms/batch - loss: 26.50821 - diff: 15.88mlTrain batch 6/31 - 110.1ms/batch - loss: 23.08615 - diff: 14.53mlTrain batch 7/31 - 111.5ms/batch - loss: 23.88481 - diff: 15.23mlTrain batch 8/31 - 113.0ms/batch - loss: 21.61449 - diff: 14.35mlTrain batch 9/31 - 110.6ms/batch - loss: 20.15197 - diff: 13.72mlTrain batch 10/31 - 113.7ms/batch - loss: 21.72456 - diff: 14.41mlTrain batch 11/31 - 111.7ms/batch - loss: 20.85130 - diff: 14.16mlTrain batch 12/31 - 112.4ms/batch - loss: 19.97218 - diff: 13.90mlTrain batch 13/31 - 111.9ms/batch - loss: 19.64374 - diff: 13.89mlTrain batch 14/31 - 114.1ms/batch - loss: 18.65180 - diff: 13.40mlTrain batch 15/31 - 113.3ms/batch - loss: 17.88477 - diff: 13.05mlTrain batch 16/31 - 113.3ms/batch - loss: 17.58786 - diff: 12.98mlTrain batch 17/31 - 114.0ms/batch - loss: 17.41100 - diff: 12.85mlTrain batch 18/31 - 113.2ms/batch - loss: 18.25086 - diff: 13.35mlTrain batch 19/31 - 147.4ms/batch - loss: 17.85329 - diff: 13.21mlTrain batch 20/31 - 120.4ms/batch - loss: 17.47676 - diff: 13.02mlTrain batch 21/31 - 110.0ms/batch - loss: 17.38938 - diff: 12.96mlTrain batch 22/31 - 109.9ms/batch - loss: 17.43883 - diff: 12.99mlTrain batch 23/31 - 111.7ms/batch - loss: 16.97411 - diff: 12.80mlTrain batch 24/31 - 110.1ms/batch - loss: 16.72924 - diff: 12.77mlTrain batch 25/31 - 119.6ms/batch - loss: 16.63656 - diff: 12.80mlTrain batch 26/31 - 110.9ms/batch - loss: 16.30195 - diff: 12.65mlTrain batch 27/31 - 117.3ms/batch - loss: 16.70394 - diff: 12.75mlTrain batch 28/31 - 110.5ms/batch - loss: 16.40545 - diff: 12.65mlTrain batch 29/31 - 115.8ms/batch - loss: 16.07459 - diff: 12.51mlTrain batch 30/31 - 109.0ms/batch - loss: 16.15431 - diff: 12.61mlTrain batch 31/31 - 69.3ms/batch - loss: 17.25571 - diff: 12.77mlTrain batch 31/31 - 9.8s 69.3ms/batch - loss: 17.25571 - diff: 12.77ml
Test 0.8s: val_loss: 38.00431 - diff: 17.90ml
Epoch   135: reducing learning rate of group 0 to 1.5625e-05.

Epoch 135: current best loss = 36.31351, at epoch 79
Train batch 1/31 - 111.7ms/batch - loss: 10.49479 - diff: 10.20mlTrain batch 2/31 - 110.7ms/batch - loss: 28.30090 - diff: 17.70mlTrain batch 3/31 - 111.2ms/batch - loss: 21.22326 - diff: 14.83mlTrain batch 4/31 - 110.9ms/batch - loss: 19.58383 - diff: 14.54mlTrain batch 5/31 - 113.1ms/batch - loss: 17.78210 - diff: 13.69mlTrain batch 6/31 - 111.8ms/batch - loss: 21.84318 - diff: 15.33mlTrain batch 7/31 - 110.3ms/batch - loss: 20.23662 - diff: 14.67mlTrain batch 8/31 - 110.0ms/batch - loss: 19.22354 - diff: 14.18mlTrain batch 9/31 - 109.9ms/batch - loss: 18.33073 - diff: 13.76mlTrain batch 10/31 - 110.1ms/batch - loss: 18.17099 - diff: 13.65mlTrain batch 11/31 - 111.9ms/batch - loss: 17.76364 - diff: 13.48mlTrain batch 12/31 - 110.2ms/batch - loss: 16.86848 - diff: 13.09mlTrain batch 13/31 - 110.6ms/batch - loss: 17.28534 - diff: 13.39mlTrain batch 14/31 - 110.2ms/batch - loss: 16.73501 - diff: 13.15mlTrain batch 15/31 - 112.6ms/batch - loss: 16.22817 - diff: 12.96mlTrain batch 16/31 - 110.0ms/batch - loss: 15.90574 - diff: 12.79mlTrain batch 17/31 - 109.6ms/batch - loss: 15.37397 - diff: 12.58mlTrain batch 18/31 - 110.0ms/batch - loss: 14.66554 - diff: 12.15mlTrain batch 19/31 - 122.0ms/batch - loss: 15.04323 - diff: 12.42mlTrain batch 20/31 - 109.9ms/batch - loss: 14.73095 - diff: 12.21mlTrain batch 21/31 - 109.9ms/batch - loss: 14.38321 - diff: 12.04mlTrain batch 22/31 - 109.6ms/batch - loss: 14.98340 - diff: 12.37mlTrain batch 23/31 - 110.1ms/batch - loss: 15.54437 - diff: 12.62mlTrain batch 24/31 - 109.9ms/batch - loss: 15.99372 - diff: 12.75mlTrain batch 25/31 - 110.0ms/batch - loss: 15.78785 - diff: 12.61mlTrain batch 26/31 - 110.0ms/batch - loss: 15.46635 - diff: 12.49mlTrain batch 27/31 - 110.0ms/batch - loss: 15.80586 - diff: 12.68mlTrain batch 28/31 - 110.0ms/batch - loss: 15.79249 - diff: 12.68mlTrain batch 29/31 - 109.4ms/batch - loss: 15.43845 - diff: 12.49mlTrain batch 30/31 - 109.8ms/batch - loss: 15.24500 - diff: 12.43mlTrain batch 31/31 - 74.7ms/batch - loss: 15.28432 - diff: 12.37mlTrain batch 31/31 - 10.0s 74.7ms/batch - loss: 15.28432 - diff: 12.37ml
Test 0.9s: val_loss: 39.56827 - diff: 17.90ml

Epoch 136: current best loss = 36.31351, at epoch 79
Train batch 1/31 - 112.3ms/batch - loss: 11.81821 - diff: 10.22mlTrain batch 2/31 - 112.2ms/batch - loss: 10.31353 - diff: 10.42mlTrain batch 3/31 - 110.2ms/batch - loss: 8.61914 - diff: 9.46mlTrain batch 4/31 - 110.9ms/batch - loss: 13.09895 - diff: 11.77mlTrain batch 5/31 - 110.4ms/batch - loss: 12.60322 - diff: 11.43mlTrain batch 6/31 - 111.5ms/batch - loss: 11.79621 - diff: 11.02mlTrain batch 7/31 - 110.3ms/batch - loss: 11.33003 - diff: 10.78mlTrain batch 8/31 - 111.2ms/batch - loss: 10.90508 - diff: 10.66mlTrain batch 9/31 - 110.8ms/batch - loss: 11.18196 - diff: 10.90mlTrain batch 10/31 - 111.7ms/batch - loss: 14.98773 - diff: 12.44mlTrain batch 11/31 - 113.7ms/batch - loss: 14.15747 - diff: 12.07mlTrain batch 12/31 - 111.7ms/batch - loss: 14.56070 - diff: 12.37mlTrain batch 13/31 - 110.8ms/batch - loss: 14.37142 - diff: 12.20mlTrain batch 14/31 - 111.4ms/batch - loss: 14.07247 - diff: 12.12mlTrain batch 15/31 - 113.5ms/batch - loss: 16.21262 - diff: 12.96mlTrain batch 16/31 - 111.0ms/batch - loss: 16.03536 - diff: 12.95mlTrain batch 17/31 - 112.9ms/batch - loss: 16.21038 - diff: 13.07mlTrain batch 18/31 - 113.1ms/batch - loss: 15.52001 - diff: 12.72mlTrain batch 19/31 - 113.7ms/batch - loss: 15.05735 - diff: 12.52mlTrain batch 20/31 - 110.3ms/batch - loss: 15.69501 - diff: 12.87mlTrain batch 21/31 - 111.0ms/batch - loss: 15.23217 - diff: 12.56mlTrain batch 22/31 - 115.6ms/batch - loss: 15.04380 - diff: 12.45mlTrain batch 23/31 - 111.9ms/batch - loss: 14.89604 - diff: 12.40mlTrain batch 24/31 - 110.5ms/batch - loss: 14.91949 - diff: 12.44mlTrain batch 25/31 - 110.1ms/batch - loss: 14.71166 - diff: 12.30mlTrain batch 26/31 - 110.0ms/batch - loss: 16.50068 - diff: 12.72mlTrain batch 27/31 - 110.0ms/batch - loss: 16.40299 - diff: 12.66mlTrain batch 28/31 - 114.5ms/batch - loss: 16.81492 - diff: 12.87mlTrain batch 29/31 - 111.3ms/batch - loss: 16.89691 - diff: 12.95mlTrain batch 30/31 - 110.1ms/batch - loss: 16.60290 - diff: 12.79mlTrain batch 31/31 - 71.7ms/batch - loss: 16.76912 - diff: 12.78mlTrain batch 31/31 - 9.8s 71.7ms/batch - loss: 16.76912 - diff: 12.78ml
Test 0.9s: val_loss: 38.39124 - diff: 18.16ml

Epoch 137: current best loss = 36.31351, at epoch 79
Train batch 1/31 - 112.9ms/batch - loss: 12.11726 - diff: 11.41mlTrain batch 2/31 - 111.4ms/batch - loss: 28.67264 - diff: 17.58mlTrain batch 3/31 - 120.3ms/batch - loss: 22.98016 - diff: 15.14mlTrain batch 4/31 - 112.7ms/batch - loss: 19.64590 - diff: 13.85mlTrain batch 5/31 - 120.6ms/batch - loss: 20.15150 - diff: 14.18mlTrain batch 6/31 - 113.8ms/batch - loss: 17.86391 - diff: 13.28mlTrain batch 7/31 - 126.7ms/batch - loss: 15.83827 - diff: 12.21mlTrain batch 8/31 - 113.1ms/batch - loss: 16.34813 - diff: 12.62mlTrain batch 9/31 - 112.6ms/batch - loss: 16.14470 - diff: 12.72mlTrain batch 10/31 - 112.3ms/batch - loss: 15.44270 - diff: 12.48mlTrain batch 11/31 - 113.3ms/batch - loss: 15.70309 - diff: 12.57mlTrain batch 12/31 - 112.3ms/batch - loss: 15.72399 - diff: 12.59mlTrain batch 13/31 - 113.6ms/batch - loss: 15.46252 - diff: 12.54mlTrain batch 14/31 - 116.7ms/batch - loss: 15.03117 - diff: 12.35mlTrain batch 15/31 - 111.4ms/batch - loss: 14.92885 - diff: 12.36mlTrain batch 16/31 - 111.1ms/batch - loss: 14.74509 - diff: 12.09mlTrain batch 17/31 - 133.3ms/batch - loss: 15.13541 - diff: 12.28mlTrain batch 18/31 - 116.8ms/batch - loss: 14.81231 - diff: 12.05mlTrain batch 19/31 - 110.3ms/batch - loss: 17.23765 - diff: 12.92mlTrain batch 20/31 - 109.6ms/batch - loss: 16.88240 - diff: 12.81mlTrain batch 21/31 - 113.4ms/batch - loss: 16.64234 - diff: 12.68mlTrain batch 22/31 - 110.4ms/batch - loss: 18.28521 - diff: 13.12mlTrain batch 23/31 - 110.4ms/batch - loss: 17.80013 - diff: 12.96mlTrain batch 24/31 - 110.1ms/batch - loss: 17.47163 - diff: 12.88mlTrain batch 25/31 - 111.9ms/batch - loss: 16.98236 - diff: 12.67mlTrain batch 26/31 - 111.1ms/batch - loss: 16.67934 - diff: 12.54mlTrain batch 27/31 - 114.5ms/batch - loss: 16.41681 - diff: 12.47mlTrain batch 28/31 - 109.7ms/batch - loss: 16.34152 - diff: 12.45mlTrain batch 29/31 - 110.3ms/batch - loss: 16.05796 - diff: 12.31mlTrain batch 30/31 - 109.5ms/batch - loss: 15.61520 - diff: 12.07mlTrain batch 31/31 - 69.0ms/batch - loss: 16.50612 - diff: 12.19mlTrain batch 31/31 - 9.8s 69.0ms/batch - loss: 16.50612 - diff: 12.19ml
Test 0.9s: val_loss: 40.23974 - diff: 18.17ml

Epoch 138: current best loss = 36.31351, at epoch 79
Train batch 1/31 - 110.3ms/batch - loss: 6.54975 - diff: 9.26mlTrain batch 2/31 - 109.9ms/batch - loss: 7.24363 - diff: 8.82mlTrain batch 3/31 - 112.5ms/batch - loss: 7.32364 - diff: 8.95mlTrain batch 4/31 - 110.0ms/batch - loss: 9.46998 - diff: 10.06mlTrain batch 5/31 - 110.4ms/batch - loss: 9.13928 - diff: 9.85mlTrain batch 6/31 - 109.5ms/batch - loss: 9.44911 - diff: 10.06mlTrain batch 7/31 - 111.0ms/batch - loss: 12.82697 - diff: 11.70mlTrain batch 8/31 - 109.6ms/batch - loss: 16.60600 - diff: 13.08mlTrain batch 9/31 - 111.5ms/batch - loss: 17.84145 - diff: 13.66mlTrain batch 10/31 - 109.9ms/batch - loss: 20.41049 - diff: 14.78mlTrain batch 11/31 - 111.1ms/batch - loss: 19.31208 - diff: 14.26mlTrain batch 12/31 - 110.0ms/batch - loss: 19.34666 - diff: 14.33mlTrain batch 13/31 - 112.4ms/batch - loss: 18.35894 - diff: 13.92mlTrain batch 14/31 - 110.2ms/batch - loss: 18.24519 - diff: 13.83mlTrain batch 15/31 - 112.7ms/batch - loss: 18.31286 - diff: 13.87mlTrain batch 16/31 - 110.6ms/batch - loss: 17.84333 - diff: 13.71mlTrain batch 17/31 - 138.1ms/batch - loss: 17.42076 - diff: 13.49mlTrain batch 18/31 - 114.8ms/batch - loss: 18.10296 - diff: 13.75mlTrain batch 19/31 - 113.0ms/batch - loss: 17.74810 - diff: 13.61mlTrain batch 20/31 - 109.9ms/batch - loss: 17.58021 - diff: 13.57mlTrain batch 21/31 - 114.3ms/batch - loss: 17.02255 - diff: 13.30mlTrain batch 22/31 - 109.9ms/batch - loss: 16.91907 - diff: 13.19mlTrain batch 23/31 - 114.0ms/batch - loss: 16.30092 - diff: 12.85mlTrain batch 24/31 - 110.0ms/batch - loss: 15.98154 - diff: 12.74mlTrain batch 25/31 - 113.0ms/batch - loss: 15.77826 - diff: 12.66mlTrain batch 26/31 - 109.8ms/batch - loss: 15.48986 - diff: 12.55mlTrain batch 27/31 - 111.5ms/batch - loss: 15.60952 - diff: 12.56mlTrain batch 28/31 - 110.6ms/batch - loss: 15.45344 - diff: 12.49mlTrain batch 29/31 - 110.1ms/batch - loss: 15.40470 - diff: 12.52mlTrain batch 30/31 - 109.4ms/batch - loss: 15.46569 - diff: 12.53mlTrain batch 31/31 - 69.6ms/batch - loss: 17.81894 - diff: 12.84mlTrain batch 31/31 - 9.9s 69.6ms/batch - loss: 17.81894 - diff: 12.84ml
Test 0.8s: val_loss: 42.34944 - diff: 18.79ml

Epoch 139: current best loss = 36.31351, at epoch 79
Train batch 1/31 - 111.1ms/batch - loss: 10.14172 - diff: 10.07mlTrain batch 2/31 - 110.0ms/batch - loss: 9.60442 - diff: 10.36mlTrain batch 3/31 - 109.9ms/batch - loss: 9.57340 - diff: 10.33mlTrain batch 4/31 - 109.9ms/batch - loss: 15.12283 - diff: 12.73mlTrain batch 5/31 - 109.7ms/batch - loss: 13.87480 - diff: 11.90mlTrain batch 6/31 - 109.8ms/batch - loss: 12.67313 - diff: 11.37mlTrain batch 7/31 - 109.8ms/batch - loss: 15.23495 - diff: 12.31mlTrain batch 8/31 - 109.7ms/batch - loss: 15.97746 - diff: 12.77mlTrain batch 9/31 - 110.7ms/batch - loss: 15.17627 - diff: 12.32mlTrain batch 10/31 - 110.6ms/batch - loss: 13.92488 - diff: 11.66mlTrain batch 11/31 - 110.4ms/batch - loss: 14.56362 - diff: 11.94mlTrain batch 12/31 - 110.1ms/batch - loss: 15.29830 - diff: 12.37mlTrain batch 13/31 - 109.9ms/batch - loss: 15.81332 - diff: 12.72mlTrain batch 14/31 - 110.1ms/batch - loss: 15.83718 - diff: 12.79mlTrain batch 15/31 - 110.7ms/batch - loss: 15.53352 - diff: 12.69mlTrain batch 16/31 - 113.8ms/batch - loss: 15.35733 - diff: 12.56mlTrain batch 17/31 - 109.7ms/batch - loss: 15.06953 - diff: 12.41mlTrain batch 18/31 - 109.9ms/batch - loss: 14.84319 - diff: 12.32mlTrain batch 19/31 - 111.0ms/batch - loss: 14.24650 - diff: 12.00mlTrain batch 20/31 - 113.1ms/batch - loss: 14.16131 - diff: 11.99mlTrain batch 21/31 - 111.3ms/batch - loss: 13.90090 - diff: 11.93mlTrain batch 22/31 - 114.7ms/batch - loss: 13.62836 - diff: 11.79mlTrain batch 23/31 - 111.2ms/batch - loss: 13.28421 - diff: 11.61mlTrain batch 24/31 - 114.9ms/batch - loss: 15.73903 - diff: 12.19mlTrain batch 25/31 - 111.1ms/batch - loss: 15.48934 - diff: 12.10mlTrain batch 26/31 - 113.8ms/batch - loss: 15.17019 - diff: 11.97mlTrain batch 27/31 - 111.0ms/batch - loss: 15.85757 - diff: 12.33mlTrain batch 28/31 - 114.9ms/batch - loss: 15.79934 - diff: 12.28mlTrain batch 29/31 - 111.2ms/batch - loss: 15.83223 - diff: 12.28mlTrain batch 30/31 - 110.9ms/batch - loss: 16.74552 - diff: 12.66mlTrain batch 31/31 - 70.0ms/batch - loss: 17.35558 - diff: 12.71mlTrain batch 31/31 - 9.8s 70.0ms/batch - loss: 17.35558 - diff: 12.71ml
Test 0.8s: val_loss: 42.03142 - diff: 17.82ml

Epoch 140: current best loss = 36.31351, at epoch 79
Train batch 1/31 - 112.1ms/batch - loss: 86.66206 - diff: 34.61mlTrain batch 2/31 - 110.4ms/batch - loss: 49.95543 - diff: 22.94mlTrain batch 3/31 - 114.9ms/batch - loss: 46.70037 - diff: 23.12mlTrain batch 4/31 - 113.8ms/batch - loss: 36.15880 - diff: 19.04mlTrain batch 5/31 - 118.5ms/batch - loss: 30.86631 - diff: 17.23mlTrain batch 6/31 - 113.1ms/batch - loss: 28.88706 - diff: 16.89mlTrain batch 7/31 - 110.7ms/batch - loss: 26.67617 - diff: 16.12mlTrain batch 8/31 - 111.4ms/batch - loss: 24.56944 - diff: 15.39mlTrain batch 9/31 - 115.0ms/batch - loss: 22.74982 - diff: 14.74mlTrain batch 10/31 - 115.0ms/batch - loss: 23.33103 - diff: 15.07mlTrain batch 11/31 - 111.9ms/batch - loss: 22.23159 - diff: 14.68mlTrain batch 12/31 - 116.5ms/batch - loss: 21.52669 - diff: 14.41mlTrain batch 13/31 - 112.4ms/batch - loss: 21.65290 - diff: 14.32mlTrain batch 14/31 - 116.0ms/batch - loss: 22.98117 - diff: 14.90mlTrain batch 15/31 - 125.3ms/batch - loss: 22.15414 - diff: 14.63mlTrain batch 16/31 - 119.8ms/batch - loss: 21.87921 - diff: 14.62mlTrain batch 17/31 - 109.8ms/batch - loss: 21.15727 - diff: 14.33mlTrain batch 18/31 - 109.7ms/batch - loss: 21.39443 - diff: 14.59mlTrain batch 19/31 - 114.9ms/batch - loss: 21.04184 - diff: 14.51mlTrain batch 20/31 - 111.7ms/batch - loss: 20.95484 - diff: 14.59mlTrain batch 21/31 - 111.1ms/batch - loss: 21.87601 - diff: 14.92mlTrain batch 22/31 - 111.3ms/batch - loss: 22.81414 - diff: 15.12mlTrain batch 23/31 - 111.5ms/batch - loss: 22.84464 - diff: 15.19mlTrain batch 24/31 - 110.0ms/batch - loss: 22.35423 - diff: 15.01mlTrain batch 25/31 - 113.7ms/batch - loss: 22.25601 - diff: 15.05mlTrain batch 26/31 - 110.1ms/batch - loss: 25.18508 - diff: 15.95mlTrain batch 27/31 - 111.4ms/batch - loss: 24.73918 - diff: 15.80mlTrain batch 28/31 - 109.8ms/batch - loss: 24.43499 - diff: 15.74mlTrain batch 29/31 - 114.1ms/batch - loss: 23.92376 - diff: 15.55mlTrain batch 30/31 - 109.7ms/batch - loss: 23.48832 - diff: 15.36mlTrain batch 31/31 - 69.1ms/batch - loss: 25.92198 - diff: 15.64mlTrain batch 31/31 - 9.9s 69.1ms/batch - loss: 25.92198 - diff: 15.64ml
Test 0.8s: val_loss: 42.86639 - diff: 19.53ml

Epoch 141: current best loss = 36.31351, at epoch 79
Train batch 1/31 - 124.2ms/batch - loss: 92.84924 - diff: 35.27mlTrain batch 2/31 - 110.2ms/batch - loss: 49.17058 - diff: 21.21mlTrain batch 3/31 - 116.5ms/batch - loss: 51.82485 - diff: 22.74mlTrain batch 4/31 - 109.7ms/batch - loss: 42.77001 - diff: 20.52mlTrain batch 5/31 - 112.7ms/batch - loss: 37.04136 - diff: 18.83mlTrain batch 6/31 - 109.8ms/batch - loss: 32.97653 - diff: 17.61mlTrain batch 7/31 - 112.7ms/batch - loss: 30.29055 - diff: 16.85mlTrain batch 8/31 - 110.4ms/batch - loss: 27.50700 - diff: 15.85mlTrain batch 9/31 - 112.4ms/batch - loss: 25.03256 - diff: 14.91mlTrain batch 10/31 - 109.6ms/batch - loss: 23.85979 - diff: 14.67mlTrain batch 11/31 - 112.5ms/batch - loss: 22.95726 - diff: 14.43mlTrain batch 12/31 - 110.0ms/batch - loss: 21.61134 - diff: 13.91mlTrain batch 13/31 - 110.9ms/batch - loss: 20.40022 - diff: 13.46mlTrain batch 14/31 - 109.7ms/batch - loss: 20.28324 - diff: 13.53mlTrain batch 15/31 - 122.5ms/batch - loss: 19.41021 - diff: 13.19mlTrain batch 16/31 - 110.4ms/batch - loss: 19.39536 - diff: 13.22mlTrain batch 17/31 - 113.0ms/batch - loss: 18.82772 - diff: 12.99mlTrain batch 18/31 - 110.0ms/batch - loss: 18.17740 - diff: 12.76mlTrain batch 19/31 - 112.8ms/batch - loss: 17.89818 - diff: 12.76mlTrain batch 20/31 - 110.2ms/batch - loss: 18.06093 - diff: 12.94mlTrain batch 21/31 - 110.7ms/batch - loss: 17.52914 - diff: 12.74mlTrain batch 22/31 - 110.0ms/batch - loss: 17.78655 - diff: 12.91mlTrain batch 23/31 - 112.4ms/batch - loss: 18.31709 - diff: 13.14mlTrain batch 24/31 - 110.2ms/batch - loss: 18.15083 - diff: 13.11mlTrain batch 25/31 - 110.2ms/batch - loss: 18.31009 - diff: 13.14mlTrain batch 26/31 - 109.8ms/batch - loss: 17.77709 - diff: 12.85mlTrain batch 27/31 - 113.0ms/batch - loss: 17.40896 - diff: 12.69mlTrain batch 28/31 - 110.0ms/batch - loss: 17.03233 - diff: 12.54mlTrain batch 29/31 - 112.4ms/batch - loss: 17.78932 - diff: 12.85mlTrain batch 30/31 - 109.6ms/batch - loss: 17.35093 - diff: 12.64mlTrain batch 31/31 - 69.1ms/batch - loss: 17.33431 - diff: 12.59mlTrain batch 31/31 - 9.9s 69.1ms/batch - loss: 17.33431 - diff: 12.59ml
Test 0.8s: val_loss: 48.75088 - diff: 18.18ml

Epoch 142: current best loss = 36.31351, at epoch 79
Train batch 1/31 - 110.7ms/batch - loss: 29.21809 - diff: 17.39mlTrain batch 2/31 - 109.9ms/batch - loss: 27.63856 - diff: 16.67mlTrain batch 3/31 - 111.0ms/batch - loss: 24.46886 - diff: 16.26mlTrain batch 4/31 - 110.5ms/batch - loss: 20.55661 - diff: 14.50mlTrain batch 5/31 - 110.8ms/batch - loss: 19.06184 - diff: 13.75mlTrain batch 6/31 - 110.6ms/batch - loss: 17.28610 - diff: 13.04mlTrain batch 7/31 - 110.3ms/batch - loss: 19.18025 - diff: 14.17mlTrain batch 8/31 - 110.4ms/batch - loss: 19.07205 - diff: 14.25mlTrain batch 9/31 - 109.9ms/batch - loss: 22.10968 - diff: 15.43mlTrain batch 10/31 - 109.8ms/batch - loss: 28.03619 - diff: 16.46mlTrain batch 11/31 - 110.3ms/batch - loss: 29.27511 - diff: 17.05mlTrain batch 12/31 - 109.8ms/batch - loss: 28.47742 - diff: 16.85mlTrain batch 13/31 - 113.7ms/batch - loss: 27.69565 - diff: 16.41mlTrain batch 14/31 - 112.6ms/batch - loss: 26.36370 - diff: 15.85mlTrain batch 15/31 - 110.0ms/batch - loss: 27.00529 - diff: 16.09mlTrain batch 16/31 - 109.5ms/batch - loss: 25.83028 - diff: 15.69mlTrain batch 17/31 - 111.0ms/batch - loss: 24.77644 - diff: 15.31mlTrain batch 18/31 - 111.2ms/batch - loss: 25.02883 - diff: 15.41mlTrain batch 19/31 - 110.1ms/batch - loss: 24.22446 - diff: 15.13mlTrain batch 20/31 - 114.7ms/batch - loss: 24.56749 - diff: 15.40mlTrain batch 21/31 - 110.1ms/batch - loss: 23.97443 - diff: 15.23mlTrain batch 22/31 - 116.5ms/batch - loss: 23.59883 - diff: 15.09mlTrain batch 23/31 - 109.9ms/batch - loss: 22.97233 - diff: 14.88mlTrain batch 24/31 - 112.7ms/batch - loss: 23.72499 - diff: 15.25mlTrain batch 25/31 - 110.6ms/batch - loss: 23.36931 - diff: 15.14mlTrain batch 26/31 - 111.0ms/batch - loss: 24.04793 - diff: 15.43mlTrain batch 27/31 - 110.1ms/batch - loss: 23.39286 - diff: 15.17mlTrain batch 28/31 - 116.6ms/batch - loss: 22.77040 - diff: 14.86mlTrain batch 29/31 - 109.7ms/batch - loss: 22.48157 - diff: 14.80mlTrain batch 30/31 - 111.0ms/batch - loss: 22.16451 - diff: 14.71mlTrain batch 31/31 - 72.0ms/batch - loss: 22.14462 - diff: 14.64mlTrain batch 31/31 - 9.8s 72.0ms/batch - loss: 22.14462 - diff: 14.64ml
Test 0.8s: val_loss: 39.20686 - diff: 17.86ml

Epoch 143: current best loss = 36.31351, at epoch 79
Train batch 1/31 - 116.4ms/batch - loss: 12.38615 - diff: 9.81mlTrain batch 2/31 - 111.3ms/batch - loss: 14.43667 - diff: 11.57mlTrain batch 3/31 - 115.3ms/batch - loss: 14.34831 - diff: 11.81mlTrain batch 4/31 - 113.6ms/batch - loss: 15.92668 - diff: 12.85mlTrain batch 5/31 - 114.6ms/batch - loss: 15.20183 - diff: 12.69mlTrain batch 6/31 - 113.8ms/batch - loss: 14.27155 - diff: 11.97mlTrain batch 7/31 - 114.7ms/batch - loss: 15.44026 - diff: 12.66mlTrain batch 8/31 - 114.7ms/batch - loss: 17.26495 - diff: 13.37mlTrain batch 9/31 - 112.1ms/batch - loss: 16.34795 - diff: 12.93mlTrain batch 10/31 - 113.7ms/batch - loss: 15.14820 - diff: 12.32mlTrain batch 11/31 - 111.3ms/batch - loss: 15.65987 - diff: 12.55mlTrain batch 12/31 - 112.5ms/batch - loss: 15.74446 - diff: 12.65mlTrain batch 13/31 - 139.1ms/batch - loss: 16.72503 - diff: 13.12mlTrain batch 14/31 - 118.7ms/batch - loss: 17.71199 - diff: 13.68mlTrain batch 15/31 - 110.8ms/batch - loss: 19.30057 - diff: 14.22mlTrain batch 16/31 - 110.1ms/batch - loss: 18.32491 - diff: 13.73mlTrain batch 17/31 - 114.4ms/batch - loss: 18.01413 - diff: 13.65mlTrain batch 18/31 - 110.6ms/batch - loss: 17.82140 - diff: 13.60mlTrain batch 19/31 - 110.6ms/batch - loss: 18.83454 - diff: 14.03mlTrain batch 20/31 - 110.3ms/batch - loss: 18.77219 - diff: 13.97mlTrain batch 21/31 - 112.8ms/batch - loss: 18.17268 - diff: 13.73mlTrain batch 22/31 - 110.2ms/batch - loss: 17.70485 - diff: 13.53mlTrain batch 23/31 - 110.3ms/batch - loss: 17.22155 - diff: 13.31mlTrain batch 24/31 - 110.1ms/batch - loss: 17.33192 - diff: 13.41mlTrain batch 25/31 - 110.4ms/batch - loss: 17.02814 - diff: 13.29mlTrain batch 26/31 - 109.6ms/batch - loss: 18.85816 - diff: 13.93mlTrain batch 27/31 - 111.6ms/batch - loss: 18.76722 - diff: 13.90mlTrain batch 28/31 - 110.0ms/batch - loss: 18.55687 - diff: 13.81mlTrain batch 29/31 - 109.6ms/batch - loss: 18.20006 - diff: 13.69mlTrain batch 30/31 - 109.4ms/batch - loss: 18.08638 - diff: 13.60mlTrain batch 31/31 - 70.0ms/batch - loss: 18.64422 - diff: 13.67mlTrain batch 31/31 - 9.9s 70.0ms/batch - loss: 18.64422 - diff: 13.67ml
Test 0.9s: val_loss: 43.15546 - diff: 18.16ml

Epoch 144: current best loss = 36.31351, at epoch 79
Train batch 1/31 - 112.7ms/batch - loss: 14.93501 - diff: 12.47mlTrain batch 2/31 - 112.0ms/batch - loss: 18.02991 - diff: 14.53mlTrain batch 3/31 - 112.4ms/batch - loss: 27.09999 - diff: 17.33mlTrain batch 4/31 - 110.1ms/batch - loss: 23.96414 - diff: 16.40mlTrain batch 5/31 - 110.4ms/batch - loss: 24.27347 - diff: 16.43mlTrain batch 6/31 - 110.4ms/batch - loss: 21.74804 - diff: 15.26mlTrain batch 7/31 - 110.0ms/batch - loss: 20.40125 - diff: 14.80mlTrain batch 8/31 - 110.2ms/batch - loss: 19.45963 - diff: 14.53mlTrain batch 9/31 - 109.6ms/batch - loss: 22.69883 - diff: 15.83mlTrain batch 10/31 - 109.4ms/batch - loss: 26.72433 - diff: 16.44mlTrain batch 11/31 - 109.2ms/batch - loss: 24.97882 - diff: 15.72mlTrain batch 12/31 - 109.8ms/batch - loss: 24.02225 - diff: 15.48mlTrain batch 13/31 - 110.1ms/batch - loss: 24.62690 - diff: 15.88mlTrain batch 14/31 - 109.8ms/batch - loss: 23.87915 - diff: 15.62mlTrain batch 15/31 - 109.6ms/batch - loss: 23.09350 - diff: 15.33mlTrain batch 16/31 - 110.6ms/batch - loss: 23.90039 - diff: 15.69mlTrain batch 17/31 - 109.4ms/batch - loss: 23.05284 - diff: 15.37mlTrain batch 18/31 - 110.2ms/batch - loss: 22.98757 - diff: 15.37mlTrain batch 19/31 - 109.9ms/batch - loss: 22.20196 - diff: 15.07mlTrain batch 20/31 - 110.2ms/batch - loss: 22.11192 - diff: 14.97mlTrain batch 21/31 - 109.5ms/batch - loss: 21.77128 - diff: 14.85mlTrain batch 22/31 - 110.8ms/batch - loss: 21.22248 - diff: 14.66mlTrain batch 23/31 - 109.7ms/batch - loss: 21.47062 - diff: 14.87mlTrain batch 24/31 - 111.4ms/batch - loss: 22.43816 - diff: 15.26mlTrain batch 25/31 - 110.0ms/batch - loss: 22.37011 - diff: 15.28mlTrain batch 26/31 - 111.6ms/batch - loss: 22.90742 - diff: 15.35mlTrain batch 27/31 - 110.1ms/batch - loss: 22.35616 - diff: 15.06mlTrain batch 28/31 - 111.7ms/batch - loss: 22.12795 - diff: 15.00mlTrain batch 29/31 - 109.2ms/batch - loss: 21.67066 - diff: 14.80mlTrain batch 30/31 - 111.6ms/batch - loss: 21.05289 - diff: 14.50mlTrain batch 31/31 - 71.0ms/batch - loss: 22.35844 - diff: 14.66mlTrain batch 31/31 - 9.9s 71.0ms/batch - loss: 22.35844 - diff: 14.66ml
Test 0.8s: val_loss: 38.31506 - diff: 17.95ml

Epoch 145: current best loss = 36.31351, at epoch 79
Train batch 1/31 - 111.3ms/batch - loss: 7.66887 - diff: 9.49mlTrain batch 2/31 - 111.0ms/batch - loss: 14.55632 - diff: 12.65mlTrain batch 3/31 - 111.1ms/batch - loss: 25.60465 - diff: 16.23mlTrain batch 4/31 - 111.4ms/batch - loss: 20.87694 - diff: 14.27mlTrain batch 5/31 - 111.9ms/batch - loss: 25.72310 - diff: 16.10mlTrain batch 6/31 - 111.9ms/batch - loss: 23.18617 - diff: 15.28mlTrain batch 7/31 - 110.6ms/batch - loss: 22.88883 - diff: 15.32mlTrain batch 8/31 - 110.6ms/batch - loss: 21.27427 - diff: 14.78mlTrain batch 9/31 - 110.4ms/batch - loss: 19.21022 - diff: 13.71mlTrain batch 10/31 - 110.3ms/batch - loss: 24.88370 - diff: 15.65mlTrain batch 11/31 - 112.6ms/batch - loss: 25.40405 - diff: 16.02mlTrain batch 12/31 - 117.8ms/batch - loss: 24.71963 - diff: 15.85mlTrain batch 13/31 - 110.6ms/batch - loss: 23.96716 - diff: 15.67mlTrain batch 14/31 - 110.7ms/batch - loss: 23.23519 - diff: 15.50mlTrain batch 15/31 - 113.1ms/batch - loss: 22.05472 - diff: 15.00mlTrain batch 16/31 - 110.8ms/batch - loss: 22.73368 - diff: 15.35mlTrain batch 17/31 - 111.3ms/batch - loss: 22.15596 - diff: 15.13mlTrain batch 18/31 - 111.3ms/batch - loss: 21.37268 - diff: 14.77mlTrain batch 19/31 - 111.7ms/batch - loss: 20.48143 - diff: 14.38mlTrain batch 20/31 - 111.7ms/batch - loss: 20.69669 - diff: 14.59mlTrain batch 21/31 - 112.3ms/batch - loss: 20.48931 - diff: 14.52mlTrain batch 22/31 - 114.6ms/batch - loss: 20.18221 - diff: 14.45mlTrain batch 23/31 - 110.5ms/batch - loss: 20.06388 - diff: 14.27mlTrain batch 24/31 - 109.9ms/batch - loss: 19.74479 - diff: 14.21mlTrain batch 25/31 - 110.4ms/batch - loss: 19.43509 - diff: 14.13mlTrain batch 26/31 - 110.3ms/batch - loss: 18.83048 - diff: 13.85mlTrain batch 27/31 - 110.5ms/batch - loss: 18.78954 - diff: 13.87mlTrain batch 28/31 - 111.3ms/batch - loss: 19.41495 - diff: 13.92mlTrain batch 29/31 - 110.4ms/batch - loss: 19.24413 - diff: 13.89mlTrain batch 30/31 - 109.2ms/batch - loss: 19.29003 - diff: 13.84mlTrain batch 31/31 - 69.4ms/batch - loss: 19.40127 - diff: 13.83mlTrain batch 31/31 - 9.9s 69.4ms/batch - loss: 19.40127 - diff: 13.83ml
Test 0.9s: val_loss: 41.90811 - diff: 18.70ml
Epoch   146: reducing learning rate of group 0 to 7.8125e-06.

Epoch 146: current best loss = 36.31351, at epoch 79
Train batch 1/31 - 129.0ms/batch - loss: 14.91421 - diff: 11.86mlTrain batch 2/31 - 110.3ms/batch - loss: 12.83468 - diff: 10.67mlTrain batch 3/31 - 122.0ms/batch - loss: 11.75306 - diff: 10.73mlTrain batch 4/31 - 110.7ms/batch - loss: 13.75425 - diff: 11.90mlTrain batch 5/31 - 116.9ms/batch - loss: 12.75622 - diff: 11.41mlTrain batch 6/31 - 110.5ms/batch - loss: 13.66894 - diff: 12.04mlTrain batch 7/31 - 113.8ms/batch - loss: 14.33408 - diff: 12.31mlTrain batch 8/31 - 110.9ms/batch - loss: 13.33387 - diff: 11.79mlTrain batch 9/31 - 113.5ms/batch - loss: 13.44294 - diff: 11.93mlTrain batch 10/31 - 110.3ms/batch - loss: 13.40068 - diff: 11.89mlTrain batch 11/31 - 133.8ms/batch - loss: 12.98603 - diff: 11.70mlTrain batch 12/31 - 118.8ms/batch - loss: 13.06495 - diff: 11.66mlTrain batch 13/31 - 110.6ms/batch - loss: 12.46880 - diff: 11.33mlTrain batch 14/31 - 110.3ms/batch - loss: 13.02241 - diff: 11.64mlTrain batch 15/31 - 110.0ms/batch - loss: 14.13647 - diff: 12.18mlTrain batch 16/31 - 109.8ms/batch - loss: 13.71427 - diff: 12.00mlTrain batch 17/31 - 109.9ms/batch - loss: 13.22270 - diff: 11.76mlTrain batch 18/31 - 109.9ms/batch - loss: 13.20263 - diff: 11.80mlTrain batch 19/31 - 111.5ms/batch - loss: 13.04115 - diff: 11.76mlTrain batch 20/31 - 110.4ms/batch - loss: 15.07323 - diff: 12.53mlTrain batch 21/31 - 112.6ms/batch - loss: 14.92555 - diff: 12.43mlTrain batch 22/31 - 110.3ms/batch - loss: 14.49298 - diff: 12.17mlTrain batch 23/31 - 111.2ms/batch - loss: 15.10452 - diff: 12.40mlTrain batch 24/31 - 109.4ms/batch - loss: 14.76814 - diff: 12.24mlTrain batch 25/31 - 115.2ms/batch - loss: 15.09566 - diff: 12.36mlTrain batch 26/31 - 110.4ms/batch - loss: 15.02766 - diff: 12.37mlTrain batch 27/31 - 112.5ms/batch - loss: 14.81457 - diff: 12.28mlTrain batch 28/31 - 109.9ms/batch - loss: 14.99988 - diff: 12.34mlTrain batch 29/31 - 112.1ms/batch - loss: 15.31613 - diff: 12.37mlTrain batch 30/31 - 109.0ms/batch - loss: 15.22588 - diff: 12.38mlTrain batch 31/31 - 69.4ms/batch - loss: 15.58536 - diff: 12.43mlTrain batch 31/31 - 9.8s 69.4ms/batch - loss: 15.58536 - diff: 12.43ml
Test 0.8s: val_loss: 40.12166 - diff: 18.94ml

Epoch 147: current best loss = 36.31351, at epoch 79
Train batch 1/31 - 115.6ms/batch - loss: 12.18105 - diff: 11.22mlTrain batch 2/31 - 111.7ms/batch - loss: 14.27777 - diff: 13.05mlTrain batch 3/31 - 111.0ms/batch - loss: 15.63403 - diff: 13.66mlTrain batch 4/31 - 110.1ms/batch - loss: 15.75698 - diff: 13.57mlTrain batch 5/31 - 109.9ms/batch - loss: 22.86743 - diff: 16.21mlTrain batch 6/31 - 109.7ms/batch - loss: 22.48249 - diff: 16.08mlTrain batch 7/31 - 109.7ms/batch - loss: 20.66488 - diff: 15.19mlTrain batch 8/31 - 109.7ms/batch - loss: 19.20601 - diff: 14.50mlTrain batch 9/31 - 109.6ms/batch - loss: 18.05171 - diff: 14.01mlTrain batch 10/31 - 109.5ms/batch - loss: 17.22191 - diff: 13.61mlTrain batch 11/31 - 120.5ms/batch - loss: 17.52892 - diff: 13.84mlTrain batch 12/31 - 111.3ms/batch - loss: 17.07623 - diff: 13.63mlTrain batch 13/31 - 110.5ms/batch - loss: 17.31141 - diff: 13.85mlTrain batch 14/31 - 109.9ms/batch - loss: 16.41804 - diff: 13.44mlTrain batch 15/31 - 110.6ms/batch - loss: 16.61570 - diff: 13.48mlTrain batch 16/31 - 110.0ms/batch - loss: 16.36586 - diff: 13.41mlTrain batch 17/31 - 110.9ms/batch - loss: 16.24467 - diff: 13.31mlTrain batch 18/31 - 110.1ms/batch - loss: 16.11319 - diff: 13.22mlTrain batch 19/31 - 110.3ms/batch - loss: 15.91884 - diff: 13.13mlTrain batch 20/31 - 110.2ms/batch - loss: 16.12746 - diff: 13.22mlTrain batch 21/31 - 110.1ms/batch - loss: 15.72366 - diff: 13.05mlTrain batch 22/31 - 110.1ms/batch - loss: 16.41250 - diff: 13.15mlTrain batch 23/31 - 110.0ms/batch - loss: 17.44323 - diff: 13.64mlTrain batch 24/31 - 110.1ms/batch - loss: 17.88335 - diff: 13.80mlTrain batch 25/31 - 110.4ms/batch - loss: 17.84306 - diff: 13.82mlTrain batch 26/31 - 109.7ms/batch - loss: 17.52935 - diff: 13.64mlTrain batch 27/31 - 109.9ms/batch - loss: 17.95999 - diff: 13.69mlTrain batch 28/31 - 110.2ms/batch - loss: 18.01950 - diff: 13.73mlTrain batch 29/31 - 109.6ms/batch - loss: 17.79895 - diff: 13.64mlTrain batch 30/31 - 109.6ms/batch - loss: 17.92179 - diff: 13.64mlTrain batch 31/31 - 74.8ms/batch - loss: 18.96799 - diff: 13.79mlTrain batch 31/31 - 10.0s 74.8ms/batch - loss: 18.96799 - diff: 13.79ml
Test 0.8s: val_loss: 39.25975 - diff: 18.82ml

Epoch 148: current best loss = 36.31351, at epoch 79
Train batch 1/31 - 110.7ms/batch - loss: 18.40810 - diff: 13.36mlTrain batch 2/31 - 110.3ms/batch - loss: 22.14065 - diff: 14.33mlTrain batch 3/31 - 110.3ms/batch - loss: 19.84127 - diff: 14.17mlTrain batch 4/31 - 110.5ms/batch - loss: 21.11404 - diff: 15.07mlTrain batch 5/31 - 109.6ms/batch - loss: 17.76500 - diff: 13.42mlTrain batch 6/31 - 109.9ms/batch - loss: 16.92591 - diff: 13.11mlTrain batch 7/31 - 109.6ms/batch - loss: 15.36591 - diff: 12.28mlTrain batch 8/31 - 109.6ms/batch - loss: 14.16437 - diff: 11.75mlTrain batch 9/31 - 110.7ms/batch - loss: 13.39952 - diff: 11.50mlTrain batch 10/31 - 113.1ms/batch - loss: 12.75995 - diff: 11.17mlTrain batch 11/31 - 109.5ms/batch - loss: 12.81838 - diff: 11.27mlTrain batch 12/31 - 109.8ms/batch - loss: 13.40073 - diff: 11.74mlTrain batch 13/31 - 111.6ms/batch - loss: 12.98052 - diff: 11.52mlTrain batch 14/31 - 111.1ms/batch - loss: 13.17999 - diff: 11.69mlTrain batch 15/31 - 112.6ms/batch - loss: 13.10256 - diff: 11.71mlTrain batch 16/31 - 113.4ms/batch - loss: 12.78817 - diff: 11.60mlTrain batch 17/31 - 112.4ms/batch - loss: 13.16283 - diff: 11.81mlTrain batch 18/31 - 114.1ms/batch - loss: 13.70408 - diff: 12.12mlTrain batch 19/31 - 111.2ms/batch - loss: 13.36793 - diff: 11.94mlTrain batch 20/31 - 113.5ms/batch - loss: 13.22449 - diff: 11.88mlTrain batch 21/31 - 111.0ms/batch - loss: 14.45338 - diff: 12.45mlTrain batch 22/31 - 114.3ms/batch - loss: 14.40991 - diff: 12.39mlTrain batch 23/31 - 112.3ms/batch - loss: 14.30544 - diff: 12.33mlTrain batch 24/31 - 113.0ms/batch - loss: 14.69576 - diff: 12.50mlTrain batch 25/31 - 112.1ms/batch - loss: 16.62559 - diff: 13.20mlTrain batch 26/31 - 117.4ms/batch - loss: 16.42579 - diff: 13.14mlTrain batch 27/31 - 112.3ms/batch - loss: 16.34531 - diff: 13.13mlTrain batch 28/31 - 114.2ms/batch - loss: 17.19118 - diff: 13.46mlTrain batch 29/31 - 110.8ms/batch - loss: 16.91676 - diff: 13.33mlTrain batch 30/31 - 113.3ms/batch - loss: 16.77502 - diff: 13.23mlTrain batch 31/31 - 70.4ms/batch - loss: 16.98236 - diff: 13.19mlTrain batch 31/31 - 9.8s 70.4ms/batch - loss: 16.98236 - diff: 13.19ml
Test 0.8s: val_loss: 39.31448 - diff: 18.45ml

Epoch 149: current best loss = 36.31351, at epoch 79
Train batch 1/31 - 115.8ms/batch - loss: 49.67953 - diff: 25.22mlTrain batch 2/31 - 113.4ms/batch - loss: 30.01535 - diff: 17.69mlTrain batch 3/31 - 114.0ms/batch - loss: 36.08183 - diff: 20.19mlTrain batch 4/31 - 111.5ms/batch - loss: 35.96515 - diff: 20.80mlTrain batch 5/31 - 112.9ms/batch - loss: 31.42406 - diff: 18.89mlTrain batch 6/31 - 112.4ms/batch - loss: 28.01369 - diff: 17.65mlTrain batch 7/31 - 112.9ms/batch - loss: 28.43395 - diff: 18.01mlTrain batch 8/31 - 110.7ms/batch - loss: 26.63988 - diff: 17.31mlTrain batch 9/31 - 135.3ms/batch - loss: 25.12674 - diff: 16.85mlTrain batch 10/31 - 121.5ms/batch - loss: 24.78451 - diff: 16.73mlTrain batch 11/31 - 110.8ms/batch - loss: 23.05297 - diff: 15.91mlTrain batch 12/31 - 109.3ms/batch - loss: 24.82956 - diff: 16.10mlTrain batch 13/31 - 111.7ms/batch - loss: 23.72039 - diff: 15.65mlTrain batch 14/31 - 109.9ms/batch - loss: 22.82261 - diff: 15.23mlTrain batch 15/31 - 110.2ms/batch - loss: 21.58280 - diff: 14.63mlTrain batch 16/31 - 109.4ms/batch - loss: 21.69707 - diff: 14.75mlTrain batch 17/31 - 114.1ms/batch - loss: 21.37018 - diff: 14.68mlTrain batch 18/31 - 108.9ms/batch - loss: 21.09251 - diff: 14.49mlTrain batch 19/31 - 109.2ms/batch - loss: 20.52995 - diff: 14.29mlTrain batch 20/31 - 108.8ms/batch - loss: 19.86145 - diff: 14.04mlTrain batch 21/31 - 109.1ms/batch - loss: 19.37847 - diff: 13.88mlTrain batch 22/31 - 108.9ms/batch - loss: 18.75686 - diff: 13.59mlTrain batch 23/31 - 109.2ms/batch - loss: 19.03971 - diff: 13.76mlTrain batch 24/31 - 109.0ms/batch - loss: 19.59697 - diff: 13.97mlTrain batch 25/31 - 109.3ms/batch - loss: 19.71209 - diff: 14.05mlTrain batch 26/31 - 109.2ms/batch - loss: 20.82611 - diff: 14.45mlTrain batch 27/31 - 110.4ms/batch - loss: 20.28682 - diff: 14.21mlTrain batch 28/31 - 108.9ms/batch - loss: 20.14764 - diff: 14.17mlTrain batch 29/31 - 108.8ms/batch - loss: 19.58483 - diff: 13.91mlTrain batch 30/31 - 108.6ms/batch - loss: 20.42329 - diff: 14.24mlTrain batch 31/31 - 67.6ms/batch - loss: 21.47243 - diff: 14.35mlTrain batch 31/31 - 9.7s 67.6ms/batch - loss: 21.47243 - diff: 14.35ml
Test 0.8s: val_loss: 37.52210 - diff: 17.85ml

Traceback (most recent call last):
  File "train.py", line 266, in <module>
    plot_results(train_losses, test_losses, title=f"Loss {target_label}", save_as=exp_name + "_loss")
  File "/home/allochi/tfm/workspace/lib/utils.py", line 393, in plot_results
    plt.plot(train_values, "r", label="train")
  File "/home/allochi/.conda/envs/DL_env/lib/python3.8/site-packages/matplotlib/pyplot.py", line 2761, in plot
    return gca().plot(
  File "/home/allochi/.conda/envs/DL_env/lib/python3.8/site-packages/matplotlib/pyplot.py", line 879, in gca
    return gcf().gca(**kwargs)
  File "/home/allochi/.conda/envs/DL_env/lib/python3.8/site-packages/matplotlib/pyplot.py", line 611, in gcf
    return figure()
  File "/home/allochi/.conda/envs/DL_env/lib/python3.8/site-packages/matplotlib/pyplot.py", line 540, in figure
    figManager = new_figure_manager(num, figsize=figsize,
  File "/home/allochi/.conda/envs/DL_env/lib/python3.8/site-packages/matplotlib/backend_bases.py", line 3358, in new_figure_manager
    return cls.new_figure_manager_given_figure(num, fig)
  File "/home/allochi/.conda/envs/DL_env/lib/python3.8/site-packages/matplotlib/backends/_backend_tk.py", line 888, in new_figure_manager_given_figure
    window = tk.Tk(className="matplotlib")
  File "/home/allochi/.conda/envs/DL_env/lib/python3.8/tkinter/__init__.py", line 2261, in __init__
    self.tk = _tkinter.create(screenName, baseName, className, interactive, wantobjects, useTk, sync, use)
_tkinter.TclError: couldn't connect to display "localhost:10.0"
