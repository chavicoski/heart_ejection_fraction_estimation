nohup: ignoring input
Running experiment 4CH_preproc1_150x150_bySlices_dataset_allViews_Systole_TimeAsDepth_1_Adam-0.001_MSE_DA3
Going to train with the GPU in the slot 0 -> device model: GeForce RTX 2080
Model architecture:
 TimeAsDepth_1(
  (conv_block): Sequential(
    (0): Conv2d(30, 64, kernel_size=(3, 3), stride=(2, 2))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))
    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU()
    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (7): Dropout(p=0.4, inplace=False)
    (8): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))
    (9): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): ReLU()
    (11): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))
    (12): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (13): ReLU()
    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (15): Dropout(p=0.4, inplace=False)
    (16): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))
    (17): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): ReLU()
    (19): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))
    (20): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (21): ReLU()
    (22): Dropout(p=0.4, inplace=False)
    (23): AdaptiveAvgPool2d(output_size=(1, 1))
  )
  (flatten): Flatten()
  (dense_block): Sequential(
    (0): Linear(in_features=256, out_features=1024, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.4, inplace=False)
    (3): Linear(in_features=1024, out_features=1, bias=True)
  )
) 


############################
# TRAIN PHASE:  100 epochs #
############################

Epoch 0: 
Train batch 1/4 - 153.1ms/batch - loss: 59.73336 - diff: 71.25mlTrain batch 2/4 - 145.3ms/batch - loss: 55.15860 - diff: 70.28mlTrain batch 3/4 - 147.5ms/batch - loss: 54.35226 - diff: 71.11mlTrain batch 4/4 - 117.0ms/batch - loss: 54.87953 - diff: 70.03mlTrain batch 4/4 - 10.7s 117.0ms/batch - loss: 54.87953 - diff: 70.03ml
Test 0.6s: val_loss: 58.05973 - diff: 65.73ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Systole_TimeAsDepth_1_Adam-0.001_MSE_DA3_best

Epoch 1: current best loss = 58.05973, at epoch 0
Train batch 1/4 - 151.8ms/batch - loss: 63.30644 - diff: 71.46mlTrain batch 2/4 - 144.0ms/batch - loss: 57.31432 - diff: 70.77mlTrain batch 3/4 - 149.8ms/batch - loss: 50.95486 - diff: 67.54mlTrain batch 4/4 - 117.0ms/batch - loss: 49.68815 - diff: 65.63mlTrain batch 4/4 - 10.6s 117.0ms/batch - loss: 49.68815 - diff: 65.63ml
Test 0.6s: val_loss: 42.51201 - diff: 53.41ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Systole_TimeAsDepth_1_Adam-0.001_MSE_DA3_best

Epoch 2: current best loss = 42.51201, at epoch 1
Train batch 1/4 - 147.8ms/batch - loss: 45.67301 - diff: 64.94mlTrain batch 2/4 - 144.0ms/batch - loss: 47.99441 - diff: 62.76mlTrain batch 3/4 - 148.4ms/batch - loss: 42.87235 - diff: 59.89mlTrain batch 4/4 - 118.6ms/batch - loss: 43.02495 - diff: 59.22mlTrain batch 4/4 - 10.6s 118.6ms/batch - loss: 43.02495 - diff: 59.22ml
Test 0.6s: val_loss: 26.70988 - diff: 40.79ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Systole_TimeAsDepth_1_Adam-0.001_MSE_DA3_best

Epoch 3: current best loss = 26.70988, at epoch 2
Train batch 1/4 - 151.8ms/batch - loss: 33.49872 - diff: 54.05mlTrain batch 2/4 - 146.6ms/batch - loss: 28.90768 - diff: 50.68mlTrain batch 3/4 - 152.3ms/batch - loss: 33.39531 - diff: 50.88mlTrain batch 4/4 - 118.5ms/batch - loss: 35.00938 - diff: 50.66mlTrain batch 4/4 - 10.7s 118.5ms/batch - loss: 35.00938 - diff: 50.66ml
Test 0.6s: val_loss: 13.33441 - diff: 25.17ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Systole_TimeAsDepth_1_Adam-0.001_MSE_DA3_best

Epoch 4: current best loss = 13.33441, at epoch 3
Train batch 1/4 - 149.4ms/batch - loss: 29.98509 - diff: 48.72mlTrain batch 2/4 - 143.9ms/batch - loss: 31.70438 - diff: 45.46mlTrain batch 3/4 - 145.7ms/batch - loss: 26.92124 - diff: 41.90mlTrain batch 4/4 - 118.1ms/batch - loss: 26.30845 - diff: 40.59mlTrain batch 4/4 - 10.7s 118.1ms/batch - loss: 26.30845 - diff: 40.59ml
Test 0.6s: val_loss: 27.69388 - diff: 45.97ml

Epoch 5: current best loss = 13.33441, at epoch 3
Train batch 1/4 - 148.4ms/batch - loss: 18.89212 - diff: 32.57mlTrain batch 2/4 - 147.1ms/batch - loss: 16.89162 - diff: 31.32mlTrain batch 3/4 - 152.1ms/batch - loss: 16.19944 - diff: 30.96mlTrain batch 4/4 - 122.6ms/batch - loss: 18.81562 - diff: 30.20mlTrain batch 4/4 - 10.7s 122.6ms/batch - loss: 18.81562 - diff: 30.20ml
Test 0.6s: val_loss: 18.35200 - diff: 32.16ml

Epoch 6: current best loss = 13.33441, at epoch 3
Train batch 1/4 - 150.4ms/batch - loss: 11.65437 - diff: 24.06mlTrain batch 2/4 - 145.6ms/batch - loss: 9.77317 - diff: 23.16mlTrain batch 3/4 - 152.0ms/batch - loss: 13.25031 - diff: 24.97mlTrain batch 4/4 - 119.7ms/batch - loss: 13.67436 - diff: 25.17mlTrain batch 4/4 - 10.7s 119.7ms/batch - loss: 13.67436 - diff: 25.17ml
Test 0.6s: val_loss: 12.30662 - diff: 23.65ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Systole_TimeAsDepth_1_Adam-0.001_MSE_DA3_best

Epoch 7: current best loss = 12.30662, at epoch 6
Train batch 1/4 - 152.0ms/batch - loss: 7.27206 - diff: 21.30mlTrain batch 2/4 - 142.4ms/batch - loss: 7.90167 - diff: 22.42mlTrain batch 3/4 - 150.8ms/batch - loss: 11.03874 - diff: 24.68mlTrain batch 4/4 - 118.6ms/batch - loss: 11.36577 - diff: 24.53mlTrain batch 4/4 - 10.7s 118.6ms/batch - loss: 11.36577 - diff: 24.53ml
Test 0.6s: val_loss: 16.59975 - diff: 30.29ml

Epoch 8: current best loss = 12.30662, at epoch 6
Train batch 1/4 - 151.7ms/batch - loss: 10.42584 - diff: 27.13mlTrain batch 2/4 - 144.0ms/batch - loss: 9.55713 - diff: 26.37mlTrain batch 3/4 - 147.6ms/batch - loss: 12.14207 - diff: 28.15mlTrain batch 4/4 - 117.2ms/batch - loss: 12.68952 - diff: 28.05mlTrain batch 4/4 - 10.6s 117.2ms/batch - loss: 12.68952 - diff: 28.05ml
Test 0.6s: val_loss: 26.35372 - diff: 41.61ml

Epoch 9: current best loss = 12.30662, at epoch 6
Train batch 1/4 - 151.9ms/batch - loss: 10.40939 - diff: 28.50mlTrain batch 2/4 - 144.1ms/batch - loss: 14.36309 - diff: 30.29mlTrain batch 3/4 - 147.5ms/batch - loss: 12.47038 - diff: 29.57mlTrain batch 4/4 - 117.3ms/batch - loss: 12.35031 - diff: 29.18mlTrain batch 4/4 - 10.6s 117.3ms/batch - loss: 12.35031 - diff: 29.18ml
Test 0.6s: val_loss: 29.41654 - diff: 41.65ml

Epoch 10: current best loss = 12.30662, at epoch 6
Train batch 1/4 - 147.6ms/batch - loss: 8.43432 - diff: 25.04mlTrain batch 2/4 - 147.8ms/batch - loss: 11.88171 - diff: 26.57mlTrain batch 3/4 - 152.0ms/batch - loss: 10.59582 - diff: 26.43mlTrain batch 4/4 - 124.8ms/batch - loss: 11.13006 - diff: 26.64mlTrain batch 4/4 - 10.7s 124.8ms/batch - loss: 11.13006 - diff: 26.64ml
Test 0.6s: val_loss: 30.05416 - diff: 48.57ml

Epoch 11: current best loss = 12.30662, at epoch 6
Train batch 1/4 - 151.9ms/batch - loss: 9.59397 - diff: 25.85mlTrain batch 2/4 - 142.5ms/batch - loss: 7.76608 - diff: 24.00mlTrain batch 3/4 - 152.0ms/batch - loss: 9.83852 - diff: 24.52mlTrain batch 4/4 - 122.7ms/batch - loss: 10.24433 - diff: 24.55mlTrain batch 4/4 - 10.6s 122.7ms/batch - loss: 10.24433 - diff: 24.55ml
Test 0.6s: val_loss: 20.95806 - diff: 34.12ml

Epoch 12: current best loss = 12.30662, at epoch 6
Train batch 1/4 - 150.2ms/batch - loss: 11.84686 - diff: 21.77mlTrain batch 2/4 - 144.2ms/batch - loss: 11.05903 - diff: 23.82mlTrain batch 3/4 - 150.4ms/batch - loss: 9.29146 - diff: 22.92mlTrain batch 4/4 - 123.3ms/batch - loss: 9.84954 - diff: 23.01mlTrain batch 4/4 - 10.6s 123.3ms/batch - loss: 9.84954 - diff: 23.01ml
Test 0.6s: val_loss: 16.59150 - diff: 35.08ml

Epoch 13: current best loss = 12.30662, at epoch 6
Train batch 1/4 - 150.8ms/batch - loss: 6.31050 - diff: 20.48mlTrain batch 2/4 - 144.0ms/batch - loss: 12.51939 - diff: 24.57mlTrain batch 3/4 - 152.2ms/batch - loss: 10.55051 - diff: 23.41mlTrain batch 4/4 - 121.8ms/batch - loss: 10.10084 - diff: 22.80mlTrain batch 4/4 - 10.6s 121.8ms/batch - loss: 10.10084 - diff: 22.80ml
Test 0.6s: val_loss: 13.78662 - diff: 25.12ml

Epoch 14: current best loss = 12.30662, at epoch 6
Train batch 1/4 - 148.9ms/batch - loss: 5.66512 - diff: 19.14mlTrain batch 2/4 - 144.2ms/batch - loss: 8.31711 - diff: 22.16mlTrain batch 3/4 - 151.9ms/batch - loss: 7.68687 - diff: 22.02mlTrain batch 4/4 - 121.6ms/batch - loss: 10.32524 - diff: 22.52mlTrain batch 4/4 - 10.6s 121.6ms/batch - loss: 10.32524 - diff: 22.52ml
Test 0.6s: val_loss: 12.13815 - diff: 24.08ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Systole_TimeAsDepth_1_Adam-0.001_MSE_DA3_best

Epoch 15: current best loss = 12.13815, at epoch 14
Train batch 1/4 - 147.0ms/batch - loss: 7.01461 - diff: 21.38mlTrain batch 2/4 - 142.4ms/batch - loss: 7.32766 - diff: 21.65mlTrain batch 3/4 - 151.9ms/batch - loss: 10.27077 - diff: 23.01mlTrain batch 4/4 - 120.4ms/batch - loss: 9.83780 - diff: 22.63mlTrain batch 4/4 - 10.6s 120.4ms/batch - loss: 9.83780 - diff: 22.63ml
Test 0.6s: val_loss: 10.64729 - diff: 22.96ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Systole_TimeAsDepth_1_Adam-0.001_MSE_DA3_best

Epoch 16: current best loss = 10.64729, at epoch 15
Train batch 1/4 - 151.9ms/batch - loss: 8.55213 - diff: 24.26mlTrain batch 2/4 - 148.4ms/batch - loss: 7.28582 - diff: 22.11mlTrain batch 3/4 - 150.4ms/batch - loss: 9.47163 - diff: 23.16mlTrain batch 4/4 - 117.5ms/batch - loss: 9.61298 - diff: 22.97mlTrain batch 4/4 - 10.6s 117.5ms/batch - loss: 9.61298 - diff: 22.97ml
Test 0.6s: val_loss: 11.68122 - diff: 21.77ml

Epoch 17: current best loss = 10.64729, at epoch 15
Train batch 1/4 - 151.8ms/batch - loss: 8.38797 - diff: 23.18mlTrain batch 2/4 - 149.5ms/batch - loss: 11.29620 - diff: 24.26mlTrain batch 3/4 - 152.2ms/batch - loss: 9.85482 - diff: 23.62mlTrain batch 4/4 - 117.2ms/batch - loss: 9.60686 - diff: 22.98mlTrain batch 4/4 - 10.6s 117.2ms/batch - loss: 9.60686 - diff: 22.98ml
Test 0.6s: val_loss: 12.34546 - diff: 23.24ml

Epoch 18: current best loss = 10.64729, at epoch 15
Train batch 1/4 - 150.5ms/batch - loss: 10.88797 - diff: 21.54mlTrain batch 2/4 - 149.2ms/batch - loss: 10.40883 - diff: 23.39mlTrain batch 3/4 - 152.0ms/batch - loss: 9.78687 - diff: 23.39mlTrain batch 4/4 - 119.3ms/batch - loss: 9.21432 - diff: 22.89mlTrain batch 4/4 - 10.6s 119.3ms/batch - loss: 9.21432 - diff: 22.89ml
Test 0.6s: val_loss: 9.43542 - diff: 21.96ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Systole_TimeAsDepth_1_Adam-0.001_MSE_DA3_best

Epoch 19: current best loss = 9.43542, at epoch 18
Train batch 1/4 - 152.1ms/batch - loss: 6.82248 - diff: 23.08mlTrain batch 2/4 - 142.5ms/batch - loss: 7.16054 - diff: 22.31mlTrain batch 3/4 - 152.0ms/batch - loss: 7.15295 - diff: 22.13mlTrain batch 4/4 - 118.7ms/batch - loss: 9.93600 - diff: 23.47mlTrain batch 4/4 - 10.6s 118.7ms/batch - loss: 9.93600 - diff: 23.47ml
Test 0.6s: val_loss: 9.61414 - diff: 20.27ml

Epoch 20: current best loss = 9.43542, at epoch 18
Train batch 1/4 - 152.0ms/batch - loss: 8.91788 - diff: 20.38mlTrain batch 2/4 - 144.7ms/batch - loss: 7.63309 - diff: 20.44mlTrain batch 3/4 - 146.1ms/batch - loss: 8.78727 - diff: 22.58mlTrain batch 4/4 - 117.5ms/batch - loss: 9.13790 - diff: 22.91mlTrain batch 4/4 - 10.7s 117.5ms/batch - loss: 9.13790 - diff: 22.91ml
Test 0.6s: val_loss: 9.87333 - diff: 22.33ml

Epoch 21: current best loss = 9.43542, at epoch 18
Train batch 1/4 - 148.5ms/batch - loss: 13.07425 - diff: 24.77mlTrain batch 2/4 - 144.2ms/batch - loss: 9.12093 - diff: 22.16mlTrain batch 3/4 - 150.8ms/batch - loss: 8.15834 - diff: 21.67mlTrain batch 4/4 - 117.2ms/batch - loss: 8.32354 - diff: 21.76mlTrain batch 4/4 - 10.6s 117.2ms/batch - loss: 8.32354 - diff: 21.76ml
Test 0.6s: val_loss: 17.00430 - diff: 35.11ml

Epoch 22: current best loss = 9.43542, at epoch 18
Train batch 1/4 - 148.8ms/batch - loss: 8.89945 - diff: 23.50mlTrain batch 2/4 - 144.2ms/batch - loss: 8.11411 - diff: 22.72mlTrain batch 3/4 - 148.8ms/batch - loss: 7.32503 - diff: 22.28mlTrain batch 4/4 - 118.7ms/batch - loss: 9.19259 - diff: 22.51mlTrain batch 4/4 - 10.6s 118.7ms/batch - loss: 9.19259 - diff: 22.51ml
Test 0.6s: val_loss: 10.54904 - diff: 21.01ml

Epoch 23: current best loss = 9.43542, at epoch 18
Train batch 1/4 - 147.5ms/batch - loss: 5.31326 - diff: 19.27mlTrain batch 2/4 - 142.4ms/batch - loss: 8.08559 - diff: 21.27mlTrain batch 3/4 - 147.2ms/batch - loss: 8.79806 - diff: 22.94mlTrain batch 4/4 - 119.1ms/batch - loss: 8.21452 - diff: 22.19mlTrain batch 4/4 - 10.6s 119.1ms/batch - loss: 8.21452 - diff: 22.19ml
Test 0.6s: val_loss: 9.42031 - diff: 22.40ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Systole_TimeAsDepth_1_Adam-0.001_MSE_DA3_best

Epoch 24: current best loss = 9.42031, at epoch 23
Train batch 1/4 - 152.0ms/batch - loss: 7.93792 - diff: 22.57mlTrain batch 2/4 - 146.7ms/batch - loss: 8.85768 - diff: 22.68mlTrain batch 3/4 - 150.3ms/batch - loss: 8.08956 - diff: 22.24mlTrain batch 4/4 - 119.1ms/batch - loss: 8.39325 - diff: 22.37mlTrain batch 4/4 - 10.7s 119.1ms/batch - loss: 8.39325 - diff: 22.37ml
Test 0.6s: val_loss: 10.16667 - diff: 21.25ml

Epoch 25: current best loss = 9.42031, at epoch 23
Train batch 1/4 - 151.9ms/batch - loss: 9.91111 - diff: 21.56mlTrain batch 2/4 - 144.8ms/batch - loss: 7.97738 - diff: 21.08mlTrain batch 3/4 - 152.0ms/batch - loss: 8.85615 - diff: 22.82mlTrain batch 4/4 - 117.4ms/batch - loss: 7.87000 - diff: 21.30mlTrain batch 4/4 - 10.7s 117.4ms/batch - loss: 7.87000 - diff: 21.30ml
Test 0.6s: val_loss: 11.57040 - diff: 23.29ml

Epoch 26: current best loss = 9.42031, at epoch 23
Train batch 1/4 - 150.4ms/batch - loss: 7.86750 - diff: 22.67mlTrain batch 2/4 - 147.2ms/batch - loss: 6.97476 - diff: 21.92mlTrain batch 3/4 - 151.9ms/batch - loss: 7.12086 - diff: 21.99mlTrain batch 4/4 - 118.8ms/batch - loss: 8.53494 - diff: 22.19mlTrain batch 4/4 - 10.6s 118.8ms/batch - loss: 8.53494 - diff: 22.19ml
Test 0.6s: val_loss: 15.90571 - diff: 27.43ml

Epoch 27: current best loss = 9.42031, at epoch 23
Train batch 1/4 - 151.8ms/batch - loss: 9.02076 - diff: 22.32mlTrain batch 2/4 - 144.8ms/batch - loss: 7.16892 - diff: 21.36mlTrain batch 3/4 - 151.9ms/batch - loss: 9.25164 - diff: 23.02mlTrain batch 4/4 - 118.6ms/batch - loss: 9.43232 - diff: 23.42mlTrain batch 4/4 - 10.6s 118.6ms/batch - loss: 9.43232 - diff: 23.42ml
Test 0.6s: val_loss: 10.99205 - diff: 24.69ml

Epoch 28: current best loss = 9.42031, at epoch 23
Train batch 1/4 - 151.2ms/batch - loss: 5.72652 - diff: 20.30mlTrain batch 2/4 - 144.1ms/batch - loss: 5.76078 - diff: 20.46mlTrain batch 3/4 - 150.4ms/batch - loss: 5.94981 - diff: 20.69mlTrain batch 4/4 - 118.7ms/batch - loss: 8.47818 - diff: 21.66mlTrain batch 4/4 - 10.6s 118.7ms/batch - loss: 8.47818 - diff: 21.66ml
Test 0.6s: val_loss: 9.42067 - diff: 24.01ml

Epoch 29: current best loss = 9.42031, at epoch 23
Train batch 1/4 - 151.6ms/batch - loss: 5.54390 - diff: 19.85mlTrain batch 2/4 - 149.7ms/batch - loss: 5.99411 - diff: 20.74mlTrain batch 3/4 - 147.8ms/batch - loss: 8.32651 - diff: 22.36mlTrain batch 4/4 - 118.6ms/batch - loss: 8.48806 - diff: 22.45mlTrain batch 4/4 - 10.5s 118.6ms/batch - loss: 8.48806 - diff: 22.45ml
Test 0.6s: val_loss: 10.99754 - diff: 24.57ml

Epoch 30: current best loss = 9.42031, at epoch 23
Train batch 1/4 - 150.4ms/batch - loss: 8.08742 - diff: 20.57mlTrain batch 2/4 - 144.3ms/batch - loss: 8.14504 - diff: 22.52mlTrain batch 3/4 - 152.1ms/batch - loss: 8.10534 - diff: 22.81mlTrain batch 4/4 - 124.6ms/batch - loss: 9.36486 - diff: 22.39mlTrain batch 4/4 - 10.6s 124.6ms/batch - loss: 9.36486 - diff: 22.39ml
Test 0.6s: val_loss: 9.83153 - diff: 24.79ml

Epoch 31: current best loss = 9.42031, at epoch 23
Train batch 1/4 - 149.7ms/batch - loss: 6.84269 - diff: 21.08mlTrain batch 2/4 - 142.6ms/batch - loss: 8.39142 - diff: 21.13mlTrain batch 3/4 - 152.1ms/batch - loss: 7.94278 - diff: 21.31mlTrain batch 4/4 - 125.3ms/batch - loss: 7.73637 - diff: 21.24mlTrain batch 4/4 - 10.6s 125.3ms/batch - loss: 7.73637 - diff: 21.24ml
Test 0.6s: val_loss: 12.03108 - diff: 27.79ml

Epoch 32: current best loss = 9.42031, at epoch 23
Train batch 1/4 - 152.1ms/batch - loss: 5.90593 - diff: 21.23mlTrain batch 2/4 - 147.4ms/batch - loss: 9.20119 - diff: 22.64mlTrain batch 3/4 - 150.2ms/batch - loss: 8.29628 - diff: 22.03mlTrain batch 4/4 - 119.3ms/batch - loss: 7.92061 - diff: 21.39mlTrain batch 4/4 - 10.7s 119.3ms/batch - loss: 7.92061 - diff: 21.39ml
Test 0.6s: val_loss: 11.81899 - diff: 26.58ml

Epoch 33: current best loss = 9.42031, at epoch 23
Train batch 1/4 - 147.3ms/batch - loss: 6.27387 - diff: 21.66mlTrain batch 2/4 - 144.1ms/batch - loss: 6.71962 - diff: 22.10mlTrain batch 3/4 - 151.9ms/batch - loss: 8.35178 - diff: 22.56mlTrain batch 4/4 - 119.9ms/batch - loss: 7.98414 - diff: 21.98mlTrain batch 4/4 - 10.6s 119.9ms/batch - loss: 7.98414 - diff: 21.98ml
Test 0.6s: val_loss: 9.68110 - diff: 22.80ml

Epoch 34: current best loss = 9.42031, at epoch 23
Train batch 1/4 - 145.8ms/batch - loss: 5.03178 - diff: 19.43mlTrain batch 2/4 - 144.4ms/batch - loss: 5.92392 - diff: 20.29mlTrain batch 3/4 - 151.8ms/batch - loss: 5.83324 - diff: 20.18mlTrain batch 4/4 - 121.4ms/batch - loss: 7.87379 - diff: 21.05mlTrain batch 4/4 - 10.6s 121.4ms/batch - loss: 7.87379 - diff: 21.05ml
Test 0.6s: val_loss: 7.78772 - diff: 19.54ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Systole_TimeAsDepth_1_Adam-0.001_MSE_DA3_best

Epoch 35: current best loss = 7.78772, at epoch 34
Train batch 1/4 - 152.1ms/batch - loss: 10.86718 - diff: 22.74mlTrain batch 2/4 - 146.8ms/batch - loss: 8.25691 - diff: 21.62mlTrain batch 3/4 - 152.0ms/batch - loss: 7.98054 - diff: 21.51mlTrain batch 4/4 - 118.9ms/batch - loss: 11.78157 - diff: 21.87mlTrain batch 4/4 - 10.6s 118.9ms/batch - loss: 11.78157 - diff: 21.87ml
Test 0.6s: val_loss: 10.60712 - diff: 27.30ml

Epoch 36: current best loss = 7.78772, at epoch 34
Train batch 1/4 - 151.9ms/batch - loss: 7.09558 - diff: 22.88mlTrain batch 2/4 - 144.3ms/batch - loss: 8.63164 - diff: 22.57mlTrain batch 3/4 - 150.3ms/batch - loss: 7.89150 - diff: 21.95mlTrain batch 4/4 - 117.7ms/batch - loss: 9.36291 - diff: 22.29mlTrain batch 4/4 - 10.7s 117.7ms/batch - loss: 9.36291 - diff: 22.29ml
Test 0.6s: val_loss: 9.64279 - diff: 21.12ml

Epoch 37: current best loss = 7.78772, at epoch 34
Train batch 1/4 - 151.7ms/batch - loss: 9.08273 - diff: 23.83mlTrain batch 2/4 - 144.4ms/batch - loss: 7.28036 - diff: 21.65mlTrain batch 3/4 - 148.3ms/batch - loss: 8.17659 - diff: 21.45mlTrain batch 4/4 - 117.4ms/batch - loss: 8.98495 - diff: 21.13mlTrain batch 4/4 - 10.7s 117.4ms/batch - loss: 8.98495 - diff: 21.13ml
Test 0.6s: val_loss: 14.36788 - diff: 26.27ml

Epoch 38: current best loss = 7.78772, at epoch 34
Train batch 1/4 - 147.1ms/batch - loss: 5.66668 - diff: 20.68mlTrain batch 2/4 - 147.2ms/batch - loss: 6.45063 - diff: 21.02mlTrain batch 3/4 - 148.2ms/batch - loss: 9.42336 - diff: 21.92mlTrain batch 4/4 - 121.1ms/batch - loss: 9.12697 - diff: 21.79mlTrain batch 4/4 - 10.7s 121.1ms/batch - loss: 9.12697 - diff: 21.79ml
Test 0.6s: val_loss: 15.58554 - diff: 28.15ml

Epoch 39: current best loss = 7.78772, at epoch 34
Train batch 1/4 - 151.8ms/batch - loss: 6.30550 - diff: 21.59mlTrain batch 2/4 - 145.5ms/batch - loss: 9.04620 - diff: 21.80mlTrain batch 3/4 - 152.1ms/batch - loss: 8.11994 - diff: 21.33mlTrain batch 4/4 - 120.1ms/batch - loss: 9.13815 - diff: 21.81mlTrain batch 4/4 - 10.7s 120.1ms/batch - loss: 9.13815 - diff: 21.81ml
Test 0.6s: val_loss: 10.73653 - diff: 21.36ml

Epoch 40: current best loss = 7.78772, at epoch 34
Train batch 1/4 - 151.8ms/batch - loss: 16.80302 - diff: 27.86mlTrain batch 2/4 - 149.3ms/batch - loss: 11.55322 - diff: 24.64mlTrain batch 3/4 - 150.3ms/batch - loss: 9.64609 - diff: 23.13mlTrain batch 4/4 - 123.0ms/batch - loss: 8.95201 - diff: 22.48mlTrain batch 4/4 - 10.6s 123.0ms/batch - loss: 8.95201 - diff: 22.48ml
Test 0.6s: val_loss: 8.19150 - diff: 19.83ml

Epoch 41: current best loss = 7.78772, at epoch 34
Train batch 1/4 - 148.2ms/batch - loss: 14.21288 - diff: 23.59mlTrain batch 2/4 - 144.3ms/batch - loss: 9.89797 - diff: 21.91mlTrain batch 3/4 - 152.0ms/batch - loss: 8.56152 - diff: 21.68mlTrain batch 4/4 - 120.7ms/batch - loss: 8.41709 - diff: 21.68mlTrain batch 4/4 - 10.6s 120.7ms/batch - loss: 8.41709 - diff: 21.68ml
Test 0.6s: val_loss: 8.68700 - diff: 18.99ml

Epoch 42: current best loss = 7.78772, at epoch 34
Train batch 1/4 - 146.4ms/batch - loss: 5.52493 - diff: 20.33mlTrain batch 2/4 - 144.4ms/batch - loss: 6.25646 - diff: 20.85mlTrain batch 3/4 - 151.7ms/batch - loss: 6.34194 - diff: 20.68mlTrain batch 4/4 - 123.2ms/batch - loss: 8.50027 - diff: 21.55mlTrain batch 4/4 - 10.6s 123.2ms/batch - loss: 8.50027 - diff: 21.55ml
Test 0.6s: val_loss: 8.71698 - diff: 19.70ml

Epoch 43: current best loss = 7.78772, at epoch 34
Train batch 1/4 - 151.7ms/batch - loss: 5.76062 - diff: 19.38mlTrain batch 2/4 - 143.9ms/batch - loss: 6.47666 - diff: 20.60mlTrain batch 3/4 - 152.0ms/batch - loss: 6.14456 - diff: 20.32mlTrain batch 4/4 - 120.3ms/batch - loss: 7.76668 - diff: 20.70mlTrain batch 4/4 - 10.6s 120.3ms/batch - loss: 7.76668 - diff: 20.70ml
Test 0.6s: val_loss: 9.90444 - diff: 20.89ml

Epoch 44: current best loss = 7.78772, at epoch 34
Train batch 1/4 - 151.8ms/batch - loss: 8.82287 - diff: 21.03mlTrain batch 2/4 - 144.3ms/batch - loss: 7.91129 - diff: 21.13mlTrain batch 3/4 - 150.5ms/batch - loss: 7.19622 - diff: 20.69mlTrain batch 4/4 - 118.4ms/batch - loss: 7.33243 - diff: 20.25mlTrain batch 4/4 - 10.6s 118.4ms/batch - loss: 7.33243 - diff: 20.25ml
Test 0.6s: val_loss: 8.51137 - diff: 19.42ml

Epoch 45: current best loss = 7.78772, at epoch 34
Train batch 1/4 - 151.9ms/batch - loss: 5.46287 - diff: 19.26mlTrain batch 2/4 - 147.5ms/batch - loss: 5.46528 - diff: 19.29mlTrain batch 3/4 - 152.0ms/batch - loss: 7.55335 - diff: 21.08mlTrain batch 4/4 - 123.9ms/batch - loss: 7.67102 - diff: 20.78mlTrain batch 4/4 - 10.6s 123.9ms/batch - loss: 7.67102 - diff: 20.78ml
Test 0.6s: val_loss: 10.52386 - diff: 21.04ml
Epoch    46: reducing learning rate of group 0 to 5.0000e-04.

Epoch 46: current best loss = 7.78772, at epoch 34
Train batch 1/4 - 145.7ms/batch - loss: 7.12775 - diff: 20.84mlTrain batch 2/4 - 144.3ms/batch - loss: 7.06575 - diff: 19.48mlTrain batch 3/4 - 146.9ms/batch - loss: 7.05237 - diff: 20.32mlTrain batch 4/4 - 119.1ms/batch - loss: 7.26191 - diff: 20.55mlTrain batch 4/4 - 10.6s 119.1ms/batch - loss: 7.26191 - diff: 20.55ml
Test 0.6s: val_loss: 8.70391 - diff: 20.29ml

Epoch 47: current best loss = 7.78772, at epoch 34
Train batch 1/4 - 147.0ms/batch - loss: 11.02151 - diff: 25.21mlTrain batch 2/4 - 142.8ms/batch - loss: 8.30165 - diff: 21.95mlTrain batch 3/4 - 151.8ms/batch - loss: 7.32561 - diff: 21.45mlTrain batch 4/4 - 122.7ms/batch - loss: 7.01654 - diff: 20.79mlTrain batch 4/4 - 10.7s 122.7ms/batch - loss: 7.01654 - diff: 20.79ml
Test 0.6s: val_loss: 7.62783 - diff: 19.90ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Systole_TimeAsDepth_1_Adam-0.001_MSE_DA3_best

Epoch 48: current best loss = 7.62783, at epoch 47
Train batch 1/4 - 152.0ms/batch - loss: 6.43577 - diff: 22.01mlTrain batch 2/4 - 145.1ms/batch - loss: 6.31423 - diff: 21.13mlTrain batch 3/4 - 150.2ms/batch - loss: 5.74685 - diff: 20.18mlTrain batch 4/4 - 117.8ms/batch - loss: 7.12811 - diff: 20.56mlTrain batch 4/4 - 10.7s 117.8ms/batch - loss: 7.12811 - diff: 20.56ml
Test 0.6s: val_loss: 8.23334 - diff: 19.94ml

Epoch 49: current best loss = 7.62783, at epoch 47
Train batch 1/4 - 152.0ms/batch - loss: 6.23186 - diff: 21.24mlTrain batch 2/4 - 144.5ms/batch - loss: 5.86665 - diff: 20.64mlTrain batch 3/4 - 149.6ms/batch - loss: 5.80053 - diff: 20.56mlTrain batch 4/4 - 117.4ms/batch - loss: 6.86682 - diff: 20.25mlTrain batch 4/4 - 10.6s 117.4ms/batch - loss: 6.86682 - diff: 20.25ml
Test 0.7s: val_loss: 8.14465 - diff: 19.74ml

Epoch 50: current best loss = 7.62783, at epoch 47
Train batch 1/4 - 150.5ms/batch - loss: 7.97172 - diff: 21.12mlTrain batch 2/4 - 148.1ms/batch - loss: 7.26163 - diff: 21.03mlTrain batch 3/4 - 147.3ms/batch - loss: 6.35975 - diff: 20.03mlTrain batch 4/4 - 118.8ms/batch - loss: 6.61367 - diff: 19.83mlTrain batch 4/4 - 10.6s 118.8ms/batch - loss: 6.61367 - diff: 19.83ml
Test 0.6s: val_loss: 7.92652 - diff: 19.11ml

Epoch 51: current best loss = 7.62783, at epoch 47
Train batch 1/4 - 152.0ms/batch - loss: 6.36493 - diff: 19.66mlTrain batch 2/4 - 146.8ms/batch - loss: 6.03678 - diff: 19.40mlTrain batch 3/4 - 149.1ms/batch - loss: 5.91247 - diff: 19.89mlTrain batch 4/4 - 118.8ms/batch - loss: 7.00748 - diff: 20.21mlTrain batch 4/4 - 10.6s 118.8ms/batch - loss: 7.00748 - diff: 20.21ml
Test 0.6s: val_loss: 7.85051 - diff: 19.19ml

Epoch 52: current best loss = 7.62783, at epoch 47
Train batch 1/4 - 151.8ms/batch - loss: 6.02963 - diff: 19.94mlTrain batch 2/4 - 144.4ms/batch - loss: 6.11880 - diff: 19.41mlTrain batch 3/4 - 150.3ms/batch - loss: 5.67593 - diff: 19.07mlTrain batch 4/4 - 117.6ms/batch - loss: 5.93688 - diff: 19.16mlTrain batch 4/4 - 10.5s 117.6ms/batch - loss: 5.93688 - diff: 19.16ml
Test 0.7s: val_loss: 8.22801 - diff: 19.01ml

Epoch 53: current best loss = 7.62783, at epoch 47
Train batch 1/4 - 151.9ms/batch - loss: 5.88018 - diff: 19.86mlTrain batch 2/4 - 144.5ms/batch - loss: 6.48427 - diff: 19.86mlTrain batch 3/4 - 148.4ms/batch - loss: 6.46227 - diff: 19.97mlTrain batch 4/4 - 117.4ms/batch - loss: 6.68353 - diff: 20.06mlTrain batch 4/4 - 10.6s 117.4ms/batch - loss: 6.68353 - diff: 20.06ml
Test 0.6s: val_loss: 8.66385 - diff: 20.72ml

Epoch 54: current best loss = 7.62783, at epoch 47
Train batch 1/4 - 146.9ms/batch - loss: 5.74904 - diff: 19.96mlTrain batch 2/4 - 144.5ms/batch - loss: 6.89576 - diff: 20.06mlTrain batch 3/4 - 150.3ms/batch - loss: 5.93285 - diff: 19.33mlTrain batch 4/4 - 118.9ms/batch - loss: 6.60641 - diff: 19.61mlTrain batch 4/4 - 10.6s 118.9ms/batch - loss: 6.60641 - diff: 19.61ml
Test 0.6s: val_loss: 7.52604 - diff: 20.54ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Systole_TimeAsDepth_1_Adam-0.001_MSE_DA3_best

Epoch 55: current best loss = 7.52604, at epoch 54
Train batch 1/4 - 151.9ms/batch - loss: 5.07020 - diff: 19.49mlTrain batch 2/4 - 145.8ms/batch - loss: 5.02564 - diff: 19.01mlTrain batch 3/4 - 151.7ms/batch - loss: 6.66820 - diff: 20.56mlTrain batch 4/4 - 123.3ms/batch - loss: 6.40229 - diff: 20.11mlTrain batch 4/4 - 10.7s 123.3ms/batch - loss: 6.40229 - diff: 20.11ml
Test 0.6s: val_loss: 8.06420 - diff: 18.99ml

Epoch 56: current best loss = 7.52604, at epoch 54
Train batch 1/4 - 152.1ms/batch - loss: 3.51695 - diff: 17.23mlTrain batch 2/4 - 147.2ms/batch - loss: 4.79812 - diff: 18.22mlTrain batch 3/4 - 150.5ms/batch - loss: 4.92017 - diff: 18.14mlTrain batch 4/4 - 120.9ms/batch - loss: 6.38168 - diff: 18.93mlTrain batch 4/4 - 10.6s 120.9ms/batch - loss: 6.38168 - diff: 18.93ml
Test 0.6s: val_loss: 7.28649 - diff: 19.63ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Systole_TimeAsDepth_1_Adam-0.001_MSE_DA3_best

Epoch 57: current best loss = 7.28649, at epoch 56
Train batch 1/4 - 151.6ms/batch - loss: 7.33207 - diff: 17.61mlTrain batch 2/4 - 145.3ms/batch - loss: 6.60057 - diff: 18.91mlTrain batch 3/4 - 151.9ms/batch - loss: 5.71243 - diff: 18.33mlTrain batch 4/4 - 117.5ms/batch - loss: 6.11537 - diff: 18.85mlTrain batch 4/4 - 10.6s 117.5ms/batch - loss: 6.11537 - diff: 18.85ml
Test 0.6s: val_loss: 8.32908 - diff: 19.69ml

Epoch 58: current best loss = 7.28649, at epoch 56
Train batch 1/4 - 150.5ms/batch - loss: 4.74387 - diff: 19.79mlTrain batch 2/4 - 144.4ms/batch - loss: 4.58801 - diff: 19.01mlTrain batch 3/4 - 149.9ms/batch - loss: 4.70344 - diff: 18.86mlTrain batch 4/4 - 118.9ms/batch - loss: 6.06519 - diff: 19.70mlTrain batch 4/4 - 10.6s 118.9ms/batch - loss: 6.06519 - diff: 19.70ml
Test 0.6s: val_loss: 7.81352 - diff: 18.71ml

Epoch 59: current best loss = 7.28649, at epoch 56
Train batch 1/4 - 147.9ms/batch - loss: 5.42203 - diff: 19.98mlTrain batch 2/4 - 144.5ms/batch - loss: 6.78133 - diff: 20.22mlTrain batch 3/4 - 151.8ms/batch - loss: 6.40647 - diff: 20.25mlTrain batch 4/4 - 118.8ms/batch - loss: 5.90265 - diff: 19.33mlTrain batch 4/4 - 10.6s 118.8ms/batch - loss: 5.90265 - diff: 19.33ml
Test 0.6s: val_loss: 7.93701 - diff: 18.87ml

Epoch 60: current best loss = 7.28649, at epoch 56
Train batch 1/4 - 148.3ms/batch - loss: 7.47493 - diff: 19.37mlTrain batch 2/4 - 144.4ms/batch - loss: 6.53890 - diff: 20.01mlTrain batch 3/4 - 150.5ms/batch - loss: 6.49508 - diff: 20.04mlTrain batch 4/4 - 117.6ms/batch - loss: 5.98835 - diff: 19.01mlTrain batch 4/4 - 10.6s 117.6ms/batch - loss: 5.98835 - diff: 19.01ml
Test 0.6s: val_loss: 7.77854 - diff: 19.76ml

Epoch 61: current best loss = 7.28649, at epoch 56
Train batch 1/4 - 151.2ms/batch - loss: 4.67306 - diff: 17.51mlTrain batch 2/4 - 144.4ms/batch - loss: 5.40408 - diff: 18.00mlTrain batch 3/4 - 149.4ms/batch - loss: 5.58283 - diff: 18.94mlTrain batch 4/4 - 117.4ms/batch - loss: 5.61603 - diff: 18.84mlTrain batch 4/4 - 10.6s 117.4ms/batch - loss: 5.61603 - diff: 18.84ml
Test 0.6s: val_loss: 7.85881 - diff: 20.68ml

Epoch 62: current best loss = 7.28649, at epoch 56
Train batch 1/4 - 150.4ms/batch - loss: 4.90534 - diff: 19.35mlTrain batch 2/4 - 144.5ms/batch - loss: 5.11347 - diff: 18.90mlTrain batch 3/4 - 151.9ms/batch - loss: 5.31815 - diff: 19.26mlTrain batch 4/4 - 119.1ms/batch - loss: 5.92717 - diff: 19.29mlTrain batch 4/4 - 10.6s 119.1ms/batch - loss: 5.92717 - diff: 19.29ml
Test 0.6s: val_loss: 8.53679 - diff: 20.33ml

Epoch 63: current best loss = 7.28649, at epoch 56
Train batch 1/4 - 148.9ms/batch - loss: 5.15485 - diff: 18.55mlTrain batch 2/4 - 146.2ms/batch - loss: 6.34081 - diff: 19.02mlTrain batch 3/4 - 147.8ms/batch - loss: 5.83947 - diff: 19.05mlTrain batch 4/4 - 118.8ms/batch - loss: 5.79483 - diff: 19.08mlTrain batch 4/4 - 10.6s 118.8ms/batch - loss: 5.79483 - diff: 19.08ml
Test 0.6s: val_loss: 7.99691 - diff: 20.12ml

Epoch 64: current best loss = 7.28649, at epoch 56
Train batch 1/4 - 151.9ms/batch - loss: 4.68980 - diff: 17.77mlTrain batch 2/4 - 148.3ms/batch - loss: 5.25007 - diff: 18.86mlTrain batch 3/4 - 148.9ms/batch - loss: 5.73248 - diff: 19.15mlTrain batch 4/4 - 117.5ms/batch - loss: 5.54491 - diff: 18.97mlTrain batch 4/4 - 10.6s 117.5ms/batch - loss: 5.54491 - diff: 18.97ml
Test 0.6s: val_loss: 9.73752 - diff: 22.25ml

Epoch 65: current best loss = 7.28649, at epoch 56
Train batch 1/4 - 150.5ms/batch - loss: 4.22829 - diff: 16.76mlTrain batch 2/4 - 144.5ms/batch - loss: 5.42573 - diff: 17.84mlTrain batch 3/4 - 149.0ms/batch - loss: 5.24730 - diff: 18.41mlTrain batch 4/4 - 117.3ms/batch - loss: 5.69394 - diff: 18.81mlTrain batch 4/4 - 10.6s 117.3ms/batch - loss: 5.69394 - diff: 18.81ml
Test 0.6s: val_loss: 9.11486 - diff: 22.94ml

Epoch 66: current best loss = 7.28649, at epoch 56
Train batch 1/4 - 146.2ms/batch - loss: 6.66050 - diff: 20.39mlTrain batch 2/4 - 145.6ms/batch - loss: 5.61685 - diff: 19.48mlTrain batch 3/4 - 151.9ms/batch - loss: 5.88131 - diff: 19.96mlTrain batch 4/4 - 125.3ms/batch - loss: 5.54489 - diff: 19.17mlTrain batch 4/4 - 10.6s 125.3ms/batch - loss: 5.54489 - diff: 19.17ml
Test 0.6s: val_loss: 8.60438 - diff: 20.82ml

Epoch 67: current best loss = 7.28649, at epoch 56
Train batch 1/4 - 151.7ms/batch - loss: 3.85784 - diff: 16.41mlTrain batch 2/4 - 144.0ms/batch - loss: 4.68742 - diff: 18.30mlTrain batch 3/4 - 151.9ms/batch - loss: 5.41427 - diff: 19.21mlTrain batch 4/4 - 122.9ms/batch - loss: 6.21325 - diff: 18.88mlTrain batch 4/4 - 10.6s 122.9ms/batch - loss: 6.21325 - diff: 18.88ml
Test 0.6s: val_loss: 7.85172 - diff: 20.55ml
Epoch    68: reducing learning rate of group 0 to 2.5000e-04.

Epoch 68: current best loss = 7.28649, at epoch 56
Train batch 1/4 - 147.0ms/batch - loss: 3.97324 - diff: 18.14mlTrain batch 2/4 - 144.9ms/batch - loss: 4.61499 - diff: 18.51mlTrain batch 3/4 - 150.4ms/batch - loss: 5.05088 - diff: 18.82mlTrain batch 4/4 - 119.6ms/batch - loss: 6.04338 - diff: 18.94mlTrain batch 4/4 - 10.6s 119.6ms/batch - loss: 6.04338 - diff: 18.94ml
Test 0.6s: val_loss: 8.24588 - diff: 20.48ml

Epoch 69: current best loss = 7.28649, at epoch 56
Train batch 1/4 - 151.8ms/batch - loss: 4.10069 - diff: 16.90mlTrain batch 2/4 - 147.9ms/batch - loss: 5.36602 - diff: 18.15mlTrain batch 3/4 - 151.9ms/batch - loss: 5.26644 - diff: 18.64mlTrain batch 4/4 - 117.4ms/batch - loss: 5.51030 - diff: 18.56mlTrain batch 4/4 - 10.7s 117.4ms/batch - loss: 5.51030 - diff: 18.56ml
Test 0.6s: val_loss: 9.00987 - diff: 22.21ml

Epoch 70: current best loss = 7.28649, at epoch 56
Train batch 1/4 - 150.3ms/batch - loss: 7.42921 - diff: 20.87mlTrain batch 2/4 - 145.7ms/batch - loss: 6.12426 - diff: 19.52mlTrain batch 3/4 - 150.4ms/batch - loss: 5.77380 - diff: 19.48mlTrain batch 4/4 - 118.9ms/batch - loss: 5.57436 - diff: 18.98mlTrain batch 4/4 - 10.6s 118.9ms/batch - loss: 5.57436 - diff: 18.98ml
Test 0.6s: val_loss: 11.21885 - diff: 25.28ml

Epoch 71: current best loss = 7.28649, at epoch 56
Train batch 1/4 - 151.8ms/batch - loss: 5.18832 - diff: 19.70mlTrain batch 2/4 - 142.8ms/batch - loss: 5.78221 - diff: 19.19mlTrain batch 3/4 - 147.0ms/batch - loss: 5.33802 - diff: 18.96mlTrain batch 4/4 - 118.8ms/batch - loss: 5.58994 - diff: 19.04mlTrain batch 4/4 - 10.6s 118.8ms/batch - loss: 5.58994 - diff: 19.04ml
Test 0.6s: val_loss: 8.53506 - diff: 21.96ml

Epoch 72: current best loss = 7.28649, at epoch 56
Train batch 1/4 - 151.6ms/batch - loss: 4.64562 - diff: 17.16mlTrain batch 2/4 - 144.4ms/batch - loss: 4.94955 - diff: 17.47mlTrain batch 3/4 - 148.8ms/batch - loss: 5.21952 - diff: 17.91mlTrain batch 4/4 - 117.7ms/batch - loss: 4.98119 - diff: 17.73mlTrain batch 4/4 - 10.6s 117.7ms/batch - loss: 4.98119 - diff: 17.73ml
Test 0.6s: val_loss: 8.90365 - diff: 21.30ml

Epoch 73: current best loss = 7.28649, at epoch 56
Train batch 1/4 - 149.0ms/batch - loss: 4.02533 - diff: 17.46mlTrain batch 2/4 - 147.6ms/batch - loss: 5.88534 - diff: 18.78mlTrain batch 3/4 - 151.9ms/batch - loss: 5.64834 - diff: 18.72mlTrain batch 4/4 - 117.4ms/batch - loss: 5.90741 - diff: 18.55mlTrain batch 4/4 - 10.6s 117.4ms/batch - loss: 5.90741 - diff: 18.55ml
Test 0.6s: val_loss: 8.29214 - diff: 21.32ml

Epoch 74: current best loss = 7.28649, at epoch 56
Train batch 1/4 - 147.0ms/batch - loss: 6.60675 - diff: 19.78mlTrain batch 2/4 - 144.4ms/batch - loss: 5.90608 - diff: 19.13mlTrain batch 3/4 - 148.5ms/batch - loss: 5.30824 - diff: 18.73mlTrain batch 4/4 - 121.3ms/batch - loss: 4.86175 - diff: 17.73mlTrain batch 4/4 - 10.7s 121.3ms/batch - loss: 4.86175 - diff: 17.73ml
Test 0.6s: val_loss: 8.84243 - diff: 23.04ml

Epoch 75: current best loss = 7.28649, at epoch 56
Train batch 1/4 - 149.3ms/batch - loss: 4.74500 - diff: 18.02mlTrain batch 2/4 - 142.9ms/batch - loss: 4.47497 - diff: 17.36mlTrain batch 3/4 - 149.2ms/batch - loss: 4.99347 - diff: 18.09mlTrain batch 4/4 - 118.9ms/batch - loss: 5.43735 - diff: 18.03mlTrain batch 4/4 - 10.5s 118.9ms/batch - loss: 5.43735 - diff: 18.03ml
Test 0.6s: val_loss: 8.02603 - diff: 21.03ml

Epoch 76: current best loss = 7.28649, at epoch 56
Train batch 1/4 - 148.9ms/batch - loss: 5.19953 - diff: 17.33mlTrain batch 2/4 - 147.6ms/batch - loss: 5.05493 - diff: 18.01mlTrain batch 3/4 - 150.3ms/batch - loss: 4.87029 - diff: 18.40mlTrain batch 4/4 - 124.1ms/batch - loss: 5.37247 - diff: 18.15mlTrain batch 4/4 - 10.7s 124.1ms/batch - loss: 5.37247 - diff: 18.15ml
Test 0.6s: val_loss: 7.65729 - diff: 19.71ml

Epoch 77: current best loss = 7.28649, at epoch 56
Train batch 1/4 - 151.7ms/batch - loss: 7.27824 - diff: 17.70mlTrain batch 2/4 - 144.5ms/batch - loss: 6.15700 - diff: 18.37mlTrain batch 3/4 - 151.7ms/batch - loss: 5.47062 - diff: 17.82mlTrain batch 4/4 - 117.5ms/batch - loss: 5.35122 - diff: 17.60mlTrain batch 4/4 - 10.7s 117.5ms/batch - loss: 5.35122 - diff: 17.60ml
Test 0.6s: val_loss: 7.67944 - diff: 20.14ml

Epoch 78: current best loss = 7.28649, at epoch 56
Train batch 1/4 - 150.4ms/batch - loss: 4.41634 - diff: 17.88mlTrain batch 2/4 - 146.3ms/batch - loss: 4.96857 - diff: 18.74mlTrain batch 3/4 - 152.0ms/batch - loss: 4.69832 - diff: 17.96mlTrain batch 4/4 - 119.0ms/batch - loss: 5.26967 - diff: 17.88mlTrain batch 4/4 - 10.7s 119.0ms/batch - loss: 5.26967 - diff: 17.88ml
Test 0.6s: val_loss: 7.98975 - diff: 19.66ml
Epoch    79: reducing learning rate of group 0 to 1.2500e-04.

Epoch 79: current best loss = 7.28649, at epoch 56
Train batch 1/4 - 148.7ms/batch - loss: 3.67779 - diff: 15.80mlTrain batch 2/4 - 142.7ms/batch - loss: 4.33511 - diff: 17.08mlTrain batch 3/4 - 149.9ms/batch - loss: 3.93530 - diff: 16.43mlTrain batch 4/4 - 118.8ms/batch - loss: 5.02472 - diff: 17.11mlTrain batch 4/4 - 10.6s 118.8ms/batch - loss: 5.02472 - diff: 17.11ml
Test 0.6s: val_loss: 7.63158 - diff: 18.79ml

Epoch 80: current best loss = 7.28649, at epoch 56
Train batch 1/4 - 151.9ms/batch - loss: 3.42538 - diff: 15.35mlTrain batch 2/4 - 148.9ms/batch - loss: 4.92022 - diff: 17.14mlTrain batch 3/4 - 150.1ms/batch - loss: 4.76191 - diff: 17.41mlTrain batch 4/4 - 117.7ms/batch - loss: 4.72216 - diff: 17.18mlTrain batch 4/4 - 10.6s 117.7ms/batch - loss: 4.72216 - diff: 17.18ml
Test 0.7s: val_loss: 7.73268 - diff: 18.85ml

Epoch 81: current best loss = 7.28649, at epoch 56
Train batch 1/4 - 151.9ms/batch - loss: 5.04030 - diff: 17.34mlTrain batch 2/4 - 144.5ms/batch - loss: 4.03177 - diff: 16.14mlTrain batch 3/4 - 150.2ms/batch - loss: 4.50059 - diff: 17.20mlTrain batch 4/4 - 117.3ms/batch - loss: 5.31612 - diff: 17.91mlTrain batch 4/4 - 10.6s 117.3ms/batch - loss: 5.31612 - diff: 17.91ml
Test 0.6s: val_loss: 8.24585 - diff: 19.36ml

Epoch 82: current best loss = 7.28649, at epoch 56
Train batch 1/4 - 149.7ms/batch - loss: 4.17901 - diff: 17.02mlTrain batch 2/4 - 144.4ms/batch - loss: 3.98022 - diff: 16.62mlTrain batch 3/4 - 152.1ms/batch - loss: 4.55390 - diff: 17.84mlTrain batch 4/4 - 125.4ms/batch - loss: 5.58557 - diff: 17.94mlTrain batch 4/4 - 10.7s 125.4ms/batch - loss: 5.58557 - diff: 17.94ml
Test 0.6s: val_loss: 8.27075 - diff: 21.24ml

Epoch 83: current best loss = 7.28649, at epoch 56
Train batch 1/4 - 146.7ms/batch - loss: 5.00463 - diff: 17.96mlTrain batch 2/4 - 142.8ms/batch - loss: 4.28372 - diff: 16.63mlTrain batch 3/4 - 148.2ms/batch - loss: 4.30666 - diff: 17.27mlTrain batch 4/4 - 118.9ms/batch - loss: 4.48697 - diff: 17.11mlTrain batch 4/4 - 10.5s 118.9ms/batch - loss: 4.48697 - diff: 17.11ml
Test 0.6s: val_loss: 8.12479 - diff: 19.82ml

Epoch 84: current best loss = 7.28649, at epoch 56
Train batch 1/4 - 152.1ms/batch - loss: 5.86600 - diff: 18.85mlTrain batch 2/4 - 147.3ms/batch - loss: 4.95333 - diff: 18.07mlTrain batch 3/4 - 146.9ms/batch - loss: 5.47975 - diff: 18.47mlTrain batch 4/4 - 117.6ms/batch - loss: 5.29902 - diff: 18.16mlTrain batch 4/4 - 10.6s 117.6ms/batch - loss: 5.29902 - diff: 18.16ml
Test 0.6s: val_loss: 6.72157 - diff: 18.96ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Systole_TimeAsDepth_1_Adam-0.001_MSE_DA3_best

Epoch 85: current best loss = 6.72157, at epoch 84
Train batch 1/4 - 151.9ms/batch - loss: 4.15554 - diff: 16.73mlTrain batch 2/4 - 145.6ms/batch - loss: 4.90174 - diff: 17.38mlTrain batch 3/4 - 151.9ms/batch - loss: 4.77206 - diff: 17.88mlTrain batch 4/4 - 118.5ms/batch - loss: 4.96679 - diff: 17.97mlTrain batch 4/4 - 10.7s 118.5ms/batch - loss: 4.96679 - diff: 17.97ml
Test 0.6s: val_loss: 7.34992 - diff: 19.25ml

Epoch 86: current best loss = 6.72157, at epoch 84
Train batch 1/4 - 150.5ms/batch - loss: 4.44671 - diff: 17.68mlTrain batch 2/4 - 144.4ms/batch - loss: 4.88903 - diff: 18.67mlTrain batch 3/4 - 151.9ms/batch - loss: 5.39032 - diff: 18.56mlTrain batch 4/4 - 118.9ms/batch - loss: 5.29351 - diff: 18.30mlTrain batch 4/4 - 10.6s 118.9ms/batch - loss: 5.29351 - diff: 18.30ml
Test 0.6s: val_loss: 7.83546 - diff: 19.37ml

Epoch 87: current best loss = 6.72157, at epoch 84
Train batch 1/4 - 151.7ms/batch - loss: 6.56258 - diff: 19.14mlTrain batch 2/4 - 144.0ms/batch - loss: 5.35117 - diff: 17.89mlTrain batch 3/4 - 151.7ms/batch - loss: 5.43589 - diff: 18.15mlTrain batch 4/4 - 121.6ms/batch - loss: 5.34152 - diff: 17.96mlTrain batch 4/4 - 10.6s 121.6ms/batch - loss: 5.34152 - diff: 17.96ml
Test 0.6s: val_loss: 6.99224 - diff: 19.40ml

Epoch 88: current best loss = 6.72157, at epoch 84
Train batch 1/4 - 149.6ms/batch - loss: 3.69740 - diff: 16.35mlTrain batch 2/4 - 148.4ms/batch - loss: 4.19305 - diff: 17.10mlTrain batch 3/4 - 150.4ms/batch - loss: 4.16043 - diff: 16.98mlTrain batch 4/4 - 117.8ms/batch - loss: 4.53132 - diff: 16.77mlTrain batch 4/4 - 10.6s 117.8ms/batch - loss: 4.53132 - diff: 16.77ml
Test 0.6s: val_loss: 7.40447 - diff: 19.35ml

Epoch 89: current best loss = 6.72157, at epoch 84
Train batch 1/4 - 152.0ms/batch - loss: 4.75161 - diff: 18.05mlTrain batch 2/4 - 147.4ms/batch - loss: 4.47250 - diff: 17.55mlTrain batch 3/4 - 151.6ms/batch - loss: 4.57049 - diff: 17.40mlTrain batch 4/4 - 121.0ms/batch - loss: 4.62010 - diff: 17.22mlTrain batch 4/4 - 10.6s 121.0ms/batch - loss: 4.62010 - diff: 17.22ml
Test 0.6s: val_loss: 7.62336 - diff: 19.58ml

Epoch 90: current best loss = 6.72157, at epoch 84
Train batch 1/4 - 150.5ms/batch - loss: 4.10732 - diff: 16.79mlTrain batch 2/4 - 147.2ms/batch - loss: 3.76346 - diff: 16.53mlTrain batch 3/4 - 151.6ms/batch - loss: 4.56293 - diff: 17.25mlTrain batch 4/4 - 118.9ms/batch - loss: 4.46926 - diff: 16.90mlTrain batch 4/4 - 10.6s 118.9ms/batch - loss: 4.46926 - diff: 16.90ml
Test 0.6s: val_loss: 7.91010 - diff: 19.27ml

Epoch 91: current best loss = 6.72157, at epoch 84
Train batch 1/4 - 152.1ms/batch - loss: 3.89015 - diff: 16.72mlTrain batch 2/4 - 142.9ms/batch - loss: 4.09188 - diff: 17.34mlTrain batch 3/4 - 152.0ms/batch - loss: 4.46511 - diff: 17.46mlTrain batch 4/4 - 119.0ms/batch - loss: 4.77183 - diff: 17.50mlTrain batch 4/4 - 10.7s 119.0ms/batch - loss: 4.77183 - diff: 17.50ml
Test 0.6s: val_loss: 7.31972 - diff: 19.27ml

Epoch 92: current best loss = 6.72157, at epoch 84
Train batch 1/4 - 150.5ms/batch - loss: 3.40644 - diff: 15.22mlTrain batch 2/4 - 144.3ms/batch - loss: 5.20950 - diff: 17.85mlTrain batch 3/4 - 150.1ms/batch - loss: 4.49736 - diff: 17.25mlTrain batch 4/4 - 123.9ms/batch - loss: 4.94309 - diff: 17.79mlTrain batch 4/4 - 10.7s 123.9ms/batch - loss: 4.94309 - diff: 17.79ml
Test 0.6s: val_loss: 7.32442 - diff: 18.94ml

Epoch 93: current best loss = 6.72157, at epoch 84
Train batch 1/4 - 151.7ms/batch - loss: 4.68246 - diff: 18.72mlTrain batch 2/4 - 146.0ms/batch - loss: 5.46038 - diff: 18.56mlTrain batch 3/4 - 151.7ms/batch - loss: 5.28263 - diff: 18.26mlTrain batch 4/4 - 117.6ms/batch - loss: 5.22209 - diff: 18.02mlTrain batch 4/4 - 10.7s 117.6ms/batch - loss: 5.22209 - diff: 18.02ml
Test 0.6s: val_loss: 7.26117 - diff: 18.78ml

Epoch 94: current best loss = 6.72157, at epoch 84
Train batch 1/4 - 146.2ms/batch - loss: 3.71166 - diff: 15.89mlTrain batch 2/4 - 145.8ms/batch - loss: 3.72611 - diff: 16.66mlTrain batch 3/4 - 151.1ms/batch - loss: 4.34340 - diff: 17.12mlTrain batch 4/4 - 124.2ms/batch - loss: 4.58104 - diff: 17.38mlTrain batch 4/4 - 10.7s 124.2ms/batch - loss: 4.58104 - diff: 17.38ml
Test 0.7s: val_loss: 7.79598 - diff: 18.76ml

Epoch 95: current best loss = 6.72157, at epoch 84
Train batch 1/4 - 151.2ms/batch - loss: 3.56172 - diff: 16.48mlTrain batch 2/4 - 147.9ms/batch - loss: 4.09061 - diff: 17.10mlTrain batch 3/4 - 151.7ms/batch - loss: 4.36699 - diff: 16.83mlTrain batch 4/4 - 122.1ms/batch - loss: 4.58196 - diff: 16.91mlTrain batch 4/4 - 10.6s 122.1ms/batch - loss: 4.58196 - diff: 16.91ml
Test 0.6s: val_loss: 7.87357 - diff: 18.92ml
Epoch    96: reducing learning rate of group 0 to 6.2500e-05.

Epoch 96: current best loss = 6.72157, at epoch 84
Train batch 1/4 - 152.0ms/batch - loss: 4.07523 - diff: 16.36mlTrain batch 2/4 - 145.4ms/batch - loss: 4.42581 - diff: 17.38mlTrain batch 3/4 - 150.5ms/batch - loss: 4.86016 - diff: 17.64mlTrain batch 4/4 - 118.2ms/batch - loss: 4.91053 - diff: 17.68mlTrain batch 4/4 - 10.6s 118.2ms/batch - loss: 4.91053 - diff: 17.68ml
Test 0.6s: val_loss: 7.33358 - diff: 18.90ml

Epoch 97: current best loss = 6.72157, at epoch 84
Train batch 1/4 - 152.0ms/batch - loss: 4.62815 - diff: 16.80mlTrain batch 2/4 - 147.1ms/batch - loss: 5.76951 - diff: 18.48mlTrain batch 3/4 - 151.6ms/batch - loss: 5.13651 - diff: 17.91mlTrain batch 4/4 - 119.9ms/batch - loss: 4.88665 - diff: 17.51mlTrain batch 4/4 - 10.6s 119.9ms/batch - loss: 4.88665 - diff: 17.51ml
Test 0.6s: val_loss: 8.04086 - diff: 18.63ml

Epoch 98: current best loss = 6.72157, at epoch 84
Train batch 1/4 - 150.6ms/batch - loss: 6.72846 - diff: 19.33mlTrain batch 2/4 - 145.3ms/batch - loss: 5.21993 - diff: 17.71mlTrain batch 3/4 - 152.0ms/batch - loss: 4.72412 - diff: 17.54mlTrain batch 4/4 - 119.8ms/batch - loss: 4.99225 - diff: 17.54mlTrain batch 4/4 - 10.6s 119.8ms/batch - loss: 4.99225 - diff: 17.54ml
Test 0.6s: val_loss: 7.18420 - diff: 18.57ml

Epoch 99: current best loss = 6.72157, at epoch 84
Train batch 1/4 - 151.9ms/batch - loss: 4.95086 - diff: 18.05mlTrain batch 2/4 - 144.1ms/batch - loss: 4.91274 - diff: 17.70mlTrain batch 3/4 - 152.0ms/batch - loss: 5.00932 - diff: 18.11mlTrain batch 4/4 - 125.5ms/batch - loss: 5.18958 - diff: 18.01mlTrain batch 4/4 - 10.7s 125.5ms/batch - loss: 5.18958 - diff: 18.01ml
Test 0.6s: val_loss: 7.54560 - diff: 18.59ml

