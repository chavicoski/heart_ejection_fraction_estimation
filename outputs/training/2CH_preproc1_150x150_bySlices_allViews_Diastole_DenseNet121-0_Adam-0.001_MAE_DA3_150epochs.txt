nohup: ignoring input
Running experiment 2CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_DenseNet121_0_Adam-0.001_MAE_DA3
Going to train with the GPU in the slot 1 -> device model: GeForce RTX 2080
Model architecture:
 DenseNet121_0(
  (first_conv): Sequential(
    (0): Conv2d(30, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (pretrained_block): Sequential(
    (0): _DenseBlock(
      (denselayer1): _DenseLayer(
        (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer2): _DenseLayer(
        (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer3): _DenseLayer(
        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer4): _DenseLayer(
        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer5): _DenseLayer(
        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer6): _DenseLayer(
        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
    (1): _Transition(
      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)
    )
    (2): _DenseBlock(
      (denselayer1): _DenseLayer(
        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer2): _DenseLayer(
        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer3): _DenseLayer(
        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer4): _DenseLayer(
        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer5): _DenseLayer(
        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer6): _DenseLayer(
        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer7): _DenseLayer(
        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer8): _DenseLayer(
        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer9): _DenseLayer(
        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer10): _DenseLayer(
        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer11): _DenseLayer(
        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer12): _DenseLayer(
        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
    (3): _Transition(
      (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)
    )
    (4): _DenseBlock(
      (denselayer1): _DenseLayer(
        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer2): _DenseLayer(
        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer3): _DenseLayer(
        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer4): _DenseLayer(
        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer5): _DenseLayer(
        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer6): _DenseLayer(
        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer7): _DenseLayer(
        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer8): _DenseLayer(
        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer9): _DenseLayer(
        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer10): _DenseLayer(
        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer11): _DenseLayer(
        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer12): _DenseLayer(
        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer13): _DenseLayer(
        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer14): _DenseLayer(
        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer15): _DenseLayer(
        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer16): _DenseLayer(
        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer17): _DenseLayer(
        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer18): _DenseLayer(
        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer19): _DenseLayer(
        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer20): _DenseLayer(
        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer21): _DenseLayer(
        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer22): _DenseLayer(
        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer23): _DenseLayer(
        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer24): _DenseLayer(
        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
    (5): _Transition(
      (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)
    )
    (6): _DenseBlock(
      (denselayer1): _DenseLayer(
        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer2): _DenseLayer(
        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer3): _DenseLayer(
        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer4): _DenseLayer(
        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer5): _DenseLayer(
        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer6): _DenseLayer(
        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer7): _DenseLayer(
        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer8): _DenseLayer(
        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer9): _DenseLayer(
        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer10): _DenseLayer(
        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer11): _DenseLayer(
        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer12): _DenseLayer(
        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer13): _DenseLayer(
        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer14): _DenseLayer(
        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer15): _DenseLayer(
        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer16): _DenseLayer(
        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
    (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (reduction_block): Sequential(
    (0): AdaptiveAvgPool2d(output_size=(1, 1))
    (1): Flatten()
  )
  (dense_block): Sequential(
    (0): Linear(in_features=1024, out_features=512, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.4, inplace=False)
    (3): Linear(in_features=512, out_features=1, bias=True)
  )
) 


############################
# TRAIN PHASE:  150 epochs #
############################

Epoch 0: 
Train batch 1/32 - 126.8ms/batch - loss: 9.76626 - diff: 156.26mlTrain batch 2/32 - 93.9ms/batch - loss: 10.50579 - diff: 168.09mlTrain batch 3/32 - 82.0ms/batch - loss: 10.39502 - diff: 166.32mlTrain batch 4/32 - 95.2ms/batch - loss: 10.03977 - diff: 160.64mlTrain batch 5/32 - 91.7ms/batch - loss: 9.79334 - diff: 156.69mlTrain batch 6/32 - 95.1ms/batch - loss: 9.79580 - diff: 156.73mlTrain batch 7/32 - 91.7ms/batch - loss: 9.73867 - diff: 155.82mlTrain batch 8/32 - 92.4ms/batch - loss: 9.78215 - diff: 156.51mlTrain batch 9/32 - 88.1ms/batch - loss: 9.71616 - diff: 155.46mlTrain batch 10/32 - 73.8ms/batch - loss: 9.73849 - diff: 155.82mlTrain batch 11/32 - 107.8ms/batch - loss: 9.75377 - diff: 156.06mlTrain batch 12/32 - 68.9ms/batch - loss: 9.64572 - diff: 154.33mlTrain batch 13/32 - 79.9ms/batch - loss: 9.62374 - diff: 153.98mlTrain batch 14/32 - 65.3ms/batch - loss: 9.59382 - diff: 153.50mlTrain batch 15/32 - 69.5ms/batch - loss: 9.57602 - diff: 153.22mlTrain batch 16/32 - 84.6ms/batch - loss: 9.56225 - diff: 153.00mlTrain batch 17/32 - 71.0ms/batch - loss: 9.42212 - diff: 150.75mlTrain batch 18/32 - 63.8ms/batch - loss: 9.42003 - diff: 150.72mlTrain batch 19/32 - 64.1ms/batch - loss: 9.35260 - diff: 149.64mlTrain batch 20/32 - 64.8ms/batch - loss: 9.27324 - diff: 148.37mlTrain batch 21/32 - 76.0ms/batch - loss: 9.23602 - diff: 147.78mlTrain batch 22/32 - 77.9ms/batch - loss: 9.11801 - diff: 145.89mlTrain batch 23/32 - 85.5ms/batch - loss: 9.05350 - diff: 144.86mlTrain batch 24/32 - 66.5ms/batch - loss: 8.92989 - diff: 142.88mlTrain batch 25/32 - 55.5ms/batch - loss: 8.87210 - diff: 141.95mlTrain batch 26/32 - 95.2ms/batch - loss: 8.74712 - diff: 139.95mlTrain batch 27/32 - 79.5ms/batch - loss: 8.71922 - diff: 139.51mlTrain batch 28/32 - 86.8ms/batch - loss: 8.62539 - diff: 138.01mlTrain batch 29/32 - 93.2ms/batch - loss: 8.54703 - diff: 136.75mlTrain batch 30/32 - 80.2ms/batch - loss: 8.42185 - diff: 134.75mlTrain batch 31/32 - 80.0ms/batch - loss: 8.28772 - diff: 132.60mlTrain batch 32/32 - 61.2ms/batch - loss: 8.28922 - diff: 131.81mlTrain batch 32/32 - 32.9s 61.2ms/batch - loss: 8.28922 - diff: 131.81ml
Test 8.3s: val_loss: 7.86300 - diff: 120.31ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_DenseNet121_0_Adam-0.001_MAE_DA3_best

Epoch 1: current best loss = 7.86300, at epoch 0
Train batch 1/32 - 95.9ms/batch - loss: 4.70392 - diff: 75.26mlTrain batch 2/32 - 88.3ms/batch - loss: 4.34843 - diff: 69.57mlTrain batch 3/32 - 74.3ms/batch - loss: 4.67232 - diff: 74.76mlTrain batch 4/32 - 99.8ms/batch - loss: 4.73189 - diff: 75.71mlTrain batch 5/32 - 81.8ms/batch - loss: 4.64617 - diff: 74.34mlTrain batch 6/32 - 97.3ms/batch - loss: 4.60361 - diff: 73.66mlTrain batch 7/32 - 72.9ms/batch - loss: 4.32524 - diff: 69.20mlTrain batch 8/32 - 72.9ms/batch - loss: 4.38371 - diff: 70.14mlTrain batch 9/32 - 93.9ms/batch - loss: 4.21397 - diff: 67.42mlTrain batch 10/32 - 69.9ms/batch - loss: 4.21273 - diff: 67.40mlTrain batch 11/32 - 107.9ms/batch - loss: 4.27166 - diff: 68.35mlTrain batch 12/32 - 106.3ms/batch - loss: 4.29492 - diff: 68.72mlTrain batch 13/32 - 85.1ms/batch - loss: 4.34354 - diff: 69.50mlTrain batch 14/32 - 74.8ms/batch - loss: 4.34390 - diff: 69.50mlTrain batch 15/32 - 63.8ms/batch - loss: 4.43124 - diff: 70.90mlTrain batch 16/32 - 61.5ms/batch - loss: 4.39966 - diff: 70.39mlTrain batch 17/32 - 93.5ms/batch - loss: 4.31033 - diff: 68.97mlTrain batch 18/32 - 75.1ms/batch - loss: 4.21854 - diff: 67.50mlTrain batch 19/32 - 59.0ms/batch - loss: 4.15166 - diff: 66.43mlTrain batch 20/32 - 59.0ms/batch - loss: 4.08763 - diff: 65.40mlTrain batch 21/32 - 87.1ms/batch - loss: 4.01098 - diff: 64.18mlTrain batch 22/32 - 93.8ms/batch - loss: 3.95235 - diff: 63.24mlTrain batch 23/32 - 84.9ms/batch - loss: 3.90385 - diff: 62.46mlTrain batch 24/32 - 93.0ms/batch - loss: 3.91075 - diff: 62.57mlTrain batch 25/32 - 80.1ms/batch - loss: 3.90506 - diff: 62.48mlTrain batch 26/32 - 92.1ms/batch - loss: 3.85184 - diff: 61.63mlTrain batch 27/32 - 95.7ms/batch - loss: 3.83713 - diff: 61.39mlTrain batch 28/32 - 91.0ms/batch - loss: 3.88823 - diff: 62.21mlTrain batch 29/32 - 92.8ms/batch - loss: 3.86267 - diff: 61.80mlTrain batch 30/32 - 88.6ms/batch - loss: 3.82559 - diff: 61.21mlTrain batch 31/32 - 59.8ms/batch - loss: 3.79285 - diff: 60.69mlTrain batch 32/32 - 89.2ms/batch - loss: 3.85416 - diff: 60.57mlTrain batch 32/32 - 15.3s 89.2ms/batch - loss: 3.85416 - diff: 60.57ml
Test 1.0s: val_loss: 4.23920 - diff: 66.36ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_DenseNet121_0_Adam-0.001_MAE_DA3_best

Epoch 2: current best loss = 4.23920, at epoch 1
Train batch 1/32 - 131.9ms/batch - loss: 3.37302 - diff: 53.97mlTrain batch 2/32 - 65.1ms/batch - loss: 3.58174 - diff: 57.31mlTrain batch 3/32 - 87.7ms/batch - loss: 3.73689 - diff: 59.79mlTrain batch 4/32 - 96.6ms/batch - loss: 3.43842 - diff: 55.01mlTrain batch 5/32 - 85.7ms/batch - loss: 3.67338 - diff: 58.77mlTrain batch 6/32 - 93.5ms/batch - loss: 3.47505 - diff: 55.60mlTrain batch 7/32 - 64.4ms/batch - loss: 3.35445 - diff: 53.67mlTrain batch 8/32 - 61.8ms/batch - loss: 3.42801 - diff: 54.85mlTrain batch 9/32 - 94.2ms/batch - loss: 3.42730 - diff: 54.84mlTrain batch 10/32 - 91.4ms/batch - loss: 3.40748 - diff: 54.52mlTrain batch 11/32 - 89.0ms/batch - loss: 3.40778 - diff: 54.52mlTrain batch 12/32 - 94.2ms/batch - loss: 3.39213 - diff: 54.27mlTrain batch 13/32 - 72.2ms/batch - loss: 3.36982 - diff: 53.92mlTrain batch 14/32 - 65.5ms/batch - loss: 3.39315 - diff: 54.29mlTrain batch 15/32 - 88.3ms/batch - loss: 3.44011 - diff: 55.04mlTrain batch 16/32 - 84.6ms/batch - loss: 3.34643 - diff: 53.54mlTrain batch 17/32 - 92.5ms/batch - loss: 3.36110 - diff: 53.78mlTrain batch 18/32 - 83.7ms/batch - loss: 3.34187 - diff: 53.47mlTrain batch 19/32 - 63.2ms/batch - loss: 3.31156 - diff: 52.99mlTrain batch 20/32 - 69.9ms/batch - loss: 3.34873 - diff: 53.58mlTrain batch 21/32 - 97.2ms/batch - loss: 3.34143 - diff: 53.46mlTrain batch 22/32 - 74.3ms/batch - loss: 3.39899 - diff: 54.38mlTrain batch 23/32 - 62.2ms/batch - loss: 3.35637 - diff: 53.70mlTrain batch 24/32 - 71.7ms/batch - loss: 3.35521 - diff: 53.68mlTrain batch 25/32 - 61.3ms/batch - loss: 3.36094 - diff: 53.78mlTrain batch 26/32 - 113.2ms/batch - loss: 3.39626 - diff: 54.34mlTrain batch 27/32 - 97.4ms/batch - loss: 3.43034 - diff: 54.89mlTrain batch 28/32 - 98.8ms/batch - loss: 3.42159 - diff: 54.75mlTrain batch 29/32 - 96.8ms/batch - loss: 3.42332 - diff: 54.77mlTrain batch 30/32 - 84.6ms/batch - loss: 3.45847 - diff: 55.34mlTrain batch 31/32 - 95.4ms/batch - loss: 3.45113 - diff: 55.22mlTrain batch 32/32 - 54.1ms/batch - loss: 3.57022 - diff: 55.36mlTrain batch 32/32 - 16.4s 54.1ms/batch - loss: 3.57022 - diff: 55.36ml
Test 1.2s: val_loss: 3.95621 - diff: 61.40ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_DenseNet121_0_Adam-0.001_MAE_DA3_best

Epoch 3: current best loss = 3.95621, at epoch 2
Train batch 1/32 - 82.3ms/batch - loss: 4.89137 - diff: 78.26mlTrain batch 2/32 - 87.5ms/batch - loss: 3.91150 - diff: 62.58mlTrain batch 3/32 - 98.1ms/batch - loss: 3.32566 - diff: 53.21mlTrain batch 4/32 - 107.3ms/batch - loss: 3.51400 - diff: 56.22mlTrain batch 5/32 - 95.8ms/batch - loss: 3.51555 - diff: 56.25mlTrain batch 6/32 - 151.5ms/batch - loss: 3.58081 - diff: 57.29mlTrain batch 7/32 - 105.7ms/batch - loss: 3.48556 - diff: 55.77mlTrain batch 8/32 - 90.1ms/batch - loss: 3.46114 - diff: 55.38mlTrain batch 9/32 - 95.2ms/batch - loss: 3.40928 - diff: 54.55mlTrain batch 10/32 - 131.4ms/batch - loss: 3.44999 - diff: 55.20mlTrain batch 11/32 - 64.6ms/batch - loss: 3.43399 - diff: 54.94mlTrain batch 12/32 - 121.6ms/batch - loss: 3.34347 - diff: 53.50mlTrain batch 13/32 - 64.1ms/batch - loss: 3.28868 - diff: 52.62mlTrain batch 14/32 - 71.4ms/batch - loss: 3.28730 - diff: 52.60mlTrain batch 15/32 - 80.8ms/batch - loss: 3.32470 - diff: 53.20mlTrain batch 16/32 - 75.6ms/batch - loss: 3.33174 - diff: 53.31mlTrain batch 17/32 - 62.1ms/batch - loss: 3.40436 - diff: 54.47mlTrain batch 18/32 - 98.8ms/batch - loss: 3.34033 - diff: 53.45mlTrain batch 19/32 - 74.3ms/batch - loss: 3.34611 - diff: 53.54mlTrain batch 20/32 - 119.5ms/batch - loss: 3.37148 - diff: 53.94mlTrain batch 21/32 - 72.8ms/batch - loss: 3.31795 - diff: 53.09mlTrain batch 22/32 - 101.0ms/batch - loss: 3.27389 - diff: 52.38mlTrain batch 23/32 - 80.9ms/batch - loss: 3.25494 - diff: 52.08mlTrain batch 24/32 - 85.5ms/batch - loss: 3.16958 - diff: 50.71mlTrain batch 25/32 - 69.2ms/batch - loss: 3.16704 - diff: 50.67mlTrain batch 26/32 - 103.9ms/batch - loss: 3.15615 - diff: 50.50mlTrain batch 27/32 - 85.3ms/batch - loss: 3.14727 - diff: 50.36mlTrain batch 28/32 - 70.4ms/batch - loss: 3.14454 - diff: 50.31mlTrain batch 29/32 - 86.4ms/batch - loss: 3.12076 - diff: 49.93mlTrain batch 30/32 - 79.9ms/batch - loss: 3.09382 - diff: 49.50mlTrain batch 31/32 - 64.8ms/batch - loss: 3.13306 - diff: 50.13mlTrain batch 32/32 - 56.7ms/batch - loss: 3.23787 - diff: 50.25mlTrain batch 32/32 - 17.8s 56.7ms/batch - loss: 3.23787 - diff: 50.25ml
Test 1.1s: val_loss: 3.89498 - diff: 60.87ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_DenseNet121_0_Adam-0.001_MAE_DA3_best

Epoch 4: current best loss = 3.89498, at epoch 3
Train batch 1/32 - 83.6ms/batch - loss: 4.25303 - diff: 68.05mlTrain batch 2/32 - 64.2ms/batch - loss: 3.49540 - diff: 55.93mlTrain batch 3/32 - 80.2ms/batch - loss: 3.40018 - diff: 54.40mlTrain batch 4/32 - 78.1ms/batch - loss: 3.29335 - diff: 52.69mlTrain batch 5/32 - 97.0ms/batch - loss: 3.20360 - diff: 51.26mlTrain batch 6/32 - 79.4ms/batch - loss: 3.03727 - diff: 48.60mlTrain batch 7/32 - 94.0ms/batch - loss: 3.07008 - diff: 49.12mlTrain batch 8/32 - 118.7ms/batch - loss: 2.99833 - diff: 47.97mlTrain batch 9/32 - 106.6ms/batch - loss: 3.00749 - diff: 48.12mlTrain batch 10/32 - 131.1ms/batch - loss: 3.01297 - diff: 48.21mlTrain batch 11/32 - 75.6ms/batch - loss: 3.00782 - diff: 48.13mlTrain batch 12/32 - 84.5ms/batch - loss: 3.08298 - diff: 49.33mlTrain batch 13/32 - 71.6ms/batch - loss: 2.95892 - diff: 47.34mlTrain batch 14/32 - 72.4ms/batch - loss: 2.91728 - diff: 46.68mlTrain batch 15/32 - 78.6ms/batch - loss: 2.91730 - diff: 46.68mlTrain batch 16/32 - 82.9ms/batch - loss: 2.94796 - diff: 47.17mlTrain batch 17/32 - 107.1ms/batch - loss: 2.89353 - diff: 46.30mlTrain batch 18/32 - 90.8ms/batch - loss: 2.90679 - diff: 46.51mlTrain batch 19/32 - 74.8ms/batch - loss: 2.97112 - diff: 47.54mlTrain batch 20/32 - 72.0ms/batch - loss: 2.96377 - diff: 47.42mlTrain batch 21/32 - 63.4ms/batch - loss: 2.96367 - diff: 47.42mlTrain batch 22/32 - 98.1ms/batch - loss: 2.97090 - diff: 47.53mlTrain batch 23/32 - 74.5ms/batch - loss: 2.98925 - diff: 47.83mlTrain batch 24/32 - 63.0ms/batch - loss: 2.97636 - diff: 47.62mlTrain batch 25/32 - 87.2ms/batch - loss: 2.99025 - diff: 47.84mlTrain batch 26/32 - 97.1ms/batch - loss: 3.00388 - diff: 48.06mlTrain batch 27/32 - 92.6ms/batch - loss: 2.99341 - diff: 47.89mlTrain batch 28/32 - 88.5ms/batch - loss: 3.01001 - diff: 48.16mlTrain batch 29/32 - 72.3ms/batch - loss: 2.96930 - diff: 47.51mlTrain batch 30/32 - 71.9ms/batch - loss: 2.98437 - diff: 47.75mlTrain batch 31/32 - 66.7ms/batch - loss: 2.96942 - diff: 47.51mlTrain batch 32/32 - 59.3ms/batch - loss: 3.03256 - diff: 47.48mlTrain batch 32/32 - 17.0s 59.3ms/batch - loss: 3.03256 - diff: 47.48ml
Test 1.1s: val_loss: 3.09489 - diff: 47.17ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_DenseNet121_0_Adam-0.001_MAE_DA3_best

Epoch 5: current best loss = 3.09489, at epoch 4
Train batch 1/32 - 108.6ms/batch - loss: 2.59233 - diff: 41.48mlTrain batch 2/32 - 91.4ms/batch - loss: 2.35401 - diff: 37.66mlTrain batch 3/32 - 95.5ms/batch - loss: 2.45462 - diff: 39.27mlTrain batch 4/32 - 84.7ms/batch - loss: 2.48765 - diff: 39.80mlTrain batch 5/32 - 89.6ms/batch - loss: 2.73108 - diff: 43.70mlTrain batch 6/32 - 112.2ms/batch - loss: 2.85553 - diff: 45.69mlTrain batch 7/32 - 89.9ms/batch - loss: 2.96446 - diff: 47.43mlTrain batch 8/32 - 103.1ms/batch - loss: 3.06323 - diff: 49.01mlTrain batch 9/32 - 85.8ms/batch - loss: 3.09510 - diff: 49.52mlTrain batch 10/32 - 94.1ms/batch - loss: 3.07042 - diff: 49.13mlTrain batch 11/32 - 72.8ms/batch - loss: 3.05311 - diff: 48.85mlTrain batch 12/32 - 97.9ms/batch - loss: 3.08816 - diff: 49.41mlTrain batch 13/32 - 78.3ms/batch - loss: 3.11651 - diff: 49.86mlTrain batch 14/32 - 77.8ms/batch - loss: 3.17010 - diff: 50.72mlTrain batch 15/32 - 107.8ms/batch - loss: 3.15313 - diff: 50.45mlTrain batch 16/32 - 92.6ms/batch - loss: 3.12407 - diff: 49.99mlTrain batch 17/32 - 113.2ms/batch - loss: 3.02485 - diff: 48.40mlTrain batch 18/32 - 85.0ms/batch - loss: 2.92830 - diff: 46.85mlTrain batch 19/32 - 73.3ms/batch - loss: 2.92491 - diff: 46.80mlTrain batch 20/32 - 116.1ms/batch - loss: 2.91134 - diff: 46.58mlTrain batch 21/32 - 62.1ms/batch - loss: 2.97795 - diff: 47.65mlTrain batch 22/32 - 60.8ms/batch - loss: 2.95474 - diff: 47.28mlTrain batch 23/32 - 79.3ms/batch - loss: 2.92496 - diff: 46.80mlTrain batch 24/32 - 115.7ms/batch - loss: 2.88116 - diff: 46.10mlTrain batch 25/32 - 68.3ms/batch - loss: 2.85762 - diff: 45.72mlTrain batch 26/32 - 100.2ms/batch - loss: 2.88918 - diff: 46.23mlTrain batch 27/32 - 60.9ms/batch - loss: 2.89962 - diff: 46.39mlTrain batch 28/32 - 87.6ms/batch - loss: 2.90231 - diff: 46.44mlTrain batch 29/32 - 62.0ms/batch - loss: 2.86702 - diff: 45.87mlTrain batch 30/32 - 85.9ms/batch - loss: 2.89159 - diff: 46.27mlTrain batch 31/32 - 80.9ms/batch - loss: 2.88167 - diff: 46.11mlTrain batch 32/32 - 68.9ms/batch - loss: 2.92819 - diff: 46.02mlTrain batch 32/32 - 17.3s 68.9ms/batch - loss: 2.92819 - diff: 46.02ml
Test 1.1s: val_loss: 2.97346 - diff: 46.05ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_DenseNet121_0_Adam-0.001_MAE_DA3_best

Epoch 6: current best loss = 2.97346, at epoch 5
Train batch 1/32 - 120.2ms/batch - loss: 2.66290 - diff: 42.61mlTrain batch 2/32 - 74.9ms/batch - loss: 2.35603 - diff: 37.70mlTrain batch 3/32 - 78.5ms/batch - loss: 2.34920 - diff: 37.59mlTrain batch 4/32 - 61.7ms/batch - loss: 2.63618 - diff: 42.18mlTrain batch 5/32 - 68.8ms/batch - loss: 2.74100 - diff: 43.86mlTrain batch 6/32 - 83.1ms/batch - loss: 2.74579 - diff: 43.93mlTrain batch 7/32 - 85.4ms/batch - loss: 2.70733 - diff: 43.32mlTrain batch 8/32 - 78.0ms/batch - loss: 2.73502 - diff: 43.76mlTrain batch 9/32 - 75.0ms/batch - loss: 2.70485 - diff: 43.28mlTrain batch 10/32 - 96.5ms/batch - loss: 2.71868 - diff: 43.50mlTrain batch 11/32 - 85.5ms/batch - loss: 2.67049 - diff: 42.73mlTrain batch 12/32 - 96.9ms/batch - loss: 2.66351 - diff: 42.62mlTrain batch 13/32 - 71.6ms/batch - loss: 2.67051 - diff: 42.73mlTrain batch 14/32 - 89.2ms/batch - loss: 2.69080 - diff: 43.05mlTrain batch 15/32 - 80.3ms/batch - loss: 2.67029 - diff: 42.72mlTrain batch 16/32 - 117.2ms/batch - loss: 2.63856 - diff: 42.22mlTrain batch 17/32 - 80.5ms/batch - loss: 2.62074 - diff: 41.93mlTrain batch 18/32 - 84.0ms/batch - loss: 2.62362 - diff: 41.98mlTrain batch 19/32 - 81.0ms/batch - loss: 2.56695 - diff: 41.07mlTrain batch 20/32 - 84.8ms/batch - loss: 2.57002 - diff: 41.12mlTrain batch 21/32 - 77.1ms/batch - loss: 2.60085 - diff: 41.61mlTrain batch 22/32 - 129.3ms/batch - loss: 2.63849 - diff: 42.22mlTrain batch 23/32 - 94.8ms/batch - loss: 2.67064 - diff: 42.73mlTrain batch 24/32 - 94.4ms/batch - loss: 2.66325 - diff: 42.61mlTrain batch 25/32 - 80.1ms/batch - loss: 2.65791 - diff: 42.53mlTrain batch 26/32 - 90.6ms/batch - loss: 2.68064 - diff: 42.89mlTrain batch 27/32 - 82.5ms/batch - loss: 2.66900 - diff: 42.70mlTrain batch 28/32 - 70.3ms/batch - loss: 2.67428 - diff: 42.79mlTrain batch 29/32 - 87.2ms/batch - loss: 2.68109 - diff: 42.90mlTrain batch 30/32 - 62.4ms/batch - loss: 2.68664 - diff: 42.99mlTrain batch 31/32 - 69.0ms/batch - loss: 2.68155 - diff: 42.90mlTrain batch 32/32 - 56.7ms/batch - loss: 2.73881 - diff: 42.88mlTrain batch 32/32 - 17.8s 56.7ms/batch - loss: 2.73881 - diff: 42.88ml
Test 1.1s: val_loss: 2.62991 - diff: 41.02ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_DenseNet121_0_Adam-0.001_MAE_DA3_best

Epoch 7: current best loss = 2.62991, at epoch 6
Train batch 1/32 - 90.7ms/batch - loss: 4.36476 - diff: 69.84mlTrain batch 2/32 - 98.6ms/batch - loss: 3.78311 - diff: 60.53mlTrain batch 3/32 - 92.3ms/batch - loss: 3.69602 - diff: 59.14mlTrain batch 4/32 - 82.2ms/batch - loss: 3.46724 - diff: 55.48mlTrain batch 5/32 - 83.0ms/batch - loss: 3.24865 - diff: 51.98mlTrain batch 6/32 - 89.5ms/batch - loss: 3.15805 - diff: 50.53mlTrain batch 7/32 - 130.4ms/batch - loss: 2.99154 - diff: 47.86mlTrain batch 8/32 - 113.8ms/batch - loss: 2.90472 - diff: 46.48mlTrain batch 9/32 - 83.8ms/batch - loss: 2.86292 - diff: 45.81mlTrain batch 10/32 - 102.8ms/batch - loss: 2.92690 - diff: 46.83mlTrain batch 11/32 - 85.4ms/batch - loss: 2.90236 - diff: 46.44mlTrain batch 12/32 - 69.9ms/batch - loss: 3.03902 - diff: 48.62mlTrain batch 13/32 - 78.6ms/batch - loss: 2.98126 - diff: 47.70mlTrain batch 14/32 - 77.1ms/batch - loss: 2.97375 - diff: 47.58mlTrain batch 15/32 - 78.2ms/batch - loss: 2.93089 - diff: 46.89mlTrain batch 16/32 - 69.7ms/batch - loss: 2.88699 - diff: 46.19mlTrain batch 17/32 - 60.9ms/batch - loss: 2.85313 - diff: 45.65mlTrain batch 18/32 - 90.5ms/batch - loss: 2.77324 - diff: 44.37mlTrain batch 19/32 - 59.5ms/batch - loss: 2.81340 - diff: 45.01mlTrain batch 20/32 - 78.2ms/batch - loss: 2.81455 - diff: 45.03mlTrain batch 21/32 - 92.1ms/batch - loss: 2.79516 - diff: 44.72mlTrain batch 22/32 - 79.7ms/batch - loss: 2.81521 - diff: 45.04mlTrain batch 23/32 - 77.1ms/batch - loss: 2.76621 - diff: 44.26mlTrain batch 24/32 - 73.1ms/batch - loss: 2.73945 - diff: 43.83mlTrain batch 25/32 - 80.7ms/batch - loss: 2.71033 - diff: 43.37mlTrain batch 26/32 - 65.5ms/batch - loss: 2.70907 - diff: 43.35mlTrain batch 27/32 - 92.5ms/batch - loss: 2.70582 - diff: 43.29mlTrain batch 28/32 - 74.4ms/batch - loss: 2.72336 - diff: 43.57mlTrain batch 29/32 - 86.0ms/batch - loss: 2.72403 - diff: 43.58mlTrain batch 30/32 - 79.8ms/batch - loss: 2.72774 - diff: 43.64mlTrain batch 31/32 - 88.5ms/batch - loss: 2.72114 - diff: 43.54mlTrain batch 32/32 - 100.6ms/batch - loss: 2.82918 - diff: 43.71mlTrain batch 32/32 - 16.2s 100.6ms/batch - loss: 2.82918 - diff: 43.71ml
Test 1.1s: val_loss: 2.69564 - diff: 42.10ml

Epoch 8: current best loss = 2.62991, at epoch 6
Train batch 1/32 - 73.8ms/batch - loss: 2.41592 - diff: 38.65mlTrain batch 2/32 - 83.4ms/batch - loss: 2.86806 - diff: 45.89mlTrain batch 3/32 - 80.2ms/batch - loss: 3.00809 - diff: 48.13mlTrain batch 4/32 - 106.2ms/batch - loss: 2.81016 - diff: 44.96mlTrain batch 5/32 - 85.3ms/batch - loss: 2.58719 - diff: 41.40mlTrain batch 6/32 - 65.0ms/batch - loss: 2.64210 - diff: 42.27mlTrain batch 7/32 - 96.5ms/batch - loss: 2.71042 - diff: 43.37mlTrain batch 8/32 - 89.3ms/batch - loss: 2.66622 - diff: 42.66mlTrain batch 9/32 - 75.4ms/batch - loss: 2.74310 - diff: 43.89mlTrain batch 10/32 - 61.2ms/batch - loss: 2.72927 - diff: 43.67mlTrain batch 11/32 - 88.4ms/batch - loss: 2.61732 - diff: 41.88mlTrain batch 12/32 - 81.6ms/batch - loss: 2.60237 - diff: 41.64mlTrain batch 13/32 - 89.8ms/batch - loss: 2.61114 - diff: 41.78mlTrain batch 14/32 - 114.4ms/batch - loss: 2.64057 - diff: 42.25mlTrain batch 15/32 - 105.5ms/batch - loss: 2.64431 - diff: 42.31mlTrain batch 16/32 - 111.1ms/batch - loss: 2.60553 - diff: 41.69mlTrain batch 17/32 - 85.2ms/batch - loss: 2.66786 - diff: 42.69mlTrain batch 18/32 - 126.5ms/batch - loss: 2.65366 - diff: 42.46mlTrain batch 19/32 - 101.5ms/batch - loss: 2.60590 - diff: 41.69mlTrain batch 20/32 - 93.7ms/batch - loss: 2.66573 - diff: 42.65mlTrain batch 21/32 - 92.3ms/batch - loss: 2.65556 - diff: 42.49mlTrain batch 22/32 - 86.7ms/batch - loss: 2.64927 - diff: 42.39mlTrain batch 23/32 - 107.0ms/batch - loss: 2.64272 - diff: 42.28mlTrain batch 24/32 - 90.6ms/batch - loss: 2.64218 - diff: 42.27mlTrain batch 25/32 - 85.5ms/batch - loss: 2.65588 - diff: 42.49mlTrain batch 26/32 - 90.0ms/batch - loss: 2.67504 - diff: 42.80mlTrain batch 27/32 - 81.3ms/batch - loss: 2.65049 - diff: 42.41mlTrain batch 28/32 - 81.2ms/batch - loss: 2.69595 - diff: 43.14mlTrain batch 29/32 - 77.0ms/batch - loss: 2.68205 - diff: 42.91mlTrain batch 30/32 - 76.4ms/batch - loss: 2.65032 - diff: 42.41mlTrain batch 31/32 - 96.7ms/batch - loss: 2.64493 - diff: 42.32mlTrain batch 32/32 - 56.9ms/batch - loss: 2.67834 - diff: 42.20mlTrain batch 32/32 - 18.3s 56.9ms/batch - loss: 2.67834 - diff: 42.20ml
Test 1.1s: val_loss: 2.71804 - diff: 40.93ml

Epoch 9: current best loss = 2.62991, at epoch 6
Train batch 1/32 - 75.0ms/batch - loss: 2.19345 - diff: 35.10mlTrain batch 2/32 - 96.8ms/batch - loss: 2.13800 - diff: 34.21mlTrain batch 3/32 - 61.4ms/batch - loss: 2.01643 - diff: 32.26mlTrain batch 4/32 - 79.3ms/batch - loss: 2.36485 - diff: 37.84mlTrain batch 5/32 - 92.3ms/batch - loss: 2.80791 - diff: 44.93mlTrain batch 6/32 - 104.7ms/batch - loss: 2.82699 - diff: 45.23mlTrain batch 7/32 - 97.3ms/batch - loss: 2.87610 - diff: 46.02mlTrain batch 8/32 - 108.1ms/batch - loss: 2.76559 - diff: 44.25mlTrain batch 9/32 - 89.9ms/batch - loss: 2.69270 - diff: 43.08mlTrain batch 10/32 - 83.2ms/batch - loss: 2.68891 - diff: 43.02mlTrain batch 11/32 - 79.3ms/batch - loss: 2.71366 - diff: 43.42mlTrain batch 12/32 - 101.4ms/batch - loss: 2.83393 - diff: 45.34mlTrain batch 13/32 - 82.8ms/batch - loss: 2.78422 - diff: 44.55mlTrain batch 14/32 - 113.7ms/batch - loss: 2.76595 - diff: 44.26mlTrain batch 15/32 - 87.4ms/batch - loss: 2.71195 - diff: 43.39mlTrain batch 16/32 - 61.6ms/batch - loss: 2.71348 - diff: 43.42mlTrain batch 17/32 - 101.5ms/batch - loss: 2.73297 - diff: 43.73mlTrain batch 18/32 - 107.6ms/batch - loss: 2.71719 - diff: 43.48mlTrain batch 19/32 - 78.6ms/batch - loss: 2.69443 - diff: 43.11mlTrain batch 20/32 - 91.5ms/batch - loss: 2.64218 - diff: 42.27mlTrain batch 21/32 - 68.6ms/batch - loss: 2.64265 - diff: 42.28mlTrain batch 22/32 - 92.0ms/batch - loss: 2.63945 - diff: 42.23mlTrain batch 23/32 - 90.4ms/batch - loss: 2.60135 - diff: 41.62mlTrain batch 24/32 - 90.1ms/batch - loss: 2.56282 - diff: 41.01mlTrain batch 25/32 - 74.1ms/batch - loss: 2.58355 - diff: 41.34mlTrain batch 26/32 - 85.8ms/batch - loss: 2.56863 - diff: 41.10mlTrain batch 27/32 - 85.6ms/batch - loss: 2.57708 - diff: 41.23mlTrain batch 28/32 - 61.8ms/batch - loss: 2.64932 - diff: 42.39mlTrain batch 29/32 - 89.0ms/batch - loss: 2.62346 - diff: 41.98mlTrain batch 30/32 - 60.8ms/batch - loss: 2.62176 - diff: 41.95mlTrain batch 31/32 - 82.0ms/batch - loss: 2.59483 - diff: 41.52mlTrain batch 32/32 - 53.8ms/batch - loss: 2.63199 - diff: 41.42mlTrain batch 32/32 - 16.8s 53.8ms/batch - loss: 2.63199 - diff: 41.42ml
Test 1.0s: val_loss: 3.13222 - diff: 48.67ml

Epoch 10: current best loss = 2.62991, at epoch 6
Train batch 1/32 - 103.9ms/batch - loss: 2.78494 - diff: 44.56mlTrain batch 2/32 - 83.8ms/batch - loss: 2.39790 - diff: 38.37mlTrain batch 3/32 - 82.1ms/batch - loss: 2.24984 - diff: 36.00mlTrain batch 4/32 - 92.5ms/batch - loss: 2.20358 - diff: 35.26mlTrain batch 5/32 - 83.5ms/batch - loss: 2.32433 - diff: 37.19mlTrain batch 6/32 - 117.3ms/batch - loss: 2.32098 - diff: 37.14mlTrain batch 7/32 - 88.1ms/batch - loss: 2.44074 - diff: 39.05mlTrain batch 8/32 - 91.9ms/batch - loss: 2.50769 - diff: 40.12mlTrain batch 9/32 - 84.8ms/batch - loss: 2.50325 - diff: 40.05mlTrain batch 10/32 - 98.7ms/batch - loss: 2.59323 - diff: 41.49mlTrain batch 11/32 - 62.1ms/batch - loss: 2.56403 - diff: 41.02mlTrain batch 12/32 - 85.1ms/batch - loss: 2.51462 - diff: 40.23mlTrain batch 13/32 - 83.2ms/batch - loss: 2.48676 - diff: 39.79mlTrain batch 14/32 - 91.9ms/batch - loss: 2.46595 - diff: 39.46mlTrain batch 15/32 - 86.9ms/batch - loss: 2.49446 - diff: 39.91mlTrain batch 16/32 - 62.1ms/batch - loss: 2.48597 - diff: 39.78mlTrain batch 17/32 - 74.7ms/batch - loss: 2.47976 - diff: 39.68mlTrain batch 18/32 - 65.3ms/batch - loss: 2.44826 - diff: 39.17mlTrain batch 19/32 - 87.5ms/batch - loss: 2.59001 - diff: 41.44mlTrain batch 20/32 - 115.8ms/batch - loss: 2.59654 - diff: 41.54mlTrain batch 21/32 - 67.8ms/batch - loss: 2.58927 - diff: 41.43mlTrain batch 22/32 - 95.7ms/batch - loss: 2.60930 - diff: 41.75mlTrain batch 23/32 - 88.8ms/batch - loss: 2.63850 - diff: 42.22mlTrain batch 24/32 - 97.9ms/batch - loss: 2.62585 - diff: 42.01mlTrain batch 25/32 - 90.4ms/batch - loss: 2.60675 - diff: 41.71mlTrain batch 26/32 - 112.3ms/batch - loss: 2.59654 - diff: 41.54mlTrain batch 27/32 - 70.7ms/batch - loss: 2.60157 - diff: 41.63mlTrain batch 28/32 - 85.4ms/batch - loss: 2.60405 - diff: 41.66mlTrain batch 29/32 - 93.6ms/batch - loss: 2.58101 - diff: 41.30mlTrain batch 30/32 - 60.8ms/batch - loss: 2.57850 - diff: 41.26mlTrain batch 31/32 - 64.5ms/batch - loss: 2.58264 - diff: 41.32mlTrain batch 32/32 - 93.3ms/batch - loss: 2.66179 - diff: 41.39mlTrain batch 32/32 - 17.2s 93.3ms/batch - loss: 2.66179 - diff: 41.39ml
Test 1.1s: val_loss: 2.82831 - diff: 43.48ml

Epoch 11: current best loss = 2.62991, at epoch 6
Train batch 1/32 - 111.8ms/batch - loss: 3.08103 - diff: 49.30mlTrain batch 2/32 - 75.9ms/batch - loss: 2.44852 - diff: 39.18mlTrain batch 3/32 - 84.3ms/batch - loss: 2.28780 - diff: 36.60mlTrain batch 4/32 - 108.7ms/batch - loss: 2.35397 - diff: 37.66mlTrain batch 5/32 - 91.7ms/batch - loss: 2.24895 - diff: 35.98mlTrain batch 6/32 - 115.4ms/batch - loss: 2.24697 - diff: 35.95mlTrain batch 7/32 - 112.0ms/batch - loss: 2.29164 - diff: 36.67mlTrain batch 8/32 - 117.8ms/batch - loss: 2.34535 - diff: 37.53mlTrain batch 9/32 - 86.0ms/batch - loss: 2.29459 - diff: 36.71mlTrain batch 10/32 - 88.1ms/batch - loss: 2.47700 - diff: 39.63mlTrain batch 11/32 - 71.6ms/batch - loss: 2.47267 - diff: 39.56mlTrain batch 12/32 - 88.0ms/batch - loss: 2.48468 - diff: 39.75mlTrain batch 13/32 - 64.6ms/batch - loss: 2.46793 - diff: 39.49mlTrain batch 14/32 - 109.4ms/batch - loss: 2.51358 - diff: 40.22mlTrain batch 15/32 - 142.8ms/batch - loss: 2.52120 - diff: 40.34mlTrain batch 16/32 - 120.7ms/batch - loss: 2.50853 - diff: 40.14mlTrain batch 17/32 - 78.8ms/batch - loss: 2.52846 - diff: 40.46mlTrain batch 18/32 - 107.7ms/batch - loss: 2.51869 - diff: 40.30mlTrain batch 19/32 - 83.9ms/batch - loss: 2.54509 - diff: 40.72mlTrain batch 20/32 - 103.5ms/batch - loss: 2.58497 - diff: 41.36mlTrain batch 21/32 - 68.7ms/batch - loss: 2.61746 - diff: 41.88mlTrain batch 22/32 - 96.0ms/batch - loss: 2.61061 - diff: 41.77mlTrain batch 23/32 - 88.9ms/batch - loss: 2.64723 - diff: 42.36mlTrain batch 24/32 - 89.1ms/batch - loss: 2.64270 - diff: 42.28mlTrain batch 25/32 - 78.5ms/batch - loss: 2.68364 - diff: 42.94mlTrain batch 26/32 - 68.9ms/batch - loss: 2.64721 - diff: 42.36mlTrain batch 27/32 - 76.9ms/batch - loss: 2.63239 - diff: 42.12mlTrain batch 28/32 - 94.8ms/batch - loss: 2.65102 - diff: 42.42mlTrain batch 29/32 - 64.6ms/batch - loss: 2.67417 - diff: 42.79mlTrain batch 30/32 - 58.0ms/batch - loss: 2.64463 - diff: 42.31mlTrain batch 31/32 - 103.3ms/batch - loss: 2.65215 - diff: 42.43mlTrain batch 32/32 - 61.3ms/batch - loss: 2.74560 - diff: 42.55mlTrain batch 32/32 - 16.5s 61.3ms/batch - loss: 2.74560 - diff: 42.55ml
Test 0.9s: val_loss: 2.59347 - diff: 39.78ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_DenseNet121_0_Adam-0.001_MAE_DA3_best

Epoch 12: current best loss = 2.59347, at epoch 11
Train batch 1/32 - 94.9ms/batch - loss: 2.43313 - diff: 38.93mlTrain batch 2/32 - 89.4ms/batch - loss: 2.25947 - diff: 36.15mlTrain batch 3/32 - 110.4ms/batch - loss: 2.56300 - diff: 41.01mlTrain batch 4/32 - 88.1ms/batch - loss: 2.55844 - diff: 40.94mlTrain batch 5/32 - 74.5ms/batch - loss: 2.70847 - diff: 43.34mlTrain batch 6/32 - 77.9ms/batch - loss: 2.66766 - diff: 42.68mlTrain batch 7/32 - 79.6ms/batch - loss: 2.74537 - diff: 43.93mlTrain batch 8/32 - 73.0ms/batch - loss: 2.65109 - diff: 42.42mlTrain batch 9/32 - 125.2ms/batch - loss: 2.57607 - diff: 41.22mlTrain batch 10/32 - 105.6ms/batch - loss: 2.59520 - diff: 41.52mlTrain batch 11/32 - 91.0ms/batch - loss: 2.76284 - diff: 44.21mlTrain batch 12/32 - 101.0ms/batch - loss: 2.69058 - diff: 43.05mlTrain batch 13/32 - 101.1ms/batch - loss: 2.67805 - diff: 42.85mlTrain batch 14/32 - 93.6ms/batch - loss: 2.64269 - diff: 42.28mlTrain batch 15/32 - 80.7ms/batch - loss: 2.60886 - diff: 41.74mlTrain batch 16/32 - 135.7ms/batch - loss: 2.61644 - diff: 41.86mlTrain batch 17/32 - 82.8ms/batch - loss: 2.62672 - diff: 42.03mlTrain batch 18/32 - 80.4ms/batch - loss: 2.65754 - diff: 42.52mlTrain batch 19/32 - 114.3ms/batch - loss: 2.65629 - diff: 42.50mlTrain batch 20/32 - 134.0ms/batch - loss: 2.61966 - diff: 41.91mlTrain batch 21/32 - 83.8ms/batch - loss: 2.62325 - diff: 41.97mlTrain batch 22/32 - 105.5ms/batch - loss: 2.61729 - diff: 41.88mlTrain batch 23/32 - 114.7ms/batch - loss: 2.62527 - diff: 42.00mlTrain batch 24/32 - 104.8ms/batch - loss: 2.63775 - diff: 42.20mlTrain batch 25/32 - 57.7ms/batch - loss: 2.66613 - diff: 42.66mlTrain batch 26/32 - 90.5ms/batch - loss: 2.64658 - diff: 42.35mlTrain batch 27/32 - 89.7ms/batch - loss: 2.66143 - diff: 42.58mlTrain batch 28/32 - 57.7ms/batch - loss: 2.68398 - diff: 42.94mlTrain batch 29/32 - 71.3ms/batch - loss: 2.67850 - diff: 42.86mlTrain batch 30/32 - 80.5ms/batch - loss: 2.65363 - diff: 42.46mlTrain batch 31/32 - 63.8ms/batch - loss: 2.64463 - diff: 42.31mlTrain batch 32/32 - 56.4ms/batch - loss: 2.70371 - diff: 42.30mlTrain batch 32/32 - 16.9s 56.4ms/batch - loss: 2.70371 - diff: 42.30ml
Test 1.1s: val_loss: 2.42605 - diff: 36.84ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_DenseNet121_0_Adam-0.001_MAE_DA3_best

Epoch 13: current best loss = 2.42605, at epoch 12
Train batch 1/32 - 79.6ms/batch - loss: 3.37057 - diff: 53.93mlTrain batch 2/32 - 108.1ms/batch - loss: 2.73471 - diff: 43.76mlTrain batch 3/32 - 70.1ms/batch - loss: 2.62986 - diff: 42.08mlTrain batch 4/32 - 58.1ms/batch - loss: 2.61941 - diff: 41.91mlTrain batch 5/32 - 78.7ms/batch - loss: 2.70512 - diff: 43.28mlTrain batch 6/32 - 94.2ms/batch - loss: 2.73825 - diff: 43.81mlTrain batch 7/32 - 77.8ms/batch - loss: 2.60034 - diff: 41.61mlTrain batch 8/32 - 81.7ms/batch - loss: 2.51972 - diff: 40.32mlTrain batch 9/32 - 83.2ms/batch - loss: 2.44706 - diff: 39.15mlTrain batch 10/32 - 81.9ms/batch - loss: 2.42164 - diff: 38.75mlTrain batch 11/32 - 76.8ms/batch - loss: 2.45026 - diff: 39.20mlTrain batch 12/32 - 92.1ms/batch - loss: 2.46318 - diff: 39.41mlTrain batch 13/32 - 96.0ms/batch - loss: 2.47874 - diff: 39.66mlTrain batch 14/32 - 98.6ms/batch - loss: 2.47390 - diff: 39.58mlTrain batch 15/32 - 72.0ms/batch - loss: 2.52411 - diff: 40.39mlTrain batch 16/32 - 73.8ms/batch - loss: 2.51793 - diff: 40.29mlTrain batch 17/32 - 63.2ms/batch - loss: 2.48615 - diff: 39.78mlTrain batch 18/32 - 92.6ms/batch - loss: 2.44990 - diff: 39.20mlTrain batch 19/32 - 107.5ms/batch - loss: 2.43515 - diff: 38.96mlTrain batch 20/32 - 83.1ms/batch - loss: 2.41060 - diff: 38.57mlTrain batch 21/32 - 76.8ms/batch - loss: 2.42197 - diff: 38.75mlTrain batch 22/32 - 82.0ms/batch - loss: 2.39027 - diff: 38.24mlTrain batch 23/32 - 89.7ms/batch - loss: 2.39066 - diff: 38.25mlTrain batch 24/32 - 88.9ms/batch - loss: 2.38709 - diff: 38.19mlTrain batch 25/32 - 97.2ms/batch - loss: 2.40498 - diff: 38.48mlTrain batch 26/32 - 92.0ms/batch - loss: 2.39737 - diff: 38.36mlTrain batch 27/32 - 92.7ms/batch - loss: 2.43655 - diff: 38.98mlTrain batch 28/32 - 84.3ms/batch - loss: 2.47607 - diff: 39.62mlTrain batch 29/32 - 78.1ms/batch - loss: 2.52464 - diff: 40.39mlTrain batch 30/32 - 105.6ms/batch - loss: 2.50953 - diff: 40.15mlTrain batch 31/32 - 62.8ms/batch - loss: 2.50704 - diff: 40.11mlTrain batch 32/32 - 82.3ms/batch - loss: 2.59358 - diff: 40.22mlTrain batch 32/32 - 17.0s 82.3ms/batch - loss: 2.59358 - diff: 40.22ml
Test 1.2s: val_loss: 2.66898 - diff: 41.37ml

Epoch 14: current best loss = 2.42605, at epoch 12
Train batch 1/32 - 116.5ms/batch - loss: 3.08402 - diff: 49.34mlTrain batch 2/32 - 109.8ms/batch - loss: 2.79200 - diff: 44.67mlTrain batch 3/32 - 85.0ms/batch - loss: 2.35943 - diff: 37.75mlTrain batch 4/32 - 75.6ms/batch - loss: 2.42534 - diff: 38.81mlTrain batch 5/32 - 73.0ms/batch - loss: 2.34344 - diff: 37.50mlTrain batch 6/32 - 90.5ms/batch - loss: 2.36600 - diff: 37.86mlTrain batch 7/32 - 82.4ms/batch - loss: 2.42202 - diff: 38.75mlTrain batch 8/32 - 76.4ms/batch - loss: 2.36924 - diff: 37.91mlTrain batch 9/32 - 102.4ms/batch - loss: 2.42850 - diff: 38.86mlTrain batch 10/32 - 90.1ms/batch - loss: 2.59503 - diff: 41.52mlTrain batch 11/32 - 115.4ms/batch - loss: 2.54482 - diff: 40.72mlTrain batch 12/32 - 112.6ms/batch - loss: 2.53673 - diff: 40.59mlTrain batch 13/32 - 106.9ms/batch - loss: 2.55571 - diff: 40.89mlTrain batch 14/32 - 99.6ms/batch - loss: 2.60104 - diff: 41.62mlTrain batch 15/32 - 95.4ms/batch - loss: 2.55066 - diff: 40.81mlTrain batch 16/32 - 60.1ms/batch - loss: 2.56320 - diff: 41.01mlTrain batch 17/32 - 107.8ms/batch - loss: 2.56057 - diff: 40.97mlTrain batch 18/32 - 61.8ms/batch - loss: 2.47020 - diff: 39.52mlTrain batch 19/32 - 82.3ms/batch - loss: 2.44231 - diff: 39.08mlTrain batch 20/32 - 86.4ms/batch - loss: 2.39017 - diff: 38.24mlTrain batch 21/32 - 78.0ms/batch - loss: 2.42275 - diff: 38.76mlTrain batch 22/32 - 76.1ms/batch - loss: 2.39036 - diff: 38.25mlTrain batch 23/32 - 80.6ms/batch - loss: 2.36777 - diff: 37.88mlTrain batch 24/32 - 90.9ms/batch - loss: 2.36953 - diff: 37.91mlTrain batch 25/32 - 65.3ms/batch - loss: 2.35338 - diff: 37.65mlTrain batch 26/32 - 77.5ms/batch - loss: 2.37101 - diff: 37.94mlTrain batch 27/32 - 99.9ms/batch - loss: 2.40992 - diff: 38.56mlTrain batch 28/32 - 131.9ms/batch - loss: 2.42728 - diff: 38.84mlTrain batch 29/32 - 91.3ms/batch - loss: 2.41195 - diff: 38.59mlTrain batch 30/32 - 92.7ms/batch - loss: 2.40904 - diff: 38.54mlTrain batch 31/32 - 93.4ms/batch - loss: 2.44012 - diff: 39.04mlTrain batch 32/32 - 75.4ms/batch - loss: 2.45918 - diff: 38.88mlTrain batch 32/32 - 16.8s 75.4ms/batch - loss: 2.45918 - diff: 38.88ml
Test 1.0s: val_loss: 2.41108 - diff: 37.62ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_DenseNet121_0_Adam-0.001_MAE_DA3_best

Epoch 15: current best loss = 2.41108, at epoch 14
Train batch 1/32 - 76.5ms/batch - loss: 2.03774 - diff: 32.60mlTrain batch 2/32 - 84.2ms/batch - loss: 1.79168 - diff: 28.67mlTrain batch 3/32 - 61.5ms/batch - loss: 1.82915 - diff: 29.27mlTrain batch 4/32 - 96.3ms/batch - loss: 1.93093 - diff: 30.89mlTrain batch 5/32 - 85.8ms/batch - loss: 1.98474 - diff: 31.76mlTrain batch 6/32 - 77.3ms/batch - loss: 1.99581 - diff: 31.93mlTrain batch 7/32 - 59.3ms/batch - loss: 2.04698 - diff: 32.75mlTrain batch 8/32 - 64.8ms/batch - loss: 2.09401 - diff: 33.50mlTrain batch 9/32 - 58.7ms/batch - loss: 2.18925 - diff: 35.03mlTrain batch 10/32 - 101.0ms/batch - loss: 2.09470 - diff: 33.52mlTrain batch 11/32 - 61.0ms/batch - loss: 2.13424 - diff: 34.15mlTrain batch 12/32 - 87.7ms/batch - loss: 2.25367 - diff: 36.06mlTrain batch 13/32 - 89.3ms/batch - loss: 2.26974 - diff: 36.32mlTrain batch 14/32 - 66.4ms/batch - loss: 2.23786 - diff: 35.81mlTrain batch 15/32 - 61.6ms/batch - loss: 2.21136 - diff: 35.38mlTrain batch 16/32 - 79.6ms/batch - loss: 2.29589 - diff: 36.73mlTrain batch 17/32 - 93.5ms/batch - loss: 2.30419 - diff: 36.87mlTrain batch 18/32 - 91.1ms/batch - loss: 2.25944 - diff: 36.15mlTrain batch 19/32 - 107.7ms/batch - loss: 2.30915 - diff: 36.95mlTrain batch 20/32 - 73.2ms/batch - loss: 2.27712 - diff: 36.43mlTrain batch 21/32 - 98.9ms/batch - loss: 2.26556 - diff: 36.25mlTrain batch 22/32 - 80.7ms/batch - loss: 2.26804 - diff: 36.29mlTrain batch 23/32 - 61.0ms/batch - loss: 2.27975 - diff: 36.48mlTrain batch 24/32 - 85.4ms/batch - loss: 2.30420 - diff: 36.87mlTrain batch 25/32 - 87.3ms/batch - loss: 2.30233 - diff: 36.84mlTrain batch 26/32 - 81.6ms/batch - loss: 2.34469 - diff: 37.52mlTrain batch 27/32 - 101.6ms/batch - loss: 2.33810 - diff: 37.41mlTrain batch 28/32 - 58.7ms/batch - loss: 2.35840 - diff: 37.73mlTrain batch 29/32 - 98.3ms/batch - loss: 2.38331 - diff: 38.13mlTrain batch 30/32 - 75.1ms/batch - loss: 2.43084 - diff: 38.89mlTrain batch 31/32 - 107.1ms/batch - loss: 2.42104 - diff: 38.74mlTrain batch 32/32 - 79.9ms/batch - loss: 2.47293 - diff: 38.71mlTrain batch 32/32 - 16.3s 79.9ms/batch - loss: 2.47293 - diff: 38.71ml
Test 1.3s: val_loss: 2.57921 - diff: 39.98ml

Epoch 16: current best loss = 2.41108, at epoch 14
Train batch 1/32 - 80.1ms/batch - loss: 1.70259 - diff: 27.24mlTrain batch 2/32 - 101.9ms/batch - loss: 1.95478 - diff: 31.28mlTrain batch 3/32 - 87.4ms/batch - loss: 2.03454 - diff: 32.55mlTrain batch 4/32 - 97.9ms/batch - loss: 2.15803 - diff: 34.53mlTrain batch 5/32 - 100.6ms/batch - loss: 2.09521 - diff: 33.52mlTrain batch 6/32 - 76.2ms/batch - loss: 2.11936 - diff: 33.91mlTrain batch 7/32 - 99.0ms/batch - loss: 2.07168 - diff: 33.15mlTrain batch 8/32 - 94.4ms/batch - loss: 2.18357 - diff: 34.94mlTrain batch 9/32 - 86.3ms/batch - loss: 2.17189 - diff: 34.75mlTrain batch 10/32 - 70.8ms/batch - loss: 2.16510 - diff: 34.64mlTrain batch 11/32 - 68.7ms/batch - loss: 2.31039 - diff: 36.97mlTrain batch 12/32 - 69.0ms/batch - loss: 2.27244 - diff: 36.36mlTrain batch 13/32 - 64.7ms/batch - loss: 2.24457 - diff: 35.91mlTrain batch 14/32 - 84.0ms/batch - loss: 2.31928 - diff: 37.11mlTrain batch 15/32 - 111.6ms/batch - loss: 2.43392 - diff: 38.94mlTrain batch 16/32 - 116.0ms/batch - loss: 2.49014 - diff: 39.84mlTrain batch 17/32 - 78.6ms/batch - loss: 2.42908 - diff: 38.87mlTrain batch 18/32 - 89.7ms/batch - loss: 2.45574 - diff: 39.29mlTrain batch 19/32 - 89.6ms/batch - loss: 2.47420 - diff: 39.59mlTrain batch 20/32 - 93.7ms/batch - loss: 2.46739 - diff: 39.48mlTrain batch 21/32 - 122.1ms/batch - loss: 2.44742 - diff: 39.16mlTrain batch 22/32 - 123.2ms/batch - loss: 2.50059 - diff: 40.01mlTrain batch 23/32 - 72.7ms/batch - loss: 2.46233 - diff: 39.40mlTrain batch 24/32 - 93.4ms/batch - loss: 2.50335 - diff: 40.05mlTrain batch 25/32 - 82.2ms/batch - loss: 2.47100 - diff: 39.54mlTrain batch 26/32 - 73.8ms/batch - loss: 2.44151 - diff: 39.06mlTrain batch 27/32 - 69.9ms/batch - loss: 2.47005 - diff: 39.52mlTrain batch 28/32 - 103.4ms/batch - loss: 2.47635 - diff: 39.62mlTrain batch 29/32 - 101.0ms/batch - loss: 2.45817 - diff: 39.33mlTrain batch 30/32 - 99.3ms/batch - loss: 2.44123 - diff: 39.06mlTrain batch 31/32 - 65.1ms/batch - loss: 2.44809 - diff: 39.17mlTrain batch 32/32 - 74.6ms/batch - loss: 2.52403 - diff: 39.24mlTrain batch 32/32 - 16.4s 74.6ms/batch - loss: 2.52403 - diff: 39.24ml
Test 1.1s: val_loss: 2.38112 - diff: 36.38ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_DenseNet121_0_Adam-0.001_MAE_DA3_best

Epoch 17: current best loss = 2.38112, at epoch 16
Train batch 1/32 - 84.2ms/batch - loss: 2.00847 - diff: 32.14mlTrain batch 2/32 - 79.6ms/batch - loss: 2.26857 - diff: 36.30mlTrain batch 3/32 - 82.3ms/batch - loss: 2.37955 - diff: 38.07mlTrain batch 4/32 - 88.4ms/batch - loss: 2.06398 - diff: 33.02mlTrain batch 5/32 - 63.8ms/batch - loss: 2.12946 - diff: 34.07mlTrain batch 6/32 - 77.9ms/batch - loss: 2.10517 - diff: 33.68mlTrain batch 7/32 - 60.7ms/batch - loss: 2.19955 - diff: 35.19mlTrain batch 8/32 - 77.1ms/batch - loss: 2.16135 - diff: 34.58mlTrain batch 9/32 - 82.5ms/batch - loss: 2.17120 - diff: 34.74mlTrain batch 10/32 - 74.2ms/batch - loss: 2.26824 - diff: 36.29mlTrain batch 11/32 - 71.2ms/batch - loss: 2.26083 - diff: 36.17mlTrain batch 12/32 - 86.5ms/batch - loss: 2.23404 - diff: 35.74mlTrain batch 13/32 - 64.1ms/batch - loss: 2.24960 - diff: 35.99mlTrain batch 14/32 - 98.1ms/batch - loss: 2.27326 - diff: 36.37mlTrain batch 15/32 - 97.9ms/batch - loss: 2.28501 - diff: 36.56mlTrain batch 16/32 - 84.1ms/batch - loss: 2.31692 - diff: 37.07mlTrain batch 17/32 - 77.0ms/batch - loss: 2.31879 - diff: 37.10mlTrain batch 18/32 - 89.9ms/batch - loss: 2.31102 - diff: 36.98mlTrain batch 19/32 - 82.2ms/batch - loss: 2.30346 - diff: 36.86mlTrain batch 20/32 - 73.9ms/batch - loss: 2.26020 - diff: 36.16mlTrain batch 21/32 - 73.0ms/batch - loss: 2.26684 - diff: 36.27mlTrain batch 22/32 - 74.4ms/batch - loss: 2.29114 - diff: 36.66mlTrain batch 23/32 - 75.5ms/batch - loss: 2.35192 - diff: 37.63mlTrain batch 24/32 - 68.9ms/batch - loss: 2.30574 - diff: 36.89mlTrain batch 25/32 - 88.4ms/batch - loss: 2.30932 - diff: 36.95mlTrain batch 26/32 - 81.0ms/batch - loss: 2.33031 - diff: 37.28mlTrain batch 27/32 - 73.8ms/batch - loss: 2.36446 - diff: 37.83mlTrain batch 28/32 - 83.1ms/batch - loss: 2.36456 - diff: 37.83mlTrain batch 29/32 - 60.5ms/batch - loss: 2.35055 - diff: 37.61mlTrain batch 30/32 - 82.7ms/batch - loss: 2.34534 - diff: 37.53mlTrain batch 31/32 - 80.9ms/batch - loss: 2.36812 - diff: 37.89mlTrain batch 32/32 - 64.7ms/batch - loss: 2.41525 - diff: 37.85mlTrain batch 32/32 - 16.3s 64.7ms/batch - loss: 2.41525 - diff: 37.85ml
Test 1.0s: val_loss: 2.31406 - diff: 35.67ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_DenseNet121_0_Adam-0.001_MAE_DA3_best

Epoch 18: current best loss = 2.31406, at epoch 17
Train batch 1/32 - 116.3ms/batch - loss: 2.45755 - diff: 39.32mlTrain batch 2/32 - 109.1ms/batch - loss: 2.38862 - diff: 38.22mlTrain batch 3/32 - 107.5ms/batch - loss: 2.35166 - diff: 37.63mlTrain batch 4/32 - 62.2ms/batch - loss: 2.60327 - diff: 41.65mlTrain batch 5/32 - 87.3ms/batch - loss: 2.51017 - diff: 40.16mlTrain batch 6/32 - 109.4ms/batch - loss: 2.48822 - diff: 39.81mlTrain batch 7/32 - 82.5ms/batch - loss: 2.52297 - diff: 40.37mlTrain batch 8/32 - 102.1ms/batch - loss: 2.55086 - diff: 40.81mlTrain batch 9/32 - 84.7ms/batch - loss: 2.48183 - diff: 39.71mlTrain batch 10/32 - 92.0ms/batch - loss: 2.33110 - diff: 37.30mlTrain batch 11/32 - 79.0ms/batch - loss: 2.43887 - diff: 39.02mlTrain batch 12/32 - 80.0ms/batch - loss: 2.41859 - diff: 38.70mlTrain batch 13/32 - 99.1ms/batch - loss: 2.52441 - diff: 40.39mlTrain batch 14/32 - 81.3ms/batch - loss: 2.49367 - diff: 39.90mlTrain batch 15/32 - 72.4ms/batch - loss: 2.51326 - diff: 40.21mlTrain batch 16/32 - 87.7ms/batch - loss: 2.57832 - diff: 41.25mlTrain batch 17/32 - 75.5ms/batch - loss: 2.58003 - diff: 41.28mlTrain batch 18/32 - 82.5ms/batch - loss: 2.61253 - diff: 41.80mlTrain batch 19/32 - 74.7ms/batch - loss: 2.56754 - diff: 41.08mlTrain batch 20/32 - 101.8ms/batch - loss: 2.54655 - diff: 40.74mlTrain batch 21/32 - 81.2ms/batch - loss: 2.56376 - diff: 41.02mlTrain batch 22/32 - 76.3ms/batch - loss: 2.53243 - diff: 40.52mlTrain batch 23/32 - 77.5ms/batch - loss: 2.56001 - diff: 40.96mlTrain batch 24/32 - 94.5ms/batch - loss: 2.55485 - diff: 40.88mlTrain batch 25/32 - 93.1ms/batch - loss: 2.54769 - diff: 40.76mlTrain batch 26/32 - 63.8ms/batch - loss: 2.52254 - diff: 40.36mlTrain batch 27/32 - 83.9ms/batch - loss: 2.49923 - diff: 39.99mlTrain batch 28/32 - 75.8ms/batch - loss: 2.46895 - diff: 39.50mlTrain batch 29/32 - 59.5ms/batch - loss: 2.48028 - diff: 39.68mlTrain batch 30/32 - 104.1ms/batch - loss: 2.47015 - diff: 39.52mlTrain batch 31/32 - 105.0ms/batch - loss: 2.44996 - diff: 39.20mlTrain batch 32/32 - 70.8ms/batch - loss: 2.49257 - diff: 39.13mlTrain batch 32/32 - 16.0s 70.8ms/batch - loss: 2.49257 - diff: 39.13ml
Test 1.0s: val_loss: 2.20785 - diff: 34.32ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_DenseNet121_0_Adam-0.001_MAE_DA3_best

Epoch 19: current best loss = 2.20785, at epoch 18
Train batch 1/32 - 106.2ms/batch - loss: 2.35737 - diff: 37.72mlTrain batch 2/32 - 100.7ms/batch - loss: 2.01530 - diff: 32.24mlTrain batch 3/32 - 81.8ms/batch - loss: 2.23460 - diff: 35.75mlTrain batch 4/32 - 97.4ms/batch - loss: 2.23897 - diff: 35.82mlTrain batch 5/32 - 92.8ms/batch - loss: 2.23819 - diff: 35.81mlTrain batch 6/32 - 83.7ms/batch - loss: 2.15078 - diff: 34.41mlTrain batch 7/32 - 64.2ms/batch - loss: 2.08650 - diff: 33.38mlTrain batch 8/32 - 95.8ms/batch - loss: 2.09531 - diff: 33.52mlTrain batch 9/32 - 96.1ms/batch - loss: 2.04714 - diff: 32.75mlTrain batch 10/32 - 111.9ms/batch - loss: 2.03364 - diff: 32.54mlTrain batch 11/32 - 96.1ms/batch - loss: 2.05974 - diff: 32.96mlTrain batch 12/32 - 112.6ms/batch - loss: 2.12796 - diff: 34.05mlTrain batch 13/32 - 97.3ms/batch - loss: 2.17438 - diff: 34.79mlTrain batch 14/32 - 81.5ms/batch - loss: 2.15247 - diff: 34.44mlTrain batch 15/32 - 78.1ms/batch - loss: 2.21626 - diff: 35.46mlTrain batch 16/32 - 64.9ms/batch - loss: 2.19908 - diff: 35.19mlTrain batch 17/32 - 97.8ms/batch - loss: 2.23534 - diff: 35.77mlTrain batch 18/32 - 61.9ms/batch - loss: 2.26728 - diff: 36.28mlTrain batch 19/32 - 67.3ms/batch - loss: 2.25284 - diff: 36.05mlTrain batch 20/32 - 101.2ms/batch - loss: 2.27256 - diff: 36.36mlTrain batch 21/32 - 76.0ms/batch - loss: 2.24100 - diff: 35.86mlTrain batch 22/32 - 83.7ms/batch - loss: 2.29781 - diff: 36.76mlTrain batch 23/32 - 89.9ms/batch - loss: 2.30189 - diff: 36.83mlTrain batch 24/32 - 94.1ms/batch - loss: 2.28261 - diff: 36.52mlTrain batch 25/32 - 85.3ms/batch - loss: 2.26977 - diff: 36.32mlTrain batch 26/32 - 93.1ms/batch - loss: 2.29570 - diff: 36.73mlTrain batch 27/32 - 95.9ms/batch - loss: 2.28453 - diff: 36.55mlTrain batch 28/32 - 106.3ms/batch - loss: 2.29139 - diff: 36.66mlTrain batch 29/32 - 63.6ms/batch - loss: 2.29802 - diff: 36.77mlTrain batch 30/32 - 59.4ms/batch - loss: 2.30368 - diff: 36.86mlTrain batch 31/32 - 59.1ms/batch - loss: 2.33109 - diff: 37.30mlTrain batch 32/32 - 74.6ms/batch - loss: 2.36313 - diff: 37.20mlTrain batch 32/32 - 17.2s 74.6ms/batch - loss: 2.36313 - diff: 37.20ml
Test 1.0s: val_loss: 2.26835 - diff: 35.14ml

Epoch 20: current best loss = 2.20785, at epoch 18
Train batch 1/32 - 94.1ms/batch - loss: 2.64618 - diff: 42.34mlTrain batch 2/32 - 85.2ms/batch - loss: 2.14458 - diff: 34.31mlTrain batch 3/32 - 97.1ms/batch - loss: 2.16719 - diff: 34.68mlTrain batch 4/32 - 109.9ms/batch - loss: 2.51616 - diff: 40.26mlTrain batch 5/32 - 91.9ms/batch - loss: 2.38344 - diff: 38.14mlTrain batch 6/32 - 97.2ms/batch - loss: 2.44437 - diff: 39.11mlTrain batch 7/32 - 89.7ms/batch - loss: 2.64981 - diff: 42.40mlTrain batch 8/32 - 74.5ms/batch - loss: 2.51561 - diff: 40.25mlTrain batch 9/32 - 79.1ms/batch - loss: 2.46050 - diff: 39.37mlTrain batch 10/32 - 62.3ms/batch - loss: 2.55584 - diff: 40.89mlTrain batch 11/32 - 88.6ms/batch - loss: 2.49482 - diff: 39.92mlTrain batch 12/32 - 88.8ms/batch - loss: 2.45810 - diff: 39.33mlTrain batch 13/32 - 77.8ms/batch - loss: 2.42952 - diff: 38.87mlTrain batch 14/32 - 80.9ms/batch - loss: 2.41493 - diff: 38.64mlTrain batch 15/32 - 80.0ms/batch - loss: 2.39411 - diff: 38.31mlTrain batch 16/32 - 83.3ms/batch - loss: 2.44457 - diff: 39.11mlTrain batch 17/32 - 77.7ms/batch - loss: 2.40394 - diff: 38.46mlTrain batch 18/32 - 75.8ms/batch - loss: 2.42321 - diff: 38.77mlTrain batch 19/32 - 85.1ms/batch - loss: 2.42776 - diff: 38.84mlTrain batch 20/32 - 85.5ms/batch - loss: 2.38768 - diff: 38.20mlTrain batch 21/32 - 92.8ms/batch - loss: 2.39288 - diff: 38.29mlTrain batch 22/32 - 99.6ms/batch - loss: 2.41821 - diff: 38.69mlTrain batch 23/32 - 102.8ms/batch - loss: 2.42079 - diff: 38.73mlTrain batch 24/32 - 97.3ms/batch - loss: 2.40455 - diff: 38.47mlTrain batch 25/32 - 92.9ms/batch - loss: 2.39806 - diff: 38.37mlTrain batch 26/32 - 94.7ms/batch - loss: 2.38069 - diff: 38.09mlTrain batch 27/32 - 110.4ms/batch - loss: 2.39038 - diff: 38.25mlTrain batch 28/32 - 90.0ms/batch - loss: 2.40344 - diff: 38.46mlTrain batch 29/32 - 66.2ms/batch - loss: 2.41421 - diff: 38.63mlTrain batch 30/32 - 94.4ms/batch - loss: 2.40557 - diff: 38.49mlTrain batch 31/32 - 62.7ms/batch - loss: 2.38969 - diff: 38.24mlTrain batch 32/32 - 59.2ms/batch - loss: 2.41830 - diff: 38.12mlTrain batch 32/32 - 16.6s 59.2ms/batch - loss: 2.41830 - diff: 38.12ml
Test 1.0s: val_loss: 2.39776 - diff: 36.76ml

Epoch 21: current best loss = 2.20785, at epoch 18
Train batch 1/32 - 98.4ms/batch - loss: 2.56056 - diff: 40.97mlTrain batch 2/32 - 81.9ms/batch - loss: 2.04303 - diff: 32.69mlTrain batch 3/32 - 81.7ms/batch - loss: 1.97772 - diff: 31.64mlTrain batch 4/32 - 83.2ms/batch - loss: 2.02838 - diff: 32.45mlTrain batch 5/32 - 92.7ms/batch - loss: 2.11769 - diff: 33.88mlTrain batch 6/32 - 64.5ms/batch - loss: 2.24695 - diff: 35.95mlTrain batch 7/32 - 61.3ms/batch - loss: 2.16369 - diff: 34.62mlTrain batch 8/32 - 96.5ms/batch - loss: 2.09288 - diff: 33.49mlTrain batch 9/32 - 76.0ms/batch - loss: 2.05210 - diff: 32.83mlTrain batch 10/32 - 81.0ms/batch - loss: 2.06646 - diff: 33.06mlTrain batch 11/32 - 79.9ms/batch - loss: 2.05725 - diff: 32.92mlTrain batch 12/32 - 94.1ms/batch - loss: 2.07521 - diff: 33.20mlTrain batch 13/32 - 84.1ms/batch - loss: 2.10259 - diff: 33.64mlTrain batch 14/32 - 80.5ms/batch - loss: 2.14810 - diff: 34.37mlTrain batch 15/32 - 108.2ms/batch - loss: 2.17459 - diff: 34.79mlTrain batch 16/32 - 73.9ms/batch - loss: 2.17340 - diff: 34.77mlTrain batch 17/32 - 104.3ms/batch - loss: 2.20614 - diff: 35.30mlTrain batch 18/32 - 80.5ms/batch - loss: 2.32887 - diff: 37.26mlTrain batch 19/32 - 61.7ms/batch - loss: 2.31157 - diff: 36.99mlTrain batch 20/32 - 62.8ms/batch - loss: 2.28537 - diff: 36.57mlTrain batch 21/32 - 60.9ms/batch - loss: 2.30960 - diff: 36.95mlTrain batch 22/32 - 60.6ms/batch - loss: 2.37603 - diff: 38.02mlTrain batch 23/32 - 64.3ms/batch - loss: 2.35940 - diff: 37.75mlTrain batch 24/32 - 81.1ms/batch - loss: 2.36180 - diff: 37.79mlTrain batch 25/32 - 90.4ms/batch - loss: 2.35129 - diff: 37.62mlTrain batch 26/32 - 92.1ms/batch - loss: 2.36344 - diff: 37.82mlTrain batch 27/32 - 110.7ms/batch - loss: 2.36910 - diff: 37.91mlTrain batch 28/32 - 91.7ms/batch - loss: 2.35413 - diff: 37.67mlTrain batch 29/32 - 102.9ms/batch - loss: 2.34085 - diff: 37.45mlTrain batch 30/32 - 76.1ms/batch - loss: 2.36050 - diff: 37.77mlTrain batch 31/32 - 94.0ms/batch - loss: 2.32714 - diff: 37.23mlTrain batch 32/32 - 76.3ms/batch - loss: 2.38719 - diff: 37.25mlTrain batch 32/32 - 16.7s 76.3ms/batch - loss: 2.38719 - diff: 37.25ml
Test 1.1s: val_loss: 2.19832 - diff: 33.06ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_DenseNet121_0_Adam-0.001_MAE_DA3_best

Epoch 22: current best loss = 2.19832, at epoch 21
Train batch 1/32 - 89.5ms/batch - loss: 1.25991 - diff: 20.16mlTrain batch 2/32 - 80.1ms/batch - loss: 1.66715 - diff: 26.67mlTrain batch 3/32 - 62.4ms/batch - loss: 1.92120 - diff: 30.74mlTrain batch 4/32 - 62.7ms/batch - loss: 1.95211 - diff: 31.23mlTrain batch 5/32 - 95.0ms/batch - loss: 1.89884 - diff: 30.38mlTrain batch 6/32 - 84.1ms/batch - loss: 1.94204 - diff: 31.07mlTrain batch 7/32 - 73.0ms/batch - loss: 2.05399 - diff: 32.86mlTrain batch 8/32 - 90.0ms/batch - loss: 2.07637 - diff: 33.22mlTrain batch 9/32 - 86.1ms/batch - loss: 2.08956 - diff: 33.43mlTrain batch 10/32 - 81.7ms/batch - loss: 2.04710 - diff: 32.75mlTrain batch 11/32 - 83.3ms/batch - loss: 2.19088 - diff: 35.05mlTrain batch 12/32 - 90.7ms/batch - loss: 2.29404 - diff: 36.70mlTrain batch 13/32 - 100.0ms/batch - loss: 2.23439 - diff: 35.75mlTrain batch 14/32 - 95.4ms/batch - loss: 2.19973 - diff: 35.20mlTrain batch 15/32 - 73.6ms/batch - loss: 2.17619 - diff: 34.82mlTrain batch 16/32 - 74.3ms/batch - loss: 2.24904 - diff: 35.98mlTrain batch 17/32 - 82.5ms/batch - loss: 2.20874 - diff: 35.34mlTrain batch 18/32 - 97.1ms/batch - loss: 2.19587 - diff: 35.13mlTrain batch 19/32 - 102.0ms/batch - loss: 2.20137 - diff: 35.22mlTrain batch 20/32 - 108.5ms/batch - loss: 2.23911 - diff: 35.83mlTrain batch 21/32 - 70.6ms/batch - loss: 2.25678 - diff: 36.11mlTrain batch 22/32 - 81.3ms/batch - loss: 2.28850 - diff: 36.62mlTrain batch 23/32 - 77.1ms/batch - loss: 2.28632 - diff: 36.58mlTrain batch 24/32 - 84.2ms/batch - loss: 2.30828 - diff: 36.93mlTrain batch 25/32 - 74.1ms/batch - loss: 2.30748 - diff: 36.92mlTrain batch 26/32 - 72.7ms/batch - loss: 2.29308 - diff: 36.69mlTrain batch 27/32 - 77.3ms/batch - loss: 2.27532 - diff: 36.41mlTrain batch 28/32 - 82.9ms/batch - loss: 2.30263 - diff: 36.84mlTrain batch 29/32 - 101.0ms/batch - loss: 2.27952 - diff: 36.47mlTrain batch 30/32 - 79.5ms/batch - loss: 2.29391 - diff: 36.70mlTrain batch 31/32 - 66.1ms/batch - loss: 2.27247 - diff: 36.36mlTrain batch 32/32 - 62.4ms/batch - loss: 2.33026 - diff: 36.37mlTrain batch 32/32 - 17.4s 62.4ms/batch - loss: 2.33026 - diff: 36.37ml
Test 1.1s: val_loss: 2.25758 - diff: 34.85ml

Epoch 23: current best loss = 2.19832, at epoch 21
Train batch 1/32 - 75.5ms/batch - loss: 1.82452 - diff: 29.19mlTrain batch 2/32 - 74.1ms/batch - loss: 2.44414 - diff: 39.11mlTrain batch 3/32 - 69.2ms/batch - loss: 2.45067 - diff: 39.21mlTrain batch 4/32 - 90.2ms/batch - loss: 2.40698 - diff: 38.51mlTrain batch 5/32 - 82.8ms/batch - loss: 2.26458 - diff: 36.23mlTrain batch 6/32 - 75.6ms/batch - loss: 2.27291 - diff: 36.37mlTrain batch 7/32 - 77.2ms/batch - loss: 2.29109 - diff: 36.66mlTrain batch 8/32 - 86.6ms/batch - loss: 2.24697 - diff: 35.95mlTrain batch 9/32 - 96.6ms/batch - loss: 2.34728 - diff: 37.56mlTrain batch 10/32 - 77.4ms/batch - loss: 2.27143 - diff: 36.34mlTrain batch 11/32 - 83.1ms/batch - loss: 2.26532 - diff: 36.25mlTrain batch 12/32 - 76.1ms/batch - loss: 2.28015 - diff: 36.48mlTrain batch 13/32 - 94.8ms/batch - loss: 2.29732 - diff: 36.76mlTrain batch 14/32 - 103.8ms/batch - loss: 2.29563 - diff: 36.73mlTrain batch 15/32 - 78.5ms/batch - loss: 2.22901 - diff: 35.66mlTrain batch 16/32 - 80.2ms/batch - loss: 2.19806 - diff: 35.17mlTrain batch 17/32 - 63.3ms/batch - loss: 2.15893 - diff: 34.54mlTrain batch 18/32 - 100.1ms/batch - loss: 2.15171 - diff: 34.43mlTrain batch 19/32 - 83.0ms/batch - loss: 2.15048 - diff: 34.41mlTrain batch 20/32 - 108.1ms/batch - loss: 2.14277 - diff: 34.28mlTrain batch 21/32 - 87.6ms/batch - loss: 2.16651 - diff: 34.66mlTrain batch 22/32 - 74.9ms/batch - loss: 2.19381 - diff: 35.10mlTrain batch 23/32 - 62.7ms/batch - loss: 2.20774 - diff: 35.32mlTrain batch 24/32 - 80.4ms/batch - loss: 2.17784 - diff: 34.85mlTrain batch 25/32 - 76.3ms/batch - loss: 2.17520 - diff: 34.80mlTrain batch 26/32 - 86.9ms/batch - loss: 2.17786 - diff: 34.85mlTrain batch 27/32 - 60.8ms/batch - loss: 2.18578 - diff: 34.97mlTrain batch 28/32 - 95.4ms/batch - loss: 2.21319 - diff: 35.41mlTrain batch 29/32 - 107.5ms/batch - loss: 2.23645 - diff: 35.78mlTrain batch 30/32 - 91.2ms/batch - loss: 2.25022 - diff: 36.00mlTrain batch 31/32 - 88.5ms/batch - loss: 2.25912 - diff: 36.15mlTrain batch 32/32 - 50.1ms/batch - loss: 2.35238 - diff: 36.30mlTrain batch 32/32 - 16.8s 50.1ms/batch - loss: 2.35238 - diff: 36.30ml
Test 1.1s: val_loss: 2.08915 - diff: 32.04ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_DenseNet121_0_Adam-0.001_MAE_DA3_best

Epoch 24: current best loss = 2.08915, at epoch 23
Train batch 1/32 - 75.0ms/batch - loss: 2.06645 - diff: 33.06mlTrain batch 2/32 - 63.9ms/batch - loss: 2.10349 - diff: 33.66mlTrain batch 3/32 - 94.2ms/batch - loss: 1.99923 - diff: 31.99mlTrain batch 4/32 - 102.0ms/batch - loss: 2.08150 - diff: 33.30mlTrain batch 5/32 - 74.6ms/batch - loss: 1.98533 - diff: 31.77mlTrain batch 6/32 - 112.2ms/batch - loss: 2.07387 - diff: 33.18mlTrain batch 7/32 - 93.6ms/batch - loss: 2.00747 - diff: 32.12mlTrain batch 8/32 - 78.9ms/batch - loss: 2.03159 - diff: 32.51mlTrain batch 9/32 - 80.2ms/batch - loss: 2.04529 - diff: 32.72mlTrain batch 10/32 - 104.5ms/batch - loss: 2.06645 - diff: 33.06mlTrain batch 11/32 - 78.2ms/batch - loss: 2.14681 - diff: 34.35mlTrain batch 12/32 - 84.4ms/batch - loss: 2.22959 - diff: 35.67mlTrain batch 13/32 - 89.9ms/batch - loss: 2.28534 - diff: 36.57mlTrain batch 14/32 - 100.6ms/batch - loss: 2.28309 - diff: 36.53mlTrain batch 15/32 - 84.3ms/batch - loss: 2.23637 - diff: 35.78mlTrain batch 16/32 - 112.3ms/batch - loss: 2.23584 - diff: 35.77mlTrain batch 17/32 - 79.6ms/batch - loss: 2.20078 - diff: 35.21mlTrain batch 18/32 - 87.0ms/batch - loss: 2.21438 - diff: 35.43mlTrain batch 19/32 - 78.8ms/batch - loss: 2.20037 - diff: 35.21mlTrain batch 20/32 - 98.1ms/batch - loss: 2.21218 - diff: 35.39mlTrain batch 21/32 - 88.9ms/batch - loss: 2.22848 - diff: 35.66mlTrain batch 22/32 - 105.3ms/batch - loss: 2.26270 - diff: 36.20mlTrain batch 23/32 - 82.0ms/batch - loss: 2.28707 - diff: 36.59mlTrain batch 24/32 - 86.7ms/batch - loss: 2.29767 - diff: 36.76mlTrain batch 25/32 - 89.5ms/batch - loss: 2.31179 - diff: 36.99mlTrain batch 26/32 - 100.0ms/batch - loss: 2.36515 - diff: 37.84mlTrain batch 27/32 - 100.5ms/batch - loss: 2.35047 - diff: 37.61mlTrain batch 28/32 - 82.4ms/batch - loss: 2.34800 - diff: 37.57mlTrain batch 29/32 - 80.8ms/batch - loss: 2.32856 - diff: 37.26mlTrain batch 30/32 - 84.0ms/batch - loss: 2.31752 - diff: 37.08mlTrain batch 31/32 - 62.0ms/batch - loss: 2.31239 - diff: 37.00mlTrain batch 32/32 - 82.9ms/batch - loss: 2.34554 - diff: 36.91mlTrain batch 32/32 - 17.0s 82.9ms/batch - loss: 2.34554 - diff: 36.91ml
Test 1.2s: val_loss: 2.25065 - diff: 34.29ml

Epoch 25: current best loss = 2.08915, at epoch 23
Train batch 1/32 - 90.1ms/batch - loss: 3.23318 - diff: 51.73mlTrain batch 2/32 - 96.2ms/batch - loss: 2.40410 - diff: 38.47mlTrain batch 3/32 - 68.5ms/batch - loss: 2.14953 - diff: 34.39mlTrain batch 4/32 - 73.5ms/batch - loss: 2.07597 - diff: 33.22mlTrain batch 5/32 - 77.7ms/batch - loss: 2.09792 - diff: 33.57mlTrain batch 6/32 - 93.4ms/batch - loss: 1.97963 - diff: 31.67mlTrain batch 7/32 - 80.9ms/batch - loss: 2.04285 - diff: 32.69mlTrain batch 8/32 - 95.1ms/batch - loss: 2.10520 - diff: 33.68mlTrain batch 9/32 - 108.0ms/batch - loss: 2.15726 - diff: 34.52mlTrain batch 10/32 - 77.5ms/batch - loss: 2.17667 - diff: 34.83mlTrain batch 11/32 - 64.5ms/batch - loss: 2.20407 - diff: 35.27mlTrain batch 12/32 - 79.1ms/batch - loss: 2.16365 - diff: 34.62mlTrain batch 13/32 - 99.2ms/batch - loss: 2.14699 - diff: 34.35mlTrain batch 14/32 - 67.9ms/batch - loss: 2.13528 - diff: 34.16mlTrain batch 15/32 - 74.3ms/batch - loss: 2.16055 - diff: 34.57mlTrain batch 16/32 - 82.5ms/batch - loss: 2.17794 - diff: 34.85mlTrain batch 17/32 - 95.7ms/batch - loss: 2.20131 - diff: 35.22mlTrain batch 18/32 - 109.0ms/batch - loss: 2.19798 - diff: 35.17mlTrain batch 19/32 - 88.3ms/batch - loss: 2.21767 - diff: 35.48mlTrain batch 20/32 - 73.6ms/batch - loss: 2.20962 - diff: 35.35mlTrain batch 21/32 - 99.7ms/batch - loss: 2.24787 - diff: 35.97mlTrain batch 22/32 - 93.7ms/batch - loss: 2.29308 - diff: 36.69mlTrain batch 23/32 - 80.1ms/batch - loss: 2.27578 - diff: 36.41mlTrain batch 24/32 - 86.0ms/batch - loss: 2.30004 - diff: 36.80mlTrain batch 25/32 - 72.8ms/batch - loss: 2.30743 - diff: 36.92mlTrain batch 26/32 - 70.7ms/batch - loss: 2.28807 - diff: 36.61mlTrain batch 27/32 - 91.5ms/batch - loss: 2.27391 - diff: 36.38mlTrain batch 28/32 - 62.8ms/batch - loss: 2.26675 - diff: 36.27mlTrain batch 29/32 - 103.1ms/batch - loss: 2.26085 - diff: 36.17mlTrain batch 30/32 - 63.5ms/batch - loss: 2.26247 - diff: 36.20mlTrain batch 31/32 - 97.7ms/batch - loss: 2.24789 - diff: 35.97mlTrain batch 32/32 - 88.8ms/batch - loss: 2.28049 - diff: 35.88mlTrain batch 32/32 - 17.4s 88.8ms/batch - loss: 2.28049 - diff: 35.88ml
Test 1.2s: val_loss: 1.95987 - diff: 30.37ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_DenseNet121_0_Adam-0.001_MAE_DA3_best

Epoch 26: current best loss = 1.95987, at epoch 25
Train batch 1/32 - 91.0ms/batch - loss: 1.70408 - diff: 27.27mlTrain batch 2/32 - 92.9ms/batch - loss: 1.99077 - diff: 31.85mlTrain batch 3/32 - 88.0ms/batch - loss: 2.02539 - diff: 32.41mlTrain batch 4/32 - 58.7ms/batch - loss: 2.06496 - diff: 33.04mlTrain batch 5/32 - 81.2ms/batch - loss: 2.30143 - diff: 36.82mlTrain batch 6/32 - 83.2ms/batch - loss: 2.53234 - diff: 40.52mlTrain batch 7/32 - 86.0ms/batch - loss: 2.40127 - diff: 38.42mlTrain batch 8/32 - 85.9ms/batch - loss: 2.34342 - diff: 37.49mlTrain batch 9/32 - 77.8ms/batch - loss: 2.52963 - diff: 40.47mlTrain batch 10/32 - 83.5ms/batch - loss: 2.45997 - diff: 39.36mlTrain batch 11/32 - 75.6ms/batch - loss: 2.42659 - diff: 38.83mlTrain batch 12/32 - 116.6ms/batch - loss: 2.40470 - diff: 38.48mlTrain batch 13/32 - 113.9ms/batch - loss: 2.35128 - diff: 37.62mlTrain batch 14/32 - 96.5ms/batch - loss: 2.29343 - diff: 36.69mlTrain batch 15/32 - 88.2ms/batch - loss: 2.39161 - diff: 38.27mlTrain batch 16/32 - 78.9ms/batch - loss: 2.41853 - diff: 38.70mlTrain batch 17/32 - 87.7ms/batch - loss: 2.37656 - diff: 38.02mlTrain batch 18/32 - 77.6ms/batch - loss: 2.36814 - diff: 37.89mlTrain batch 19/32 - 92.7ms/batch - loss: 2.33446 - diff: 37.35mlTrain batch 20/32 - 96.1ms/batch - loss: 2.33926 - diff: 37.43mlTrain batch 21/32 - 83.6ms/batch - loss: 2.33212 - diff: 37.31mlTrain batch 22/32 - 78.0ms/batch - loss: 2.31225 - diff: 37.00mlTrain batch 23/32 - 74.8ms/batch - loss: 2.29157 - diff: 36.67mlTrain batch 24/32 - 74.2ms/batch - loss: 2.33529 - diff: 37.36mlTrain batch 25/32 - 69.5ms/batch - loss: 2.32724 - diff: 37.24mlTrain batch 26/32 - 85.3ms/batch - loss: 2.33395 - diff: 37.34mlTrain batch 27/32 - 66.2ms/batch - loss: 2.33916 - diff: 37.43mlTrain batch 28/32 - 79.1ms/batch - loss: 2.29836 - diff: 36.77mlTrain batch 29/32 - 85.9ms/batch - loss: 2.30967 - diff: 36.95mlTrain batch 30/32 - 86.1ms/batch - loss: 2.32978 - diff: 37.28mlTrain batch 31/32 - 67.1ms/batch - loss: 2.35121 - diff: 37.62mlTrain batch 32/32 - 88.9ms/batch - loss: 2.41464 - diff: 37.65mlTrain batch 32/32 - 16.1s 88.9ms/batch - loss: 2.41464 - diff: 37.65ml
Test 1.2s: val_loss: 2.12173 - diff: 32.60ml

Epoch 27: current best loss = 1.95987, at epoch 25
Train batch 1/32 - 123.8ms/batch - loss: 1.89236 - diff: 30.28mlTrain batch 2/32 - 79.8ms/batch - loss: 1.83581 - diff: 29.37mlTrain batch 3/32 - 83.7ms/batch - loss: 1.99541 - diff: 31.93mlTrain batch 4/32 - 84.1ms/batch - loss: 2.07644 - diff: 33.22mlTrain batch 5/32 - 81.9ms/batch - loss: 2.07096 - diff: 33.14mlTrain batch 6/32 - 73.8ms/batch - loss: 2.05550 - diff: 32.89mlTrain batch 7/32 - 63.5ms/batch - loss: 2.07993 - diff: 33.28mlTrain batch 8/32 - 71.8ms/batch - loss: 2.20969 - diff: 35.36mlTrain batch 9/32 - 58.8ms/batch - loss: 2.23442 - diff: 35.75mlTrain batch 10/32 - 55.0ms/batch - loss: 2.13141 - diff: 34.10mlTrain batch 11/32 - 83.2ms/batch - loss: 2.11141 - diff: 33.78mlTrain batch 12/32 - 108.7ms/batch - loss: 2.16821 - diff: 34.69mlTrain batch 13/32 - 97.1ms/batch - loss: 2.19426 - diff: 35.11mlTrain batch 14/32 - 101.2ms/batch - loss: 2.28693 - diff: 36.59mlTrain batch 15/32 - 88.5ms/batch - loss: 2.28295 - diff: 36.53mlTrain batch 16/32 - 89.3ms/batch - loss: 2.24557 - diff: 35.93mlTrain batch 17/32 - 89.0ms/batch - loss: 2.27014 - diff: 36.32mlTrain batch 18/32 - 88.6ms/batch - loss: 2.24920 - diff: 35.99mlTrain batch 19/32 - 71.6ms/batch - loss: 2.20912 - diff: 35.35mlTrain batch 20/32 - 111.9ms/batch - loss: 2.20721 - diff: 35.32mlTrain batch 21/32 - 64.4ms/batch - loss: 2.20162 - diff: 35.23mlTrain batch 22/32 - 95.1ms/batch - loss: 2.20426 - diff: 35.27mlTrain batch 23/32 - 83.3ms/batch - loss: 2.20348 - diff: 35.26mlTrain batch 24/32 - 73.6ms/batch - loss: 2.20850 - diff: 35.34mlTrain batch 25/32 - 73.4ms/batch - loss: 2.22622 - diff: 35.62mlTrain batch 26/32 - 77.1ms/batch - loss: 2.21544 - diff: 35.45mlTrain batch 27/32 - 72.7ms/batch - loss: 2.21535 - diff: 35.45mlTrain batch 28/32 - 70.8ms/batch - loss: 2.22108 - diff: 35.54mlTrain batch 29/32 - 64.3ms/batch - loss: 2.18649 - diff: 34.98mlTrain batch 30/32 - 101.1ms/batch - loss: 2.19931 - diff: 35.19mlTrain batch 31/32 - 92.3ms/batch - loss: 2.19727 - diff: 35.16mlTrain batch 32/32 - 57.0ms/batch - loss: 2.27550 - diff: 35.26mlTrain batch 32/32 - 16.2s 57.0ms/batch - loss: 2.27550 - diff: 35.26ml
Test 1.1s: val_loss: 2.14124 - diff: 33.29ml

Epoch 28: current best loss = 1.95987, at epoch 25
Train batch 1/32 - 85.3ms/batch - loss: 2.40514 - diff: 38.48mlTrain batch 2/32 - 61.0ms/batch - loss: 2.57991 - diff: 41.28mlTrain batch 3/32 - 93.7ms/batch - loss: 2.37116 - diff: 37.94mlTrain batch 4/32 - 80.0ms/batch - loss: 2.37834 - diff: 38.05mlTrain batch 5/32 - 81.4ms/batch - loss: 2.30239 - diff: 36.84mlTrain batch 6/32 - 78.4ms/batch - loss: 2.21304 - diff: 35.41mlTrain batch 7/32 - 81.3ms/batch - loss: 2.24809 - diff: 35.97mlTrain batch 8/32 - 77.4ms/batch - loss: 2.32763 - diff: 37.24mlTrain batch 9/32 - 76.9ms/batch - loss: 2.34970 - diff: 37.60mlTrain batch 10/32 - 89.9ms/batch - loss: 2.37031 - diff: 37.92mlTrain batch 11/32 - 77.5ms/batch - loss: 2.44960 - diff: 39.19mlTrain batch 12/32 - 61.9ms/batch - loss: 2.38518 - diff: 38.16mlTrain batch 13/32 - 97.0ms/batch - loss: 2.35161 - diff: 37.63mlTrain batch 14/32 - 81.4ms/batch - loss: 2.32991 - diff: 37.28mlTrain batch 15/32 - 102.6ms/batch - loss: 2.32258 - diff: 37.16mlTrain batch 16/32 - 98.6ms/batch - loss: 2.31172 - diff: 36.99mlTrain batch 17/32 - 83.2ms/batch - loss: 2.40625 - diff: 38.50mlTrain batch 18/32 - 85.1ms/batch - loss: 2.38681 - diff: 38.19mlTrain batch 19/32 - 82.6ms/batch - loss: 2.38795 - diff: 38.21mlTrain batch 20/32 - 86.5ms/batch - loss: 2.41086 - diff: 38.57mlTrain batch 21/32 - 108.4ms/batch - loss: 2.41429 - diff: 38.63mlTrain batch 22/32 - 99.4ms/batch - loss: 2.41540 - diff: 38.65mlTrain batch 23/32 - 85.9ms/batch - loss: 2.39669 - diff: 38.35mlTrain batch 24/32 - 109.3ms/batch - loss: 2.38889 - diff: 38.22mlTrain batch 25/32 - 103.3ms/batch - loss: 2.38765 - diff: 38.20mlTrain batch 26/32 - 106.4ms/batch - loss: 2.38011 - diff: 38.08mlTrain batch 27/32 - 82.1ms/batch - loss: 2.39089 - diff: 38.25mlTrain batch 28/32 - 109.9ms/batch - loss: 2.37389 - diff: 37.98mlTrain batch 29/32 - 73.8ms/batch - loss: 2.35811 - diff: 37.73mlTrain batch 30/32 - 81.8ms/batch - loss: 2.38824 - diff: 38.21mlTrain batch 31/32 - 69.8ms/batch - loss: 2.38827 - diff: 38.21mlTrain batch 32/32 - 61.7ms/batch - loss: 2.47813 - diff: 38.34mlTrain batch 32/32 - 17.5s 61.7ms/batch - loss: 2.47813 - diff: 38.34ml
Test 1.0s: val_loss: 2.24495 - diff: 34.44ml

Epoch 29: current best loss = 1.95987, at epoch 25
Train batch 1/32 - 112.3ms/batch - loss: 2.41843 - diff: 38.69mlTrain batch 2/32 - 90.0ms/batch - loss: 2.45792 - diff: 39.33mlTrain batch 3/32 - 94.5ms/batch - loss: 2.10958 - diff: 33.75mlTrain batch 4/32 - 93.5ms/batch - loss: 2.28615 - diff: 36.58mlTrain batch 5/32 - 73.3ms/batch - loss: 2.19228 - diff: 35.08mlTrain batch 6/32 - 93.5ms/batch - loss: 2.18738 - diff: 35.00mlTrain batch 7/32 - 96.2ms/batch - loss: 2.25219 - diff: 36.04mlTrain batch 8/32 - 110.3ms/batch - loss: 2.38018 - diff: 38.08mlTrain batch 9/32 - 104.1ms/batch - loss: 2.41170 - diff: 38.59mlTrain batch 10/32 - 116.5ms/batch - loss: 2.39610 - diff: 38.34mlTrain batch 11/32 - 64.4ms/batch - loss: 2.36105 - diff: 37.78mlTrain batch 12/32 - 123.5ms/batch - loss: 2.38653 - diff: 38.18mlTrain batch 13/32 - 77.5ms/batch - loss: 2.43932 - diff: 39.03mlTrain batch 14/32 - 66.5ms/batch - loss: 2.44001 - diff: 39.04mlTrain batch 15/32 - 88.1ms/batch - loss: 2.41588 - diff: 38.65mlTrain batch 16/32 - 82.4ms/batch - loss: 2.37699 - diff: 38.03mlTrain batch 17/32 - 110.5ms/batch - loss: 2.36952 - diff: 37.91mlTrain batch 18/32 - 132.0ms/batch - loss: 2.38741 - diff: 38.20mlTrain batch 19/32 - 93.5ms/batch - loss: 2.37725 - diff: 38.04mlTrain batch 20/32 - 63.1ms/batch - loss: 2.36439 - diff: 37.83mlTrain batch 21/32 - 74.5ms/batch - loss: 2.34659 - diff: 37.55mlTrain batch 22/32 - 132.1ms/batch - loss: 2.30168 - diff: 36.83mlTrain batch 23/32 - 111.5ms/batch - loss: 2.31736 - diff: 37.08mlTrain batch 24/32 - 77.8ms/batch - loss: 2.37977 - diff: 38.08mlTrain batch 25/32 - 97.1ms/batch - loss: 2.36436 - diff: 37.83mlTrain batch 26/32 - 74.7ms/batch - loss: 2.32868 - diff: 37.26mlTrain batch 27/32 - 80.5ms/batch - loss: 2.31442 - diff: 37.03mlTrain batch 28/32 - 94.8ms/batch - loss: 2.34038 - diff: 37.45mlTrain batch 29/32 - 75.9ms/batch - loss: 2.31463 - diff: 37.03mlTrain batch 30/32 - 70.4ms/batch - loss: 2.31210 - diff: 36.99mlTrain batch 31/32 - 91.7ms/batch - loss: 2.29913 - diff: 36.79mlTrain batch 32/32 - 92.5ms/batch - loss: 2.31608 - diff: 36.63mlTrain batch 32/32 - 17.4s 92.5ms/batch - loss: 2.31608 - diff: 36.63ml
Test 1.2s: val_loss: 2.24613 - diff: 34.52ml

Epoch 30: current best loss = 1.95987, at epoch 25
Train batch 1/32 - 95.9ms/batch - loss: 3.00615 - diff: 48.10mlTrain batch 2/32 - 73.7ms/batch - loss: 2.92814 - diff: 46.85mlTrain batch 3/32 - 78.4ms/batch - loss: 2.58205 - diff: 41.31mlTrain batch 4/32 - 87.0ms/batch - loss: 2.76428 - diff: 44.23mlTrain batch 5/32 - 62.3ms/batch - loss: 2.66368 - diff: 42.62mlTrain batch 6/32 - 103.3ms/batch - loss: 2.51225 - diff: 40.20mlTrain batch 7/32 - 110.2ms/batch - loss: 2.33919 - diff: 37.43mlTrain batch 8/32 - 93.9ms/batch - loss: 2.28737 - diff: 36.60mlTrain batch 9/32 - 88.8ms/batch - loss: 2.30898 - diff: 36.94mlTrain batch 10/32 - 77.9ms/batch - loss: 2.34634 - diff: 37.54mlTrain batch 11/32 - 92.3ms/batch - loss: 2.25315 - diff: 36.05mlTrain batch 12/32 - 93.1ms/batch - loss: 2.23829 - diff: 35.81mlTrain batch 13/32 - 91.3ms/batch - loss: 2.24108 - diff: 35.86mlTrain batch 14/32 - 91.9ms/batch - loss: 2.21295 - diff: 35.41mlTrain batch 15/32 - 58.8ms/batch - loss: 2.24550 - diff: 35.93mlTrain batch 16/32 - 73.8ms/batch - loss: 2.27126 - diff: 36.34mlTrain batch 17/32 - 145.4ms/batch - loss: 2.26208 - diff: 36.19mlTrain batch 18/32 - 117.5ms/batch - loss: 2.29765 - diff: 36.76mlTrain batch 19/32 - 123.4ms/batch - loss: 2.27883 - diff: 36.46mlTrain batch 20/32 - 86.7ms/batch - loss: 2.26631 - diff: 36.26mlTrain batch 21/32 - 84.8ms/batch - loss: 2.26640 - diff: 36.26mlTrain batch 22/32 - 59.8ms/batch - loss: 2.25695 - diff: 36.11mlTrain batch 23/32 - 57.9ms/batch - loss: 2.28487 - diff: 36.56mlTrain batch 24/32 - 67.4ms/batch - loss: 2.30369 - diff: 36.86mlTrain batch 25/32 - 109.8ms/batch - loss: 2.27575 - diff: 36.41mlTrain batch 26/32 - 83.0ms/batch - loss: 2.27546 - diff: 36.41mlTrain batch 27/32 - 94.3ms/batch - loss: 2.28972 - diff: 36.64mlTrain batch 28/32 - 98.9ms/batch - loss: 2.27918 - diff: 36.47mlTrain batch 29/32 - 95.8ms/batch - loss: 2.27984 - diff: 36.48mlTrain batch 30/32 - 107.1ms/batch - loss: 2.27285 - diff: 36.37mlTrain batch 31/32 - 93.4ms/batch - loss: 2.26849 - diff: 36.30mlTrain batch 32/32 - 82.7ms/batch - loss: 2.27288 - diff: 36.10mlTrain batch 32/32 - 16.6s 82.7ms/batch - loss: 2.27288 - diff: 36.10ml
Test 1.3s: val_loss: 2.14019 - diff: 33.01ml

Epoch 31: current best loss = 1.95987, at epoch 25
Train batch 1/32 - 116.7ms/batch - loss: 3.33065 - diff: 53.29mlTrain batch 2/32 - 96.2ms/batch - loss: 2.99786 - diff: 47.97mlTrain batch 3/32 - 82.4ms/batch - loss: 2.70438 - diff: 43.27mlTrain batch 4/32 - 80.0ms/batch - loss: 2.72786 - diff: 43.65mlTrain batch 5/32 - 86.2ms/batch - loss: 2.51633 - diff: 40.26mlTrain batch 6/32 - 63.2ms/batch - loss: 2.50973 - diff: 40.16mlTrain batch 7/32 - 81.4ms/batch - loss: 2.44022 - diff: 39.04mlTrain batch 8/32 - 103.6ms/batch - loss: 2.44974 - diff: 39.20mlTrain batch 9/32 - 64.9ms/batch - loss: 2.46533 - diff: 39.45mlTrain batch 10/32 - 66.0ms/batch - loss: 2.39693 - diff: 38.35mlTrain batch 11/32 - 94.3ms/batch - loss: 2.37127 - diff: 37.94mlTrain batch 12/32 - 63.7ms/batch - loss: 2.33752 - diff: 37.40mlTrain batch 13/32 - 96.1ms/batch - loss: 2.29351 - diff: 36.70mlTrain batch 14/32 - 63.4ms/batch - loss: 2.28952 - diff: 36.63mlTrain batch 15/32 - 97.7ms/batch - loss: 2.31169 - diff: 36.99mlTrain batch 16/32 - 96.7ms/batch - loss: 2.30259 - diff: 36.84mlTrain batch 17/32 - 103.3ms/batch - loss: 2.27589 - diff: 36.41mlTrain batch 18/32 - 101.5ms/batch - loss: 2.28995 - diff: 36.64mlTrain batch 19/32 - 68.0ms/batch - loss: 2.28084 - diff: 36.49mlTrain batch 20/32 - 91.7ms/batch - loss: 2.27331 - diff: 36.37mlTrain batch 21/32 - 86.2ms/batch - loss: 2.26364 - diff: 36.22mlTrain batch 22/32 - 82.9ms/batch - loss: 2.24308 - diff: 35.89mlTrain batch 23/32 - 66.3ms/batch - loss: 2.22699 - diff: 35.63mlTrain batch 24/32 - 80.5ms/batch - loss: 2.24128 - diff: 35.86mlTrain batch 25/32 - 80.0ms/batch - loss: 2.24556 - diff: 35.93mlTrain batch 26/32 - 63.6ms/batch - loss: 2.25602 - diff: 36.10mlTrain batch 27/32 - 78.0ms/batch - loss: 2.27398 - diff: 36.38mlTrain batch 28/32 - 103.5ms/batch - loss: 2.25484 - diff: 36.08mlTrain batch 29/32 - 85.4ms/batch - loss: 2.27915 - diff: 36.47mlTrain batch 30/32 - 100.2ms/batch - loss: 2.32596 - diff: 37.22mlTrain batch 31/32 - 95.6ms/batch - loss: 2.33027 - diff: 37.28mlTrain batch 32/32 - 60.4ms/batch - loss: 2.43046 - diff: 37.46mlTrain batch 32/32 - 17.2s 60.4ms/batch - loss: 2.43046 - diff: 37.46ml
Test 1.3s: val_loss: 2.22018 - diff: 34.24ml

Epoch 32: current best loss = 1.95987, at epoch 25
Train batch 1/32 - 141.4ms/batch - loss: 3.30471 - diff: 52.88mlTrain batch 2/32 - 89.0ms/batch - loss: 3.48138 - diff: 55.70mlTrain batch 3/32 - 119.0ms/batch - loss: 2.97615 - diff: 47.62mlTrain batch 4/32 - 116.1ms/batch - loss: 3.00679 - diff: 48.11mlTrain batch 5/32 - 90.7ms/batch - loss: 2.77172 - diff: 44.35mlTrain batch 6/32 - 82.6ms/batch - loss: 2.55935 - diff: 40.95mlTrain batch 7/32 - 90.1ms/batch - loss: 2.71504 - diff: 43.44mlTrain batch 8/32 - 88.8ms/batch - loss: 2.57216 - diff: 41.15mlTrain batch 9/32 - 88.3ms/batch - loss: 2.48199 - diff: 39.71mlTrain batch 10/32 - 82.8ms/batch - loss: 2.45590 - diff: 39.29mlTrain batch 11/32 - 73.9ms/batch - loss: 2.47939 - diff: 39.67mlTrain batch 12/32 - 80.9ms/batch - loss: 2.48658 - diff: 39.79mlTrain batch 13/32 - 77.9ms/batch - loss: 2.41996 - diff: 38.72mlTrain batch 14/32 - 111.3ms/batch - loss: 2.37695 - diff: 38.03mlTrain batch 15/32 - 64.1ms/batch - loss: 2.33976 - diff: 37.44mlTrain batch 16/32 - 87.8ms/batch - loss: 2.33847 - diff: 37.42mlTrain batch 17/32 - 82.2ms/batch - loss: 2.31546 - diff: 37.05mlTrain batch 18/32 - 90.0ms/batch - loss: 2.32907 - diff: 37.27mlTrain batch 19/32 - 63.4ms/batch - loss: 2.32823 - diff: 37.25mlTrain batch 20/32 - 78.3ms/batch - loss: 2.32475 - diff: 37.20mlTrain batch 21/32 - 84.5ms/batch - loss: 2.37753 - diff: 38.04mlTrain batch 22/32 - 61.4ms/batch - loss: 2.35800 - diff: 37.73mlTrain batch 23/32 - 73.9ms/batch - loss: 2.31567 - diff: 37.05mlTrain batch 24/32 - 60.6ms/batch - loss: 2.28114 - diff: 36.50mlTrain batch 25/32 - 83.8ms/batch - loss: 2.27521 - diff: 36.40mlTrain batch 26/32 - 62.2ms/batch - loss: 2.24867 - diff: 35.98mlTrain batch 27/32 - 81.0ms/batch - loss: 2.22705 - diff: 35.63mlTrain batch 28/32 - 89.9ms/batch - loss: 2.22201 - diff: 35.55mlTrain batch 29/32 - 83.9ms/batch - loss: 2.22322 - diff: 35.57mlTrain batch 30/32 - 132.8ms/batch - loss: 2.23340 - diff: 35.73mlTrain batch 31/32 - 67.6ms/batch - loss: 2.23250 - diff: 35.72mlTrain batch 32/32 - 76.1ms/batch - loss: 2.27227 - diff: 35.66mlTrain batch 32/32 - 17.6s 76.1ms/batch - loss: 2.27227 - diff: 35.66ml
Test 1.1s: val_loss: 1.94078 - diff: 29.85ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_DenseNet121_0_Adam-0.001_MAE_DA3_best

Epoch 33: current best loss = 1.94078, at epoch 32
Train batch 1/32 - 83.1ms/batch - loss: 2.84835 - diff: 45.57mlTrain batch 2/32 - 86.8ms/batch - loss: 2.29418 - diff: 36.71mlTrain batch 3/32 - 80.1ms/batch - loss: 2.09297 - diff: 33.49mlTrain batch 4/32 - 99.2ms/batch - loss: 2.11402 - diff: 33.82mlTrain batch 5/32 - 67.4ms/batch - loss: 2.23540 - diff: 35.77mlTrain batch 6/32 - 63.3ms/batch - loss: 2.25282 - diff: 36.05mlTrain batch 7/32 - 63.2ms/batch - loss: 2.21877 - diff: 35.50mlTrain batch 8/32 - 63.3ms/batch - loss: 2.15612 - diff: 34.50mlTrain batch 9/32 - 89.0ms/batch - loss: 2.12632 - diff: 34.02mlTrain batch 10/32 - 76.7ms/batch - loss: 2.17597 - diff: 34.82mlTrain batch 11/32 - 71.3ms/batch - loss: 2.20985 - diff: 35.36mlTrain batch 12/32 - 67.5ms/batch - loss: 2.18691 - diff: 34.99mlTrain batch 13/32 - 91.7ms/batch - loss: 2.16382 - diff: 34.62mlTrain batch 14/32 - 71.9ms/batch - loss: 2.20068 - diff: 35.21mlTrain batch 15/32 - 97.5ms/batch - loss: 2.13990 - diff: 34.24mlTrain batch 16/32 - 81.3ms/batch - loss: 2.14651 - diff: 34.34mlTrain batch 17/32 - 75.7ms/batch - loss: 2.18533 - diff: 34.97mlTrain batch 18/32 - 104.8ms/batch - loss: 2.20241 - diff: 35.24mlTrain batch 19/32 - 103.6ms/batch - loss: 2.20050 - diff: 35.21mlTrain batch 20/32 - 81.6ms/batch - loss: 2.22204 - diff: 35.55mlTrain batch 21/32 - 98.1ms/batch - loss: 2.18846 - diff: 35.02mlTrain batch 22/32 - 92.1ms/batch - loss: 2.22974 - diff: 35.68mlTrain batch 23/32 - 95.9ms/batch - loss: 2.19604 - diff: 35.14mlTrain batch 24/32 - 69.0ms/batch - loss: 2.22256 - diff: 35.56mlTrain batch 25/32 - 75.6ms/batch - loss: 2.27666 - diff: 36.43mlTrain batch 26/32 - 90.0ms/batch - loss: 2.25145 - diff: 36.02mlTrain batch 27/32 - 96.7ms/batch - loss: 2.22388 - diff: 35.58mlTrain batch 28/32 - 90.7ms/batch - loss: 2.21965 - diff: 35.51mlTrain batch 29/32 - 70.1ms/batch - loss: 2.26342 - diff: 36.21mlTrain batch 30/32 - 94.2ms/batch - loss: 2.27530 - diff: 36.40mlTrain batch 31/32 - 102.8ms/batch - loss: 2.26933 - diff: 36.31mlTrain batch 32/32 - 79.7ms/batch - loss: 2.28029 - diff: 36.14mlTrain batch 32/32 - 16.0s 79.7ms/batch - loss: 2.28029 - diff: 36.14ml
Test 1.2s: val_loss: 2.36704 - diff: 36.15ml

Epoch 34: current best loss = 1.94078, at epoch 32
Train batch 1/32 - 104.0ms/batch - loss: 2.01295 - diff: 32.21mlTrain batch 2/32 - 96.4ms/batch - loss: 2.19894 - diff: 35.18mlTrain batch 3/32 - 81.1ms/batch - loss: 2.19078 - diff: 35.05mlTrain batch 4/32 - 87.8ms/batch - loss: 2.26667 - diff: 36.27mlTrain batch 5/32 - 81.2ms/batch - loss: 2.08209 - diff: 33.31mlTrain batch 6/32 - 102.6ms/batch - loss: 2.14813 - diff: 34.37mlTrain batch 7/32 - 94.3ms/batch - loss: 2.15108 - diff: 34.42mlTrain batch 8/32 - 103.4ms/batch - loss: 2.14496 - diff: 34.32mlTrain batch 9/32 - 81.0ms/batch - loss: 2.11347 - diff: 33.82mlTrain batch 10/32 - 100.1ms/batch - loss: 2.08112 - diff: 33.30mlTrain batch 11/32 - 113.7ms/batch - loss: 2.16681 - diff: 34.67mlTrain batch 12/32 - 90.9ms/batch - loss: 2.16493 - diff: 34.64mlTrain batch 13/32 - 68.9ms/batch - loss: 2.21963 - diff: 35.51mlTrain batch 14/32 - 78.9ms/batch - loss: 2.18956 - diff: 35.03mlTrain batch 15/32 - 78.0ms/batch - loss: 2.16048 - diff: 34.57mlTrain batch 16/32 - 71.7ms/batch - loss: 2.13072 - diff: 34.09mlTrain batch 17/32 - 67.8ms/batch - loss: 2.16611 - diff: 34.66mlTrain batch 18/32 - 68.4ms/batch - loss: 2.18116 - diff: 34.90mlTrain batch 19/32 - 81.6ms/batch - loss: 2.21374 - diff: 35.42mlTrain batch 20/32 - 85.3ms/batch - loss: 2.20999 - diff: 35.36mlTrain batch 21/32 - 64.6ms/batch - loss: 2.21260 - diff: 35.40mlTrain batch 22/32 - 97.3ms/batch - loss: 2.24276 - diff: 35.88mlTrain batch 23/32 - 66.3ms/batch - loss: 2.23720 - diff: 35.80mlTrain batch 24/32 - 77.2ms/batch - loss: 2.27755 - diff: 36.44mlTrain batch 25/32 - 78.5ms/batch - loss: 2.29551 - diff: 36.73mlTrain batch 26/32 - 96.5ms/batch - loss: 2.31077 - diff: 36.97mlTrain batch 27/32 - 76.7ms/batch - loss: 2.31934 - diff: 37.11mlTrain batch 28/32 - 81.1ms/batch - loss: 2.30280 - diff: 36.84mlTrain batch 29/32 - 87.2ms/batch - loss: 2.30665 - diff: 36.91mlTrain batch 30/32 - 99.8ms/batch - loss: 2.29037 - diff: 36.65mlTrain batch 31/32 - 78.8ms/batch - loss: 2.26715 - diff: 36.27mlTrain batch 32/32 - 92.2ms/batch - loss: 2.33353 - diff: 36.32mlTrain batch 32/32 - 17.5s 92.2ms/batch - loss: 2.33353 - diff: 36.32ml
Test 1.0s: val_loss: 2.22279 - diff: 33.32ml

Epoch 35: current best loss = 1.94078, at epoch 32
Train batch 1/32 - 76.5ms/batch - loss: 1.84223 - diff: 29.48mlTrain batch 2/32 - 63.8ms/batch - loss: 1.81142 - diff: 28.98mlTrain batch 3/32 - 85.1ms/batch - loss: 1.96722 - diff: 31.48mlTrain batch 4/32 - 103.8ms/batch - loss: 1.83925 - diff: 29.43mlTrain batch 5/32 - 84.6ms/batch - loss: 1.97923 - diff: 31.67mlTrain batch 6/32 - 100.2ms/batch - loss: 2.00995 - diff: 32.16mlTrain batch 7/32 - 89.5ms/batch - loss: 2.05080 - diff: 32.81mlTrain batch 8/32 - 83.6ms/batch - loss: 2.09229 - diff: 33.48mlTrain batch 9/32 - 95.5ms/batch - loss: 2.11220 - diff: 33.80mlTrain batch 10/32 - 97.1ms/batch - loss: 2.15947 - diff: 34.55mlTrain batch 11/32 - 64.9ms/batch - loss: 2.15120 - diff: 34.42mlTrain batch 12/32 - 64.1ms/batch - loss: 2.12379 - diff: 33.98mlTrain batch 13/32 - 92.6ms/batch - loss: 2.07116 - diff: 33.14mlTrain batch 14/32 - 103.5ms/batch - loss: 2.07497 - diff: 33.20mlTrain batch 15/32 - 107.7ms/batch - loss: 2.07082 - diff: 33.13mlTrain batch 16/32 - 112.3ms/batch - loss: 2.07203 - diff: 33.15mlTrain batch 17/32 - 81.3ms/batch - loss: 2.10701 - diff: 33.71mlTrain batch 18/32 - 95.5ms/batch - loss: 2.13424 - diff: 34.15mlTrain batch 19/32 - 94.6ms/batch - loss: 2.15786 - diff: 34.53mlTrain batch 20/32 - 63.3ms/batch - loss: 2.16389 - diff: 34.62mlTrain batch 21/32 - 63.1ms/batch - loss: 2.19418 - diff: 35.11mlTrain batch 22/32 - 59.5ms/batch - loss: 2.20852 - diff: 35.34mlTrain batch 23/32 - 93.3ms/batch - loss: 2.24015 - diff: 35.84mlTrain batch 24/32 - 107.3ms/batch - loss: 2.25556 - diff: 36.09mlTrain batch 25/32 - 76.1ms/batch - loss: 2.29636 - diff: 36.74mlTrain batch 26/32 - 91.1ms/batch - loss: 2.27574 - diff: 36.41mlTrain batch 27/32 - 86.3ms/batch - loss: 2.29273 - diff: 36.68mlTrain batch 28/32 - 91.9ms/batch - loss: 2.31364 - diff: 37.02mlTrain batch 29/32 - 84.6ms/batch - loss: 2.30399 - diff: 36.86mlTrain batch 30/32 - 93.3ms/batch - loss: 2.33642 - diff: 37.38mlTrain batch 31/32 - 67.7ms/batch - loss: 2.35074 - diff: 37.61mlTrain batch 32/32 - 59.5ms/batch - loss: 2.42216 - diff: 37.67mlTrain batch 32/32 - 17.1s 59.5ms/batch - loss: 2.42216 - diff: 37.67ml
Test 1.1s: val_loss: 1.90353 - diff: 29.63ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_DenseNet121_0_Adam-0.001_MAE_DA3_best

Epoch 36: current best loss = 1.90353, at epoch 35
Train batch 1/32 - 98.4ms/batch - loss: 1.87551 - diff: 30.01mlTrain batch 2/32 - 86.8ms/batch - loss: 2.21572 - diff: 35.45mlTrain batch 3/32 - 79.4ms/batch - loss: 2.29439 - diff: 36.71mlTrain batch 4/32 - 68.9ms/batch - loss: 2.21440 - diff: 35.43mlTrain batch 5/32 - 74.6ms/batch - loss: 2.22030 - diff: 35.52mlTrain batch 6/32 - 106.0ms/batch - loss: 2.50600 - diff: 40.10mlTrain batch 7/32 - 82.9ms/batch - loss: 2.51963 - diff: 40.31mlTrain batch 8/32 - 107.6ms/batch - loss: 2.52507 - diff: 40.40mlTrain batch 9/32 - 79.0ms/batch - loss: 2.51873 - diff: 40.30mlTrain batch 10/32 - 84.5ms/batch - loss: 2.46304 - diff: 39.41mlTrain batch 11/32 - 97.6ms/batch - loss: 2.42510 - diff: 38.80mlTrain batch 12/32 - 109.1ms/batch - loss: 2.41777 - diff: 38.68mlTrain batch 13/32 - 108.9ms/batch - loss: 2.42807 - diff: 38.85mlTrain batch 14/32 - 102.3ms/batch - loss: 2.37268 - diff: 37.96mlTrain batch 15/32 - 85.3ms/batch - loss: 2.34267 - diff: 37.48mlTrain batch 16/32 - 78.2ms/batch - loss: 2.36054 - diff: 37.77mlTrain batch 17/32 - 96.1ms/batch - loss: 2.34947 - diff: 37.59mlTrain batch 18/32 - 77.5ms/batch - loss: 2.36890 - diff: 37.90mlTrain batch 19/32 - 97.6ms/batch - loss: 2.32661 - diff: 37.23mlTrain batch 20/32 - 98.9ms/batch - loss: 2.30673 - diff: 36.91mlTrain batch 21/32 - 85.1ms/batch - loss: 2.27584 - diff: 36.41mlTrain batch 22/32 - 86.8ms/batch - loss: 2.28469 - diff: 36.56mlTrain batch 23/32 - 98.9ms/batch - loss: 2.26340 - diff: 36.21mlTrain batch 24/32 - 80.9ms/batch - loss: 2.23226 - diff: 35.72mlTrain batch 25/32 - 92.1ms/batch - loss: 2.19460 - diff: 35.11mlTrain batch 26/32 - 76.8ms/batch - loss: 2.16963 - diff: 34.71mlTrain batch 27/32 - 78.8ms/batch - loss: 2.13461 - diff: 34.15mlTrain batch 28/32 - 102.5ms/batch - loss: 2.15478 - diff: 34.48mlTrain batch 29/32 - 100.1ms/batch - loss: 2.15855 - diff: 34.54mlTrain batch 30/32 - 94.9ms/batch - loss: 2.16230 - diff: 34.60mlTrain batch 31/32 - 99.9ms/batch - loss: 2.13392 - diff: 34.14mlTrain batch 32/32 - 108.9ms/batch - loss: 2.16813 - diff: 34.07mlTrain batch 32/32 - 17.5s 108.9ms/batch - loss: 2.16813 - diff: 34.07ml
Test 1.1s: val_loss: 2.14437 - diff: 32.46ml

Epoch 37: current best loss = 1.90353, at epoch 35
Train batch 1/32 - 135.0ms/batch - loss: 2.94615 - diff: 47.14mlTrain batch 2/32 - 96.8ms/batch - loss: 2.97801 - diff: 47.65mlTrain batch 3/32 - 89.8ms/batch - loss: 2.77314 - diff: 44.37mlTrain batch 4/32 - 94.1ms/batch - loss: 2.60251 - diff: 41.64mlTrain batch 5/32 - 69.5ms/batch - loss: 2.32054 - diff: 37.13mlTrain batch 6/32 - 110.3ms/batch - loss: 2.45571 - diff: 39.29mlTrain batch 7/32 - 96.7ms/batch - loss: 2.38272 - diff: 38.12mlTrain batch 8/32 - 92.2ms/batch - loss: 2.30699 - diff: 36.91mlTrain batch 9/32 - 62.2ms/batch - loss: 2.21628 - diff: 35.46mlTrain batch 10/32 - 72.5ms/batch - loss: 2.25189 - diff: 36.03mlTrain batch 11/32 - 89.5ms/batch - loss: 2.26491 - diff: 36.24mlTrain batch 12/32 - 91.5ms/batch - loss: 2.26489 - diff: 36.24mlTrain batch 13/32 - 105.4ms/batch - loss: 2.26685 - diff: 36.27mlTrain batch 14/32 - 127.4ms/batch - loss: 2.26082 - diff: 36.17mlTrain batch 15/32 - 101.7ms/batch - loss: 2.27020 - diff: 36.32mlTrain batch 16/32 - 113.3ms/batch - loss: 2.24658 - diff: 35.95mlTrain batch 17/32 - 96.9ms/batch - loss: 2.25902 - diff: 36.14mlTrain batch 18/32 - 90.9ms/batch - loss: 2.26227 - diff: 36.20mlTrain batch 19/32 - 111.0ms/batch - loss: 2.26401 - diff: 36.22mlTrain batch 20/32 - 84.0ms/batch - loss: 2.27204 - diff: 36.35mlTrain batch 21/32 - 95.1ms/batch - loss: 2.24814 - diff: 35.97mlTrain batch 22/32 - 79.3ms/batch - loss: 2.25050 - diff: 36.01mlTrain batch 23/32 - 121.6ms/batch - loss: 2.25496 - diff: 36.08mlTrain batch 24/32 - 84.1ms/batch - loss: 2.25026 - diff: 36.00mlTrain batch 25/32 - 75.9ms/batch - loss: 2.26395 - diff: 36.22mlTrain batch 26/32 - 106.6ms/batch - loss: 2.26173 - diff: 36.19mlTrain batch 27/32 - 96.7ms/batch - loss: 2.24070 - diff: 35.85mlTrain batch 28/32 - 62.6ms/batch - loss: 2.23111 - diff: 35.70mlTrain batch 29/32 - 67.8ms/batch - loss: 2.25137 - diff: 36.02mlTrain batch 30/32 - 72.4ms/batch - loss: 2.23363 - diff: 35.74mlTrain batch 31/32 - 80.7ms/batch - loss: 2.22857 - diff: 35.66mlTrain batch 32/32 - 90.5ms/batch - loss: 2.31911 - diff: 35.81mlTrain batch 32/32 - 16.5s 90.5ms/batch - loss: 2.31911 - diff: 35.81ml
Test 1.2s: val_loss: 2.34974 - diff: 36.22ml

Epoch 38: current best loss = 1.90353, at epoch 35
Train batch 1/32 - 115.3ms/batch - loss: 3.01007 - diff: 48.16mlTrain batch 2/32 - 104.8ms/batch - loss: 2.78346 - diff: 44.54mlTrain batch 3/32 - 80.8ms/batch - loss: 2.33269 - diff: 37.32mlTrain batch 4/32 - 91.0ms/batch - loss: 2.30006 - diff: 36.80mlTrain batch 5/32 - 76.4ms/batch - loss: 2.29714 - diff: 36.75mlTrain batch 6/32 - 87.8ms/batch - loss: 2.51237 - diff: 40.20mlTrain batch 7/32 - 96.9ms/batch - loss: 2.38616 - diff: 38.18mlTrain batch 8/32 - 89.5ms/batch - loss: 2.38010 - diff: 38.08mlTrain batch 9/32 - 89.1ms/batch - loss: 2.37418 - diff: 37.99mlTrain batch 10/32 - 77.1ms/batch - loss: 2.34942 - diff: 37.59mlTrain batch 11/32 - 84.5ms/batch - loss: 2.29673 - diff: 36.75mlTrain batch 12/32 - 119.6ms/batch - loss: 2.29033 - diff: 36.65mlTrain batch 13/32 - 72.2ms/batch - loss: 2.30311 - diff: 36.85mlTrain batch 14/32 - 90.9ms/batch - loss: 2.32980 - diff: 37.28mlTrain batch 15/32 - 83.7ms/batch - loss: 2.38008 - diff: 38.08mlTrain batch 16/32 - 98.0ms/batch - loss: 2.32629 - diff: 37.22mlTrain batch 17/32 - 92.5ms/batch - loss: 2.27883 - diff: 36.46mlTrain batch 18/32 - 107.9ms/batch - loss: 2.28077 - diff: 36.49mlTrain batch 19/32 - 84.2ms/batch - loss: 2.26861 - diff: 36.30mlTrain batch 20/32 - 95.2ms/batch - loss: 2.29900 - diff: 36.78mlTrain batch 21/32 - 82.7ms/batch - loss: 2.28484 - diff: 36.56mlTrain batch 22/32 - 96.6ms/batch - loss: 2.29559 - diff: 36.73mlTrain batch 23/32 - 111.8ms/batch - loss: 2.26629 - diff: 36.26mlTrain batch 24/32 - 104.3ms/batch - loss: 2.23604 - diff: 35.78mlTrain batch 25/32 - 81.8ms/batch - loss: 2.23269 - diff: 35.72mlTrain batch 26/32 - 94.4ms/batch - loss: 2.21391 - diff: 35.42mlTrain batch 27/32 - 75.5ms/batch - loss: 2.20776 - diff: 35.32mlTrain batch 28/32 - 96.0ms/batch - loss: 2.20934 - diff: 35.35mlTrain batch 29/32 - 59.7ms/batch - loss: 2.19892 - diff: 35.18mlTrain batch 30/32 - 86.3ms/batch - loss: 2.17746 - diff: 34.84mlTrain batch 31/32 - 57.9ms/batch - loss: 2.18201 - diff: 34.91mlTrain batch 32/32 - 50.3ms/batch - loss: 2.21592 - diff: 34.84mlTrain batch 32/32 - 15.8s 50.3ms/batch - loss: 2.21592 - diff: 34.84ml
Test 1.0s: val_loss: 2.27201 - diff: 35.18ml

Epoch 39: current best loss = 1.90353, at epoch 35
Train batch 1/32 - 118.2ms/batch - loss: 2.80319 - diff: 44.85mlTrain batch 2/32 - 94.0ms/batch - loss: 2.19780 - diff: 35.16mlTrain batch 3/32 - 76.7ms/batch - loss: 2.19423 - diff: 35.11mlTrain batch 4/32 - 74.7ms/batch - loss: 2.35362 - diff: 37.66mlTrain batch 5/32 - 82.3ms/batch - loss: 2.38376 - diff: 38.14mlTrain batch 6/32 - 80.3ms/batch - loss: 2.38869 - diff: 38.22mlTrain batch 7/32 - 90.9ms/batch - loss: 2.30062 - diff: 36.81mlTrain batch 8/32 - 90.2ms/batch - loss: 2.32732 - diff: 37.24mlTrain batch 9/32 - 74.0ms/batch - loss: 2.45511 - diff: 39.28mlTrain batch 10/32 - 99.7ms/batch - loss: 2.45637 - diff: 39.30mlTrain batch 11/32 - 99.0ms/batch - loss: 2.40367 - diff: 38.46mlTrain batch 12/32 - 93.7ms/batch - loss: 2.31805 - diff: 37.09mlTrain batch 13/32 - 78.9ms/batch - loss: 2.43342 - diff: 38.93mlTrain batch 14/32 - 83.9ms/batch - loss: 2.36472 - diff: 37.84mlTrain batch 15/32 - 66.8ms/batch - loss: 2.33948 - diff: 37.43mlTrain batch 16/32 - 93.5ms/batch - loss: 2.28785 - diff: 36.61mlTrain batch 17/32 - 83.7ms/batch - loss: 2.32277 - diff: 37.16mlTrain batch 18/32 - 83.0ms/batch - loss: 2.31244 - diff: 37.00mlTrain batch 19/32 - 97.7ms/batch - loss: 2.30472 - diff: 36.88mlTrain batch 20/32 - 80.7ms/batch - loss: 2.26360 - diff: 36.22mlTrain batch 21/32 - 79.9ms/batch - loss: 2.27402 - diff: 36.38mlTrain batch 22/32 - 110.6ms/batch - loss: 2.26844 - diff: 36.30mlTrain batch 23/32 - 83.6ms/batch - loss: 2.25737 - diff: 36.12mlTrain batch 24/32 - 99.6ms/batch - loss: 2.21359 - diff: 35.42mlTrain batch 25/32 - 86.2ms/batch - loss: 2.21437 - diff: 35.43mlTrain batch 26/32 - 107.9ms/batch - loss: 2.23583 - diff: 35.77mlTrain batch 27/32 - 100.8ms/batch - loss: 2.23624 - diff: 35.78mlTrain batch 28/32 - 82.5ms/batch - loss: 2.24348 - diff: 35.90mlTrain batch 29/32 - 103.2ms/batch - loss: 2.25728 - diff: 36.12mlTrain batch 30/32 - 101.4ms/batch - loss: 2.26743 - diff: 36.28mlTrain batch 31/32 - 68.7ms/batch - loss: 2.26534 - diff: 36.25mlTrain batch 32/32 - 72.9ms/batch - loss: 2.30549 - diff: 36.19mlTrain batch 32/32 - 16.5s 72.9ms/batch - loss: 2.30549 - diff: 36.19ml
Test 1.2s: val_loss: 2.26503 - diff: 35.37ml

Epoch 40: current best loss = 1.90353, at epoch 35
Train batch 1/32 - 95.2ms/batch - loss: 2.03514 - diff: 32.56mlTrain batch 2/32 - 98.3ms/batch - loss: 2.24490 - diff: 35.92mlTrain batch 3/32 - 97.8ms/batch - loss: 2.41499 - diff: 38.64mlTrain batch 4/32 - 81.7ms/batch - loss: 2.33069 - diff: 37.29mlTrain batch 5/32 - 86.5ms/batch - loss: 2.40567 - diff: 38.49mlTrain batch 6/32 - 104.5ms/batch - loss: 2.42878 - diff: 38.86mlTrain batch 7/32 - 87.0ms/batch - loss: 2.37107 - diff: 37.94mlTrain batch 8/32 - 103.0ms/batch - loss: 2.48514 - diff: 39.76mlTrain batch 9/32 - 83.6ms/batch - loss: 2.49722 - diff: 39.96mlTrain batch 10/32 - 105.8ms/batch - loss: 2.47753 - diff: 39.64mlTrain batch 11/32 - 74.0ms/batch - loss: 2.49196 - diff: 39.87mlTrain batch 12/32 - 126.5ms/batch - loss: 2.45732 - diff: 39.32mlTrain batch 13/32 - 89.2ms/batch - loss: 2.50409 - diff: 40.07mlTrain batch 14/32 - 99.3ms/batch - loss: 2.55473 - diff: 40.88mlTrain batch 15/32 - 107.8ms/batch - loss: 2.53440 - diff: 40.55mlTrain batch 16/32 - 107.2ms/batch - loss: 2.47802 - diff: 39.65mlTrain batch 17/32 - 79.6ms/batch - loss: 2.49256 - diff: 39.88mlTrain batch 18/32 - 100.9ms/batch - loss: 2.48202 - diff: 39.71mlTrain batch 19/32 - 119.0ms/batch - loss: 2.48048 - diff: 39.69mlTrain batch 20/32 - 129.4ms/batch - loss: 2.45989 - diff: 39.36mlTrain batch 21/32 - 90.5ms/batch - loss: 2.44423 - diff: 39.11mlTrain batch 22/32 - 84.1ms/batch - loss: 2.41794 - diff: 38.69mlTrain batch 23/32 - 93.0ms/batch - loss: 2.43892 - diff: 39.02mlTrain batch 24/32 - 89.3ms/batch - loss: 2.45299 - diff: 39.25mlTrain batch 25/32 - 83.6ms/batch - loss: 2.46151 - diff: 39.38mlTrain batch 26/32 - 87.8ms/batch - loss: 2.45354 - diff: 39.26mlTrain batch 27/32 - 74.5ms/batch - loss: 2.43466 - diff: 38.95mlTrain batch 28/32 - 93.3ms/batch - loss: 2.42455 - diff: 38.79mlTrain batch 29/32 - 85.6ms/batch - loss: 2.40928 - diff: 38.55mlTrain batch 30/32 - 97.4ms/batch - loss: 2.39151 - diff: 38.26mlTrain batch 31/32 - 78.6ms/batch - loss: 2.35602 - diff: 37.70mlTrain batch 32/32 - 79.4ms/batch - loss: 2.52262 - diff: 38.14mlTrain batch 32/32 - 15.7s 79.4ms/batch - loss: 2.52262 - diff: 38.14ml
Test 1.1s: val_loss: 2.27157 - diff: 34.97ml

Epoch 41: current best loss = 1.90353, at epoch 35
Train batch 1/32 - 98.7ms/batch - loss: 2.07803 - diff: 33.25mlTrain batch 2/32 - 83.3ms/batch - loss: 2.22546 - diff: 35.61mlTrain batch 3/32 - 92.9ms/batch - loss: 2.28715 - diff: 36.59mlTrain batch 4/32 - 91.6ms/batch - loss: 2.71886 - diff: 43.50mlTrain batch 5/32 - 112.6ms/batch - loss: 2.55338 - diff: 40.85mlTrain batch 6/32 - 103.5ms/batch - loss: 2.39500 - diff: 38.32mlTrain batch 7/32 - 83.4ms/batch - loss: 2.34316 - diff: 37.49mlTrain batch 8/32 - 93.1ms/batch - loss: 2.36167 - diff: 37.79mlTrain batch 9/32 - 84.9ms/batch - loss: 2.37616 - diff: 38.02mlTrain batch 10/32 - 93.7ms/batch - loss: 2.44214 - diff: 39.07mlTrain batch 11/32 - 94.8ms/batch - loss: 2.38104 - diff: 38.10mlTrain batch 12/32 - 97.1ms/batch - loss: 2.33889 - diff: 37.42mlTrain batch 13/32 - 80.1ms/batch - loss: 2.31601 - diff: 37.06mlTrain batch 14/32 - 116.8ms/batch - loss: 2.28398 - diff: 36.54mlTrain batch 15/32 - 94.6ms/batch - loss: 2.25948 - diff: 36.15mlTrain batch 16/32 - 99.7ms/batch - loss: 2.21732 - diff: 35.48mlTrain batch 17/32 - 95.2ms/batch - loss: 2.19162 - diff: 35.07mlTrain batch 18/32 - 77.6ms/batch - loss: 2.18745 - diff: 35.00mlTrain batch 19/32 - 75.7ms/batch - loss: 2.17081 - diff: 34.73mlTrain batch 20/32 - 82.9ms/batch - loss: 2.16428 - diff: 34.63mlTrain batch 21/32 - 74.9ms/batch - loss: 2.18430 - diff: 34.95mlTrain batch 22/32 - 82.5ms/batch - loss: 2.19406 - diff: 35.11mlTrain batch 23/32 - 72.5ms/batch - loss: 2.19872 - diff: 35.18mlTrain batch 24/32 - 92.5ms/batch - loss: 2.18723 - diff: 35.00mlTrain batch 25/32 - 81.0ms/batch - loss: 2.17398 - diff: 34.78mlTrain batch 26/32 - 88.5ms/batch - loss: 2.17774 - diff: 34.84mlTrain batch 27/32 - 76.1ms/batch - loss: 2.22589 - diff: 35.61mlTrain batch 28/32 - 84.9ms/batch - loss: 2.24510 - diff: 35.92mlTrain batch 29/32 - 82.0ms/batch - loss: 2.24892 - diff: 35.98mlTrain batch 30/32 - 75.2ms/batch - loss: 2.24350 - diff: 35.90mlTrain batch 31/32 - 87.3ms/batch - loss: 2.26732 - diff: 36.28mlTrain batch 32/32 - 94.1ms/batch - loss: 2.30712 - diff: 36.22mlTrain batch 32/32 - 17.4s 94.1ms/batch - loss: 2.30712 - diff: 36.22ml
Test 1.1s: val_loss: 2.30327 - diff: 34.90ml

Epoch 42: current best loss = 1.90353, at epoch 35
Train batch 1/32 - 114.2ms/batch - loss: 2.21398 - diff: 35.42mlTrain batch 2/32 - 87.7ms/batch - loss: 2.46446 - diff: 39.43mlTrain batch 3/32 - 87.9ms/batch - loss: 2.36794 - diff: 37.89mlTrain batch 4/32 - 78.9ms/batch - loss: 2.30955 - diff: 36.95mlTrain batch 5/32 - 96.0ms/batch - loss: 2.39827 - diff: 38.37mlTrain batch 6/32 - 77.6ms/batch - loss: 2.31716 - diff: 37.07mlTrain batch 7/32 - 87.6ms/batch - loss: 2.25952 - diff: 36.15mlTrain batch 8/32 - 80.3ms/batch - loss: 2.30002 - diff: 36.80mlTrain batch 9/32 - 99.0ms/batch - loss: 2.28331 - diff: 36.53mlTrain batch 10/32 - 86.8ms/batch - loss: 2.18922 - diff: 35.03mlTrain batch 11/32 - 79.2ms/batch - loss: 2.23987 - diff: 35.84mlTrain batch 12/32 - 79.1ms/batch - loss: 2.21769 - diff: 35.48mlTrain batch 13/32 - 81.1ms/batch - loss: 2.21879 - diff: 35.50mlTrain batch 14/32 - 78.5ms/batch - loss: 2.33451 - diff: 37.35mlTrain batch 15/32 - 92.5ms/batch - loss: 2.35261 - diff: 37.64mlTrain batch 16/32 - 96.7ms/batch - loss: 2.41163 - diff: 38.59mlTrain batch 17/32 - 76.9ms/batch - loss: 2.41123 - diff: 38.58mlTrain batch 18/32 - 77.3ms/batch - loss: 2.37484 - diff: 38.00mlTrain batch 19/32 - 73.9ms/batch - loss: 2.37084 - diff: 37.93mlTrain batch 20/32 - 87.7ms/batch - loss: 2.38759 - diff: 38.20mlTrain batch 21/32 - 94.2ms/batch - loss: 2.42219 - diff: 38.76mlTrain batch 22/32 - 86.6ms/batch - loss: 2.44623 - diff: 39.14mlTrain batch 23/32 - 87.5ms/batch - loss: 2.43695 - diff: 38.99mlTrain batch 24/32 - 86.4ms/batch - loss: 2.41505 - diff: 38.64mlTrain batch 25/32 - 101.5ms/batch - loss: 2.41291 - diff: 38.61mlTrain batch 26/32 - 78.4ms/batch - loss: 2.42282 - diff: 38.77mlTrain batch 27/32 - 90.9ms/batch - loss: 2.42175 - diff: 38.75mlTrain batch 28/32 - 73.9ms/batch - loss: 2.40618 - diff: 38.50mlTrain batch 29/32 - 66.0ms/batch - loss: 2.39618 - diff: 38.34mlTrain batch 30/32 - 59.6ms/batch - loss: 2.35846 - diff: 37.74mlTrain batch 31/32 - 68.2ms/batch - loss: 2.35062 - diff: 37.61mlTrain batch 32/32 - 59.2ms/batch - loss: 2.37564 - diff: 37.48mlTrain batch 32/32 - 17.1s 59.2ms/batch - loss: 2.37564 - diff: 37.48ml
Test 1.2s: val_loss: 2.39020 - diff: 36.49ml

Epoch 43: current best loss = 1.90353, at epoch 35
Train batch 1/32 - 82.1ms/batch - loss: 1.72398 - diff: 27.58mlTrain batch 2/32 - 60.0ms/batch - loss: 2.06221 - diff: 33.00mlTrain batch 3/32 - 61.6ms/batch - loss: 2.06869 - diff: 33.10mlTrain batch 4/32 - 73.6ms/batch - loss: 2.32894 - diff: 37.26mlTrain batch 5/32 - 89.3ms/batch - loss: 2.25716 - diff: 36.11mlTrain batch 6/32 - 71.4ms/batch - loss: 2.24474 - diff: 35.92mlTrain batch 7/32 - 87.7ms/batch - loss: 2.26826 - diff: 36.29mlTrain batch 8/32 - 92.4ms/batch - loss: 2.29788 - diff: 36.77mlTrain batch 9/32 - 92.6ms/batch - loss: 2.34437 - diff: 37.51mlTrain batch 10/32 - 86.6ms/batch - loss: 2.25783 - diff: 36.13mlTrain batch 11/32 - 86.3ms/batch - loss: 2.24825 - diff: 35.97mlTrain batch 12/32 - 134.4ms/batch - loss: 2.23878 - diff: 35.82mlTrain batch 13/32 - 93.5ms/batch - loss: 2.30058 - diff: 36.81mlTrain batch 14/32 - 150.5ms/batch - loss: 2.35403 - diff: 37.66mlTrain batch 15/32 - 88.4ms/batch - loss: 2.33050 - diff: 37.29mlTrain batch 16/32 - 60.0ms/batch - loss: 2.36021 - diff: 37.76mlTrain batch 17/32 - 79.2ms/batch - loss: 2.37954 - diff: 38.07mlTrain batch 18/32 - 58.5ms/batch - loss: 2.34578 - diff: 37.53mlTrain batch 19/32 - 92.5ms/batch - loss: 2.32799 - diff: 37.25mlTrain batch 20/32 - 92.5ms/batch - loss: 2.30761 - diff: 36.92mlTrain batch 21/32 - 64.0ms/batch - loss: 2.28006 - diff: 36.48mlTrain batch 22/32 - 92.3ms/batch - loss: 2.27538 - diff: 36.41mlTrain batch 23/32 - 87.6ms/batch - loss: 2.28184 - diff: 36.51mlTrain batch 24/32 - 101.7ms/batch - loss: 2.25567 - diff: 36.09mlTrain batch 25/32 - 63.3ms/batch - loss: 2.26942 - diff: 36.31mlTrain batch 26/32 - 103.8ms/batch - loss: 2.26023 - diff: 36.16mlTrain batch 27/32 - 74.3ms/batch - loss: 2.25472 - diff: 36.08mlTrain batch 28/32 - 84.8ms/batch - loss: 2.28876 - diff: 36.62mlTrain batch 29/32 - 86.4ms/batch - loss: 2.28828 - diff: 36.61mlTrain batch 30/32 - 91.2ms/batch - loss: 2.27511 - diff: 36.40mlTrain batch 31/32 - 64.7ms/batch - loss: 2.26766 - diff: 36.28mlTrain batch 32/32 - 98.8ms/batch - loss: 2.34623 - diff: 36.38mlTrain batch 32/32 - 16.0s 98.8ms/batch - loss: 2.34623 - diff: 36.38ml
Test 1.2s: val_loss: 2.38264 - diff: 37.14ml

Epoch 44: current best loss = 1.90353, at epoch 35
Train batch 1/32 - 112.2ms/batch - loss: 1.70023 - diff: 27.20mlTrain batch 2/32 - 90.8ms/batch - loss: 2.50519 - diff: 40.08mlTrain batch 3/32 - 94.3ms/batch - loss: 2.25659 - diff: 36.11mlTrain batch 4/32 - 103.8ms/batch - loss: 2.19143 - diff: 35.06mlTrain batch 5/32 - 112.7ms/batch - loss: 2.03162 - diff: 32.51mlTrain batch 6/32 - 105.0ms/batch - loss: 2.09906 - diff: 33.59mlTrain batch 7/32 - 60.2ms/batch - loss: 2.14941 - diff: 34.39mlTrain batch 8/32 - 58.8ms/batch - loss: 2.10275 - diff: 33.64mlTrain batch 9/32 - 113.5ms/batch - loss: 2.28816 - diff: 36.61mlTrain batch 10/32 - 58.4ms/batch - loss: 2.24810 - diff: 35.97mlTrain batch 11/32 - 80.4ms/batch - loss: 2.19080 - diff: 35.05mlTrain batch 12/32 - 89.4ms/batch - loss: 2.17747 - diff: 34.84mlTrain batch 13/32 - 88.1ms/batch - loss: 2.17296 - diff: 34.77mlTrain batch 14/32 - 100.3ms/batch - loss: 2.13979 - diff: 34.24mlTrain batch 15/32 - 81.3ms/batch - loss: 2.10388 - diff: 33.66mlTrain batch 16/32 - 104.6ms/batch - loss: 2.10508 - diff: 33.68mlTrain batch 17/32 - 76.8ms/batch - loss: 2.12399 - diff: 33.98mlTrain batch 18/32 - 112.2ms/batch - loss: 2.08891 - diff: 33.42mlTrain batch 19/32 - 71.9ms/batch - loss: 2.07836 - diff: 33.25mlTrain batch 20/32 - 76.1ms/batch - loss: 2.05556 - diff: 32.89mlTrain batch 21/32 - 72.0ms/batch - loss: 2.12537 - diff: 34.01mlTrain batch 22/32 - 112.6ms/batch - loss: 2.12836 - diff: 34.05mlTrain batch 23/32 - 66.7ms/batch - loss: 2.09033 - diff: 33.45mlTrain batch 24/32 - 73.4ms/batch - loss: 2.10846 - diff: 33.74mlTrain batch 25/32 - 72.6ms/batch - loss: 2.09144 - diff: 33.46mlTrain batch 26/32 - 71.8ms/batch - loss: 2.05906 - diff: 32.94mlTrain batch 27/32 - 96.0ms/batch - loss: 2.07742 - diff: 33.24mlTrain batch 28/32 - 74.5ms/batch - loss: 2.07328 - diff: 33.17mlTrain batch 29/32 - 86.1ms/batch - loss: 2.10610 - diff: 33.70mlTrain batch 30/32 - 104.5ms/batch - loss: 2.11971 - diff: 33.92mlTrain batch 31/32 - 67.8ms/batch - loss: 2.12000 - diff: 33.92mlTrain batch 32/32 - 54.7ms/batch - loss: 2.18221 - diff: 33.97mlTrain batch 32/32 - 17.3s 54.7ms/batch - loss: 2.18221 - diff: 33.97ml
Test 1.1s: val_loss: 2.40891 - diff: 36.87ml

Epoch 45: current best loss = 1.90353, at epoch 35
Going to unfreeze the pretrained weights
Train batch 1/32 - 209.6ms/batch - loss: 2.12336 - diff: 33.97mlTrain batch 2/32 - 184.6ms/batch - loss: 2.50050 - diff: 40.01mlTrain batch 3/32 - 177.1ms/batch - loss: 3.11288 - diff: 49.81mlTrain batch 4/32 - 194.9ms/batch - loss: 3.48772 - diff: 55.80mlTrain batch 5/32 - 151.3ms/batch - loss: 3.51972 - diff: 56.32mlTrain batch 6/32 - 136.9ms/batch - loss: 3.39424 - diff: 54.31mlTrain batch 7/32 - 159.2ms/batch - loss: 3.77192 - diff: 60.35mlTrain batch 8/32 - 183.4ms/batch - loss: 3.85146 - diff: 61.62mlTrain batch 9/32 - 134.7ms/batch - loss: 3.97634 - diff: 63.62mlTrain batch 10/32 - 161.1ms/batch - loss: 3.85497 - diff: 61.68mlTrain batch 11/32 - 165.1ms/batch - loss: 3.96014 - diff: 63.36mlTrain batch 12/32 - 149.4ms/batch - loss: 3.95915 - diff: 63.35mlTrain batch 13/32 - 157.0ms/batch - loss: 3.98388 - diff: 63.74mlTrain batch 14/32 - 131.2ms/batch - loss: 3.91806 - diff: 62.69mlTrain batch 15/32 - 170.0ms/batch - loss: 3.85404 - diff: 61.66mlTrain batch 16/32 - 216.8ms/batch - loss: 3.81728 - diff: 61.08mlTrain batch 17/32 - 183.5ms/batch - loss: 3.78028 - diff: 60.48mlTrain batch 18/32 - 138.5ms/batch - loss: 3.74094 - diff: 59.85mlTrain batch 19/32 - 176.3ms/batch - loss: 3.68408 - diff: 58.95mlTrain batch 20/32 - 138.0ms/batch - loss: 3.64835 - diff: 58.37mlTrain batch 21/32 - 174.7ms/batch - loss: 3.66215 - diff: 58.59mlTrain batch 22/32 - 190.0ms/batch - loss: 3.67779 - diff: 58.84mlTrain batch 23/32 - 163.5ms/batch - loss: 3.68490 - diff: 58.96mlTrain batch 24/32 - 134.5ms/batch - loss: 3.69591 - diff: 59.13mlTrain batch 25/32 - 173.3ms/batch - loss: 3.68597 - diff: 58.98mlTrain batch 26/32 - 161.3ms/batch - loss: 3.68866 - diff: 59.02mlTrain batch 27/32 - 156.4ms/batch - loss: 3.66533 - diff: 58.65mlTrain batch 28/32 - 167.9ms/batch - loss: 3.60358 - diff: 57.66mlTrain batch 29/32 - 131.9ms/batch - loss: 3.59499 - diff: 57.52mlTrain batch 30/32 - 137.6ms/batch - loss: 3.55837 - diff: 56.93mlTrain batch 31/32 - 124.2ms/batch - loss: 3.54792 - diff: 56.77mlTrain batch 32/32 - 113.1ms/batch - loss: 3.58893 - diff: 56.59mlTrain batch 32/32 - 17.2s 113.1ms/batch - loss: 3.58893 - diff: 56.59ml
Test 1.2s: val_loss: 8.44498 - diff: 129.77ml

Epoch 46: current best loss = 1.90353, at epoch 35
Train batch 1/32 - 178.6ms/batch - loss: 2.19141 - diff: 35.06mlTrain batch 2/32 - 187.7ms/batch - loss: 2.68159 - diff: 42.91mlTrain batch 3/32 - 170.5ms/batch - loss: 2.77907 - diff: 44.47mlTrain batch 4/32 - 132.5ms/batch - loss: 2.66851 - diff: 42.70mlTrain batch 5/32 - 141.0ms/batch - loss: 3.02048 - diff: 48.33mlTrain batch 6/32 - 142.2ms/batch - loss: 2.99020 - diff: 47.84mlTrain batch 7/32 - 163.0ms/batch - loss: 2.99792 - diff: 47.97mlTrain batch 8/32 - 211.0ms/batch - loss: 2.88258 - diff: 46.12mlTrain batch 9/32 - 167.7ms/batch - loss: 2.88453 - diff: 46.15mlTrain batch 10/32 - 125.1ms/batch - loss: 2.81555 - diff: 45.05mlTrain batch 11/32 - 172.0ms/batch - loss: 2.70148 - diff: 43.22mlTrain batch 12/32 - 211.8ms/batch - loss: 2.63672 - diff: 42.19mlTrain batch 13/32 - 154.6ms/batch - loss: 2.68239 - diff: 42.92mlTrain batch 14/32 - 171.3ms/batch - loss: 2.68768 - diff: 43.00mlTrain batch 15/32 - 129.3ms/batch - loss: 2.67312 - diff: 42.77mlTrain batch 16/32 - 139.5ms/batch - loss: 2.62084 - diff: 41.93mlTrain batch 17/32 - 164.8ms/batch - loss: 2.56830 - diff: 41.09mlTrain batch 18/32 - 133.4ms/batch - loss: 2.58457 - diff: 41.35mlTrain batch 19/32 - 169.5ms/batch - loss: 2.54297 - diff: 40.69mlTrain batch 20/32 - 189.4ms/batch - loss: 2.50618 - diff: 40.10mlTrain batch 21/32 - 176.8ms/batch - loss: 2.49893 - diff: 39.98mlTrain batch 22/32 - 197.2ms/batch - loss: 2.44347 - diff: 39.10mlTrain batch 23/32 - 157.4ms/batch - loss: 2.41875 - diff: 38.70mlTrain batch 24/32 - 152.1ms/batch - loss: 2.44404 - diff: 39.10mlTrain batch 25/32 - 124.3ms/batch - loss: 2.45433 - diff: 39.27mlTrain batch 26/32 - 140.4ms/batch - loss: 2.40256 - diff: 38.44mlTrain batch 27/32 - 153.6ms/batch - loss: 2.39494 - diff: 38.32mlTrain batch 28/32 - 133.3ms/batch - loss: 2.39138 - diff: 38.26mlTrain batch 29/32 - 163.9ms/batch - loss: 2.39353 - diff: 38.30mlTrain batch 30/32 - 195.1ms/batch - loss: 2.36008 - diff: 37.76mlTrain batch 31/32 - 111.1ms/batch - loss: 2.36098 - diff: 37.78mlTrain batch 32/32 - 102.7ms/batch - loss: 2.43605 - diff: 37.85mlTrain batch 32/32 - 17.8s 102.7ms/batch - loss: 2.43605 - diff: 37.85ml
Test 1.3s: val_loss: 2.25693 - diff: 34.25ml
Epoch    47: reducing learning rate of group 0 to 5.0000e-04.

Epoch 47: current best loss = 1.90353, at epoch 35
Train batch 1/32 - 207.1ms/batch - loss: 1.80917 - diff: 28.95mlTrain batch 2/32 - 136.7ms/batch - loss: 2.00042 - diff: 32.01mlTrain batch 3/32 - 111.5ms/batch - loss: 2.04023 - diff: 32.64mlTrain batch 4/32 - 106.4ms/batch - loss: 1.93368 - diff: 30.94mlTrain batch 5/32 - 152.0ms/batch - loss: 1.97985 - diff: 31.68mlTrain batch 6/32 - 110.6ms/batch - loss: 1.94048 - diff: 31.05mlTrain batch 7/32 - 102.6ms/batch - loss: 1.96355 - diff: 31.42mlTrain batch 8/32 - 122.5ms/batch - loss: 1.96403 - diff: 31.42mlTrain batch 9/32 - 179.0ms/batch - loss: 1.91219 - diff: 30.60mlTrain batch 10/32 - 175.6ms/batch - loss: 1.94778 - diff: 31.16mlTrain batch 11/32 - 173.2ms/batch - loss: 1.95484 - diff: 31.28mlTrain batch 12/32 - 196.8ms/batch - loss: 1.92856 - diff: 30.86mlTrain batch 13/32 - 185.9ms/batch - loss: 1.96287 - diff: 31.41mlTrain batch 14/32 - 198.0ms/batch - loss: 1.96192 - diff: 31.39mlTrain batch 15/32 - 118.0ms/batch - loss: 1.91919 - diff: 30.71mlTrain batch 16/32 - 126.7ms/batch - loss: 1.98517 - diff: 31.76mlTrain batch 17/32 - 145.9ms/batch - loss: 1.97307 - diff: 31.57mlTrain batch 18/32 - 183.2ms/batch - loss: 2.04229 - diff: 32.68mlTrain batch 19/32 - 161.5ms/batch - loss: 2.06087 - diff: 32.97mlTrain batch 20/32 - 104.9ms/batch - loss: 2.04924 - diff: 32.79mlTrain batch 21/32 - 123.7ms/batch - loss: 2.08451 - diff: 33.35mlTrain batch 22/32 - 151.8ms/batch - loss: 2.10027 - diff: 33.60mlTrain batch 23/32 - 147.4ms/batch - loss: 2.07486 - diff: 33.20mlTrain batch 24/32 - 103.3ms/batch - loss: 2.09105 - diff: 33.46mlTrain batch 25/32 - 162.5ms/batch - loss: 2.09109 - diff: 33.46mlTrain batch 26/32 - 157.1ms/batch - loss: 2.10646 - diff: 33.70mlTrain batch 27/32 - 181.1ms/batch - loss: 2.11244 - diff: 33.80mlTrain batch 28/32 - 119.0ms/batch - loss: 2.12387 - diff: 33.98mlTrain batch 29/32 - 190.0ms/batch - loss: 2.11414 - diff: 33.83mlTrain batch 30/32 - 167.5ms/batch - loss: 2.10402 - diff: 33.66mlTrain batch 31/32 - 148.0ms/batch - loss: 2.11191 - diff: 33.79mlTrain batch 32/32 - 139.9ms/batch - loss: 2.17196 - diff: 33.83mlTrain batch 32/32 - 17.5s 139.9ms/batch - loss: 2.17196 - diff: 33.83ml
Test 1.2s: val_loss: 1.75890 - diff: 26.81ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_DenseNet121_0_Adam-0.001_MAE_DA3_best

Epoch 48: current best loss = 1.75890, at epoch 47
Train batch 1/32 - 204.9ms/batch - loss: 2.05242 - diff: 32.84mlTrain batch 2/32 - 136.6ms/batch - loss: 1.82199 - diff: 29.15mlTrain batch 3/32 - 190.1ms/batch - loss: 1.51452 - diff: 24.23mlTrain batch 4/32 - 190.9ms/batch - loss: 1.65119 - diff: 26.42mlTrain batch 5/32 - 186.2ms/batch - loss: 1.79940 - diff: 28.79mlTrain batch 6/32 - 202.0ms/batch - loss: 1.73781 - diff: 27.80mlTrain batch 7/32 - 140.2ms/batch - loss: 1.85311 - diff: 29.65mlTrain batch 8/32 - 143.6ms/batch - loss: 1.86721 - diff: 29.88mlTrain batch 9/32 - 121.1ms/batch - loss: 1.86021 - diff: 29.76mlTrain batch 10/32 - 173.5ms/batch - loss: 1.89426 - diff: 30.31mlTrain batch 11/32 - 162.3ms/batch - loss: 1.88638 - diff: 30.18mlTrain batch 12/32 - 167.0ms/batch - loss: 1.87925 - diff: 30.07mlTrain batch 13/32 - 151.9ms/batch - loss: 1.85298 - diff: 29.65mlTrain batch 14/32 - 152.0ms/batch - loss: 1.94613 - diff: 31.14mlTrain batch 15/32 - 173.3ms/batch - loss: 1.92966 - diff: 30.87mlTrain batch 16/32 - 184.3ms/batch - loss: 1.90800 - diff: 30.53mlTrain batch 17/32 - 178.5ms/batch - loss: 1.88341 - diff: 30.13mlTrain batch 18/32 - 209.4ms/batch - loss: 1.87090 - diff: 29.93mlTrain batch 19/32 - 202.5ms/batch - loss: 1.87330 - diff: 29.97mlTrain batch 20/32 - 170.9ms/batch - loss: 1.86715 - diff: 29.87mlTrain batch 21/32 - 155.0ms/batch - loss: 1.85500 - diff: 29.68mlTrain batch 22/32 - 236.5ms/batch - loss: 1.87570 - diff: 30.01mlTrain batch 23/32 - 171.1ms/batch - loss: 1.92780 - diff: 30.84mlTrain batch 24/32 - 172.0ms/batch - loss: 1.89870 - diff: 30.38mlTrain batch 25/32 - 208.9ms/batch - loss: 1.86788 - diff: 29.89mlTrain batch 26/32 - 202.8ms/batch - loss: 1.86458 - diff: 29.83mlTrain batch 27/32 - 192.1ms/batch - loss: 1.82981 - diff: 29.28mlTrain batch 28/32 - 192.5ms/batch - loss: 1.81145 - diff: 28.98mlTrain batch 29/32 - 152.9ms/batch - loss: 1.80205 - diff: 28.83mlTrain batch 30/32 - 188.8ms/batch - loss: 1.81482 - diff: 29.04mlTrain batch 31/32 - 148.7ms/batch - loss: 1.80324 - diff: 28.85mlTrain batch 32/32 - 183.6ms/batch - loss: 1.81844 - diff: 28.74mlTrain batch 32/32 - 16.9s 183.6ms/batch - loss: 1.81844 - diff: 28.74ml
Test 1.3s: val_loss: 1.54221 - diff: 23.92ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_DenseNet121_0_Adam-0.001_MAE_DA3_best

Epoch 49: current best loss = 1.54221, at epoch 48
Train batch 1/32 - 192.7ms/batch - loss: 1.37088 - diff: 21.93mlTrain batch 2/32 - 176.9ms/batch - loss: 1.29917 - diff: 20.79mlTrain batch 3/32 - 120.9ms/batch - loss: 1.43361 - diff: 22.94mlTrain batch 4/32 - 149.8ms/batch - loss: 1.39655 - diff: 22.34mlTrain batch 5/32 - 172.2ms/batch - loss: 1.52719 - diff: 24.44mlTrain batch 6/32 - 161.3ms/batch - loss: 1.50045 - diff: 24.01mlTrain batch 7/32 - 170.0ms/batch - loss: 1.55424 - diff: 24.87mlTrain batch 8/32 - 186.2ms/batch - loss: 1.53556 - diff: 24.57mlTrain batch 9/32 - 177.6ms/batch - loss: 1.64180 - diff: 26.27mlTrain batch 10/32 - 206.7ms/batch - loss: 1.67847 - diff: 26.86mlTrain batch 11/32 - 189.3ms/batch - loss: 1.69495 - diff: 27.12mlTrain batch 12/32 - 196.4ms/batch - loss: 1.68402 - diff: 26.94mlTrain batch 13/32 - 162.4ms/batch - loss: 1.74412 - diff: 27.91mlTrain batch 14/32 - 172.8ms/batch - loss: 1.74111 - diff: 27.86mlTrain batch 15/32 - 142.0ms/batch - loss: 1.75546 - diff: 28.09mlTrain batch 16/32 - 142.6ms/batch - loss: 1.76843 - diff: 28.29mlTrain batch 17/32 - 163.2ms/batch - loss: 1.73636 - diff: 27.78mlTrain batch 18/32 - 204.5ms/batch - loss: 1.70459 - diff: 27.27mlTrain batch 19/32 - 145.5ms/batch - loss: 1.73248 - diff: 27.72mlTrain batch 20/32 - 136.7ms/batch - loss: 1.78782 - diff: 28.61mlTrain batch 21/32 - 177.6ms/batch - loss: 1.77545 - diff: 28.41mlTrain batch 22/32 - 175.8ms/batch - loss: 1.74243 - diff: 27.88mlTrain batch 23/32 - 174.6ms/batch - loss: 1.75001 - diff: 28.00mlTrain batch 24/32 - 195.7ms/batch - loss: 1.77696 - diff: 28.43mlTrain batch 25/32 - 119.3ms/batch - loss: 1.76771 - diff: 28.28mlTrain batch 26/32 - 104.6ms/batch - loss: 1.75798 - diff: 28.13mlTrain batch 27/32 - 102.4ms/batch - loss: 1.76798 - diff: 28.29mlTrain batch 28/32 - 153.3ms/batch - loss: 1.80171 - diff: 28.83mlTrain batch 29/32 - 164.9ms/batch - loss: 1.81452 - diff: 29.03mlTrain batch 30/32 - 154.2ms/batch - loss: 1.81782 - diff: 29.09mlTrain batch 31/32 - 103.1ms/batch - loss: 1.80687 - diff: 28.91mlTrain batch 32/32 - 96.0ms/batch - loss: 1.84143 - diff: 28.87mlTrain batch 32/32 - 17.4s 96.0ms/batch - loss: 1.84143 - diff: 28.87ml
Test 1.2s: val_loss: 1.61808 - diff: 24.52ml

Epoch 50: current best loss = 1.54221, at epoch 48
Train batch 1/32 - 221.4ms/batch - loss: 1.84282 - diff: 29.49mlTrain batch 2/32 - 186.0ms/batch - loss: 1.68768 - diff: 27.00mlTrain batch 3/32 - 174.9ms/batch - loss: 1.82471 - diff: 29.20mlTrain batch 4/32 - 191.9ms/batch - loss: 1.85428 - diff: 29.67mlTrain batch 5/32 - 168.8ms/batch - loss: 1.78915 - diff: 28.63mlTrain batch 6/32 - 193.2ms/batch - loss: 1.73124 - diff: 27.70mlTrain batch 7/32 - 145.1ms/batch - loss: 1.74846 - diff: 27.98mlTrain batch 8/32 - 146.3ms/batch - loss: 1.82139 - diff: 29.14mlTrain batch 9/32 - 183.8ms/batch - loss: 1.83159 - diff: 29.31mlTrain batch 10/32 - 181.5ms/batch - loss: 1.83942 - diff: 29.43mlTrain batch 11/32 - 134.6ms/batch - loss: 1.84592 - diff: 29.53mlTrain batch 12/32 - 147.8ms/batch - loss: 1.85547 - diff: 29.69mlTrain batch 13/32 - 178.7ms/batch - loss: 1.83449 - diff: 29.35mlTrain batch 14/32 - 143.3ms/batch - loss: 1.82263 - diff: 29.16mlTrain batch 15/32 - 104.0ms/batch - loss: 1.79185 - diff: 28.67mlTrain batch 16/32 - 136.8ms/batch - loss: 1.84268 - diff: 29.48mlTrain batch 17/32 - 169.0ms/batch - loss: 1.85393 - diff: 29.66mlTrain batch 18/32 - 181.5ms/batch - loss: 1.82739 - diff: 29.24mlTrain batch 19/32 - 170.3ms/batch - loss: 1.80270 - diff: 28.84mlTrain batch 20/32 - 139.8ms/batch - loss: 1.80533 - diff: 28.89mlTrain batch 21/32 - 129.7ms/batch - loss: 1.78987 - diff: 28.64mlTrain batch 22/32 - 155.2ms/batch - loss: 1.80870 - diff: 28.94mlTrain batch 23/32 - 152.1ms/batch - loss: 1.77968 - diff: 28.47mlTrain batch 24/32 - 143.9ms/batch - loss: 1.81141 - diff: 28.98mlTrain batch 25/32 - 147.6ms/batch - loss: 1.84087 - diff: 29.45mlTrain batch 26/32 - 201.5ms/batch - loss: 1.85406 - diff: 29.67mlTrain batch 27/32 - 164.7ms/batch - loss: 1.88353 - diff: 30.14mlTrain batch 28/32 - 141.9ms/batch - loss: 1.88810 - diff: 30.21mlTrain batch 29/32 - 139.2ms/batch - loss: 1.89031 - diff: 30.24mlTrain batch 30/32 - 151.9ms/batch - loss: 1.89294 - diff: 30.29mlTrain batch 31/32 - 169.0ms/batch - loss: 1.90375 - diff: 30.46mlTrain batch 32/32 - 150.5ms/batch - loss: 1.94120 - diff: 30.43mlTrain batch 32/32 - 15.7s 150.5ms/batch - loss: 1.94120 - diff: 30.43ml
Test 1.2s: val_loss: 1.85848 - diff: 28.67ml

Epoch 51: current best loss = 1.54221, at epoch 48
Train batch 1/32 - 234.6ms/batch - loss: 2.18935 - diff: 35.03mlTrain batch 2/32 - 176.0ms/batch - loss: 2.09574 - diff: 33.53mlTrain batch 3/32 - 164.1ms/batch - loss: 1.89946 - diff: 30.39mlTrain batch 4/32 - 144.6ms/batch - loss: 1.75736 - diff: 28.12mlTrain batch 5/32 - 178.7ms/batch - loss: 1.92583 - diff: 30.81mlTrain batch 6/32 - 199.9ms/batch - loss: 1.97828 - diff: 31.65mlTrain batch 7/32 - 186.5ms/batch - loss: 1.88918 - diff: 30.23mlTrain batch 8/32 - 184.6ms/batch - loss: 1.96763 - diff: 31.48mlTrain batch 9/32 - 167.3ms/batch - loss: 1.89027 - diff: 30.24mlTrain batch 10/32 - 168.7ms/batch - loss: 1.88803 - diff: 30.21mlTrain batch 11/32 - 140.8ms/batch - loss: 1.92804 - diff: 30.85mlTrain batch 12/32 - 180.2ms/batch - loss: 1.91199 - diff: 30.59mlTrain batch 13/32 - 186.3ms/batch - loss: 1.93571 - diff: 30.97mlTrain batch 14/32 - 155.1ms/batch - loss: 2.04125 - diff: 32.66mlTrain batch 15/32 - 150.5ms/batch - loss: 2.00559 - diff: 32.09mlTrain batch 16/32 - 128.2ms/batch - loss: 1.99362 - diff: 31.90mlTrain batch 17/32 - 135.3ms/batch - loss: 1.93549 - diff: 30.97mlTrain batch 18/32 - 176.9ms/batch - loss: 1.90056 - diff: 30.41mlTrain batch 19/32 - 213.4ms/batch - loss: 1.91710 - diff: 30.67mlTrain batch 20/32 - 136.2ms/batch - loss: 1.90741 - diff: 30.52mlTrain batch 21/32 - 176.6ms/batch - loss: 1.89161 - diff: 30.27mlTrain batch 22/32 - 165.3ms/batch - loss: 1.86120 - diff: 29.78mlTrain batch 23/32 - 164.3ms/batch - loss: 1.86020 - diff: 29.76mlTrain batch 24/32 - 161.8ms/batch - loss: 1.84319 - diff: 29.49mlTrain batch 25/32 - 140.2ms/batch - loss: 1.82009 - diff: 29.12mlTrain batch 26/32 - 160.6ms/batch - loss: 1.79679 - diff: 28.75mlTrain batch 27/32 - 175.4ms/batch - loss: 1.78270 - diff: 28.52mlTrain batch 28/32 - 180.0ms/batch - loss: 1.79085 - diff: 28.65mlTrain batch 29/32 - 134.8ms/batch - loss: 1.79290 - diff: 28.69mlTrain batch 30/32 - 163.5ms/batch - loss: 1.79999 - diff: 28.80mlTrain batch 31/32 - 167.3ms/batch - loss: 1.81040 - diff: 28.97mlTrain batch 32/32 - 159.1ms/batch - loss: 1.84285 - diff: 28.92mlTrain batch 32/32 - 17.6s 159.1ms/batch - loss: 1.84285 - diff: 28.92ml
Test 1.2s: val_loss: 1.84398 - diff: 28.34ml

Epoch 52: current best loss = 1.54221, at epoch 48
Train batch 1/32 - 143.1ms/batch - loss: 1.58229 - diff: 25.32mlTrain batch 2/32 - 166.1ms/batch - loss: 1.47984 - diff: 23.68mlTrain batch 3/32 - 154.8ms/batch - loss: 1.64449 - diff: 26.31mlTrain batch 4/32 - 111.9ms/batch - loss: 1.55604 - diff: 24.90mlTrain batch 5/32 - 170.1ms/batch - loss: 1.72530 - diff: 27.60mlTrain batch 6/32 - 205.8ms/batch - loss: 1.72417 - diff: 27.59mlTrain batch 7/32 - 209.5ms/batch - loss: 1.63498 - diff: 26.16mlTrain batch 8/32 - 173.6ms/batch - loss: 1.57057 - diff: 25.13mlTrain batch 9/32 - 150.2ms/batch - loss: 1.65761 - diff: 26.52mlTrain batch 10/32 - 189.0ms/batch - loss: 1.61573 - diff: 25.85mlTrain batch 11/32 - 119.9ms/batch - loss: 1.66948 - diff: 26.71mlTrain batch 12/32 - 115.2ms/batch - loss: 1.66283 - diff: 26.61mlTrain batch 13/32 - 144.4ms/batch - loss: 1.67379 - diff: 26.78mlTrain batch 14/32 - 134.2ms/batch - loss: 1.71385 - diff: 27.42mlTrain batch 15/32 - 128.8ms/batch - loss: 1.71954 - diff: 27.51mlTrain batch 16/32 - 133.3ms/batch - loss: 1.69520 - diff: 27.12mlTrain batch 17/32 - 149.6ms/batch - loss: 1.65337 - diff: 26.45mlTrain batch 18/32 - 181.3ms/batch - loss: 1.68035 - diff: 26.89mlTrain batch 19/32 - 166.9ms/batch - loss: 1.68560 - diff: 26.97mlTrain batch 20/32 - 121.2ms/batch - loss: 1.68125 - diff: 26.90mlTrain batch 21/32 - 123.4ms/batch - loss: 1.68401 - diff: 26.94mlTrain batch 22/32 - 144.6ms/batch - loss: 1.68873 - diff: 27.02mlTrain batch 23/32 - 145.9ms/batch - loss: 1.70668 - diff: 27.31mlTrain batch 24/32 - 181.1ms/batch - loss: 1.68741 - diff: 27.00mlTrain batch 25/32 - 199.4ms/batch - loss: 1.69404 - diff: 27.10mlTrain batch 26/32 - 190.2ms/batch - loss: 1.70548 - diff: 27.29mlTrain batch 27/32 - 186.3ms/batch - loss: 1.69814 - diff: 27.17mlTrain batch 28/32 - 224.6ms/batch - loss: 1.71342 - diff: 27.41mlTrain batch 29/32 - 141.0ms/batch - loss: 1.74325 - diff: 27.89mlTrain batch 30/32 - 156.7ms/batch - loss: 1.75286 - diff: 28.05mlTrain batch 31/32 - 139.1ms/batch - loss: 1.78804 - diff: 28.61mlTrain batch 32/32 - 186.9ms/batch - loss: 1.83336 - diff: 28.62mlTrain batch 32/32 - 17.7s 186.9ms/batch - loss: 1.83336 - diff: 28.62ml
Test 1.3s: val_loss: 1.52855 - diff: 23.74ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_DenseNet121_0_Adam-0.001_MAE_DA3_best

Epoch 53: current best loss = 1.52855, at epoch 52
Train batch 1/32 - 185.2ms/batch - loss: 1.85798 - diff: 29.73mlTrain batch 2/32 - 129.8ms/batch - loss: 2.28725 - diff: 36.60mlTrain batch 3/32 - 203.1ms/batch - loss: 1.95698 - diff: 31.31mlTrain batch 4/32 - 211.5ms/batch - loss: 1.84442 - diff: 29.51mlTrain batch 5/32 - 166.4ms/batch - loss: 1.74190 - diff: 27.87mlTrain batch 6/32 - 183.6ms/batch - loss: 1.75841 - diff: 28.13mlTrain batch 7/32 - 176.6ms/batch - loss: 1.77692 - diff: 28.43mlTrain batch 8/32 - 154.5ms/batch - loss: 1.89066 - diff: 30.25mlTrain batch 9/32 - 186.7ms/batch - loss: 1.98774 - diff: 31.80mlTrain batch 10/32 - 182.9ms/batch - loss: 2.02980 - diff: 32.48mlTrain batch 11/32 - 139.6ms/batch - loss: 1.97497 - diff: 31.60mlTrain batch 12/32 - 218.2ms/batch - loss: 1.96598 - diff: 31.46mlTrain batch 13/32 - 136.6ms/batch - loss: 1.92985 - diff: 30.88mlTrain batch 14/32 - 193.7ms/batch - loss: 1.89003 - diff: 30.24mlTrain batch 15/32 - 161.3ms/batch - loss: 1.90873 - diff: 30.54mlTrain batch 16/32 - 169.2ms/batch - loss: 1.91411 - diff: 30.63mlTrain batch 17/32 - 192.3ms/batch - loss: 1.92168 - diff: 30.75mlTrain batch 18/32 - 162.7ms/batch - loss: 1.96076 - diff: 31.37mlTrain batch 19/32 - 148.7ms/batch - loss: 1.92849 - diff: 30.86mlTrain batch 20/32 - 188.2ms/batch - loss: 1.92027 - diff: 30.72mlTrain batch 21/32 - 152.3ms/batch - loss: 1.93924 - diff: 31.03mlTrain batch 22/32 - 196.6ms/batch - loss: 1.89453 - diff: 30.31mlTrain batch 23/32 - 162.5ms/batch - loss: 1.88168 - diff: 30.11mlTrain batch 24/32 - 184.6ms/batch - loss: 1.86987 - diff: 29.92mlTrain batch 25/32 - 153.8ms/batch - loss: 1.88037 - diff: 30.09mlTrain batch 26/32 - 188.8ms/batch - loss: 1.85647 - diff: 29.70mlTrain batch 27/32 - 169.4ms/batch - loss: 1.85331 - diff: 29.65mlTrain batch 28/32 - 176.1ms/batch - loss: 1.83035 - diff: 29.29mlTrain batch 29/32 - 179.7ms/batch - loss: 1.81752 - diff: 29.08mlTrain batch 30/32 - 160.8ms/batch - loss: 1.85500 - diff: 29.68mlTrain batch 31/32 - 130.9ms/batch - loss: 1.84142 - diff: 29.46mlTrain batch 32/32 - 144.2ms/batch - loss: 1.90026 - diff: 29.52mlTrain batch 32/32 - 17.6s 144.2ms/batch - loss: 1.90026 - diff: 29.52ml
Test 1.1s: val_loss: 1.69422 - diff: 26.05ml

Epoch 54: current best loss = 1.52855, at epoch 52
Train batch 1/32 - 158.8ms/batch - loss: 1.27921 - diff: 20.47mlTrain batch 2/32 - 128.6ms/batch - loss: 1.34287 - diff: 21.49mlTrain batch 3/32 - 184.1ms/batch - loss: 1.35760 - diff: 21.72mlTrain batch 4/32 - 179.7ms/batch - loss: 1.65643 - diff: 26.50mlTrain batch 5/32 - 147.9ms/batch - loss: 1.71627 - diff: 27.46mlTrain batch 6/32 - 200.7ms/batch - loss: 1.64765 - diff: 26.36mlTrain batch 7/32 - 166.8ms/batch - loss: 1.72003 - diff: 27.52mlTrain batch 8/32 - 189.9ms/batch - loss: 1.75691 - diff: 28.11mlTrain batch 9/32 - 125.0ms/batch - loss: 1.72186 - diff: 27.55mlTrain batch 10/32 - 169.9ms/batch - loss: 1.71406 - diff: 27.43mlTrain batch 11/32 - 158.5ms/batch - loss: 1.73021 - diff: 27.68mlTrain batch 12/32 - 140.9ms/batch - loss: 1.70095 - diff: 27.22mlTrain batch 13/32 - 131.7ms/batch - loss: 1.70243 - diff: 27.24mlTrain batch 14/32 - 152.5ms/batch - loss: 1.69980 - diff: 27.20mlTrain batch 15/32 - 156.2ms/batch - loss: 1.75752 - diff: 28.12mlTrain batch 16/32 - 150.2ms/batch - loss: 1.76701 - diff: 28.27mlTrain batch 17/32 - 138.3ms/batch - loss: 1.78308 - diff: 28.53mlTrain batch 18/32 - 117.0ms/batch - loss: 1.76676 - diff: 28.27mlTrain batch 19/32 - 160.3ms/batch - loss: 1.78154 - diff: 28.50mlTrain batch 20/32 - 132.8ms/batch - loss: 1.77530 - diff: 28.40mlTrain batch 21/32 - 140.5ms/batch - loss: 1.77806 - diff: 28.45mlTrain batch 22/32 - 171.5ms/batch - loss: 1.73511 - diff: 27.76mlTrain batch 23/32 - 216.8ms/batch - loss: 1.72866 - diff: 27.66mlTrain batch 24/32 - 150.7ms/batch - loss: 1.72228 - diff: 27.56mlTrain batch 25/32 - 187.9ms/batch - loss: 1.71223 - diff: 27.40mlTrain batch 26/32 - 163.8ms/batch - loss: 1.69062 - diff: 27.05mlTrain batch 27/32 - 228.0ms/batch - loss: 1.67453 - diff: 26.79mlTrain batch 28/32 - 161.2ms/batch - loss: 1.64867 - diff: 26.38mlTrain batch 29/32 - 148.1ms/batch - loss: 1.64049 - diff: 26.25mlTrain batch 30/32 - 172.0ms/batch - loss: 1.64520 - diff: 26.32mlTrain batch 31/32 - 118.7ms/batch - loss: 1.65757 - diff: 26.52mlTrain batch 32/32 - 104.2ms/batch - loss: 1.67883 - diff: 26.45mlTrain batch 32/32 - 16.9s 104.2ms/batch - loss: 1.67883 - diff: 26.45ml
Test 1.2s: val_loss: 1.89469 - diff: 29.30ml

Epoch 55: current best loss = 1.52855, at epoch 52
Train batch 1/32 - 199.7ms/batch - loss: 1.78011 - diff: 28.48mlTrain batch 2/32 - 195.0ms/batch - loss: 1.41643 - diff: 22.66mlTrain batch 3/32 - 162.7ms/batch - loss: 1.47886 - diff: 23.66mlTrain batch 4/32 - 143.1ms/batch - loss: 1.57710 - diff: 25.23mlTrain batch 5/32 - 105.8ms/batch - loss: 1.66650 - diff: 26.66mlTrain batch 6/32 - 169.6ms/batch - loss: 1.70095 - diff: 27.22mlTrain batch 7/32 - 173.2ms/batch - loss: 1.77652 - diff: 28.42mlTrain batch 8/32 - 155.7ms/batch - loss: 1.67549 - diff: 26.81mlTrain batch 9/32 - 127.8ms/batch - loss: 1.62589 - diff: 26.01mlTrain batch 10/32 - 135.8ms/batch - loss: 1.57680 - diff: 25.23mlTrain batch 11/32 - 140.3ms/batch - loss: 1.64074 - diff: 26.25mlTrain batch 12/32 - 144.5ms/batch - loss: 1.66498 - diff: 26.64mlTrain batch 13/32 - 158.9ms/batch - loss: 1.66756 - diff: 26.68mlTrain batch 14/32 - 195.9ms/batch - loss: 1.69079 - diff: 27.05mlTrain batch 15/32 - 133.0ms/batch - loss: 1.67471 - diff: 26.80mlTrain batch 16/32 - 147.6ms/batch - loss: 1.67784 - diff: 26.85mlTrain batch 17/32 - 143.9ms/batch - loss: 1.67916 - diff: 26.87mlTrain batch 18/32 - 137.4ms/batch - loss: 1.69329 - diff: 27.09mlTrain batch 19/32 - 150.4ms/batch - loss: 1.68107 - diff: 26.90mlTrain batch 20/32 - 146.7ms/batch - loss: 1.63724 - diff: 26.20mlTrain batch 21/32 - 146.7ms/batch - loss: 1.62161 - diff: 25.95mlTrain batch 22/32 - 190.9ms/batch - loss: 1.61917 - diff: 25.91mlTrain batch 23/32 - 181.9ms/batch - loss: 1.62319 - diff: 25.97mlTrain batch 24/32 - 187.6ms/batch - loss: 1.62464 - diff: 25.99mlTrain batch 25/32 - 148.3ms/batch - loss: 1.60851 - diff: 25.74mlTrain batch 26/32 - 159.3ms/batch - loss: 1.61297 - diff: 25.81mlTrain batch 27/32 - 168.7ms/batch - loss: 1.61261 - diff: 25.80mlTrain batch 28/32 - 174.7ms/batch - loss: 1.64609 - diff: 26.34mlTrain batch 29/32 - 173.9ms/batch - loss: 1.63773 - diff: 26.20mlTrain batch 30/32 - 181.7ms/batch - loss: 1.64458 - diff: 26.31mlTrain batch 31/32 - 129.5ms/batch - loss: 1.64566 - diff: 26.33mlTrain batch 32/32 - 138.6ms/batch - loss: 1.72720 - diff: 26.50mlTrain batch 32/32 - 16.7s 138.6ms/batch - loss: 1.72720 - diff: 26.50ml
Test 1.1s: val_loss: 2.16586 - diff: 33.21ml

Epoch 56: current best loss = 1.52855, at epoch 52
Train batch 1/32 - 179.7ms/batch - loss: 1.63004 - diff: 26.08mlTrain batch 2/32 - 172.5ms/batch - loss: 1.95007 - diff: 31.20mlTrain batch 3/32 - 152.1ms/batch - loss: 1.83558 - diff: 29.37mlTrain batch 4/32 - 137.0ms/batch - loss: 1.74170 - diff: 27.87mlTrain batch 5/32 - 198.7ms/batch - loss: 1.90691 - diff: 30.51mlTrain batch 6/32 - 184.7ms/batch - loss: 1.81907 - diff: 29.11mlTrain batch 7/32 - 169.8ms/batch - loss: 1.65776 - diff: 26.52mlTrain batch 8/32 - 218.1ms/batch - loss: 1.67172 - diff: 26.75mlTrain batch 9/32 - 168.6ms/batch - loss: 1.65096 - diff: 26.42mlTrain batch 10/32 - 150.4ms/batch - loss: 1.62931 - diff: 26.07mlTrain batch 11/32 - 179.3ms/batch - loss: 1.63664 - diff: 26.19mlTrain batch 12/32 - 156.1ms/batch - loss: 1.67554 - diff: 26.81mlTrain batch 13/32 - 141.6ms/batch - loss: 1.67762 - diff: 26.84mlTrain batch 14/32 - 176.7ms/batch - loss: 1.66399 - diff: 26.62mlTrain batch 15/32 - 148.0ms/batch - loss: 1.63312 - diff: 26.13mlTrain batch 16/32 - 148.0ms/batch - loss: 1.62242 - diff: 25.96mlTrain batch 17/32 - 131.3ms/batch - loss: 1.62799 - diff: 26.05mlTrain batch 18/32 - 141.3ms/batch - loss: 1.61577 - diff: 25.85mlTrain batch 19/32 - 161.6ms/batch - loss: 1.58136 - diff: 25.30mlTrain batch 20/32 - 151.5ms/batch - loss: 1.60676 - diff: 25.71mlTrain batch 21/32 - 176.7ms/batch - loss: 1.58036 - diff: 25.29mlTrain batch 22/32 - 190.9ms/batch - loss: 1.58465 - diff: 25.35mlTrain batch 23/32 - 157.6ms/batch - loss: 1.59130 - diff: 25.46mlTrain batch 24/32 - 187.4ms/batch - loss: 1.58955 - diff: 25.43mlTrain batch 25/32 - 173.1ms/batch - loss: 1.57041 - diff: 25.13mlTrain batch 26/32 - 183.5ms/batch - loss: 1.56760 - diff: 25.08mlTrain batch 27/32 - 172.7ms/batch - loss: 1.57804 - diff: 25.25mlTrain batch 28/32 - 200.4ms/batch - loss: 1.56679 - diff: 25.07mlTrain batch 29/32 - 192.9ms/batch - loss: 1.56246 - diff: 25.00mlTrain batch 30/32 - 164.8ms/batch - loss: 1.55131 - diff: 24.82mlTrain batch 31/32 - 180.6ms/batch - loss: 1.54807 - diff: 24.77mlTrain batch 32/32 - 198.3ms/batch - loss: 1.57885 - diff: 24.74mlTrain batch 32/32 - 16.9s 198.3ms/batch - loss: 1.57885 - diff: 24.74ml
Test 1.2s: val_loss: 1.62495 - diff: 24.66ml

Epoch 57: current best loss = 1.52855, at epoch 52
Train batch 1/32 - 221.8ms/batch - loss: 1.49893 - diff: 23.98mlTrain batch 2/32 - 202.2ms/batch - loss: 1.37876 - diff: 22.06mlTrain batch 3/32 - 125.5ms/batch - loss: 1.74611 - diff: 27.94mlTrain batch 4/32 - 139.1ms/batch - loss: 1.87433 - diff: 29.99mlTrain batch 5/32 - 149.1ms/batch - loss: 1.88170 - diff: 30.11mlTrain batch 6/32 - 174.9ms/batch - loss: 1.85612 - diff: 29.70mlTrain batch 7/32 - 165.6ms/batch - loss: 1.81382 - diff: 29.02mlTrain batch 8/32 - 178.1ms/batch - loss: 1.86905 - diff: 29.90mlTrain batch 9/32 - 189.1ms/batch - loss: 1.88006 - diff: 30.08mlTrain batch 10/32 - 196.4ms/batch - loss: 1.86292 - diff: 29.81mlTrain batch 11/32 - 186.2ms/batch - loss: 1.83553 - diff: 29.37mlTrain batch 12/32 - 124.0ms/batch - loss: 1.80767 - diff: 28.92mlTrain batch 13/32 - 125.7ms/batch - loss: 1.76109 - diff: 28.18mlTrain batch 14/32 - 160.6ms/batch - loss: 1.75020 - diff: 28.00mlTrain batch 15/32 - 184.5ms/batch - loss: 1.71157 - diff: 27.39mlTrain batch 16/32 - 213.8ms/batch - loss: 1.69224 - diff: 27.08mlTrain batch 17/32 - 149.0ms/batch - loss: 1.66250 - diff: 26.60mlTrain batch 18/32 - 186.1ms/batch - loss: 1.62608 - diff: 26.02mlTrain batch 19/32 - 171.7ms/batch - loss: 1.62049 - diff: 25.93mlTrain batch 20/32 - 174.6ms/batch - loss: 1.62248 - diff: 25.96mlTrain batch 21/32 - 160.6ms/batch - loss: 1.61680 - diff: 25.87mlTrain batch 22/32 - 144.1ms/batch - loss: 1.61727 - diff: 25.88mlTrain batch 23/32 - 174.9ms/batch - loss: 1.59162 - diff: 25.47mlTrain batch 24/32 - 172.5ms/batch - loss: 1.58024 - diff: 25.28mlTrain batch 25/32 - 178.3ms/batch - loss: 1.61575 - diff: 25.85mlTrain batch 26/32 - 158.5ms/batch - loss: 1.62391 - diff: 25.98mlTrain batch 27/32 - 148.7ms/batch - loss: 1.60540 - diff: 25.69mlTrain batch 28/32 - 170.4ms/batch - loss: 1.61354 - diff: 25.82mlTrain batch 29/32 - 164.1ms/batch - loss: 1.59700 - diff: 25.55mlTrain batch 30/32 - 194.4ms/batch - loss: 1.59428 - diff: 25.51mlTrain batch 31/32 - 124.9ms/batch - loss: 1.58373 - diff: 25.34mlTrain batch 32/32 - 112.1ms/batch - loss: 1.59298 - diff: 25.22mlTrain batch 32/32 - 16.7s 112.1ms/batch - loss: 1.59298 - diff: 25.22ml
Test 1.1s: val_loss: 1.47931 - diff: 22.68ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_DenseNet121_0_Adam-0.001_MAE_DA3_best

Epoch 58: current best loss = 1.47931, at epoch 57
Train batch 1/32 - 126.7ms/batch - loss: 1.28170 - diff: 20.51mlTrain batch 2/32 - 125.4ms/batch - loss: 1.77158 - diff: 28.35mlTrain batch 3/32 - 147.0ms/batch - loss: 1.81056 - diff: 28.97mlTrain batch 4/32 - 163.4ms/batch - loss: 1.75980 - diff: 28.16mlTrain batch 5/32 - 200.6ms/batch - loss: 1.79932 - diff: 28.79mlTrain batch 6/32 - 130.9ms/batch - loss: 1.64745 - diff: 26.36mlTrain batch 7/32 - 157.7ms/batch - loss: 1.59405 - diff: 25.50mlTrain batch 8/32 - 186.3ms/batch - loss: 1.57896 - diff: 25.26mlTrain batch 9/32 - 174.6ms/batch - loss: 1.56936 - diff: 25.11mlTrain batch 10/32 - 173.9ms/batch - loss: 1.59454 - diff: 25.51mlTrain batch 11/32 - 185.8ms/batch - loss: 1.65969 - diff: 26.55mlTrain batch 12/32 - 209.1ms/batch - loss: 1.66807 - diff: 26.69mlTrain batch 13/32 - 128.8ms/batch - loss: 1.68450 - diff: 26.95mlTrain batch 14/32 - 156.4ms/batch - loss: 1.71436 - diff: 27.43mlTrain batch 15/32 - 165.5ms/batch - loss: 1.71061 - diff: 27.37mlTrain batch 16/32 - 186.1ms/batch - loss: 1.72409 - diff: 27.59mlTrain batch 17/32 - 160.5ms/batch - loss: 1.70362 - diff: 27.26mlTrain batch 18/32 - 113.3ms/batch - loss: 1.68118 - diff: 26.90mlTrain batch 19/32 - 124.3ms/batch - loss: 1.67041 - diff: 26.73mlTrain batch 20/32 - 111.4ms/batch - loss: 1.68658 - diff: 26.99mlTrain batch 21/32 - 187.8ms/batch - loss: 1.66454 - diff: 26.63mlTrain batch 22/32 - 145.2ms/batch - loss: 1.68494 - diff: 26.96mlTrain batch 23/32 - 128.8ms/batch - loss: 1.67411 - diff: 26.79mlTrain batch 24/32 - 153.3ms/batch - loss: 1.67980 - diff: 26.88mlTrain batch 25/32 - 113.0ms/batch - loss: 1.66722 - diff: 26.68mlTrain batch 26/32 - 111.0ms/batch - loss: 1.66974 - diff: 26.72mlTrain batch 27/32 - 111.5ms/batch - loss: 1.65509 - diff: 26.48mlTrain batch 28/32 - 114.1ms/batch - loss: 1.63790 - diff: 26.21mlTrain batch 29/32 - 131.2ms/batch - loss: 1.63571 - diff: 26.17mlTrain batch 30/32 - 140.5ms/batch - loss: 1.62493 - diff: 26.00mlTrain batch 31/32 - 123.2ms/batch - loss: 1.67350 - diff: 26.78mlTrain batch 32/32 - 168.5ms/batch - loss: 1.71031 - diff: 26.76mlTrain batch 32/32 - 16.0s 168.5ms/batch - loss: 1.71031 - diff: 26.76ml
Test 1.1s: val_loss: 1.88572 - diff: 28.79ml

Epoch 59: current best loss = 1.47931, at epoch 57
Train batch 1/32 - 116.5ms/batch - loss: 1.27039 - diff: 20.33mlTrain batch 2/32 - 104.1ms/batch - loss: 1.09721 - diff: 17.56mlTrain batch 3/32 - 152.9ms/batch - loss: 1.26699 - diff: 20.27mlTrain batch 4/32 - 200.8ms/batch - loss: 1.47317 - diff: 23.57mlTrain batch 5/32 - 184.7ms/batch - loss: 1.50989 - diff: 24.16mlTrain batch 6/32 - 128.1ms/batch - loss: 1.49571 - diff: 23.93mlTrain batch 7/32 - 126.0ms/batch - loss: 1.51126 - diff: 24.18mlTrain batch 8/32 - 204.6ms/batch - loss: 1.47046 - diff: 23.53mlTrain batch 9/32 - 165.5ms/batch - loss: 1.46540 - diff: 23.45mlTrain batch 10/32 - 121.5ms/batch - loss: 1.46629 - diff: 23.46mlTrain batch 11/32 - 133.3ms/batch - loss: 1.41727 - diff: 22.68mlTrain batch 12/32 - 105.0ms/batch - loss: 1.41990 - diff: 22.72mlTrain batch 13/32 - 141.0ms/batch - loss: 1.46555 - diff: 23.45mlTrain batch 14/32 - 167.5ms/batch - loss: 1.46574 - diff: 23.45mlTrain batch 15/32 - 159.5ms/batch - loss: 1.50523 - diff: 24.08mlTrain batch 16/32 - 141.7ms/batch - loss: 1.51046 - diff: 24.17mlTrain batch 17/32 - 193.6ms/batch - loss: 1.52620 - diff: 24.42mlTrain batch 18/32 - 125.8ms/batch - loss: 1.56269 - diff: 25.00mlTrain batch 19/32 - 154.4ms/batch - loss: 1.54491 - diff: 24.72mlTrain batch 20/32 - 119.5ms/batch - loss: 1.60089 - diff: 25.61mlTrain batch 21/32 - 124.8ms/batch - loss: 1.59023 - diff: 25.44mlTrain batch 22/32 - 124.4ms/batch - loss: 1.58893 - diff: 25.42mlTrain batch 23/32 - 171.5ms/batch - loss: 1.59089 - diff: 25.45mlTrain batch 24/32 - 159.8ms/batch - loss: 1.58825 - diff: 25.41mlTrain batch 25/32 - 145.5ms/batch - loss: 1.58335 - diff: 25.33mlTrain batch 26/32 - 174.4ms/batch - loss: 1.56497 - diff: 25.04mlTrain batch 27/32 - 181.5ms/batch - loss: 1.63384 - diff: 26.14mlTrain batch 28/32 - 202.3ms/batch - loss: 1.65227 - diff: 26.44mlTrain batch 29/32 - 143.1ms/batch - loss: 1.68456 - diff: 26.95mlTrain batch 30/32 - 155.3ms/batch - loss: 1.68687 - diff: 26.99mlTrain batch 31/32 - 205.2ms/batch - loss: 1.67644 - diff: 26.82mlTrain batch 32/32 - 149.4ms/batch - loss: 1.72536 - diff: 26.86mlTrain batch 32/32 - 17.5s 149.4ms/batch - loss: 1.72536 - diff: 26.86ml
Test 1.3s: val_loss: 1.61260 - diff: 25.12ml

Epoch 60: current best loss = 1.47931, at epoch 57
Train batch 1/32 - 143.8ms/batch - loss: 1.15722 - diff: 18.52mlTrain batch 2/32 - 118.9ms/batch - loss: 1.81620 - diff: 29.06mlTrain batch 3/32 - 193.1ms/batch - loss: 1.85583 - diff: 29.69mlTrain batch 4/32 - 155.3ms/batch - loss: 1.71745 - diff: 27.48mlTrain batch 5/32 - 166.7ms/batch - loss: 1.66743 - diff: 26.68mlTrain batch 6/32 - 173.6ms/batch - loss: 1.57409 - diff: 25.19mlTrain batch 7/32 - 148.2ms/batch - loss: 1.55709 - diff: 24.91mlTrain batch 8/32 - 148.1ms/batch - loss: 1.50116 - diff: 24.02mlTrain batch 9/32 - 182.5ms/batch - loss: 1.49595 - diff: 23.94mlTrain batch 10/32 - 186.9ms/batch - loss: 1.57248 - diff: 25.16mlTrain batch 11/32 - 178.2ms/batch - loss: 1.57977 - diff: 25.28mlTrain batch 12/32 - 165.3ms/batch - loss: 1.62164 - diff: 25.95mlTrain batch 13/32 - 202.7ms/batch - loss: 1.57100 - diff: 25.14mlTrain batch 14/32 - 161.1ms/batch - loss: 1.53587 - diff: 24.57mlTrain batch 15/32 - 190.0ms/batch - loss: 1.50576 - diff: 24.09mlTrain batch 16/32 - 185.0ms/batch - loss: 1.51804 - diff: 24.29mlTrain batch 17/32 - 138.9ms/batch - loss: 1.51771 - diff: 24.28mlTrain batch 18/32 - 149.2ms/batch - loss: 1.55748 - diff: 24.92mlTrain batch 19/32 - 169.2ms/batch - loss: 1.57447 - diff: 25.19mlTrain batch 20/32 - 189.5ms/batch - loss: 1.57750 - diff: 25.24mlTrain batch 21/32 - 166.1ms/batch - loss: 1.57371 - diff: 25.18mlTrain batch 22/32 - 153.7ms/batch - loss: 1.57878 - diff: 25.26mlTrain batch 23/32 - 161.1ms/batch - loss: 1.59106 - diff: 25.46mlTrain batch 24/32 - 156.9ms/batch - loss: 1.57360 - diff: 25.18mlTrain batch 25/32 - 150.2ms/batch - loss: 1.56630 - diff: 25.06mlTrain batch 26/32 - 177.2ms/batch - loss: 1.58755 - diff: 25.40mlTrain batch 27/32 - 143.1ms/batch - loss: 1.58838 - diff: 25.41mlTrain batch 28/32 - 176.3ms/batch - loss: 1.58963 - diff: 25.43mlTrain batch 29/32 - 165.7ms/batch - loss: 1.58149 - diff: 25.30mlTrain batch 30/32 - 166.9ms/batch - loss: 1.60416 - diff: 25.67mlTrain batch 31/32 - 155.8ms/batch - loss: 1.60159 - diff: 25.63mlTrain batch 32/32 - 132.9ms/batch - loss: 1.66657 - diff: 25.73mlTrain batch 32/32 - 17.6s 132.9ms/batch - loss: 1.66657 - diff: 25.73ml
Test 1.2s: val_loss: 1.60102 - diff: 24.66ml

Epoch 61: current best loss = 1.47931, at epoch 57
Train batch 1/32 - 169.3ms/batch - loss: 1.76476 - diff: 28.24mlTrain batch 2/32 - 129.7ms/batch - loss: 1.68176 - diff: 26.91mlTrain batch 3/32 - 196.7ms/batch - loss: 1.61580 - diff: 25.85mlTrain batch 4/32 - 134.3ms/batch - loss: 1.57049 - diff: 25.13mlTrain batch 5/32 - 170.8ms/batch - loss: 1.66749 - diff: 26.68mlTrain batch 6/32 - 152.2ms/batch - loss: 1.71639 - diff: 27.46mlTrain batch 7/32 - 182.4ms/batch - loss: 1.78513 - diff: 28.56mlTrain batch 8/32 - 180.8ms/batch - loss: 1.73231 - diff: 27.72mlTrain batch 9/32 - 175.8ms/batch - loss: 1.72131 - diff: 27.54mlTrain batch 10/32 - 181.3ms/batch - loss: 1.71190 - diff: 27.39mlTrain batch 11/32 - 156.5ms/batch - loss: 1.65623 - diff: 26.50mlTrain batch 12/32 - 187.9ms/batch - loss: 1.67910 - diff: 26.87mlTrain batch 13/32 - 164.5ms/batch - loss: 1.75039 - diff: 28.01mlTrain batch 14/32 - 140.1ms/batch - loss: 1.73510 - diff: 27.76mlTrain batch 15/32 - 119.8ms/batch - loss: 1.70208 - diff: 27.23mlTrain batch 16/32 - 103.9ms/batch - loss: 1.68978 - diff: 27.04mlTrain batch 17/32 - 147.3ms/batch - loss: 1.74070 - diff: 27.85mlTrain batch 18/32 - 169.1ms/batch - loss: 1.78861 - diff: 28.62mlTrain batch 19/32 - 163.3ms/batch - loss: 1.77451 - diff: 28.39mlTrain batch 20/32 - 191.7ms/batch - loss: 1.75289 - diff: 28.05mlTrain batch 21/32 - 151.0ms/batch - loss: 1.75191 - diff: 28.03mlTrain batch 22/32 - 110.6ms/batch - loss: 1.73986 - diff: 27.84mlTrain batch 23/32 - 160.4ms/batch - loss: 1.71320 - diff: 27.41mlTrain batch 24/32 - 141.5ms/batch - loss: 1.72476 - diff: 27.60mlTrain batch 25/32 - 157.1ms/batch - loss: 1.72082 - diff: 27.53mlTrain batch 26/32 - 178.0ms/batch - loss: 1.72582 - diff: 27.61mlTrain batch 27/32 - 153.6ms/batch - loss: 1.71825 - diff: 27.49mlTrain batch 28/32 - 109.7ms/batch - loss: 1.72654 - diff: 27.62mlTrain batch 29/32 - 130.7ms/batch - loss: 1.71379 - diff: 27.42mlTrain batch 30/32 - 140.7ms/batch - loss: 1.70027 - diff: 27.20mlTrain batch 31/32 - 157.5ms/batch - loss: 1.69378 - diff: 27.10mlTrain batch 32/32 - 145.8ms/batch - loss: 1.74809 - diff: 27.16mlTrain batch 32/32 - 18.5s 145.8ms/batch - loss: 1.74809 - diff: 27.16ml
Test 1.2s: val_loss: 1.40062 - diff: 21.62ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_DenseNet121_0_Adam-0.001_MAE_DA3_best

Epoch 62: current best loss = 1.40062, at epoch 61
Train batch 1/32 - 195.2ms/batch - loss: 1.60012 - diff: 25.60mlTrain batch 2/32 - 158.3ms/batch - loss: 1.63900 - diff: 26.22mlTrain batch 3/32 - 145.2ms/batch - loss: 1.57321 - diff: 25.17mlTrain batch 4/32 - 160.4ms/batch - loss: 1.74164 - diff: 27.87mlTrain batch 5/32 - 127.0ms/batch - loss: 1.58607 - diff: 25.38mlTrain batch 6/32 - 121.2ms/batch - loss: 1.47513 - diff: 23.60mlTrain batch 7/32 - 134.0ms/batch - loss: 1.42854 - diff: 22.86mlTrain batch 8/32 - 119.9ms/batch - loss: 1.36732 - diff: 21.88mlTrain batch 9/32 - 121.8ms/batch - loss: 1.36047 - diff: 21.77mlTrain batch 10/32 - 176.7ms/batch - loss: 1.39645 - diff: 22.34mlTrain batch 11/32 - 116.9ms/batch - loss: 1.34743 - diff: 21.56mlTrain batch 12/32 - 155.5ms/batch - loss: 1.32339 - diff: 21.17mlTrain batch 13/32 - 171.3ms/batch - loss: 1.31872 - diff: 21.10mlTrain batch 14/32 - 146.8ms/batch - loss: 1.30280 - diff: 20.84mlTrain batch 15/32 - 155.4ms/batch - loss: 1.32938 - diff: 21.27mlTrain batch 16/32 - 190.6ms/batch - loss: 1.29134 - diff: 20.66mlTrain batch 17/32 - 152.2ms/batch - loss: 1.28377 - diff: 20.54mlTrain batch 18/32 - 196.9ms/batch - loss: 1.33681 - diff: 21.39mlTrain batch 19/32 - 121.8ms/batch - loss: 1.35423 - diff: 21.67mlTrain batch 20/32 - 104.7ms/batch - loss: 1.37533 - diff: 22.01mlTrain batch 21/32 - 139.5ms/batch - loss: 1.39907 - diff: 22.39mlTrain batch 22/32 - 119.6ms/batch - loss: 1.42249 - diff: 22.76mlTrain batch 23/32 - 180.2ms/batch - loss: 1.41634 - diff: 22.66mlTrain batch 24/32 - 200.5ms/batch - loss: 1.41412 - diff: 22.63mlTrain batch 25/32 - 168.3ms/batch - loss: 1.42245 - diff: 22.76mlTrain batch 26/32 - 175.9ms/batch - loss: 1.42209 - diff: 22.75mlTrain batch 27/32 - 138.7ms/batch - loss: 1.42553 - diff: 22.81mlTrain batch 28/32 - 151.9ms/batch - loss: 1.44037 - diff: 23.05mlTrain batch 29/32 - 180.6ms/batch - loss: 1.42955 - diff: 22.87mlTrain batch 30/32 - 196.4ms/batch - loss: 1.41745 - diff: 22.68mlTrain batch 31/32 - 142.2ms/batch - loss: 1.41095 - diff: 22.58mlTrain batch 32/32 - 123.5ms/batch - loss: 1.50230 - diff: 22.81mlTrain batch 32/32 - 16.9s 123.5ms/batch - loss: 1.50230 - diff: 22.81ml
Test 1.2s: val_loss: 1.48459 - diff: 23.03ml

Epoch 63: current best loss = 1.40062, at epoch 61
Train batch 1/32 - 157.8ms/batch - loss: 1.32573 - diff: 21.21mlTrain batch 2/32 - 212.3ms/batch - loss: 1.26173 - diff: 20.19mlTrain batch 3/32 - 163.6ms/batch - loss: 1.29216 - diff: 20.67mlTrain batch 4/32 - 147.1ms/batch - loss: 1.27662 - diff: 20.43mlTrain batch 5/32 - 174.1ms/batch - loss: 1.31073 - diff: 20.97mlTrain batch 6/32 - 139.1ms/batch - loss: 1.51465 - diff: 24.23mlTrain batch 7/32 - 186.3ms/batch - loss: 1.50539 - diff: 24.09mlTrain batch 8/32 - 109.4ms/batch - loss: 1.52210 - diff: 24.35mlTrain batch 9/32 - 150.9ms/batch - loss: 1.50204 - diff: 24.03mlTrain batch 10/32 - 161.7ms/batch - loss: 1.47698 - diff: 23.63mlTrain batch 11/32 - 203.8ms/batch - loss: 1.43794 - diff: 23.01mlTrain batch 12/32 - 174.7ms/batch - loss: 1.44585 - diff: 23.13mlTrain batch 13/32 - 141.1ms/batch - loss: 1.49687 - diff: 23.95mlTrain batch 14/32 - 119.4ms/batch - loss: 1.60551 - diff: 25.69mlTrain batch 15/32 - 171.5ms/batch - loss: 1.59612 - diff: 25.54mlTrain batch 16/32 - 164.0ms/batch - loss: 1.59100 - diff: 25.46mlTrain batch 17/32 - 201.8ms/batch - loss: 1.59582 - diff: 25.53mlTrain batch 18/32 - 166.5ms/batch - loss: 1.56235 - diff: 25.00mlTrain batch 19/32 - 133.7ms/batch - loss: 1.54867 - diff: 24.78mlTrain batch 20/32 - 162.9ms/batch - loss: 1.57433 - diff: 25.19mlTrain batch 21/32 - 178.0ms/batch - loss: 1.57175 - diff: 25.15mlTrain batch 22/32 - 194.0ms/batch - loss: 1.57746 - diff: 25.24mlTrain batch 23/32 - 121.9ms/batch - loss: 1.55731 - diff: 24.92mlTrain batch 24/32 - 105.7ms/batch - loss: 1.53826 - diff: 24.61mlTrain batch 25/32 - 164.7ms/batch - loss: 1.52684 - diff: 24.43mlTrain batch 26/32 - 188.5ms/batch - loss: 1.52680 - diff: 24.43mlTrain batch 27/32 - 173.9ms/batch - loss: 1.51165 - diff: 24.19mlTrain batch 28/32 - 199.0ms/batch - loss: 1.51515 - diff: 24.24mlTrain batch 29/32 - 143.4ms/batch - loss: 1.49417 - diff: 23.91mlTrain batch 30/32 - 109.7ms/batch - loss: 1.49971 - diff: 24.00mlTrain batch 31/32 - 136.8ms/batch - loss: 1.49558 - diff: 23.93mlTrain batch 32/32 - 136.2ms/batch - loss: 1.58119 - diff: 24.13mlTrain batch 32/32 - 18.5s 136.2ms/batch - loss: 1.58119 - diff: 24.13ml
Test 1.1s: val_loss: 1.37417 - diff: 21.12ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_DenseNet121_0_Adam-0.001_MAE_DA3_best

Epoch 64: current best loss = 1.37417, at epoch 63
Train batch 1/32 - 179.6ms/batch - loss: 1.11477 - diff: 17.84mlTrain batch 2/32 - 182.7ms/batch - loss: 1.26446 - diff: 20.23mlTrain batch 3/32 - 182.3ms/batch - loss: 1.29466 - diff: 20.71mlTrain batch 4/32 - 198.3ms/batch - loss: 1.28181 - diff: 20.51mlTrain batch 5/32 - 173.9ms/batch - loss: 1.24926 - diff: 19.99mlTrain batch 6/32 - 189.5ms/batch - loss: 1.35913 - diff: 21.75mlTrain batch 7/32 - 186.2ms/batch - loss: 1.29882 - diff: 20.78mlTrain batch 8/32 - 181.3ms/batch - loss: 1.31544 - diff: 21.05mlTrain batch 9/32 - 164.9ms/batch - loss: 1.32143 - diff: 21.14mlTrain batch 10/32 - 167.4ms/batch - loss: 1.30653 - diff: 20.90mlTrain batch 11/32 - 182.5ms/batch - loss: 1.31335 - diff: 21.01mlTrain batch 12/32 - 121.7ms/batch - loss: 1.35618 - diff: 21.70mlTrain batch 13/32 - 194.8ms/batch - loss: 1.36313 - diff: 21.81mlTrain batch 14/32 - 148.7ms/batch - loss: 1.37433 - diff: 21.99mlTrain batch 15/32 - 177.6ms/batch - loss: 1.39614 - diff: 22.34mlTrain batch 16/32 - 149.2ms/batch - loss: 1.45423 - diff: 23.27mlTrain batch 17/32 - 211.8ms/batch - loss: 1.47382 - diff: 23.58mlTrain batch 18/32 - 183.6ms/batch - loss: 1.46538 - diff: 23.45mlTrain batch 19/32 - 157.6ms/batch - loss: 1.46833 - diff: 23.49mlTrain batch 20/32 - 180.4ms/batch - loss: 1.44550 - diff: 23.13mlTrain batch 21/32 - 161.4ms/batch - loss: 1.45900 - diff: 23.34mlTrain batch 22/32 - 181.6ms/batch - loss: 1.43972 - diff: 23.04mlTrain batch 23/32 - 173.5ms/batch - loss: 1.44969 - diff: 23.20mlTrain batch 24/32 - 162.5ms/batch - loss: 1.44637 - diff: 23.14mlTrain batch 25/32 - 139.8ms/batch - loss: 1.47470 - diff: 23.60mlTrain batch 26/32 - 170.7ms/batch - loss: 1.51385 - diff: 24.22mlTrain batch 27/32 - 137.4ms/batch - loss: 1.53882 - diff: 24.62mlTrain batch 28/32 - 169.7ms/batch - loss: 1.54189 - diff: 24.67mlTrain batch 29/32 - 185.7ms/batch - loss: 1.53723 - diff: 24.60mlTrain batch 30/32 - 105.4ms/batch - loss: 1.54319 - diff: 24.69mlTrain batch 31/32 - 136.6ms/batch - loss: 1.53504 - diff: 24.56mlTrain batch 32/32 - 157.7ms/batch - loss: 1.58767 - diff: 24.62mlTrain batch 32/32 - 15.8s 157.7ms/batch - loss: 1.58767 - diff: 24.62ml
Test 1.2s: val_loss: 1.46219 - diff: 22.40ml

Epoch 65: current best loss = 1.37417, at epoch 63
Train batch 1/32 - 178.9ms/batch - loss: 1.86204 - diff: 29.79mlTrain batch 2/32 - 156.9ms/batch - loss: 1.81751 - diff: 29.08mlTrain batch 3/32 - 174.8ms/batch - loss: 1.83452 - diff: 29.35mlTrain batch 4/32 - 158.5ms/batch - loss: 1.66669 - diff: 26.67mlTrain batch 5/32 - 185.2ms/batch - loss: 1.54666 - diff: 24.75mlTrain batch 6/32 - 107.0ms/batch - loss: 1.65712 - diff: 26.51mlTrain batch 7/32 - 155.6ms/batch - loss: 1.66248 - diff: 26.60mlTrain batch 8/32 - 115.3ms/batch - loss: 1.59855 - diff: 25.58mlTrain batch 9/32 - 147.0ms/batch - loss: 1.53699 - diff: 24.59mlTrain batch 10/32 - 133.3ms/batch - loss: 1.52765 - diff: 24.44mlTrain batch 11/32 - 119.4ms/batch - loss: 1.50387 - diff: 24.06mlTrain batch 12/32 - 160.4ms/batch - loss: 1.50853 - diff: 24.14mlTrain batch 13/32 - 170.6ms/batch - loss: 1.48484 - diff: 23.76mlTrain batch 14/32 - 171.7ms/batch - loss: 1.51093 - diff: 24.17mlTrain batch 15/32 - 201.5ms/batch - loss: 1.50716 - diff: 24.11mlTrain batch 16/32 - 196.1ms/batch - loss: 1.48066 - diff: 23.69mlTrain batch 17/32 - 202.4ms/batch - loss: 1.46021 - diff: 23.36mlTrain batch 18/32 - 178.5ms/batch - loss: 1.44733 - diff: 23.16mlTrain batch 19/32 - 191.5ms/batch - loss: 1.45766 - diff: 23.32mlTrain batch 20/32 - 137.8ms/batch - loss: 1.47264 - diff: 23.56mlTrain batch 21/32 - 172.9ms/batch - loss: 1.46255 - diff: 23.40mlTrain batch 22/32 - 173.4ms/batch - loss: 1.47046 - diff: 23.53mlTrain batch 23/32 - 190.9ms/batch - loss: 1.45547 - diff: 23.29mlTrain batch 24/32 - 159.1ms/batch - loss: 1.44348 - diff: 23.10mlTrain batch 25/32 - 164.5ms/batch - loss: 1.44170 - diff: 23.07mlTrain batch 26/32 - 175.1ms/batch - loss: 1.46887 - diff: 23.50mlTrain batch 27/32 - 215.9ms/batch - loss: 1.44590 - diff: 23.13mlTrain batch 28/32 - 178.8ms/batch - loss: 1.47174 - diff: 23.55mlTrain batch 29/32 - 169.2ms/batch - loss: 1.46817 - diff: 23.49mlTrain batch 30/32 - 123.8ms/batch - loss: 1.47368 - diff: 23.58mlTrain batch 31/32 - 123.5ms/batch - loss: 1.49703 - diff: 23.95mlTrain batch 32/32 - 137.0ms/batch - loss: 1.50803 - diff: 23.85mlTrain batch 32/32 - 16.3s 137.0ms/batch - loss: 1.50803 - diff: 23.85ml
Test 1.4s: val_loss: 1.54589 - diff: 23.20ml

Epoch 66: current best loss = 1.37417, at epoch 63
Train batch 1/32 - 175.1ms/batch - loss: 1.56072 - diff: 24.97mlTrain batch 2/32 - 165.4ms/batch - loss: 1.66986 - diff: 26.72mlTrain batch 3/32 - 172.4ms/batch - loss: 1.66744 - diff: 26.68mlTrain batch 4/32 - 175.5ms/batch - loss: 1.60798 - diff: 25.73mlTrain batch 5/32 - 162.2ms/batch - loss: 1.45194 - diff: 23.23mlTrain batch 6/32 - 182.4ms/batch - loss: 1.49514 - diff: 23.92mlTrain batch 7/32 - 202.0ms/batch - loss: 1.42621 - diff: 22.82mlTrain batch 8/32 - 148.5ms/batch - loss: 1.42082 - diff: 22.73mlTrain batch 9/32 - 200.5ms/batch - loss: 1.45925 - diff: 23.35mlTrain batch 10/32 - 160.0ms/batch - loss: 1.41339 - diff: 22.61mlTrain batch 11/32 - 144.4ms/batch - loss: 1.43994 - diff: 23.04mlTrain batch 12/32 - 182.1ms/batch - loss: 1.43054 - diff: 22.89mlTrain batch 13/32 - 181.4ms/batch - loss: 1.41325 - diff: 22.61mlTrain batch 14/32 - 201.3ms/batch - loss: 1.40163 - diff: 22.43mlTrain batch 15/32 - 156.1ms/batch - loss: 1.38854 - diff: 22.22mlTrain batch 16/32 - 169.0ms/batch - loss: 1.45350 - diff: 23.26mlTrain batch 17/32 - 135.8ms/batch - loss: 1.48728 - diff: 23.80mlTrain batch 18/32 - 172.3ms/batch - loss: 1.48223 - diff: 23.72mlTrain batch 19/32 - 135.0ms/batch - loss: 1.46646 - diff: 23.46mlTrain batch 20/32 - 214.8ms/batch - loss: 1.46495 - diff: 23.44mlTrain batch 21/32 - 148.2ms/batch - loss: 1.46352 - diff: 23.42mlTrain batch 22/32 - 228.1ms/batch - loss: 1.45344 - diff: 23.25mlTrain batch 23/32 - 164.1ms/batch - loss: 1.46332 - diff: 23.41mlTrain batch 24/32 - 201.1ms/batch - loss: 1.47001 - diff: 23.52mlTrain batch 25/32 - 167.9ms/batch - loss: 1.47182 - diff: 23.55mlTrain batch 26/32 - 154.4ms/batch - loss: 1.45672 - diff: 23.31mlTrain batch 27/32 - 154.2ms/batch - loss: 1.44642 - diff: 23.14mlTrain batch 28/32 - 174.1ms/batch - loss: 1.42633 - diff: 22.82mlTrain batch 29/32 - 152.7ms/batch - loss: 1.42377 - diff: 22.78mlTrain batch 30/32 - 167.2ms/batch - loss: 1.40397 - diff: 22.46mlTrain batch 31/32 - 149.4ms/batch - loss: 1.38871 - diff: 22.22mlTrain batch 32/32 - 177.6ms/batch - loss: 1.47095 - diff: 22.42mlTrain batch 32/32 - 17.2s 177.6ms/batch - loss: 1.47095 - diff: 22.42ml
Test 1.3s: val_loss: 1.40829 - diff: 22.00ml

Epoch 67: current best loss = 1.37417, at epoch 63
Train batch 1/32 - 175.2ms/batch - loss: 1.75879 - diff: 28.14mlTrain batch 2/32 - 159.0ms/batch - loss: 1.75391 - diff: 28.06mlTrain batch 3/32 - 168.7ms/batch - loss: 1.77267 - diff: 28.36mlTrain batch 4/32 - 184.1ms/batch - loss: 1.66154 - diff: 26.58mlTrain batch 5/32 - 136.4ms/batch - loss: 1.59368 - diff: 25.50mlTrain batch 6/32 - 168.6ms/batch - loss: 1.51434 - diff: 24.23mlTrain batch 7/32 - 142.8ms/batch - loss: 1.45005 - diff: 23.20mlTrain batch 8/32 - 186.8ms/batch - loss: 1.49973 - diff: 24.00mlTrain batch 9/32 - 144.6ms/batch - loss: 1.56725 - diff: 25.08mlTrain batch 10/32 - 165.2ms/batch - loss: 1.56543 - diff: 25.05mlTrain batch 11/32 - 145.4ms/batch - loss: 1.55200 - diff: 24.83mlTrain batch 12/32 - 127.8ms/batch - loss: 1.49328 - diff: 23.89mlTrain batch 13/32 - 157.3ms/batch - loss: 1.51078 - diff: 24.17mlTrain batch 14/32 - 182.8ms/batch - loss: 1.49603 - diff: 23.94mlTrain batch 15/32 - 157.1ms/batch - loss: 1.47418 - diff: 23.59mlTrain batch 16/32 - 167.5ms/batch - loss: 1.43272 - diff: 22.92mlTrain batch 17/32 - 195.9ms/batch - loss: 1.42403 - diff: 22.78mlTrain batch 18/32 - 194.3ms/batch - loss: 1.41083 - diff: 22.57mlTrain batch 19/32 - 212.2ms/batch - loss: 1.45695 - diff: 23.31mlTrain batch 20/32 - 158.8ms/batch - loss: 1.45927 - diff: 23.35mlTrain batch 21/32 - 171.9ms/batch - loss: 1.43990 - diff: 23.04mlTrain batch 22/32 - 211.6ms/batch - loss: 1.44266 - diff: 23.08mlTrain batch 23/32 - 156.0ms/batch - loss: 1.42548 - diff: 22.81mlTrain batch 24/32 - 181.1ms/batch - loss: 1.41926 - diff: 22.71mlTrain batch 25/32 - 149.0ms/batch - loss: 1.41161 - diff: 22.59mlTrain batch 26/32 - 178.0ms/batch - loss: 1.40889 - diff: 22.54mlTrain batch 27/32 - 188.5ms/batch - loss: 1.40265 - diff: 22.44mlTrain batch 28/32 - 185.9ms/batch - loss: 1.40778 - diff: 22.52mlTrain batch 29/32 - 163.1ms/batch - loss: 1.40117 - diff: 22.42mlTrain batch 30/32 - 127.5ms/batch - loss: 1.39273 - diff: 22.28mlTrain batch 31/32 - 158.7ms/batch - loss: 1.38076 - diff: 22.09mlTrain batch 32/32 - 167.1ms/batch - loss: 1.41984 - diff: 22.12mlTrain batch 32/32 - 17.1s 167.1ms/batch - loss: 1.41984 - diff: 22.12ml
Test 1.2s: val_loss: 1.60295 - diff: 24.31ml

Epoch 68: current best loss = 1.37417, at epoch 63
Train batch 1/32 - 211.6ms/batch - loss: 1.32281 - diff: 21.17mlTrain batch 2/32 - 194.7ms/batch - loss: 1.17566 - diff: 18.81mlTrain batch 3/32 - 136.8ms/batch - loss: 1.06782 - diff: 17.09mlTrain batch 4/32 - 189.0ms/batch - loss: 1.17534 - diff: 18.81mlTrain batch 5/32 - 158.9ms/batch - loss: 1.19616 - diff: 19.14mlTrain batch 6/32 - 157.7ms/batch - loss: 1.32079 - diff: 21.13mlTrain batch 7/32 - 132.2ms/batch - loss: 1.43070 - diff: 22.89mlTrain batch 8/32 - 145.5ms/batch - loss: 1.37602 - diff: 22.02mlTrain batch 9/32 - 163.3ms/batch - loss: 1.36177 - diff: 21.79mlTrain batch 10/32 - 184.6ms/batch - loss: 1.49014 - diff: 23.84mlTrain batch 11/32 - 174.0ms/batch - loss: 1.46105 - diff: 23.38mlTrain batch 12/32 - 160.5ms/batch - loss: 1.42738 - diff: 22.84mlTrain batch 13/32 - 171.5ms/batch - loss: 1.42460 - diff: 22.79mlTrain batch 14/32 - 144.6ms/batch - loss: 1.40332 - diff: 22.45mlTrain batch 15/32 - 146.5ms/batch - loss: 1.39036 - diff: 22.25mlTrain batch 16/32 - 141.4ms/batch - loss: 1.51699 - diff: 24.27mlTrain batch 17/32 - 183.8ms/batch - loss: 1.57405 - diff: 25.18mlTrain batch 18/32 - 142.8ms/batch - loss: 1.55116 - diff: 24.82mlTrain batch 19/32 - 114.9ms/batch - loss: 1.54023 - diff: 24.64mlTrain batch 20/32 - 175.6ms/batch - loss: 1.56483 - diff: 25.04mlTrain batch 21/32 - 145.1ms/batch - loss: 1.58003 - diff: 25.28mlTrain batch 22/32 - 166.5ms/batch - loss: 1.56373 - diff: 25.02mlTrain batch 23/32 - 159.8ms/batch - loss: 1.56828 - diff: 25.09mlTrain batch 24/32 - 177.5ms/batch - loss: 1.57592 - diff: 25.21mlTrain batch 25/32 - 164.5ms/batch - loss: 1.57307 - diff: 25.17mlTrain batch 26/32 - 166.8ms/batch - loss: 1.59361 - diff: 25.50mlTrain batch 27/32 - 177.8ms/batch - loss: 1.60113 - diff: 25.62mlTrain batch 28/32 - 167.0ms/batch - loss: 1.58337 - diff: 25.33mlTrain batch 29/32 - 152.0ms/batch - loss: 1.56849 - diff: 25.10mlTrain batch 30/32 - 142.2ms/batch - loss: 1.57585 - diff: 25.21mlTrain batch 31/32 - 154.9ms/batch - loss: 1.57842 - diff: 25.25mlTrain batch 32/32 - 108.8ms/batch - loss: 1.62389 - diff: 25.29mlTrain batch 32/32 - 16.2s 108.8ms/batch - loss: 1.62389 - diff: 25.29ml
Test 1.2s: val_loss: 1.63359 - diff: 25.34ml

Epoch 69: current best loss = 1.37417, at epoch 63
Train batch 1/32 - 187.8ms/batch - loss: 1.91025 - diff: 30.56mlTrain batch 2/32 - 204.7ms/batch - loss: 1.69830 - diff: 27.17mlTrain batch 3/32 - 136.8ms/batch - loss: 1.47227 - diff: 23.56mlTrain batch 4/32 - 131.0ms/batch - loss: 1.54295 - diff: 24.69mlTrain batch 5/32 - 165.5ms/batch - loss: 1.52188 - diff: 24.35mlTrain batch 6/32 - 182.0ms/batch - loss: 1.45514 - diff: 23.28mlTrain batch 7/32 - 204.4ms/batch - loss: 1.56860 - diff: 25.10mlTrain batch 8/32 - 167.4ms/batch - loss: 1.54268 - diff: 24.68mlTrain batch 9/32 - 163.6ms/batch - loss: 1.51654 - diff: 24.26mlTrain batch 10/32 - 160.6ms/batch - loss: 1.46111 - diff: 23.38mlTrain batch 11/32 - 144.1ms/batch - loss: 1.43467 - diff: 22.95mlTrain batch 12/32 - 182.5ms/batch - loss: 1.48474 - diff: 23.76mlTrain batch 13/32 - 181.5ms/batch - loss: 1.47318 - diff: 23.57mlTrain batch 14/32 - 183.1ms/batch - loss: 1.46431 - diff: 23.43mlTrain batch 15/32 - 132.4ms/batch - loss: 1.45353 - diff: 23.26mlTrain batch 16/32 - 179.0ms/batch - loss: 1.52045 - diff: 24.33mlTrain batch 17/32 - 186.4ms/batch - loss: 1.49582 - diff: 23.93mlTrain batch 18/32 - 192.1ms/batch - loss: 1.51021 - diff: 24.16mlTrain batch 19/32 - 134.0ms/batch - loss: 1.54146 - diff: 24.66mlTrain batch 20/32 - 119.7ms/batch - loss: 1.58242 - diff: 25.32mlTrain batch 21/32 - 162.9ms/batch - loss: 1.60841 - diff: 25.73mlTrain batch 22/32 - 166.7ms/batch - loss: 1.61210 - diff: 25.79mlTrain batch 23/32 - 119.1ms/batch - loss: 1.59578 - diff: 25.53mlTrain batch 24/32 - 165.3ms/batch - loss: 1.58813 - diff: 25.41mlTrain batch 25/32 - 164.4ms/batch - loss: 1.59035 - diff: 25.45mlTrain batch 26/32 - 163.5ms/batch - loss: 1.58129 - diff: 25.30mlTrain batch 27/32 - 117.5ms/batch - loss: 1.57502 - diff: 25.20mlTrain batch 28/32 - 160.6ms/batch - loss: 1.57278 - diff: 25.16mlTrain batch 29/32 - 146.8ms/batch - loss: 1.55691 - diff: 24.91mlTrain batch 30/32 - 130.4ms/batch - loss: 1.55305 - diff: 24.85mlTrain batch 31/32 - 150.9ms/batch - loss: 1.54746 - diff: 24.76mlTrain batch 32/32 - 121.0ms/batch - loss: 1.57466 - diff: 24.72mlTrain batch 32/32 - 15.4s 121.0ms/batch - loss: 1.57466 - diff: 24.72ml
Test 1.2s: val_loss: 1.63148 - diff: 24.80ml

Epoch 70: current best loss = 1.37417, at epoch 63
Train batch 1/32 - 172.0ms/batch - loss: 1.17274 - diff: 18.76mlTrain batch 2/32 - 181.4ms/batch - loss: 1.19060 - diff: 19.05mlTrain batch 3/32 - 206.0ms/batch - loss: 1.15237 - diff: 18.44mlTrain batch 4/32 - 150.4ms/batch - loss: 1.25934 - diff: 20.15mlTrain batch 5/32 - 179.8ms/batch - loss: 1.35496 - diff: 21.68mlTrain batch 6/32 - 132.5ms/batch - loss: 1.37880 - diff: 22.06mlTrain batch 7/32 - 165.1ms/batch - loss: 1.30059 - diff: 20.81mlTrain batch 8/32 - 183.9ms/batch - loss: 1.35639 - diff: 21.70mlTrain batch 9/32 - 146.7ms/batch - loss: 1.38329 - diff: 22.13mlTrain batch 10/32 - 179.2ms/batch - loss: 1.32359 - diff: 21.18mlTrain batch 11/32 - 171.3ms/batch - loss: 1.37012 - diff: 21.92mlTrain batch 12/32 - 149.1ms/batch - loss: 1.35565 - diff: 21.69mlTrain batch 13/32 - 135.4ms/batch - loss: 1.40475 - diff: 22.48mlTrain batch 14/32 - 167.5ms/batch - loss: 1.45064 - diff: 23.21mlTrain batch 15/32 - 130.3ms/batch - loss: 1.44444 - diff: 23.11mlTrain batch 16/32 - 112.6ms/batch - loss: 1.42041 - diff: 22.73mlTrain batch 17/32 - 185.0ms/batch - loss: 1.41053 - diff: 22.57mlTrain batch 18/32 - 139.1ms/batch - loss: 1.40169 - diff: 22.43mlTrain batch 19/32 - 210.2ms/batch - loss: 1.43849 - diff: 23.02mlTrain batch 20/32 - 180.0ms/batch - loss: 1.44528 - diff: 23.12mlTrain batch 21/32 - 153.6ms/batch - loss: 1.43754 - diff: 23.00mlTrain batch 22/32 - 192.4ms/batch - loss: 1.44527 - diff: 23.12mlTrain batch 23/32 - 143.5ms/batch - loss: 1.46954 - diff: 23.51mlTrain batch 24/32 - 159.4ms/batch - loss: 1.47328 - diff: 23.57mlTrain batch 25/32 - 166.2ms/batch - loss: 1.45268 - diff: 23.24mlTrain batch 26/32 - 156.7ms/batch - loss: 1.46533 - diff: 23.45mlTrain batch 27/32 - 155.7ms/batch - loss: 1.48084 - diff: 23.69mlTrain batch 28/32 - 171.3ms/batch - loss: 1.47070 - diff: 23.53mlTrain batch 29/32 - 172.1ms/batch - loss: 1.47606 - diff: 23.62mlTrain batch 30/32 - 201.3ms/batch - loss: 1.46202 - diff: 23.39mlTrain batch 31/32 - 144.8ms/batch - loss: 1.45901 - diff: 23.34mlTrain batch 32/32 - 151.2ms/batch - loss: 1.47882 - diff: 23.28mlTrain batch 32/32 - 18.2s 151.2ms/batch - loss: 1.47882 - diff: 23.28ml
Test 1.3s: val_loss: 1.42003 - diff: 21.78ml

Epoch 71: current best loss = 1.37417, at epoch 63
Train batch 1/32 - 158.2ms/batch - loss: 1.29153 - diff: 20.66mlTrain batch 2/32 - 185.0ms/batch - loss: 1.37229 - diff: 21.96mlTrain batch 3/32 - 188.1ms/batch - loss: 1.20954 - diff: 19.35mlTrain batch 4/32 - 106.8ms/batch - loss: 1.23173 - diff: 19.71mlTrain batch 5/32 - 107.8ms/batch - loss: 1.25847 - diff: 20.14mlTrain batch 6/32 - 175.2ms/batch - loss: 1.53553 - diff: 24.57mlTrain batch 7/32 - 180.0ms/batch - loss: 1.56313 - diff: 25.01mlTrain batch 8/32 - 121.9ms/batch - loss: 1.54010 - diff: 24.64mlTrain batch 9/32 - 127.7ms/batch - loss: 1.52631 - diff: 24.42mlTrain batch 10/32 - 128.1ms/batch - loss: 1.63921 - diff: 26.23mlTrain batch 11/32 - 185.2ms/batch - loss: 1.64933 - diff: 26.39mlTrain batch 12/32 - 126.0ms/batch - loss: 1.66914 - diff: 26.71mlTrain batch 13/32 - 124.3ms/batch - loss: 1.63601 - diff: 26.18mlTrain batch 14/32 - 159.9ms/batch - loss: 1.60458 - diff: 25.67mlTrain batch 15/32 - 189.8ms/batch - loss: 1.57774 - diff: 25.24mlTrain batch 16/32 - 159.4ms/batch - loss: 1.58595 - diff: 25.38mlTrain batch 17/32 - 134.6ms/batch - loss: 1.53638 - diff: 24.58mlTrain batch 18/32 - 172.4ms/batch - loss: 1.51225 - diff: 24.20mlTrain batch 19/32 - 166.2ms/batch - loss: 1.49537 - diff: 23.93mlTrain batch 20/32 - 150.3ms/batch - loss: 1.50075 - diff: 24.01mlTrain batch 21/32 - 178.5ms/batch - loss: 1.49287 - diff: 23.89mlTrain batch 22/32 - 140.4ms/batch - loss: 1.49659 - diff: 23.95mlTrain batch 23/32 - 163.5ms/batch - loss: 1.47789 - diff: 23.65mlTrain batch 24/32 - 150.7ms/batch - loss: 1.46984 - diff: 23.52mlTrain batch 25/32 - 137.6ms/batch - loss: 1.45490 - diff: 23.28mlTrain batch 26/32 - 137.4ms/batch - loss: 1.45695 - diff: 23.31mlTrain batch 27/32 - 131.9ms/batch - loss: 1.45169 - diff: 23.23mlTrain batch 28/32 - 137.0ms/batch - loss: 1.45410 - diff: 23.27mlTrain batch 29/32 - 120.9ms/batch - loss: 1.44426 - diff: 23.11mlTrain batch 30/32 - 158.7ms/batch - loss: 1.45053 - diff: 23.21mlTrain batch 31/32 - 178.8ms/batch - loss: 1.45148 - diff: 23.22mlTrain batch 32/32 - 169.8ms/batch - loss: 1.46694 - diff: 23.15mlTrain batch 32/32 - 16.4s 169.8ms/batch - loss: 1.46694 - diff: 23.15ml
Test 1.3s: val_loss: 1.42263 - diff: 21.76ml

Epoch 72: current best loss = 1.37417, at epoch 63
Train batch 1/32 - 201.8ms/batch - loss: 1.00782 - diff: 16.13mlTrain batch 2/32 - 177.1ms/batch - loss: 1.38805 - diff: 22.21mlTrain batch 3/32 - 157.4ms/batch - loss: 1.41240 - diff: 22.60mlTrain batch 4/32 - 182.1ms/batch - loss: 1.43362 - diff: 22.94mlTrain batch 5/32 - 189.1ms/batch - loss: 1.43810 - diff: 23.01mlTrain batch 6/32 - 136.2ms/batch - loss: 1.45820 - diff: 23.33mlTrain batch 7/32 - 169.1ms/batch - loss: 1.41963 - diff: 22.71mlTrain batch 8/32 - 112.0ms/batch - loss: 1.40529 - diff: 22.48mlTrain batch 9/32 - 133.6ms/batch - loss: 1.38249 - diff: 22.12mlTrain batch 10/32 - 133.3ms/batch - loss: 1.40839 - diff: 22.53mlTrain batch 11/32 - 171.2ms/batch - loss: 1.38997 - diff: 22.24mlTrain batch 12/32 - 135.1ms/batch - loss: 1.44011 - diff: 23.04mlTrain batch 13/32 - 186.2ms/batch - loss: 1.52466 - diff: 24.39mlTrain batch 14/32 - 103.9ms/batch - loss: 1.51401 - diff: 24.22mlTrain batch 15/32 - 122.3ms/batch - loss: 1.51459 - diff: 24.23mlTrain batch 16/32 - 123.9ms/batch - loss: 1.50092 - diff: 24.01mlTrain batch 17/32 - 157.8ms/batch - loss: 1.49211 - diff: 23.87mlTrain batch 18/32 - 160.0ms/batch - loss: 1.55548 - diff: 24.89mlTrain batch 19/32 - 162.2ms/batch - loss: 1.53406 - diff: 24.55mlTrain batch 20/32 - 176.5ms/batch - loss: 1.53366 - diff: 24.54mlTrain batch 21/32 - 223.3ms/batch - loss: 1.53103 - diff: 24.50mlTrain batch 22/32 - 155.2ms/batch - loss: 1.55205 - diff: 24.83mlTrain batch 23/32 - 151.5ms/batch - loss: 1.55011 - diff: 24.80mlTrain batch 24/32 - 159.0ms/batch - loss: 1.53497 - diff: 24.56mlTrain batch 25/32 - 135.2ms/batch - loss: 1.51836 - diff: 24.29mlTrain batch 26/32 - 127.8ms/batch - loss: 1.52512 - diff: 24.40mlTrain batch 27/32 - 146.9ms/batch - loss: 1.52297 - diff: 24.37mlTrain batch 28/32 - 162.4ms/batch - loss: 1.52504 - diff: 24.40mlTrain batch 29/32 - 164.0ms/batch - loss: 1.50447 - diff: 24.07mlTrain batch 30/32 - 182.0ms/batch - loss: 1.50879 - diff: 24.14mlTrain batch 31/32 - 155.1ms/batch - loss: 1.50898 - diff: 24.14mlTrain batch 32/32 - 151.4ms/batch - loss: 1.52440 - diff: 24.06mlTrain batch 32/32 - 17.3s 151.4ms/batch - loss: 1.52440 - diff: 24.06ml
Test 1.1s: val_loss: 1.56283 - diff: 23.75ml

Epoch 73: current best loss = 1.37417, at epoch 63
Train batch 1/32 - 124.6ms/batch - loss: 1.29809 - diff: 20.77mlTrain batch 2/32 - 109.0ms/batch - loss: 1.36141 - diff: 21.78mlTrain batch 3/32 - 170.6ms/batch - loss: 1.60904 - diff: 25.74mlTrain batch 4/32 - 138.1ms/batch - loss: 1.58378 - diff: 25.34mlTrain batch 5/32 - 155.8ms/batch - loss: 1.47926 - diff: 23.67mlTrain batch 6/32 - 142.2ms/batch - loss: 1.49181 - diff: 23.87mlTrain batch 7/32 - 190.4ms/batch - loss: 1.43931 - diff: 23.03mlTrain batch 8/32 - 164.9ms/batch - loss: 1.58634 - diff: 25.38mlTrain batch 9/32 - 201.1ms/batch - loss: 1.59053 - diff: 25.45mlTrain batch 10/32 - 187.4ms/batch - loss: 1.56797 - diff: 25.09mlTrain batch 11/32 - 157.4ms/batch - loss: 1.49876 - diff: 23.98mlTrain batch 12/32 - 163.6ms/batch - loss: 1.51513 - diff: 24.24mlTrain batch 13/32 - 171.2ms/batch - loss: 1.46596 - diff: 23.46mlTrain batch 14/32 - 123.3ms/batch - loss: 1.48794 - diff: 23.81mlTrain batch 15/32 - 169.7ms/batch - loss: 1.45910 - diff: 23.35mlTrain batch 16/32 - 185.4ms/batch - loss: 1.42383 - diff: 22.78mlTrain batch 17/32 - 136.2ms/batch - loss: 1.39541 - diff: 22.33mlTrain batch 18/32 - 174.2ms/batch - loss: 1.37891 - diff: 22.06mlTrain batch 19/32 - 162.4ms/batch - loss: 1.38305 - diff: 22.13mlTrain batch 20/32 - 177.8ms/batch - loss: 1.38883 - diff: 22.22mlTrain batch 21/32 - 184.6ms/batch - loss: 1.38432 - diff: 22.15mlTrain batch 22/32 - 90.7ms/batch - loss: 1.38764 - diff: 22.20mlTrain batch 23/32 - 101.3ms/batch - loss: 1.38242 - diff: 22.12mlTrain batch 24/32 - 170.7ms/batch - loss: 1.38753 - diff: 22.20mlTrain batch 25/32 - 232.2ms/batch - loss: 1.40243 - diff: 22.44mlTrain batch 26/32 - 179.1ms/batch - loss: 1.38522 - diff: 22.16mlTrain batch 27/32 - 195.9ms/batch - loss: 1.40081 - diff: 22.41mlTrain batch 28/32 - 162.7ms/batch - loss: 1.39673 - diff: 22.35mlTrain batch 29/32 - 214.6ms/batch - loss: 1.43111 - diff: 22.90mlTrain batch 30/32 - 164.5ms/batch - loss: 1.43632 - diff: 22.98mlTrain batch 31/32 - 123.4ms/batch - loss: 1.45122 - diff: 23.22mlTrain batch 32/32 - 108.2ms/batch - loss: 1.45798 - diff: 23.11mlTrain batch 32/32 - 17.4s 108.2ms/batch - loss: 1.45798 - diff: 23.11ml
Test 1.3s: val_loss: 1.36021 - diff: 21.00ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_DenseNet121_0_Adam-0.001_MAE_DA3_best

Epoch 74: current best loss = 1.36021, at epoch 73
Train batch 1/32 - 201.6ms/batch - loss: 1.62405 - diff: 25.98mlTrain batch 2/32 - 189.7ms/batch - loss: 1.40344 - diff: 22.46mlTrain batch 3/32 - 179.5ms/batch - loss: 1.28519 - diff: 20.56mlTrain batch 4/32 - 173.6ms/batch - loss: 1.32108 - diff: 21.14mlTrain batch 5/32 - 180.3ms/batch - loss: 1.25502 - diff: 20.08mlTrain batch 6/32 - 229.4ms/batch - loss: 1.40047 - diff: 22.41mlTrain batch 7/32 - 149.8ms/batch - loss: 1.38559 - diff: 22.17mlTrain batch 8/32 - 131.7ms/batch - loss: 1.37221 - diff: 21.96mlTrain batch 9/32 - 142.5ms/batch - loss: 1.33438 - diff: 21.35mlTrain batch 10/32 - 173.6ms/batch - loss: 1.35418 - diff: 21.67mlTrain batch 11/32 - 141.6ms/batch - loss: 1.42030 - diff: 22.72mlTrain batch 12/32 - 178.5ms/batch - loss: 1.40873 - diff: 22.54mlTrain batch 13/32 - 169.2ms/batch - loss: 1.39966 - diff: 22.39mlTrain batch 14/32 - 140.0ms/batch - loss: 1.38925 - diff: 22.23mlTrain batch 15/32 - 172.7ms/batch - loss: 1.37418 - diff: 21.99mlTrain batch 16/32 - 184.0ms/batch - loss: 1.39013 - diff: 22.24mlTrain batch 17/32 - 202.0ms/batch - loss: 1.37096 - diff: 21.94mlTrain batch 18/32 - 135.6ms/batch - loss: 1.41955 - diff: 22.71mlTrain batch 19/32 - 129.1ms/batch - loss: 1.41066 - diff: 22.57mlTrain batch 20/32 - 114.3ms/batch - loss: 1.40036 - diff: 22.41mlTrain batch 21/32 - 125.8ms/batch - loss: 1.38977 - diff: 22.24mlTrain batch 22/32 - 150.7ms/batch - loss: 1.38759 - diff: 22.20mlTrain batch 23/32 - 152.9ms/batch - loss: 1.36882 - diff: 21.90mlTrain batch 24/32 - 166.4ms/batch - loss: 1.39318 - diff: 22.29mlTrain batch 25/32 - 151.2ms/batch - loss: 1.39065 - diff: 22.25mlTrain batch 26/32 - 143.4ms/batch - loss: 1.39971 - diff: 22.40mlTrain batch 27/32 - 215.3ms/batch - loss: 1.42805 - diff: 22.85mlTrain batch 28/32 - 170.1ms/batch - loss: 1.44385 - diff: 23.10mlTrain batch 29/32 - 190.9ms/batch - loss: 1.42727 - diff: 22.84mlTrain batch 30/32 - 131.5ms/batch - loss: 1.42100 - diff: 22.74mlTrain batch 31/32 - 142.3ms/batch - loss: 1.43921 - diff: 23.03mlTrain batch 32/32 - 158.8ms/batch - loss: 1.46198 - diff: 22.98mlTrain batch 32/32 - 17.4s 158.8ms/batch - loss: 1.46198 - diff: 22.98ml
Test 1.1s: val_loss: 1.40680 - diff: 21.29ml

Epoch 75: current best loss = 1.36021, at epoch 73
Train batch 1/32 - 194.1ms/batch - loss: 1.17146 - diff: 18.74mlTrain batch 2/32 - 164.4ms/batch - loss: 1.31494 - diff: 21.04mlTrain batch 3/32 - 159.5ms/batch - loss: 1.27600 - diff: 20.42mlTrain batch 4/32 - 126.7ms/batch - loss: 1.24939 - diff: 19.99mlTrain batch 5/32 - 164.3ms/batch - loss: 1.15813 - diff: 18.53mlTrain batch 6/32 - 139.6ms/batch - loss: 1.16148 - diff: 18.58mlTrain batch 7/32 - 191.3ms/batch - loss: 1.19459 - diff: 19.11mlTrain batch 8/32 - 146.5ms/batch - loss: 1.23379 - diff: 19.74mlTrain batch 9/32 - 149.6ms/batch - loss: 1.26809 - diff: 20.29mlTrain batch 10/32 - 121.5ms/batch - loss: 1.35024 - diff: 21.60mlTrain batch 11/32 - 145.8ms/batch - loss: 1.31196 - diff: 20.99mlTrain batch 12/32 - 131.2ms/batch - loss: 1.31592 - diff: 21.05mlTrain batch 13/32 - 155.7ms/batch - loss: 1.31385 - diff: 21.02mlTrain batch 14/32 - 129.0ms/batch - loss: 1.32835 - diff: 21.25mlTrain batch 15/32 - 141.1ms/batch - loss: 1.35911 - diff: 21.75mlTrain batch 16/32 - 164.7ms/batch - loss: 1.36300 - diff: 21.81mlTrain batch 17/32 - 149.9ms/batch - loss: 1.35422 - diff: 21.67mlTrain batch 18/32 - 172.8ms/batch - loss: 1.36157 - diff: 21.79mlTrain batch 19/32 - 148.6ms/batch - loss: 1.33857 - diff: 21.42mlTrain batch 20/32 - 192.4ms/batch - loss: 1.36295 - diff: 21.81mlTrain batch 21/32 - 206.9ms/batch - loss: 1.37377 - diff: 21.98mlTrain batch 22/32 - 187.5ms/batch - loss: 1.37133 - diff: 21.94mlTrain batch 23/32 - 169.6ms/batch - loss: 1.36242 - diff: 21.80mlTrain batch 24/32 - 168.1ms/batch - loss: 1.35596 - diff: 21.70mlTrain batch 25/32 - 151.2ms/batch - loss: 1.36613 - diff: 21.86mlTrain batch 26/32 - 143.3ms/batch - loss: 1.35344 - diff: 21.65mlTrain batch 27/32 - 109.1ms/batch - loss: 1.35378 - diff: 21.66mlTrain batch 28/32 - 145.6ms/batch - loss: 1.36016 - diff: 21.76mlTrain batch 29/32 - 148.7ms/batch - loss: 1.36416 - diff: 21.83mlTrain batch 30/32 - 187.1ms/batch - loss: 1.37634 - diff: 22.02mlTrain batch 31/32 - 203.5ms/batch - loss: 1.45326 - diff: 23.25mlTrain batch 32/32 - 143.9ms/batch - loss: 1.52461 - diff: 23.40mlTrain batch 32/32 - 16.3s 143.9ms/batch - loss: 1.52461 - diff: 23.40ml
Test 1.3s: val_loss: 1.40075 - diff: 21.72ml

Epoch 76: current best loss = 1.36021, at epoch 73
Train batch 1/32 - 202.6ms/batch - loss: 1.30664 - diff: 20.91mlTrain batch 2/32 - 169.1ms/batch - loss: 1.23147 - diff: 19.70mlTrain batch 3/32 - 188.5ms/batch - loss: 1.18342 - diff: 18.93mlTrain batch 4/32 - 209.8ms/batch - loss: 1.19602 - diff: 19.14mlTrain batch 5/32 - 184.3ms/batch - loss: 1.26162 - diff: 20.19mlTrain batch 6/32 - 118.9ms/batch - loss: 1.23404 - diff: 19.74mlTrain batch 7/32 - 125.7ms/batch - loss: 1.22140 - diff: 19.54mlTrain batch 8/32 - 124.7ms/batch - loss: 1.23103 - diff: 19.70mlTrain batch 9/32 - 202.1ms/batch - loss: 1.20082 - diff: 19.21mlTrain batch 10/32 - 208.0ms/batch - loss: 1.21305 - diff: 19.41mlTrain batch 11/32 - 121.4ms/batch - loss: 1.19410 - diff: 19.11mlTrain batch 12/32 - 137.5ms/batch - loss: 1.24690 - diff: 19.95mlTrain batch 13/32 - 182.4ms/batch - loss: 1.22050 - diff: 19.53mlTrain batch 14/32 - 122.9ms/batch - loss: 1.23723 - diff: 19.80mlTrain batch 15/32 - 156.7ms/batch - loss: 1.21772 - diff: 19.48mlTrain batch 16/32 - 175.5ms/batch - loss: 1.20271 - diff: 19.24mlTrain batch 17/32 - 144.3ms/batch - loss: 1.19962 - diff: 19.19mlTrain batch 18/32 - 176.1ms/batch - loss: 1.22626 - diff: 19.62mlTrain batch 19/32 - 148.2ms/batch - loss: 1.24082 - diff: 19.85mlTrain batch 20/32 - 135.2ms/batch - loss: 1.24986 - diff: 20.00mlTrain batch 21/32 - 172.1ms/batch - loss: 1.25100 - diff: 20.02mlTrain batch 22/32 - 140.2ms/batch - loss: 1.24604 - diff: 19.94mlTrain batch 23/32 - 134.7ms/batch - loss: 1.25148 - diff: 20.02mlTrain batch 24/32 - 136.4ms/batch - loss: 1.23914 - diff: 19.83mlTrain batch 25/32 - 148.0ms/batch - loss: 1.26831 - diff: 20.29mlTrain batch 26/32 - 110.8ms/batch - loss: 1.28032 - diff: 20.49mlTrain batch 27/32 - 125.6ms/batch - loss: 1.30160 - diff: 20.83mlTrain batch 28/32 - 159.8ms/batch - loss: 1.30956 - diff: 20.95mlTrain batch 29/32 - 126.1ms/batch - loss: 1.30098 - diff: 20.82mlTrain batch 30/32 - 148.4ms/batch - loss: 1.29882 - diff: 20.78mlTrain batch 31/32 - 104.7ms/batch - loss: 1.28810 - diff: 20.61mlTrain batch 32/32 - 95.0ms/batch - loss: 1.34687 - diff: 20.72mlTrain batch 32/32 - 16.8s 95.0ms/batch - loss: 1.34687 - diff: 20.72ml
Test 1.1s: val_loss: 1.39850 - diff: 21.46ml

Epoch 77: current best loss = 1.36021, at epoch 73
Train batch 1/32 - 222.3ms/batch - loss: 1.04533 - diff: 16.73mlTrain batch 2/32 - 179.4ms/batch - loss: 1.03725 - diff: 16.60mlTrain batch 3/32 - 174.5ms/batch - loss: 1.04853 - diff: 16.78mlTrain batch 4/32 - 150.5ms/batch - loss: 1.28075 - diff: 20.49mlTrain batch 5/32 - 166.2ms/batch - loss: 1.26101 - diff: 20.18mlTrain batch 6/32 - 161.3ms/batch - loss: 1.30842 - diff: 20.93mlTrain batch 7/32 - 156.2ms/batch - loss: 1.34242 - diff: 21.48mlTrain batch 8/32 - 202.8ms/batch - loss: 1.30918 - diff: 20.95mlTrain batch 9/32 - 201.8ms/batch - loss: 1.27871 - diff: 20.46mlTrain batch 10/32 - 208.6ms/batch - loss: 1.26541 - diff: 20.25mlTrain batch 11/32 - 190.8ms/batch - loss: 1.23524 - diff: 19.76mlTrain batch 12/32 - 217.3ms/batch - loss: 1.22299 - diff: 19.57mlTrain batch 13/32 - 106.0ms/batch - loss: 1.21400 - diff: 19.42mlTrain batch 14/32 - 106.1ms/batch - loss: 1.21864 - diff: 19.50mlTrain batch 15/32 - 137.4ms/batch - loss: 1.23233 - diff: 19.72mlTrain batch 16/32 - 119.3ms/batch - loss: 1.23353 - diff: 19.74mlTrain batch 17/32 - 125.5ms/batch - loss: 1.27631 - diff: 20.42mlTrain batch 18/32 - 109.1ms/batch - loss: 1.28258 - diff: 20.52mlTrain batch 19/32 - 139.9ms/batch - loss: 1.30421 - diff: 20.87mlTrain batch 20/32 - 165.9ms/batch - loss: 1.31062 - diff: 20.97mlTrain batch 21/32 - 121.3ms/batch - loss: 1.31336 - diff: 21.01mlTrain batch 22/32 - 149.6ms/batch - loss: 1.31430 - diff: 21.03mlTrain batch 23/32 - 151.1ms/batch - loss: 1.28910 - diff: 20.63mlTrain batch 24/32 - 169.7ms/batch - loss: 1.30037 - diff: 20.81mlTrain batch 25/32 - 147.7ms/batch - loss: 1.33317 - diff: 21.33mlTrain batch 26/32 - 186.9ms/batch - loss: 1.33968 - diff: 21.43mlTrain batch 27/32 - 143.2ms/batch - loss: 1.36325 - diff: 21.81mlTrain batch 28/32 - 211.6ms/batch - loss: 1.43127 - diff: 22.90mlTrain batch 29/32 - 134.5ms/batch - loss: 1.42869 - diff: 22.86mlTrain batch 30/32 - 141.8ms/batch - loss: 1.41581 - diff: 22.65mlTrain batch 31/32 - 126.4ms/batch - loss: 1.40908 - diff: 22.55mlTrain batch 32/32 - 109.8ms/batch - loss: 1.42932 - diff: 22.49mlTrain batch 32/32 - 15.8s 109.8ms/batch - loss: 1.42932 - diff: 22.49ml
Test 1.1s: val_loss: 1.54322 - diff: 23.48ml

Epoch 78: current best loss = 1.36021, at epoch 73
Train batch 1/32 - 184.6ms/batch - loss: 0.96069 - diff: 15.37mlTrain batch 2/32 - 148.7ms/batch - loss: 1.25835 - diff: 20.13mlTrain batch 3/32 - 160.2ms/batch - loss: 1.22547 - diff: 19.61mlTrain batch 4/32 - 171.2ms/batch - loss: 1.12666 - diff: 18.03mlTrain batch 5/32 - 111.7ms/batch - loss: 1.07684 - diff: 17.23mlTrain batch 6/32 - 125.6ms/batch - loss: 1.07020 - diff: 17.12mlTrain batch 7/32 - 131.6ms/batch - loss: 1.08399 - diff: 17.34mlTrain batch 8/32 - 149.5ms/batch - loss: 1.12076 - diff: 17.93mlTrain batch 9/32 - 162.0ms/batch - loss: 1.10466 - diff: 17.67mlTrain batch 10/32 - 94.8ms/batch - loss: 1.18753 - diff: 19.00mlTrain batch 11/32 - 93.8ms/batch - loss: 1.29240 - diff: 20.68mlTrain batch 12/32 - 161.1ms/batch - loss: 1.33251 - diff: 21.32mlTrain batch 13/32 - 165.2ms/batch - loss: 1.32441 - diff: 21.19mlTrain batch 14/32 - 137.8ms/batch - loss: 1.34513 - diff: 21.52mlTrain batch 15/32 - 119.3ms/batch - loss: 1.37385 - diff: 21.98mlTrain batch 16/32 - 180.4ms/batch - loss: 1.34404 - diff: 21.50mlTrain batch 17/32 - 189.9ms/batch - loss: 1.36246 - diff: 21.80mlTrain batch 18/32 - 196.1ms/batch - loss: 1.36359 - diff: 21.82mlTrain batch 19/32 - 225.8ms/batch - loss: 1.36534 - diff: 21.85mlTrain batch 20/32 - 105.9ms/batch - loss: 1.35416 - diff: 21.67mlTrain batch 21/32 - 122.0ms/batch - loss: 1.34018 - diff: 21.44mlTrain batch 22/32 - 170.3ms/batch - loss: 1.35044 - diff: 21.61mlTrain batch 23/32 - 135.3ms/batch - loss: 1.33764 - diff: 21.40mlTrain batch 24/32 - 169.1ms/batch - loss: 1.34111 - diff: 21.46mlTrain batch 25/32 - 137.2ms/batch - loss: 1.36360 - diff: 21.82mlTrain batch 26/32 - 153.9ms/batch - loss: 1.36895 - diff: 21.90mlTrain batch 27/32 - 182.0ms/batch - loss: 1.36961 - diff: 21.91mlTrain batch 28/32 - 142.1ms/batch - loss: 1.39618 - diff: 22.34mlTrain batch 29/32 - 190.9ms/batch - loss: 1.37465 - diff: 21.99mlTrain batch 30/32 - 141.3ms/batch - loss: 1.37436 - diff: 21.99mlTrain batch 31/32 - 186.8ms/batch - loss: 1.36610 - diff: 21.86mlTrain batch 32/32 - 119.3ms/batch - loss: 1.43070 - diff: 21.98mlTrain batch 32/32 - 16.9s 119.3ms/batch - loss: 1.43070 - diff: 21.98ml
Test 1.1s: val_loss: 1.46426 - diff: 22.08ml

Epoch 79: current best loss = 1.36021, at epoch 73
Train batch 1/32 - 175.8ms/batch - loss: 0.95919 - diff: 15.35mlTrain batch 2/32 - 192.0ms/batch - loss: 1.02686 - diff: 16.43mlTrain batch 3/32 - 144.4ms/batch - loss: 1.00228 - diff: 16.04mlTrain batch 4/32 - 170.0ms/batch - loss: 0.93526 - diff: 14.96mlTrain batch 5/32 - 188.9ms/batch - loss: 0.94571 - diff: 15.13mlTrain batch 6/32 - 147.6ms/batch - loss: 1.05284 - diff: 16.85mlTrain batch 7/32 - 173.8ms/batch - loss: 1.31385 - diff: 21.02mlTrain batch 8/32 - 105.4ms/batch - loss: 1.29949 - diff: 20.79mlTrain batch 9/32 - 131.8ms/batch - loss: 1.29243 - diff: 20.68mlTrain batch 10/32 - 170.1ms/batch - loss: 1.32130 - diff: 21.14mlTrain batch 11/32 - 191.4ms/batch - loss: 1.28525 - diff: 20.56mlTrain batch 12/32 - 173.5ms/batch - loss: 1.30035 - diff: 20.81mlTrain batch 13/32 - 155.0ms/batch - loss: 1.27360 - diff: 20.38mlTrain batch 14/32 - 185.9ms/batch - loss: 1.29445 - diff: 20.71mlTrain batch 15/32 - 145.2ms/batch - loss: 1.29053 - diff: 20.65mlTrain batch 16/32 - 191.2ms/batch - loss: 1.28393 - diff: 20.54mlTrain batch 17/32 - 142.2ms/batch - loss: 1.27005 - diff: 20.32mlTrain batch 18/32 - 169.2ms/batch - loss: 1.26765 - diff: 20.28mlTrain batch 19/32 - 147.8ms/batch - loss: 1.27349 - diff: 20.38mlTrain batch 20/32 - 187.4ms/batch - loss: 1.26463 - diff: 20.23mlTrain batch 21/32 - 180.5ms/batch - loss: 1.25945 - diff: 20.15mlTrain batch 22/32 - 183.3ms/batch - loss: 1.23892 - diff: 19.82mlTrain batch 23/32 - 198.3ms/batch - loss: 1.26461 - diff: 20.23mlTrain batch 24/32 - 170.6ms/batch - loss: 1.28742 - diff: 20.60mlTrain batch 25/32 - 183.3ms/batch - loss: 1.29452 - diff: 20.71mlTrain batch 26/32 - 110.6ms/batch - loss: 1.29489 - diff: 20.72mlTrain batch 27/32 - 148.5ms/batch - loss: 1.29989 - diff: 20.80mlTrain batch 28/32 - 201.8ms/batch - loss: 1.29192 - diff: 20.67mlTrain batch 29/32 - 181.4ms/batch - loss: 1.29333 - diff: 20.69mlTrain batch 30/32 - 163.1ms/batch - loss: 1.30193 - diff: 20.83mlTrain batch 31/32 - 152.5ms/batch - loss: 1.34341 - diff: 21.49mlTrain batch 32/32 - 111.7ms/batch - loss: 1.37141 - diff: 21.48mlTrain batch 32/32 - 17.5s 111.7ms/batch - loss: 1.37141 - diff: 21.48ml
Test 1.4s: val_loss: 1.25041 - diff: 19.41ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_DenseNet121_0_Adam-0.001_MAE_DA3_best

Epoch 80: current best loss = 1.25041, at epoch 79
Train batch 1/32 - 212.3ms/batch - loss: 1.38266 - diff: 22.12mlTrain batch 2/32 - 169.8ms/batch - loss: 1.13057 - diff: 18.09mlTrain batch 3/32 - 158.9ms/batch - loss: 1.06553 - diff: 17.05mlTrain batch 4/32 - 142.0ms/batch - loss: 1.18692 - diff: 18.99mlTrain batch 5/32 - 122.0ms/batch - loss: 1.16407 - diff: 18.63mlTrain batch 6/32 - 198.0ms/batch - loss: 1.08477 - diff: 17.36mlTrain batch 7/32 - 195.2ms/batch - loss: 1.12237 - diff: 17.96mlTrain batch 8/32 - 167.7ms/batch - loss: 1.12211 - diff: 17.95mlTrain batch 9/32 - 139.8ms/batch - loss: 1.13105 - diff: 18.10mlTrain batch 10/32 - 142.5ms/batch - loss: 1.19673 - diff: 19.15mlTrain batch 11/32 - 123.8ms/batch - loss: 1.18306 - diff: 18.93mlTrain batch 12/32 - 114.7ms/batch - loss: 1.18479 - diff: 18.96mlTrain batch 13/32 - 184.2ms/batch - loss: 1.24190 - diff: 19.87mlTrain batch 14/32 - 217.9ms/batch - loss: 1.24574 - diff: 19.93mlTrain batch 15/32 - 152.3ms/batch - loss: 1.22638 - diff: 19.62mlTrain batch 16/32 - 116.6ms/batch - loss: 1.19018 - diff: 19.04mlTrain batch 17/32 - 158.3ms/batch - loss: 1.19644 - diff: 19.14mlTrain batch 18/32 - 137.4ms/batch - loss: 1.20634 - diff: 19.30mlTrain batch 19/32 - 204.2ms/batch - loss: 1.19739 - diff: 19.16mlTrain batch 20/32 - 191.7ms/batch - loss: 1.19474 - diff: 19.12mlTrain batch 21/32 - 169.7ms/batch - loss: 1.20545 - diff: 19.29mlTrain batch 22/32 - 111.3ms/batch - loss: 1.20882 - diff: 19.34mlTrain batch 23/32 - 133.2ms/batch - loss: 1.23843 - diff: 19.81mlTrain batch 24/32 - 112.6ms/batch - loss: 1.24723 - diff: 19.96mlTrain batch 25/32 - 174.2ms/batch - loss: 1.23439 - diff: 19.75mlTrain batch 26/32 - 199.1ms/batch - loss: 1.23109 - diff: 19.70mlTrain batch 27/32 - 196.9ms/batch - loss: 1.24363 - diff: 19.90mlTrain batch 28/32 - 190.5ms/batch - loss: 1.23214 - diff: 19.71mlTrain batch 29/32 - 164.9ms/batch - loss: 1.22483 - diff: 19.60mlTrain batch 30/32 - 189.1ms/batch - loss: 1.26438 - diff: 20.23mlTrain batch 31/32 - 137.0ms/batch - loss: 1.26989 - diff: 20.32mlTrain batch 32/32 - 135.2ms/batch - loss: 1.33003 - diff: 20.44mlTrain batch 32/32 - 17.4s 135.2ms/batch - loss: 1.33003 - diff: 20.44ml
Test 1.2s: val_loss: 1.56702 - diff: 24.19ml

Epoch 81: current best loss = 1.25041, at epoch 79
Train batch 1/32 - 164.8ms/batch - loss: 0.92035 - diff: 14.73mlTrain batch 2/32 - 190.8ms/batch - loss: 0.87959 - diff: 14.07mlTrain batch 3/32 - 139.0ms/batch - loss: 0.83109 - diff: 13.30mlTrain batch 4/32 - 122.5ms/batch - loss: 1.11290 - diff: 17.81mlTrain batch 5/32 - 182.1ms/batch - loss: 1.14760 - diff: 18.36mlTrain batch 6/32 - 194.6ms/batch - loss: 1.13110 - diff: 18.10mlTrain batch 7/32 - 162.2ms/batch - loss: 1.19078 - diff: 19.05mlTrain batch 8/32 - 162.0ms/batch - loss: 1.14762 - diff: 18.36mlTrain batch 9/32 - 197.8ms/batch - loss: 1.17318 - diff: 18.77mlTrain batch 10/32 - 123.2ms/batch - loss: 1.21100 - diff: 19.38mlTrain batch 11/32 - 148.7ms/batch - loss: 1.20740 - diff: 19.32mlTrain batch 12/32 - 118.4ms/batch - loss: 1.31851 - diff: 21.10mlTrain batch 13/32 - 147.6ms/batch - loss: 1.30206 - diff: 20.83mlTrain batch 14/32 - 157.7ms/batch - loss: 1.32969 - diff: 21.27mlTrain batch 15/32 - 162.1ms/batch - loss: 1.30132 - diff: 20.82mlTrain batch 16/32 - 174.9ms/batch - loss: 1.32455 - diff: 21.19mlTrain batch 17/32 - 166.3ms/batch - loss: 1.33411 - diff: 21.35mlTrain batch 18/32 - 159.3ms/batch - loss: 1.30809 - diff: 20.93mlTrain batch 19/32 - 191.9ms/batch - loss: 1.28662 - diff: 20.59mlTrain batch 20/32 - 165.4ms/batch - loss: 1.29550 - diff: 20.73mlTrain batch 21/32 - 151.4ms/batch - loss: 1.28971 - diff: 20.64mlTrain batch 22/32 - 117.3ms/batch - loss: 1.28856 - diff: 20.62mlTrain batch 23/32 - 145.1ms/batch - loss: 1.30454 - diff: 20.87mlTrain batch 24/32 - 146.4ms/batch - loss: 1.34928 - diff: 21.59mlTrain batch 25/32 - 172.5ms/batch - loss: 1.33144 - diff: 21.30mlTrain batch 26/32 - 176.8ms/batch - loss: 1.31959 - diff: 21.11mlTrain batch 27/32 - 127.7ms/batch - loss: 1.31537 - diff: 21.05mlTrain batch 28/32 - 183.7ms/batch - loss: 1.31658 - diff: 21.07mlTrain batch 29/32 - 149.7ms/batch - loss: 1.33231 - diff: 21.32mlTrain batch 30/32 - 121.3ms/batch - loss: 1.36395 - diff: 21.82mlTrain batch 31/32 - 168.6ms/batch - loss: 1.36119 - diff: 21.78mlTrain batch 32/32 - 181.6ms/batch - loss: 1.48245 - diff: 22.13mlTrain batch 32/32 - 17.4s 181.6ms/batch - loss: 1.48245 - diff: 22.13ml
Test 1.2s: val_loss: 1.61001 - diff: 24.40ml

Epoch 82: current best loss = 1.25041, at epoch 79
Train batch 1/32 - 193.1ms/batch - loss: 1.56259 - diff: 25.00mlTrain batch 2/32 - 187.6ms/batch - loss: 1.42628 - diff: 22.82mlTrain batch 3/32 - 136.3ms/batch - loss: 1.30242 - diff: 20.84mlTrain batch 4/32 - 160.9ms/batch - loss: 1.39597 - diff: 22.34mlTrain batch 5/32 - 135.8ms/batch - loss: 1.40292 - diff: 22.45mlTrain batch 6/32 - 128.9ms/batch - loss: 1.36757 - diff: 21.88mlTrain batch 7/32 - 136.7ms/batch - loss: 1.29937 - diff: 20.79mlTrain batch 8/32 - 179.9ms/batch - loss: 1.29712 - diff: 20.75mlTrain batch 9/32 - 183.6ms/batch - loss: 1.33324 - diff: 21.33mlTrain batch 10/32 - 177.9ms/batch - loss: 1.38318 - diff: 22.13mlTrain batch 11/32 - 176.8ms/batch - loss: 1.36418 - diff: 21.83mlTrain batch 12/32 - 179.7ms/batch - loss: 1.37095 - diff: 21.94mlTrain batch 13/32 - 170.2ms/batch - loss: 1.34614 - diff: 21.54mlTrain batch 14/32 - 149.1ms/batch - loss: 1.31301 - diff: 21.01mlTrain batch 15/32 - 198.0ms/batch - loss: 1.31361 - diff: 21.02mlTrain batch 16/32 - 190.0ms/batch - loss: 1.28635 - diff: 20.58mlTrain batch 17/32 - 154.9ms/batch - loss: 1.27466 - diff: 20.39mlTrain batch 18/32 - 151.0ms/batch - loss: 1.27186 - diff: 20.35mlTrain batch 19/32 - 137.4ms/batch - loss: 1.25836 - diff: 20.13mlTrain batch 20/32 - 196.2ms/batch - loss: 1.26378 - diff: 20.22mlTrain batch 21/32 - 142.1ms/batch - loss: 1.26236 - diff: 20.20mlTrain batch 22/32 - 191.7ms/batch - loss: 1.27789 - diff: 20.45mlTrain batch 23/32 - 189.7ms/batch - loss: 1.26790 - diff: 20.29mlTrain batch 24/32 - 231.2ms/batch - loss: 1.27814 - diff: 20.45mlTrain batch 25/32 - 157.9ms/batch - loss: 1.25953 - diff: 20.15mlTrain batch 26/32 - 201.7ms/batch - loss: 1.26993 - diff: 20.32mlTrain batch 27/32 - 197.3ms/batch - loss: 1.26469 - diff: 20.23mlTrain batch 28/32 - 203.3ms/batch - loss: 1.24803 - diff: 19.97mlTrain batch 29/32 - 162.7ms/batch - loss: 1.24411 - diff: 19.91mlTrain batch 30/32 - 136.9ms/batch - loss: 1.25238 - diff: 20.04mlTrain batch 31/32 - 117.0ms/batch - loss: 1.24395 - diff: 19.90mlTrain batch 32/32 - 107.4ms/batch - loss: 1.26560 - diff: 19.87mlTrain batch 32/32 - 18.2s 107.4ms/batch - loss: 1.26560 - diff: 19.87ml
Test 1.3s: val_loss: 1.48876 - diff: 22.69ml

Epoch 83: current best loss = 1.25041, at epoch 79
Train batch 1/32 - 170.8ms/batch - loss: 1.51303 - diff: 24.21mlTrain batch 2/32 - 176.5ms/batch - loss: 1.76367 - diff: 28.22mlTrain batch 3/32 - 193.6ms/batch - loss: 1.52862 - diff: 24.46mlTrain batch 4/32 - 158.6ms/batch - loss: 1.51541 - diff: 24.25mlTrain batch 5/32 - 176.3ms/batch - loss: 1.52403 - diff: 24.38mlTrain batch 6/32 - 217.4ms/batch - loss: 1.49165 - diff: 23.87mlTrain batch 7/32 - 193.6ms/batch - loss: 1.51517 - diff: 24.24mlTrain batch 8/32 - 197.2ms/batch - loss: 1.48374 - diff: 23.74mlTrain batch 9/32 - 225.4ms/batch - loss: 1.45330 - diff: 23.25mlTrain batch 10/32 - 227.6ms/batch - loss: 1.43310 - diff: 22.93mlTrain batch 11/32 - 165.0ms/batch - loss: 1.41678 - diff: 22.67mlTrain batch 12/32 - 191.6ms/batch - loss: 1.51993 - diff: 24.32mlTrain batch 13/32 - 153.1ms/batch - loss: 1.52502 - diff: 24.40mlTrain batch 14/32 - 181.6ms/batch - loss: 1.49850 - diff: 23.98mlTrain batch 15/32 - 141.9ms/batch - loss: 1.50024 - diff: 24.00mlTrain batch 16/32 - 198.7ms/batch - loss: 1.47225 - diff: 23.56mlTrain batch 17/32 - 157.5ms/batch - loss: 1.44741 - diff: 23.16mlTrain batch 18/32 - 178.8ms/batch - loss: 1.44472 - diff: 23.12mlTrain batch 19/32 - 124.5ms/batch - loss: 1.45466 - diff: 23.27mlTrain batch 20/32 - 176.9ms/batch - loss: 1.51653 - diff: 24.26mlTrain batch 21/32 - 150.7ms/batch - loss: 1.51371 - diff: 24.22mlTrain batch 22/32 - 146.3ms/batch - loss: 1.49908 - diff: 23.99mlTrain batch 23/32 - 141.5ms/batch - loss: 1.48660 - diff: 23.79mlTrain batch 24/32 - 144.7ms/batch - loss: 1.46300 - diff: 23.41mlTrain batch 25/32 - 120.1ms/batch - loss: 1.47084 - diff: 23.53mlTrain batch 26/32 - 174.8ms/batch - loss: 1.46564 - diff: 23.45mlTrain batch 27/32 - 133.5ms/batch - loss: 1.45686 - diff: 23.31mlTrain batch 28/32 - 128.1ms/batch - loss: 1.45528 - diff: 23.28mlTrain batch 29/32 - 148.4ms/batch - loss: 1.44533 - diff: 23.13mlTrain batch 30/32 - 158.1ms/batch - loss: 1.42867 - diff: 22.86mlTrain batch 31/32 - 171.9ms/batch - loss: 1.41055 - diff: 22.57mlTrain batch 32/32 - 151.8ms/batch - loss: 1.52016 - diff: 22.87mlTrain batch 32/32 - 17.8s 151.8ms/batch - loss: 1.52016 - diff: 22.87ml
Test 1.1s: val_loss: 1.62965 - diff: 25.40ml

Epoch 84: current best loss = 1.25041, at epoch 79
Train batch 1/32 - 213.5ms/batch - loss: 1.19079 - diff: 19.05mlTrain batch 2/32 - 137.5ms/batch - loss: 1.36174 - diff: 21.79mlTrain batch 3/32 - 178.7ms/batch - loss: 1.37625 - diff: 22.02mlTrain batch 4/32 - 182.5ms/batch - loss: 1.25741 - diff: 20.12mlTrain batch 5/32 - 159.1ms/batch - loss: 1.28645 - diff: 20.58mlTrain batch 6/32 - 184.3ms/batch - loss: 1.32940 - diff: 21.27mlTrain batch 7/32 - 185.4ms/batch - loss: 1.23871 - diff: 19.82mlTrain batch 8/32 - 145.9ms/batch - loss: 1.25722 - diff: 20.12mlTrain batch 9/32 - 157.5ms/batch - loss: 1.37082 - diff: 21.93mlTrain batch 10/32 - 146.3ms/batch - loss: 1.44541 - diff: 23.13mlTrain batch 11/32 - 153.9ms/batch - loss: 1.45181 - diff: 23.23mlTrain batch 12/32 - 177.6ms/batch - loss: 1.41872 - diff: 22.70mlTrain batch 13/32 - 185.7ms/batch - loss: 1.40033 - diff: 22.41mlTrain batch 14/32 - 171.5ms/batch - loss: 1.43200 - diff: 22.91mlTrain batch 15/32 - 188.4ms/batch - loss: 1.45947 - diff: 23.35mlTrain batch 16/32 - 145.0ms/batch - loss: 1.43622 - diff: 22.98mlTrain batch 17/32 - 210.6ms/batch - loss: 1.41912 - diff: 22.71mlTrain batch 18/32 - 161.4ms/batch - loss: 1.42342 - diff: 22.77mlTrain batch 19/32 - 124.1ms/batch - loss: 1.41431 - diff: 22.63mlTrain batch 20/32 - 133.5ms/batch - loss: 1.40937 - diff: 22.55mlTrain batch 21/32 - 161.0ms/batch - loss: 1.42022 - diff: 22.72mlTrain batch 22/32 - 134.3ms/batch - loss: 1.40929 - diff: 22.55mlTrain batch 23/32 - 138.9ms/batch - loss: 1.39169 - diff: 22.27mlTrain batch 24/32 - 112.5ms/batch - loss: 1.39145 - diff: 22.26mlTrain batch 25/32 - 141.4ms/batch - loss: 1.42909 - diff: 22.87mlTrain batch 26/32 - 168.7ms/batch - loss: 1.45481 - diff: 23.28mlTrain batch 27/32 - 180.6ms/batch - loss: 1.46079 - diff: 23.37mlTrain batch 28/32 - 179.1ms/batch - loss: 1.45154 - diff: 23.22mlTrain batch 29/32 - 209.1ms/batch - loss: 1.43380 - diff: 22.94mlTrain batch 30/32 - 161.8ms/batch - loss: 1.43225 - diff: 22.92mlTrain batch 31/32 - 152.9ms/batch - loss: 1.42643 - diff: 22.82mlTrain batch 32/32 - 159.5ms/batch - loss: 1.43931 - diff: 22.74mlTrain batch 32/32 - 16.6s 159.5ms/batch - loss: 1.43931 - diff: 22.74ml
Test 1.1s: val_loss: 1.43326 - diff: 21.75ml

Epoch 85: current best loss = 1.25041, at epoch 79
Train batch 1/32 - 173.2ms/batch - loss: 1.38726 - diff: 22.20mlTrain batch 2/32 - 125.8ms/batch - loss: 1.97090 - diff: 31.53mlTrain batch 3/32 - 177.7ms/batch - loss: 1.92390 - diff: 30.78mlTrain batch 4/32 - 206.0ms/batch - loss: 1.75325 - diff: 28.05mlTrain batch 5/32 - 221.4ms/batch - loss: 1.56704 - diff: 25.07mlTrain batch 6/32 - 212.4ms/batch - loss: 1.47071 - diff: 23.53mlTrain batch 7/32 - 151.7ms/batch - loss: 1.43252 - diff: 22.92mlTrain batch 8/32 - 192.0ms/batch - loss: 1.44429 - diff: 23.11mlTrain batch 9/32 - 160.6ms/batch - loss: 1.43410 - diff: 22.95mlTrain batch 10/32 - 161.6ms/batch - loss: 1.45594 - diff: 23.30mlTrain batch 11/32 - 175.3ms/batch - loss: 1.41697 - diff: 22.67mlTrain batch 12/32 - 178.3ms/batch - loss: 1.36588 - diff: 21.85mlTrain batch 13/32 - 162.4ms/batch - loss: 1.35628 - diff: 21.70mlTrain batch 14/32 - 178.0ms/batch - loss: 1.36359 - diff: 21.82mlTrain batch 15/32 - 119.0ms/batch - loss: 1.34704 - diff: 21.55mlTrain batch 16/32 - 150.1ms/batch - loss: 1.33714 - diff: 21.39mlTrain batch 17/32 - 168.1ms/batch - loss: 1.31245 - diff: 21.00mlTrain batch 18/32 - 143.3ms/batch - loss: 1.31925 - diff: 21.11mlTrain batch 19/32 - 142.1ms/batch - loss: 1.31192 - diff: 20.99mlTrain batch 20/32 - 167.0ms/batch - loss: 1.29975 - diff: 20.80mlTrain batch 21/32 - 175.9ms/batch - loss: 1.29966 - diff: 20.79mlTrain batch 22/32 - 178.4ms/batch - loss: 1.28917 - diff: 20.63mlTrain batch 23/32 - 184.6ms/batch - loss: 1.26526 - diff: 20.24mlTrain batch 24/32 - 159.6ms/batch - loss: 1.25750 - diff: 20.12mlTrain batch 25/32 - 150.2ms/batch - loss: 1.23763 - diff: 19.80mlTrain batch 26/32 - 247.1ms/batch - loss: 1.23271 - diff: 19.72mlTrain batch 27/32 - 126.9ms/batch - loss: 1.23840 - diff: 19.81mlTrain batch 28/32 - 164.1ms/batch - loss: 1.27843 - diff: 20.45mlTrain batch 29/32 - 135.3ms/batch - loss: 1.28352 - diff: 20.54mlTrain batch 30/32 - 127.2ms/batch - loss: 1.29000 - diff: 20.64mlTrain batch 31/32 - 158.2ms/batch - loss: 1.27463 - diff: 20.39mlTrain batch 32/32 - 141.0ms/batch - loss: 1.32996 - diff: 20.49mlTrain batch 32/32 - 18.2s 141.0ms/batch - loss: 1.32996 - diff: 20.49ml
Test 1.3s: val_loss: 1.31441 - diff: 20.15ml

Epoch 86: current best loss = 1.25041, at epoch 79
Train batch 1/32 - 172.3ms/batch - loss: 1.17103 - diff: 18.74mlTrain batch 2/32 - 187.0ms/batch - loss: 1.32304 - diff: 21.17mlTrain batch 3/32 - 189.0ms/batch - loss: 1.31645 - diff: 21.06mlTrain batch 4/32 - 115.4ms/batch - loss: 1.30752 - diff: 20.92mlTrain batch 5/32 - 140.4ms/batch - loss: 1.24227 - diff: 19.88mlTrain batch 6/32 - 166.7ms/batch - loss: 1.20405 - diff: 19.26mlTrain batch 7/32 - 128.0ms/batch - loss: 1.24959 - diff: 19.99mlTrain batch 8/32 - 109.3ms/batch - loss: 1.20036 - diff: 19.21mlTrain batch 9/32 - 169.8ms/batch - loss: 1.21707 - diff: 19.47mlTrain batch 10/32 - 171.2ms/batch - loss: 1.25277 - diff: 20.04mlTrain batch 11/32 - 184.2ms/batch - loss: 1.30980 - diff: 20.96mlTrain batch 12/32 - 201.0ms/batch - loss: 1.37476 - diff: 22.00mlTrain batch 13/32 - 146.8ms/batch - loss: 1.40962 - diff: 22.55mlTrain batch 14/32 - 112.2ms/batch - loss: 1.38478 - diff: 22.16mlTrain batch 15/32 - 149.2ms/batch - loss: 1.36529 - diff: 21.84mlTrain batch 16/32 - 213.6ms/batch - loss: 1.35484 - diff: 21.68mlTrain batch 17/32 - 185.4ms/batch - loss: 1.37878 - diff: 22.06mlTrain batch 18/32 - 196.8ms/batch - loss: 1.36998 - diff: 21.92mlTrain batch 19/32 - 142.7ms/batch - loss: 1.35325 - diff: 21.65mlTrain batch 20/32 - 190.5ms/batch - loss: 1.34907 - diff: 21.59mlTrain batch 21/32 - 139.9ms/batch - loss: 1.35110 - diff: 21.62mlTrain batch 22/32 - 163.9ms/batch - loss: 1.34694 - diff: 21.55mlTrain batch 23/32 - 147.5ms/batch - loss: 1.34182 - diff: 21.47mlTrain batch 24/32 - 152.1ms/batch - loss: 1.34071 - diff: 21.45mlTrain batch 25/32 - 152.2ms/batch - loss: 1.33271 - diff: 21.32mlTrain batch 26/32 - 136.3ms/batch - loss: 1.32689 - diff: 21.23mlTrain batch 27/32 - 172.5ms/batch - loss: 1.32712 - diff: 21.23mlTrain batch 28/32 - 165.9ms/batch - loss: 1.33345 - diff: 21.34mlTrain batch 29/32 - 173.3ms/batch - loss: 1.34066 - diff: 21.45mlTrain batch 30/32 - 163.8ms/batch - loss: 1.37041 - diff: 21.93mlTrain batch 31/32 - 124.8ms/batch - loss: 1.37047 - diff: 21.93mlTrain batch 32/32 - 133.6ms/batch - loss: 1.38752 - diff: 21.86mlTrain batch 32/32 - 16.8s 133.6ms/batch - loss: 1.38752 - diff: 21.86ml
Test 1.3s: val_loss: 1.44931 - diff: 22.63ml

Epoch 87: current best loss = 1.25041, at epoch 79
Train batch 1/32 - 254.7ms/batch - loss: 1.47273 - diff: 23.56mlTrain batch 2/32 - 214.3ms/batch - loss: 2.12282 - diff: 33.97mlTrain batch 3/32 - 126.4ms/batch - loss: 1.81598 - diff: 29.06mlTrain batch 4/32 - 183.0ms/batch - loss: 1.72212 - diff: 27.55mlTrain batch 5/32 - 192.4ms/batch - loss: 1.58612 - diff: 25.38mlTrain batch 6/32 - 105.5ms/batch - loss: 1.68310 - diff: 26.93mlTrain batch 7/32 - 122.7ms/batch - loss: 1.69644 - diff: 27.14mlTrain batch 8/32 - 134.8ms/batch - loss: 1.63735 - diff: 26.20mlTrain batch 9/32 - 151.8ms/batch - loss: 1.69817 - diff: 27.17mlTrain batch 10/32 - 108.6ms/batch - loss: 1.65862 - diff: 26.54mlTrain batch 11/32 - 124.1ms/batch - loss: 1.64416 - diff: 26.31mlTrain batch 12/32 - 161.3ms/batch - loss: 1.60122 - diff: 25.62mlTrain batch 13/32 - 171.0ms/batch - loss: 1.72913 - diff: 27.67mlTrain batch 14/32 - 178.8ms/batch - loss: 1.76790 - diff: 28.29mlTrain batch 15/32 - 135.3ms/batch - loss: 1.75294 - diff: 28.05mlTrain batch 16/32 - 151.7ms/batch - loss: 1.72460 - diff: 27.59mlTrain batch 17/32 - 173.2ms/batch - loss: 1.71508 - diff: 27.44mlTrain batch 18/32 - 178.0ms/batch - loss: 1.70323 - diff: 27.25mlTrain batch 19/32 - 168.9ms/batch - loss: 1.67804 - diff: 26.85mlTrain batch 20/32 - 161.7ms/batch - loss: 1.66465 - diff: 26.63mlTrain batch 21/32 - 160.4ms/batch - loss: 1.66735 - diff: 26.68mlTrain batch 22/32 - 171.6ms/batch - loss: 1.67926 - diff: 26.87mlTrain batch 23/32 - 157.8ms/batch - loss: 1.65828 - diff: 26.53mlTrain batch 24/32 - 176.2ms/batch - loss: 1.61598 - diff: 25.86mlTrain batch 25/32 - 156.6ms/batch - loss: 1.58462 - diff: 25.35mlTrain batch 26/32 - 166.8ms/batch - loss: 1.57127 - diff: 25.14mlTrain batch 27/32 - 201.4ms/batch - loss: 1.58049 - diff: 25.29mlTrain batch 28/32 - 206.0ms/batch - loss: 1.57751 - diff: 25.24mlTrain batch 29/32 - 209.4ms/batch - loss: 1.57287 - diff: 25.17mlTrain batch 30/32 - 168.7ms/batch - loss: 1.59009 - diff: 25.44mlTrain batch 31/32 - 147.7ms/batch - loss: 1.57307 - diff: 25.17mlTrain batch 32/32 - 157.9ms/batch - loss: 1.61834 - diff: 25.20mlTrain batch 32/32 - 18.6s 157.9ms/batch - loss: 1.61834 - diff: 25.20ml
Test 1.1s: val_loss: 1.63754 - diff: 25.26ml

Epoch 88: current best loss = 1.25041, at epoch 79
Train batch 1/32 - 255.3ms/batch - loss: 1.73703 - diff: 27.79mlTrain batch 2/32 - 163.1ms/batch - loss: 1.93679 - diff: 30.99mlTrain batch 3/32 - 209.4ms/batch - loss: 2.08658 - diff: 33.39mlTrain batch 4/32 - 182.2ms/batch - loss: 1.84550 - diff: 29.53mlTrain batch 5/32 - 157.1ms/batch - loss: 1.74644 - diff: 27.94mlTrain batch 6/32 - 164.6ms/batch - loss: 1.59855 - diff: 25.58mlTrain batch 7/32 - 188.4ms/batch - loss: 1.53555 - diff: 24.57mlTrain batch 8/32 - 162.0ms/batch - loss: 1.48998 - diff: 23.84mlTrain batch 9/32 - 185.0ms/batch - loss: 1.45299 - diff: 23.25mlTrain batch 10/32 - 190.8ms/batch - loss: 1.48885 - diff: 23.82mlTrain batch 11/32 - 177.3ms/batch - loss: 1.42564 - diff: 22.81mlTrain batch 12/32 - 166.4ms/batch - loss: 1.40906 - diff: 22.54mlTrain batch 13/32 - 159.5ms/batch - loss: 1.37028 - diff: 21.92mlTrain batch 14/32 - 120.7ms/batch - loss: 1.34861 - diff: 21.58mlTrain batch 15/32 - 159.0ms/batch - loss: 1.37597 - diff: 22.02mlTrain batch 16/32 - 117.2ms/batch - loss: 1.36440 - diff: 21.83mlTrain batch 17/32 - 148.7ms/batch - loss: 1.35064 - diff: 21.61mlTrain batch 18/32 - 128.2ms/batch - loss: 1.34733 - diff: 21.56mlTrain batch 19/32 - 133.2ms/batch - loss: 1.38193 - diff: 22.11mlTrain batch 20/32 - 108.3ms/batch - loss: 1.38759 - diff: 22.20mlTrain batch 21/32 - 187.0ms/batch - loss: 1.40333 - diff: 22.45mlTrain batch 22/32 - 171.0ms/batch - loss: 1.41956 - diff: 22.71mlTrain batch 23/32 - 161.2ms/batch - loss: 1.41300 - diff: 22.61mlTrain batch 24/32 - 156.4ms/batch - loss: 1.40878 - diff: 22.54mlTrain batch 25/32 - 168.5ms/batch - loss: 1.41032 - diff: 22.57mlTrain batch 26/32 - 225.9ms/batch - loss: 1.38582 - diff: 22.17mlTrain batch 27/32 - 125.5ms/batch - loss: 1.39689 - diff: 22.35mlTrain batch 28/32 - 172.4ms/batch - loss: 1.39341 - diff: 22.29mlTrain batch 29/32 - 112.9ms/batch - loss: 1.38064 - diff: 22.09mlTrain batch 30/32 - 123.9ms/batch - loss: 1.35708 - diff: 21.71mlTrain batch 31/32 - 141.8ms/batch - loss: 1.35481 - diff: 21.68mlTrain batch 32/32 - 111.2ms/batch - loss: 1.39575 - diff: 21.71mlTrain batch 32/32 - 17.0s 111.2ms/batch - loss: 1.39575 - diff: 21.71ml
Test 1.2s: val_loss: 1.34769 - diff: 21.03ml

Epoch 89: current best loss = 1.25041, at epoch 79
Train batch 1/32 - 231.3ms/batch - loss: 1.54967 - diff: 24.79mlTrain batch 2/32 - 194.6ms/batch - loss: 1.33153 - diff: 21.30mlTrain batch 3/32 - 142.9ms/batch - loss: 1.31332 - diff: 21.01mlTrain batch 4/32 - 128.8ms/batch - loss: 1.32491 - diff: 21.20mlTrain batch 5/32 - 148.2ms/batch - loss: 1.35641 - diff: 21.70mlTrain batch 6/32 - 154.2ms/batch - loss: 1.32506 - diff: 21.20mlTrain batch 7/32 - 168.8ms/batch - loss: 1.33157 - diff: 21.31mlTrain batch 8/32 - 141.4ms/batch - loss: 1.29003 - diff: 20.64mlTrain batch 9/32 - 150.7ms/batch - loss: 1.24818 - diff: 19.97mlTrain batch 10/32 - 162.6ms/batch - loss: 1.21518 - diff: 19.44mlTrain batch 11/32 - 170.0ms/batch - loss: 1.17430 - diff: 18.79mlTrain batch 12/32 - 186.5ms/batch - loss: 1.17337 - diff: 18.77mlTrain batch 13/32 - 163.6ms/batch - loss: 1.17742 - diff: 18.84mlTrain batch 14/32 - 167.0ms/batch - loss: 1.28447 - diff: 20.55mlTrain batch 15/32 - 159.2ms/batch - loss: 1.28727 - diff: 20.60mlTrain batch 16/32 - 173.5ms/batch - loss: 1.26216 - diff: 20.19mlTrain batch 17/32 - 169.2ms/batch - loss: 1.26287 - diff: 20.21mlTrain batch 18/32 - 119.5ms/batch - loss: 1.26232 - diff: 20.20mlTrain batch 19/32 - 104.1ms/batch - loss: 1.29052 - diff: 20.65mlTrain batch 20/32 - 195.6ms/batch - loss: 1.28057 - diff: 20.49mlTrain batch 21/32 - 166.3ms/batch - loss: 1.28807 - diff: 20.61mlTrain batch 22/32 - 164.2ms/batch - loss: 1.27036 - diff: 20.33mlTrain batch 23/32 - 168.8ms/batch - loss: 1.26851 - diff: 20.30mlTrain batch 24/32 - 162.2ms/batch - loss: 1.27575 - diff: 20.41mlTrain batch 25/32 - 126.1ms/batch - loss: 1.26475 - diff: 20.24mlTrain batch 26/32 - 165.8ms/batch - loss: 1.27070 - diff: 20.33mlTrain batch 27/32 - 165.2ms/batch - loss: 1.28045 - diff: 20.49mlTrain batch 28/32 - 111.2ms/batch - loss: 1.28029 - diff: 20.48mlTrain batch 29/32 - 112.5ms/batch - loss: 1.28816 - diff: 20.61mlTrain batch 30/32 - 159.4ms/batch - loss: 1.29257 - diff: 20.68mlTrain batch 31/32 - 172.0ms/batch - loss: 1.27826 - diff: 20.45mlTrain batch 32/32 - 122.5ms/batch - loss: 1.38748 - diff: 20.77mlTrain batch 32/32 - 16.8s 122.5ms/batch - loss: 1.38748 - diff: 20.77ml
Test 1.4s: val_loss: 2.34256 - diff: 36.41ml

Epoch 90: current best loss = 1.25041, at epoch 79
Train batch 1/32 - 192.3ms/batch - loss: 1.08772 - diff: 17.40mlTrain batch 2/32 - 182.0ms/batch - loss: 1.08972 - diff: 17.44mlTrain batch 3/32 - 164.8ms/batch - loss: 1.10271 - diff: 17.64mlTrain batch 4/32 - 189.1ms/batch - loss: 1.14292 - diff: 18.29mlTrain batch 5/32 - 206.8ms/batch - loss: 1.19303 - diff: 19.09mlTrain batch 6/32 - 114.4ms/batch - loss: 1.28055 - diff: 20.49mlTrain batch 7/32 - 169.6ms/batch - loss: 1.26517 - diff: 20.24mlTrain batch 8/32 - 119.2ms/batch - loss: 1.20986 - diff: 19.36mlTrain batch 9/32 - 210.8ms/batch - loss: 1.16346 - diff: 18.62mlTrain batch 10/32 - 137.8ms/batch - loss: 1.12636 - diff: 18.02mlTrain batch 11/32 - 174.4ms/batch - loss: 1.09540 - diff: 17.53mlTrain batch 12/32 - 215.6ms/batch - loss: 1.29493 - diff: 20.72mlTrain batch 13/32 - 138.8ms/batch - loss: 1.24518 - diff: 19.92mlTrain batch 14/32 - 132.8ms/batch - loss: 1.21593 - diff: 19.45mlTrain batch 15/32 - 174.0ms/batch - loss: 1.23604 - diff: 19.78mlTrain batch 16/32 - 137.4ms/batch - loss: 1.30184 - diff: 20.83mlTrain batch 17/32 - 144.1ms/batch - loss: 1.28752 - diff: 20.60mlTrain batch 18/32 - 164.7ms/batch - loss: 1.27209 - diff: 20.35mlTrain batch 19/32 - 174.6ms/batch - loss: 1.26206 - diff: 20.19mlTrain batch 20/32 - 189.8ms/batch - loss: 1.24783 - diff: 19.97mlTrain batch 21/32 - 183.8ms/batch - loss: 1.24201 - diff: 19.87mlTrain batch 22/32 - 163.2ms/batch - loss: 1.24065 - diff: 19.85mlTrain batch 23/32 - 178.9ms/batch - loss: 1.23673 - diff: 19.79mlTrain batch 24/32 - 186.3ms/batch - loss: 1.24513 - diff: 19.92mlTrain batch 25/32 - 188.8ms/batch - loss: 1.23229 - diff: 19.72mlTrain batch 26/32 - 156.4ms/batch - loss: 1.23611 - diff: 19.78mlTrain batch 27/32 - 145.1ms/batch - loss: 1.23350 - diff: 19.74mlTrain batch 28/32 - 160.6ms/batch - loss: 1.21640 - diff: 19.46mlTrain batch 29/32 - 159.4ms/batch - loss: 1.22770 - diff: 19.64mlTrain batch 30/32 - 175.1ms/batch - loss: 1.22997 - diff: 19.68mlTrain batch 31/32 - 157.5ms/batch - loss: 1.22241 - diff: 19.56mlTrain batch 32/32 - 149.6ms/batch - loss: 1.28377 - diff: 19.69mlTrain batch 32/32 - 16.4s 149.6ms/batch - loss: 1.28377 - diff: 19.69ml
Test 1.2s: val_loss: 1.45230 - diff: 22.51ml
Epoch    91: reducing learning rate of group 0 to 2.5000e-04.

Epoch 91: current best loss = 1.25041, at epoch 79
Train batch 1/32 - 214.3ms/batch - loss: 2.58141 - diff: 41.30mlTrain batch 2/32 - 162.2ms/batch - loss: 1.72857 - diff: 27.66mlTrain batch 3/32 - 185.9ms/batch - loss: 1.57985 - diff: 25.28mlTrain batch 4/32 - 192.8ms/batch - loss: 1.40763 - diff: 22.52mlTrain batch 5/32 - 142.5ms/batch - loss: 1.57270 - diff: 25.16mlTrain batch 6/32 - 108.5ms/batch - loss: 1.55149 - diff: 24.82mlTrain batch 7/32 - 175.2ms/batch - loss: 1.43620 - diff: 22.98mlTrain batch 8/32 - 111.3ms/batch - loss: 1.41323 - diff: 22.61mlTrain batch 9/32 - 174.1ms/batch - loss: 1.38406 - diff: 22.14mlTrain batch 10/32 - 159.9ms/batch - loss: 1.32192 - diff: 21.15mlTrain batch 11/32 - 148.0ms/batch - loss: 1.31750 - diff: 21.08mlTrain batch 12/32 - 141.3ms/batch - loss: 1.33329 - diff: 21.33mlTrain batch 13/32 - 172.9ms/batch - loss: 1.32898 - diff: 21.26mlTrain batch 14/32 - 120.0ms/batch - loss: 1.30148 - diff: 20.82mlTrain batch 15/32 - 186.0ms/batch - loss: 1.31094 - diff: 20.97mlTrain batch 16/32 - 153.4ms/batch - loss: 1.27632 - diff: 20.42mlTrain batch 17/32 - 139.6ms/batch - loss: 1.24854 - diff: 19.98mlTrain batch 18/32 - 170.0ms/batch - loss: 1.26207 - diff: 20.19mlTrain batch 19/32 - 176.6ms/batch - loss: 1.25042 - diff: 20.01mlTrain batch 20/32 - 181.9ms/batch - loss: 1.24180 - diff: 19.87mlTrain batch 21/32 - 181.8ms/batch - loss: 1.26578 - diff: 20.25mlTrain batch 22/32 - 184.9ms/batch - loss: 1.27805 - diff: 20.45mlTrain batch 23/32 - 178.0ms/batch - loss: 1.28416 - diff: 20.55mlTrain batch 24/32 - 156.6ms/batch - loss: 1.27750 - diff: 20.44mlTrain batch 25/32 - 131.3ms/batch - loss: 1.25501 - diff: 20.08mlTrain batch 26/32 - 158.0ms/batch - loss: 1.25578 - diff: 20.09mlTrain batch 27/32 - 150.5ms/batch - loss: 1.27019 - diff: 20.32mlTrain batch 28/32 - 171.1ms/batch - loss: 1.26376 - diff: 20.22mlTrain batch 29/32 - 161.9ms/batch - loss: 1.25266 - diff: 20.04mlTrain batch 30/32 - 150.5ms/batch - loss: 1.24654 - diff: 19.94mlTrain batch 31/32 - 133.9ms/batch - loss: 1.25200 - diff: 20.03mlTrain batch 32/32 - 197.0ms/batch - loss: 1.33859 - diff: 20.26mlTrain batch 32/32 - 16.3s 197.0ms/batch - loss: 1.33859 - diff: 20.26ml
Test 1.2s: val_loss: 1.39988 - diff: 21.78ml

Epoch 92: current best loss = 1.25041, at epoch 79
Train batch 1/32 - 211.3ms/batch - loss: 0.91205 - diff: 14.59mlTrain batch 2/32 - 198.2ms/batch - loss: 0.98215 - diff: 15.71mlTrain batch 3/32 - 190.2ms/batch - loss: 0.96358 - diff: 15.42mlTrain batch 4/32 - 128.2ms/batch - loss: 0.94674 - diff: 15.15mlTrain batch 5/32 - 171.4ms/batch - loss: 0.99035 - diff: 15.85mlTrain batch 6/32 - 141.6ms/batch - loss: 0.98322 - diff: 15.73mlTrain batch 7/32 - 168.7ms/batch - loss: 0.95504 - diff: 15.28mlTrain batch 8/32 - 150.5ms/batch - loss: 0.99679 - diff: 15.95mlTrain batch 9/32 - 170.9ms/batch - loss: 1.01905 - diff: 16.30mlTrain batch 10/32 - 163.1ms/batch - loss: 1.01863 - diff: 16.30mlTrain batch 11/32 - 138.8ms/batch - loss: 1.02364 - diff: 16.38mlTrain batch 12/32 - 153.8ms/batch - loss: 1.00322 - diff: 16.05mlTrain batch 13/32 - 138.2ms/batch - loss: 1.02185 - diff: 16.35mlTrain batch 14/32 - 115.4ms/batch - loss: 1.00656 - diff: 16.11mlTrain batch 15/32 - 126.4ms/batch - loss: 1.00796 - diff: 16.13mlTrain batch 16/32 - 118.9ms/batch - loss: 0.98578 - diff: 15.77mlTrain batch 17/32 - 181.7ms/batch - loss: 1.00699 - diff: 16.11mlTrain batch 18/32 - 166.1ms/batch - loss: 1.01247 - diff: 16.20mlTrain batch 19/32 - 120.4ms/batch - loss: 0.99582 - diff: 15.93mlTrain batch 20/32 - 167.7ms/batch - loss: 1.00928 - diff: 16.15mlTrain batch 21/32 - 157.3ms/batch - loss: 1.01282 - diff: 16.21mlTrain batch 22/32 - 171.0ms/batch - loss: 1.00616 - diff: 16.10mlTrain batch 23/32 - 155.9ms/batch - loss: 0.99952 - diff: 15.99mlTrain batch 24/32 - 160.2ms/batch - loss: 0.99299 - diff: 15.89mlTrain batch 25/32 - 187.4ms/batch - loss: 0.98622 - diff: 15.78mlTrain batch 26/32 - 166.4ms/batch - loss: 1.00842 - diff: 16.13mlTrain batch 27/32 - 179.8ms/batch - loss: 1.02490 - diff: 16.40mlTrain batch 28/32 - 151.4ms/batch - loss: 1.01582 - diff: 16.25mlTrain batch 29/32 - 142.6ms/batch - loss: 1.01223 - diff: 16.20mlTrain batch 30/32 - 143.0ms/batch - loss: 1.05629 - diff: 16.90mlTrain batch 31/32 - 148.2ms/batch - loss: 1.05699 - diff: 16.91mlTrain batch 32/32 - 193.4ms/batch - loss: 1.09862 - diff: 16.98mlTrain batch 32/32 - 16.8s 193.4ms/batch - loss: 1.09862 - diff: 16.98ml
Test 1.2s: val_loss: 1.39985 - diff: 21.60ml

Epoch 93: current best loss = 1.25041, at epoch 79
Train batch 1/32 - 167.6ms/batch - loss: 0.87420 - diff: 13.99mlTrain batch 2/32 - 150.1ms/batch - loss: 1.01838 - diff: 16.29mlTrain batch 3/32 - 123.8ms/batch - loss: 1.00567 - diff: 16.09mlTrain batch 4/32 - 164.4ms/batch - loss: 1.24900 - diff: 19.98mlTrain batch 5/32 - 175.7ms/batch - loss: 1.45306 - diff: 23.25mlTrain batch 6/32 - 114.5ms/batch - loss: 1.37567 - diff: 22.01mlTrain batch 7/32 - 118.6ms/batch - loss: 1.41717 - diff: 22.67mlTrain batch 8/32 - 166.2ms/batch - loss: 1.39164 - diff: 22.27mlTrain batch 9/32 - 130.7ms/batch - loss: 1.35178 - diff: 21.63mlTrain batch 10/32 - 112.3ms/batch - loss: 1.35281 - diff: 21.64mlTrain batch 11/32 - 158.9ms/batch - loss: 1.32889 - diff: 21.26mlTrain batch 12/32 - 116.6ms/batch - loss: 1.31523 - diff: 21.04mlTrain batch 13/32 - 138.4ms/batch - loss: 1.29744 - diff: 20.76mlTrain batch 14/32 - 104.3ms/batch - loss: 1.26891 - diff: 20.30mlTrain batch 15/32 - 180.6ms/batch - loss: 1.26130 - diff: 20.18mlTrain batch 16/32 - 141.9ms/batch - loss: 1.28214 - diff: 20.51mlTrain batch 17/32 - 157.2ms/batch - loss: 1.26442 - diff: 20.23mlTrain batch 18/32 - 141.4ms/batch - loss: 1.26659 - diff: 20.27mlTrain batch 19/32 - 175.8ms/batch - loss: 1.24407 - diff: 19.91mlTrain batch 20/32 - 188.5ms/batch - loss: 1.22410 - diff: 19.59mlTrain batch 21/32 - 167.6ms/batch - loss: 1.21701 - diff: 19.47mlTrain batch 22/32 - 180.7ms/batch - loss: 1.20139 - diff: 19.22mlTrain batch 23/32 - 176.7ms/batch - loss: 1.22355 - diff: 19.58mlTrain batch 24/32 - 123.2ms/batch - loss: 1.28712 - diff: 20.59mlTrain batch 25/32 - 169.3ms/batch - loss: 1.27297 - diff: 20.37mlTrain batch 26/32 - 181.8ms/batch - loss: 1.25594 - diff: 20.09mlTrain batch 27/32 - 175.6ms/batch - loss: 1.23778 - diff: 19.80mlTrain batch 28/32 - 163.4ms/batch - loss: 1.25549 - diff: 20.09mlTrain batch 29/32 - 133.5ms/batch - loss: 1.24593 - diff: 19.93mlTrain batch 30/32 - 157.4ms/batch - loss: 1.23413 - diff: 19.75mlTrain batch 31/32 - 164.4ms/batch - loss: 1.22022 - diff: 19.52mlTrain batch 32/32 - 198.1ms/batch - loss: 1.25014 - diff: 19.53mlTrain batch 32/32 - 16.2s 198.1ms/batch - loss: 1.25014 - diff: 19.53ml
Test 1.2s: val_loss: 1.34522 - diff: 20.68ml

Epoch 94: current best loss = 1.25041, at epoch 79
Train batch 1/32 - 190.2ms/batch - loss: 1.12655 - diff: 18.02mlTrain batch 2/32 - 190.5ms/batch - loss: 1.52545 - diff: 24.41mlTrain batch 3/32 - 165.3ms/batch - loss: 1.52444 - diff: 24.39mlTrain batch 4/32 - 183.4ms/batch - loss: 1.31850 - diff: 21.10mlTrain batch 5/32 - 161.6ms/batch - loss: 1.27723 - diff: 20.44mlTrain batch 6/32 - 164.7ms/batch - loss: 1.20077 - diff: 19.21mlTrain batch 7/32 - 164.1ms/batch - loss: 1.31730 - diff: 21.08mlTrain batch 8/32 - 154.7ms/batch - loss: 1.30552 - diff: 20.89mlTrain batch 9/32 - 166.4ms/batch - loss: 1.26133 - diff: 20.18mlTrain batch 10/32 - 167.3ms/batch - loss: 1.22613 - diff: 19.62mlTrain batch 11/32 - 166.6ms/batch - loss: 1.19365 - diff: 19.10mlTrain batch 12/32 - 141.8ms/batch - loss: 1.19464 - diff: 19.11mlTrain batch 13/32 - 166.0ms/batch - loss: 1.15761 - diff: 18.52mlTrain batch 14/32 - 181.8ms/batch - loss: 1.12728 - diff: 18.04mlTrain batch 15/32 - 141.7ms/batch - loss: 1.10874 - diff: 17.74mlTrain batch 16/32 - 173.9ms/batch - loss: 1.09602 - diff: 17.54mlTrain batch 17/32 - 159.2ms/batch - loss: 1.08309 - diff: 17.33mlTrain batch 18/32 - 167.0ms/batch - loss: 1.07572 - diff: 17.21mlTrain batch 19/32 - 198.0ms/batch - loss: 1.10006 - diff: 17.60mlTrain batch 20/32 - 145.6ms/batch - loss: 1.07771 - diff: 17.24mlTrain batch 21/32 - 147.2ms/batch - loss: 1.09434 - diff: 17.51mlTrain batch 22/32 - 170.5ms/batch - loss: 1.08077 - diff: 17.29mlTrain batch 23/32 - 162.6ms/batch - loss: 1.08596 - diff: 17.38mlTrain batch 24/32 - 141.1ms/batch - loss: 1.08388 - diff: 17.34mlTrain batch 25/32 - 161.9ms/batch - loss: 1.08788 - diff: 17.41mlTrain batch 26/32 - 128.4ms/batch - loss: 1.08768 - diff: 17.40mlTrain batch 27/32 - 137.6ms/batch - loss: 1.08597 - diff: 17.38mlTrain batch 28/32 - 158.2ms/batch - loss: 1.10423 - diff: 17.67mlTrain batch 29/32 - 103.5ms/batch - loss: 1.09998 - diff: 17.60mlTrain batch 30/32 - 197.3ms/batch - loss: 1.09774 - diff: 17.56mlTrain batch 31/32 - 166.6ms/batch - loss: 1.12186 - diff: 17.95mlTrain batch 32/32 - 115.8ms/batch - loss: 1.13369 - diff: 17.89mlTrain batch 32/32 - 16.6s 115.8ms/batch - loss: 1.13369 - diff: 17.89ml
Test 1.2s: val_loss: 1.33090 - diff: 20.30ml

Epoch 95: current best loss = 1.25041, at epoch 79
Train batch 1/32 - 153.3ms/batch - loss: 0.73913 - diff: 11.83mlTrain batch 2/32 - 125.6ms/batch - loss: 1.16462 - diff: 18.63mlTrain batch 3/32 - 187.7ms/batch - loss: 1.16820 - diff: 18.69mlTrain batch 4/32 - 164.7ms/batch - loss: 1.12736 - diff: 18.04mlTrain batch 5/32 - 166.2ms/batch - loss: 1.09314 - diff: 17.49mlTrain batch 6/32 - 190.3ms/batch - loss: 1.06968 - diff: 17.11mlTrain batch 7/32 - 144.5ms/batch - loss: 1.06835 - diff: 17.09mlTrain batch 8/32 - 229.0ms/batch - loss: 1.01981 - diff: 16.32mlTrain batch 9/32 - 145.8ms/batch - loss: 1.03362 - diff: 16.54mlTrain batch 10/32 - 128.4ms/batch - loss: 1.01479 - diff: 16.24mlTrain batch 11/32 - 153.5ms/batch - loss: 0.99891 - diff: 15.98mlTrain batch 12/32 - 143.3ms/batch - loss: 0.98679 - diff: 15.79mlTrain batch 13/32 - 145.9ms/batch - loss: 0.98560 - diff: 15.77mlTrain batch 14/32 - 124.7ms/batch - loss: 1.01246 - diff: 16.20mlTrain batch 15/32 - 110.4ms/batch - loss: 1.02741 - diff: 16.44mlTrain batch 16/32 - 151.4ms/batch - loss: 1.04423 - diff: 16.71mlTrain batch 17/32 - 148.7ms/batch - loss: 1.08878 - diff: 17.42mlTrain batch 18/32 - 211.4ms/batch - loss: 1.08460 - diff: 17.35mlTrain batch 19/32 - 195.5ms/batch - loss: 1.08043 - diff: 17.29mlTrain batch 20/32 - 208.3ms/batch - loss: 1.07304 - diff: 17.17mlTrain batch 21/32 - 171.2ms/batch - loss: 1.06200 - diff: 16.99mlTrain batch 22/32 - 191.0ms/batch - loss: 1.07022 - diff: 17.12mlTrain batch 23/32 - 145.2ms/batch - loss: 1.06349 - diff: 17.02mlTrain batch 24/32 - 211.4ms/batch - loss: 1.07973 - diff: 17.28mlTrain batch 25/32 - 157.5ms/batch - loss: 1.07477 - diff: 17.20mlTrain batch 26/32 - 203.4ms/batch - loss: 1.06368 - diff: 17.02mlTrain batch 27/32 - 213.8ms/batch - loss: 1.07289 - diff: 17.17mlTrain batch 28/32 - 183.7ms/batch - loss: 1.05815 - diff: 16.93mlTrain batch 29/32 - 176.1ms/batch - loss: 1.06039 - diff: 16.97mlTrain batch 30/32 - 154.2ms/batch - loss: 1.06462 - diff: 17.03mlTrain batch 31/32 - 158.2ms/batch - loss: 1.05810 - diff: 16.93mlTrain batch 32/32 - 101.6ms/batch - loss: 1.07858 - diff: 16.91mlTrain batch 32/32 - 18.1s 101.6ms/batch - loss: 1.07858 - diff: 16.91ml
Test 1.3s: val_loss: 1.31643 - diff: 20.28ml

Epoch 96: current best loss = 1.25041, at epoch 79
Train batch 1/32 - 196.1ms/batch - loss: 1.04959 - diff: 16.79mlTrain batch 2/32 - 166.6ms/batch - loss: 1.00727 - diff: 16.12mlTrain batch 3/32 - 178.9ms/batch - loss: 1.07353 - diff: 17.18mlTrain batch 4/32 - 164.0ms/batch - loss: 1.18647 - diff: 18.98mlTrain batch 5/32 - 170.1ms/batch - loss: 1.09569 - diff: 17.53mlTrain batch 6/32 - 159.7ms/batch - loss: 1.08845 - diff: 17.42mlTrain batch 7/32 - 133.6ms/batch - loss: 1.13845 - diff: 18.22mlTrain batch 8/32 - 125.5ms/batch - loss: 1.14817 - diff: 18.37mlTrain batch 9/32 - 154.4ms/batch - loss: 1.15549 - diff: 18.49mlTrain batch 10/32 - 199.2ms/batch - loss: 1.21612 - diff: 19.46mlTrain batch 11/32 - 171.7ms/batch - loss: 1.16489 - diff: 18.64mlTrain batch 12/32 - 191.9ms/batch - loss: 1.17438 - diff: 18.79mlTrain batch 13/32 - 173.5ms/batch - loss: 1.16163 - diff: 18.59mlTrain batch 14/32 - 182.4ms/batch - loss: 1.14129 - diff: 18.26mlTrain batch 15/32 - 168.9ms/batch - loss: 1.23529 - diff: 19.76mlTrain batch 16/32 - 184.5ms/batch - loss: 1.22005 - diff: 19.52mlTrain batch 17/32 - 179.8ms/batch - loss: 1.19343 - diff: 19.09mlTrain batch 18/32 - 113.8ms/batch - loss: 1.15728 - diff: 18.52mlTrain batch 19/32 - 179.3ms/batch - loss: 1.15027 - diff: 18.40mlTrain batch 20/32 - 152.4ms/batch - loss: 1.14698 - diff: 18.35mlTrain batch 21/32 - 171.9ms/batch - loss: 1.16992 - diff: 18.72mlTrain batch 22/32 - 182.7ms/batch - loss: 1.14680 - diff: 18.35mlTrain batch 23/32 - 176.8ms/batch - loss: 1.14412 - diff: 18.31mlTrain batch 24/32 - 194.7ms/batch - loss: 1.12620 - diff: 18.02mlTrain batch 25/32 - 183.2ms/batch - loss: 1.12187 - diff: 17.95mlTrain batch 26/32 - 166.7ms/batch - loss: 1.11891 - diff: 17.90mlTrain batch 27/32 - 160.4ms/batch - loss: 1.11295 - diff: 17.81mlTrain batch 28/32 - 173.3ms/batch - loss: 1.10143 - diff: 17.62mlTrain batch 29/32 - 137.7ms/batch - loss: 1.10092 - diff: 17.61mlTrain batch 30/32 - 167.2ms/batch - loss: 1.11092 - diff: 17.77mlTrain batch 31/32 - 121.2ms/batch - loss: 1.13474 - diff: 18.16mlTrain batch 32/32 - 211.0ms/batch - loss: 1.21580 - diff: 18.37mlTrain batch 32/32 - 17.3s 211.0ms/batch - loss: 1.21580 - diff: 18.37ml
Test 1.1s: val_loss: 1.48928 - diff: 23.10ml

Epoch 97: current best loss = 1.25041, at epoch 79
Train batch 1/32 - 244.9ms/batch - loss: 0.91320 - diff: 14.61mlTrain batch 2/32 - 196.8ms/batch - loss: 0.81511 - diff: 13.04mlTrain batch 3/32 - 146.8ms/batch - loss: 0.87828 - diff: 14.05mlTrain batch 4/32 - 110.9ms/batch - loss: 1.02148 - diff: 16.34mlTrain batch 5/32 - 178.8ms/batch - loss: 1.02463 - diff: 16.39mlTrain batch 6/32 - 162.7ms/batch - loss: 0.92562 - diff: 14.81mlTrain batch 7/32 - 121.1ms/batch - loss: 0.96242 - diff: 15.40mlTrain batch 8/32 - 168.6ms/batch - loss: 1.01808 - diff: 16.29mlTrain batch 9/32 - 200.6ms/batch - loss: 1.05534 - diff: 16.89mlTrain batch 10/32 - 183.1ms/batch - loss: 1.05377 - diff: 16.86mlTrain batch 11/32 - 156.5ms/batch - loss: 1.02949 - diff: 16.47mlTrain batch 12/32 - 130.9ms/batch - loss: 1.04806 - diff: 16.77mlTrain batch 13/32 - 146.3ms/batch - loss: 1.03126 - diff: 16.50mlTrain batch 14/32 - 167.2ms/batch - loss: 1.01182 - diff: 16.19mlTrain batch 15/32 - 177.1ms/batch - loss: 1.00894 - diff: 16.14mlTrain batch 16/32 - 188.9ms/batch - loss: 1.03081 - diff: 16.49mlTrain batch 17/32 - 150.1ms/batch - loss: 1.06059 - diff: 16.97mlTrain batch 18/32 - 127.2ms/batch - loss: 1.05169 - diff: 16.83mlTrain batch 19/32 - 150.9ms/batch - loss: 1.12408 - diff: 17.99mlTrain batch 20/32 - 147.5ms/batch - loss: 1.14339 - diff: 18.29mlTrain batch 21/32 - 138.4ms/batch - loss: 1.15881 - diff: 18.54mlTrain batch 22/32 - 161.4ms/batch - loss: 1.16446 - diff: 18.63mlTrain batch 23/32 - 178.4ms/batch - loss: 1.16636 - diff: 18.66mlTrain batch 24/32 - 192.7ms/batch - loss: 1.17474 - diff: 18.80mlTrain batch 25/32 - 160.0ms/batch - loss: 1.16124 - diff: 18.58mlTrain batch 26/32 - 176.5ms/batch - loss: 1.19826 - diff: 19.17mlTrain batch 27/32 - 138.9ms/batch - loss: 1.19074 - diff: 19.05mlTrain batch 28/32 - 201.5ms/batch - loss: 1.18886 - diff: 19.02mlTrain batch 29/32 - 152.0ms/batch - loss: 1.17062 - diff: 18.73mlTrain batch 30/32 - 177.6ms/batch - loss: 1.15796 - diff: 18.53mlTrain batch 31/32 - 131.8ms/batch - loss: 1.15436 - diff: 18.47mlTrain batch 32/32 - 109.2ms/batch - loss: 1.21628 - diff: 18.61mlTrain batch 32/32 - 17.2s 109.2ms/batch - loss: 1.21628 - diff: 18.61ml
Test 1.2s: val_loss: 1.57690 - diff: 24.22ml

Epoch 98: current best loss = 1.25041, at epoch 79
Train batch 1/32 - 232.3ms/batch - loss: 0.86210 - diff: 13.79mlTrain batch 2/32 - 148.6ms/batch - loss: 0.79488 - diff: 12.72mlTrain batch 3/32 - 177.0ms/batch - loss: 0.81985 - diff: 13.12mlTrain batch 4/32 - 193.1ms/batch - loss: 0.94430 - diff: 15.11mlTrain batch 5/32 - 164.1ms/batch - loss: 0.88382 - diff: 14.14mlTrain batch 6/32 - 128.5ms/batch - loss: 1.08529 - diff: 17.36mlTrain batch 7/32 - 149.9ms/batch - loss: 1.12503 - diff: 18.00mlTrain batch 8/32 - 136.4ms/batch - loss: 1.12031 - diff: 17.93mlTrain batch 9/32 - 155.3ms/batch - loss: 1.08381 - diff: 17.34mlTrain batch 10/32 - 160.3ms/batch - loss: 1.08402 - diff: 17.34mlTrain batch 11/32 - 196.7ms/batch - loss: 1.05240 - diff: 16.84mlTrain batch 12/32 - 176.9ms/batch - loss: 1.09481 - diff: 17.52mlTrain batch 13/32 - 143.9ms/batch - loss: 1.14942 - diff: 18.39mlTrain batch 14/32 - 202.3ms/batch - loss: 1.18069 - diff: 18.89mlTrain batch 15/32 - 227.8ms/batch - loss: 1.17430 - diff: 18.79mlTrain batch 16/32 - 184.6ms/batch - loss: 1.18467 - diff: 18.95mlTrain batch 17/32 - 177.0ms/batch - loss: 1.18133 - diff: 18.90mlTrain batch 18/32 - 198.0ms/batch - loss: 1.18955 - diff: 19.03mlTrain batch 19/32 - 187.6ms/batch - loss: 1.17714 - diff: 18.83mlTrain batch 20/32 - 139.4ms/batch - loss: 1.15958 - diff: 18.55mlTrain batch 21/32 - 167.2ms/batch - loss: 1.17612 - diff: 18.82mlTrain batch 22/32 - 185.2ms/batch - loss: 1.16431 - diff: 18.63mlTrain batch 23/32 - 201.2ms/batch - loss: 1.14835 - diff: 18.37mlTrain batch 24/32 - 153.9ms/batch - loss: 1.15123 - diff: 18.42mlTrain batch 25/32 - 140.3ms/batch - loss: 1.16427 - diff: 18.63mlTrain batch 26/32 - 142.2ms/batch - loss: 1.16601 - diff: 18.66mlTrain batch 27/32 - 151.4ms/batch - loss: 1.15395 - diff: 18.46mlTrain batch 28/32 - 158.8ms/batch - loss: 1.17162 - diff: 18.75mlTrain batch 29/32 - 185.8ms/batch - loss: 1.15932 - diff: 18.55mlTrain batch 30/32 - 179.2ms/batch - loss: 1.14850 - diff: 18.38mlTrain batch 31/32 - 140.9ms/batch - loss: 1.16270 - diff: 18.60mlTrain batch 32/32 - 111.1ms/batch - loss: 1.16799 - diff: 18.51mlTrain batch 32/32 - 18.1s 111.1ms/batch - loss: 1.16799 - diff: 18.51ml
Test 1.2s: val_loss: 1.31529 - diff: 20.26ml

Epoch 99: current best loss = 1.25041, at epoch 79
Train batch 1/32 - 204.7ms/batch - loss: 1.03553 - diff: 16.57mlTrain batch 2/32 - 140.5ms/batch - loss: 1.00857 - diff: 16.14mlTrain batch 3/32 - 153.4ms/batch - loss: 0.98824 - diff: 15.81mlTrain batch 4/32 - 157.7ms/batch - loss: 1.00221 - diff: 16.04mlTrain batch 5/32 - 169.0ms/batch - loss: 1.11344 - diff: 17.82mlTrain batch 6/32 - 173.2ms/batch - loss: 1.08326 - diff: 17.33mlTrain batch 7/32 - 186.5ms/batch - loss: 1.00791 - diff: 16.13mlTrain batch 8/32 - 147.3ms/batch - loss: 1.04121 - diff: 16.66mlTrain batch 9/32 - 142.2ms/batch - loss: 1.07829 - diff: 17.25mlTrain batch 10/32 - 130.2ms/batch - loss: 1.10448 - diff: 17.67mlTrain batch 11/32 - 163.7ms/batch - loss: 1.09386 - diff: 17.50mlTrain batch 12/32 - 168.7ms/batch - loss: 1.06670 - diff: 17.07mlTrain batch 13/32 - 112.0ms/batch - loss: 1.02939 - diff: 16.47mlTrain batch 14/32 - 195.3ms/batch - loss: 1.01401 - diff: 16.22mlTrain batch 15/32 - 204.9ms/batch - loss: 1.01147 - diff: 16.18mlTrain batch 16/32 - 187.6ms/batch - loss: 1.04779 - diff: 16.76mlTrain batch 17/32 - 160.6ms/batch - loss: 1.07085 - diff: 17.13mlTrain batch 18/32 - 124.6ms/batch - loss: 1.05290 - diff: 16.85mlTrain batch 19/32 - 137.8ms/batch - loss: 1.05670 - diff: 16.91mlTrain batch 20/32 - 118.6ms/batch - loss: 1.07460 - diff: 17.19mlTrain batch 21/32 - 173.2ms/batch - loss: 1.06681 - diff: 17.07mlTrain batch 22/32 - 187.0ms/batch - loss: 1.08291 - diff: 17.33mlTrain batch 23/32 - 166.3ms/batch - loss: 1.08558 - diff: 17.37mlTrain batch 24/32 - 127.9ms/batch - loss: 1.09415 - diff: 17.51mlTrain batch 25/32 - 199.5ms/batch - loss: 1.09111 - diff: 17.46mlTrain batch 26/32 - 196.6ms/batch - loss: 1.07946 - diff: 17.27mlTrain batch 27/32 - 178.0ms/batch - loss: 1.10690 - diff: 17.71mlTrain batch 28/32 - 178.0ms/batch - loss: 1.10319 - diff: 17.65mlTrain batch 29/32 - 157.5ms/batch - loss: 1.10541 - diff: 17.69mlTrain batch 30/32 - 135.4ms/batch - loss: 1.09684 - diff: 17.55mlTrain batch 31/32 - 118.3ms/batch - loss: 1.10854 - diff: 17.74mlTrain batch 32/32 - 120.1ms/batch - loss: 1.13879 - diff: 17.75mlTrain batch 32/32 - 17.0s 120.1ms/batch - loss: 1.13879 - diff: 17.75ml
Test 1.4s: val_loss: 1.46353 - diff: 22.73ml

Epoch 100: current best loss = 1.25041, at epoch 79
Train batch 1/32 - 215.0ms/batch - loss: 1.22988 - diff: 19.68mlTrain batch 2/32 - 142.3ms/batch - loss: 1.65218 - diff: 26.43mlTrain batch 3/32 - 144.0ms/batch - loss: 1.81848 - diff: 29.10mlTrain batch 4/32 - 161.8ms/batch - loss: 1.61000 - diff: 25.76mlTrain batch 5/32 - 141.5ms/batch - loss: 1.60523 - diff: 25.68mlTrain batch 6/32 - 167.0ms/batch - loss: 1.47264 - diff: 23.56mlTrain batch 7/32 - 154.4ms/batch - loss: 1.36148 - diff: 21.78mlTrain batch 8/32 - 180.4ms/batch - loss: 1.35311 - diff: 21.65mlTrain batch 9/32 - 201.0ms/batch - loss: 1.35321 - diff: 21.65mlTrain batch 10/32 - 179.5ms/batch - loss: 1.30516 - diff: 20.88mlTrain batch 11/32 - 154.1ms/batch - loss: 1.36090 - diff: 21.77mlTrain batch 12/32 - 138.2ms/batch - loss: 1.35927 - diff: 21.75mlTrain batch 13/32 - 142.0ms/batch - loss: 1.43880 - diff: 23.02mlTrain batch 14/32 - 109.6ms/batch - loss: 1.50906 - diff: 24.15mlTrain batch 15/32 - 180.1ms/batch - loss: 1.49999 - diff: 24.00mlTrain batch 16/32 - 171.1ms/batch - loss: 1.45251 - diff: 23.24mlTrain batch 17/32 - 172.5ms/batch - loss: 1.39568 - diff: 22.33mlTrain batch 18/32 - 162.0ms/batch - loss: 1.35489 - diff: 21.68mlTrain batch 19/32 - 184.8ms/batch - loss: 1.33461 - diff: 21.35mlTrain batch 20/32 - 172.8ms/batch - loss: 1.31165 - diff: 20.99mlTrain batch 21/32 - 137.9ms/batch - loss: 1.32516 - diff: 21.20mlTrain batch 22/32 - 143.0ms/batch - loss: 1.30677 - diff: 20.91mlTrain batch 23/32 - 173.0ms/batch - loss: 1.31533 - diff: 21.05mlTrain batch 24/32 - 171.0ms/batch - loss: 1.29698 - diff: 20.75mlTrain batch 25/32 - 159.3ms/batch - loss: 1.28768 - diff: 20.60mlTrain batch 26/32 - 147.2ms/batch - loss: 1.25842 - diff: 20.13mlTrain batch 27/32 - 166.5ms/batch - loss: 1.28636 - diff: 20.58mlTrain batch 28/32 - 159.6ms/batch - loss: 1.30479 - diff: 20.88mlTrain batch 29/32 - 187.0ms/batch - loss: 1.29103 - diff: 20.66mlTrain batch 30/32 - 138.9ms/batch - loss: 1.27817 - diff: 20.45mlTrain batch 31/32 - 118.6ms/batch - loss: 1.26037 - diff: 20.17mlTrain batch 32/32 - 111.2ms/batch - loss: 1.41612 - diff: 20.67mlTrain batch 32/32 - 17.1s 111.2ms/batch - loss: 1.41612 - diff: 20.67ml
Test 1.1s: val_loss: 1.39204 - diff: 21.18ml

Epoch 101: current best loss = 1.25041, at epoch 79
Train batch 1/32 - 181.0ms/batch - loss: 0.72614 - diff: 11.62mlTrain batch 2/32 - 167.1ms/batch - loss: 0.72359 - diff: 11.58mlTrain batch 3/32 - 181.6ms/batch - loss: 0.77733 - diff: 12.44mlTrain batch 4/32 - 170.8ms/batch - loss: 1.02920 - diff: 16.47mlTrain batch 5/32 - 177.8ms/batch - loss: 1.05309 - diff: 16.85mlTrain batch 6/32 - 165.7ms/batch - loss: 1.09535 - diff: 17.53mlTrain batch 7/32 - 155.6ms/batch - loss: 1.05175 - diff: 16.83mlTrain batch 8/32 - 153.9ms/batch - loss: 1.03694 - diff: 16.59mlTrain batch 9/32 - 173.4ms/batch - loss: 1.01108 - diff: 16.18mlTrain batch 10/32 - 170.9ms/batch - loss: 1.03965 - diff: 16.63mlTrain batch 11/32 - 180.9ms/batch - loss: 1.07072 - diff: 17.13mlTrain batch 12/32 - 144.2ms/batch - loss: 1.03769 - diff: 16.60mlTrain batch 13/32 - 146.3ms/batch - loss: 1.12994 - diff: 18.08mlTrain batch 14/32 - 139.6ms/batch - loss: 1.12662 - diff: 18.03mlTrain batch 15/32 - 163.1ms/batch - loss: 1.09399 - diff: 17.50mlTrain batch 16/32 - 182.6ms/batch - loss: 1.08038 - diff: 17.29mlTrain batch 17/32 - 197.5ms/batch - loss: 1.08276 - diff: 17.32mlTrain batch 18/32 - 173.1ms/batch - loss: 1.08721 - diff: 17.40mlTrain batch 19/32 - 162.8ms/batch - loss: 1.10434 - diff: 17.67mlTrain batch 20/32 - 141.3ms/batch - loss: 1.08903 - diff: 17.42mlTrain batch 21/32 - 176.1ms/batch - loss: 1.07267 - diff: 17.16mlTrain batch 22/32 - 133.2ms/batch - loss: 1.06459 - diff: 17.03mlTrain batch 23/32 - 165.4ms/batch - loss: 1.06730 - diff: 17.08mlTrain batch 24/32 - 178.4ms/batch - loss: 1.05606 - diff: 16.90mlTrain batch 25/32 - 155.1ms/batch - loss: 1.08699 - diff: 17.39mlTrain batch 26/32 - 157.9ms/batch - loss: 1.08922 - diff: 17.43mlTrain batch 27/32 - 145.6ms/batch - loss: 1.07942 - diff: 17.27mlTrain batch 28/32 - 192.0ms/batch - loss: 1.08832 - diff: 17.41mlTrain batch 29/32 - 162.1ms/batch - loss: 1.08151 - diff: 17.30mlTrain batch 30/32 - 183.1ms/batch - loss: 1.09500 - diff: 17.52mlTrain batch 31/32 - 149.8ms/batch - loss: 1.08004 - diff: 17.28mlTrain batch 32/32 - 142.6ms/batch - loss: 1.12112 - diff: 17.34mlTrain batch 32/32 - 16.4s 142.6ms/batch - loss: 1.12112 - diff: 17.34ml
Test 1.3s: val_loss: 1.28199 - diff: 20.19ml
Epoch   102: reducing learning rate of group 0 to 1.2500e-04.

Epoch 102: current best loss = 1.25041, at epoch 79
Train batch 1/32 - 160.8ms/batch - loss: 1.62824 - diff: 26.05mlTrain batch 2/32 - 171.7ms/batch - loss: 1.16472 - diff: 18.64mlTrain batch 3/32 - 177.2ms/batch - loss: 1.11560 - diff: 17.85mlTrain batch 4/32 - 203.6ms/batch - loss: 1.12496 - diff: 18.00mlTrain batch 5/32 - 146.3ms/batch - loss: 1.17267 - diff: 18.76mlTrain batch 6/32 - 124.4ms/batch - loss: 1.15068 - diff: 18.41mlTrain batch 7/32 - 144.7ms/batch - loss: 1.20304 - diff: 19.25mlTrain batch 8/32 - 104.3ms/batch - loss: 1.14371 - diff: 18.30mlTrain batch 9/32 - 138.5ms/batch - loss: 1.23086 - diff: 19.69mlTrain batch 10/32 - 177.4ms/batch - loss: 1.17510 - diff: 18.80mlTrain batch 11/32 - 184.3ms/batch - loss: 1.17278 - diff: 18.76mlTrain batch 12/32 - 156.0ms/batch - loss: 1.14732 - diff: 18.36mlTrain batch 13/32 - 194.2ms/batch - loss: 1.15388 - diff: 18.46mlTrain batch 14/32 - 234.5ms/batch - loss: 1.13295 - diff: 18.13mlTrain batch 15/32 - 179.6ms/batch - loss: 1.11159 - diff: 17.79mlTrain batch 16/32 - 227.1ms/batch - loss: 1.12707 - diff: 18.03mlTrain batch 17/32 - 145.9ms/batch - loss: 1.12516 - diff: 18.00mlTrain batch 18/32 - 176.6ms/batch - loss: 1.14030 - diff: 18.24mlTrain batch 19/32 - 171.7ms/batch - loss: 1.11588 - diff: 17.85mlTrain batch 20/32 - 203.0ms/batch - loss: 1.12058 - diff: 17.93mlTrain batch 21/32 - 136.3ms/batch - loss: 1.11803 - diff: 17.89mlTrain batch 22/32 - 104.2ms/batch - loss: 1.11550 - diff: 17.85mlTrain batch 23/32 - 129.9ms/batch - loss: 1.10868 - diff: 17.74mlTrain batch 24/32 - 112.0ms/batch - loss: 1.09116 - diff: 17.46mlTrain batch 25/32 - 184.5ms/batch - loss: 1.07411 - diff: 17.19mlTrain batch 26/32 - 173.6ms/batch - loss: 1.06513 - diff: 17.04mlTrain batch 27/32 - 176.7ms/batch - loss: 1.06996 - diff: 17.12mlTrain batch 28/32 - 170.1ms/batch - loss: 1.09786 - diff: 17.57mlTrain batch 29/32 - 149.8ms/batch - loss: 1.09801 - diff: 17.57mlTrain batch 30/32 - 209.4ms/batch - loss: 1.10926 - diff: 17.75mlTrain batch 31/32 - 117.9ms/batch - loss: 1.10958 - diff: 17.75mlTrain batch 32/32 - 151.4ms/batch - loss: 1.11185 - diff: 17.66mlTrain batch 32/32 - 16.8s 151.4ms/batch - loss: 1.11185 - diff: 17.66ml
Test 1.2s: val_loss: 1.35825 - diff: 20.79ml

Epoch 103: current best loss = 1.25041, at epoch 79
Train batch 1/32 - 253.7ms/batch - loss: 1.48136 - diff: 23.70mlTrain batch 2/32 - 172.2ms/batch - loss: 1.17175 - diff: 18.75mlTrain batch 3/32 - 155.3ms/batch - loss: 1.23552 - diff: 19.77mlTrain batch 4/32 - 131.7ms/batch - loss: 1.23908 - diff: 19.83mlTrain batch 5/32 - 201.3ms/batch - loss: 1.55068 - diff: 24.81mlTrain batch 6/32 - 188.7ms/batch - loss: 1.47210 - diff: 23.55mlTrain batch 7/32 - 182.7ms/batch - loss: 1.35463 - diff: 21.67mlTrain batch 8/32 - 203.0ms/batch - loss: 1.29115 - diff: 20.66mlTrain batch 9/32 - 195.3ms/batch - loss: 1.24075 - diff: 19.85mlTrain batch 10/32 - 192.6ms/batch - loss: 1.20295 - diff: 19.25mlTrain batch 11/32 - 186.0ms/batch - loss: 1.27647 - diff: 20.42mlTrain batch 12/32 - 171.0ms/batch - loss: 1.23439 - diff: 19.75mlTrain batch 13/32 - 146.3ms/batch - loss: 1.23140 - diff: 19.70mlTrain batch 14/32 - 129.4ms/batch - loss: 1.27960 - diff: 20.47mlTrain batch 15/32 - 140.9ms/batch - loss: 1.25959 - diff: 20.15mlTrain batch 16/32 - 159.9ms/batch - loss: 1.27515 - diff: 20.40mlTrain batch 17/32 - 126.4ms/batch - loss: 1.30824 - diff: 20.93mlTrain batch 18/32 - 152.5ms/batch - loss: 1.29129 - diff: 20.66mlTrain batch 19/32 - 140.3ms/batch - loss: 1.26882 - diff: 20.30mlTrain batch 20/32 - 167.4ms/batch - loss: 1.24389 - diff: 19.90mlTrain batch 21/32 - 151.0ms/batch - loss: 1.23903 - diff: 19.82mlTrain batch 22/32 - 154.8ms/batch - loss: 1.21433 - diff: 19.43mlTrain batch 23/32 - 176.2ms/batch - loss: 1.20397 - diff: 19.26mlTrain batch 24/32 - 220.5ms/batch - loss: 1.18544 - diff: 18.97mlTrain batch 25/32 - 175.1ms/batch - loss: 1.16708 - diff: 18.67mlTrain batch 26/32 - 192.0ms/batch - loss: 1.18864 - diff: 19.02mlTrain batch 27/32 - 111.4ms/batch - loss: 1.17091 - diff: 18.73mlTrain batch 28/32 - 106.6ms/batch - loss: 1.17693 - diff: 18.83mlTrain batch 29/32 - 127.0ms/batch - loss: 1.16872 - diff: 18.70mlTrain batch 30/32 - 126.8ms/batch - loss: 1.16005 - diff: 18.56mlTrain batch 31/32 - 152.0ms/batch - loss: 1.15461 - diff: 18.47mlTrain batch 32/32 - 106.9ms/batch - loss: 1.18865 - diff: 18.50mlTrain batch 32/32 - 17.5s 106.9ms/batch - loss: 1.18865 - diff: 18.50ml
Test 1.2s: val_loss: 1.28820 - diff: 19.83ml

Epoch 104: current best loss = 1.25041, at epoch 79
Train batch 1/32 - 217.9ms/batch - loss: 0.86951 - diff: 13.91mlTrain batch 2/32 - 160.5ms/batch - loss: 0.91499 - diff: 14.64mlTrain batch 3/32 - 168.6ms/batch - loss: 0.81772 - diff: 13.08mlTrain batch 4/32 - 176.8ms/batch - loss: 0.93422 - diff: 14.95mlTrain batch 5/32 - 206.3ms/batch - loss: 0.99247 - diff: 15.88mlTrain batch 6/32 - 181.4ms/batch - loss: 0.95212 - diff: 15.23mlTrain batch 7/32 - 195.4ms/batch - loss: 0.96349 - diff: 15.42mlTrain batch 8/32 - 161.9ms/batch - loss: 0.96461 - diff: 15.43mlTrain batch 9/32 - 176.6ms/batch - loss: 0.96464 - diff: 15.43mlTrain batch 10/32 - 190.1ms/batch - loss: 1.00770 - diff: 16.12mlTrain batch 11/32 - 129.6ms/batch - loss: 1.00259 - diff: 16.04mlTrain batch 12/32 - 157.2ms/batch - loss: 1.04956 - diff: 16.79mlTrain batch 13/32 - 126.2ms/batch - loss: 1.04486 - diff: 16.72mlTrain batch 14/32 - 167.3ms/batch - loss: 1.04803 - diff: 16.77mlTrain batch 15/32 - 191.7ms/batch - loss: 1.06203 - diff: 16.99mlTrain batch 16/32 - 194.7ms/batch - loss: 1.05865 - diff: 16.94mlTrain batch 17/32 - 159.6ms/batch - loss: 1.07013 - diff: 17.12mlTrain batch 18/32 - 171.0ms/batch - loss: 1.05926 - diff: 16.95mlTrain batch 19/32 - 161.9ms/batch - loss: 1.04278 - diff: 16.68mlTrain batch 20/32 - 159.7ms/batch - loss: 1.03427 - diff: 16.55mlTrain batch 21/32 - 191.6ms/batch - loss: 1.01095 - diff: 16.18mlTrain batch 22/32 - 191.9ms/batch - loss: 1.00910 - diff: 16.15mlTrain batch 23/32 - 179.5ms/batch - loss: 1.00736 - diff: 16.12mlTrain batch 24/32 - 141.6ms/batch - loss: 1.01123 - diff: 16.18mlTrain batch 25/32 - 215.6ms/batch - loss: 1.02670 - diff: 16.43mlTrain batch 26/32 - 134.2ms/batch - loss: 1.03652 - diff: 16.58mlTrain batch 27/32 - 171.8ms/batch - loss: 1.03921 - diff: 16.63mlTrain batch 28/32 - 191.9ms/batch - loss: 1.03801 - diff: 16.61mlTrain batch 29/32 - 125.4ms/batch - loss: 1.02741 - diff: 16.44mlTrain batch 30/32 - 168.2ms/batch - loss: 1.02523 - diff: 16.40mlTrain batch 31/32 - 148.7ms/batch - loss: 1.04077 - diff: 16.65mlTrain batch 32/32 - 170.7ms/batch - loss: 1.12244 - diff: 16.88mlTrain batch 32/32 - 17.2s 170.7ms/batch - loss: 1.12244 - diff: 16.88ml
Test 1.3s: val_loss: 1.32680 - diff: 20.48ml

Epoch 105: current best loss = 1.25041, at epoch 79
Train batch 1/32 - 248.1ms/batch - loss: 1.13013 - diff: 18.08mlTrain batch 2/32 - 204.3ms/batch - loss: 1.00609 - diff: 16.10mlTrain batch 3/32 - 175.4ms/batch - loss: 1.47264 - diff: 23.56mlTrain batch 4/32 - 139.7ms/batch - loss: 1.33929 - diff: 21.43mlTrain batch 5/32 - 166.6ms/batch - loss: 1.28948 - diff: 20.63mlTrain batch 6/32 - 184.7ms/batch - loss: 1.29431 - diff: 20.71mlTrain batch 7/32 - 176.9ms/batch - loss: 1.25057 - diff: 20.01mlTrain batch 8/32 - 160.8ms/batch - loss: 1.22580 - diff: 19.61mlTrain batch 9/32 - 183.7ms/batch - loss: 1.20336 - diff: 19.25mlTrain batch 10/32 - 168.6ms/batch - loss: 1.17525 - diff: 18.80mlTrain batch 11/32 - 185.1ms/batch - loss: 1.16880 - diff: 18.70mlTrain batch 12/32 - 179.5ms/batch - loss: 1.18987 - diff: 19.04mlTrain batch 13/32 - 175.1ms/batch - loss: 1.17937 - diff: 18.87mlTrain batch 14/32 - 138.8ms/batch - loss: 1.18973 - diff: 19.04mlTrain batch 15/32 - 159.8ms/batch - loss: 1.17302 - diff: 18.77mlTrain batch 16/32 - 154.5ms/batch - loss: 1.15817 - diff: 18.53mlTrain batch 17/32 - 188.8ms/batch - loss: 1.17158 - diff: 18.75mlTrain batch 18/32 - 189.9ms/batch - loss: 1.17773 - diff: 18.84mlTrain batch 19/32 - 159.2ms/batch - loss: 1.15237 - diff: 18.44mlTrain batch 20/32 - 152.9ms/batch - loss: 1.13751 - diff: 18.20mlTrain batch 21/32 - 138.9ms/batch - loss: 1.14818 - diff: 18.37mlTrain batch 22/32 - 156.3ms/batch - loss: 1.13166 - diff: 18.11mlTrain batch 23/32 - 188.7ms/batch - loss: 1.10942 - diff: 17.75mlTrain batch 24/32 - 230.6ms/batch - loss: 1.10889 - diff: 17.74mlTrain batch 25/32 - 181.7ms/batch - loss: 1.09615 - diff: 17.54mlTrain batch 26/32 - 222.2ms/batch - loss: 1.08889 - diff: 17.42mlTrain batch 27/32 - 155.8ms/batch - loss: 1.08254 - diff: 17.32mlTrain batch 28/32 - 191.5ms/batch - loss: 1.07595 - diff: 17.22mlTrain batch 29/32 - 168.0ms/batch - loss: 1.07955 - diff: 17.27mlTrain batch 30/32 - 195.4ms/batch - loss: 1.07657 - diff: 17.23mlTrain batch 31/32 - 120.4ms/batch - loss: 1.07622 - diff: 17.22mlTrain batch 32/32 - 114.2ms/batch - loss: 1.13197 - diff: 17.34mlTrain batch 32/32 - 17.7s 114.2ms/batch - loss: 1.13197 - diff: 17.34ml
Test 1.2s: val_loss: 1.27397 - diff: 19.68ml

Epoch 106: current best loss = 1.25041, at epoch 79
Train batch 1/32 - 221.4ms/batch - loss: 0.72046 - diff: 11.53mlTrain batch 2/32 - 187.1ms/batch - loss: 1.23591 - diff: 19.77mlTrain batch 3/32 - 174.5ms/batch - loss: 0.97947 - diff: 15.67mlTrain batch 4/32 - 206.4ms/batch - loss: 1.11153 - diff: 17.78mlTrain batch 5/32 - 166.6ms/batch - loss: 1.08958 - diff: 17.43mlTrain batch 6/32 - 174.8ms/batch - loss: 1.09772 - diff: 17.56mlTrain batch 7/32 - 157.7ms/batch - loss: 1.06913 - diff: 17.11mlTrain batch 8/32 - 167.1ms/batch - loss: 1.21271 - diff: 19.40mlTrain batch 9/32 - 198.8ms/batch - loss: 1.15605 - diff: 18.50mlTrain batch 10/32 - 196.1ms/batch - loss: 1.15142 - diff: 18.42mlTrain batch 11/32 - 202.8ms/batch - loss: 1.13410 - diff: 18.15mlTrain batch 12/32 - 211.5ms/batch - loss: 1.17301 - diff: 18.77mlTrain batch 13/32 - 149.6ms/batch - loss: 1.21287 - diff: 19.41mlTrain batch 14/32 - 177.6ms/batch - loss: 1.19639 - diff: 19.14mlTrain batch 15/32 - 146.7ms/batch - loss: 1.22234 - diff: 19.56mlTrain batch 16/32 - 142.9ms/batch - loss: 1.20608 - diff: 19.30mlTrain batch 17/32 - 145.4ms/batch - loss: 1.22444 - diff: 19.59mlTrain batch 18/32 - 195.0ms/batch - loss: 1.20882 - diff: 19.34mlTrain batch 19/32 - 172.4ms/batch - loss: 1.24807 - diff: 19.97mlTrain batch 20/32 - 176.8ms/batch - loss: 1.24698 - diff: 19.95mlTrain batch 21/32 - 167.2ms/batch - loss: 1.23768 - diff: 19.80mlTrain batch 22/32 - 105.6ms/batch - loss: 1.23184 - diff: 19.71mlTrain batch 23/32 - 140.7ms/batch - loss: 1.23125 - diff: 19.70mlTrain batch 24/32 - 174.3ms/batch - loss: 1.23371 - diff: 19.74mlTrain batch 25/32 - 131.7ms/batch - loss: 1.21621 - diff: 19.46mlTrain batch 26/32 - 105.5ms/batch - loss: 1.21344 - diff: 19.42mlTrain batch 27/32 - 143.2ms/batch - loss: 1.20025 - diff: 19.20mlTrain batch 28/32 - 172.9ms/batch - loss: 1.19356 - diff: 19.10mlTrain batch 29/32 - 190.8ms/batch - loss: 1.18729 - diff: 19.00mlTrain batch 30/32 - 171.7ms/batch - loss: 1.19668 - diff: 19.15mlTrain batch 31/32 - 120.2ms/batch - loss: 1.18075 - diff: 18.89mlTrain batch 32/32 - 125.0ms/batch - loss: 1.24886 - diff: 19.05mlTrain batch 32/32 - 16.5s 125.0ms/batch - loss: 1.24886 - diff: 19.05ml
Test 1.3s: val_loss: 1.30688 - diff: 20.41ml

Epoch 107: current best loss = 1.25041, at epoch 79
Train batch 1/32 - 256.0ms/batch - loss: 0.74107 - diff: 11.86mlTrain batch 2/32 - 191.2ms/batch - loss: 0.95301 - diff: 15.25mlTrain batch 3/32 - 182.9ms/batch - loss: 0.88846 - diff: 14.22mlTrain batch 4/32 - 179.9ms/batch - loss: 0.96801 - diff: 15.49mlTrain batch 5/32 - 154.3ms/batch - loss: 0.93813 - diff: 15.01mlTrain batch 6/32 - 141.6ms/batch - loss: 0.96624 - diff: 15.46mlTrain batch 7/32 - 160.6ms/batch - loss: 0.93622 - diff: 14.98mlTrain batch 8/32 - 164.9ms/batch - loss: 0.89534 - diff: 14.33mlTrain batch 9/32 - 169.4ms/batch - loss: 0.91089 - diff: 14.57mlTrain batch 10/32 - 190.7ms/batch - loss: 0.97623 - diff: 15.62mlTrain batch 11/32 - 172.5ms/batch - loss: 0.96178 - diff: 15.39mlTrain batch 12/32 - 192.8ms/batch - loss: 1.01629 - diff: 16.26mlTrain batch 13/32 - 139.1ms/batch - loss: 1.10933 - diff: 17.75mlTrain batch 14/32 - 168.0ms/batch - loss: 1.09230 - diff: 17.48mlTrain batch 15/32 - 122.6ms/batch - loss: 1.09886 - diff: 17.58mlTrain batch 16/32 - 143.2ms/batch - loss: 1.08429 - diff: 17.35mlTrain batch 17/32 - 124.2ms/batch - loss: 1.06517 - diff: 17.04mlTrain batch 18/32 - 142.2ms/batch - loss: 1.06870 - diff: 17.10mlTrain batch 19/32 - 167.2ms/batch - loss: 1.08676 - diff: 17.39mlTrain batch 20/32 - 189.0ms/batch - loss: 1.07817 - diff: 17.25mlTrain batch 21/32 - 170.8ms/batch - loss: 1.06837 - diff: 17.09mlTrain batch 22/32 - 159.4ms/batch - loss: 1.05819 - diff: 16.93mlTrain batch 23/32 - 120.5ms/batch - loss: 1.05127 - diff: 16.82mlTrain batch 24/32 - 170.8ms/batch - loss: 1.05048 - diff: 16.81mlTrain batch 25/32 - 171.2ms/batch - loss: 1.07195 - diff: 17.15mlTrain batch 26/32 - 187.5ms/batch - loss: 1.06238 - diff: 17.00mlTrain batch 27/32 - 162.4ms/batch - loss: 1.06476 - diff: 17.04mlTrain batch 28/32 - 170.8ms/batch - loss: 1.05258 - diff: 16.84mlTrain batch 29/32 - 177.5ms/batch - loss: 1.03802 - diff: 16.61mlTrain batch 30/32 - 185.6ms/batch - loss: 1.04720 - diff: 16.76mlTrain batch 31/32 - 169.7ms/batch - loss: 1.04013 - diff: 16.64mlTrain batch 32/32 - 196.3ms/batch - loss: 1.05526 - diff: 16.60mlTrain batch 32/32 - 17.7s 196.3ms/batch - loss: 1.05526 - diff: 16.60ml
Test 1.1s: val_loss: 1.30727 - diff: 19.92ml

Epoch 108: current best loss = 1.25041, at epoch 79
Train batch 1/32 - 182.3ms/batch - loss: 3.04040 - diff: 48.65mlTrain batch 2/32 - 113.8ms/batch - loss: 2.61448 - diff: 41.83mlTrain batch 3/32 - 158.5ms/batch - loss: 1.94416 - diff: 31.11mlTrain batch 4/32 - 151.0ms/batch - loss: 1.67417 - diff: 26.79mlTrain batch 5/32 - 180.5ms/batch - loss: 1.48351 - diff: 23.74mlTrain batch 6/32 - 158.9ms/batch - loss: 1.37593 - diff: 22.01mlTrain batch 7/32 - 143.5ms/batch - loss: 1.28717 - diff: 20.59mlTrain batch 8/32 - 180.2ms/batch - loss: 1.22465 - diff: 19.59mlTrain batch 9/32 - 213.3ms/batch - loss: 1.28186 - diff: 20.51mlTrain batch 10/32 - 184.6ms/batch - loss: 1.25574 - diff: 20.09mlTrain batch 11/32 - 160.8ms/batch - loss: 1.26125 - diff: 20.18mlTrain batch 12/32 - 172.1ms/batch - loss: 1.20988 - diff: 19.36mlTrain batch 13/32 - 165.3ms/batch - loss: 1.16969 - diff: 18.72mlTrain batch 14/32 - 160.3ms/batch - loss: 1.14073 - diff: 18.25mlTrain batch 15/32 - 203.0ms/batch - loss: 1.10441 - diff: 17.67mlTrain batch 16/32 - 197.3ms/batch - loss: 1.11367 - diff: 17.82mlTrain batch 17/32 - 141.2ms/batch - loss: 1.14436 - diff: 18.31mlTrain batch 18/32 - 110.8ms/batch - loss: 1.14321 - diff: 18.29mlTrain batch 19/32 - 134.9ms/batch - loss: 1.16853 - diff: 18.70mlTrain batch 20/32 - 150.7ms/batch - loss: 1.18032 - diff: 18.89mlTrain batch 21/32 - 145.6ms/batch - loss: 1.19212 - diff: 19.07mlTrain batch 22/32 - 104.7ms/batch - loss: 1.17265 - diff: 18.76mlTrain batch 23/32 - 198.0ms/batch - loss: 1.16999 - diff: 18.72mlTrain batch 24/32 - 219.7ms/batch - loss: 1.15179 - diff: 18.43mlTrain batch 25/32 - 163.2ms/batch - loss: 1.14513 - diff: 18.32mlTrain batch 26/32 - 174.7ms/batch - loss: 1.14042 - diff: 18.25mlTrain batch 27/32 - 104.0ms/batch - loss: 1.14345 - diff: 18.30mlTrain batch 28/32 - 101.7ms/batch - loss: 1.13706 - diff: 18.19mlTrain batch 29/32 - 180.5ms/batch - loss: 1.13179 - diff: 18.11mlTrain batch 30/32 - 138.6ms/batch - loss: 1.11382 - diff: 17.82mlTrain batch 31/32 - 141.7ms/batch - loss: 1.10692 - diff: 17.71mlTrain batch 32/32 - 160.5ms/batch - loss: 1.12685 - diff: 17.68mlTrain batch 32/32 - 17.3s 160.5ms/batch - loss: 1.12685 - diff: 17.68ml
Test 1.4s: val_loss: 1.22404 - diff: 19.30ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_DenseNet121_0_Adam-0.001_MAE_DA3_best

Epoch 109: current best loss = 1.22404, at epoch 108
Train batch 1/32 - 196.3ms/batch - loss: 0.89643 - diff: 14.34mlTrain batch 2/32 - 159.1ms/batch - loss: 0.86809 - diff: 13.89mlTrain batch 3/32 - 149.8ms/batch - loss: 1.04292 - diff: 16.69mlTrain batch 4/32 - 158.7ms/batch - loss: 1.06901 - diff: 17.10mlTrain batch 5/32 - 168.6ms/batch - loss: 1.01293 - diff: 16.21mlTrain batch 6/32 - 187.0ms/batch - loss: 0.99345 - diff: 15.90mlTrain batch 7/32 - 156.0ms/batch - loss: 1.10807 - diff: 17.73mlTrain batch 8/32 - 116.5ms/batch - loss: 1.07662 - diff: 17.23mlTrain batch 9/32 - 148.9ms/batch - loss: 1.07724 - diff: 17.24mlTrain batch 10/32 - 157.9ms/batch - loss: 1.06225 - diff: 17.00mlTrain batch 11/32 - 170.3ms/batch - loss: 1.11790 - diff: 17.89mlTrain batch 12/32 - 142.2ms/batch - loss: 1.14472 - diff: 18.32mlTrain batch 13/32 - 127.5ms/batch - loss: 1.11325 - diff: 17.81mlTrain batch 14/32 - 130.3ms/batch - loss: 1.11331 - diff: 17.81mlTrain batch 15/32 - 109.4ms/batch - loss: 1.08090 - diff: 17.29mlTrain batch 16/32 - 114.2ms/batch - loss: 1.08178 - diff: 17.31mlTrain batch 17/32 - 181.9ms/batch - loss: 1.08585 - diff: 17.37mlTrain batch 18/32 - 163.5ms/batch - loss: 1.09088 - diff: 17.45mlTrain batch 19/32 - 143.8ms/batch - loss: 1.08595 - diff: 17.38mlTrain batch 20/32 - 174.4ms/batch - loss: 1.07217 - diff: 17.15mlTrain batch 21/32 - 143.0ms/batch - loss: 1.05708 - diff: 16.91mlTrain batch 22/32 - 158.4ms/batch - loss: 1.05472 - diff: 16.88mlTrain batch 23/32 - 142.3ms/batch - loss: 1.05212 - diff: 16.83mlTrain batch 24/32 - 163.4ms/batch - loss: 1.03021 - diff: 16.48mlTrain batch 25/32 - 158.4ms/batch - loss: 1.02050 - diff: 16.33mlTrain batch 26/32 - 208.9ms/batch - loss: 1.04568 - diff: 16.73mlTrain batch 27/32 - 182.8ms/batch - loss: 1.02736 - diff: 16.44mlTrain batch 28/32 - 202.3ms/batch - loss: 1.01376 - diff: 16.22mlTrain batch 29/32 - 137.2ms/batch - loss: 1.00619 - diff: 16.10mlTrain batch 30/32 - 172.5ms/batch - loss: 0.99875 - diff: 15.98mlTrain batch 31/32 - 132.8ms/batch - loss: 1.00642 - diff: 16.10mlTrain batch 32/32 - 159.6ms/batch - loss: 1.05322 - diff: 16.19mlTrain batch 32/32 - 17.3s 159.6ms/batch - loss: 1.05322 - diff: 16.19ml
Test 1.2s: val_loss: 1.31795 - diff: 20.25ml

Epoch 110: current best loss = 1.22404, at epoch 108
Train batch 1/32 - 221.1ms/batch - loss: 0.80916 - diff: 12.95mlTrain batch 2/32 - 198.5ms/batch - loss: 0.73413 - diff: 11.75mlTrain batch 3/32 - 141.5ms/batch - loss: 0.81522 - diff: 13.04mlTrain batch 4/32 - 178.0ms/batch - loss: 0.88621 - diff: 14.18mlTrain batch 5/32 - 189.6ms/batch - loss: 0.78820 - diff: 12.61mlTrain batch 6/32 - 162.6ms/batch - loss: 0.81407 - diff: 13.03mlTrain batch 7/32 - 174.9ms/batch - loss: 0.83993 - diff: 13.44mlTrain batch 8/32 - 186.6ms/batch - loss: 0.99339 - diff: 15.89mlTrain batch 9/32 - 168.6ms/batch - loss: 1.03670 - diff: 16.59mlTrain batch 10/32 - 196.1ms/batch - loss: 1.02972 - diff: 16.48mlTrain batch 11/32 - 188.5ms/batch - loss: 1.00574 - diff: 16.09mlTrain batch 12/32 - 193.7ms/batch - loss: 0.97893 - diff: 15.66mlTrain batch 13/32 - 199.8ms/batch - loss: 0.95351 - diff: 15.26mlTrain batch 14/32 - 183.0ms/batch - loss: 0.95217 - diff: 15.23mlTrain batch 15/32 - 168.4ms/batch - loss: 0.97902 - diff: 15.66mlTrain batch 16/32 - 104.9ms/batch - loss: 1.01141 - diff: 16.18mlTrain batch 17/32 - 175.9ms/batch - loss: 1.01349 - diff: 16.22mlTrain batch 18/32 - 141.4ms/batch - loss: 1.05543 - diff: 16.89mlTrain batch 19/32 - 176.0ms/batch - loss: 1.05018 - diff: 16.80mlTrain batch 20/32 - 155.9ms/batch - loss: 1.03028 - diff: 16.48mlTrain batch 21/32 - 163.7ms/batch - loss: 1.01298 - diff: 16.21mlTrain batch 22/32 - 123.0ms/batch - loss: 1.02756 - diff: 16.44mlTrain batch 23/32 - 169.5ms/batch - loss: 1.04679 - diff: 16.75mlTrain batch 24/32 - 189.2ms/batch - loss: 1.03766 - diff: 16.60mlTrain batch 25/32 - 173.1ms/batch - loss: 1.04276 - diff: 16.68mlTrain batch 26/32 - 112.6ms/batch - loss: 1.02963 - diff: 16.47mlTrain batch 27/32 - 113.1ms/batch - loss: 1.02880 - diff: 16.46mlTrain batch 28/32 - 136.4ms/batch - loss: 1.03066 - diff: 16.49mlTrain batch 29/32 - 174.2ms/batch - loss: 1.04454 - diff: 16.71mlTrain batch 30/32 - 162.8ms/batch - loss: 1.03932 - diff: 16.63mlTrain batch 31/32 - 113.3ms/batch - loss: 1.04751 - diff: 16.76mlTrain batch 32/32 - 105.3ms/batch - loss: 1.10689 - diff: 16.90mlTrain batch 32/32 - 16.5s 105.3ms/batch - loss: 1.10689 - diff: 16.90ml
Test 1.3s: val_loss: 1.38040 - diff: 21.02ml

Epoch 111: current best loss = 1.22404, at epoch 108
Train batch 1/32 - 201.7ms/batch - loss: 1.14742 - diff: 18.36mlTrain batch 2/32 - 145.6ms/batch - loss: 0.99316 - diff: 15.89mlTrain batch 3/32 - 199.2ms/batch - loss: 1.59658 - diff: 25.55mlTrain batch 4/32 - 183.3ms/batch - loss: 1.46612 - diff: 23.46mlTrain batch 5/32 - 192.7ms/batch - loss: 1.31013 - diff: 20.96mlTrain batch 6/32 - 164.9ms/batch - loss: 1.24836 - diff: 19.97mlTrain batch 7/32 - 184.7ms/batch - loss: 1.21982 - diff: 19.52mlTrain batch 8/32 - 153.4ms/batch - loss: 1.15989 - diff: 18.56mlTrain batch 9/32 - 171.7ms/batch - loss: 1.22551 - diff: 19.61mlTrain batch 10/32 - 201.8ms/batch - loss: 1.19805 - diff: 19.17mlTrain batch 11/32 - 183.9ms/batch - loss: 1.15876 - diff: 18.54mlTrain batch 12/32 - 166.7ms/batch - loss: 1.11130 - diff: 17.78mlTrain batch 13/32 - 188.6ms/batch - loss: 1.13394 - diff: 18.14mlTrain batch 14/32 - 152.1ms/batch - loss: 1.13892 - diff: 18.22mlTrain batch 15/32 - 166.3ms/batch - loss: 1.13263 - diff: 18.12mlTrain batch 16/32 - 134.1ms/batch - loss: 1.12750 - diff: 18.04mlTrain batch 17/32 - 182.8ms/batch - loss: 1.16215 - diff: 18.59mlTrain batch 18/32 - 152.7ms/batch - loss: 1.15609 - diff: 18.50mlTrain batch 19/32 - 125.4ms/batch - loss: 1.13180 - diff: 18.11mlTrain batch 20/32 - 205.3ms/batch - loss: 1.10107 - diff: 17.62mlTrain batch 21/32 - 166.7ms/batch - loss: 1.08900 - diff: 17.42mlTrain batch 22/32 - 196.5ms/batch - loss: 1.08069 - diff: 17.29mlTrain batch 23/32 - 181.9ms/batch - loss: 1.07230 - diff: 17.16mlTrain batch 24/32 - 219.3ms/batch - loss: 1.08142 - diff: 17.30mlTrain batch 25/32 - 155.8ms/batch - loss: 1.07755 - diff: 17.24mlTrain batch 26/32 - 107.2ms/batch - loss: 1.09477 - diff: 17.52mlTrain batch 27/32 - 136.6ms/batch - loss: 1.07856 - diff: 17.26mlTrain batch 28/32 - 150.5ms/batch - loss: 1.06680 - diff: 17.07mlTrain batch 29/32 - 148.6ms/batch - loss: 1.07594 - diff: 17.22mlTrain batch 30/32 - 140.0ms/batch - loss: 1.06116 - diff: 16.98mlTrain batch 31/32 - 112.7ms/batch - loss: 1.04994 - diff: 16.80mlTrain batch 32/32 - 105.0ms/batch - loss: 1.07156 - diff: 16.78mlTrain batch 32/32 - 18.2s 105.0ms/batch - loss: 1.07156 - diff: 16.78ml
Test 1.2s: val_loss: 1.30996 - diff: 20.22ml

Epoch 112: current best loss = 1.22404, at epoch 108
Train batch 1/32 - 193.3ms/batch - loss: 3.08464 - diff: 49.35mlTrain batch 2/32 - 153.5ms/batch - loss: 1.88898 - diff: 30.22mlTrain batch 3/32 - 191.1ms/batch - loss: 1.51864 - diff: 24.30mlTrain batch 4/32 - 161.9ms/batch - loss: 1.34476 - diff: 21.52mlTrain batch 5/32 - 148.4ms/batch - loss: 1.27698 - diff: 20.43mlTrain batch 6/32 - 125.1ms/batch - loss: 1.17233 - diff: 18.76mlTrain batch 7/32 - 120.8ms/batch - loss: 1.27971 - diff: 20.48mlTrain batch 8/32 - 118.4ms/batch - loss: 1.35975 - diff: 21.76mlTrain batch 9/32 - 150.3ms/batch - loss: 1.49160 - diff: 23.87mlTrain batch 10/32 - 107.3ms/batch - loss: 1.47627 - diff: 23.62mlTrain batch 11/32 - 159.1ms/batch - loss: 1.41233 - diff: 22.60mlTrain batch 12/32 - 103.8ms/batch - loss: 1.38310 - diff: 22.13mlTrain batch 13/32 - 145.2ms/batch - loss: 1.36593 - diff: 21.85mlTrain batch 14/32 - 119.3ms/batch - loss: 1.31888 - diff: 21.10mlTrain batch 15/32 - 169.2ms/batch - loss: 1.28619 - diff: 20.58mlTrain batch 16/32 - 196.7ms/batch - loss: 1.27689 - diff: 20.43mlTrain batch 17/32 - 169.4ms/batch - loss: 1.26008 - diff: 20.16mlTrain batch 18/32 - 180.8ms/batch - loss: 1.25610 - diff: 20.10mlTrain batch 19/32 - 154.2ms/batch - loss: 1.23525 - diff: 19.76mlTrain batch 20/32 - 133.7ms/batch - loss: 1.24438 - diff: 19.91mlTrain batch 21/32 - 142.9ms/batch - loss: 1.22766 - diff: 19.64mlTrain batch 22/32 - 165.4ms/batch - loss: 1.19792 - diff: 19.17mlTrain batch 23/32 - 205.2ms/batch - loss: 1.18784 - diff: 19.01mlTrain batch 24/32 - 170.8ms/batch - loss: 1.16342 - diff: 18.61mlTrain batch 25/32 - 155.6ms/batch - loss: 1.16315 - diff: 18.61mlTrain batch 26/32 - 161.5ms/batch - loss: 1.15755 - diff: 18.52mlTrain batch 27/32 - 202.8ms/batch - loss: 1.16627 - diff: 18.66mlTrain batch 28/32 - 177.0ms/batch - loss: 1.17332 - diff: 18.77mlTrain batch 29/32 - 165.9ms/batch - loss: 1.21737 - diff: 19.48mlTrain batch 30/32 - 169.4ms/batch - loss: 1.19769 - diff: 19.16mlTrain batch 31/32 - 151.2ms/batch - loss: 1.23087 - diff: 19.69mlTrain batch 32/32 - 179.2ms/batch - loss: 1.24061 - diff: 19.61mlTrain batch 32/32 - 16.9s 179.2ms/batch - loss: 1.24061 - diff: 19.61ml
Test 1.2s: val_loss: 1.29616 - diff: 19.77ml

Epoch 113: current best loss = 1.22404, at epoch 108
Train batch 1/32 - 154.4ms/batch - loss: 0.66165 - diff: 10.59mlTrain batch 2/32 - 139.6ms/batch - loss: 0.71991 - diff: 11.52mlTrain batch 3/32 - 142.0ms/batch - loss: 0.85648 - diff: 13.70mlTrain batch 4/32 - 109.7ms/batch - loss: 1.03220 - diff: 16.52mlTrain batch 5/32 - 117.8ms/batch - loss: 1.13025 - diff: 18.08mlTrain batch 6/32 - 147.4ms/batch - loss: 1.15780 - diff: 18.52mlTrain batch 7/32 - 172.5ms/batch - loss: 1.27155 - diff: 20.34mlTrain batch 8/32 - 183.0ms/batch - loss: 1.25965 - diff: 20.15mlTrain batch 9/32 - 185.4ms/batch - loss: 1.20712 - diff: 19.31mlTrain batch 10/32 - 158.6ms/batch - loss: 1.16886 - diff: 18.70mlTrain batch 11/32 - 178.3ms/batch - loss: 1.22421 - diff: 19.59mlTrain batch 12/32 - 184.3ms/batch - loss: 1.18486 - diff: 18.96mlTrain batch 13/32 - 178.4ms/batch - loss: 1.18174 - diff: 18.91mlTrain batch 14/32 - 179.7ms/batch - loss: 1.16896 - diff: 18.70mlTrain batch 15/32 - 156.2ms/batch - loss: 1.13156 - diff: 18.10mlTrain batch 16/32 - 150.7ms/batch - loss: 1.11808 - diff: 17.89mlTrain batch 17/32 - 169.4ms/batch - loss: 1.08946 - diff: 17.43mlTrain batch 18/32 - 150.2ms/batch - loss: 1.08077 - diff: 17.29mlTrain batch 19/32 - 141.9ms/batch - loss: 1.06770 - diff: 17.08mlTrain batch 20/32 - 107.3ms/batch - loss: 1.06274 - diff: 17.00mlTrain batch 21/32 - 166.7ms/batch - loss: 1.05031 - diff: 16.80mlTrain batch 22/32 - 154.1ms/batch - loss: 1.03705 - diff: 16.59mlTrain batch 23/32 - 144.9ms/batch - loss: 1.03628 - diff: 16.58mlTrain batch 24/32 - 136.3ms/batch - loss: 1.03617 - diff: 16.58mlTrain batch 25/32 - 162.6ms/batch - loss: 1.02630 - diff: 16.42mlTrain batch 26/32 - 149.7ms/batch - loss: 1.02323 - diff: 16.37mlTrain batch 27/32 - 156.6ms/batch - loss: 1.01782 - diff: 16.29mlTrain batch 28/32 - 110.7ms/batch - loss: 1.01875 - diff: 16.30mlTrain batch 29/32 - 125.8ms/batch - loss: 1.01774 - diff: 16.28mlTrain batch 30/32 - 146.8ms/batch - loss: 1.00922 - diff: 16.15mlTrain batch 31/32 - 159.1ms/batch - loss: 0.99231 - diff: 15.88mlTrain batch 32/32 - 184.1ms/batch - loss: 1.03041 - diff: 15.93mlTrain batch 32/32 - 17.0s 184.1ms/batch - loss: 1.03041 - diff: 15.93ml
Test 1.2s: val_loss: 1.23710 - diff: 19.04ml

Epoch 114: current best loss = 1.22404, at epoch 108
Train batch 1/32 - 196.3ms/batch - loss: 0.87041 - diff: 13.93mlTrain batch 2/32 - 123.7ms/batch - loss: 0.90215 - diff: 14.43mlTrain batch 3/32 - 144.6ms/batch - loss: 1.16274 - diff: 18.60mlTrain batch 4/32 - 142.1ms/batch - loss: 1.10605 - diff: 17.70mlTrain batch 5/32 - 187.0ms/batch - loss: 1.17544 - diff: 18.81mlTrain batch 6/32 - 110.9ms/batch - loss: 1.11347 - diff: 17.82mlTrain batch 7/32 - 180.5ms/batch - loss: 1.13622 - diff: 18.18mlTrain batch 8/32 - 196.9ms/batch - loss: 1.11909 - diff: 17.91mlTrain batch 9/32 - 165.5ms/batch - loss: 1.11146 - diff: 17.78mlTrain batch 10/32 - 190.4ms/batch - loss: 1.09518 - diff: 17.52mlTrain batch 11/32 - 144.3ms/batch - loss: 1.04748 - diff: 16.76mlTrain batch 12/32 - 124.9ms/batch - loss: 1.06969 - diff: 17.12mlTrain batch 13/32 - 143.7ms/batch - loss: 1.07604 - diff: 17.22mlTrain batch 14/32 - 118.3ms/batch - loss: 1.08295 - diff: 17.33mlTrain batch 15/32 - 128.3ms/batch - loss: 1.07198 - diff: 17.15mlTrain batch 16/32 - 182.1ms/batch - loss: 1.05786 - diff: 16.93mlTrain batch 17/32 - 172.6ms/batch - loss: 1.08458 - diff: 17.35mlTrain batch 18/32 - 148.7ms/batch - loss: 1.06507 - diff: 17.04mlTrain batch 19/32 - 145.2ms/batch - loss: 1.04782 - diff: 16.77mlTrain batch 20/32 - 171.9ms/batch - loss: 1.07521 - diff: 17.20mlTrain batch 21/32 - 183.8ms/batch - loss: 1.06949 - diff: 17.11mlTrain batch 22/32 - 161.7ms/batch - loss: 1.11726 - diff: 17.88mlTrain batch 23/32 - 181.9ms/batch - loss: 1.16715 - diff: 18.67mlTrain batch 24/32 - 191.6ms/batch - loss: 1.15360 - diff: 18.46mlTrain batch 25/32 - 148.7ms/batch - loss: 1.13172 - diff: 18.11mlTrain batch 26/32 - 161.3ms/batch - loss: 1.13545 - diff: 18.17mlTrain batch 27/32 - 183.7ms/batch - loss: 1.11685 - diff: 17.87mlTrain batch 28/32 - 143.0ms/batch - loss: 1.13531 - diff: 18.16mlTrain batch 29/32 - 160.2ms/batch - loss: 1.12814 - diff: 18.05mlTrain batch 30/32 - 195.4ms/batch - loss: 1.11415 - diff: 17.83mlTrain batch 31/32 - 180.5ms/batch - loss: 1.11729 - diff: 17.88mlTrain batch 32/32 - 110.7ms/batch - loss: 1.12933 - diff: 17.82mlTrain batch 32/32 - 17.4s 110.7ms/batch - loss: 1.12933 - diff: 17.82ml
Test 1.1s: val_loss: 1.31929 - diff: 20.39ml

Epoch 115: current best loss = 1.22404, at epoch 108
Train batch 1/32 - 133.3ms/batch - loss: 0.79793 - diff: 12.77mlTrain batch 2/32 - 134.9ms/batch - loss: 0.80518 - diff: 12.88mlTrain batch 3/32 - 135.7ms/batch - loss: 0.75327 - diff: 12.05mlTrain batch 4/32 - 108.6ms/batch - loss: 0.81754 - diff: 13.08mlTrain batch 5/32 - 138.7ms/batch - loss: 0.78731 - diff: 12.60mlTrain batch 6/32 - 127.0ms/batch - loss: 0.93800 - diff: 15.01mlTrain batch 7/32 - 123.1ms/batch - loss: 0.93180 - diff: 14.91mlTrain batch 8/32 - 104.4ms/batch - loss: 0.90186 - diff: 14.43mlTrain batch 9/32 - 168.7ms/batch - loss: 0.89071 - diff: 14.25mlTrain batch 10/32 - 156.4ms/batch - loss: 0.87723 - diff: 14.04mlTrain batch 11/32 - 182.9ms/batch - loss: 0.89405 - diff: 14.30mlTrain batch 12/32 - 153.5ms/batch - loss: 0.87337 - diff: 13.97mlTrain batch 13/32 - 183.2ms/batch - loss: 0.88498 - diff: 14.16mlTrain batch 14/32 - 160.2ms/batch - loss: 0.88253 - diff: 14.12mlTrain batch 15/32 - 164.1ms/batch - loss: 0.87267 - diff: 13.96mlTrain batch 16/32 - 155.6ms/batch - loss: 0.92369 - diff: 14.78mlTrain batch 17/32 - 132.5ms/batch - loss: 0.91181 - diff: 14.59mlTrain batch 18/32 - 179.7ms/batch - loss: 0.94826 - diff: 15.17mlTrain batch 19/32 - 154.8ms/batch - loss: 0.92696 - diff: 14.83mlTrain batch 20/32 - 176.5ms/batch - loss: 0.90769 - diff: 14.52mlTrain batch 21/32 - 174.1ms/batch - loss: 0.89548 - diff: 14.33mlTrain batch 22/32 - 121.8ms/batch - loss: 0.88008 - diff: 14.08mlTrain batch 23/32 - 157.5ms/batch - loss: 0.87356 - diff: 13.98mlTrain batch 24/32 - 140.8ms/batch - loss: 0.87281 - diff: 13.97mlTrain batch 25/32 - 172.9ms/batch - loss: 0.89051 - diff: 14.25mlTrain batch 26/32 - 153.6ms/batch - loss: 0.92323 - diff: 14.77mlTrain batch 27/32 - 162.4ms/batch - loss: 0.91767 - diff: 14.68mlTrain batch 28/32 - 191.6ms/batch - loss: 0.92075 - diff: 14.73mlTrain batch 29/32 - 173.8ms/batch - loss: 0.95186 - diff: 15.23mlTrain batch 30/32 - 190.2ms/batch - loss: 0.94922 - diff: 15.19mlTrain batch 31/32 - 127.7ms/batch - loss: 0.94278 - diff: 15.08mlTrain batch 32/32 - 113.6ms/batch - loss: 0.96255 - diff: 15.07mlTrain batch 32/32 - 15.8s 113.6ms/batch - loss: 0.96255 - diff: 15.07ml
Test 1.4s: val_loss: 1.29465 - diff: 20.31ml

Epoch 116: current best loss = 1.22404, at epoch 108
Train batch 1/32 - 183.5ms/batch - loss: 0.82846 - diff: 13.26mlTrain batch 2/32 - 202.2ms/batch - loss: 0.80981 - diff: 12.96mlTrain batch 3/32 - 173.0ms/batch - loss: 0.78433 - diff: 12.55mlTrain batch 4/32 - 180.2ms/batch - loss: 0.81292 - diff: 13.01mlTrain batch 5/32 - 190.1ms/batch - loss: 0.77301 - diff: 12.37mlTrain batch 6/32 - 198.7ms/batch - loss: 0.77711 - diff: 12.43mlTrain batch 7/32 - 158.2ms/batch - loss: 0.79541 - diff: 12.73mlTrain batch 8/32 - 174.2ms/batch - loss: 0.81969 - diff: 13.11mlTrain batch 9/32 - 180.4ms/batch - loss: 0.81009 - diff: 12.96mlTrain batch 10/32 - 152.7ms/batch - loss: 0.91310 - diff: 14.61mlTrain batch 11/32 - 167.1ms/batch - loss: 0.99428 - diff: 15.91mlTrain batch 12/32 - 154.4ms/batch - loss: 1.02318 - diff: 16.37mlTrain batch 13/32 - 147.7ms/batch - loss: 0.99448 - diff: 15.91mlTrain batch 14/32 - 153.5ms/batch - loss: 1.04772 - diff: 16.76mlTrain batch 15/32 - 169.9ms/batch - loss: 1.03761 - diff: 16.60mlTrain batch 16/32 - 171.9ms/batch - loss: 1.08043 - diff: 17.29mlTrain batch 17/32 - 151.4ms/batch - loss: 1.14459 - diff: 18.31mlTrain batch 18/32 - 139.3ms/batch - loss: 1.13044 - diff: 18.09mlTrain batch 19/32 - 143.6ms/batch - loss: 1.11067 - diff: 17.77mlTrain batch 20/32 - 181.2ms/batch - loss: 1.08041 - diff: 17.29mlTrain batch 21/32 - 131.1ms/batch - loss: 1.08680 - diff: 17.39mlTrain batch 22/32 - 128.0ms/batch - loss: 1.06788 - diff: 17.09mlTrain batch 23/32 - 163.1ms/batch - loss: 1.06479 - diff: 17.04mlTrain batch 24/32 - 240.9ms/batch - loss: 1.05569 - diff: 16.89mlTrain batch 25/32 - 186.3ms/batch - loss: 1.04116 - diff: 16.66mlTrain batch 26/32 - 219.5ms/batch - loss: 1.03313 - diff: 16.53mlTrain batch 27/32 - 112.1ms/batch - loss: 1.02264 - diff: 16.36mlTrain batch 28/32 - 141.9ms/batch - loss: 1.06133 - diff: 16.98mlTrain batch 29/32 - 113.9ms/batch - loss: 1.04748 - diff: 16.76mlTrain batch 30/32 - 121.5ms/batch - loss: 1.04533 - diff: 16.73mlTrain batch 31/32 - 139.9ms/batch - loss: 1.04720 - diff: 16.76mlTrain batch 32/32 - 163.8ms/batch - loss: 1.10573 - diff: 16.89mlTrain batch 32/32 - 17.5s 163.8ms/batch - loss: 1.10573 - diff: 16.89ml
Test 1.2s: val_loss: 1.30662 - diff: 19.51ml

Epoch 117: current best loss = 1.22404, at epoch 108
Train batch 1/32 - 215.3ms/batch - loss: 0.63295 - diff: 10.13mlTrain batch 2/32 - 169.2ms/batch - loss: 0.79377 - diff: 12.70mlTrain batch 3/32 - 153.5ms/batch - loss: 0.66215 - diff: 10.59mlTrain batch 4/32 - 166.0ms/batch - loss: 0.65133 - diff: 10.42mlTrain batch 5/32 - 136.4ms/batch - loss: 0.71636 - diff: 11.46mlTrain batch 6/32 - 164.8ms/batch - loss: 0.95321 - diff: 15.25mlTrain batch 7/32 - 188.1ms/batch - loss: 1.09534 - diff: 17.53mlTrain batch 8/32 - 176.2ms/batch - loss: 1.10239 - diff: 17.64mlTrain batch 9/32 - 179.7ms/batch - loss: 1.09520 - diff: 17.52mlTrain batch 10/32 - 159.3ms/batch - loss: 1.24453 - diff: 19.91mlTrain batch 11/32 - 157.7ms/batch - loss: 1.20484 - diff: 19.28mlTrain batch 12/32 - 172.3ms/batch - loss: 1.17509 - diff: 18.80mlTrain batch 13/32 - 169.9ms/batch - loss: 1.14412 - diff: 18.31mlTrain batch 14/32 - 171.3ms/batch - loss: 1.15532 - diff: 18.49mlTrain batch 15/32 - 155.9ms/batch - loss: 1.14058 - diff: 18.25mlTrain batch 16/32 - 124.9ms/batch - loss: 1.11787 - diff: 17.89mlTrain batch 17/32 - 151.1ms/batch - loss: 1.14508 - diff: 18.32mlTrain batch 18/32 - 158.6ms/batch - loss: 1.13205 - diff: 18.11mlTrain batch 19/32 - 153.1ms/batch - loss: 1.10397 - diff: 17.66mlTrain batch 20/32 - 152.0ms/batch - loss: 1.09830 - diff: 17.57mlTrain batch 21/32 - 184.8ms/batch - loss: 1.09148 - diff: 17.46mlTrain batch 22/32 - 159.4ms/batch - loss: 1.08398 - diff: 17.34mlTrain batch 23/32 - 116.0ms/batch - loss: 1.07401 - diff: 17.18mlTrain batch 24/32 - 152.0ms/batch - loss: 1.07898 - diff: 17.26mlTrain batch 25/32 - 145.9ms/batch - loss: 1.08581 - diff: 17.37mlTrain batch 26/32 - 166.6ms/batch - loss: 1.08309 - diff: 17.33mlTrain batch 27/32 - 138.8ms/batch - loss: 1.07344 - diff: 17.18mlTrain batch 28/32 - 142.1ms/batch - loss: 1.06101 - diff: 16.98mlTrain batch 29/32 - 148.7ms/batch - loss: 1.04897 - diff: 16.78mlTrain batch 30/32 - 149.4ms/batch - loss: 1.05545 - diff: 16.89mlTrain batch 31/32 - 117.7ms/batch - loss: 1.05869 - diff: 16.94mlTrain batch 32/32 - 113.4ms/batch - loss: 1.08487 - diff: 16.94mlTrain batch 32/32 - 17.1s 113.4ms/batch - loss: 1.08487 - diff: 16.94ml
Test 1.2s: val_loss: 1.31071 - diff: 19.85ml

Epoch 118: current best loss = 1.22404, at epoch 108
Train batch 1/32 - 184.0ms/batch - loss: 1.09199 - diff: 17.47mlTrain batch 2/32 - 201.1ms/batch - loss: 0.91345 - diff: 14.62mlTrain batch 3/32 - 202.0ms/batch - loss: 0.89603 - diff: 14.34mlTrain batch 4/32 - 166.4ms/batch - loss: 0.95625 - diff: 15.30mlTrain batch 5/32 - 132.7ms/batch - loss: 1.05962 - diff: 16.95mlTrain batch 6/32 - 174.5ms/batch - loss: 1.04249 - diff: 16.68mlTrain batch 7/32 - 156.6ms/batch - loss: 0.99338 - diff: 15.89mlTrain batch 8/32 - 163.6ms/batch - loss: 1.06832 - diff: 17.09mlTrain batch 9/32 - 156.4ms/batch - loss: 1.08906 - diff: 17.43mlTrain batch 10/32 - 174.3ms/batch - loss: 1.05485 - diff: 16.88mlTrain batch 11/32 - 161.9ms/batch - loss: 1.03037 - diff: 16.49mlTrain batch 12/32 - 168.8ms/batch - loss: 0.99110 - diff: 15.86mlTrain batch 13/32 - 183.8ms/batch - loss: 0.97340 - diff: 15.57mlTrain batch 14/32 - 177.0ms/batch - loss: 0.94850 - diff: 15.18mlTrain batch 15/32 - 160.3ms/batch - loss: 0.91739 - diff: 14.68mlTrain batch 16/32 - 154.3ms/batch - loss: 0.90199 - diff: 14.43mlTrain batch 17/32 - 136.8ms/batch - loss: 0.89655 - diff: 14.34mlTrain batch 18/32 - 136.9ms/batch - loss: 0.89678 - diff: 14.35mlTrain batch 19/32 - 177.5ms/batch - loss: 0.89563 - diff: 14.33mlTrain batch 20/32 - 165.7ms/batch - loss: 0.88433 - diff: 14.15mlTrain batch 21/32 - 174.6ms/batch - loss: 0.87343 - diff: 13.97mlTrain batch 22/32 - 154.8ms/batch - loss: 0.93368 - diff: 14.94mlTrain batch 23/32 - 165.2ms/batch - loss: 0.94558 - diff: 15.13mlTrain batch 24/32 - 206.9ms/batch - loss: 0.96937 - diff: 15.51mlTrain batch 25/32 - 149.0ms/batch - loss: 0.95832 - diff: 15.33mlTrain batch 26/32 - 150.8ms/batch - loss: 0.98206 - diff: 15.71mlTrain batch 27/32 - 143.6ms/batch - loss: 1.00336 - diff: 16.05mlTrain batch 28/32 - 105.9ms/batch - loss: 1.00440 - diff: 16.07mlTrain batch 29/32 - 156.7ms/batch - loss: 1.00088 - diff: 16.01mlTrain batch 30/32 - 170.5ms/batch - loss: 0.99930 - diff: 15.99mlTrain batch 31/32 - 142.0ms/batch - loss: 0.99618 - diff: 15.94mlTrain batch 32/32 - 184.2ms/batch - loss: 1.01560 - diff: 15.92mlTrain batch 32/32 - 16.2s 184.2ms/batch - loss: 1.01560 - diff: 15.92ml
Test 1.2s: val_loss: 1.31006 - diff: 20.27ml

Epoch 119: current best loss = 1.22404, at epoch 108
Train batch 1/32 - 129.5ms/batch - loss: 1.72131 - diff: 27.54mlTrain batch 2/32 - 187.5ms/batch - loss: 1.37615 - diff: 22.02mlTrain batch 3/32 - 217.7ms/batch - loss: 1.18438 - diff: 18.95mlTrain batch 4/32 - 152.5ms/batch - loss: 1.11256 - diff: 17.80mlTrain batch 5/32 - 157.3ms/batch - loss: 1.06728 - diff: 17.08mlTrain batch 6/32 - 152.0ms/batch - loss: 1.14308 - diff: 18.29mlTrain batch 7/32 - 133.3ms/batch - loss: 1.11007 - diff: 17.76mlTrain batch 8/32 - 164.2ms/batch - loss: 1.10207 - diff: 17.63mlTrain batch 9/32 - 161.6ms/batch - loss: 1.08810 - diff: 17.41mlTrain batch 10/32 - 194.6ms/batch - loss: 1.06363 - diff: 17.02mlTrain batch 11/32 - 166.4ms/batch - loss: 1.01794 - diff: 16.29mlTrain batch 12/32 - 191.1ms/batch - loss: 1.03769 - diff: 16.60mlTrain batch 13/32 - 135.0ms/batch - loss: 1.07925 - diff: 17.27mlTrain batch 14/32 - 150.3ms/batch - loss: 1.11803 - diff: 17.89mlTrain batch 15/32 - 179.9ms/batch - loss: 1.08796 - diff: 17.41mlTrain batch 16/32 - 166.2ms/batch - loss: 1.11836 - diff: 17.89mlTrain batch 17/32 - 157.3ms/batch - loss: 1.10071 - diff: 17.61mlTrain batch 18/32 - 184.8ms/batch - loss: 1.08235 - diff: 17.32mlTrain batch 19/32 - 156.9ms/batch - loss: 1.06458 - diff: 17.03mlTrain batch 20/32 - 145.8ms/batch - loss: 1.06451 - diff: 17.03mlTrain batch 21/32 - 165.9ms/batch - loss: 1.08167 - diff: 17.31mlTrain batch 22/32 - 166.5ms/batch - loss: 1.08470 - diff: 17.36mlTrain batch 23/32 - 129.4ms/batch - loss: 1.07006 - diff: 17.12mlTrain batch 24/32 - 136.4ms/batch - loss: 1.06394 - diff: 17.02mlTrain batch 25/32 - 145.5ms/batch - loss: 1.12021 - diff: 17.92mlTrain batch 26/32 - 144.4ms/batch - loss: 1.11305 - diff: 17.81mlTrain batch 27/32 - 170.0ms/batch - loss: 1.11055 - diff: 17.77mlTrain batch 28/32 - 169.2ms/batch - loss: 1.10156 - diff: 17.62mlTrain batch 29/32 - 142.1ms/batch - loss: 1.15618 - diff: 18.50mlTrain batch 30/32 - 132.4ms/batch - loss: 1.15129 - diff: 18.42mlTrain batch 31/32 - 127.7ms/batch - loss: 1.13598 - diff: 18.18mlTrain batch 32/32 - 138.0ms/batch - loss: 1.14751 - diff: 18.11mlTrain batch 32/32 - 17.5s 138.0ms/batch - loss: 1.14751 - diff: 18.11ml
Test 1.4s: val_loss: 1.30406 - diff: 20.18ml
Epoch   120: reducing learning rate of group 0 to 6.2500e-05.

Epoch 120: current best loss = 1.22404, at epoch 108
Train batch 1/32 - 168.3ms/batch - loss: 0.91422 - diff: 14.63mlTrain batch 2/32 - 165.3ms/batch - loss: 0.68150 - diff: 10.90mlTrain batch 3/32 - 153.7ms/batch - loss: 0.78156 - diff: 12.50mlTrain batch 4/32 - 146.4ms/batch - loss: 0.80285 - diff: 12.85mlTrain batch 5/32 - 183.6ms/batch - loss: 0.78805 - diff: 12.61mlTrain batch 6/32 - 171.8ms/batch - loss: 0.77087 - diff: 12.33mlTrain batch 7/32 - 150.1ms/batch - loss: 0.77974 - diff: 12.48mlTrain batch 8/32 - 135.0ms/batch - loss: 0.85186 - diff: 13.63mlTrain batch 9/32 - 170.3ms/batch - loss: 0.84014 - diff: 13.44mlTrain batch 10/32 - 139.6ms/batch - loss: 0.93919 - diff: 15.03mlTrain batch 11/32 - 166.8ms/batch - loss: 0.90940 - diff: 14.55mlTrain batch 12/32 - 147.5ms/batch - loss: 0.90495 - diff: 14.48mlTrain batch 13/32 - 174.0ms/batch - loss: 0.91385 - diff: 14.62mlTrain batch 14/32 - 146.3ms/batch - loss: 0.93734 - diff: 15.00mlTrain batch 15/32 - 133.2ms/batch - loss: 0.95269 - diff: 15.24mlTrain batch 16/32 - 146.2ms/batch - loss: 0.98751 - diff: 15.80mlTrain batch 17/32 - 182.9ms/batch - loss: 0.96190 - diff: 15.39mlTrain batch 18/32 - 135.2ms/batch - loss: 0.95793 - diff: 15.33mlTrain batch 19/32 - 160.3ms/batch - loss: 0.94039 - diff: 15.05mlTrain batch 20/32 - 160.7ms/batch - loss: 0.99468 - diff: 15.91mlTrain batch 21/32 - 142.5ms/batch - loss: 0.97926 - diff: 15.67mlTrain batch 22/32 - 169.0ms/batch - loss: 0.99360 - diff: 15.90mlTrain batch 23/32 - 157.5ms/batch - loss: 0.99051 - diff: 15.85mlTrain batch 24/32 - 161.8ms/batch - loss: 0.97222 - diff: 15.56mlTrain batch 25/32 - 151.7ms/batch - loss: 0.95541 - diff: 15.29mlTrain batch 26/32 - 167.9ms/batch - loss: 0.95050 - diff: 15.21mlTrain batch 27/32 - 154.6ms/batch - loss: 0.94117 - diff: 15.06mlTrain batch 28/32 - 171.2ms/batch - loss: 0.97302 - diff: 15.57mlTrain batch 29/32 - 124.0ms/batch - loss: 0.96182 - diff: 15.39mlTrain batch 30/32 - 154.9ms/batch - loss: 0.97068 - diff: 15.53mlTrain batch 31/32 - 140.5ms/batch - loss: 0.98150 - diff: 15.70mlTrain batch 32/32 - 112.6ms/batch - loss: 1.02256 - diff: 15.77mlTrain batch 32/32 - 15.6s 112.6ms/batch - loss: 1.02256 - diff: 15.77ml
Test 1.2s: val_loss: 1.28986 - diff: 20.12ml

Epoch 121: current best loss = 1.22404, at epoch 108
Train batch 1/32 - 188.9ms/batch - loss: 0.91386 - diff: 14.62mlTrain batch 2/32 - 123.3ms/batch - loss: 1.50504 - diff: 24.08mlTrain batch 3/32 - 155.1ms/batch - loss: 1.29640 - diff: 20.74mlTrain batch 4/32 - 161.4ms/batch - loss: 1.21630 - diff: 19.46mlTrain batch 5/32 - 166.0ms/batch - loss: 1.19016 - diff: 19.04mlTrain batch 6/32 - 183.0ms/batch - loss: 1.15367 - diff: 18.46mlTrain batch 7/32 - 192.5ms/batch - loss: 1.08988 - diff: 17.44mlTrain batch 8/32 - 106.1ms/batch - loss: 1.07506 - diff: 17.20mlTrain batch 9/32 - 141.7ms/batch - loss: 1.04254 - diff: 16.68mlTrain batch 10/32 - 125.4ms/batch - loss: 1.16434 - diff: 18.63mlTrain batch 11/32 - 178.6ms/batch - loss: 1.19596 - diff: 19.14mlTrain batch 12/32 - 181.7ms/batch - loss: 1.15041 - diff: 18.41mlTrain batch 13/32 - 152.9ms/batch - loss: 1.12790 - diff: 18.05mlTrain batch 14/32 - 219.7ms/batch - loss: 1.12266 - diff: 17.96mlTrain batch 15/32 - 196.9ms/batch - loss: 1.09387 - diff: 17.50mlTrain batch 16/32 - 111.3ms/batch - loss: 1.07195 - diff: 17.15mlTrain batch 17/32 - 140.2ms/batch - loss: 1.17570 - diff: 18.81mlTrain batch 18/32 - 180.4ms/batch - loss: 1.14466 - diff: 18.31mlTrain batch 19/32 - 141.8ms/batch - loss: 1.19673 - diff: 19.15mlTrain batch 20/32 - 176.1ms/batch - loss: 1.23653 - diff: 19.78mlTrain batch 21/32 - 153.8ms/batch - loss: 1.20823 - diff: 19.33mlTrain batch 22/32 - 171.9ms/batch - loss: 1.18292 - diff: 18.93mlTrain batch 23/32 - 158.1ms/batch - loss: 1.15458 - diff: 18.47mlTrain batch 24/32 - 155.5ms/batch - loss: 1.13468 - diff: 18.15mlTrain batch 25/32 - 179.6ms/batch - loss: 1.17541 - diff: 18.81mlTrain batch 26/32 - 191.0ms/batch - loss: 1.15554 - diff: 18.49mlTrain batch 27/32 - 151.3ms/batch - loss: 1.14435 - diff: 18.31mlTrain batch 28/32 - 146.2ms/batch - loss: 1.13234 - diff: 18.12mlTrain batch 29/32 - 148.5ms/batch - loss: 1.13498 - diff: 18.16mlTrain batch 30/32 - 166.2ms/batch - loss: 1.14378 - diff: 18.30mlTrain batch 31/32 - 154.9ms/batch - loss: 1.13307 - diff: 18.13mlTrain batch 32/32 - 157.4ms/batch - loss: 1.15410 - diff: 18.10mlTrain batch 32/32 - 16.8s 157.4ms/batch - loss: 1.15410 - diff: 18.10ml
Test 1.3s: val_loss: 1.32053 - diff: 19.92ml

Epoch 122: current best loss = 1.22404, at epoch 108
Train batch 1/32 - 154.8ms/batch - loss: 0.93995 - diff: 15.04mlTrain batch 2/32 - 146.4ms/batch - loss: 0.78375 - diff: 12.54mlTrain batch 3/32 - 138.1ms/batch - loss: 0.82941 - diff: 13.27mlTrain batch 4/32 - 158.8ms/batch - loss: 0.86913 - diff: 13.91mlTrain batch 5/32 - 146.9ms/batch - loss: 0.97026 - diff: 15.52mlTrain batch 6/32 - 173.0ms/batch - loss: 0.94457 - diff: 15.11mlTrain batch 7/32 - 167.3ms/batch - loss: 0.92454 - diff: 14.79mlTrain batch 8/32 - 182.7ms/batch - loss: 0.85763 - diff: 13.72mlTrain batch 9/32 - 146.5ms/batch - loss: 0.84575 - diff: 13.53mlTrain batch 10/32 - 146.2ms/batch - loss: 0.84278 - diff: 13.48mlTrain batch 11/32 - 168.6ms/batch - loss: 0.86438 - diff: 13.83mlTrain batch 12/32 - 165.5ms/batch - loss: 0.84590 - diff: 13.53mlTrain batch 13/32 - 162.3ms/batch - loss: 0.84124 - diff: 13.46mlTrain batch 14/32 - 182.0ms/batch - loss: 0.84699 - diff: 13.55mlTrain batch 15/32 - 184.9ms/batch - loss: 0.88219 - diff: 14.12mlTrain batch 16/32 - 210.0ms/batch - loss: 0.87972 - diff: 14.08mlTrain batch 17/32 - 186.8ms/batch - loss: 0.90207 - diff: 14.43mlTrain batch 18/32 - 162.0ms/batch - loss: 0.89642 - diff: 14.34mlTrain batch 19/32 - 189.8ms/batch - loss: 0.89324 - diff: 14.29mlTrain batch 20/32 - 170.1ms/batch - loss: 0.89008 - diff: 14.24mlTrain batch 21/32 - 165.8ms/batch - loss: 0.89430 - diff: 14.31mlTrain batch 22/32 - 171.5ms/batch - loss: 0.90998 - diff: 14.56mlTrain batch 23/32 - 195.8ms/batch - loss: 0.89855 - diff: 14.38mlTrain batch 24/32 - 176.8ms/batch - loss: 0.93729 - diff: 15.00mlTrain batch 25/32 - 178.6ms/batch - loss: 0.92877 - diff: 14.86mlTrain batch 26/32 - 155.6ms/batch - loss: 0.91752 - diff: 14.68mlTrain batch 27/32 - 163.3ms/batch - loss: 0.92416 - diff: 14.79mlTrain batch 28/32 - 162.6ms/batch - loss: 0.94137 - diff: 15.06mlTrain batch 29/32 - 152.1ms/batch - loss: 0.93601 - diff: 14.98mlTrain batch 30/32 - 144.7ms/batch - loss: 0.92144 - diff: 14.74mlTrain batch 31/32 - 127.2ms/batch - loss: 0.91282 - diff: 14.61mlTrain batch 32/32 - 103.4ms/batch - loss: 1.00148 - diff: 14.87mlTrain batch 32/32 - 17.9s 103.4ms/batch - loss: 1.00148 - diff: 14.87ml
Test 1.1s: val_loss: 1.32530 - diff: 20.31ml

Epoch 123: current best loss = 1.22404, at epoch 108
Train batch 1/32 - 204.8ms/batch - loss: 0.78166 - diff: 12.51mlTrain batch 2/32 - 178.1ms/batch - loss: 0.75304 - diff: 12.05mlTrain batch 3/32 - 176.8ms/batch - loss: 0.81915 - diff: 13.11mlTrain batch 4/32 - 162.6ms/batch - loss: 0.80382 - diff: 12.86mlTrain batch 5/32 - 155.9ms/batch - loss: 0.94164 - diff: 15.07mlTrain batch 6/32 - 208.1ms/batch - loss: 1.08487 - diff: 17.36mlTrain batch 7/32 - 160.4ms/batch - loss: 1.05836 - diff: 16.93mlTrain batch 8/32 - 162.6ms/batch - loss: 1.01712 - diff: 16.27mlTrain batch 9/32 - 151.0ms/batch - loss: 0.97398 - diff: 15.58mlTrain batch 10/32 - 126.6ms/batch - loss: 1.05833 - diff: 16.93mlTrain batch 11/32 - 148.0ms/batch - loss: 1.12263 - diff: 17.96mlTrain batch 12/32 - 150.2ms/batch - loss: 1.14021 - diff: 18.24mlTrain batch 13/32 - 125.4ms/batch - loss: 1.12849 - diff: 18.06mlTrain batch 14/32 - 123.9ms/batch - loss: 1.10988 - diff: 17.76mlTrain batch 15/32 - 138.6ms/batch - loss: 1.19686 - diff: 19.15mlTrain batch 16/32 - 189.1ms/batch - loss: 1.16795 - diff: 18.69mlTrain batch 17/32 - 156.2ms/batch - loss: 1.14365 - diff: 18.30mlTrain batch 18/32 - 185.1ms/batch - loss: 1.15842 - diff: 18.53mlTrain batch 19/32 - 150.1ms/batch - loss: 1.16428 - diff: 18.63mlTrain batch 20/32 - 170.1ms/batch - loss: 1.15566 - diff: 18.49mlTrain batch 21/32 - 162.4ms/batch - loss: 1.14227 - diff: 18.28mlTrain batch 22/32 - 153.0ms/batch - loss: 1.13799 - diff: 18.21mlTrain batch 23/32 - 108.0ms/batch - loss: 1.12576 - diff: 18.01mlTrain batch 24/32 - 161.8ms/batch - loss: 1.10687 - diff: 17.71mlTrain batch 25/32 - 141.2ms/batch - loss: 1.10774 - diff: 17.72mlTrain batch 26/32 - 171.0ms/batch - loss: 1.09654 - diff: 17.54mlTrain batch 27/32 - 160.9ms/batch - loss: 1.12546 - diff: 18.01mlTrain batch 28/32 - 147.2ms/batch - loss: 1.10167 - diff: 17.63mlTrain batch 29/32 - 106.9ms/batch - loss: 1.09200 - diff: 17.47mlTrain batch 30/32 - 140.5ms/batch - loss: 1.08609 - diff: 17.38mlTrain batch 31/32 - 185.4ms/batch - loss: 1.07295 - diff: 17.17mlTrain batch 32/32 - 206.6ms/batch - loss: 1.12853 - diff: 17.29mlTrain batch 32/32 - 16.4s 206.6ms/batch - loss: 1.12853 - diff: 17.29ml
Test 1.2s: val_loss: 1.27589 - diff: 19.85ml

Epoch 124: current best loss = 1.22404, at epoch 108
Train batch 1/32 - 179.1ms/batch - loss: 1.07907 - diff: 17.27mlTrain batch 2/32 - 138.9ms/batch - loss: 1.06690 - diff: 17.07mlTrain batch 3/32 - 135.4ms/batch - loss: 0.94934 - diff: 15.19mlTrain batch 4/32 - 146.3ms/batch - loss: 0.92054 - diff: 14.73mlTrain batch 5/32 - 156.8ms/batch - loss: 1.02861 - diff: 16.46mlTrain batch 6/32 - 167.6ms/batch - loss: 1.05626 - diff: 16.90mlTrain batch 7/32 - 133.5ms/batch - loss: 1.03271 - diff: 16.52mlTrain batch 8/32 - 108.2ms/batch - loss: 1.00648 - diff: 16.10mlTrain batch 9/32 - 183.2ms/batch - loss: 0.98103 - diff: 15.70mlTrain batch 10/32 - 163.9ms/batch - loss: 0.95155 - diff: 15.22mlTrain batch 11/32 - 182.3ms/batch - loss: 0.96981 - diff: 15.52mlTrain batch 12/32 - 146.1ms/batch - loss: 1.02610 - diff: 16.42mlTrain batch 13/32 - 174.3ms/batch - loss: 1.00314 - diff: 16.05mlTrain batch 14/32 - 135.7ms/batch - loss: 0.99226 - diff: 15.88mlTrain batch 15/32 - 173.3ms/batch - loss: 1.02066 - diff: 16.33mlTrain batch 16/32 - 164.2ms/batch - loss: 1.00045 - diff: 16.01mlTrain batch 17/32 - 167.5ms/batch - loss: 0.98523 - diff: 15.76mlTrain batch 18/32 - 180.5ms/batch - loss: 0.98199 - diff: 15.71mlTrain batch 19/32 - 130.9ms/batch - loss: 0.95337 - diff: 15.25mlTrain batch 20/32 - 104.1ms/batch - loss: 0.93593 - diff: 14.97mlTrain batch 21/32 - 161.6ms/batch - loss: 0.92412 - diff: 14.79mlTrain batch 22/32 - 142.4ms/batch - loss: 0.91320 - diff: 14.61mlTrain batch 23/32 - 112.0ms/batch - loss: 0.90699 - diff: 14.51mlTrain batch 24/32 - 173.1ms/batch - loss: 0.89473 - diff: 14.32mlTrain batch 25/32 - 194.0ms/batch - loss: 0.88390 - diff: 14.14mlTrain batch 26/32 - 170.5ms/batch - loss: 0.88242 - diff: 14.12mlTrain batch 27/32 - 156.4ms/batch - loss: 0.88443 - diff: 14.15mlTrain batch 28/32 - 143.0ms/batch - loss: 0.89697 - diff: 14.35mlTrain batch 29/32 - 175.4ms/batch - loss: 0.89232 - diff: 14.28mlTrain batch 30/32 - 144.1ms/batch - loss: 0.89668 - diff: 14.35mlTrain batch 31/32 - 128.8ms/batch - loss: 0.89632 - diff: 14.34mlTrain batch 32/32 - 122.1ms/batch - loss: 0.99549 - diff: 14.65mlTrain batch 32/32 - 16.8s 122.1ms/batch - loss: 0.99549 - diff: 14.65ml
Test 1.2s: val_loss: 1.27847 - diff: 19.41ml

Epoch 125: current best loss = 1.22404, at epoch 108
Train batch 1/32 - 181.6ms/batch - loss: 1.14789 - diff: 18.37mlTrain batch 2/32 - 164.3ms/batch - loss: 1.01278 - diff: 16.20mlTrain batch 3/32 - 162.9ms/batch - loss: 1.08670 - diff: 17.39mlTrain batch 4/32 - 182.9ms/batch - loss: 0.98292 - diff: 15.73mlTrain batch 5/32 - 226.7ms/batch - loss: 0.91193 - diff: 14.59mlTrain batch 6/32 - 190.5ms/batch - loss: 0.91694 - diff: 14.67mlTrain batch 7/32 - 154.0ms/batch - loss: 0.92906 - diff: 14.86mlTrain batch 8/32 - 142.1ms/batch - loss: 0.87646 - diff: 14.02mlTrain batch 9/32 - 163.7ms/batch - loss: 0.84766 - diff: 13.56mlTrain batch 10/32 - 180.9ms/batch - loss: 0.86357 - diff: 13.82mlTrain batch 11/32 - 167.4ms/batch - loss: 0.83726 - diff: 13.40mlTrain batch 12/32 - 199.5ms/batch - loss: 0.82949 - diff: 13.27mlTrain batch 13/32 - 115.9ms/batch - loss: 0.80140 - diff: 12.82mlTrain batch 14/32 - 116.1ms/batch - loss: 0.85973 - diff: 13.76mlTrain batch 15/32 - 176.2ms/batch - loss: 0.86169 - diff: 13.79mlTrain batch 16/32 - 158.3ms/batch - loss: 0.86972 - diff: 13.92mlTrain batch 17/32 - 192.4ms/batch - loss: 0.89414 - diff: 14.31mlTrain batch 18/32 - 217.4ms/batch - loss: 0.91638 - diff: 14.66mlTrain batch 19/32 - 175.8ms/batch - loss: 0.92611 - diff: 14.82mlTrain batch 20/32 - 179.4ms/batch - loss: 0.92151 - diff: 14.74mlTrain batch 21/32 - 191.5ms/batch - loss: 0.98436 - diff: 15.75mlTrain batch 22/32 - 158.3ms/batch - loss: 0.98286 - diff: 15.73mlTrain batch 23/32 - 158.1ms/batch - loss: 0.98832 - diff: 15.81mlTrain batch 24/32 - 185.6ms/batch - loss: 0.98593 - diff: 15.77mlTrain batch 25/32 - 148.4ms/batch - loss: 0.97991 - diff: 15.68mlTrain batch 26/32 - 160.5ms/batch - loss: 0.96662 - diff: 15.47mlTrain batch 27/32 - 227.2ms/batch - loss: 0.97350 - diff: 15.58mlTrain batch 28/32 - 129.5ms/batch - loss: 0.96693 - diff: 15.47mlTrain batch 29/32 - 173.9ms/batch - loss: 0.95787 - diff: 15.33mlTrain batch 30/32 - 178.8ms/batch - loss: 0.94921 - diff: 15.19mlTrain batch 31/32 - 125.7ms/batch - loss: 0.95612 - diff: 15.30mlTrain batch 32/32 - 146.1ms/batch - loss: 1.02959 - diff: 15.50mlTrain batch 32/32 - 17.0s 146.1ms/batch - loss: 1.02959 - diff: 15.50ml
Test 1.2s: val_loss: 1.27467 - diff: 19.69ml

Epoch 126: current best loss = 1.22404, at epoch 108
Train batch 1/32 - 151.2ms/batch - loss: 0.81199 - diff: 12.99mlTrain batch 2/32 - 161.7ms/batch - loss: 0.99020 - diff: 15.84mlTrain batch 3/32 - 176.1ms/batch - loss: 0.85977 - diff: 13.76mlTrain batch 4/32 - 154.9ms/batch - loss: 0.83809 - diff: 13.41mlTrain batch 5/32 - 208.0ms/batch - loss: 1.02507 - diff: 16.40mlTrain batch 6/32 - 162.5ms/batch - loss: 1.04959 - diff: 16.79mlTrain batch 7/32 - 166.5ms/batch - loss: 1.06189 - diff: 16.99mlTrain batch 8/32 - 169.7ms/batch - loss: 1.00220 - diff: 16.04mlTrain batch 9/32 - 135.8ms/batch - loss: 0.98653 - diff: 15.78mlTrain batch 10/32 - 156.8ms/batch - loss: 0.99170 - diff: 15.87mlTrain batch 11/32 - 169.3ms/batch - loss: 0.99679 - diff: 15.95mlTrain batch 12/32 - 139.2ms/batch - loss: 0.98056 - diff: 15.69mlTrain batch 13/32 - 182.3ms/batch - loss: 1.01790 - diff: 16.29mlTrain batch 14/32 - 136.8ms/batch - loss: 0.99285 - diff: 15.89mlTrain batch 15/32 - 148.0ms/batch - loss: 1.01282 - diff: 16.21mlTrain batch 16/32 - 106.2ms/batch - loss: 1.01106 - diff: 16.18mlTrain batch 17/32 - 131.2ms/batch - loss: 1.06575 - diff: 17.05mlTrain batch 18/32 - 223.3ms/batch - loss: 1.05012 - diff: 16.80mlTrain batch 19/32 - 140.3ms/batch - loss: 1.04713 - diff: 16.75mlTrain batch 20/32 - 160.8ms/batch - loss: 1.03616 - diff: 16.58mlTrain batch 21/32 - 177.3ms/batch - loss: 1.03791 - diff: 16.61mlTrain batch 22/32 - 112.5ms/batch - loss: 1.03611 - diff: 16.58mlTrain batch 23/32 - 171.1ms/batch - loss: 1.02546 - diff: 16.41mlTrain batch 24/32 - 188.7ms/batch - loss: 1.00651 - diff: 16.10mlTrain batch 25/32 - 182.0ms/batch - loss: 1.00747 - diff: 16.12mlTrain batch 26/32 - 120.5ms/batch - loss: 0.99158 - diff: 15.87mlTrain batch 27/32 - 210.2ms/batch - loss: 0.98243 - diff: 15.72mlTrain batch 28/32 - 114.3ms/batch - loss: 0.96344 - diff: 15.42mlTrain batch 29/32 - 206.5ms/batch - loss: 0.97427 - diff: 15.59mlTrain batch 30/32 - 162.7ms/batch - loss: 0.97091 - diff: 15.53mlTrain batch 31/32 - 134.8ms/batch - loss: 0.96386 - diff: 15.42mlTrain batch 32/32 - 111.2ms/batch - loss: 0.98367 - diff: 15.41mlTrain batch 32/32 - 16.8s 111.2ms/batch - loss: 0.98367 - diff: 15.41ml
Test 1.3s: val_loss: 1.27667 - diff: 19.67ml

Epoch 127: current best loss = 1.22404, at epoch 108
Train batch 1/32 - 138.4ms/batch - loss: 0.50049 - diff: 8.01mlTrain batch 2/32 - 114.1ms/batch - loss: 0.57230 - diff: 9.16mlTrain batch 3/32 - 184.3ms/batch - loss: 0.63852 - diff: 10.22mlTrain batch 4/32 - 106.6ms/batch - loss: 0.63529 - diff: 10.16mlTrain batch 5/32 - 170.2ms/batch - loss: 0.74728 - diff: 11.96mlTrain batch 6/32 - 164.7ms/batch - loss: 0.84718 - diff: 13.55mlTrain batch 7/32 - 123.6ms/batch - loss: 0.83760 - diff: 13.40mlTrain batch 8/32 - 103.7ms/batch - loss: 0.78205 - diff: 12.51mlTrain batch 9/32 - 152.4ms/batch - loss: 0.80601 - diff: 12.90mlTrain batch 10/32 - 185.8ms/batch - loss: 0.82408 - diff: 13.19mlTrain batch 11/32 - 149.8ms/batch - loss: 0.89873 - diff: 14.38mlTrain batch 12/32 - 183.3ms/batch - loss: 0.86301 - diff: 13.81mlTrain batch 13/32 - 150.0ms/batch - loss: 0.94962 - diff: 15.19mlTrain batch 14/32 - 117.0ms/batch - loss: 0.93479 - diff: 14.96mlTrain batch 15/32 - 161.2ms/batch - loss: 0.93071 - diff: 14.89mlTrain batch 16/32 - 219.7ms/batch - loss: 0.92938 - diff: 14.87mlTrain batch 17/32 - 196.0ms/batch - loss: 0.91412 - diff: 14.63mlTrain batch 18/32 - 209.4ms/batch - loss: 0.97536 - diff: 15.61mlTrain batch 19/32 - 155.9ms/batch - loss: 0.98307 - diff: 15.73mlTrain batch 20/32 - 150.1ms/batch - loss: 0.96244 - diff: 15.40mlTrain batch 21/32 - 173.8ms/batch - loss: 0.95203 - diff: 15.23mlTrain batch 22/32 - 226.8ms/batch - loss: 0.93918 - diff: 15.03mlTrain batch 23/32 - 177.8ms/batch - loss: 0.93366 - diff: 14.94mlTrain batch 24/32 - 200.0ms/batch - loss: 0.91930 - diff: 14.71mlTrain batch 25/32 - 163.9ms/batch - loss: 0.94573 - diff: 15.13mlTrain batch 26/32 - 179.9ms/batch - loss: 0.94136 - diff: 15.06mlTrain batch 27/32 - 181.2ms/batch - loss: 0.93594 - diff: 14.98mlTrain batch 28/32 - 167.5ms/batch - loss: 0.92727 - diff: 14.84mlTrain batch 29/32 - 164.6ms/batch - loss: 0.93132 - diff: 14.90mlTrain batch 30/32 - 153.7ms/batch - loss: 0.92092 - diff: 14.73mlTrain batch 31/32 - 153.1ms/batch - loss: 0.91906 - diff: 14.70mlTrain batch 32/32 - 107.8ms/batch - loss: 0.95352 - diff: 14.75mlTrain batch 32/32 - 18.0s 107.8ms/batch - loss: 0.95352 - diff: 14.75ml
Test 1.3s: val_loss: 1.29666 - diff: 19.84ml

Epoch 128: current best loss = 1.22404, at epoch 108
Train batch 1/32 - 173.2ms/batch - loss: 1.08165 - diff: 17.31mlTrain batch 2/32 - 132.4ms/batch - loss: 0.89391 - diff: 14.30mlTrain batch 3/32 - 130.3ms/batch - loss: 1.51067 - diff: 24.17mlTrain batch 4/32 - 149.8ms/batch - loss: 1.39926 - diff: 22.39mlTrain batch 5/32 - 185.0ms/batch - loss: 1.23880 - diff: 19.82mlTrain batch 6/32 - 167.3ms/batch - loss: 1.30544 - diff: 20.89mlTrain batch 7/32 - 149.8ms/batch - loss: 1.20383 - diff: 19.26mlTrain batch 8/32 - 110.3ms/batch - loss: 1.14371 - diff: 18.30mlTrain batch 9/32 - 153.2ms/batch - loss: 1.14739 - diff: 18.36mlTrain batch 10/32 - 177.0ms/batch - loss: 1.13291 - diff: 18.13mlTrain batch 11/32 - 165.7ms/batch - loss: 1.10839 - diff: 17.73mlTrain batch 12/32 - 134.3ms/batch - loss: 1.11357 - diff: 17.82mlTrain batch 13/32 - 156.5ms/batch - loss: 1.11667 - diff: 17.87mlTrain batch 14/32 - 118.1ms/batch - loss: 1.09768 - diff: 17.56mlTrain batch 15/32 - 168.5ms/batch - loss: 1.08825 - diff: 17.41mlTrain batch 16/32 - 140.5ms/batch - loss: 1.05456 - diff: 16.87mlTrain batch 17/32 - 111.7ms/batch - loss: 1.04287 - diff: 16.69mlTrain batch 18/32 - 149.3ms/batch - loss: 1.02648 - diff: 16.42mlTrain batch 19/32 - 163.5ms/batch - loss: 1.02427 - diff: 16.39mlTrain batch 20/32 - 178.2ms/batch - loss: 1.07522 - diff: 17.20mlTrain batch 21/32 - 169.8ms/batch - loss: 1.11299 - diff: 17.81mlTrain batch 22/32 - 165.6ms/batch - loss: 1.08254 - diff: 17.32mlTrain batch 23/32 - 179.5ms/batch - loss: 1.07168 - diff: 17.15mlTrain batch 24/32 - 148.3ms/batch - loss: 1.07262 - diff: 17.16mlTrain batch 25/32 - 136.1ms/batch - loss: 1.06590 - diff: 17.05mlTrain batch 26/32 - 129.0ms/batch - loss: 1.05006 - diff: 16.80mlTrain batch 27/32 - 200.1ms/batch - loss: 1.04504 - diff: 16.72mlTrain batch 28/32 - 167.7ms/batch - loss: 1.02598 - diff: 16.42mlTrain batch 29/32 - 111.6ms/batch - loss: 1.02592 - diff: 16.41mlTrain batch 30/32 - 110.5ms/batch - loss: 1.01523 - diff: 16.24mlTrain batch 31/32 - 130.0ms/batch - loss: 1.01778 - diff: 16.28mlTrain batch 32/32 - 138.5ms/batch - loss: 1.03186 - diff: 16.24mlTrain batch 32/32 - 16.7s 138.5ms/batch - loss: 1.03186 - diff: 16.24ml
Test 1.3s: val_loss: 1.30757 - diff: 19.62ml

Epoch 129: current best loss = 1.22404, at epoch 108
Train batch 1/32 - 226.1ms/batch - loss: 0.72905 - diff: 11.66mlTrain batch 2/32 - 202.2ms/batch - loss: 1.01616 - diff: 16.26mlTrain batch 3/32 - 141.7ms/batch - loss: 0.87203 - diff: 13.95mlTrain batch 4/32 - 174.9ms/batch - loss: 0.90437 - diff: 14.47mlTrain batch 5/32 - 234.0ms/batch - loss: 0.95586 - diff: 15.29mlTrain batch 6/32 - 191.6ms/batch - loss: 0.94151 - diff: 15.06mlTrain batch 7/32 - 157.6ms/batch - loss: 0.90260 - diff: 14.44mlTrain batch 8/32 - 144.1ms/batch - loss: 0.85468 - diff: 13.67mlTrain batch 9/32 - 173.7ms/batch - loss: 0.87667 - diff: 14.03mlTrain batch 10/32 - 130.1ms/batch - loss: 0.89105 - diff: 14.26mlTrain batch 11/32 - 179.0ms/batch - loss: 0.90624 - diff: 14.50mlTrain batch 12/32 - 190.1ms/batch - loss: 0.89572 - diff: 14.33mlTrain batch 13/32 - 185.7ms/batch - loss: 0.90346 - diff: 14.46mlTrain batch 14/32 - 179.2ms/batch - loss: 0.88202 - diff: 14.11mlTrain batch 15/32 - 180.6ms/batch - loss: 0.88658 - diff: 14.19mlTrain batch 16/32 - 170.8ms/batch - loss: 0.87440 - diff: 13.99mlTrain batch 17/32 - 179.4ms/batch - loss: 0.97846 - diff: 15.66mlTrain batch 18/32 - 178.2ms/batch - loss: 0.99252 - diff: 15.88mlTrain batch 19/32 - 220.9ms/batch - loss: 0.98084 - diff: 15.69mlTrain batch 20/32 - 176.4ms/batch - loss: 0.98066 - diff: 15.69mlTrain batch 21/32 - 165.7ms/batch - loss: 0.99288 - diff: 15.89mlTrain batch 22/32 - 183.5ms/batch - loss: 0.99058 - diff: 15.85mlTrain batch 23/32 - 166.2ms/batch - loss: 0.97636 - diff: 15.62mlTrain batch 24/32 - 153.1ms/batch - loss: 0.97026 - diff: 15.52mlTrain batch 25/32 - 141.0ms/batch - loss: 0.96503 - diff: 15.44mlTrain batch 26/32 - 183.6ms/batch - loss: 0.94456 - diff: 15.11mlTrain batch 27/32 - 137.0ms/batch - loss: 0.97467 - diff: 15.59mlTrain batch 28/32 - 146.4ms/batch - loss: 0.96406 - diff: 15.42mlTrain batch 29/32 - 152.4ms/batch - loss: 0.95444 - diff: 15.27mlTrain batch 30/32 - 120.1ms/batch - loss: 0.94898 - diff: 15.18mlTrain batch 31/32 - 140.3ms/batch - loss: 0.94427 - diff: 15.11mlTrain batch 32/32 - 183.2ms/batch - loss: 0.96002 - diff: 15.08mlTrain batch 32/32 - 18.3s 183.2ms/batch - loss: 0.96002 - diff: 15.08ml
Test 1.4s: val_loss: 1.30535 - diff: 20.02ml

Epoch 130: current best loss = 1.22404, at epoch 108
Train batch 1/32 - 198.8ms/batch - loss: 0.81043 - diff: 12.97mlTrain batch 2/32 - 204.0ms/batch - loss: 0.73566 - diff: 11.77mlTrain batch 3/32 - 173.1ms/batch - loss: 0.68981 - diff: 11.04mlTrain batch 4/32 - 204.4ms/batch - loss: 0.71031 - diff: 11.37mlTrain batch 5/32 - 177.0ms/batch - loss: 0.85351 - diff: 13.66mlTrain batch 6/32 - 190.4ms/batch - loss: 0.86346 - diff: 13.82mlTrain batch 7/32 - 184.1ms/batch - loss: 0.94173 - diff: 15.07mlTrain batch 8/32 - 173.8ms/batch - loss: 0.92344 - diff: 14.78mlTrain batch 9/32 - 168.1ms/batch - loss: 0.95425 - diff: 15.27mlTrain batch 10/32 - 179.8ms/batch - loss: 0.92314 - diff: 14.77mlTrain batch 11/32 - 164.5ms/batch - loss: 0.94207 - diff: 15.07mlTrain batch 12/32 - 180.9ms/batch - loss: 0.95457 - diff: 15.27mlTrain batch 13/32 - 134.9ms/batch - loss: 0.93615 - diff: 14.98mlTrain batch 14/32 - 166.7ms/batch - loss: 0.92032 - diff: 14.73mlTrain batch 15/32 - 142.9ms/batch - loss: 0.92983 - diff: 14.88mlTrain batch 16/32 - 162.0ms/batch - loss: 0.91492 - diff: 14.64mlTrain batch 17/32 - 157.4ms/batch - loss: 0.91968 - diff: 14.71mlTrain batch 18/32 - 146.9ms/batch - loss: 0.90628 - diff: 14.50mlTrain batch 19/32 - 161.5ms/batch - loss: 0.90719 - diff: 14.52mlTrain batch 20/32 - 126.3ms/batch - loss: 0.92528 - diff: 14.80mlTrain batch 21/32 - 132.1ms/batch - loss: 0.95324 - diff: 15.25mlTrain batch 22/32 - 173.6ms/batch - loss: 0.96321 - diff: 15.41mlTrain batch 23/32 - 152.9ms/batch - loss: 0.96069 - diff: 15.37mlTrain batch 24/32 - 154.1ms/batch - loss: 0.96186 - diff: 15.39mlTrain batch 25/32 - 161.2ms/batch - loss: 0.97416 - diff: 15.59mlTrain batch 26/32 - 182.4ms/batch - loss: 0.95756 - diff: 15.32mlTrain batch 27/32 - 116.8ms/batch - loss: 0.95630 - diff: 15.30mlTrain batch 28/32 - 198.9ms/batch - loss: 0.95583 - diff: 15.29mlTrain batch 29/32 - 170.6ms/batch - loss: 0.95519 - diff: 15.28mlTrain batch 30/32 - 157.2ms/batch - loss: 0.94418 - diff: 15.11mlTrain batch 31/32 - 155.3ms/batch - loss: 0.93450 - diff: 14.95mlTrain batch 32/32 - 120.6ms/batch - loss: 0.98480 - diff: 15.06mlTrain batch 32/32 - 15.8s 120.6ms/batch - loss: 0.98480 - diff: 15.06ml
Test 1.4s: val_loss: 1.31773 - diff: 20.32ml
Epoch   131: reducing learning rate of group 0 to 3.1250e-05.

Epoch 131: current best loss = 1.22404, at epoch 108
Train batch 1/32 - 191.4ms/batch - loss: 0.79757 - diff: 12.76mlTrain batch 2/32 - 184.8ms/batch - loss: 0.65346 - diff: 10.46mlTrain batch 3/32 - 170.7ms/batch - loss: 0.63553 - diff: 10.17mlTrain batch 4/32 - 200.2ms/batch - loss: 0.74333 - diff: 11.89mlTrain batch 5/32 - 136.9ms/batch - loss: 0.90715 - diff: 14.51mlTrain batch 6/32 - 141.7ms/batch - loss: 0.85192 - diff: 13.63mlTrain batch 7/32 - 146.5ms/batch - loss: 0.85991 - diff: 13.76mlTrain batch 8/32 - 134.6ms/batch - loss: 0.86286 - diff: 13.81mlTrain batch 9/32 - 173.0ms/batch - loss: 0.83710 - diff: 13.39mlTrain batch 10/32 - 161.6ms/batch - loss: 0.79713 - diff: 12.75mlTrain batch 11/32 - 190.0ms/batch - loss: 0.78707 - diff: 12.59mlTrain batch 12/32 - 158.8ms/batch - loss: 0.80350 - diff: 12.86mlTrain batch 13/32 - 157.6ms/batch - loss: 0.82289 - diff: 13.17mlTrain batch 14/32 - 163.3ms/batch - loss: 0.83287 - diff: 13.33mlTrain batch 15/32 - 235.5ms/batch - loss: 0.84141 - diff: 13.46mlTrain batch 16/32 - 187.9ms/batch - loss: 0.82921 - diff: 13.27mlTrain batch 17/32 - 166.2ms/batch - loss: 0.86409 - diff: 13.83mlTrain batch 18/32 - 184.0ms/batch - loss: 0.86521 - diff: 13.84mlTrain batch 19/32 - 172.7ms/batch - loss: 0.87376 - diff: 13.98mlTrain batch 20/32 - 155.1ms/batch - loss: 0.89333 - diff: 14.29mlTrain batch 21/32 - 135.2ms/batch - loss: 0.88163 - diff: 14.11mlTrain batch 22/32 - 118.6ms/batch - loss: 0.87015 - diff: 13.92mlTrain batch 23/32 - 124.9ms/batch - loss: 0.85557 - diff: 13.69mlTrain batch 24/32 - 138.3ms/batch - loss: 0.85295 - diff: 13.65mlTrain batch 25/32 - 155.2ms/batch - loss: 0.83869 - diff: 13.42mlTrain batch 26/32 - 127.3ms/batch - loss: 0.85973 - diff: 13.76mlTrain batch 27/32 - 151.6ms/batch - loss: 0.85706 - diff: 13.71mlTrain batch 28/32 - 182.1ms/batch - loss: 0.87251 - diff: 13.96mlTrain batch 29/32 - 173.3ms/batch - loss: 0.87336 - diff: 13.97mlTrain batch 30/32 - 134.0ms/batch - loss: 0.86645 - diff: 13.86mlTrain batch 31/32 - 146.5ms/batch - loss: 0.86095 - diff: 13.78mlTrain batch 32/32 - 123.9ms/batch - loss: 0.89838 - diff: 13.84mlTrain batch 32/32 - 16.8s 123.9ms/batch - loss: 0.89838 - diff: 13.84ml
Test 1.2s: val_loss: 1.32754 - diff: 20.22ml

Epoch 132: current best loss = 1.22404, at epoch 108
Train batch 1/32 - 182.3ms/batch - loss: 0.78135 - diff: 12.50mlTrain batch 2/32 - 205.4ms/batch - loss: 0.99354 - diff: 15.90mlTrain batch 3/32 - 192.0ms/batch - loss: 1.39994 - diff: 22.40mlTrain batch 4/32 - 211.4ms/batch - loss: 1.36202 - diff: 21.79mlTrain batch 5/32 - 182.8ms/batch - loss: 1.20161 - diff: 19.23mlTrain batch 6/32 - 165.8ms/batch - loss: 1.09545 - diff: 17.53mlTrain batch 7/32 - 160.4ms/batch - loss: 1.04306 - diff: 16.69mlTrain batch 8/32 - 141.5ms/batch - loss: 1.00437 - diff: 16.07mlTrain batch 9/32 - 188.0ms/batch - loss: 0.96513 - diff: 15.44mlTrain batch 10/32 - 190.8ms/batch - loss: 0.93663 - diff: 14.99mlTrain batch 11/32 - 157.5ms/batch - loss: 0.92034 - diff: 14.73mlTrain batch 12/32 - 187.5ms/batch - loss: 0.90819 - diff: 14.53mlTrain batch 13/32 - 155.4ms/batch - loss: 0.91001 - diff: 14.56mlTrain batch 14/32 - 149.9ms/batch - loss: 0.90969 - diff: 14.56mlTrain batch 15/32 - 168.4ms/batch - loss: 0.92036 - diff: 14.73mlTrain batch 16/32 - 160.3ms/batch - loss: 0.90665 - diff: 14.51mlTrain batch 17/32 - 194.4ms/batch - loss: 0.89193 - diff: 14.27mlTrain batch 18/32 - 178.4ms/batch - loss: 0.90140 - diff: 14.42mlTrain batch 19/32 - 186.8ms/batch - loss: 0.89370 - diff: 14.30mlTrain batch 20/32 - 151.6ms/batch - loss: 0.88761 - diff: 14.20mlTrain batch 21/32 - 156.6ms/batch - loss: 0.86839 - diff: 13.89mlTrain batch 22/32 - 176.7ms/batch - loss: 0.87063 - diff: 13.93mlTrain batch 23/32 - 166.1ms/batch - loss: 0.88586 - diff: 14.17mlTrain batch 24/32 - 159.5ms/batch - loss: 0.87103 - diff: 13.94mlTrain batch 25/32 - 199.8ms/batch - loss: 0.87046 - diff: 13.93mlTrain batch 26/32 - 174.9ms/batch - loss: 0.85771 - diff: 13.72mlTrain batch 27/32 - 179.9ms/batch - loss: 0.89913 - diff: 14.39mlTrain batch 28/32 - 182.7ms/batch - loss: 0.89509 - diff: 14.32mlTrain batch 29/32 - 147.3ms/batch - loss: 0.89612 - diff: 14.34mlTrain batch 30/32 - 177.4ms/batch - loss: 0.88799 - diff: 14.21mlTrain batch 31/32 - 159.9ms/batch - loss: 0.90407 - diff: 14.47mlTrain batch 32/32 - 190.6ms/batch - loss: 0.94421 - diff: 14.54mlTrain batch 32/32 - 16.1s 190.6ms/batch - loss: 0.94421 - diff: 14.54ml
Test 1.4s: val_loss: 1.35325 - diff: 20.97ml

Epoch 133: current best loss = 1.22404, at epoch 108
Train batch 1/32 - 199.4ms/batch - loss: 0.60978 - diff: 9.76mlTrain batch 2/32 - 139.4ms/batch - loss: 0.66955 - diff: 10.71mlTrain batch 3/32 - 171.0ms/batch - loss: 0.64409 - diff: 10.31mlTrain batch 4/32 - 208.5ms/batch - loss: 1.08565 - diff: 17.37mlTrain batch 5/32 - 177.9ms/batch - loss: 0.95057 - diff: 15.21mlTrain batch 6/32 - 142.9ms/batch - loss: 0.91581 - diff: 14.65mlTrain batch 7/32 - 140.0ms/batch - loss: 0.97607 - diff: 15.62mlTrain batch 8/32 - 159.6ms/batch - loss: 0.95078 - diff: 15.21mlTrain batch 9/32 - 144.9ms/batch - loss: 0.94783 - diff: 15.17mlTrain batch 10/32 - 220.0ms/batch - loss: 0.94239 - diff: 15.08mlTrain batch 11/32 - 175.7ms/batch - loss: 0.92294 - diff: 14.77mlTrain batch 12/32 - 135.8ms/batch - loss: 0.91587 - diff: 14.65mlTrain batch 13/32 - 186.9ms/batch - loss: 0.96213 - diff: 15.39mlTrain batch 14/32 - 174.2ms/batch - loss: 0.92675 - diff: 14.83mlTrain batch 15/32 - 167.8ms/batch - loss: 0.91792 - diff: 14.69mlTrain batch 16/32 - 153.4ms/batch - loss: 0.89922 - diff: 14.39mlTrain batch 17/32 - 170.1ms/batch - loss: 0.89228 - diff: 14.28mlTrain batch 18/32 - 156.6ms/batch - loss: 0.89432 - diff: 14.31mlTrain batch 19/32 - 187.0ms/batch - loss: 0.90390 - diff: 14.46mlTrain batch 20/32 - 164.6ms/batch - loss: 0.90700 - diff: 14.51mlTrain batch 21/32 - 168.7ms/batch - loss: 0.90755 - diff: 14.52mlTrain batch 22/32 - 140.8ms/batch - loss: 0.94622 - diff: 15.14mlTrain batch 23/32 - 170.9ms/batch - loss: 0.93320 - diff: 14.93mlTrain batch 24/32 - 145.6ms/batch - loss: 0.91702 - diff: 14.67mlTrain batch 25/32 - 135.8ms/batch - loss: 0.90826 - diff: 14.53mlTrain batch 26/32 - 127.1ms/batch - loss: 0.94309 - diff: 15.09mlTrain batch 27/32 - 137.1ms/batch - loss: 0.94427 - diff: 15.11mlTrain batch 28/32 - 139.6ms/batch - loss: 0.93274 - diff: 14.92mlTrain batch 29/32 - 185.0ms/batch - loss: 0.92487 - diff: 14.80mlTrain batch 30/32 - 192.6ms/batch - loss: 0.91340 - diff: 14.61mlTrain batch 31/32 - 141.1ms/batch - loss: 0.90966 - diff: 14.55mlTrain batch 32/32 - 160.4ms/batch - loss: 0.93564 - diff: 14.57mlTrain batch 32/32 - 16.4s 160.4ms/batch - loss: 0.93564 - diff: 14.57ml
Test 1.3s: val_loss: 1.24981 - diff: 19.57ml

Epoch 134: current best loss = 1.22404, at epoch 108
Train batch 1/32 - 143.4ms/batch - loss: 0.65560 - diff: 10.49mlTrain batch 2/32 - 154.0ms/batch - loss: 0.54451 - diff: 8.71mlTrain batch 3/32 - 191.1ms/batch - loss: 0.48643 - diff: 7.78mlTrain batch 4/32 - 157.5ms/batch - loss: 0.52417 - diff: 8.39mlTrain batch 5/32 - 160.8ms/batch - loss: 0.58988 - diff: 9.44mlTrain batch 6/32 - 155.4ms/batch - loss: 0.59777 - diff: 9.56mlTrain batch 7/32 - 205.0ms/batch - loss: 0.59531 - diff: 9.52mlTrain batch 8/32 - 209.1ms/batch - loss: 0.59847 - diff: 9.58mlTrain batch 9/32 - 185.0ms/batch - loss: 0.61976 - diff: 9.92mlTrain batch 10/32 - 180.9ms/batch - loss: 0.62747 - diff: 10.04mlTrain batch 11/32 - 125.6ms/batch - loss: 0.65431 - diff: 10.47mlTrain batch 12/32 - 119.2ms/batch - loss: 0.74394 - diff: 11.90mlTrain batch 13/32 - 175.4ms/batch - loss: 0.76876 - diff: 12.30mlTrain batch 14/32 - 161.9ms/batch - loss: 0.79875 - diff: 12.78mlTrain batch 15/32 - 154.3ms/batch - loss: 0.79967 - diff: 12.79mlTrain batch 16/32 - 152.0ms/batch - loss: 0.80342 - diff: 12.85mlTrain batch 17/32 - 195.9ms/batch - loss: 0.85235 - diff: 13.64mlTrain batch 18/32 - 173.1ms/batch - loss: 0.86508 - diff: 13.84mlTrain batch 19/32 - 149.7ms/batch - loss: 0.85722 - diff: 13.72mlTrain batch 20/32 - 132.5ms/batch - loss: 0.84885 - diff: 13.58mlTrain batch 21/32 - 166.1ms/batch - loss: 0.84408 - diff: 13.51mlTrain batch 22/32 - 161.9ms/batch - loss: 0.83597 - diff: 13.38mlTrain batch 23/32 - 129.4ms/batch - loss: 0.82853 - diff: 13.26mlTrain batch 24/32 - 144.2ms/batch - loss: 0.84077 - diff: 13.45mlTrain batch 25/32 - 119.6ms/batch - loss: 0.84279 - diff: 13.48mlTrain batch 26/32 - 178.9ms/batch - loss: 0.84900 - diff: 13.58mlTrain batch 27/32 - 134.1ms/batch - loss: 0.84993 - diff: 13.60mlTrain batch 28/32 - 124.2ms/batch - loss: 0.84364 - diff: 13.50mlTrain batch 29/32 - 133.3ms/batch - loss: 0.84393 - diff: 13.50mlTrain batch 30/32 - 135.8ms/batch - loss: 0.83455 - diff: 13.35mlTrain batch 31/32 - 137.5ms/batch - loss: 0.85628 - diff: 13.70mlTrain batch 32/32 - 138.0ms/batch - loss: 0.86594 - diff: 13.66mlTrain batch 32/32 - 17.9s 138.0ms/batch - loss: 0.86594 - diff: 13.66ml
Test 1.1s: val_loss: 1.29868 - diff: 20.01ml

Epoch 135: current best loss = 1.22404, at epoch 108
Train batch 1/32 - 210.8ms/batch - loss: 1.87356 - diff: 29.98mlTrain batch 2/32 - 143.8ms/batch - loss: 1.34522 - diff: 21.52mlTrain batch 3/32 - 184.0ms/batch - loss: 1.30059 - diff: 20.81mlTrain batch 4/32 - 196.2ms/batch - loss: 1.26072 - diff: 20.17mlTrain batch 5/32 - 167.9ms/batch - loss: 1.24791 - diff: 19.97mlTrain batch 6/32 - 120.5ms/batch - loss: 1.15630 - diff: 18.50mlTrain batch 7/32 - 160.0ms/batch - loss: 1.08708 - diff: 17.39mlTrain batch 8/32 - 182.5ms/batch - loss: 1.14179 - diff: 18.27mlTrain batch 9/32 - 174.0ms/batch - loss: 1.08344 - diff: 17.33mlTrain batch 10/32 - 181.8ms/batch - loss: 1.09147 - diff: 17.46mlTrain batch 11/32 - 168.7ms/batch - loss: 1.04892 - diff: 16.78mlTrain batch 12/32 - 170.8ms/batch - loss: 1.01956 - diff: 16.31mlTrain batch 13/32 - 168.3ms/batch - loss: 1.06169 - diff: 16.99mlTrain batch 14/32 - 161.6ms/batch - loss: 1.09143 - diff: 17.46mlTrain batch 15/32 - 167.9ms/batch - loss: 1.06875 - diff: 17.10mlTrain batch 16/32 - 173.0ms/batch - loss: 1.06638 - diff: 17.06mlTrain batch 17/32 - 144.3ms/batch - loss: 1.04413 - diff: 16.71mlTrain batch 18/32 - 131.8ms/batch - loss: 1.06024 - diff: 16.96mlTrain batch 19/32 - 190.4ms/batch - loss: 1.08829 - diff: 17.41mlTrain batch 20/32 - 180.2ms/batch - loss: 1.08964 - diff: 17.43mlTrain batch 21/32 - 174.0ms/batch - loss: 1.06963 - diff: 17.11mlTrain batch 22/32 - 200.6ms/batch - loss: 1.06482 - diff: 17.04mlTrain batch 23/32 - 180.8ms/batch - loss: 1.05268 - diff: 16.84mlTrain batch 24/32 - 186.2ms/batch - loss: 1.06097 - diff: 16.98mlTrain batch 25/32 - 125.6ms/batch - loss: 1.05114 - diff: 16.82mlTrain batch 26/32 - 172.0ms/batch - loss: 1.03020 - diff: 16.48mlTrain batch 27/32 - 105.2ms/batch - loss: 1.10042 - diff: 17.61mlTrain batch 28/32 - 136.7ms/batch - loss: 1.08987 - diff: 17.44mlTrain batch 29/32 - 130.7ms/batch - loss: 1.08334 - diff: 17.33mlTrain batch 30/32 - 111.6ms/batch - loss: 1.07295 - diff: 17.17mlTrain batch 31/32 - 117.7ms/batch - loss: 1.07352 - diff: 17.18mlTrain batch 32/32 - 112.9ms/batch - loss: 1.10694 - diff: 17.21mlTrain batch 32/32 - 16.3s 112.9ms/batch - loss: 1.10694 - diff: 17.21ml
Test 1.3s: val_loss: 1.29719 - diff: 19.48ml

Epoch 136: current best loss = 1.22404, at epoch 108
Train batch 1/32 - 220.6ms/batch - loss: 0.65283 - diff: 10.45mlTrain batch 2/32 - 164.1ms/batch - loss: 0.61349 - diff: 9.82mlTrain batch 3/32 - 151.4ms/batch - loss: 0.57355 - diff: 9.18mlTrain batch 4/32 - 144.1ms/batch - loss: 0.64861 - diff: 10.38mlTrain batch 5/32 - 164.3ms/batch - loss: 0.65610 - diff: 10.50mlTrain batch 6/32 - 137.5ms/batch - loss: 0.75253 - diff: 12.04mlTrain batch 7/32 - 183.2ms/batch - loss: 0.74321 - diff: 11.89mlTrain batch 8/32 - 177.7ms/batch - loss: 1.03152 - diff: 16.50mlTrain batch 9/32 - 183.2ms/batch - loss: 1.03282 - diff: 16.53mlTrain batch 10/32 - 212.8ms/batch - loss: 0.98989 - diff: 15.84mlTrain batch 11/32 - 184.4ms/batch - loss: 0.97783 - diff: 15.65mlTrain batch 12/32 - 166.7ms/batch - loss: 0.93957 - diff: 15.03mlTrain batch 13/32 - 187.3ms/batch - loss: 0.91622 - diff: 14.66mlTrain batch 14/32 - 260.4ms/batch - loss: 0.91614 - diff: 14.66mlTrain batch 15/32 - 163.9ms/batch - loss: 0.91354 - diff: 14.62mlTrain batch 16/32 - 113.0ms/batch - loss: 0.89782 - diff: 14.37mlTrain batch 17/32 - 173.7ms/batch - loss: 0.91321 - diff: 14.61mlTrain batch 18/32 - 137.7ms/batch - loss: 0.90252 - diff: 14.44mlTrain batch 19/32 - 187.2ms/batch - loss: 0.88202 - diff: 14.11mlTrain batch 20/32 - 183.9ms/batch - loss: 0.87666 - diff: 14.03mlTrain batch 21/32 - 181.1ms/batch - loss: 0.86762 - diff: 13.88mlTrain batch 22/32 - 195.9ms/batch - loss: 0.86462 - diff: 13.83mlTrain batch 23/32 - 149.5ms/batch - loss: 0.89600 - diff: 14.34mlTrain batch 24/32 - 186.1ms/batch - loss: 0.89056 - diff: 14.25mlTrain batch 25/32 - 185.3ms/batch - loss: 0.90469 - diff: 14.48mlTrain batch 26/32 - 197.1ms/batch - loss: 0.89896 - diff: 14.38mlTrain batch 27/32 - 173.8ms/batch - loss: 0.90713 - diff: 14.51mlTrain batch 28/32 - 172.5ms/batch - loss: 0.90708 - diff: 14.51mlTrain batch 29/32 - 192.4ms/batch - loss: 0.89888 - diff: 14.38mlTrain batch 30/32 - 142.6ms/batch - loss: 0.88874 - diff: 14.22mlTrain batch 31/32 - 126.3ms/batch - loss: 0.88633 - diff: 14.18mlTrain batch 32/32 - 130.6ms/batch - loss: 0.95336 - diff: 14.36mlTrain batch 32/32 - 17.6s 130.6ms/batch - loss: 0.95336 - diff: 14.36ml
Test 1.2s: val_loss: 1.28285 - diff: 19.90ml

Epoch 137: current best loss = 1.22404, at epoch 108
Train batch 1/32 - 223.6ms/batch - loss: 0.68179 - diff: 10.91mlTrain batch 2/32 - 172.0ms/batch - loss: 0.83427 - diff: 13.35mlTrain batch 3/32 - 151.6ms/batch - loss: 0.79949 - diff: 12.79mlTrain batch 4/32 - 160.5ms/batch - loss: 0.84644 - diff: 13.54mlTrain batch 5/32 - 165.2ms/batch - loss: 0.83984 - diff: 13.44mlTrain batch 6/32 - 164.2ms/batch - loss: 0.81893 - diff: 13.10mlTrain batch 7/32 - 171.4ms/batch - loss: 0.89001 - diff: 14.24mlTrain batch 8/32 - 151.1ms/batch - loss: 0.86597 - diff: 13.86mlTrain batch 9/32 - 152.5ms/batch - loss: 0.84438 - diff: 13.51mlTrain batch 10/32 - 146.9ms/batch - loss: 0.86517 - diff: 13.84mlTrain batch 11/32 - 156.4ms/batch - loss: 0.93191 - diff: 14.91mlTrain batch 12/32 - 180.6ms/batch - loss: 0.91505 - diff: 14.64mlTrain batch 13/32 - 147.2ms/batch - loss: 0.93912 - diff: 15.03mlTrain batch 14/32 - 156.7ms/batch - loss: 0.91552 - diff: 14.65mlTrain batch 15/32 - 125.7ms/batch - loss: 0.97553 - diff: 15.61mlTrain batch 16/32 - 129.1ms/batch - loss: 1.01656 - diff: 16.27mlTrain batch 17/32 - 163.5ms/batch - loss: 0.99406 - diff: 15.90mlTrain batch 18/32 - 174.6ms/batch - loss: 0.97608 - diff: 15.62mlTrain batch 19/32 - 200.8ms/batch - loss: 1.01632 - diff: 16.26mlTrain batch 20/32 - 128.1ms/batch - loss: 1.02272 - diff: 16.36mlTrain batch 21/32 - 166.0ms/batch - loss: 1.00057 - diff: 16.01mlTrain batch 22/32 - 137.3ms/batch - loss: 0.98795 - diff: 15.81mlTrain batch 23/32 - 105.3ms/batch - loss: 0.97110 - diff: 15.54mlTrain batch 24/32 - 131.7ms/batch - loss: 0.95055 - diff: 15.21mlTrain batch 25/32 - 183.1ms/batch - loss: 0.93943 - diff: 15.03mlTrain batch 26/32 - 151.0ms/batch - loss: 0.92871 - diff: 14.86mlTrain batch 27/32 - 120.2ms/batch - loss: 0.93701 - diff: 14.99mlTrain batch 28/32 - 140.0ms/batch - loss: 0.92011 - diff: 14.72mlTrain batch 29/32 - 203.3ms/batch - loss: 0.91461 - diff: 14.63mlTrain batch 30/32 - 165.6ms/batch - loss: 0.90745 - diff: 14.52mlTrain batch 31/32 - 188.3ms/batch - loss: 0.91028 - diff: 14.56mlTrain batch 32/32 - 188.0ms/batch - loss: 0.92516 - diff: 14.54mlTrain batch 32/32 - 16.7s 188.0ms/batch - loss: 0.92516 - diff: 14.54ml
Test 1.3s: val_loss: 1.30624 - diff: 19.83ml

Epoch 138: current best loss = 1.22404, at epoch 108
Train batch 1/32 - 187.5ms/batch - loss: 0.85799 - diff: 13.73mlTrain batch 2/32 - 135.3ms/batch - loss: 0.87010 - diff: 13.92mlTrain batch 3/32 - 169.7ms/batch - loss: 0.74832 - diff: 11.97mlTrain batch 4/32 - 174.4ms/batch - loss: 0.81391 - diff: 13.02mlTrain batch 5/32 - 162.9ms/batch - loss: 0.80955 - diff: 12.95mlTrain batch 6/32 - 192.6ms/batch - loss: 0.78370 - diff: 12.54mlTrain batch 7/32 - 149.9ms/batch - loss: 0.79961 - diff: 12.79mlTrain batch 8/32 - 203.7ms/batch - loss: 0.77333 - diff: 12.37mlTrain batch 9/32 - 170.7ms/batch - loss: 0.81812 - diff: 13.09mlTrain batch 10/32 - 176.8ms/batch - loss: 0.88316 - diff: 14.13mlTrain batch 11/32 - 174.6ms/batch - loss: 0.87247 - diff: 13.96mlTrain batch 12/32 - 160.3ms/batch - loss: 0.85479 - diff: 13.68mlTrain batch 13/32 - 183.3ms/batch - loss: 0.85122 - diff: 13.62mlTrain batch 14/32 - 177.9ms/batch - loss: 0.83527 - diff: 13.36mlTrain batch 15/32 - 160.4ms/batch - loss: 0.86389 - diff: 13.82mlTrain batch 16/32 - 229.6ms/batch - loss: 0.87664 - diff: 14.03mlTrain batch 17/32 - 181.3ms/batch - loss: 0.87777 - diff: 14.04mlTrain batch 18/32 - 166.0ms/batch - loss: 0.90256 - diff: 14.44mlTrain batch 19/32 - 192.0ms/batch - loss: 0.88523 - diff: 14.16mlTrain batch 20/32 - 182.3ms/batch - loss: 0.87699 - diff: 14.03mlTrain batch 21/32 - 155.7ms/batch - loss: 0.85567 - diff: 13.69mlTrain batch 22/32 - 140.5ms/batch - loss: 0.84786 - diff: 13.57mlTrain batch 23/32 - 144.1ms/batch - loss: 0.85080 - diff: 13.61mlTrain batch 24/32 - 158.9ms/batch - loss: 0.84349 - diff: 13.50mlTrain batch 25/32 - 160.0ms/batch - loss: 0.83603 - diff: 13.38mlTrain batch 26/32 - 105.1ms/batch - loss: 0.82560 - diff: 13.21mlTrain batch 27/32 - 168.4ms/batch - loss: 0.82809 - diff: 13.25mlTrain batch 28/32 - 159.8ms/batch - loss: 0.82179 - diff: 13.15mlTrain batch 29/32 - 193.5ms/batch - loss: 0.82477 - diff: 13.20mlTrain batch 30/32 - 212.7ms/batch - loss: 0.84503 - diff: 13.52mlTrain batch 31/32 - 108.8ms/batch - loss: 0.84919 - diff: 13.59mlTrain batch 32/32 - 125.9ms/batch - loss: 0.87777 - diff: 13.62mlTrain batch 32/32 - 18.0s 125.9ms/batch - loss: 0.87777 - diff: 13.62ml
Test 1.3s: val_loss: 1.31072 - diff: 20.16ml

Epoch 139: current best loss = 1.22404, at epoch 108
Train batch 1/32 - 187.3ms/batch - loss: 1.82034 - diff: 29.13mlTrain batch 2/32 - 204.2ms/batch - loss: 1.17380 - diff: 18.78mlTrain batch 3/32 - 200.1ms/batch - loss: 1.00250 - diff: 16.04mlTrain batch 4/32 - 178.8ms/batch - loss: 0.93100 - diff: 14.90mlTrain batch 5/32 - 184.7ms/batch - loss: 0.94607 - diff: 15.14mlTrain batch 6/32 - 197.2ms/batch - loss: 1.00028 - diff: 16.00mlTrain batch 7/32 - 192.7ms/batch - loss: 0.95567 - diff: 15.29mlTrain batch 8/32 - 175.1ms/batch - loss: 0.94706 - diff: 15.15mlTrain batch 9/32 - 169.5ms/batch - loss: 0.96520 - diff: 15.44mlTrain batch 10/32 - 147.2ms/batch - loss: 0.92001 - diff: 14.72mlTrain batch 11/32 - 181.5ms/batch - loss: 0.89347 - diff: 14.30mlTrain batch 12/32 - 132.1ms/batch - loss: 0.90046 - diff: 14.41mlTrain batch 13/32 - 211.6ms/batch - loss: 0.96623 - diff: 15.46mlTrain batch 14/32 - 172.2ms/batch - loss: 0.97621 - diff: 15.62mlTrain batch 15/32 - 165.9ms/batch - loss: 0.97628 - diff: 15.62mlTrain batch 16/32 - 174.6ms/batch - loss: 0.97653 - diff: 15.62mlTrain batch 17/32 - 180.1ms/batch - loss: 1.01214 - diff: 16.19mlTrain batch 18/32 - 211.0ms/batch - loss: 1.01112 - diff: 16.18mlTrain batch 19/32 - 199.2ms/batch - loss: 1.02904 - diff: 16.46mlTrain batch 20/32 - 156.9ms/batch - loss: 1.00906 - diff: 16.14mlTrain batch 21/32 - 218.7ms/batch - loss: 0.99164 - diff: 15.87mlTrain batch 22/32 - 168.4ms/batch - loss: 0.97633 - diff: 15.62mlTrain batch 23/32 - 158.0ms/batch - loss: 0.97133 - diff: 15.54mlTrain batch 24/32 - 152.4ms/batch - loss: 0.96523 - diff: 15.44mlTrain batch 25/32 - 125.4ms/batch - loss: 0.95065 - diff: 15.21mlTrain batch 26/32 - 112.0ms/batch - loss: 0.96076 - diff: 15.37mlTrain batch 27/32 - 161.0ms/batch - loss: 0.95529 - diff: 15.28mlTrain batch 28/32 - 147.2ms/batch - loss: 0.94332 - diff: 15.09mlTrain batch 29/32 - 139.7ms/batch - loss: 0.93836 - diff: 15.01mlTrain batch 30/32 - 142.9ms/batch - loss: 0.93656 - diff: 14.98mlTrain batch 31/32 - 170.5ms/batch - loss: 0.92539 - diff: 14.81mlTrain batch 32/32 - 185.3ms/batch - loss: 0.98527 - diff: 14.96mlTrain batch 32/32 - 16.4s 185.3ms/batch - loss: 0.98527 - diff: 14.96ml
Test 1.3s: val_loss: 1.31026 - diff: 19.99ml

Epoch 140: current best loss = 1.22404, at epoch 108
Train batch 1/32 - 206.6ms/batch - loss: 0.64388 - diff: 10.30mlTrain batch 2/32 - 137.4ms/batch - loss: 0.69919 - diff: 11.19mlTrain batch 3/32 - 241.1ms/batch - loss: 0.80101 - diff: 12.82mlTrain batch 4/32 - 182.9ms/batch - loss: 0.89236 - diff: 14.28mlTrain batch 5/32 - 156.3ms/batch - loss: 0.98509 - diff: 15.76mlTrain batch 6/32 - 128.5ms/batch - loss: 1.02717 - diff: 16.43mlTrain batch 7/32 - 190.0ms/batch - loss: 0.95898 - diff: 15.34mlTrain batch 8/32 - 201.9ms/batch - loss: 1.15830 - diff: 18.53mlTrain batch 9/32 - 178.8ms/batch - loss: 1.15157 - diff: 18.43mlTrain batch 10/32 - 202.3ms/batch - loss: 1.16339 - diff: 18.61mlTrain batch 11/32 - 189.2ms/batch - loss: 1.10750 - diff: 17.72mlTrain batch 12/32 - 158.8ms/batch - loss: 1.11509 - diff: 17.84mlTrain batch 13/32 - 171.4ms/batch - loss: 1.11450 - diff: 17.83mlTrain batch 14/32 - 194.9ms/batch - loss: 1.10086 - diff: 17.61mlTrain batch 15/32 - 143.5ms/batch - loss: 1.07082 - diff: 17.13mlTrain batch 16/32 - 160.0ms/batch - loss: 1.05851 - diff: 16.94mlTrain batch 17/32 - 108.4ms/batch - loss: 1.06990 - diff: 17.12mlTrain batch 18/32 - 161.3ms/batch - loss: 1.05939 - diff: 16.95mlTrain batch 19/32 - 142.6ms/batch - loss: 1.05813 - diff: 16.93mlTrain batch 20/32 - 110.1ms/batch - loss: 1.06101 - diff: 16.98mlTrain batch 21/32 - 157.9ms/batch - loss: 1.08655 - diff: 17.38mlTrain batch 22/32 - 162.3ms/batch - loss: 1.09371 - diff: 17.50mlTrain batch 23/32 - 187.6ms/batch - loss: 1.06862 - diff: 17.10mlTrain batch 24/32 - 170.5ms/batch - loss: 1.05245 - diff: 16.84mlTrain batch 25/32 - 181.7ms/batch - loss: 1.08115 - diff: 17.30mlTrain batch 26/32 - 192.2ms/batch - loss: 1.06789 - diff: 17.09mlTrain batch 27/32 - 185.0ms/batch - loss: 1.05131 - diff: 16.82mlTrain batch 28/32 - 179.1ms/batch - loss: 1.06245 - diff: 17.00mlTrain batch 29/32 - 160.4ms/batch - loss: 1.05347 - diff: 16.86mlTrain batch 30/32 - 165.8ms/batch - loss: 1.04729 - diff: 16.76mlTrain batch 31/32 - 137.4ms/batch - loss: 1.05946 - diff: 16.95mlTrain batch 32/32 - 184.8ms/batch - loss: 1.12223 - diff: 17.10mlTrain batch 32/32 - 17.0s 184.8ms/batch - loss: 1.12223 - diff: 17.10ml
Test 1.1s: val_loss: 1.39602 - diff: 21.22ml

Epoch 141: current best loss = 1.22404, at epoch 108
Train batch 1/32 - 154.4ms/batch - loss: 0.63426 - diff: 10.15mlTrain batch 2/32 - 124.6ms/batch - loss: 0.56188 - diff: 8.99mlTrain batch 3/32 - 193.4ms/batch - loss: 0.60383 - diff: 9.66mlTrain batch 4/32 - 128.0ms/batch - loss: 0.61795 - diff: 9.89mlTrain batch 5/32 - 148.2ms/batch - loss: 0.55798 - diff: 8.93mlTrain batch 6/32 - 145.0ms/batch - loss: 0.55465 - diff: 8.87mlTrain batch 7/32 - 182.6ms/batch - loss: 0.56950 - diff: 9.11mlTrain batch 8/32 - 159.7ms/batch - loss: 0.65408 - diff: 10.47mlTrain batch 9/32 - 158.0ms/batch - loss: 0.64705 - diff: 10.35mlTrain batch 10/32 - 136.5ms/batch - loss: 0.69283 - diff: 11.09mlTrain batch 11/32 - 151.4ms/batch - loss: 0.68611 - diff: 10.98mlTrain batch 12/32 - 146.2ms/batch - loss: 0.74892 - diff: 11.98mlTrain batch 13/32 - 194.0ms/batch - loss: 0.75073 - diff: 12.01mlTrain batch 14/32 - 159.8ms/batch - loss: 0.75367 - diff: 12.06mlTrain batch 15/32 - 175.4ms/batch - loss: 0.74469 - diff: 11.92mlTrain batch 16/32 - 149.0ms/batch - loss: 0.79348 - diff: 12.70mlTrain batch 17/32 - 169.8ms/batch - loss: 0.77960 - diff: 12.47mlTrain batch 18/32 - 168.2ms/batch - loss: 0.78044 - diff: 12.49mlTrain batch 19/32 - 158.3ms/batch - loss: 0.77431 - diff: 12.39mlTrain batch 20/32 - 124.9ms/batch - loss: 0.77237 - diff: 12.36mlTrain batch 21/32 - 136.7ms/batch - loss: 0.77179 - diff: 12.35mlTrain batch 22/32 - 144.2ms/batch - loss: 0.79393 - diff: 12.70mlTrain batch 23/32 - 165.4ms/batch - loss: 0.77615 - diff: 12.42mlTrain batch 24/32 - 185.3ms/batch - loss: 0.76569 - diff: 12.25mlTrain batch 25/32 - 169.8ms/batch - loss: 0.76997 - diff: 12.32mlTrain batch 26/32 - 145.0ms/batch - loss: 0.78134 - diff: 12.50mlTrain batch 27/32 - 163.3ms/batch - loss: 0.78181 - diff: 12.51mlTrain batch 28/32 - 190.9ms/batch - loss: 0.78114 - diff: 12.50mlTrain batch 29/32 - 160.3ms/batch - loss: 0.77770 - diff: 12.44mlTrain batch 30/32 - 112.2ms/batch - loss: 0.77941 - diff: 12.47mlTrain batch 31/32 - 128.1ms/batch - loss: 0.77239 - diff: 12.36mlTrain batch 32/32 - 123.9ms/batch - loss: 0.85126 - diff: 12.60mlTrain batch 32/32 - 16.5s 123.9ms/batch - loss: 0.85126 - diff: 12.60ml
Test 1.2s: val_loss: 1.27236 - diff: 19.71ml
Epoch   142: reducing learning rate of group 0 to 1.5625e-05.

Epoch 142: current best loss = 1.22404, at epoch 108
Train batch 1/32 - 177.3ms/batch - loss: 0.78433 - diff: 12.55mlTrain batch 2/32 - 119.3ms/batch - loss: 0.75627 - diff: 12.10mlTrain batch 3/32 - 157.4ms/batch - loss: 0.77298 - diff: 12.37mlTrain batch 4/32 - 154.8ms/batch - loss: 0.73801 - diff: 11.81mlTrain batch 5/32 - 191.4ms/batch - loss: 0.71137 - diff: 11.38mlTrain batch 6/32 - 192.8ms/batch - loss: 0.72494 - diff: 11.60mlTrain batch 7/32 - 199.8ms/batch - loss: 0.73494 - diff: 11.76mlTrain batch 8/32 - 200.8ms/batch - loss: 0.80372 - diff: 12.86mlTrain batch 9/32 - 145.7ms/batch - loss: 0.82025 - diff: 13.12mlTrain batch 10/32 - 154.9ms/batch - loss: 0.81376 - diff: 13.02mlTrain batch 11/32 - 194.9ms/batch - loss: 0.78587 - diff: 12.57mlTrain batch 12/32 - 162.3ms/batch - loss: 0.78059 - diff: 12.49mlTrain batch 13/32 - 176.6ms/batch - loss: 0.78427 - diff: 12.55mlTrain batch 14/32 - 158.6ms/batch - loss: 0.84177 - diff: 13.47mlTrain batch 15/32 - 184.5ms/batch - loss: 0.85672 - diff: 13.71mlTrain batch 16/32 - 163.9ms/batch - loss: 0.87341 - diff: 13.97mlTrain batch 17/32 - 136.8ms/batch - loss: 0.89715 - diff: 14.35mlTrain batch 18/32 - 126.4ms/batch - loss: 0.94478 - diff: 15.12mlTrain batch 19/32 - 158.0ms/batch - loss: 0.92629 - diff: 14.82mlTrain batch 20/32 - 143.7ms/batch - loss: 0.93563 - diff: 14.97mlTrain batch 21/32 - 186.9ms/batch - loss: 0.94545 - diff: 15.13mlTrain batch 22/32 - 131.9ms/batch - loss: 0.94231 - diff: 15.08mlTrain batch 23/32 - 164.3ms/batch - loss: 0.93802 - diff: 15.01mlTrain batch 24/32 - 168.9ms/batch - loss: 0.93467 - diff: 14.95mlTrain batch 25/32 - 164.1ms/batch - loss: 0.91996 - diff: 14.72mlTrain batch 26/32 - 175.2ms/batch - loss: 0.96074 - diff: 15.37mlTrain batch 27/32 - 180.5ms/batch - loss: 0.97425 - diff: 15.59mlTrain batch 28/32 - 179.2ms/batch - loss: 0.99368 - diff: 15.90mlTrain batch 29/32 - 105.2ms/batch - loss: 0.98660 - diff: 15.79mlTrain batch 30/32 - 104.2ms/batch - loss: 0.97692 - diff: 15.63mlTrain batch 31/32 - 141.5ms/batch - loss: 0.98341 - diff: 15.73mlTrain batch 32/32 - 185.2ms/batch - loss: 1.01708 - diff: 15.77mlTrain batch 32/32 - 16.6s 185.2ms/batch - loss: 1.01708 - diff: 15.77ml
Test 1.3s: val_loss: 1.23965 - diff: 19.49ml

Epoch 143: current best loss = 1.22404, at epoch 108
Train batch 1/32 - 195.7ms/batch - loss: 0.72960 - diff: 11.67mlTrain batch 2/32 - 145.3ms/batch - loss: 0.74354 - diff: 11.90mlTrain batch 3/32 - 168.2ms/batch - loss: 0.90588 - diff: 14.49mlTrain batch 4/32 - 165.4ms/batch - loss: 0.82656 - diff: 13.22mlTrain batch 5/32 - 143.7ms/batch - loss: 0.81277 - diff: 13.00mlTrain batch 6/32 - 126.9ms/batch - loss: 0.82950 - diff: 13.27mlTrain batch 7/32 - 131.4ms/batch - loss: 0.80427 - diff: 12.87mlTrain batch 8/32 - 199.8ms/batch - loss: 0.81322 - diff: 13.01mlTrain batch 9/32 - 177.9ms/batch - loss: 0.78293 - diff: 12.53mlTrain batch 10/32 - 198.0ms/batch - loss: 0.78023 - diff: 12.48mlTrain batch 11/32 - 184.9ms/batch - loss: 0.77761 - diff: 12.44mlTrain batch 12/32 - 158.8ms/batch - loss: 0.77568 - diff: 12.41mlTrain batch 13/32 - 167.9ms/batch - loss: 0.77246 - diff: 12.36mlTrain batch 14/32 - 173.6ms/batch - loss: 0.77336 - diff: 12.37mlTrain batch 15/32 - 132.9ms/batch - loss: 0.80223 - diff: 12.84mlTrain batch 16/32 - 120.8ms/batch - loss: 0.78790 - diff: 12.61mlTrain batch 17/32 - 172.8ms/batch - loss: 0.79424 - diff: 12.71mlTrain batch 18/32 - 151.7ms/batch - loss: 0.80035 - diff: 12.81mlTrain batch 19/32 - 143.8ms/batch - loss: 0.80753 - diff: 12.92mlTrain batch 20/32 - 112.0ms/batch - loss: 0.82071 - diff: 13.13mlTrain batch 21/32 - 224.8ms/batch - loss: 0.86761 - diff: 13.88mlTrain batch 22/32 - 176.2ms/batch - loss: 0.86117 - diff: 13.78mlTrain batch 23/32 - 177.7ms/batch - loss: 0.84731 - diff: 13.56mlTrain batch 24/32 - 135.1ms/batch - loss: 0.83825 - diff: 13.41mlTrain batch 25/32 - 190.1ms/batch - loss: 0.86722 - diff: 13.88mlTrain batch 26/32 - 105.8ms/batch - loss: 0.87882 - diff: 14.06mlTrain batch 27/32 - 179.3ms/batch - loss: 0.86926 - diff: 13.91mlTrain batch 28/32 - 147.5ms/batch - loss: 0.87370 - diff: 13.98mlTrain batch 29/32 - 145.8ms/batch - loss: 0.87383 - diff: 13.98mlTrain batch 30/32 - 113.4ms/batch - loss: 0.86656 - diff: 13.86mlTrain batch 31/32 - 119.9ms/batch - loss: 0.85693 - diff: 13.71mlTrain batch 32/32 - 109.4ms/batch - loss: 0.96634 - diff: 14.07mlTrain batch 32/32 - 16.5s 109.4ms/batch - loss: 0.96634 - diff: 14.07ml
Test 1.2s: val_loss: 1.30351 - diff: 20.24ml

Epoch 144: current best loss = 1.22404, at epoch 108
Train batch 1/32 - 193.7ms/batch - loss: 0.95926 - diff: 15.35mlTrain batch 2/32 - 174.5ms/batch - loss: 0.79804 - diff: 12.77mlTrain batch 3/32 - 167.9ms/batch - loss: 0.74293 - diff: 11.89mlTrain batch 4/32 - 147.7ms/batch - loss: 0.94430 - diff: 15.11mlTrain batch 5/32 - 140.1ms/batch - loss: 1.06257 - diff: 17.00mlTrain batch 6/32 - 168.1ms/batch - loss: 1.06858 - diff: 17.10mlTrain batch 7/32 - 132.9ms/batch - loss: 1.14568 - diff: 18.33mlTrain batch 8/32 - 151.8ms/batch - loss: 1.11605 - diff: 17.86mlTrain batch 9/32 - 137.7ms/batch - loss: 1.06237 - diff: 17.00mlTrain batch 10/32 - 156.3ms/batch - loss: 1.17159 - diff: 18.75mlTrain batch 11/32 - 136.8ms/batch - loss: 1.13767 - diff: 18.20mlTrain batch 12/32 - 176.7ms/batch - loss: 1.10884 - diff: 17.74mlTrain batch 13/32 - 131.1ms/batch - loss: 1.07090 - diff: 17.13mlTrain batch 14/32 - 112.7ms/batch - loss: 1.03197 - diff: 16.51mlTrain batch 15/32 - 117.3ms/batch - loss: 0.99660 - diff: 15.95mlTrain batch 16/32 - 116.9ms/batch - loss: 0.97205 - diff: 15.55mlTrain batch 17/32 - 176.3ms/batch - loss: 0.98938 - diff: 15.83mlTrain batch 18/32 - 180.3ms/batch - loss: 0.97812 - diff: 15.65mlTrain batch 19/32 - 163.1ms/batch - loss: 0.97943 - diff: 15.67mlTrain batch 20/32 - 150.4ms/batch - loss: 0.96049 - diff: 15.37mlTrain batch 21/32 - 170.4ms/batch - loss: 0.96183 - diff: 15.39mlTrain batch 22/32 - 160.3ms/batch - loss: 1.00186 - diff: 16.03mlTrain batch 23/32 - 136.6ms/batch - loss: 1.00843 - diff: 16.13mlTrain batch 24/32 - 162.4ms/batch - loss: 1.01217 - diff: 16.19mlTrain batch 25/32 - 159.3ms/batch - loss: 1.01040 - diff: 16.17mlTrain batch 26/32 - 113.6ms/batch - loss: 1.00133 - diff: 16.02mlTrain batch 27/32 - 134.2ms/batch - loss: 1.01621 - diff: 16.26mlTrain batch 28/32 - 164.8ms/batch - loss: 1.00060 - diff: 16.01mlTrain batch 29/32 - 145.2ms/batch - loss: 1.01861 - diff: 16.30mlTrain batch 30/32 - 125.0ms/batch - loss: 1.00667 - diff: 16.11mlTrain batch 31/32 - 102.5ms/batch - loss: 0.99494 - diff: 15.92mlTrain batch 32/32 - 98.8ms/batch - loss: 1.01201 - diff: 15.89mlTrain batch 32/32 - 17.1s 98.8ms/batch - loss: 1.01201 - diff: 15.89ml
Test 1.4s: val_loss: 1.32079 - diff: 20.09ml

Epoch 145: current best loss = 1.22404, at epoch 108
Train batch 1/32 - 143.3ms/batch - loss: 0.93793 - diff: 15.01mlTrain batch 2/32 - 166.6ms/batch - loss: 1.00275 - diff: 16.04mlTrain batch 3/32 - 170.9ms/batch - loss: 1.07822 - diff: 17.25mlTrain batch 4/32 - 148.8ms/batch - loss: 1.11863 - diff: 17.90mlTrain batch 5/32 - 155.8ms/batch - loss: 1.09450 - diff: 17.51mlTrain batch 6/32 - 191.5ms/batch - loss: 1.03679 - diff: 16.59mlTrain batch 7/32 - 132.2ms/batch - loss: 0.99262 - diff: 15.88mlTrain batch 8/32 - 168.4ms/batch - loss: 0.95598 - diff: 15.30mlTrain batch 9/32 - 185.4ms/batch - loss: 1.06837 - diff: 17.09mlTrain batch 10/32 - 163.5ms/batch - loss: 1.02420 - diff: 16.39mlTrain batch 11/32 - 159.3ms/batch - loss: 0.96905 - diff: 15.50mlTrain batch 12/32 - 169.4ms/batch - loss: 0.97241 - diff: 15.56mlTrain batch 13/32 - 188.6ms/batch - loss: 0.97121 - diff: 15.54mlTrain batch 14/32 - 156.6ms/batch - loss: 0.95677 - diff: 15.31mlTrain batch 15/32 - 174.9ms/batch - loss: 0.94819 - diff: 15.17mlTrain batch 16/32 - 164.0ms/batch - loss: 0.93657 - diff: 14.99mlTrain batch 17/32 - 169.7ms/batch - loss: 0.92122 - diff: 14.74mlTrain batch 18/32 - 186.6ms/batch - loss: 0.89941 - diff: 14.39mlTrain batch 19/32 - 182.9ms/batch - loss: 0.89289 - diff: 14.29mlTrain batch 20/32 - 150.5ms/batch - loss: 0.89802 - diff: 14.37mlTrain batch 21/32 - 161.0ms/batch - loss: 0.89495 - diff: 14.32mlTrain batch 22/32 - 140.3ms/batch - loss: 0.87651 - diff: 14.02mlTrain batch 23/32 - 146.1ms/batch - loss: 0.85238 - diff: 13.64mlTrain batch 24/32 - 118.5ms/batch - loss: 0.85115 - diff: 13.62mlTrain batch 25/32 - 153.7ms/batch - loss: 0.86020 - diff: 13.76mlTrain batch 26/32 - 137.2ms/batch - loss: 0.85967 - diff: 13.75mlTrain batch 27/32 - 165.2ms/batch - loss: 0.85796 - diff: 13.73mlTrain batch 28/32 - 153.4ms/batch - loss: 0.85699 - diff: 13.71mlTrain batch 29/32 - 148.8ms/batch - loss: 0.85977 - diff: 13.76mlTrain batch 30/32 - 164.7ms/batch - loss: 0.85008 - diff: 13.60mlTrain batch 31/32 - 155.8ms/batch - loss: 0.84313 - diff: 13.49mlTrain batch 32/32 - 153.5ms/batch - loss: 0.88191 - diff: 13.56mlTrain batch 32/32 - 16.7s 153.5ms/batch - loss: 0.88191 - diff: 13.56ml
Test 1.4s: val_loss: 1.30595 - diff: 19.88ml

Epoch 146: current best loss = 1.22404, at epoch 108
Train batch 1/32 - 246.3ms/batch - loss: 0.61754 - diff: 9.88mlTrain batch 2/32 - 169.7ms/batch - loss: 0.74083 - diff: 11.85mlTrain batch 3/32 - 174.8ms/batch - loss: 0.68616 - diff: 10.98mlTrain batch 4/32 - 176.4ms/batch - loss: 0.84256 - diff: 13.48mlTrain batch 5/32 - 152.7ms/batch - loss: 0.83916 - diff: 13.43mlTrain batch 6/32 - 145.7ms/batch - loss: 0.93379 - diff: 14.94mlTrain batch 7/32 - 153.4ms/batch - loss: 0.98423 - diff: 15.75mlTrain batch 8/32 - 192.0ms/batch - loss: 0.92423 - diff: 14.79mlTrain batch 9/32 - 177.2ms/batch - loss: 0.93865 - diff: 15.02mlTrain batch 10/32 - 141.2ms/batch - loss: 0.92090 - diff: 14.73mlTrain batch 11/32 - 180.9ms/batch - loss: 0.92130 - diff: 14.74mlTrain batch 12/32 - 138.7ms/batch - loss: 0.97565 - diff: 15.61mlTrain batch 13/32 - 160.7ms/batch - loss: 1.00081 - diff: 16.01mlTrain batch 14/32 - 140.5ms/batch - loss: 1.01652 - diff: 16.26mlTrain batch 15/32 - 142.8ms/batch - loss: 0.99812 - diff: 15.97mlTrain batch 16/32 - 147.0ms/batch - loss: 0.98606 - diff: 15.78mlTrain batch 17/32 - 247.7ms/batch - loss: 0.97878 - diff: 15.66mlTrain batch 18/32 - 217.3ms/batch - loss: 0.96734 - diff: 15.48mlTrain batch 19/32 - 208.7ms/batch - loss: 0.94645 - diff: 15.14mlTrain batch 20/32 - 183.3ms/batch - loss: 0.92195 - diff: 14.75mlTrain batch 21/32 - 160.3ms/batch - loss: 0.90440 - diff: 14.47mlTrain batch 22/32 - 131.9ms/batch - loss: 0.93022 - diff: 14.88mlTrain batch 23/32 - 220.1ms/batch - loss: 0.92146 - diff: 14.74mlTrain batch 24/32 - 167.0ms/batch - loss: 0.92459 - diff: 14.79mlTrain batch 25/32 - 154.5ms/batch - loss: 0.92501 - diff: 14.80mlTrain batch 26/32 - 166.7ms/batch - loss: 0.91376 - diff: 14.62mlTrain batch 27/32 - 176.4ms/batch - loss: 0.90003 - diff: 14.40mlTrain batch 28/32 - 159.3ms/batch - loss: 0.91588 - diff: 14.65mlTrain batch 29/32 - 141.7ms/batch - loss: 0.90597 - diff: 14.50mlTrain batch 30/32 - 154.1ms/batch - loss: 0.95274 - diff: 15.24mlTrain batch 31/32 - 148.5ms/batch - loss: 0.95205 - diff: 15.23mlTrain batch 32/32 - 134.1ms/batch - loss: 0.97676 - diff: 15.24mlTrain batch 32/32 - 17.3s 134.1ms/batch - loss: 0.97676 - diff: 15.24ml
Test 1.2s: val_loss: 1.24720 - diff: 19.29ml

Epoch 147: current best loss = 1.22404, at epoch 108
Train batch 1/32 - 206.6ms/batch - loss: 0.79711 - diff: 12.75mlTrain batch 2/32 - 183.3ms/batch - loss: 0.74867 - diff: 11.98mlTrain batch 3/32 - 199.8ms/batch - loss: 0.75948 - diff: 12.15mlTrain batch 4/32 - 146.2ms/batch - loss: 0.75604 - diff: 12.10mlTrain batch 5/32 - 173.4ms/batch - loss: 0.73600 - diff: 11.78mlTrain batch 6/32 - 188.9ms/batch - loss: 0.80873 - diff: 12.94mlTrain batch 7/32 - 171.4ms/batch - loss: 0.77908 - diff: 12.47mlTrain batch 8/32 - 180.0ms/batch - loss: 0.76036 - diff: 12.17mlTrain batch 9/32 - 164.7ms/batch - loss: 0.83114 - diff: 13.30mlTrain batch 10/32 - 201.3ms/batch - loss: 0.80489 - diff: 12.88mlTrain batch 11/32 - 154.2ms/batch - loss: 0.90624 - diff: 14.50mlTrain batch 12/32 - 131.9ms/batch - loss: 0.91750 - diff: 14.68mlTrain batch 13/32 - 172.8ms/batch - loss: 0.90850 - diff: 14.54mlTrain batch 14/32 - 158.6ms/batch - loss: 0.89158 - diff: 14.27mlTrain batch 15/32 - 124.7ms/batch - loss: 0.88578 - diff: 14.17mlTrain batch 16/32 - 146.7ms/batch - loss: 0.87391 - diff: 13.98mlTrain batch 17/32 - 199.0ms/batch - loss: 0.86221 - diff: 13.80mlTrain batch 18/32 - 172.9ms/batch - loss: 0.84323 - diff: 13.49mlTrain batch 19/32 - 171.4ms/batch - loss: 0.85181 - diff: 13.63mlTrain batch 20/32 - 170.8ms/batch - loss: 0.89246 - diff: 14.28mlTrain batch 21/32 - 171.8ms/batch - loss: 0.90742 - diff: 14.52mlTrain batch 22/32 - 147.0ms/batch - loss: 0.89884 - diff: 14.38mlTrain batch 23/32 - 163.7ms/batch - loss: 0.90873 - diff: 14.54mlTrain batch 24/32 - 139.1ms/batch - loss: 0.89508 - diff: 14.32mlTrain batch 25/32 - 152.2ms/batch - loss: 0.89702 - diff: 14.35mlTrain batch 26/32 - 143.8ms/batch - loss: 0.89127 - diff: 14.26mlTrain batch 27/32 - 143.8ms/batch - loss: 0.88198 - diff: 14.11mlTrain batch 28/32 - 141.1ms/batch - loss: 0.87070 - diff: 13.93mlTrain batch 29/32 - 155.4ms/batch - loss: 0.87114 - diff: 13.94mlTrain batch 30/32 - 140.9ms/batch - loss: 0.86900 - diff: 13.90mlTrain batch 31/32 - 122.5ms/batch - loss: 0.86539 - diff: 13.85mlTrain batch 32/32 - 145.8ms/batch - loss: 0.87422 - diff: 13.80mlTrain batch 32/32 - 16.1s 145.8ms/batch - loss: 0.87422 - diff: 13.80ml
Test 1.2s: val_loss: 1.26080 - diff: 19.61ml

Epoch 148: current best loss = 1.22404, at epoch 108
Train batch 1/32 - 230.3ms/batch - loss: 0.82958 - diff: 13.27mlTrain batch 2/32 - 196.4ms/batch - loss: 0.78507 - diff: 12.56mlTrain batch 3/32 - 147.2ms/batch - loss: 1.02872 - diff: 16.46mlTrain batch 4/32 - 114.8ms/batch - loss: 0.95248 - diff: 15.24mlTrain batch 5/32 - 155.6ms/batch - loss: 0.91546 - diff: 14.65mlTrain batch 6/32 - 138.3ms/batch - loss: 0.86799 - diff: 13.89mlTrain batch 7/32 - 148.5ms/batch - loss: 0.83146 - diff: 13.30mlTrain batch 8/32 - 169.3ms/batch - loss: 0.86591 - diff: 13.85mlTrain batch 9/32 - 129.9ms/batch - loss: 0.85491 - diff: 13.68mlTrain batch 10/32 - 130.5ms/batch - loss: 0.83052 - diff: 13.29mlTrain batch 11/32 - 117.2ms/batch - loss: 0.83828 - diff: 13.41mlTrain batch 12/32 - 116.9ms/batch - loss: 0.80931 - diff: 12.95mlTrain batch 13/32 - 151.5ms/batch - loss: 0.83186 - diff: 13.31mlTrain batch 14/32 - 183.2ms/batch - loss: 0.81622 - diff: 13.06mlTrain batch 15/32 - 176.4ms/batch - loss: 0.81813 - diff: 13.09mlTrain batch 16/32 - 189.0ms/batch - loss: 0.83433 - diff: 13.35mlTrain batch 17/32 - 169.0ms/batch - loss: 0.82413 - diff: 13.19mlTrain batch 18/32 - 207.1ms/batch - loss: 0.82593 - diff: 13.21mlTrain batch 19/32 - 156.4ms/batch - loss: 0.84438 - diff: 13.51mlTrain batch 20/32 - 130.2ms/batch - loss: 0.83517 - diff: 13.36mlTrain batch 21/32 - 160.6ms/batch - loss: 0.82993 - diff: 13.28mlTrain batch 22/32 - 148.8ms/batch - loss: 0.83534 - diff: 13.37mlTrain batch 23/32 - 145.1ms/batch - loss: 0.87407 - diff: 13.99mlTrain batch 24/32 - 148.2ms/batch - loss: 0.86050 - diff: 13.77mlTrain batch 25/32 - 169.5ms/batch - loss: 0.85461 - diff: 13.67mlTrain batch 26/32 - 151.1ms/batch - loss: 0.86133 - diff: 13.78mlTrain batch 27/32 - 194.6ms/batch - loss: 0.85085 - diff: 13.61mlTrain batch 28/32 - 190.6ms/batch - loss: 0.85197 - diff: 13.63mlTrain batch 29/32 - 166.6ms/batch - loss: 0.86294 - diff: 13.81mlTrain batch 30/32 - 188.0ms/batch - loss: 0.85937 - diff: 13.75mlTrain batch 31/32 - 128.0ms/batch - loss: 0.86771 - diff: 13.88mlTrain batch 32/32 - 134.7ms/batch - loss: 0.88240 - diff: 13.86mlTrain batch 32/32 - 16.6s 134.7ms/batch - loss: 0.88240 - diff: 13.86ml
Test 1.2s: val_loss: 1.25425 - diff: 19.26ml

Epoch 149: current best loss = 1.22404, at epoch 108
Train batch 1/32 - 174.3ms/batch - loss: 1.28961 - diff: 20.63mlTrain batch 2/32 - 122.1ms/batch - loss: 0.80863 - diff: 12.94mlTrain batch 3/32 - 184.3ms/batch - loss: 0.72002 - diff: 11.52mlTrain batch 4/32 - 152.1ms/batch - loss: 1.01495 - diff: 16.24mlTrain batch 5/32 - 104.8ms/batch - loss: 0.90792 - diff: 14.53mlTrain batch 6/32 - 148.7ms/batch - loss: 0.85052 - diff: 13.61mlTrain batch 7/32 - 184.1ms/batch - loss: 0.83826 - diff: 13.41mlTrain batch 8/32 - 205.4ms/batch - loss: 0.84545 - diff: 13.53mlTrain batch 9/32 - 188.6ms/batch - loss: 0.88449 - diff: 14.15mlTrain batch 10/32 - 182.1ms/batch - loss: 0.84967 - diff: 13.59mlTrain batch 11/32 - 178.4ms/batch - loss: 0.89877 - diff: 14.38mlTrain batch 12/32 - 188.0ms/batch - loss: 0.91512 - diff: 14.64mlTrain batch 13/32 - 189.6ms/batch - loss: 0.89050 - diff: 14.25mlTrain batch 14/32 - 176.6ms/batch - loss: 0.86816 - diff: 13.89mlTrain batch 15/32 - 175.8ms/batch - loss: 0.84787 - diff: 13.57mlTrain batch 16/32 - 137.6ms/batch - loss: 0.86639 - diff: 13.86mlTrain batch 17/32 - 175.5ms/batch - loss: 0.87929 - diff: 14.07mlTrain batch 18/32 - 170.8ms/batch - loss: 0.89726 - diff: 14.36mlTrain batch 19/32 - 164.9ms/batch - loss: 0.93066 - diff: 14.89mlTrain batch 20/32 - 170.6ms/batch - loss: 0.94864 - diff: 15.18mlTrain batch 21/32 - 164.6ms/batch - loss: 0.96301 - diff: 15.41mlTrain batch 22/32 - 150.2ms/batch - loss: 0.95624 - diff: 15.30mlTrain batch 23/32 - 132.0ms/batch - loss: 0.95623 - diff: 15.30mlTrain batch 24/32 - 134.6ms/batch - loss: 0.93447 - diff: 14.95mlTrain batch 25/32 - 129.2ms/batch - loss: 0.94088 - diff: 15.05mlTrain batch 26/32 - 173.0ms/batch - loss: 0.93673 - diff: 14.99mlTrain batch 27/32 - 135.3ms/batch - loss: 0.93787 - diff: 15.01mlTrain batch 28/32 - 179.1ms/batch - loss: 0.94186 - diff: 15.07mlTrain batch 29/32 - 161.7ms/batch - loss: 0.95116 - diff: 15.22mlTrain batch 30/32 - 130.1ms/batch - loss: 0.96331 - diff: 15.41mlTrain batch 31/32 - 118.7ms/batch - loss: 0.94619 - diff: 15.14mlTrain batch 32/32 - 113.8ms/batch - loss: 0.96155 - diff: 15.11mlTrain batch 32/32 - 15.2s 113.8ms/batch - loss: 0.96155 - diff: 15.11ml
Test 1.3s: val_loss: 1.27517 - diff: 19.67ml

