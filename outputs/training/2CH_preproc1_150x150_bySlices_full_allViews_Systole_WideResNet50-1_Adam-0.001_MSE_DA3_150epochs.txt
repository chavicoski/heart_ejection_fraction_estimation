nohup: ignoring input
Running experiment 2CH_preproc1_150x150_bySlices_dataset_allViews_Systole_WideResNet50_1_Adam-0.001_MSE_DA3
Going to train with the GPU in the slot 0 -> device model: GeForce RTX 2080
Model architecture:
 WideResNet50_1(
  (first_conv): Sequential(
    (0): Conv2d(30, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Dropout(p=0.4, inplace=False)
  )
  (pretrained_block): Sequential(
    (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): ReLU(inplace=True)
    (2): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (3): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (4): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (5): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (4): Bottleneck(
        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (5): Bottleneck(
        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
  )
  (reduction_block): Sequential(
    (0): AdaptiveAvgPool2d(output_size=(1, 1))
    (1): Flatten()
  )
  (dense_block): Sequential(
    (0): Linear(in_features=1024, out_features=512, bias=True)
    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Dropout(p=0.4, inplace=False)
    (4): Linear(in_features=512, out_features=1, bias=True)
  )
) 


############################
# TRAIN PHASE:  150 epochs #
############################

Epoch 0: 
Train batch 1/32 - 198.2ms/batch - loss: 252.13135 - diff: 58.31mlTrain batch 2/32 - 178.4ms/batch - loss: 313.16557 - diff: 65.26mlTrain batch 3/32 - 174.7ms/batch - loss: 290.77466 - diff: 62.15mlTrain batch 4/32 - 174.8ms/batch - loss: 372.18039 - diff: 68.94mlTrain batch 5/32 - 174.8ms/batch - loss: 433.52614 - diff: 71.45mlTrain batch 6/32 - 174.5ms/batch - loss: 407.42584 - diff: 69.58mlTrain batch 7/32 - 174.9ms/batch - loss: 416.21980 - diff: 69.48mlTrain batch 8/32 - 175.3ms/batch - loss: 422.89829 - diff: 69.47mlTrain batch 9/32 - 175.3ms/batch - loss: 422.49244 - diff: 69.94mlTrain batch 10/32 - 175.4ms/batch - loss: 423.12012 - diff: 69.68mlTrain batch 11/32 - 175.2ms/batch - loss: 429.49341 - diff: 70.62mlTrain batch 12/32 - 175.3ms/batch - loss: 420.24499 - diff: 69.94mlTrain batch 13/32 - 175.3ms/batch - loss: 408.88826 - diff: 69.18mlTrain batch 14/32 - 175.0ms/batch - loss: 402.05280 - diff: 68.98mlTrain batch 15/32 - 175.3ms/batch - loss: 396.41207 - diff: 68.61mlTrain batch 16/32 - 175.3ms/batch - loss: 388.34931 - diff: 68.07mlTrain batch 17/32 - 175.2ms/batch - loss: 386.10372 - diff: 68.12mlTrain batch 18/32 - 175.2ms/batch - loss: 386.58303 - diff: 68.39mlTrain batch 19/32 - 175.2ms/batch - loss: 379.90595 - diff: 67.94mlTrain batch 20/32 - 175.2ms/batch - loss: 376.76379 - diff: 67.87mlTrain batch 21/32 - 175.2ms/batch - loss: 414.32843 - diff: 68.81mlTrain batch 22/32 - 175.3ms/batch - loss: 406.12638 - diff: 68.26mlTrain batch 23/32 - 175.5ms/batch - loss: 407.98592 - diff: 68.71mlTrain batch 24/32 - 175.3ms/batch - loss: 406.07357 - diff: 68.71mlTrain batch 25/32 - 175.3ms/batch - loss: 412.08626 - diff: 68.97mlTrain batch 26/32 - 175.2ms/batch - loss: 427.05897 - diff: 69.86mlTrain batch 27/32 - 175.0ms/batch - loss: 428.55426 - diff: 70.06mlTrain batch 28/32 - 175.3ms/batch - loss: 426.62990 - diff: 70.01mlTrain batch 29/32 - 175.4ms/batch - loss: 423.11260 - diff: 69.81mlTrain batch 30/32 - 175.4ms/batch - loss: 417.16670 - diff: 69.43mlTrain batch 31/32 - 175.2ms/batch - loss: 411.84895 - diff: 69.06mlTrain batch 32/32 - 53.2ms/batch - loss: 413.77951 - diff: 68.87mlTrain batch 32/32 - 11.7s 53.2ms/batch - loss: 413.77951 - diff: 68.87ml
Test 1.1s: val_loss: 414.51904 - diff: 66.64ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Systole_WideResNet50_1_Adam-0.001_MSE_DA3_best

Epoch 1: current best loss = 414.51904, at epoch 0
Train batch 1/32 - 175.5ms/batch - loss: 487.33264 - diff: 77.64mlTrain batch 2/32 - 175.3ms/batch - loss: 375.50351 - diff: 66.84mlTrain batch 3/32 - 175.4ms/batch - loss: 384.56247 - diff: 67.64mlTrain batch 4/32 - 175.2ms/batch - loss: 352.86248 - diff: 64.86mlTrain batch 5/32 - 175.4ms/batch - loss: 322.57005 - diff: 62.44mlTrain batch 6/32 - 175.2ms/batch - loss: 330.87599 - diff: 62.88mlTrain batch 7/32 - 175.2ms/batch - loss: 325.44568 - diff: 62.75mlTrain batch 8/32 - 175.4ms/batch - loss: 424.59189 - diff: 65.52mlTrain batch 9/32 - 175.4ms/batch - loss: 407.70240 - diff: 65.18mlTrain batch 10/32 - 175.4ms/batch - loss: 391.84525 - diff: 64.52mlTrain batch 11/32 - 175.7ms/batch - loss: 386.58856 - diff: 64.70mlTrain batch 12/32 - 175.5ms/batch - loss: 370.41710 - diff: 63.60mlTrain batch 13/32 - 175.7ms/batch - loss: 365.63666 - diff: 63.58mlTrain batch 14/32 - 175.7ms/batch - loss: 359.47353 - diff: 63.31mlTrain batch 15/32 - 175.6ms/batch - loss: 351.36062 - diff: 62.55mlTrain batch 16/32 - 175.4ms/batch - loss: 348.62343 - diff: 62.18mlTrain batch 17/32 - 175.6ms/batch - loss: 346.13134 - diff: 62.24mlTrain batch 18/32 - 175.6ms/batch - loss: 340.99483 - diff: 61.81mlTrain batch 19/32 - 175.8ms/batch - loss: 333.94362 - diff: 61.46mlTrain batch 20/32 - 175.6ms/batch - loss: 351.21171 - diff: 62.64mlTrain batch 21/32 - 175.8ms/batch - loss: 347.29352 - diff: 62.50mlTrain batch 22/32 - 175.5ms/batch - loss: 341.23859 - diff: 62.09mlTrain batch 23/32 - 175.8ms/batch - loss: 343.43951 - diff: 62.32mlTrain batch 24/32 - 175.7ms/batch - loss: 346.65258 - diff: 62.61mlTrain batch 25/32 - 175.7ms/batch - loss: 338.85539 - diff: 61.86mlTrain batch 26/32 - 175.5ms/batch - loss: 341.00513 - diff: 62.25mlTrain batch 27/32 - 175.7ms/batch - loss: 338.63813 - diff: 62.10mlTrain batch 28/32 - 175.7ms/batch - loss: 343.39860 - diff: 62.49mlTrain batch 29/32 - 175.5ms/batch - loss: 352.41431 - diff: 63.07mlTrain batch 30/32 - 175.8ms/batch - loss: 351.33670 - diff: 62.95mlTrain batch 31/32 - 175.7ms/batch - loss: 345.84658 - diff: 62.56mlTrain batch 32/32 - 53.4ms/batch - loss: 352.74315 - diff: 62.45mlTrain batch 32/32 - 11.6s 53.4ms/batch - loss: 352.74315 - diff: 62.45ml
Test 1.1s: val_loss: 258.52156 - diff: 52.07ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Systole_WideResNet50_1_Adam-0.001_MSE_DA3_best

Epoch 2: current best loss = 258.52156, at epoch 1
Train batch 1/32 - 191.0ms/batch - loss: 125.54981 - diff: 38.86mlTrain batch 2/32 - 178.0ms/batch - loss: 214.27112 - diff: 49.16mlTrain batch 3/32 - 175.8ms/batch - loss: 230.72609 - diff: 52.67mlTrain batch 4/32 - 175.8ms/batch - loss: 262.10851 - diff: 55.34mlTrain batch 5/32 - 175.5ms/batch - loss: 257.88378 - diff: 55.56mlTrain batch 6/32 - 175.8ms/batch - loss: 271.13693 - diff: 57.35mlTrain batch 7/32 - 175.8ms/batch - loss: 262.85042 - diff: 56.98mlTrain batch 8/32 - 175.6ms/batch - loss: 244.07195 - diff: 54.68mlTrain batch 9/32 - 175.7ms/batch - loss: 273.36605 - diff: 57.05mlTrain batch 10/32 - 175.8ms/batch - loss: 275.13070 - diff: 57.07mlTrain batch 11/32 - 176.2ms/batch - loss: 266.20354 - diff: 56.21mlTrain batch 12/32 - 175.8ms/batch - loss: 277.06694 - diff: 57.34mlTrain batch 13/32 - 175.8ms/batch - loss: 278.44055 - diff: 57.30mlTrain batch 14/32 - 175.5ms/batch - loss: 278.92232 - diff: 57.06mlTrain batch 15/32 - 175.9ms/batch - loss: 275.05014 - diff: 56.92mlTrain batch 16/32 - 175.8ms/batch - loss: 280.37846 - diff: 57.43mlTrain batch 17/32 - 176.1ms/batch - loss: 275.72910 - diff: 57.03mlTrain batch 18/32 - 176.1ms/batch - loss: 277.90803 - diff: 57.30mlTrain batch 19/32 - 176.3ms/batch - loss: 274.86704 - diff: 57.18mlTrain batch 20/32 - 175.9ms/batch - loss: 271.62286 - diff: 56.88mlTrain batch 21/32 - 175.9ms/batch - loss: 273.81670 - diff: 57.20mlTrain batch 22/32 - 175.8ms/batch - loss: 273.98632 - diff: 56.91mlTrain batch 23/32 - 176.1ms/batch - loss: 272.23105 - diff: 56.79mlTrain batch 24/32 - 176.3ms/batch - loss: 266.17438 - diff: 56.12mlTrain batch 25/32 - 176.4ms/batch - loss: 272.09572 - diff: 56.19mlTrain batch 26/32 - 176.1ms/batch - loss: 266.59886 - diff: 55.63mlTrain batch 27/32 - 176.2ms/batch - loss: 267.95290 - diff: 55.88mlTrain batch 28/32 - 176.1ms/batch - loss: 264.60400 - diff: 55.52mlTrain batch 29/32 - 176.3ms/batch - loss: 258.98852 - diff: 54.75mlTrain batch 30/32 - 176.1ms/batch - loss: 254.99851 - diff: 54.16mlTrain batch 31/32 - 176.1ms/batch - loss: 279.82864 - diff: 55.06mlTrain batch 32/32 - 53.8ms/batch - loss: 282.39088 - diff: 54.95mlTrain batch 32/32 - 11.3s 53.8ms/batch - loss: 282.39088 - diff: 54.95ml
Test 1.1s: val_loss: 224.99181 - diff: 47.99ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Systole_WideResNet50_1_Adam-0.001_MSE_DA3_best

Epoch 3: current best loss = 224.99181, at epoch 2
Train batch 1/32 - 176.1ms/batch - loss: 216.64465 - diff: 49.08mlTrain batch 2/32 - 176.2ms/batch - loss: 182.12295 - diff: 46.61mlTrain batch 3/32 - 176.1ms/batch - loss: 160.62197 - diff: 44.26mlTrain batch 4/32 - 176.2ms/batch - loss: 173.29752 - diff: 46.24mlTrain batch 5/32 - 176.3ms/batch - loss: 219.66044 - diff: 50.19mlTrain batch 6/32 - 176.0ms/batch - loss: 318.90838 - diff: 54.24mlTrain batch 7/32 - 176.2ms/batch - loss: 297.23923 - diff: 52.87mlTrain batch 8/32 - 176.1ms/batch - loss: 295.93242 - diff: 53.90mlTrain batch 9/32 - 176.1ms/batch - loss: 294.51453 - diff: 54.48mlTrain batch 10/32 - 176.2ms/batch - loss: 272.96437 - diff: 52.12mlTrain batch 11/32 - 176.1ms/batch - loss: 292.42820 - diff: 52.91mlTrain batch 12/32 - 176.3ms/batch - loss: 282.72672 - diff: 52.28mlTrain batch 13/32 - 176.2ms/batch - loss: 275.29581 - diff: 51.70mlTrain batch 14/32 - 176.1ms/batch - loss: 265.79666 - diff: 50.92mlTrain batch 15/32 - 175.9ms/batch - loss: 263.09967 - diff: 50.97mlTrain batch 16/32 - 176.4ms/batch - loss: 259.60672 - diff: 50.99mlTrain batch 17/32 - 176.3ms/batch - loss: 256.24463 - diff: 50.93mlTrain batch 18/32 - 176.4ms/batch - loss: 253.05039 - diff: 50.93mlTrain batch 19/32 - 176.4ms/batch - loss: 244.76276 - diff: 49.86mlTrain batch 20/32 - 175.8ms/batch - loss: 237.85447 - diff: 49.18mlTrain batch 21/32 - 176.1ms/batch - loss: 238.24097 - diff: 49.55mlTrain batch 22/32 - 176.4ms/batch - loss: 234.29834 - diff: 49.29mlTrain batch 23/32 - 176.0ms/batch - loss: 227.50731 - diff: 48.55mlTrain batch 24/32 - 176.1ms/batch - loss: 225.20739 - diff: 48.45mlTrain batch 25/32 - 176.6ms/batch - loss: 224.76580 - diff: 48.36mlTrain batch 26/32 - 176.1ms/batch - loss: 220.62331 - diff: 47.86mlTrain batch 27/32 - 176.3ms/batch - loss: 215.20374 - diff: 47.14mlTrain batch 28/32 - 176.1ms/batch - loss: 211.96191 - diff: 46.75mlTrain batch 29/32 - 176.3ms/batch - loss: 209.69165 - diff: 46.68mlTrain batch 30/32 - 176.2ms/batch - loss: 215.79501 - diff: 47.36mlTrain batch 31/32 - 176.2ms/batch - loss: 213.54721 - diff: 47.13mlTrain batch 32/32 - 53.7ms/batch - loss: 217.95280 - diff: 47.16mlTrain batch 32/32 - 10.9s 53.7ms/batch - loss: 217.95280 - diff: 47.16ml
Test 1.1s: val_loss: 93.58841 - diff: 27.91ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Systole_WideResNet50_1_Adam-0.001_MSE_DA3_best

Epoch 4: current best loss = 93.58841, at epoch 3
Train batch 1/32 - 189.3ms/batch - loss: 69.60384 - diff: 28.95mlTrain batch 2/32 - 176.1ms/batch - loss: 144.82428 - diff: 37.86mlTrain batch 3/32 - 175.8ms/batch - loss: 125.68910 - diff: 35.80mlTrain batch 4/32 - 176.3ms/batch - loss: 126.57190 - diff: 36.82mlTrain batch 5/32 - 176.1ms/batch - loss: 122.05504 - diff: 36.42mlTrain batch 6/32 - 176.2ms/batch - loss: 112.97215 - diff: 35.09mlTrain batch 7/32 - 176.1ms/batch - loss: 119.78364 - diff: 36.43mlTrain batch 8/32 - 176.1ms/batch - loss: 142.35012 - diff: 39.64mlTrain batch 9/32 - 176.5ms/batch - loss: 135.98874 - diff: 38.53mlTrain batch 10/32 - 176.4ms/batch - loss: 161.34091 - diff: 41.60mlTrain batch 11/32 - 176.3ms/batch - loss: 176.04419 - diff: 42.22mlTrain batch 12/32 - 176.3ms/batch - loss: 171.39906 - diff: 41.55mlTrain batch 13/32 - 176.4ms/batch - loss: 167.45586 - diff: 41.21mlTrain batch 14/32 - 176.3ms/batch - loss: 165.77194 - diff: 41.04mlTrain batch 15/32 - 176.4ms/batch - loss: 160.53671 - diff: 40.42mlTrain batch 16/32 - 176.2ms/batch - loss: 156.75058 - diff: 39.91mlTrain batch 17/32 - 176.3ms/batch - loss: 153.24849 - diff: 39.63mlTrain batch 18/32 - 176.3ms/batch - loss: 151.16028 - diff: 39.44mlTrain batch 19/32 - 177.0ms/batch - loss: 157.19186 - diff: 40.15mlTrain batch 20/32 - 176.2ms/batch - loss: 159.49584 - diff: 40.31mlTrain batch 21/32 - 176.0ms/batch - loss: 156.30540 - diff: 39.98mlTrain batch 22/32 - 176.4ms/batch - loss: 154.53967 - diff: 39.87mlTrain batch 23/32 - 176.6ms/batch - loss: 154.66076 - diff: 39.88mlTrain batch 24/32 - 176.3ms/batch - loss: 155.11008 - diff: 40.12mlTrain batch 25/32 - 176.5ms/batch - loss: 152.69838 - diff: 39.67mlTrain batch 26/32 - 176.6ms/batch - loss: 167.82410 - diff: 40.38mlTrain batch 27/32 - 176.9ms/batch - loss: 165.72355 - diff: 40.34mlTrain batch 28/32 - 176.8ms/batch - loss: 161.37918 - diff: 39.67mlTrain batch 29/32 - 176.6ms/batch - loss: 158.21126 - diff: 39.35mlTrain batch 30/32 - 176.8ms/batch - loss: 158.94872 - diff: 39.55mlTrain batch 31/32 - 176.8ms/batch - loss: 160.30999 - diff: 39.87mlTrain batch 32/32 - 53.9ms/batch - loss: 163.85777 - diff: 39.85mlTrain batch 32/32 - 11.6s 53.9ms/batch - loss: 163.85777 - diff: 39.85ml
Test 1.1s: val_loss: 68.57713 - diff: 22.53ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Systole_WideResNet50_1_Adam-0.001_MSE_DA3_best

Epoch 5: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 189.6ms/batch - loss: 139.52173 - diff: 38.87mlTrain batch 2/32 - 181.2ms/batch - loss: 122.45840 - diff: 36.02mlTrain batch 3/32 - 176.4ms/batch - loss: 107.41539 - diff: 33.66mlTrain batch 4/32 - 176.5ms/batch - loss: 100.95869 - diff: 33.07mlTrain batch 5/32 - 176.4ms/batch - loss: 93.88176 - diff: 31.87mlTrain batch 6/32 - 176.5ms/batch - loss: 89.21668 - diff: 30.97mlTrain batch 7/32 - 176.6ms/batch - loss: 90.38031 - diff: 31.66mlTrain batch 8/32 - 176.8ms/batch - loss: 98.81964 - diff: 32.78mlTrain batch 9/32 - 176.6ms/batch - loss: 96.76193 - diff: 32.54mlTrain batch 10/32 - 176.7ms/batch - loss: 102.67809 - diff: 33.03mlTrain batch 11/32 - 176.5ms/batch - loss: 95.43742 - diff: 31.44mlTrain batch 12/32 - 176.8ms/batch - loss: 94.80790 - diff: 31.65mlTrain batch 13/32 - 176.4ms/batch - loss: 94.84455 - diff: 31.96mlTrain batch 14/32 - 176.9ms/batch - loss: 96.66458 - diff: 32.29mlTrain batch 15/32 - 176.4ms/batch - loss: 97.70741 - diff: 32.50mlTrain batch 16/32 - 176.3ms/batch - loss: 115.40559 - diff: 33.44mlTrain batch 17/32 - 176.6ms/batch - loss: 113.35319 - diff: 33.35mlTrain batch 18/32 - 177.1ms/batch - loss: 110.95238 - diff: 32.92mlTrain batch 19/32 - 177.1ms/batch - loss: 109.34303 - diff: 32.53mlTrain batch 20/32 - 176.8ms/batch - loss: 109.93790 - diff: 32.81mlTrain batch 21/32 - 176.8ms/batch - loss: 106.81475 - diff: 32.29mlTrain batch 22/32 - 177.1ms/batch - loss: 105.59559 - diff: 31.96mlTrain batch 23/32 - 176.6ms/batch - loss: 106.90325 - diff: 32.32mlTrain batch 24/32 - 177.0ms/batch - loss: 107.55329 - diff: 32.38mlTrain batch 25/32 - 177.0ms/batch - loss: 114.79509 - diff: 33.40mlTrain batch 26/32 - 176.6ms/batch - loss: 112.83951 - diff: 33.08mlTrain batch 27/32 - 177.1ms/batch - loss: 131.15865 - diff: 34.06mlTrain batch 28/32 - 176.6ms/batch - loss: 128.50102 - diff: 33.80mlTrain batch 29/32 - 177.0ms/batch - loss: 125.58030 - diff: 33.32mlTrain batch 30/32 - 176.9ms/batch - loss: 125.85228 - diff: 33.44mlTrain batch 31/32 - 176.9ms/batch - loss: 125.50482 - diff: 33.53mlTrain batch 32/32 - 54.0ms/batch - loss: 125.37311 - diff: 33.42mlTrain batch 32/32 - 10.9s 54.0ms/batch - loss: 125.37311 - diff: 33.42ml
Test 1.1s: val_loss: 116.79974 - diff: 34.09ml

Epoch 6: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 177.2ms/batch - loss: 53.61992 - diff: 25.16mlTrain batch 2/32 - 177.3ms/batch - loss: 88.48686 - diff: 29.03mlTrain batch 3/32 - 177.0ms/batch - loss: 90.79490 - diff: 29.26mlTrain batch 4/32 - 177.1ms/batch - loss: 82.54339 - diff: 28.38mlTrain batch 5/32 - 176.9ms/batch - loss: 83.92158 - diff: 28.98mlTrain batch 6/32 - 177.0ms/batch - loss: 91.92437 - diff: 30.65mlTrain batch 7/32 - 176.9ms/batch - loss: 80.96838 - diff: 28.24mlTrain batch 8/32 - 177.2ms/batch - loss: 86.86322 - diff: 29.12mlTrain batch 9/32 - 177.2ms/batch - loss: 81.34745 - diff: 28.19mlTrain batch 10/32 - 176.6ms/batch - loss: 76.98336 - diff: 27.39mlTrain batch 11/32 - 176.9ms/batch - loss: 104.85399 - diff: 30.38mlTrain batch 12/32 - 176.9ms/batch - loss: 98.61128 - diff: 29.41mlTrain batch 13/32 - 177.2ms/batch - loss: 95.86304 - diff: 28.93mlTrain batch 14/32 - 177.1ms/batch - loss: 98.80105 - diff: 29.28mlTrain batch 15/32 - 176.9ms/batch - loss: 96.01211 - diff: 28.97mlTrain batch 16/32 - 177.1ms/batch - loss: 92.81737 - diff: 28.40mlTrain batch 17/32 - 177.0ms/batch - loss: 92.91649 - diff: 28.70mlTrain batch 18/32 - 177.0ms/batch - loss: 89.80712 - diff: 28.17mlTrain batch 19/32 - 177.2ms/batch - loss: 87.46657 - diff: 27.82mlTrain batch 20/32 - 177.1ms/batch - loss: 84.49163 - diff: 27.33mlTrain batch 21/32 - 177.2ms/batch - loss: 83.75846 - diff: 27.23mlTrain batch 22/32 - 177.0ms/batch - loss: 82.66227 - diff: 27.16mlTrain batch 23/32 - 176.8ms/batch - loss: 83.93723 - diff: 27.48mlTrain batch 24/32 - 177.3ms/batch - loss: 82.76467 - diff: 27.42mlTrain batch 25/32 - 177.0ms/batch - loss: 81.02920 - diff: 27.15mlTrain batch 26/32 - 177.1ms/batch - loss: 94.95582 - diff: 28.21mlTrain batch 27/32 - 177.0ms/batch - loss: 92.82446 - diff: 27.80mlTrain batch 28/32 - 177.1ms/batch - loss: 91.40454 - diff: 27.61mlTrain batch 29/32 - 177.1ms/batch - loss: 91.12151 - diff: 27.73mlTrain batch 30/32 - 177.2ms/batch - loss: 89.48067 - diff: 27.46mlTrain batch 31/32 - 176.9ms/batch - loss: 88.26909 - diff: 27.33mlTrain batch 32/32 - 54.0ms/batch - loss: 94.90475 - diff: 27.57mlTrain batch 32/32 - 10.7s 54.0ms/batch - loss: 94.90475 - diff: 27.57ml
Test 1.1s: val_loss: 739.96586 - diff: 99.11ml

Epoch 7: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 177.0ms/batch - loss: 52.94866 - diff: 22.25mlTrain batch 2/32 - 177.0ms/batch - loss: 63.18683 - diff: 24.50mlTrain batch 3/32 - 177.4ms/batch - loss: 126.43772 - diff: 26.29mlTrain batch 4/32 - 177.1ms/batch - loss: 104.20823 - diff: 24.18mlTrain batch 5/32 - 176.8ms/batch - loss: 92.76804 - diff: 23.84mlTrain batch 6/32 - 177.1ms/batch - loss: 92.57347 - diff: 24.88mlTrain batch 7/32 - 176.8ms/batch - loss: 119.32969 - diff: 26.57mlTrain batch 8/32 - 177.1ms/batch - loss: 116.00271 - diff: 27.14mlTrain batch 9/32 - 177.0ms/batch - loss: 113.42712 - diff: 27.18mlTrain batch 10/32 - 177.1ms/batch - loss: 115.40551 - diff: 27.72mlTrain batch 11/32 - 176.9ms/batch - loss: 114.20277 - diff: 28.10mlTrain batch 12/32 - 177.0ms/batch - loss: 107.67023 - diff: 27.31mlTrain batch 13/32 - 176.9ms/batch - loss: 107.57326 - diff: 27.56mlTrain batch 14/32 - 177.1ms/batch - loss: 103.12776 - diff: 26.90mlTrain batch 15/32 - 177.0ms/batch - loss: 97.91186 - diff: 26.27mlTrain batch 16/32 - 177.2ms/batch - loss: 95.03038 - diff: 26.00mlTrain batch 17/32 - 177.1ms/batch - loss: 92.63257 - diff: 25.68mlTrain batch 18/32 - 177.2ms/batch - loss: 89.27279 - diff: 25.24mlTrain batch 19/32 - 177.5ms/batch - loss: 86.93673 - diff: 25.12mlTrain batch 20/32 - 177.1ms/batch - loss: 86.35449 - diff: 25.11mlTrain batch 21/32 - 177.1ms/batch - loss: 83.48934 - diff: 24.70mlTrain batch 22/32 - 177.1ms/batch - loss: 81.90443 - diff: 24.66mlTrain batch 23/32 - 176.6ms/batch - loss: 82.79639 - diff: 24.95mlTrain batch 24/32 - 177.3ms/batch - loss: 84.77186 - diff: 25.53mlTrain batch 25/32 - 177.1ms/batch - loss: 82.10299 - diff: 24.96mlTrain batch 26/32 - 177.1ms/batch - loss: 79.96549 - diff: 24.65mlTrain batch 27/32 - 177.1ms/batch - loss: 78.35576 - diff: 24.38mlTrain batch 28/32 - 177.1ms/batch - loss: 77.05459 - diff: 24.22mlTrain batch 29/32 - 177.1ms/batch - loss: 78.35302 - diff: 24.68mlTrain batch 30/32 - 177.5ms/batch - loss: 76.72000 - diff: 24.51mlTrain batch 31/32 - 177.0ms/batch - loss: 76.57068 - diff: 24.60mlTrain batch 32/32 - 54.1ms/batch - loss: 78.87791 - diff: 24.61mlTrain batch 32/32 - 11.0s 54.1ms/batch - loss: 78.87791 - diff: 24.61ml
Test 1.1s: val_loss: 283.17507 - diff: 58.73ml

Epoch 8: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 177.0ms/batch - loss: 105.33469 - diff: 33.73mlTrain batch 2/32 - 176.6ms/batch - loss: 85.04279 - diff: 30.51mlTrain batch 3/32 - 177.1ms/batch - loss: 71.57065 - diff: 28.39mlTrain batch 4/32 - 177.1ms/batch - loss: 73.13194 - diff: 28.48mlTrain batch 5/32 - 177.1ms/batch - loss: 66.12575 - diff: 26.95mlTrain batch 6/32 - 177.1ms/batch - loss: 62.90606 - diff: 26.73mlTrain batch 7/32 - 177.1ms/batch - loss: 66.77411 - diff: 27.47mlTrain batch 8/32 - 177.3ms/batch - loss: 68.73489 - diff: 27.47mlTrain batch 9/32 - 177.2ms/batch - loss: 64.67810 - diff: 26.27mlTrain batch 10/32 - 177.3ms/batch - loss: 61.43316 - diff: 25.32mlTrain batch 11/32 - 177.1ms/batch - loss: 89.09813 - diff: 26.94mlTrain batch 12/32 - 177.6ms/batch - loss: 83.41122 - diff: 25.89mlTrain batch 13/32 - 177.5ms/batch - loss: 80.57210 - diff: 25.59mlTrain batch 14/32 - 177.5ms/batch - loss: 76.51459 - diff: 24.92mlTrain batch 15/32 - 177.3ms/batch - loss: 72.75073 - diff: 24.29mlTrain batch 16/32 - 177.1ms/batch - loss: 70.61833 - diff: 24.06mlTrain batch 17/32 - 177.3ms/batch - loss: 67.57484 - diff: 23.39mlTrain batch 18/32 - 177.4ms/batch - loss: 65.67442 - diff: 23.07mlTrain batch 19/32 - 177.8ms/batch - loss: 76.39283 - diff: 24.04mlTrain batch 20/32 - 177.5ms/batch - loss: 74.03762 - diff: 23.70mlTrain batch 21/32 - 177.5ms/batch - loss: 75.27375 - diff: 23.75mlTrain batch 22/32 - 177.4ms/batch - loss: 73.15163 - diff: 23.48mlTrain batch 23/32 - 177.5ms/batch - loss: 71.60844 - diff: 23.33mlTrain batch 24/32 - 177.8ms/batch - loss: 69.81154 - diff: 23.13mlTrain batch 25/32 - 177.6ms/batch - loss: 71.50794 - diff: 23.40mlTrain batch 26/32 - 177.0ms/batch - loss: 70.18608 - diff: 23.29mlTrain batch 27/32 - 177.4ms/batch - loss: 69.66981 - diff: 23.34mlTrain batch 28/32 - 177.1ms/batch - loss: 68.20923 - diff: 23.06mlTrain batch 29/32 - 177.5ms/batch - loss: 66.66369 - diff: 22.80mlTrain batch 30/32 - 177.8ms/batch - loss: 65.78105 - diff: 22.67mlTrain batch 31/32 - 177.1ms/batch - loss: 64.37881 - diff: 22.46mlTrain batch 32/32 - 54.5ms/batch - loss: 63.90026 - diff: 22.31mlTrain batch 32/32 - 10.8s 54.5ms/batch - loss: 63.90026 - diff: 22.31ml
Test 1.1s: val_loss: 334.86659 - diff: 64.30ml

Epoch 9: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 177.6ms/batch - loss: 40.55293 - diff: 20.03mlTrain batch 2/32 - 177.6ms/batch - loss: 30.22868 - diff: 16.95mlTrain batch 3/32 - 177.4ms/batch - loss: 34.24284 - diff: 17.34mlTrain batch 4/32 - 177.9ms/batch - loss: 42.05466 - diff: 20.00mlTrain batch 5/32 - 177.7ms/batch - loss: 43.64230 - diff: 20.78mlTrain batch 6/32 - 177.1ms/batch - loss: 41.54155 - diff: 20.17mlTrain batch 7/32 - 177.8ms/batch - loss: 39.34481 - diff: 19.82mlTrain batch 8/32 - 177.6ms/batch - loss: 58.20622 - diff: 21.49mlTrain batch 9/32 - 177.7ms/batch - loss: 57.35698 - diff: 21.48mlTrain batch 10/32 - 177.2ms/batch - loss: 56.93105 - diff: 21.48mlTrain batch 11/32 - 177.4ms/batch - loss: 54.50156 - diff: 21.19mlTrain batch 12/32 - 177.3ms/batch - loss: 55.95534 - diff: 21.52mlTrain batch 13/32 - 177.7ms/batch - loss: 71.09278 - diff: 22.31mlTrain batch 14/32 - 177.4ms/batch - loss: 67.40960 - diff: 21.82mlTrain batch 15/32 - 177.7ms/batch - loss: 70.75989 - diff: 22.62mlTrain batch 16/32 - 177.3ms/batch - loss: 67.56723 - diff: 22.14mlTrain batch 17/32 - 177.4ms/batch - loss: 67.27458 - diff: 22.32mlTrain batch 18/32 - 177.5ms/batch - loss: 66.81721 - diff: 22.57mlTrain batch 19/32 - 177.6ms/batch - loss: 65.07456 - diff: 22.32mlTrain batch 20/32 - 177.7ms/batch - loss: 65.06946 - diff: 22.50mlTrain batch 21/32 - 177.7ms/batch - loss: 64.33909 - diff: 22.58mlTrain batch 22/32 - 177.5ms/batch - loss: 65.03474 - diff: 22.81mlTrain batch 23/32 - 177.7ms/batch - loss: 63.27124 - diff: 22.46mlTrain batch 24/32 - 177.3ms/batch - loss: 62.01547 - diff: 22.33mlTrain batch 25/32 - 177.8ms/batch - loss: 62.56813 - diff: 22.43mlTrain batch 26/32 - 177.8ms/batch - loss: 61.47866 - diff: 22.17mlTrain batch 27/32 - 177.5ms/batch - loss: 60.46018 - diff: 21.98mlTrain batch 28/32 - 177.4ms/batch - loss: 59.85455 - diff: 21.88mlTrain batch 29/32 - 177.6ms/batch - loss: 59.86101 - diff: 21.92mlTrain batch 30/32 - 177.5ms/batch - loss: 58.95278 - diff: 21.80mlTrain batch 31/32 - 177.7ms/batch - loss: 58.00111 - diff: 21.70mlTrain batch 32/32 - 54.2ms/batch - loss: 58.58877 - diff: 21.63mlTrain batch 32/32 - 11.2s 54.2ms/batch - loss: 58.58877 - diff: 21.63ml
Test 1.1s: val_loss: 332.94640 - diff: 65.60ml

Epoch 10: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 177.5ms/batch - loss: 49.65993 - diff: 20.04mlTrain batch 2/32 - 177.7ms/batch - loss: 63.48869 - diff: 24.01mlTrain batch 3/32 - 177.5ms/batch - loss: 56.66161 - diff: 22.83mlTrain batch 4/32 - 177.5ms/batch - loss: 51.46562 - diff: 22.17mlTrain batch 5/32 - 177.5ms/batch - loss: 48.80099 - diff: 21.55mlTrain batch 6/32 - 177.7ms/batch - loss: 44.13815 - diff: 20.60mlTrain batch 7/32 - 177.6ms/batch - loss: 42.91321 - diff: 20.22mlTrain batch 8/32 - 177.5ms/batch - loss: 44.88057 - diff: 20.86mlTrain batch 9/32 - 177.8ms/batch - loss: 42.58427 - diff: 20.35mlTrain batch 10/32 - 177.8ms/batch - loss: 48.71121 - diff: 20.49mlTrain batch 11/32 - 177.5ms/batch - loss: 49.71288 - diff: 20.79mlTrain batch 12/32 - 177.7ms/batch - loss: 48.52091 - diff: 20.73mlTrain batch 13/32 - 177.7ms/batch - loss: 46.41596 - diff: 20.29mlTrain batch 14/32 - 177.8ms/batch - loss: 46.19986 - diff: 20.33mlTrain batch 15/32 - 177.9ms/batch - loss: 46.10179 - diff: 20.48mlTrain batch 16/32 - 177.6ms/batch - loss: 46.24945 - diff: 20.65mlTrain batch 17/32 - 177.8ms/batch - loss: 45.85489 - diff: 20.66mlTrain batch 18/32 - 177.7ms/batch - loss: 45.59352 - diff: 20.74mlTrain batch 19/32 - 177.6ms/batch - loss: 45.77566 - diff: 20.84mlTrain batch 20/32 - 177.5ms/batch - loss: 45.22509 - diff: 20.84mlTrain batch 21/32 - 177.8ms/batch - loss: 61.43105 - diff: 21.93mlTrain batch 22/32 - 177.5ms/batch - loss: 62.62231 - diff: 22.22mlTrain batch 23/32 - 177.7ms/batch - loss: 63.55566 - diff: 22.59mlTrain batch 24/32 - 177.8ms/batch - loss: 62.09473 - diff: 22.39mlTrain batch 25/32 - 177.8ms/batch - loss: 61.08491 - diff: 22.21mlTrain batch 26/32 - 177.6ms/batch - loss: 59.40968 - diff: 21.83mlTrain batch 27/32 - 177.7ms/batch - loss: 58.06777 - diff: 21.61mlTrain batch 28/32 - 177.4ms/batch - loss: 57.52185 - diff: 21.57mlTrain batch 29/32 - 177.5ms/batch - loss: 56.60121 - diff: 21.36mlTrain batch 30/32 - 177.5ms/batch - loss: 56.65447 - diff: 21.45mlTrain batch 31/32 - 177.8ms/batch - loss: 55.32327 - diff: 21.18mlTrain batch 32/32 - 54.7ms/batch - loss: 56.65371 - diff: 21.24mlTrain batch 32/32 - 10.7s 54.7ms/batch - loss: 56.65371 - diff: 21.24ml
Test 1.1s: val_loss: 874.72516 - diff: 108.74ml

Epoch 11: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 177.8ms/batch - loss: 28.75173 - diff: 17.56mlTrain batch 2/32 - 177.3ms/batch - loss: 21.69717 - diff: 15.14mlTrain batch 3/32 - 177.7ms/batch - loss: 21.46756 - diff: 15.15mlTrain batch 4/32 - 177.8ms/batch - loss: 37.67047 - diff: 18.62mlTrain batch 5/32 - 177.5ms/batch - loss: 48.03699 - diff: 20.91mlTrain batch 6/32 - 177.6ms/batch - loss: 80.98254 - diff: 24.01mlTrain batch 7/32 - 177.5ms/batch - loss: 77.63176 - diff: 24.16mlTrain batch 8/32 - 177.7ms/batch - loss: 72.07540 - diff: 23.64mlTrain batch 9/32 - 177.8ms/batch - loss: 67.24388 - diff: 23.06mlTrain batch 10/32 - 177.9ms/batch - loss: 77.01582 - diff: 23.81mlTrain batch 11/32 - 177.7ms/batch - loss: 76.69204 - diff: 24.20mlTrain batch 12/32 - 177.8ms/batch - loss: 72.44035 - diff: 23.68mlTrain batch 13/32 - 177.8ms/batch - loss: 70.47818 - diff: 23.47mlTrain batch 14/32 - 177.8ms/batch - loss: 68.26319 - diff: 23.19mlTrain batch 15/32 - 177.5ms/batch - loss: 66.02898 - diff: 22.87mlTrain batch 16/32 - 177.9ms/batch - loss: 63.66967 - diff: 22.45mlTrain batch 17/32 - 177.8ms/batch - loss: 63.15085 - diff: 22.22mlTrain batch 18/32 - 177.9ms/batch - loss: 61.52933 - diff: 22.00mlTrain batch 19/32 - 177.8ms/batch - loss: 62.38369 - diff: 22.42mlTrain batch 20/32 - 177.6ms/batch - loss: 61.07947 - diff: 22.27mlTrain batch 21/32 - 177.7ms/batch - loss: 61.60866 - diff: 22.45mlTrain batch 22/32 - 177.7ms/batch - loss: 60.71736 - diff: 22.39mlTrain batch 23/32 - 177.8ms/batch - loss: 59.50005 - diff: 22.26mlTrain batch 24/32 - 177.8ms/batch - loss: 57.82883 - diff: 21.88mlTrain batch 25/32 - 177.6ms/batch - loss: 56.23702 - diff: 21.54mlTrain batch 26/32 - 177.8ms/batch - loss: 54.95247 - diff: 21.26mlTrain batch 27/32 - 177.5ms/batch - loss: 55.14740 - diff: 21.28mlTrain batch 28/32 - 177.5ms/batch - loss: 54.04492 - diff: 21.10mlTrain batch 29/32 - 177.7ms/batch - loss: 53.31145 - diff: 21.02mlTrain batch 30/32 - 177.5ms/batch - loss: 52.77547 - diff: 21.00mlTrain batch 31/32 - 177.7ms/batch - loss: 53.16141 - diff: 21.18mlTrain batch 32/32 - 54.4ms/batch - loss: 54.04428 - diff: 21.17mlTrain batch 32/32 - 10.6s 54.4ms/batch - loss: 54.04428 - diff: 21.17ml
Test 1.1s: val_loss: 577.46980 - diff: 88.93ml

Epoch 12: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 177.8ms/batch - loss: 41.77824 - diff: 21.58mlTrain batch 2/32 - 177.9ms/batch - loss: 38.53966 - diff: 21.28mlTrain batch 3/32 - 177.5ms/batch - loss: 40.13920 - diff: 21.53mlTrain batch 4/32 - 178.0ms/batch - loss: 40.16412 - diff: 20.82mlTrain batch 5/32 - 177.6ms/batch - loss: 41.79204 - diff: 20.94mlTrain batch 6/32 - 177.2ms/batch - loss: 43.14677 - diff: 21.07mlTrain batch 7/32 - 177.6ms/batch - loss: 42.32842 - diff: 20.94mlTrain batch 8/32 - 177.5ms/batch - loss: 42.64326 - diff: 20.88mlTrain batch 9/32 - 177.6ms/batch - loss: 41.25621 - diff: 20.66mlTrain batch 10/32 - 177.3ms/batch - loss: 41.45053 - diff: 20.85mlTrain batch 11/32 - 177.7ms/batch - loss: 40.28642 - diff: 20.53mlTrain batch 12/32 - 177.4ms/batch - loss: 38.91870 - diff: 19.96mlTrain batch 13/32 - 177.7ms/batch - loss: 38.09892 - diff: 19.73mlTrain batch 14/32 - 177.9ms/batch - loss: 36.88770 - diff: 19.40mlTrain batch 15/32 - 177.6ms/batch - loss: 51.39372 - diff: 20.06mlTrain batch 16/32 - 177.6ms/batch - loss: 50.03004 - diff: 19.58mlTrain batch 17/32 - 177.7ms/batch - loss: 48.86248 - diff: 19.49mlTrain batch 18/32 - 177.7ms/batch - loss: 48.21187 - diff: 19.45mlTrain batch 19/32 - 177.6ms/batch - loss: 52.04621 - diff: 20.26mlTrain batch 20/32 - 177.8ms/batch - loss: 50.50522 - diff: 19.99mlTrain batch 21/32 - 177.4ms/batch - loss: 49.28415 - diff: 19.79mlTrain batch 22/32 - 177.8ms/batch - loss: 51.08899 - diff: 20.37mlTrain batch 23/32 - 177.8ms/batch - loss: 50.87289 - diff: 20.31mlTrain batch 24/32 - 178.0ms/batch - loss: 51.19964 - diff: 20.42mlTrain batch 25/32 - 177.5ms/batch - loss: 55.36370 - diff: 20.95mlTrain batch 26/32 - 177.8ms/batch - loss: 53.78625 - diff: 20.61mlTrain batch 27/32 - 180.0ms/batch - loss: 52.64511 - diff: 20.44mlTrain batch 28/32 - 177.9ms/batch - loss: 52.43835 - diff: 20.41mlTrain batch 29/32 - 177.6ms/batch - loss: 51.20712 - diff: 20.18mlTrain batch 30/32 - 177.7ms/batch - loss: 52.05558 - diff: 20.43mlTrain batch 31/32 - 177.6ms/batch - loss: 51.99235 - diff: 20.43mlTrain batch 32/32 - 54.3ms/batch - loss: 54.54297 - diff: 20.48mlTrain batch 32/32 - 11.5s 54.3ms/batch - loss: 54.54297 - diff: 20.48ml
Test 1.1s: val_loss: 377.18161 - diff: 70.44ml

Epoch 13: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 177.9ms/batch - loss: 22.37234 - diff: 15.25mlTrain batch 2/32 - 177.9ms/batch - loss: 26.56418 - diff: 15.71mlTrain batch 3/32 - 177.6ms/batch - loss: 32.02520 - diff: 17.47mlTrain batch 4/32 - 177.9ms/batch - loss: 31.01432 - diff: 17.53mlTrain batch 5/32 - 177.7ms/batch - loss: 31.42414 - diff: 17.92mlTrain batch 6/32 - 178.1ms/batch - loss: 36.45772 - diff: 19.28mlTrain batch 7/32 - 178.1ms/batch - loss: 34.96210 - diff: 18.77mlTrain batch 8/32 - 178.1ms/batch - loss: 32.88009 - diff: 18.18mlTrain batch 9/32 - 177.5ms/batch - loss: 34.54422 - diff: 18.57mlTrain batch 10/32 - 177.8ms/batch - loss: 33.59175 - diff: 18.33mlTrain batch 11/32 - 177.6ms/batch - loss: 34.96153 - diff: 18.36mlTrain batch 12/32 - 177.7ms/batch - loss: 34.69006 - diff: 18.33mlTrain batch 13/32 - 177.7ms/batch - loss: 35.55487 - diff: 18.54mlTrain batch 14/32 - 178.1ms/batch - loss: 34.66736 - diff: 18.33mlTrain batch 15/32 - 178.2ms/batch - loss: 37.87578 - diff: 18.71mlTrain batch 16/32 - 178.2ms/batch - loss: 38.76651 - diff: 18.91mlTrain batch 17/32 - 177.9ms/batch - loss: 39.08202 - diff: 19.01mlTrain batch 18/32 - 177.6ms/batch - loss: 53.81353 - diff: 19.77mlTrain batch 19/32 - 178.0ms/batch - loss: 52.96504 - diff: 19.64mlTrain batch 20/32 - 178.1ms/batch - loss: 51.28489 - diff: 19.42mlTrain batch 21/32 - 177.8ms/batch - loss: 50.38116 - diff: 19.37mlTrain batch 22/32 - 178.0ms/batch - loss: 49.51588 - diff: 19.38mlTrain batch 23/32 - 177.8ms/batch - loss: 48.31714 - diff: 19.20mlTrain batch 24/32 - 177.5ms/batch - loss: 48.45109 - diff: 19.39mlTrain batch 25/32 - 178.1ms/batch - loss: 47.81383 - diff: 19.32mlTrain batch 26/32 - 178.3ms/batch - loss: 47.56309 - diff: 19.21mlTrain batch 27/32 - 178.0ms/batch - loss: 47.52507 - diff: 19.35mlTrain batch 28/32 - 177.9ms/batch - loss: 52.10069 - diff: 19.92mlTrain batch 29/32 - 177.5ms/batch - loss: 51.84105 - diff: 19.92mlTrain batch 30/32 - 177.7ms/batch - loss: 52.62840 - diff: 19.99mlTrain batch 31/32 - 177.6ms/batch - loss: 52.12484 - diff: 19.92mlTrain batch 32/32 - 54.2ms/batch - loss: 52.84917 - diff: 19.92mlTrain batch 32/32 - 10.9s 54.2ms/batch - loss: 52.84917 - diff: 19.92ml
Test 1.1s: val_loss: 183.42219 - diff: 47.57ml

Epoch 14: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 177.7ms/batch - loss: 12.56710 - diff: 12.32mlTrain batch 2/32 - 177.5ms/batch - loss: 29.33768 - diff: 17.01mlTrain batch 3/32 - 177.4ms/batch - loss: 32.46009 - diff: 17.61mlTrain batch 4/32 - 177.5ms/batch - loss: 34.19529 - diff: 18.14mlTrain batch 5/32 - 178.0ms/batch - loss: 32.31639 - diff: 17.44mlTrain batch 6/32 - 177.6ms/batch - loss: 34.19898 - diff: 17.54mlTrain batch 7/32 - 178.1ms/batch - loss: 38.06368 - diff: 18.77mlTrain batch 8/32 - 177.8ms/batch - loss: 39.57159 - diff: 19.18mlTrain batch 9/32 - 177.4ms/batch - loss: 38.59994 - diff: 18.97mlTrain batch 10/32 - 177.5ms/batch - loss: 56.21688 - diff: 21.09mlTrain batch 11/32 - 177.5ms/batch - loss: 53.64605 - diff: 20.89mlTrain batch 12/32 - 177.8ms/batch - loss: 52.43289 - diff: 20.52mlTrain batch 13/32 - 178.0ms/batch - loss: 49.61400 - diff: 19.97mlTrain batch 14/32 - 177.9ms/batch - loss: 48.07051 - diff: 19.65mlTrain batch 15/32 - 177.7ms/batch - loss: 46.25950 - diff: 19.39mlTrain batch 16/32 - 177.9ms/batch - loss: 45.49460 - diff: 19.21mlTrain batch 17/32 - 177.8ms/batch - loss: 44.33164 - diff: 19.05mlTrain batch 18/32 - 178.2ms/batch - loss: 44.58995 - diff: 19.37mlTrain batch 19/32 - 177.6ms/batch - loss: 44.31484 - diff: 19.46mlTrain batch 20/32 - 177.1ms/batch - loss: 45.02001 - diff: 19.56mlTrain batch 21/32 - 178.0ms/batch - loss: 44.67629 - diff: 19.50mlTrain batch 22/32 - 178.2ms/batch - loss: 44.00814 - diff: 19.42mlTrain batch 23/32 - 177.6ms/batch - loss: 44.44871 - diff: 19.62mlTrain batch 24/32 - 177.7ms/batch - loss: 44.34086 - diff: 19.65mlTrain batch 25/32 - 177.9ms/batch - loss: 45.95585 - diff: 19.93mlTrain batch 26/32 - 178.2ms/batch - loss: 46.29816 - diff: 19.98mlTrain batch 27/32 - 177.7ms/batch - loss: 45.52608 - diff: 19.83mlTrain batch 28/32 - 178.4ms/batch - loss: 55.97839 - diff: 20.21mlTrain batch 29/32 - 177.6ms/batch - loss: 55.43435 - diff: 20.27mlTrain batch 30/32 - 177.5ms/batch - loss: 54.98633 - diff: 20.28mlTrain batch 31/32 - 177.8ms/batch - loss: 54.06503 - diff: 20.16mlTrain batch 32/32 - 54.8ms/batch - loss: 58.51674 - diff: 20.27mlTrain batch 32/32 - 10.9s 54.8ms/batch - loss: 58.51674 - diff: 20.27ml
Test 1.1s: val_loss: 530.68530 - diff: 83.74ml

Epoch 15: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 177.9ms/batch - loss: 36.67743 - diff: 20.46mlTrain batch 2/32 - 177.6ms/batch - loss: 31.56581 - diff: 18.86mlTrain batch 3/32 - 177.7ms/batch - loss: 31.02294 - diff: 18.79mlTrain batch 4/32 - 177.4ms/batch - loss: 30.62496 - diff: 18.06mlTrain batch 5/32 - 177.8ms/batch - loss: 35.31389 - diff: 18.87mlTrain batch 6/32 - 178.0ms/batch - loss: 34.01016 - diff: 18.39mlTrain batch 7/32 - 177.6ms/batch - loss: 37.24499 - diff: 19.09mlTrain batch 8/32 - 177.9ms/batch - loss: 38.83281 - diff: 19.76mlTrain batch 9/32 - 177.6ms/batch - loss: 48.38809 - diff: 20.38mlTrain batch 10/32 - 178.0ms/batch - loss: 46.80246 - diff: 20.12mlTrain batch 11/32 - 177.5ms/batch - loss: 44.89239 - diff: 19.68mlTrain batch 12/32 - 177.6ms/batch - loss: 63.25954 - diff: 21.07mlTrain batch 13/32 - 177.7ms/batch - loss: 60.62320 - diff: 20.65mlTrain batch 14/32 - 177.7ms/batch - loss: 58.25802 - diff: 20.51mlTrain batch 15/32 - 177.7ms/batch - loss: 56.96554 - diff: 20.42mlTrain batch 16/32 - 178.0ms/batch - loss: 56.65113 - diff: 20.42mlTrain batch 17/32 - 177.7ms/batch - loss: 58.27934 - diff: 20.95mlTrain batch 18/32 - 177.8ms/batch - loss: 57.93942 - diff: 21.01mlTrain batch 19/32 - 177.6ms/batch - loss: 57.30642 - diff: 20.90mlTrain batch 20/32 - 177.9ms/batch - loss: 55.37334 - diff: 20.42mlTrain batch 21/32 - 178.0ms/batch - loss: 54.19108 - diff: 20.21mlTrain batch 22/32 - 178.0ms/batch - loss: 52.99194 - diff: 20.18mlTrain batch 23/32 - 177.7ms/batch - loss: 51.54382 - diff: 19.92mlTrain batch 24/32 - 177.6ms/batch - loss: 51.13061 - diff: 19.97mlTrain batch 25/32 - 178.0ms/batch - loss: 51.44402 - diff: 20.06mlTrain batch 26/32 - 178.3ms/batch - loss: 50.11153 - diff: 19.86mlTrain batch 27/32 - 177.7ms/batch - loss: 49.11684 - diff: 19.69mlTrain batch 28/32 - 177.7ms/batch - loss: 49.33892 - diff: 19.89mlTrain batch 29/32 - 178.0ms/batch - loss: 49.02121 - diff: 19.82mlTrain batch 30/32 - 177.9ms/batch - loss: 48.34956 - diff: 19.72mlTrain batch 31/32 - 178.1ms/batch - loss: 47.75678 - diff: 19.70mlTrain batch 32/32 - 54.6ms/batch - loss: 47.82270 - diff: 19.66mlTrain batch 32/32 - 12.3s 54.6ms/batch - loss: 47.82270 - diff: 19.66ml
Test 1.1s: val_loss: 663.30266 - diff: 96.01ml
Epoch    16: reducing learning rate of group 0 to 5.0000e-04.

Epoch 16: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 177.8ms/batch - loss: 126.90169 - diff: 22.11mlTrain batch 2/32 - 177.9ms/batch - loss: 91.19734 - diff: 21.81mlTrain batch 3/32 - 177.7ms/batch - loss: 70.30178 - diff: 20.39mlTrain batch 4/32 - 177.9ms/batch - loss: 57.80921 - diff: 18.73mlTrain batch 5/32 - 178.0ms/batch - loss: 56.43377 - diff: 19.51mlTrain batch 6/32 - 178.0ms/batch - loss: 52.56570 - diff: 19.51mlTrain batch 7/32 - 177.9ms/batch - loss: 51.03864 - diff: 19.75mlTrain batch 8/32 - 177.7ms/batch - loss: 50.08888 - diff: 19.90mlTrain batch 9/32 - 177.9ms/batch - loss: 50.35688 - diff: 19.80mlTrain batch 10/32 - 177.6ms/batch - loss: 47.16436 - diff: 19.31mlTrain batch 11/32 - 177.7ms/batch - loss: 47.98261 - diff: 19.53mlTrain batch 12/32 - 177.9ms/batch - loss: 46.68301 - diff: 19.40mlTrain batch 13/32 - 177.9ms/batch - loss: 48.24936 - diff: 19.74mlTrain batch 14/32 - 177.9ms/batch - loss: 46.76166 - diff: 19.53mlTrain batch 15/32 - 177.7ms/batch - loss: 46.56074 - diff: 19.33mlTrain batch 16/32 - 177.7ms/batch - loss: 45.90886 - diff: 19.24mlTrain batch 17/32 - 178.2ms/batch - loss: 45.30985 - diff: 19.28mlTrain batch 18/32 - 178.0ms/batch - loss: 44.40162 - diff: 19.12mlTrain batch 19/32 - 177.9ms/batch - loss: 51.37170 - diff: 19.52mlTrain batch 20/32 - 177.7ms/batch - loss: 50.01065 - diff: 19.31mlTrain batch 21/32 - 178.0ms/batch - loss: 49.26775 - diff: 19.17mlTrain batch 22/32 - 177.7ms/batch - loss: 48.45588 - diff: 19.07mlTrain batch 23/32 - 177.4ms/batch - loss: 48.31815 - diff: 19.25mlTrain batch 24/32 - 177.9ms/batch - loss: 48.36657 - diff: 19.29mlTrain batch 25/32 - 178.0ms/batch - loss: 47.87471 - diff: 19.23mlTrain batch 26/32 - 177.9ms/batch - loss: 47.57622 - diff: 19.30mlTrain batch 27/32 - 178.2ms/batch - loss: 47.63535 - diff: 19.49mlTrain batch 28/32 - 178.4ms/batch - loss: 46.86940 - diff: 19.34mlTrain batch 29/32 - 178.5ms/batch - loss: 47.38421 - diff: 19.50mlTrain batch 30/32 - 178.1ms/batch - loss: 46.36921 - diff: 19.24mlTrain batch 31/32 - 178.4ms/batch - loss: 45.46023 - diff: 19.10mlTrain batch 32/32 - 54.5ms/batch - loss: 46.30525 - diff: 19.13mlTrain batch 32/32 - 11.6s 54.5ms/batch - loss: 46.30525 - diff: 19.13ml
Test 1.1s: val_loss: 680.09539 - diff: 95.86ml

Epoch 17: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 178.3ms/batch - loss: 22.96477 - diff: 15.91mlTrain batch 2/32 - 178.2ms/batch - loss: 25.14472 - diff: 16.86mlTrain batch 3/32 - 178.2ms/batch - loss: 26.40368 - diff: 17.45mlTrain batch 4/32 - 178.2ms/batch - loss: 24.46601 - diff: 16.73mlTrain batch 5/32 - 178.1ms/batch - loss: 23.89673 - diff: 16.50mlTrain batch 6/32 - 178.1ms/batch - loss: 44.80993 - diff: 18.41mlTrain batch 7/32 - 178.5ms/batch - loss: 42.92196 - diff: 18.45mlTrain batch 8/32 - 178.2ms/batch - loss: 46.41268 - diff: 19.02mlTrain batch 9/32 - 177.6ms/batch - loss: 43.25159 - diff: 18.55mlTrain batch 10/32 - 178.1ms/batch - loss: 41.53257 - diff: 18.39mlTrain batch 11/32 - 178.2ms/batch - loss: 40.84094 - diff: 18.39mlTrain batch 12/32 - 178.4ms/batch - loss: 51.46988 - diff: 18.91mlTrain batch 13/32 - 178.3ms/batch - loss: 49.57666 - diff: 18.66mlTrain batch 14/32 - 178.3ms/batch - loss: 49.23507 - diff: 18.93mlTrain batch 15/32 - 178.1ms/batch - loss: 46.98601 - diff: 18.41mlTrain batch 16/32 - 178.1ms/batch - loss: 46.90905 - diff: 18.71mlTrain batch 17/32 - 178.4ms/batch - loss: 45.58427 - diff: 18.50mlTrain batch 18/32 - 178.2ms/batch - loss: 46.11426 - diff: 18.51mlTrain batch 19/32 - 178.2ms/batch - loss: 45.66891 - diff: 18.68mlTrain batch 20/32 - 178.2ms/batch - loss: 43.83654 - diff: 18.22mlTrain batch 21/32 - 178.2ms/batch - loss: 43.04573 - diff: 18.07mlTrain batch 22/32 - 178.0ms/batch - loss: 42.17397 - diff: 17.84mlTrain batch 23/32 - 178.0ms/batch - loss: 41.43440 - diff: 17.80mlTrain batch 24/32 - 178.2ms/batch - loss: 41.04235 - diff: 17.83mlTrain batch 25/32 - 178.2ms/batch - loss: 40.75338 - diff: 17.84mlTrain batch 26/32 - 178.2ms/batch - loss: 40.97540 - diff: 17.98mlTrain batch 27/32 - 178.1ms/batch - loss: 40.81794 - diff: 17.94mlTrain batch 28/32 - 178.2ms/batch - loss: 40.12654 - diff: 17.84mlTrain batch 29/32 - 178.2ms/batch - loss: 39.72248 - diff: 17.82mlTrain batch 30/32 - 178.4ms/batch - loss: 41.48683 - diff: 18.11mlTrain batch 31/32 - 178.1ms/batch - loss: 40.72785 - diff: 17.95mlTrain batch 32/32 - 54.5ms/batch - loss: 40.70737 - diff: 17.90mlTrain batch 32/32 - 11.3s 54.5ms/batch - loss: 40.70737 - diff: 17.90ml
Test 1.1s: val_loss: 787.75829 - diff: 102.22ml

Epoch 18: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 178.1ms/batch - loss: 21.87779 - diff: 16.13mlTrain batch 2/32 - 178.3ms/batch - loss: 29.64856 - diff: 18.16mlTrain batch 3/32 - 178.1ms/batch - loss: 29.28223 - diff: 17.99mlTrain batch 4/32 - 178.6ms/batch - loss: 27.65445 - diff: 16.79mlTrain batch 5/32 - 178.0ms/batch - loss: 26.31549 - diff: 16.61mlTrain batch 6/32 - 177.7ms/batch - loss: 27.04669 - diff: 16.68mlTrain batch 7/32 - 178.1ms/batch - loss: 27.33499 - diff: 16.93mlTrain batch 8/32 - 178.4ms/batch - loss: 28.00587 - diff: 16.96mlTrain batch 9/32 - 178.2ms/batch - loss: 29.29636 - diff: 17.34mlTrain batch 10/32 - 178.3ms/batch - loss: 29.86119 - diff: 17.55mlTrain batch 11/32 - 178.2ms/batch - loss: 30.68593 - diff: 17.75mlTrain batch 12/32 - 178.5ms/batch - loss: 30.93885 - diff: 17.87mlTrain batch 13/32 - 177.9ms/batch - loss: 31.06958 - diff: 17.81mlTrain batch 14/32 - 177.6ms/batch - loss: 30.29369 - diff: 17.48mlTrain batch 15/32 - 178.2ms/batch - loss: 38.27099 - diff: 17.90mlTrain batch 16/32 - 177.7ms/batch - loss: 37.18087 - diff: 17.67mlTrain batch 17/32 - 178.4ms/batch - loss: 36.76809 - diff: 17.69mlTrain batch 18/32 - 178.5ms/batch - loss: 36.46798 - diff: 17.72mlTrain batch 19/32 - 178.1ms/batch - loss: 36.75890 - diff: 17.97mlTrain batch 20/32 - 178.1ms/batch - loss: 36.14934 - diff: 17.77mlTrain batch 21/32 - 178.3ms/batch - loss: 35.56359 - diff: 17.68mlTrain batch 22/32 - 178.3ms/batch - loss: 36.90508 - diff: 18.05mlTrain batch 23/32 - 178.1ms/batch - loss: 36.87147 - diff: 18.12mlTrain batch 24/32 - 178.5ms/batch - loss: 36.72430 - diff: 18.09mlTrain batch 25/32 - 178.3ms/batch - loss: 36.68273 - diff: 18.14mlTrain batch 26/32 - 178.2ms/batch - loss: 36.79148 - diff: 18.26mlTrain batch 27/32 - 178.0ms/batch - loss: 43.68389 - diff: 18.90mlTrain batch 28/32 - 178.2ms/batch - loss: 43.27078 - diff: 18.89mlTrain batch 29/32 - 178.1ms/batch - loss: 42.43174 - diff: 18.59mlTrain batch 30/32 - 178.6ms/batch - loss: 41.66156 - diff: 18.43mlTrain batch 31/32 - 178.0ms/batch - loss: 41.63650 - diff: 18.50mlTrain batch 32/32 - 54.5ms/batch - loss: 43.74320 - diff: 18.58mlTrain batch 32/32 - 11.1s 54.5ms/batch - loss: 43.74320 - diff: 18.58ml
Test 1.1s: val_loss: 484.97881 - diff: 80.10ml

Epoch 19: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 178.2ms/batch - loss: 34.05513 - diff: 16.85mlTrain batch 2/32 - 178.2ms/batch - loss: 34.86393 - diff: 17.96mlTrain batch 3/32 - 178.2ms/batch - loss: 29.08055 - diff: 16.46mlTrain batch 4/32 - 178.1ms/batch - loss: 32.31559 - diff: 17.42mlTrain batch 5/32 - 178.3ms/batch - loss: 32.09992 - diff: 17.25mlTrain batch 6/32 - 178.4ms/batch - loss: 33.02658 - diff: 17.78mlTrain batch 7/32 - 178.3ms/batch - loss: 32.62977 - diff: 17.94mlTrain batch 8/32 - 178.4ms/batch - loss: 31.10501 - diff: 17.53mlTrain batch 9/32 - 178.1ms/batch - loss: 33.05433 - diff: 17.61mlTrain batch 10/32 - 178.4ms/batch - loss: 55.95449 - diff: 19.00mlTrain batch 11/32 - 178.3ms/batch - loss: 61.71689 - diff: 19.59mlTrain batch 12/32 - 178.4ms/batch - loss: 58.77883 - diff: 19.44mlTrain batch 13/32 - 178.4ms/batch - loss: 56.58635 - diff: 19.31mlTrain batch 14/32 - 178.4ms/batch - loss: 54.91057 - diff: 19.29mlTrain batch 15/32 - 178.1ms/batch - loss: 54.43681 - diff: 19.22mlTrain batch 16/32 - 178.3ms/batch - loss: 53.27087 - diff: 19.12mlTrain batch 17/32 - 178.1ms/batch - loss: 51.04210 - diff: 18.74mlTrain batch 18/32 - 178.5ms/batch - loss: 49.35946 - diff: 18.48mlTrain batch 19/32 - 178.1ms/batch - loss: 50.05573 - diff: 18.79mlTrain batch 20/32 - 178.3ms/batch - loss: 49.14181 - diff: 18.77mlTrain batch 21/32 - 178.1ms/batch - loss: 48.99311 - diff: 19.03mlTrain batch 22/32 - 178.3ms/batch - loss: 47.68657 - diff: 18.87mlTrain batch 23/32 - 178.1ms/batch - loss: 47.06723 - diff: 18.82mlTrain batch 24/32 - 178.4ms/batch - loss: 45.93093 - diff: 18.68mlTrain batch 25/32 - 178.2ms/batch - loss: 46.55328 - diff: 18.62mlTrain batch 26/32 - 177.8ms/batch - loss: 46.03194 - diff: 18.60mlTrain batch 27/32 - 178.1ms/batch - loss: 44.88343 - diff: 18.35mlTrain batch 28/32 - 177.9ms/batch - loss: 45.36015 - diff: 18.57mlTrain batch 29/32 - 178.3ms/batch - loss: 45.02142 - diff: 18.55mlTrain batch 30/32 - 178.6ms/batch - loss: 44.32792 - diff: 18.43mlTrain batch 31/32 - 178.1ms/batch - loss: 43.30644 - diff: 18.16mlTrain batch 32/32 - 54.6ms/batch - loss: 49.32977 - diff: 18.38mlTrain batch 32/32 - 10.7s 54.6ms/batch - loss: 49.32977 - diff: 18.38ml
Test 1.1s: val_loss: 391.82510 - diff: 71.92ml

Epoch 20: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 178.4ms/batch - loss: 25.36167 - diff: 17.45mlTrain batch 2/32 - 178.3ms/batch - loss: 30.31023 - diff: 18.12mlTrain batch 3/32 - 178.3ms/batch - loss: 30.78475 - diff: 18.48mlTrain batch 4/32 - 178.1ms/batch - loss: 38.05958 - diff: 20.23mlTrain batch 5/32 - 178.2ms/batch - loss: 34.68276 - diff: 19.37mlTrain batch 6/32 - 178.3ms/batch - loss: 34.57519 - diff: 18.96mlTrain batch 7/32 - 178.2ms/batch - loss: 32.54435 - diff: 18.23mlTrain batch 8/32 - 178.2ms/batch - loss: 33.33940 - diff: 18.40mlTrain batch 9/32 - 178.2ms/batch - loss: 33.60134 - diff: 18.48mlTrain batch 10/32 - 178.2ms/batch - loss: 32.83458 - diff: 18.32mlTrain batch 11/32 - 178.5ms/batch - loss: 36.28122 - diff: 19.02mlTrain batch 12/32 - 178.1ms/batch - loss: 37.08499 - diff: 19.19mlTrain batch 13/32 - 178.4ms/batch - loss: 37.25745 - diff: 19.22mlTrain batch 14/32 - 178.2ms/batch - loss: 36.64202 - diff: 19.07mlTrain batch 15/32 - 178.3ms/batch - loss: 39.88117 - diff: 19.43mlTrain batch 16/32 - 178.3ms/batch - loss: 39.19190 - diff: 19.33mlTrain batch 17/32 - 178.2ms/batch - loss: 41.11566 - diff: 19.66mlTrain batch 18/32 - 178.0ms/batch - loss: 41.48117 - diff: 19.86mlTrain batch 19/32 - 177.9ms/batch - loss: 41.59855 - diff: 19.61mlTrain batch 20/32 - 178.3ms/batch - loss: 40.27857 - diff: 19.21mlTrain batch 21/32 - 178.2ms/batch - loss: 40.17758 - diff: 19.29mlTrain batch 22/32 - 178.2ms/batch - loss: 39.77455 - diff: 19.26mlTrain batch 23/32 - 178.5ms/batch - loss: 39.20262 - diff: 19.13mlTrain batch 24/32 - 178.2ms/batch - loss: 48.62256 - diff: 19.77mlTrain batch 25/32 - 178.7ms/batch - loss: 47.64793 - diff: 19.67mlTrain batch 26/32 - 178.2ms/batch - loss: 54.41493 - diff: 20.15mlTrain batch 27/32 - 178.5ms/batch - loss: 53.48969 - diff: 20.05mlTrain batch 28/32 - 178.1ms/batch - loss: 55.54251 - diff: 20.52mlTrain batch 29/32 - 177.6ms/batch - loss: 55.27199 - diff: 20.59mlTrain batch 30/32 - 178.1ms/batch - loss: 54.16774 - diff: 20.45mlTrain batch 31/32 - 178.4ms/batch - loss: 54.03830 - diff: 20.48mlTrain batch 32/32 - 54.5ms/batch - loss: 55.34213 - diff: 20.51mlTrain batch 32/32 - 10.8s 54.5ms/batch - loss: 55.34213 - diff: 20.51ml
Test 1.1s: val_loss: 550.02516 - diff: 85.09ml

Epoch 21: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 178.2ms/batch - loss: 27.45432 - diff: 17.40mlTrain batch 2/32 - 178.3ms/batch - loss: 35.69506 - diff: 19.01mlTrain batch 3/32 - 178.2ms/batch - loss: 36.75608 - diff: 17.66mlTrain batch 4/32 - 178.4ms/batch - loss: 33.48426 - diff: 17.85mlTrain batch 5/32 - 178.0ms/batch - loss: 30.02487 - diff: 16.95mlTrain batch 6/32 - 178.7ms/batch - loss: 28.66556 - diff: 16.67mlTrain batch 7/32 - 178.3ms/batch - loss: 33.37113 - diff: 18.07mlTrain batch 8/32 - 178.4ms/batch - loss: 33.58617 - diff: 17.82mlTrain batch 9/32 - 178.3ms/batch - loss: 32.85166 - diff: 17.82mlTrain batch 10/32 - 178.4ms/batch - loss: 34.46102 - diff: 18.05mlTrain batch 11/32 - 178.2ms/batch - loss: 33.41693 - diff: 17.85mlTrain batch 12/32 - 178.4ms/batch - loss: 32.61878 - diff: 17.64mlTrain batch 13/32 - 178.0ms/batch - loss: 32.05511 - diff: 17.48mlTrain batch 14/32 - 177.8ms/batch - loss: 33.07804 - diff: 17.76mlTrain batch 15/32 - 178.2ms/batch - loss: 31.83171 - diff: 17.38mlTrain batch 16/32 - 178.2ms/batch - loss: 31.96172 - diff: 17.53mlTrain batch 17/32 - 178.5ms/batch - loss: 32.25469 - diff: 17.57mlTrain batch 18/32 - 178.5ms/batch - loss: 31.43679 - diff: 17.30mlTrain batch 19/32 - 178.4ms/batch - loss: 32.98813 - diff: 17.59mlTrain batch 20/32 - 178.4ms/batch - loss: 34.01916 - diff: 17.96mlTrain batch 21/32 - 178.2ms/batch - loss: 33.34399 - diff: 17.84mlTrain batch 22/32 - 178.3ms/batch - loss: 36.63744 - diff: 18.15mlTrain batch 23/32 - 178.4ms/batch - loss: 36.57155 - diff: 18.18mlTrain batch 24/32 - 178.4ms/batch - loss: 36.27970 - diff: 18.19mlTrain batch 25/32 - 178.3ms/batch - loss: 35.37266 - diff: 17.96mlTrain batch 26/32 - 178.8ms/batch - loss: 34.43792 - diff: 17.70mlTrain batch 27/32 - 178.1ms/batch - loss: 33.97889 - diff: 17.66mlTrain batch 28/32 - 178.4ms/batch - loss: 34.22526 - diff: 17.76mlTrain batch 29/32 - 178.2ms/batch - loss: 33.94328 - diff: 17.72mlTrain batch 30/32 - 178.3ms/batch - loss: 42.07782 - diff: 18.63mlTrain batch 31/32 - 178.1ms/batch - loss: 42.26675 - diff: 18.76mlTrain batch 32/32 - 54.5ms/batch - loss: 43.61313 - diff: 18.84mlTrain batch 32/32 - 10.9s 54.5ms/batch - loss: 43.61313 - diff: 18.84ml
Test 1.1s: val_loss: 781.90107 - diff: 102.24ml

Epoch 22: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 178.2ms/batch - loss: 17.22656 - diff: 13.44mlTrain batch 2/32 - 178.5ms/batch - loss: 24.03806 - diff: 15.60mlTrain batch 3/32 - 178.0ms/batch - loss: 27.47442 - diff: 16.06mlTrain batch 4/32 - 178.5ms/batch - loss: 39.83774 - diff: 17.72mlTrain batch 5/32 - 178.3ms/batch - loss: 36.39863 - diff: 17.09mlTrain batch 6/32 - 177.9ms/batch - loss: 35.56179 - diff: 17.20mlTrain batch 7/32 - 178.4ms/batch - loss: 35.90181 - diff: 17.46mlTrain batch 8/32 - 177.9ms/batch - loss: 35.48928 - diff: 17.76mlTrain batch 9/32 - 178.3ms/batch - loss: 33.80472 - diff: 17.25mlTrain batch 10/32 - 178.5ms/batch - loss: 33.11385 - diff: 17.07mlTrain batch 11/32 - 178.3ms/batch - loss: 32.04964 - diff: 16.88mlTrain batch 12/32 - 178.4ms/batch - loss: 30.88802 - diff: 16.59mlTrain batch 13/32 - 178.0ms/batch - loss: 29.96147 - diff: 16.43mlTrain batch 14/32 - 178.0ms/batch - loss: 30.16621 - diff: 16.54mlTrain batch 15/32 - 178.3ms/batch - loss: 29.56679 - diff: 16.33mlTrain batch 16/32 - 178.3ms/batch - loss: 28.39259 - diff: 16.04mlTrain batch 17/32 - 178.4ms/batch - loss: 27.47131 - diff: 15.71mlTrain batch 18/32 - 178.5ms/batch - loss: 26.95103 - diff: 15.59mlTrain batch 19/32 - 178.0ms/batch - loss: 32.74689 - diff: 16.19mlTrain batch 20/32 - 178.2ms/batch - loss: 32.59616 - diff: 16.13mlTrain batch 21/32 - 178.1ms/batch - loss: 32.66359 - diff: 16.25mlTrain batch 22/32 - 178.4ms/batch - loss: 34.76578 - diff: 16.90mlTrain batch 23/32 - 178.3ms/batch - loss: 36.86281 - diff: 17.45mlTrain batch 24/32 - 178.4ms/batch - loss: 36.85541 - diff: 17.63mlTrain batch 25/32 - 178.3ms/batch - loss: 36.84900 - diff: 17.69mlTrain batch 26/32 - 178.3ms/batch - loss: 36.89070 - diff: 17.76mlTrain batch 27/32 - 178.1ms/batch - loss: 43.53726 - diff: 18.29mlTrain batch 28/32 - 178.3ms/batch - loss: 42.99775 - diff: 18.27mlTrain batch 29/32 - 178.0ms/batch - loss: 42.14516 - diff: 18.15mlTrain batch 30/32 - 178.6ms/batch - loss: 42.34905 - diff: 18.27mlTrain batch 31/32 - 178.2ms/batch - loss: 42.00796 - diff: 18.24mlTrain batch 32/32 - 54.4ms/batch - loss: 45.01304 - diff: 18.36mlTrain batch 32/32 - 11.7s 54.4ms/batch - loss: 45.01304 - diff: 18.36ml
Test 1.1s: val_loss: 660.10421 - diff: 94.74ml

Epoch 23: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 178.1ms/batch - loss: 24.25087 - diff: 17.20mlTrain batch 2/32 - 178.4ms/batch - loss: 87.35870 - diff: 20.66mlTrain batch 3/32 - 178.2ms/batch - loss: 64.05533 - diff: 18.35mlTrain batch 4/32 - 178.4ms/batch - loss: 57.21363 - diff: 18.97mlTrain batch 5/32 - 178.3ms/batch - loss: 50.89423 - diff: 18.45mlTrain batch 6/32 - 178.2ms/batch - loss: 45.91041 - diff: 17.70mlTrain batch 7/32 - 178.2ms/batch - loss: 42.45496 - diff: 17.27mlTrain batch 8/32 - 178.3ms/batch - loss: 41.79190 - diff: 17.35mlTrain batch 9/32 - 178.3ms/batch - loss: 38.44071 - diff: 16.75mlTrain batch 10/32 - 178.1ms/batch - loss: 39.76482 - diff: 17.73mlTrain batch 11/32 - 178.8ms/batch - loss: 38.42913 - diff: 17.69mlTrain batch 12/32 - 178.6ms/batch - loss: 39.55613 - diff: 18.35mlTrain batch 13/32 - 178.5ms/batch - loss: 39.31425 - diff: 18.27mlTrain batch 14/32 - 178.2ms/batch - loss: 45.93306 - diff: 19.41mlTrain batch 15/32 - 178.5ms/batch - loss: 44.66781 - diff: 19.32mlTrain batch 16/32 - 178.3ms/batch - loss: 45.05044 - diff: 19.31mlTrain batch 17/32 - 178.2ms/batch - loss: 44.20751 - diff: 19.20mlTrain batch 18/32 - 178.4ms/batch - loss: 43.84223 - diff: 19.16mlTrain batch 19/32 - 178.5ms/batch - loss: 42.81929 - diff: 18.94mlTrain batch 20/32 - 178.6ms/batch - loss: 43.31771 - diff: 19.20mlTrain batch 21/32 - 178.3ms/batch - loss: 42.69462 - diff: 19.21mlTrain batch 22/32 - 178.2ms/batch - loss: 41.96495 - diff: 19.04mlTrain batch 23/32 - 178.4ms/batch - loss: 41.79536 - diff: 19.10mlTrain batch 24/32 - 178.2ms/batch - loss: 41.04845 - diff: 18.95mlTrain batch 25/32 - 178.5ms/batch - loss: 41.33958 - diff: 18.96mlTrain batch 26/32 - 178.3ms/batch - loss: 40.63154 - diff: 18.76mlTrain batch 27/32 - 178.5ms/batch - loss: 39.79022 - diff: 18.54mlTrain batch 28/32 - 178.3ms/batch - loss: 39.14402 - diff: 18.37mlTrain batch 29/32 - 178.2ms/batch - loss: 39.77642 - diff: 18.53mlTrain batch 30/32 - 178.0ms/batch - loss: 39.58057 - diff: 18.52mlTrain batch 31/32 - 178.3ms/batch - loss: 39.54996 - diff: 18.56mlTrain batch 32/32 - 54.5ms/batch - loss: 40.91406 - diff: 18.63mlTrain batch 32/32 - 11.1s 54.5ms/batch - loss: 40.91406 - diff: 18.63ml
Test 1.1s: val_loss: 915.82804 - diff: 112.18ml

Epoch 24: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 178.1ms/batch - loss: 36.32257 - diff: 20.51mlTrain batch 2/32 - 178.4ms/batch - loss: 70.67244 - diff: 24.35mlTrain batch 3/32 - 178.2ms/batch - loss: 59.45596 - diff: 22.69mlTrain batch 4/32 - 178.0ms/batch - loss: 57.74726 - diff: 22.30mlTrain batch 5/32 - 178.3ms/batch - loss: 51.34572 - diff: 20.59mlTrain batch 6/32 - 178.1ms/batch - loss: 52.71129 - diff: 20.71mlTrain batch 7/32 - 178.1ms/batch - loss: 51.33190 - diff: 20.94mlTrain batch 8/32 - 178.4ms/batch - loss: 46.95076 - diff: 19.95mlTrain batch 9/32 - 178.3ms/batch - loss: 44.18236 - diff: 19.34mlTrain batch 10/32 - 178.0ms/batch - loss: 41.40478 - diff: 18.77mlTrain batch 11/32 - 178.0ms/batch - loss: 39.23343 - diff: 18.39mlTrain batch 12/32 - 178.4ms/batch - loss: 38.21766 - diff: 18.34mlTrain batch 13/32 - 178.5ms/batch - loss: 37.13709 - diff: 18.18mlTrain batch 14/32 - 178.3ms/batch - loss: 36.52655 - diff: 17.99mlTrain batch 15/32 - 178.3ms/batch - loss: 42.92665 - diff: 19.20mlTrain batch 16/32 - 178.2ms/batch - loss: 40.92424 - diff: 18.67mlTrain batch 17/32 - 177.7ms/batch - loss: 41.16331 - diff: 18.88mlTrain batch 18/32 - 178.2ms/batch - loss: 40.21814 - diff: 18.67mlTrain batch 19/32 - 178.4ms/batch - loss: 39.67805 - diff: 18.68mlTrain batch 20/32 - 178.2ms/batch - loss: 39.47810 - diff: 18.75mlTrain batch 21/32 - 178.5ms/batch - loss: 38.78923 - diff: 18.69mlTrain batch 22/32 - 178.2ms/batch - loss: 38.49143 - diff: 18.66mlTrain batch 23/32 - 178.1ms/batch - loss: 37.57919 - diff: 18.35mlTrain batch 24/32 - 178.2ms/batch - loss: 42.89747 - diff: 18.82mlTrain batch 25/32 - 178.4ms/batch - loss: 43.57972 - diff: 19.14mlTrain batch 26/32 - 178.2ms/batch - loss: 42.47636 - diff: 18.90mlTrain batch 27/32 - 178.5ms/batch - loss: 42.29415 - diff: 18.97mlTrain batch 28/32 - 178.0ms/batch - loss: 44.07768 - diff: 19.01mlTrain batch 29/32 - 178.4ms/batch - loss: 43.72578 - diff: 19.05mlTrain batch 30/32 - 178.5ms/batch - loss: 43.80565 - diff: 19.09mlTrain batch 31/32 - 178.1ms/batch - loss: 43.15665 - diff: 18.94mlTrain batch 32/32 - 54.5ms/batch - loss: 43.41664 - diff: 18.90mlTrain batch 32/32 - 11.0s 54.5ms/batch - loss: 43.41664 - diff: 18.90ml
Test 1.1s: val_loss: 687.60164 - diff: 96.53ml

Epoch 25: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 178.3ms/batch - loss: 33.80417 - diff: 18.04mlTrain batch 2/32 - 178.3ms/batch - loss: 28.13349 - diff: 16.84mlTrain batch 3/32 - 178.1ms/batch - loss: 30.47262 - diff: 17.49mlTrain batch 4/32 - 178.4ms/batch - loss: 30.21211 - diff: 17.76mlTrain batch 5/32 - 178.2ms/batch - loss: 27.94304 - diff: 16.86mlTrain batch 6/32 - 178.3ms/batch - loss: 30.29238 - diff: 17.69mlTrain batch 7/32 - 178.1ms/batch - loss: 33.42864 - diff: 17.55mlTrain batch 8/32 - 178.1ms/batch - loss: 31.03834 - diff: 16.77mlTrain batch 9/32 - 178.6ms/batch - loss: 30.29362 - diff: 16.75mlTrain batch 10/32 - 178.2ms/batch - loss: 32.62517 - diff: 17.16mlTrain batch 11/32 - 178.5ms/batch - loss: 31.72711 - diff: 17.08mlTrain batch 12/32 - 178.3ms/batch - loss: 32.58869 - diff: 17.49mlTrain batch 13/32 - 178.9ms/batch - loss: 31.37778 - diff: 17.13mlTrain batch 14/32 - 178.2ms/batch - loss: 30.89212 - diff: 17.06mlTrain batch 15/32 - 178.7ms/batch - loss: 31.73230 - diff: 17.21mlTrain batch 16/32 - 178.0ms/batch - loss: 31.20928 - diff: 17.16mlTrain batch 17/32 - 178.5ms/batch - loss: 30.61150 - diff: 17.07mlTrain batch 18/32 - 178.1ms/batch - loss: 31.15893 - diff: 17.22mlTrain batch 19/32 - 178.4ms/batch - loss: 30.50073 - diff: 16.98mlTrain batch 20/32 - 178.3ms/batch - loss: 35.87618 - diff: 17.41mlTrain batch 21/32 - 178.4ms/batch - loss: 35.86980 - diff: 17.36mlTrain batch 22/32 - 178.3ms/batch - loss: 35.86304 - diff: 17.43mlTrain batch 23/32 - 178.8ms/batch - loss: 44.41057 - diff: 17.90mlTrain batch 24/32 - 178.3ms/batch - loss: 43.61647 - diff: 17.84mlTrain batch 25/32 - 177.6ms/batch - loss: 43.03358 - diff: 17.89mlTrain batch 26/32 - 178.2ms/batch - loss: 42.29312 - diff: 17.79mlTrain batch 27/32 - 178.0ms/batch - loss: 41.83344 - diff: 17.77mlTrain batch 28/32 - 178.3ms/batch - loss: 41.33386 - diff: 17.76mlTrain batch 29/32 - 178.4ms/batch - loss: 41.71649 - diff: 18.01mlTrain batch 30/32 - 178.1ms/batch - loss: 42.77723 - diff: 18.22mlTrain batch 31/32 - 178.3ms/batch - loss: 41.95037 - diff: 18.10mlTrain batch 32/32 - 54.5ms/batch - loss: 42.17674 - diff: 18.08mlTrain batch 32/32 - 11.5s 54.5ms/batch - loss: 42.17674 - diff: 18.08ml
Test 1.1s: val_loss: 625.14096 - diff: 92.81ml

Epoch 26: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 178.4ms/batch - loss: 35.56231 - diff: 19.82mlTrain batch 2/32 - 178.4ms/batch - loss: 39.56843 - diff: 20.15mlTrain batch 3/32 - 178.3ms/batch - loss: 40.73277 - diff: 20.25mlTrain batch 4/32 - 178.5ms/batch - loss: 38.41044 - diff: 20.11mlTrain batch 5/32 - 178.1ms/batch - loss: 32.89087 - diff: 18.24mlTrain batch 6/32 - 178.7ms/batch - loss: 33.40896 - diff: 18.05mlTrain batch 7/32 - 178.2ms/batch - loss: 32.22045 - diff: 18.02mlTrain batch 8/32 - 178.4ms/batch - loss: 31.80536 - diff: 17.98mlTrain batch 9/32 - 178.0ms/batch - loss: 38.64606 - diff: 18.55mlTrain batch 10/32 - 178.3ms/batch - loss: 38.11044 - diff: 18.46mlTrain batch 11/32 - 178.2ms/batch - loss: 37.64775 - diff: 18.49mlTrain batch 12/32 - 178.6ms/batch - loss: 35.52124 - diff: 17.91mlTrain batch 13/32 - 178.3ms/batch - loss: 34.23053 - diff: 17.59mlTrain batch 14/32 - 178.2ms/batch - loss: 38.55811 - diff: 18.50mlTrain batch 15/32 - 178.2ms/batch - loss: 37.65566 - diff: 18.21mlTrain batch 16/32 - 178.5ms/batch - loss: 36.11623 - diff: 17.76mlTrain batch 17/32 - 178.3ms/batch - loss: 35.35127 - diff: 17.54mlTrain batch 18/32 - 178.5ms/batch - loss: 34.63179 - diff: 17.37mlTrain batch 19/32 - 178.3ms/batch - loss: 35.03592 - diff: 17.39mlTrain batch 20/32 - 177.7ms/batch - loss: 40.91903 - diff: 17.88mlTrain batch 21/32 - 178.2ms/batch - loss: 39.82910 - diff: 17.69mlTrain batch 22/32 - 178.4ms/batch - loss: 40.15947 - diff: 17.92mlTrain batch 23/32 - 178.1ms/batch - loss: 38.94609 - diff: 17.62mlTrain batch 24/32 - 178.3ms/batch - loss: 39.29627 - diff: 17.83mlTrain batch 25/32 - 178.0ms/batch - loss: 38.88058 - diff: 17.85mlTrain batch 26/32 - 178.3ms/batch - loss: 37.96896 - diff: 17.62mlTrain batch 27/32 - 178.5ms/batch - loss: 37.70816 - diff: 17.61mlTrain batch 28/32 - 178.8ms/batch - loss: 38.34541 - diff: 17.69mlTrain batch 29/32 - 178.6ms/batch - loss: 38.72878 - diff: 17.90mlTrain batch 30/32 - 178.4ms/batch - loss: 38.90429 - diff: 18.04mlTrain batch 31/32 - 178.2ms/batch - loss: 38.20911 - diff: 17.92mlTrain batch 32/32 - 54.5ms/batch - loss: 38.87874 - diff: 17.93mlTrain batch 32/32 - 10.5s 54.5ms/batch - loss: 38.87874 - diff: 17.93ml
Test 1.1s: val_loss: 546.11719 - diff: 85.70ml
Epoch    27: reducing learning rate of group 0 to 2.5000e-04.

Epoch 27: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 181.8ms/batch - loss: 73.20554 - diff: 29.33mlTrain batch 2/32 - 178.8ms/batch - loss: 44.10947 - diff: 20.83mlTrain batch 3/32 - 178.2ms/batch - loss: 38.68264 - diff: 19.81mlTrain batch 4/32 - 178.2ms/batch - loss: 37.97473 - diff: 19.90mlTrain batch 5/32 - 178.3ms/batch - loss: 35.23762 - diff: 19.13mlTrain batch 6/32 - 178.3ms/batch - loss: 34.81777 - diff: 18.88mlTrain batch 7/32 - 178.4ms/batch - loss: 34.57808 - diff: 18.61mlTrain batch 8/32 - 178.2ms/batch - loss: 37.64137 - diff: 19.47mlTrain batch 9/32 - 178.7ms/batch - loss: 36.97582 - diff: 19.20mlTrain batch 10/32 - 178.3ms/batch - loss: 34.87768 - diff: 18.56mlTrain batch 11/32 - 178.7ms/batch - loss: 32.84559 - diff: 17.76mlTrain batch 12/32 - 178.5ms/batch - loss: 33.46595 - diff: 17.96mlTrain batch 13/32 - 178.3ms/batch - loss: 35.07947 - diff: 18.08mlTrain batch 14/32 - 178.1ms/batch - loss: 35.11392 - diff: 18.23mlTrain batch 15/32 - 178.2ms/batch - loss: 35.35785 - diff: 18.33mlTrain batch 16/32 - 178.4ms/batch - loss: 35.25625 - diff: 18.35mlTrain batch 17/32 - 178.4ms/batch - loss: 45.31637 - diff: 19.39mlTrain batch 18/32 - 178.2ms/batch - loss: 45.26030 - diff: 19.52mlTrain batch 19/32 - 178.7ms/batch - loss: 49.48047 - diff: 19.90mlTrain batch 20/32 - 178.4ms/batch - loss: 48.23477 - diff: 19.70mlTrain batch 21/32 - 178.6ms/batch - loss: 47.57387 - diff: 19.61mlTrain batch 22/32 - 178.9ms/batch - loss: 46.68743 - diff: 19.46mlTrain batch 23/32 - 178.4ms/batch - loss: 45.63071 - diff: 19.26mlTrain batch 24/32 - 178.2ms/batch - loss: 44.74386 - diff: 19.12mlTrain batch 25/32 - 178.5ms/batch - loss: 45.23166 - diff: 19.30mlTrain batch 26/32 - 178.2ms/batch - loss: 45.72748 - diff: 19.45mlTrain batch 27/32 - 178.8ms/batch - loss: 45.08657 - diff: 19.30mlTrain batch 28/32 - 178.3ms/batch - loss: 44.01670 - diff: 19.02mlTrain batch 29/32 - 178.4ms/batch - loss: 43.52750 - diff: 18.87mlTrain batch 30/32 - 178.7ms/batch - loss: 43.46785 - diff: 18.94mlTrain batch 31/32 - 178.4ms/batch - loss: 42.60616 - diff: 18.79mlTrain batch 32/32 - 54.5ms/batch - loss: 43.01163 - diff: 18.79mlTrain batch 32/32 - 11.5s 54.5ms/batch - loss: 43.01163 - diff: 18.79ml
Test 1.1s: val_loss: 717.81317 - diff: 99.24ml

Epoch 28: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 178.5ms/batch - loss: 23.48838 - diff: 17.56mlTrain batch 2/32 - 178.1ms/batch - loss: 24.07900 - diff: 17.81mlTrain batch 3/32 - 178.2ms/batch - loss: 22.70020 - diff: 16.89mlTrain batch 4/32 - 178.6ms/batch - loss: 22.40170 - diff: 16.50mlTrain batch 5/32 - 178.4ms/batch - loss: 23.01341 - diff: 16.70mlTrain batch 6/32 - 178.5ms/batch - loss: 25.11220 - diff: 17.31mlTrain batch 7/32 - 178.4ms/batch - loss: 42.48571 - diff: 19.42mlTrain batch 8/32 - 178.3ms/batch - loss: 43.12469 - diff: 19.82mlTrain batch 9/32 - 178.2ms/batch - loss: 40.38421 - diff: 19.25mlTrain batch 10/32 - 178.2ms/batch - loss: 39.84604 - diff: 19.21mlTrain batch 11/32 - 178.5ms/batch - loss: 39.14306 - diff: 19.06mlTrain batch 12/32 - 178.5ms/batch - loss: 37.70658 - diff: 18.58mlTrain batch 13/32 - 178.2ms/batch - loss: 37.21489 - diff: 18.62mlTrain batch 14/32 - 178.4ms/batch - loss: 35.24623 - diff: 17.92mlTrain batch 15/32 - 178.3ms/batch - loss: 35.23690 - diff: 17.89mlTrain batch 16/32 - 178.3ms/batch - loss: 35.18703 - diff: 17.98mlTrain batch 17/32 - 178.4ms/batch - loss: 35.27446 - diff: 18.05mlTrain batch 18/32 - 178.4ms/batch - loss: 35.02856 - diff: 18.07mlTrain batch 19/32 - 178.3ms/batch - loss: 34.28059 - diff: 17.84mlTrain batch 20/32 - 178.6ms/batch - loss: 42.74864 - diff: 18.61mlTrain batch 21/32 - 178.5ms/batch - loss: 42.13186 - diff: 18.59mlTrain batch 22/32 - 178.4ms/batch - loss: 41.89085 - diff: 18.60mlTrain batch 23/32 - 178.6ms/batch - loss: 41.29199 - diff: 18.49mlTrain batch 24/32 - 178.8ms/batch - loss: 41.79225 - diff: 18.70mlTrain batch 25/32 - 178.4ms/batch - loss: 42.87478 - diff: 18.92mlTrain batch 26/32 - 178.0ms/batch - loss: 42.27057 - diff: 18.81mlTrain batch 27/32 - 178.2ms/batch - loss: 41.37847 - diff: 18.63mlTrain batch 28/32 - 178.6ms/batch - loss: 41.16538 - diff: 18.64mlTrain batch 29/32 - 178.1ms/batch - loss: 40.48713 - diff: 18.47mlTrain batch 30/32 - 178.3ms/batch - loss: 39.61001 - diff: 18.26mlTrain batch 31/32 - 178.2ms/batch - loss: 39.46745 - diff: 18.23mlTrain batch 32/32 - 54.6ms/batch - loss: 39.88092 - diff: 18.21mlTrain batch 32/32 - 11.1s 54.6ms/batch - loss: 39.88092 - diff: 18.21ml
Test 1.1s: val_loss: 664.77300 - diff: 94.82ml

Epoch 29: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 178.3ms/batch - loss: 25.45742 - diff: 15.48mlTrain batch 2/32 - 178.5ms/batch - loss: 18.55461 - diff: 12.73mlTrain batch 3/32 - 178.2ms/batch - loss: 21.32767 - diff: 14.02mlTrain batch 4/32 - 178.3ms/batch - loss: 19.87652 - diff: 13.71mlTrain batch 5/32 - 178.4ms/batch - loss: 22.90445 - diff: 14.39mlTrain batch 6/32 - 178.8ms/batch - loss: 27.94626 - diff: 16.09mlTrain batch 7/32 - 178.1ms/batch - loss: 26.89381 - diff: 15.80mlTrain batch 8/32 - 178.0ms/batch - loss: 25.19725 - diff: 15.27mlTrain batch 9/32 - 178.4ms/batch - loss: 28.78705 - diff: 15.74mlTrain batch 10/32 - 178.4ms/batch - loss: 29.31179 - diff: 15.74mlTrain batch 11/32 - 178.4ms/batch - loss: 30.72915 - diff: 16.22mlTrain batch 12/32 - 178.4ms/batch - loss: 30.96135 - diff: 16.41mlTrain batch 13/32 - 178.1ms/batch - loss: 33.27669 - diff: 17.26mlTrain batch 14/32 - 178.4ms/batch - loss: 32.45418 - diff: 17.09mlTrain batch 15/32 - 178.4ms/batch - loss: 32.33773 - diff: 17.19mlTrain batch 16/32 - 178.6ms/batch - loss: 31.64861 - diff: 17.13mlTrain batch 17/32 - 178.6ms/batch - loss: 31.93317 - diff: 17.31mlTrain batch 18/32 - 178.7ms/batch - loss: 34.76819 - diff: 18.02mlTrain batch 19/32 - 178.4ms/batch - loss: 33.66901 - diff: 17.71mlTrain batch 20/32 - 178.9ms/batch - loss: 33.05498 - diff: 17.53mlTrain batch 21/32 - 178.1ms/batch - loss: 32.51089 - diff: 17.30mlTrain batch 22/32 - 177.8ms/batch - loss: 32.34963 - diff: 17.16mlTrain batch 23/32 - 178.2ms/batch - loss: 37.92291 - diff: 17.61mlTrain batch 24/32 - 178.7ms/batch - loss: 37.68653 - diff: 17.68mlTrain batch 25/32 - 178.2ms/batch - loss: 37.83251 - diff: 17.84mlTrain batch 26/32 - 178.5ms/batch - loss: 39.66879 - diff: 17.90mlTrain batch 27/32 - 178.2ms/batch - loss: 38.94689 - diff: 17.82mlTrain batch 28/32 - 178.5ms/batch - loss: 39.00545 - diff: 17.89mlTrain batch 29/32 - 178.4ms/batch - loss: 38.86149 - diff: 17.90mlTrain batch 30/32 - 178.3ms/batch - loss: 38.70247 - diff: 17.92mlTrain batch 31/32 - 178.5ms/batch - loss: 37.96791 - diff: 17.78mlTrain batch 32/32 - 54.5ms/batch - loss: 38.09600 - diff: 17.71mlTrain batch 32/32 - 10.9s 54.5ms/batch - loss: 38.09600 - diff: 17.71ml
Test 1.1s: val_loss: 616.53996 - diff: 90.63ml

Epoch 30: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 178.3ms/batch - loss: 16.87723 - diff: 12.82mlTrain batch 2/32 - 178.8ms/batch - loss: 31.20433 - diff: 15.13mlTrain batch 3/32 - 178.5ms/batch - loss: 30.42109 - diff: 15.56mlTrain batch 4/32 - 178.4ms/batch - loss: 30.25844 - diff: 16.05mlTrain batch 5/32 - 178.4ms/batch - loss: 28.69984 - diff: 15.93mlTrain batch 6/32 - 177.9ms/batch - loss: 26.56699 - diff: 15.27mlTrain batch 7/32 - 178.2ms/batch - loss: 24.47157 - diff: 14.60mlTrain batch 8/32 - 178.8ms/batch - loss: 24.35421 - diff: 14.67mlTrain batch 9/32 - 178.4ms/batch - loss: 24.73323 - diff: 14.99mlTrain batch 10/32 - 178.5ms/batch - loss: 24.55339 - diff: 15.03mlTrain batch 11/32 - 178.2ms/batch - loss: 24.45372 - diff: 15.15mlTrain batch 12/32 - 177.8ms/batch - loss: 23.05899 - diff: 14.58mlTrain batch 13/32 - 178.4ms/batch - loss: 23.14118 - diff: 14.64mlTrain batch 14/32 - 178.9ms/batch - loss: 23.28571 - diff: 14.66mlTrain batch 15/32 - 178.1ms/batch - loss: 22.69775 - diff: 14.58mlTrain batch 16/32 - 178.4ms/batch - loss: 27.95295 - diff: 15.32mlTrain batch 17/32 - 178.2ms/batch - loss: 29.10283 - diff: 15.67mlTrain batch 18/32 - 178.5ms/batch - loss: 28.97888 - diff: 15.68mlTrain batch 19/32 - 178.2ms/batch - loss: 29.46329 - diff: 15.95mlTrain batch 20/32 - 178.3ms/batch - loss: 38.16312 - diff: 16.68mlTrain batch 21/32 - 178.3ms/batch - loss: 37.71930 - diff: 16.60mlTrain batch 22/32 - 178.7ms/batch - loss: 37.97407 - diff: 16.82mlTrain batch 23/32 - 178.4ms/batch - loss: 36.93261 - diff: 16.66mlTrain batch 24/32 - 178.0ms/batch - loss: 36.02129 - diff: 16.44mlTrain batch 25/32 - 178.3ms/batch - loss: 35.63085 - diff: 16.42mlTrain batch 26/32 - 178.2ms/batch - loss: 34.95732 - diff: 16.31mlTrain batch 27/32 - 178.1ms/batch - loss: 35.06594 - diff: 16.42mlTrain batch 28/32 - 178.5ms/batch - loss: 35.00448 - diff: 16.40mlTrain batch 29/32 - 178.2ms/batch - loss: 34.41852 - diff: 16.25mlTrain batch 30/32 - 178.7ms/batch - loss: 33.73408 - diff: 16.10mlTrain batch 31/32 - 178.1ms/batch - loss: 33.53608 - diff: 16.10mlTrain batch 32/32 - 54.5ms/batch - loss: 33.80008 - diff: 16.08mlTrain batch 32/32 - 11.2s 54.5ms/batch - loss: 33.80008 - diff: 16.08ml
Test 1.2s: val_loss: 526.19901 - diff: 84.65ml

Epoch 31: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 178.3ms/batch - loss: 21.22929 - diff: 14.52mlTrain batch 2/32 - 178.5ms/batch - loss: 21.11821 - diff: 14.83mlTrain batch 3/32 - 178.4ms/batch - loss: 18.45176 - diff: 13.80mlTrain batch 4/32 - 178.6ms/batch - loss: 18.52102 - diff: 13.94mlTrain batch 5/32 - 178.2ms/batch - loss: 47.04667 - diff: 16.08mlTrain batch 6/32 - 178.3ms/batch - loss: 43.02702 - diff: 15.77mlTrain batch 7/32 - 178.4ms/batch - loss: 38.89036 - diff: 15.27mlTrain batch 8/32 - 178.4ms/batch - loss: 39.22153 - diff: 16.09mlTrain batch 9/32 - 177.9ms/batch - loss: 38.42378 - diff: 16.09mlTrain batch 10/32 - 178.1ms/batch - loss: 37.42640 - diff: 16.28mlTrain batch 11/32 - 178.3ms/batch - loss: 35.84366 - diff: 16.08mlTrain batch 12/32 - 178.2ms/batch - loss: 34.28483 - diff: 15.88mlTrain batch 13/32 - 177.7ms/batch - loss: 33.29978 - diff: 15.81mlTrain batch 14/32 - 178.3ms/batch - loss: 33.28862 - diff: 15.86mlTrain batch 15/32 - 178.2ms/batch - loss: 33.10800 - diff: 15.98mlTrain batch 16/32 - 178.1ms/batch - loss: 32.64529 - diff: 15.97mlTrain batch 17/32 - 178.3ms/batch - loss: 32.10881 - diff: 15.94mlTrain batch 18/32 - 177.9ms/batch - loss: 34.27707 - diff: 16.53mlTrain batch 19/32 - 178.2ms/batch - loss: 39.35354 - diff: 17.03mlTrain batch 20/32 - 178.1ms/batch - loss: 38.85179 - diff: 17.05mlTrain batch 21/32 - 178.4ms/batch - loss: 38.37833 - diff: 17.10mlTrain batch 22/32 - 178.4ms/batch - loss: 38.11371 - diff: 17.10mlTrain batch 23/32 - 178.8ms/batch - loss: 39.25885 - diff: 17.32mlTrain batch 24/32 - 178.8ms/batch - loss: 38.99595 - diff: 17.41mlTrain batch 25/32 - 178.9ms/batch - loss: 38.70313 - diff: 17.44mlTrain batch 26/32 - 177.9ms/batch - loss: 38.00026 - diff: 17.30mlTrain batch 27/32 - 178.5ms/batch - loss: 37.30991 - diff: 17.18mlTrain batch 28/32 - 178.2ms/batch - loss: 37.52900 - diff: 17.30mlTrain batch 29/32 - 178.5ms/batch - loss: 37.22445 - diff: 17.24mlTrain batch 30/32 - 178.2ms/batch - loss: 36.98407 - diff: 17.24mlTrain batch 31/32 - 178.2ms/batch - loss: 36.69064 - diff: 17.24mlTrain batch 32/32 - 55.0ms/batch - loss: 37.69361 - diff: 17.28mlTrain batch 32/32 - 11.9s 55.0ms/batch - loss: 37.69361 - diff: 17.28ml
Test 1.1s: val_loss: 638.63998 - diff: 93.40ml

Epoch 32: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 178.3ms/batch - loss: 24.90718 - diff: 13.05mlTrain batch 2/32 - 178.7ms/batch - loss: 25.06101 - diff: 15.06mlTrain batch 3/32 - 178.6ms/batch - loss: 24.29596 - diff: 14.95mlTrain batch 4/32 - 178.8ms/batch - loss: 20.27137 - diff: 13.70mlTrain batch 5/32 - 178.5ms/batch - loss: 21.26421 - diff: 14.22mlTrain batch 6/32 - 178.4ms/batch - loss: 22.65188 - diff: 14.79mlTrain batch 7/32 - 178.3ms/batch - loss: 22.33221 - diff: 14.78mlTrain batch 8/32 - 178.2ms/batch - loss: 24.81722 - diff: 15.24mlTrain batch 9/32 - 178.6ms/batch - loss: 25.78453 - diff: 15.48mlTrain batch 10/32 - 178.9ms/batch - loss: 26.01630 - diff: 15.68mlTrain batch 11/32 - 178.6ms/batch - loss: 25.00769 - diff: 15.35mlTrain batch 12/32 - 178.8ms/batch - loss: 25.02342 - diff: 15.54mlTrain batch 13/32 - 178.2ms/batch - loss: 25.62368 - diff: 15.84mlTrain batch 14/32 - 178.3ms/batch - loss: 25.76824 - diff: 15.94mlTrain batch 15/32 - 178.4ms/batch - loss: 27.18393 - diff: 16.35mlTrain batch 16/32 - 178.5ms/batch - loss: 27.91826 - diff: 16.60mlTrain batch 17/32 - 178.7ms/batch - loss: 27.24783 - diff: 16.32mlTrain batch 18/32 - 177.9ms/batch - loss: 26.69120 - diff: 16.16mlTrain batch 19/32 - 178.3ms/batch - loss: 26.61038 - diff: 16.19mlTrain batch 20/32 - 178.4ms/batch - loss: 27.46196 - diff: 16.48mlTrain batch 21/32 - 178.5ms/batch - loss: 27.87685 - diff: 16.53mlTrain batch 22/32 - 178.9ms/batch - loss: 29.03398 - diff: 16.80mlTrain batch 23/32 - 178.0ms/batch - loss: 28.81536 - diff: 16.77mlTrain batch 24/32 - 179.0ms/batch - loss: 28.32003 - diff: 16.58mlTrain batch 25/32 - 178.7ms/batch - loss: 49.21615 - diff: 18.25mlTrain batch 26/32 - 178.0ms/batch - loss: 48.19475 - diff: 18.09mlTrain batch 27/32 - 178.2ms/batch - loss: 46.84991 - diff: 17.86mlTrain batch 28/32 - 178.6ms/batch - loss: 45.90359 - diff: 17.72mlTrain batch 29/32 - 178.4ms/batch - loss: 45.71758 - diff: 17.78mlTrain batch 30/32 - 178.6ms/batch - loss: 44.91105 - diff: 17.64mlTrain batch 31/32 - 178.8ms/batch - loss: 45.16311 - diff: 17.90mlTrain batch 32/32 - 54.6ms/batch - loss: 45.14458 - diff: 17.84mlTrain batch 32/32 - 11.1s 54.6ms/batch - loss: 45.14458 - diff: 17.84ml
Test 1.1s: val_loss: 594.27852 - diff: 89.71ml

Epoch 33: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 177.9ms/batch - loss: 13.25808 - diff: 11.27mlTrain batch 2/32 - 178.4ms/batch - loss: 17.92701 - diff: 13.47mlTrain batch 3/32 - 178.2ms/batch - loss: 17.90633 - diff: 14.03mlTrain batch 4/32 - 177.5ms/batch - loss: 22.12609 - diff: 14.99mlTrain batch 5/32 - 178.6ms/batch - loss: 35.62180 - diff: 16.76mlTrain batch 6/32 - 178.7ms/batch - loss: 32.81274 - diff: 16.25mlTrain batch 7/32 - 178.2ms/batch - loss: 30.87277 - diff: 16.06mlTrain batch 8/32 - 178.2ms/batch - loss: 30.54014 - diff: 15.93mlTrain batch 9/32 - 178.4ms/batch - loss: 30.59641 - diff: 15.98mlTrain batch 10/32 - 178.4ms/batch - loss: 30.63685 - diff: 16.19mlTrain batch 11/32 - 177.9ms/batch - loss: 31.07435 - diff: 16.33mlTrain batch 12/32 - 178.0ms/batch - loss: 31.40207 - diff: 16.42mlTrain batch 13/32 - 178.4ms/batch - loss: 30.95787 - diff: 16.43mlTrain batch 14/32 - 178.3ms/batch - loss: 31.90139 - diff: 16.66mlTrain batch 15/32 - 178.0ms/batch - loss: 31.40307 - diff: 16.58mlTrain batch 16/32 - 178.0ms/batch - loss: 31.47711 - diff: 16.67mlTrain batch 17/32 - 178.4ms/batch - loss: 31.27631 - diff: 16.80mlTrain batch 18/32 - 178.5ms/batch - loss: 31.64684 - diff: 16.93mlTrain batch 19/32 - 178.5ms/batch - loss: 33.02635 - diff: 17.22mlTrain batch 20/32 - 178.5ms/batch - loss: 32.98463 - diff: 17.24mlTrain batch 21/32 - 178.6ms/batch - loss: 32.35894 - diff: 17.10mlTrain batch 22/32 - 178.8ms/batch - loss: 33.07259 - diff: 17.30mlTrain batch 23/32 - 178.6ms/batch - loss: 32.57557 - diff: 17.18mlTrain batch 24/32 - 178.7ms/batch - loss: 32.03949 - diff: 17.11mlTrain batch 25/32 - 178.6ms/batch - loss: 32.67449 - diff: 17.39mlTrain batch 26/32 - 178.5ms/batch - loss: 32.30010 - diff: 17.30mlTrain batch 27/32 - 178.7ms/batch - loss: 31.91219 - diff: 17.21mlTrain batch 28/32 - 178.8ms/batch - loss: 31.79686 - diff: 17.26mlTrain batch 29/32 - 178.5ms/batch - loss: 31.39188 - diff: 17.12mlTrain batch 30/32 - 178.5ms/batch - loss: 31.57593 - diff: 17.19mlTrain batch 31/32 - 178.6ms/batch - loss: 38.95000 - diff: 18.10mlTrain batch 32/32 - 54.5ms/batch - loss: 42.40251 - diff: 18.23mlTrain batch 32/32 - 10.9s 54.5ms/batch - loss: 42.40251 - diff: 18.23ml
Test 1.1s: val_loss: 584.30120 - diff: 88.82ml

Epoch 34: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 178.1ms/batch - loss: 27.27310 - diff: 16.77mlTrain batch 2/32 - 178.3ms/batch - loss: 26.63997 - diff: 16.28mlTrain batch 3/32 - 178.2ms/batch - loss: 24.15873 - diff: 15.43mlTrain batch 4/32 - 177.9ms/batch - loss: 26.43972 - diff: 16.19mlTrain batch 5/32 - 178.5ms/batch - loss: 28.59262 - diff: 17.05mlTrain batch 6/32 - 178.6ms/batch - loss: 26.83612 - diff: 16.62mlTrain batch 7/32 - 178.3ms/batch - loss: 29.48960 - diff: 17.52mlTrain batch 8/32 - 178.0ms/batch - loss: 28.88858 - diff: 17.27mlTrain batch 9/32 - 178.5ms/batch - loss: 30.55837 - diff: 17.90mlTrain batch 10/32 - 179.0ms/batch - loss: 31.47294 - diff: 18.08mlTrain batch 11/32 - 178.8ms/batch - loss: 31.11167 - diff: 18.03mlTrain batch 12/32 - 178.7ms/batch - loss: 30.24225 - diff: 17.76mlTrain batch 13/32 - 178.7ms/batch - loss: 29.25791 - diff: 17.44mlTrain batch 14/32 - 179.0ms/batch - loss: 28.40417 - diff: 17.17mlTrain batch 15/32 - 178.5ms/batch - loss: 28.06867 - diff: 16.84mlTrain batch 16/32 - 178.4ms/batch - loss: 27.58566 - diff: 16.74mlTrain batch 17/32 - 178.6ms/batch - loss: 27.59602 - diff: 16.72mlTrain batch 18/32 - 178.9ms/batch - loss: 26.87595 - diff: 16.47mlTrain batch 19/32 - 178.5ms/batch - loss: 28.68976 - diff: 16.89mlTrain batch 20/32 - 178.7ms/batch - loss: 28.87889 - diff: 16.97mlTrain batch 21/32 - 178.8ms/batch - loss: 35.55716 - diff: 18.08mlTrain batch 22/32 - 178.9ms/batch - loss: 35.01345 - diff: 17.99mlTrain batch 23/32 - 178.8ms/batch - loss: 34.62641 - diff: 17.88mlTrain batch 24/32 - 178.9ms/batch - loss: 40.57223 - diff: 18.30mlTrain batch 25/32 - 178.6ms/batch - loss: 39.63953 - diff: 18.07mlTrain batch 26/32 - 178.6ms/batch - loss: 39.41307 - diff: 18.12mlTrain batch 27/32 - 178.7ms/batch - loss: 38.49145 - diff: 17.96mlTrain batch 28/32 - 178.9ms/batch - loss: 38.37967 - diff: 18.03mlTrain batch 29/32 - 178.7ms/batch - loss: 37.50939 - diff: 17.81mlTrain batch 30/32 - 178.4ms/batch - loss: 36.65627 - diff: 17.61mlTrain batch 31/32 - 178.5ms/batch - loss: 36.17992 - diff: 17.54mlTrain batch 32/32 - 54.8ms/batch - loss: 39.39155 - diff: 17.67mlTrain batch 32/32 - 11.1s 54.8ms/batch - loss: 39.39155 - diff: 17.67ml
Test 1.1s: val_loss: 502.29046 - diff: 82.07ml

Epoch 35: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 178.3ms/batch - loss: 38.17188 - diff: 18.80mlTrain batch 2/32 - 178.4ms/batch - loss: 37.57326 - diff: 19.61mlTrain batch 3/32 - 178.2ms/batch - loss: 32.95369 - diff: 18.34mlTrain batch 4/32 - 178.8ms/batch - loss: 32.10619 - diff: 18.00mlTrain batch 5/32 - 178.1ms/batch - loss: 28.22745 - diff: 16.72mlTrain batch 6/32 - 178.3ms/batch - loss: 26.77248 - diff: 16.42mlTrain batch 7/32 - 178.4ms/batch - loss: 29.56547 - diff: 17.30mlTrain batch 8/32 - 178.7ms/batch - loss: 28.65718 - diff: 17.15mlTrain batch 9/32 - 178.2ms/batch - loss: 29.60746 - diff: 17.15mlTrain batch 10/32 - 178.5ms/batch - loss: 34.53384 - diff: 18.43mlTrain batch 11/32 - 178.3ms/batch - loss: 32.92283 - diff: 17.96mlTrain batch 12/32 - 178.0ms/batch - loss: 45.12945 - diff: 18.94mlTrain batch 13/32 - 178.5ms/batch - loss: 42.71093 - diff: 18.50mlTrain batch 14/32 - 178.8ms/batch - loss: 41.41773 - diff: 18.27mlTrain batch 15/32 - 178.0ms/batch - loss: 39.41091 - diff: 17.80mlTrain batch 16/32 - 178.3ms/batch - loss: 39.03114 - diff: 17.77mlTrain batch 17/32 - 178.2ms/batch - loss: 39.37377 - diff: 17.98mlTrain batch 18/32 - 178.7ms/batch - loss: 38.76429 - diff: 17.98mlTrain batch 19/32 - 178.2ms/batch - loss: 39.67282 - diff: 18.10mlTrain batch 20/32 - 178.8ms/batch - loss: 38.93397 - diff: 18.01mlTrain batch 21/32 - 178.1ms/batch - loss: 37.99541 - diff: 17.86mlTrain batch 22/32 - 177.8ms/batch - loss: 41.27006 - diff: 18.28mlTrain batch 23/32 - 178.2ms/batch - loss: 41.11770 - diff: 18.39mlTrain batch 24/32 - 178.3ms/batch - loss: 40.75534 - diff: 18.46mlTrain batch 25/32 - 178.5ms/batch - loss: 42.74735 - diff: 18.94mlTrain batch 26/32 - 178.4ms/batch - loss: 42.59507 - diff: 18.92mlTrain batch 27/32 - 178.3ms/batch - loss: 42.51875 - diff: 18.99mlTrain batch 28/32 - 178.7ms/batch - loss: 42.48912 - diff: 19.02mlTrain batch 29/32 - 178.3ms/batch - loss: 41.95574 - diff: 18.91mlTrain batch 30/32 - 178.5ms/batch - loss: 42.19903 - diff: 19.03mlTrain batch 31/32 - 178.6ms/batch - loss: 44.95938 - diff: 19.63mlTrain batch 32/32 - 54.5ms/batch - loss: 47.49717 - diff: 19.75mlTrain batch 32/32 - 11.5s 54.5ms/batch - loss: 47.49717 - diff: 19.75ml
Test 1.1s: val_loss: 620.19125 - diff: 91.69ml

Epoch 36: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 178.3ms/batch - loss: 66.14064 - diff: 20.58mlTrain batch 2/32 - 178.6ms/batch - loss: 44.96370 - diff: 18.39mlTrain batch 3/32 - 178.2ms/batch - loss: 36.78998 - diff: 17.43mlTrain batch 4/32 - 178.3ms/batch - loss: 32.80673 - diff: 16.95mlTrain batch 5/32 - 178.6ms/batch - loss: 31.66706 - diff: 16.79mlTrain batch 6/32 - 178.5ms/batch - loss: 29.93181 - diff: 16.41mlTrain batch 7/32 - 178.9ms/batch - loss: 39.94453 - diff: 18.05mlTrain batch 8/32 - 178.5ms/batch - loss: 37.53890 - diff: 17.63mlTrain batch 9/32 - 179.1ms/batch - loss: 35.43104 - diff: 17.23mlTrain batch 10/32 - 178.6ms/batch - loss: 34.77981 - diff: 17.30mlTrain batch 11/32 - 177.7ms/batch - loss: 33.11005 - diff: 16.81mlTrain batch 12/32 - 178.7ms/batch - loss: 32.21905 - diff: 16.57mlTrain batch 13/32 - 178.9ms/batch - loss: 30.81647 - diff: 16.31mlTrain batch 14/32 - 178.7ms/batch - loss: 30.32652 - diff: 16.21mlTrain batch 15/32 - 178.8ms/batch - loss: 29.22210 - diff: 15.82mlTrain batch 16/32 - 178.7ms/batch - loss: 28.33563 - diff: 15.68mlTrain batch 17/32 - 178.8ms/batch - loss: 29.66480 - diff: 16.11mlTrain batch 18/32 - 178.6ms/batch - loss: 29.00293 - diff: 15.99mlTrain batch 19/32 - 178.9ms/batch - loss: 30.03194 - diff: 16.24mlTrain batch 20/32 - 178.4ms/batch - loss: 30.84789 - diff: 16.41mlTrain batch 21/32 - 178.6ms/batch - loss: 30.64863 - diff: 16.29mlTrain batch 22/32 - 178.6ms/batch - loss: 30.45767 - diff: 16.37mlTrain batch 23/32 - 178.8ms/batch - loss: 37.19692 - diff: 16.74mlTrain batch 24/32 - 178.8ms/batch - loss: 36.69904 - diff: 16.74mlTrain batch 25/32 - 179.2ms/batch - loss: 37.70732 - diff: 16.96mlTrain batch 26/32 - 178.7ms/batch - loss: 36.86741 - diff: 16.79mlTrain batch 27/32 - 178.0ms/batch - loss: 36.42300 - diff: 16.77mlTrain batch 28/32 - 181.3ms/batch - loss: 37.12467 - diff: 17.12mlTrain batch 29/32 - 178.8ms/batch - loss: 36.90634 - diff: 17.13mlTrain batch 30/32 - 178.1ms/batch - loss: 36.48101 - diff: 17.10mlTrain batch 31/32 - 178.8ms/batch - loss: 36.20217 - diff: 17.04mlTrain batch 32/32 - 54.7ms/batch - loss: 38.96166 - diff: 17.18mlTrain batch 32/32 - 11.1s 54.7ms/batch - loss: 38.96166 - diff: 17.18ml
Test 1.1s: val_loss: 663.22127 - diff: 94.44ml

Epoch 37: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 178.0ms/batch - loss: 36.52174 - diff: 18.15mlTrain batch 2/32 - 178.4ms/batch - loss: 27.85033 - diff: 15.92mlTrain batch 3/32 - 178.2ms/batch - loss: 40.47599 - diff: 19.27mlTrain batch 4/32 - 178.3ms/batch - loss: 34.35569 - diff: 17.23mlTrain batch 5/32 - 178.5ms/batch - loss: 30.49386 - diff: 16.40mlTrain batch 6/32 - 178.2ms/batch - loss: 29.37828 - diff: 16.20mlTrain batch 7/32 - 178.3ms/batch - loss: 28.17383 - diff: 16.06mlTrain batch 8/32 - 178.6ms/batch - loss: 28.04749 - diff: 16.08mlTrain batch 9/32 - 178.3ms/batch - loss: 29.86534 - diff: 16.52mlTrain batch 10/32 - 178.8ms/batch - loss: 29.12785 - diff: 16.18mlTrain batch 11/32 - 178.3ms/batch - loss: 28.22484 - diff: 16.06mlTrain batch 12/32 - 178.8ms/batch - loss: 27.80377 - diff: 16.05mlTrain batch 13/32 - 178.5ms/batch - loss: 27.24627 - diff: 15.99mlTrain batch 14/32 - 177.8ms/batch - loss: 27.06745 - diff: 16.04mlTrain batch 15/32 - 178.5ms/batch - loss: 28.11037 - diff: 16.23mlTrain batch 16/32 - 178.4ms/batch - loss: 28.01124 - diff: 16.28mlTrain batch 17/32 - 178.2ms/batch - loss: 27.73140 - diff: 16.08mlTrain batch 18/32 - 178.3ms/batch - loss: 29.44890 - diff: 16.44mlTrain batch 19/32 - 178.8ms/batch - loss: 28.48294 - diff: 16.12mlTrain batch 20/32 - 178.7ms/batch - loss: 32.84045 - diff: 16.65mlTrain batch 21/32 - 178.5ms/batch - loss: 31.89540 - diff: 16.39mlTrain batch 22/32 - 178.6ms/batch - loss: 31.30163 - diff: 16.27mlTrain batch 23/32 - 178.5ms/batch - loss: 31.17160 - diff: 16.27mlTrain batch 24/32 - 178.7ms/batch - loss: 31.36982 - diff: 16.39mlTrain batch 25/32 - 178.9ms/batch - loss: 31.39813 - diff: 16.44mlTrain batch 26/32 - 178.8ms/batch - loss: 32.25030 - diff: 16.46mlTrain batch 27/32 - 178.0ms/batch - loss: 31.87429 - diff: 16.42mlTrain batch 28/32 - 178.6ms/batch - loss: 31.31773 - diff: 16.23mlTrain batch 29/32 - 178.7ms/batch - loss: 30.90758 - diff: 16.16mlTrain batch 30/32 - 178.4ms/batch - loss: 30.43484 - diff: 16.03mlTrain batch 31/32 - 177.9ms/batch - loss: 31.34167 - diff: 16.34mlTrain batch 32/32 - 54.3ms/batch - loss: 31.43752 - diff: 16.28mlTrain batch 32/32 - 11.2s 54.3ms/batch - loss: 31.43752 - diff: 16.28ml
Test 1.1s: val_loss: 564.07633 - diff: 86.86ml
Epoch    38: reducing learning rate of group 0 to 1.2500e-04.

Epoch 38: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 178.2ms/batch - loss: 33.99033 - diff: 18.64mlTrain batch 2/32 - 178.2ms/batch - loss: 29.71948 - diff: 16.97mlTrain batch 3/32 - 178.5ms/batch - loss: 30.56351 - diff: 16.86mlTrain batch 4/32 - 178.6ms/batch - loss: 30.92214 - diff: 16.72mlTrain batch 5/32 - 178.7ms/batch - loss: 35.75059 - diff: 17.36mlTrain batch 6/32 - 178.4ms/batch - loss: 35.02161 - diff: 17.53mlTrain batch 7/32 - 178.3ms/batch - loss: 33.24562 - diff: 17.32mlTrain batch 8/32 - 178.0ms/batch - loss: 31.53402 - diff: 16.97mlTrain batch 9/32 - 178.3ms/batch - loss: 30.24754 - diff: 16.51mlTrain batch 10/32 - 178.5ms/batch - loss: 30.31936 - diff: 16.65mlTrain batch 11/32 - 178.3ms/batch - loss: 31.90710 - diff: 17.07mlTrain batch 12/32 - 178.5ms/batch - loss: 30.65277 - diff: 16.74mlTrain batch 13/32 - 178.5ms/batch - loss: 32.27841 - diff: 17.28mlTrain batch 14/32 - 178.0ms/batch - loss: 32.28905 - diff: 17.39mlTrain batch 15/32 - 178.2ms/batch - loss: 35.17977 - diff: 17.76mlTrain batch 16/32 - 178.1ms/batch - loss: 33.59780 - diff: 17.32mlTrain batch 17/32 - 177.7ms/batch - loss: 33.73934 - diff: 17.27mlTrain batch 18/32 - 178.7ms/batch - loss: 32.75960 - diff: 17.03mlTrain batch 19/32 - 178.3ms/batch - loss: 32.61650 - diff: 17.07mlTrain batch 20/32 - 178.5ms/batch - loss: 32.60455 - diff: 17.08mlTrain batch 21/32 - 178.1ms/batch - loss: 37.30111 - diff: 17.73mlTrain batch 22/32 - 178.5ms/batch - loss: 36.51562 - diff: 17.56mlTrain batch 23/32 - 178.4ms/batch - loss: 35.69181 - diff: 17.31mlTrain batch 24/32 - 178.2ms/batch - loss: 35.47300 - diff: 17.27mlTrain batch 25/32 - 178.4ms/batch - loss: 44.96786 - diff: 18.09mlTrain batch 26/32 - 178.2ms/batch - loss: 44.64313 - diff: 17.96mlTrain batch 27/32 - 178.1ms/batch - loss: 43.79147 - diff: 17.84mlTrain batch 28/32 - 178.3ms/batch - loss: 43.30646 - diff: 17.87mlTrain batch 29/32 - 178.3ms/batch - loss: 43.01511 - diff: 17.93mlTrain batch 30/32 - 178.5ms/batch - loss: 42.18937 - diff: 17.82mlTrain batch 31/32 - 178.5ms/batch - loss: 41.74597 - diff: 17.78mlTrain batch 32/32 - 54.6ms/batch - loss: 41.92924 - diff: 17.74mlTrain batch 32/32 - 12.4s 54.6ms/batch - loss: 41.92924 - diff: 17.74ml
Test 1.1s: val_loss: 539.61069 - diff: 85.53ml

Epoch 39: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 178.2ms/batch - loss: 35.09444 - diff: 16.91mlTrain batch 2/32 - 178.4ms/batch - loss: 30.29607 - diff: 16.92mlTrain batch 3/32 - 178.2ms/batch - loss: 29.16242 - diff: 16.62mlTrain batch 4/32 - 178.3ms/batch - loss: 30.81506 - diff: 16.99mlTrain batch 5/32 - 178.5ms/batch - loss: 29.68865 - diff: 17.02mlTrain batch 6/32 - 178.7ms/batch - loss: 31.52735 - diff: 17.59mlTrain batch 7/32 - 178.5ms/batch - loss: 32.38845 - diff: 17.56mlTrain batch 8/32 - 178.7ms/batch - loss: 32.26444 - diff: 17.80mlTrain batch 9/32 - 178.5ms/batch - loss: 30.97626 - diff: 17.58mlTrain batch 10/32 - 178.7ms/batch - loss: 29.77713 - diff: 17.39mlTrain batch 11/32 - 178.2ms/batch - loss: 27.96779 - diff: 16.75mlTrain batch 12/32 - 178.9ms/batch - loss: 26.45977 - diff: 16.06mlTrain batch 13/32 - 178.3ms/batch - loss: 26.12520 - diff: 16.02mlTrain batch 14/32 - 178.3ms/batch - loss: 25.46351 - diff: 15.80mlTrain batch 15/32 - 178.5ms/batch - loss: 43.24395 - diff: 18.09mlTrain batch 16/32 - 178.6ms/batch - loss: 43.66978 - diff: 18.37mlTrain batch 17/32 - 177.9ms/batch - loss: 43.35316 - diff: 18.36mlTrain batch 18/32 - 178.5ms/batch - loss: 42.80022 - diff: 18.42mlTrain batch 19/32 - 178.3ms/batch - loss: 41.62880 - diff: 18.23mlTrain batch 20/32 - 178.8ms/batch - loss: 41.73374 - diff: 18.19mlTrain batch 21/32 - 178.2ms/batch - loss: 41.16216 - diff: 18.12mlTrain batch 22/32 - 178.6ms/batch - loss: 40.09637 - diff: 17.89mlTrain batch 23/32 - 178.1ms/batch - loss: 38.78512 - diff: 17.54mlTrain batch 24/32 - 178.2ms/batch - loss: 38.21057 - diff: 17.50mlTrain batch 25/32 - 178.2ms/batch - loss: 37.46020 - diff: 17.34mlTrain batch 26/32 - 178.7ms/batch - loss: 36.52202 - diff: 17.12mlTrain batch 27/32 - 178.2ms/batch - loss: 36.98912 - diff: 17.26mlTrain batch 28/32 - 178.3ms/batch - loss: 36.47435 - diff: 17.15mlTrain batch 29/32 - 178.5ms/batch - loss: 35.97994 - diff: 17.07mlTrain batch 30/32 - 178.3ms/batch - loss: 36.11454 - diff: 17.21mlTrain batch 31/32 - 178.3ms/batch - loss: 35.64247 - diff: 17.14mlTrain batch 32/32 - 54.8ms/batch - loss: 38.22056 - diff: 17.28mlTrain batch 32/32 - 11.6s 54.8ms/batch - loss: 38.22056 - diff: 17.28ml
Test 1.1s: val_loss: 602.57133 - diff: 89.71ml

Epoch 40: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 178.3ms/batch - loss: 19.25508 - diff: 14.19mlTrain batch 2/32 - 178.3ms/batch - loss: 20.97788 - diff: 14.73mlTrain batch 3/32 - 178.4ms/batch - loss: 21.02512 - diff: 14.21mlTrain batch 4/32 - 178.2ms/batch - loss: 26.46710 - diff: 15.85mlTrain batch 5/32 - 178.3ms/batch - loss: 25.57445 - diff: 15.84mlTrain batch 6/32 - 178.3ms/batch - loss: 24.49886 - diff: 15.51mlTrain batch 7/32 - 178.6ms/batch - loss: 23.62723 - diff: 15.06mlTrain batch 8/32 - 178.2ms/batch - loss: 23.23314 - diff: 15.10mlTrain batch 9/32 - 178.4ms/batch - loss: 23.61583 - diff: 15.01mlTrain batch 10/32 - 178.5ms/batch - loss: 23.65283 - diff: 15.05mlTrain batch 11/32 - 178.4ms/batch - loss: 24.62458 - diff: 14.95mlTrain batch 12/32 - 178.2ms/batch - loss: 25.61928 - diff: 15.36mlTrain batch 13/32 - 178.7ms/batch - loss: 24.93622 - diff: 15.12mlTrain batch 14/32 - 178.1ms/batch - loss: 26.93545 - diff: 15.72mlTrain batch 15/32 - 177.7ms/batch - loss: 26.36509 - diff: 15.50mlTrain batch 16/32 - 178.1ms/batch - loss: 36.13378 - diff: 16.63mlTrain batch 17/32 - 177.9ms/batch - loss: 34.71983 - diff: 16.28mlTrain batch 18/32 - 178.1ms/batch - loss: 34.71696 - diff: 16.47mlTrain batch 19/32 - 178.4ms/batch - loss: 36.10297 - diff: 16.97mlTrain batch 20/32 - 178.2ms/batch - loss: 39.21550 - diff: 17.06mlTrain batch 21/32 - 178.5ms/batch - loss: 38.60632 - diff: 16.97mlTrain batch 22/32 - 178.3ms/batch - loss: 37.87085 - diff: 16.83mlTrain batch 23/32 - 178.3ms/batch - loss: 37.32618 - diff: 16.65mlTrain batch 24/32 - 178.2ms/batch - loss: 36.92495 - diff: 16.59mlTrain batch 25/32 - 178.3ms/batch - loss: 36.03115 - diff: 16.40mlTrain batch 26/32 - 178.4ms/batch - loss: 35.98287 - diff: 16.41mlTrain batch 27/32 - 178.3ms/batch - loss: 35.74048 - diff: 16.44mlTrain batch 28/32 - 178.2ms/batch - loss: 35.40283 - diff: 16.46mlTrain batch 29/32 - 178.2ms/batch - loss: 36.49406 - diff: 16.83mlTrain batch 30/32 - 178.5ms/batch - loss: 36.11662 - diff: 16.80mlTrain batch 31/32 - 178.6ms/batch - loss: 35.98313 - diff: 16.84mlTrain batch 32/32 - 54.6ms/batch - loss: 35.95195 - diff: 16.78mlTrain batch 32/32 - 11.7s 54.6ms/batch - loss: 35.95195 - diff: 16.78ml
Test 1.1s: val_loss: 584.61836 - diff: 88.32ml

Epoch 41: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 178.1ms/batch - loss: 34.20007 - diff: 16.46mlTrain batch 2/32 - 178.0ms/batch - loss: 32.49010 - diff: 16.49mlTrain batch 3/32 - 178.1ms/batch - loss: 31.56503 - diff: 16.84mlTrain batch 4/32 - 178.7ms/batch - loss: 32.92956 - diff: 17.85mlTrain batch 5/32 - 178.3ms/batch - loss: 28.34749 - diff: 16.50mlTrain batch 6/32 - 178.5ms/batch - loss: 27.26402 - diff: 15.99mlTrain batch 7/32 - 178.6ms/batch - loss: 30.06955 - diff: 16.55mlTrain batch 8/32 - 178.9ms/batch - loss: 30.34616 - diff: 16.58mlTrain batch 9/32 - 178.6ms/batch - loss: 30.50729 - diff: 16.76mlTrain batch 10/32 - 178.8ms/batch - loss: 32.00795 - diff: 17.39mlTrain batch 11/32 - 178.6ms/batch - loss: 30.03003 - diff: 16.74mlTrain batch 12/32 - 178.9ms/batch - loss: 30.22002 - diff: 16.67mlTrain batch 13/32 - 178.8ms/batch - loss: 29.68170 - diff: 16.53mlTrain batch 14/32 - 178.7ms/batch - loss: 33.64869 - diff: 17.22mlTrain batch 15/32 - 178.2ms/batch - loss: 33.86651 - diff: 17.36mlTrain batch 16/32 - 178.6ms/batch - loss: 34.11007 - diff: 17.33mlTrain batch 17/32 - 178.2ms/batch - loss: 34.42743 - diff: 17.44mlTrain batch 18/32 - 178.2ms/batch - loss: 34.21197 - diff: 17.40mlTrain batch 19/32 - 178.9ms/batch - loss: 34.42354 - diff: 17.48mlTrain batch 20/32 - 178.9ms/batch - loss: 33.54043 - diff: 17.27mlTrain batch 21/32 - 178.8ms/batch - loss: 33.95976 - diff: 17.37mlTrain batch 22/32 - 178.9ms/batch - loss: 33.08568 - diff: 17.12mlTrain batch 23/32 - 178.8ms/batch - loss: 32.93166 - diff: 17.11mlTrain batch 24/32 - 178.8ms/batch - loss: 32.17026 - diff: 16.91mlTrain batch 25/32 - 178.3ms/batch - loss: 36.53953 - diff: 17.22mlTrain batch 26/32 - 178.6ms/batch - loss: 36.55123 - diff: 17.26mlTrain batch 27/32 - 178.1ms/batch - loss: 36.10957 - diff: 17.23mlTrain batch 28/32 - 178.4ms/batch - loss: 36.33304 - diff: 17.25mlTrain batch 29/32 - 178.3ms/batch - loss: 35.64907 - diff: 17.07mlTrain batch 30/32 - 178.3ms/batch - loss: 35.87485 - diff: 17.13mlTrain batch 31/32 - 178.1ms/batch - loss: 35.40774 - diff: 17.06mlTrain batch 32/32 - 54.2ms/batch - loss: 37.09427 - diff: 17.17mlTrain batch 32/32 - 11.0s 54.2ms/batch - loss: 37.09427 - diff: 17.17ml
Test 1.1s: val_loss: 532.74833 - diff: 83.65ml

Epoch 42: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 181.4ms/batch - loss: 14.11040 - diff: 12.92mlTrain batch 2/32 - 178.2ms/batch - loss: 16.78158 - diff: 12.28mlTrain batch 3/32 - 178.5ms/batch - loss: 51.19690 - diff: 17.69mlTrain batch 4/32 - 178.3ms/batch - loss: 45.27467 - diff: 17.35mlTrain batch 5/32 - 178.2ms/batch - loss: 40.15454 - diff: 16.62mlTrain batch 6/32 - 178.1ms/batch - loss: 35.89254 - diff: 15.96mlTrain batch 7/32 - 178.2ms/batch - loss: 33.67031 - diff: 15.86mlTrain batch 8/32 - 178.1ms/batch - loss: 32.36886 - diff: 15.59mlTrain batch 9/32 - 178.4ms/batch - loss: 32.71229 - diff: 16.14mlTrain batch 10/32 - 178.4ms/batch - loss: 30.42991 - diff: 15.51mlTrain batch 11/32 - 178.4ms/batch - loss: 31.30232 - diff: 15.92mlTrain batch 12/32 - 178.4ms/batch - loss: 32.08892 - diff: 16.22mlTrain batch 13/32 - 178.7ms/batch - loss: 32.00664 - diff: 16.15mlTrain batch 14/32 - 178.3ms/batch - loss: 31.20266 - diff: 16.05mlTrain batch 15/32 - 178.5ms/batch - loss: 29.89639 - diff: 15.64mlTrain batch 16/32 - 178.2ms/batch - loss: 29.43797 - diff: 15.64mlTrain batch 17/32 - 178.3ms/batch - loss: 30.16529 - diff: 15.93mlTrain batch 18/32 - 178.2ms/batch - loss: 29.68048 - diff: 15.88mlTrain batch 19/32 - 178.2ms/batch - loss: 35.07170 - diff: 16.37mlTrain batch 20/32 - 178.4ms/batch - loss: 36.16749 - diff: 16.51mlTrain batch 21/32 - 178.5ms/batch - loss: 35.36171 - diff: 16.41mlTrain batch 22/32 - 178.2ms/batch - loss: 34.87401 - diff: 16.31mlTrain batch 23/32 - 178.4ms/batch - loss: 33.94763 - diff: 16.13mlTrain batch 24/32 - 178.4ms/batch - loss: 33.28036 - diff: 16.03mlTrain batch 25/32 - 178.0ms/batch - loss: 32.87742 - diff: 15.96mlTrain batch 26/32 - 178.3ms/batch - loss: 32.92846 - diff: 16.08mlTrain batch 27/32 - 178.1ms/batch - loss: 32.28321 - diff: 15.93mlTrain batch 28/32 - 178.4ms/batch - loss: 31.45607 - diff: 15.69mlTrain batch 29/32 - 178.3ms/batch - loss: 31.07974 - diff: 15.69mlTrain batch 30/32 - 178.4ms/batch - loss: 30.77993 - diff: 15.66mlTrain batch 31/32 - 178.4ms/batch - loss: 31.04016 - diff: 15.78mlTrain batch 32/32 - 54.3ms/batch - loss: 31.05460 - diff: 15.73mlTrain batch 32/32 - 11.4s 54.3ms/batch - loss: 31.05460 - diff: 15.73ml
Test 1.1s: val_loss: 639.69182 - diff: 92.88ml

Epoch 43: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 178.5ms/batch - loss: 20.98639 - diff: 15.27mlTrain batch 2/32 - 178.5ms/batch - loss: 25.89281 - diff: 15.69mlTrain batch 3/32 - 179.3ms/batch - loss: 26.32109 - diff: 15.06mlTrain batch 4/32 - 178.7ms/batch - loss: 25.36190 - diff: 14.70mlTrain batch 5/32 - 178.6ms/batch - loss: 29.47123 - diff: 15.70mlTrain batch 6/32 - 178.3ms/batch - loss: 34.95650 - diff: 17.51mlTrain batch 7/32 - 178.4ms/batch - loss: 33.18518 - diff: 17.08mlTrain batch 8/32 - 178.6ms/batch - loss: 36.23371 - diff: 17.44mlTrain batch 9/32 - 178.5ms/batch - loss: 35.57311 - diff: 17.37mlTrain batch 10/32 - 178.9ms/batch - loss: 37.69075 - diff: 18.22mlTrain batch 11/32 - 178.5ms/batch - loss: 35.82130 - diff: 17.70mlTrain batch 12/32 - 178.2ms/batch - loss: 34.92015 - diff: 17.58mlTrain batch 13/32 - 178.4ms/batch - loss: 33.75593 - diff: 17.41mlTrain batch 14/32 - 178.7ms/batch - loss: 32.93276 - diff: 17.30mlTrain batch 15/32 - 178.6ms/batch - loss: 33.04668 - diff: 17.39mlTrain batch 16/32 - 178.4ms/batch - loss: 35.42152 - diff: 17.46mlTrain batch 17/32 - 178.3ms/batch - loss: 34.49171 - diff: 17.25mlTrain batch 18/32 - 178.9ms/batch - loss: 33.83760 - diff: 17.09mlTrain batch 19/32 - 178.8ms/batch - loss: 33.44653 - diff: 17.16mlTrain batch 20/32 - 178.9ms/batch - loss: 32.92100 - diff: 17.02mlTrain batch 21/32 - 178.5ms/batch - loss: 32.69088 - diff: 16.97mlTrain batch 22/32 - 177.9ms/batch - loss: 32.89266 - diff: 17.03mlTrain batch 23/32 - 178.0ms/batch - loss: 32.41606 - diff: 16.90mlTrain batch 24/32 - 178.2ms/batch - loss: 33.79287 - diff: 17.12mlTrain batch 25/32 - 178.2ms/batch - loss: 33.98951 - diff: 17.22mlTrain batch 26/32 - 178.8ms/batch - loss: 33.80682 - diff: 17.21mlTrain batch 27/32 - 178.5ms/batch - loss: 42.24602 - diff: 18.07mlTrain batch 28/32 - 178.8ms/batch - loss: 41.96688 - diff: 18.14mlTrain batch 29/32 - 178.7ms/batch - loss: 41.86324 - diff: 18.26mlTrain batch 30/32 - 178.9ms/batch - loss: 41.10752 - diff: 18.11mlTrain batch 31/32 - 178.4ms/batch - loss: 40.86035 - diff: 18.11mlTrain batch 32/32 - 54.6ms/batch - loss: 41.61764 - diff: 18.14mlTrain batch 32/32 - 10.9s 54.6ms/batch - loss: 41.61764 - diff: 18.14ml
Test 1.1s: val_loss: 534.39402 - diff: 83.65ml

Epoch 44: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 178.4ms/batch - loss: 30.62918 - diff: 19.23mlTrain batch 2/32 - 178.0ms/batch - loss: 20.33822 - diff: 14.41mlTrain batch 3/32 - 178.2ms/batch - loss: 26.04750 - diff: 15.69mlTrain batch 4/32 - 177.8ms/batch - loss: 25.04652 - diff: 15.88mlTrain batch 5/32 - 178.3ms/batch - loss: 23.35581 - diff: 15.23mlTrain batch 6/32 - 178.4ms/batch - loss: 21.93335 - diff: 14.61mlTrain batch 7/32 - 178.7ms/batch - loss: 19.89494 - diff: 13.80mlTrain batch 8/32 - 178.7ms/batch - loss: 21.26710 - diff: 14.48mlTrain batch 9/32 - 178.6ms/batch - loss: 20.57675 - diff: 14.05mlTrain batch 10/32 - 178.8ms/batch - loss: 21.97115 - diff: 14.69mlTrain batch 11/32 - 178.8ms/batch - loss: 23.11530 - diff: 14.78mlTrain batch 12/32 - 178.4ms/batch - loss: 23.06420 - diff: 14.86mlTrain batch 13/32 - 178.6ms/batch - loss: 23.58189 - diff: 14.79mlTrain batch 14/32 - 178.4ms/batch - loss: 23.50031 - diff: 14.80mlTrain batch 15/32 - 178.2ms/batch - loss: 24.96431 - diff: 15.33mlTrain batch 16/32 - 178.2ms/batch - loss: 24.56254 - diff: 15.25mlTrain batch 17/32 - 178.2ms/batch - loss: 24.71386 - diff: 15.37mlTrain batch 18/32 - 178.3ms/batch - loss: 23.92165 - diff: 15.04mlTrain batch 19/32 - 178.6ms/batch - loss: 30.68086 - diff: 15.79mlTrain batch 20/32 - 178.7ms/batch - loss: 31.75814 - diff: 16.17mlTrain batch 21/32 - 178.8ms/batch - loss: 31.53585 - diff: 16.14mlTrain batch 22/32 - 178.8ms/batch - loss: 31.16294 - diff: 16.13mlTrain batch 23/32 - 178.1ms/batch - loss: 31.83311 - diff: 16.27mlTrain batch 24/32 - 178.7ms/batch - loss: 33.15096 - diff: 16.64mlTrain batch 25/32 - 178.5ms/batch - loss: 33.17379 - diff: 16.65mlTrain batch 26/32 - 178.6ms/batch - loss: 32.44232 - diff: 16.46mlTrain batch 27/32 - 178.7ms/batch - loss: 34.74395 - diff: 16.73mlTrain batch 28/32 - 178.3ms/batch - loss: 34.22069 - diff: 16.65mlTrain batch 29/32 - 178.4ms/batch - loss: 34.13915 - diff: 16.72mlTrain batch 30/32 - 178.3ms/batch - loss: 33.86176 - diff: 16.71mlTrain batch 31/32 - 178.4ms/batch - loss: 33.32458 - diff: 16.63mlTrain batch 32/32 - 54.5ms/batch - loss: 39.35183 - diff: 16.87mlTrain batch 32/32 - 11.4s 54.5ms/batch - loss: 39.35183 - diff: 16.87ml
Test 1.1s: val_loss: 542.29367 - diff: 84.58ml

Epoch 45: current best loss = 68.57713, at epoch 4
Going to unfreeze the pretrained weights
Train batch 1/32 - 239.3ms/batch - loss: 24.10556 - diff: 14.36mlTrain batch 2/32 - 240.7ms/batch - loss: 27.89025 - diff: 16.54mlTrain batch 3/32 - 240.9ms/batch - loss: 37.27187 - diff: 17.44mlTrain batch 4/32 - 241.0ms/batch - loss: 55.41553 - diff: 21.90mlTrain batch 5/32 - 241.2ms/batch - loss: 54.69170 - diff: 21.31mlTrain batch 6/32 - 241.5ms/batch - loss: 61.76639 - diff: 22.02mlTrain batch 7/32 - 243.2ms/batch - loss: 67.26733 - diff: 22.95mlTrain batch 8/32 - 241.2ms/batch - loss: 82.74729 - diff: 24.66mlTrain batch 9/32 - 241.2ms/batch - loss: 81.93264 - diff: 25.12mlTrain batch 10/32 - 241.1ms/batch - loss: 81.75623 - diff: 25.55mlTrain batch 11/32 - 241.2ms/batch - loss: 78.01172 - diff: 24.92mlTrain batch 12/32 - 241.6ms/batch - loss: 77.66820 - diff: 25.21mlTrain batch 13/32 - 241.6ms/batch - loss: 80.83775 - diff: 25.86mlTrain batch 14/32 - 241.4ms/batch - loss: 79.58412 - diff: 25.78mlTrain batch 15/32 - 241.8ms/batch - loss: 80.47133 - diff: 26.22mlTrain batch 16/32 - 241.6ms/batch - loss: 79.32608 - diff: 26.25mlTrain batch 17/32 - 241.7ms/batch - loss: 80.23700 - diff: 26.47mlTrain batch 18/32 - 241.2ms/batch - loss: 77.01709 - diff: 25.85mlTrain batch 19/32 - 241.4ms/batch - loss: 78.56848 - diff: 26.13mlTrain batch 20/32 - 241.1ms/batch - loss: 75.74770 - diff: 25.63mlTrain batch 21/32 - 241.1ms/batch - loss: 76.23198 - diff: 25.62mlTrain batch 22/32 - 241.7ms/batch - loss: 76.88785 - diff: 25.90mlTrain batch 23/32 - 241.3ms/batch - loss: 76.40577 - diff: 25.91mlTrain batch 24/32 - 241.1ms/batch - loss: 76.74092 - diff: 26.02mlTrain batch 25/32 - 241.5ms/batch - loss: 75.31858 - diff: 25.82mlTrain batch 26/32 - 241.5ms/batch - loss: 75.00893 - diff: 25.83mlTrain batch 27/32 - 241.7ms/batch - loss: 73.89077 - diff: 25.63mlTrain batch 28/32 - 241.4ms/batch - loss: 72.64132 - diff: 25.32mlTrain batch 29/32 - 241.5ms/batch - loss: 72.31351 - diff: 25.32mlTrain batch 30/32 - 241.5ms/batch - loss: 70.70423 - diff: 25.04mlTrain batch 31/32 - 241.4ms/batch - loss: 77.63539 - diff: 25.51mlTrain batch 32/32 - 77.7ms/batch - loss: 79.89315 - diff: 25.57mlTrain batch 32/32 - 11.5s 77.7ms/batch - loss: 79.89315 - diff: 25.57ml
Test 1.1s: val_loss: 413.63510 - diff: 72.93ml

Epoch 46: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 241.7ms/batch - loss: 157.77675 - diff: 29.66mlTrain batch 2/32 - 241.3ms/batch - loss: 106.72213 - diff: 25.52mlTrain batch 3/32 - 241.2ms/batch - loss: 88.13135 - diff: 24.30mlTrain batch 4/32 - 241.9ms/batch - loss: 83.96266 - diff: 25.14mlTrain batch 5/32 - 241.3ms/batch - loss: 104.83492 - diff: 26.99mlTrain batch 6/32 - 241.1ms/batch - loss: 97.59582 - diff: 26.68mlTrain batch 7/32 - 241.3ms/batch - loss: 85.82156 - diff: 24.75mlTrain batch 8/32 - 241.3ms/batch - loss: 77.27516 - diff: 23.31mlTrain batch 9/32 - 241.4ms/batch - loss: 74.84029 - diff: 23.39mlTrain batch 10/32 - 241.2ms/batch - loss: 69.30910 - diff: 22.52mlTrain batch 11/32 - 241.7ms/batch - loss: 66.91123 - diff: 22.29mlTrain batch 12/32 - 241.5ms/batch - loss: 64.13835 - diff: 21.93mlTrain batch 13/32 - 241.9ms/batch - loss: 62.40376 - diff: 21.70mlTrain batch 14/32 - 241.2ms/batch - loss: 59.86479 - diff: 21.37mlTrain batch 15/32 - 241.8ms/batch - loss: 60.38350 - diff: 21.74mlTrain batch 16/32 - 241.3ms/batch - loss: 57.76368 - diff: 21.28mlTrain batch 17/32 - 241.6ms/batch - loss: 57.90977 - diff: 21.10mlTrain batch 18/32 - 241.2ms/batch - loss: 55.95994 - diff: 20.74mlTrain batch 19/32 - 241.7ms/batch - loss: 55.28498 - diff: 20.83mlTrain batch 20/32 - 241.9ms/batch - loss: 55.45691 - diff: 20.98mlTrain batch 21/32 - 241.9ms/batch - loss: 55.48520 - diff: 21.11mlTrain batch 22/32 - 241.4ms/batch - loss: 54.27682 - diff: 20.84mlTrain batch 23/32 - 241.5ms/batch - loss: 54.49776 - diff: 20.89mlTrain batch 24/32 - 241.2ms/batch - loss: 54.80842 - diff: 21.01mlTrain batch 25/32 - 241.3ms/batch - loss: 53.78748 - diff: 20.96mlTrain batch 26/32 - 241.3ms/batch - loss: 52.88040 - diff: 20.81mlTrain batch 27/32 - 241.6ms/batch - loss: 51.90028 - diff: 20.62mlTrain batch 28/32 - 241.3ms/batch - loss: 50.80568 - diff: 20.43mlTrain batch 29/32 - 241.3ms/batch - loss: 50.43691 - diff: 20.35mlTrain batch 30/32 - 241.4ms/batch - loss: 51.01217 - diff: 20.52mlTrain batch 31/32 - 241.6ms/batch - loss: 50.82570 - diff: 20.46mlTrain batch 32/32 - 77.7ms/batch - loss: 51.51416 - diff: 20.41mlTrain batch 32/32 - 11.7s 77.7ms/batch - loss: 51.51416 - diff: 20.41ml
Test 1.1s: val_loss: 137.94413 - diff: 39.82ml

Epoch 47: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 241.5ms/batch - loss: 21.56884 - diff: 14.78mlTrain batch 2/32 - 242.2ms/batch - loss: 21.35103 - diff: 14.36mlTrain batch 3/32 - 241.4ms/batch - loss: 33.09052 - diff: 17.13mlTrain batch 4/32 - 241.6ms/batch - loss: 37.25310 - diff: 18.62mlTrain batch 5/32 - 241.9ms/batch - loss: 37.86199 - diff: 19.03mlTrain batch 6/32 - 241.9ms/batch - loss: 38.59358 - diff: 19.11mlTrain batch 7/32 - 241.8ms/batch - loss: 42.29668 - diff: 20.15mlTrain batch 8/32 - 241.8ms/batch - loss: 43.22487 - diff: 20.27mlTrain batch 9/32 - 241.6ms/batch - loss: 42.24013 - diff: 20.18mlTrain batch 10/32 - 241.4ms/batch - loss: 40.86133 - diff: 19.81mlTrain batch 11/32 - 241.3ms/batch - loss: 40.00522 - diff: 19.68mlTrain batch 12/32 - 241.7ms/batch - loss: 39.47481 - diff: 19.62mlTrain batch 13/32 - 241.9ms/batch - loss: 39.80820 - diff: 19.70mlTrain batch 14/32 - 241.8ms/batch - loss: 38.66894 - diff: 19.43mlTrain batch 15/32 - 241.7ms/batch - loss: 37.44322 - diff: 19.03mlTrain batch 16/32 - 241.7ms/batch - loss: 36.60520 - diff: 18.80mlTrain batch 17/32 - 241.5ms/batch - loss: 36.66538 - diff: 18.89mlTrain batch 18/32 - 241.9ms/batch - loss: 35.70740 - diff: 18.57mlTrain batch 19/32 - 241.0ms/batch - loss: 34.51585 - diff: 18.09mlTrain batch 20/32 - 241.9ms/batch - loss: 34.30694 - diff: 17.99mlTrain batch 21/32 - 241.7ms/batch - loss: 34.01501 - diff: 17.84mlTrain batch 22/32 - 241.8ms/batch - loss: 34.01331 - diff: 17.86mlTrain batch 23/32 - 241.3ms/batch - loss: 33.85435 - diff: 17.79mlTrain batch 24/32 - 241.6ms/batch - loss: 34.28270 - diff: 17.94mlTrain batch 25/32 - 241.7ms/batch - loss: 34.30532 - diff: 18.02mlTrain batch 26/32 - 242.1ms/batch - loss: 35.06420 - diff: 18.34mlTrain batch 27/32 - 241.6ms/batch - loss: 35.27875 - diff: 18.31mlTrain batch 28/32 - 242.4ms/batch - loss: 36.31810 - diff: 18.35mlTrain batch 29/32 - 241.8ms/batch - loss: 42.74468 - diff: 19.12mlTrain batch 30/32 - 242.7ms/batch - loss: 43.63767 - diff: 19.42mlTrain batch 31/32 - 241.2ms/batch - loss: 43.65511 - diff: 19.47mlTrain batch 32/32 - 77.8ms/batch - loss: 46.01344 - diff: 19.58mlTrain batch 32/32 - 11.1s 77.8ms/batch - loss: 46.01344 - diff: 19.58ml
Test 1.1s: val_loss: 802.58063 - diff: 103.83ml

Epoch 48: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 241.3ms/batch - loss: 29.78396 - diff: 19.28mlTrain batch 2/32 - 241.6ms/batch - loss: 36.19896 - diff: 19.03mlTrain batch 3/32 - 241.3ms/batch - loss: 31.50394 - diff: 18.20mlTrain batch 4/32 - 241.6ms/batch - loss: 33.20948 - diff: 17.86mlTrain batch 5/32 - 241.6ms/batch - loss: 36.30512 - diff: 18.56mlTrain batch 6/32 - 241.7ms/batch - loss: 46.43484 - diff: 20.38mlTrain batch 7/32 - 241.5ms/batch - loss: 46.99638 - diff: 20.62mlTrain batch 8/32 - 241.5ms/batch - loss: 47.38130 - diff: 20.94mlTrain batch 9/32 - 242.1ms/batch - loss: 61.97207 - diff: 22.29mlTrain batch 10/32 - 241.5ms/batch - loss: 59.10041 - diff: 21.94mlTrain batch 11/32 - 241.6ms/batch - loss: 57.61381 - diff: 22.02mlTrain batch 12/32 - 241.4ms/batch - loss: 55.25833 - diff: 21.69mlTrain batch 13/32 - 241.8ms/batch - loss: 53.21246 - diff: 21.41mlTrain batch 14/32 - 241.4ms/batch - loss: 51.79518 - diff: 21.22mlTrain batch 15/32 - 241.7ms/batch - loss: 51.14552 - diff: 21.21mlTrain batch 16/32 - 241.7ms/batch - loss: 49.54035 - diff: 20.80mlTrain batch 17/32 - 241.6ms/batch - loss: 49.70505 - diff: 20.87mlTrain batch 18/32 - 241.7ms/batch - loss: 48.42283 - diff: 20.55mlTrain batch 19/32 - 241.7ms/batch - loss: 47.38808 - diff: 20.34mlTrain batch 20/32 - 241.1ms/batch - loss: 48.01767 - diff: 20.47mlTrain batch 21/32 - 241.8ms/batch - loss: 47.98569 - diff: 20.57mlTrain batch 22/32 - 241.4ms/batch - loss: 47.76113 - diff: 20.69mlTrain batch 23/32 - 242.0ms/batch - loss: 46.31025 - diff: 20.27mlTrain batch 24/32 - 241.5ms/batch - loss: 45.88829 - diff: 20.17mlTrain batch 25/32 - 242.0ms/batch - loss: 45.38421 - diff: 20.04mlTrain batch 26/32 - 241.8ms/batch - loss: 45.03928 - diff: 20.09mlTrain batch 27/32 - 242.5ms/batch - loss: 44.42827 - diff: 19.95mlTrain batch 28/32 - 241.6ms/batch - loss: 43.68677 - diff: 19.84mlTrain batch 29/32 - 241.5ms/batch - loss: 43.67387 - diff: 19.76mlTrain batch 30/32 - 241.8ms/batch - loss: 43.34862 - diff: 19.73mlTrain batch 31/32 - 242.1ms/batch - loss: 43.12074 - diff: 19.76mlTrain batch 32/32 - 78.3ms/batch - loss: 44.35222 - diff: 19.78mlTrain batch 32/32 - 12.2s 78.3ms/batch - loss: 44.35222 - diff: 19.78ml
Test 1.1s: val_loss: 510.16884 - diff: 81.52ml
Epoch    49: reducing learning rate of group 0 to 6.2500e-05.

Epoch 49: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 241.4ms/batch - loss: 32.37738 - diff: 17.85mlTrain batch 2/32 - 241.8ms/batch - loss: 34.47856 - diff: 18.60mlTrain batch 3/32 - 241.4ms/batch - loss: 27.97718 - diff: 17.02mlTrain batch 4/32 - 242.5ms/batch - loss: 27.22884 - diff: 16.86mlTrain batch 5/32 - 241.9ms/batch - loss: 29.20045 - diff: 17.33mlTrain batch 6/32 - 242.0ms/batch - loss: 30.77256 - diff: 17.90mlTrain batch 7/32 - 241.9ms/batch - loss: 30.36534 - diff: 17.74mlTrain batch 8/32 - 241.9ms/batch - loss: 28.95745 - diff: 17.22mlTrain batch 9/32 - 241.4ms/batch - loss: 27.42839 - diff: 16.72mlTrain batch 10/32 - 242.0ms/batch - loss: 27.99399 - diff: 16.92mlTrain batch 11/32 - 241.4ms/batch - loss: 29.10374 - diff: 17.03mlTrain batch 12/32 - 242.1ms/batch - loss: 29.22190 - diff: 16.97mlTrain batch 13/32 - 241.3ms/batch - loss: 28.75615 - diff: 16.93mlTrain batch 14/32 - 241.9ms/batch - loss: 29.92969 - diff: 17.28mlTrain batch 15/32 - 241.5ms/batch - loss: 30.43038 - diff: 17.45mlTrain batch 16/32 - 242.1ms/batch - loss: 30.62137 - diff: 17.46mlTrain batch 17/32 - 241.4ms/batch - loss: 29.47643 - diff: 17.09mlTrain batch 18/32 - 241.9ms/batch - loss: 29.28710 - diff: 16.88mlTrain batch 19/32 - 241.6ms/batch - loss: 43.13736 - diff: 18.01mlTrain batch 20/32 - 242.2ms/batch - loss: 41.51480 - diff: 17.61mlTrain batch 21/32 - 241.4ms/batch - loss: 40.90057 - diff: 17.68mlTrain batch 22/32 - 241.9ms/batch - loss: 39.81521 - diff: 17.52mlTrain batch 23/32 - 241.9ms/batch - loss: 39.58712 - diff: 17.52mlTrain batch 24/32 - 242.1ms/batch - loss: 38.37212 - diff: 17.17mlTrain batch 25/32 - 241.5ms/batch - loss: 37.96667 - diff: 17.21mlTrain batch 26/32 - 242.0ms/batch - loss: 38.10985 - diff: 17.30mlTrain batch 27/32 - 242.0ms/batch - loss: 38.23395 - diff: 17.36mlTrain batch 28/32 - 242.0ms/batch - loss: 38.09035 - diff: 17.37mlTrain batch 29/32 - 241.9ms/batch - loss: 37.61448 - diff: 17.37mlTrain batch 30/32 - 242.6ms/batch - loss: 38.43831 - diff: 17.70mlTrain batch 31/32 - 241.9ms/batch - loss: 38.33755 - diff: 17.74mlTrain batch 32/32 - 78.3ms/batch - loss: 38.15871 - diff: 17.66mlTrain batch 32/32 - 11.9s 78.3ms/batch - loss: 38.15871 - diff: 17.66ml
Test 1.1s: val_loss: 582.87817 - diff: 86.36ml

Epoch 50: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 241.5ms/batch - loss: 18.18952 - diff: 12.39mlTrain batch 2/32 - 241.8ms/batch - loss: 15.99159 - diff: 12.26mlTrain batch 3/32 - 241.5ms/batch - loss: 13.06079 - diff: 11.05mlTrain batch 4/32 - 242.0ms/batch - loss: 12.95344 - diff: 10.90mlTrain batch 5/32 - 241.5ms/batch - loss: 14.70440 - diff: 11.76mlTrain batch 6/32 - 241.3ms/batch - loss: 14.58173 - diff: 11.95mlTrain batch 7/32 - 241.6ms/batch - loss: 13.89695 - diff: 11.57mlTrain batch 8/32 - 241.7ms/batch - loss: 14.89724 - diff: 12.20mlTrain batch 9/32 - 241.8ms/batch - loss: 17.67129 - diff: 12.95mlTrain batch 10/32 - 241.5ms/batch - loss: 18.57796 - diff: 13.22mlTrain batch 11/32 - 242.0ms/batch - loss: 18.68377 - diff: 13.27mlTrain batch 12/32 - 241.8ms/batch - loss: 19.28174 - diff: 13.33mlTrain batch 13/32 - 242.0ms/batch - loss: 18.99020 - diff: 13.23mlTrain batch 14/32 - 241.5ms/batch - loss: 19.29208 - diff: 13.37mlTrain batch 15/32 - 241.9ms/batch - loss: 29.42751 - diff: 15.08mlTrain batch 16/32 - 242.0ms/batch - loss: 28.95187 - diff: 15.11mlTrain batch 17/32 - 241.8ms/batch - loss: 28.84914 - diff: 15.23mlTrain batch 18/32 - 242.0ms/batch - loss: 30.71565 - diff: 15.71mlTrain batch 19/32 - 241.7ms/batch - loss: 31.30716 - diff: 15.92mlTrain batch 20/32 - 241.7ms/batch - loss: 31.75565 - diff: 16.14mlTrain batch 21/32 - 242.1ms/batch - loss: 30.73644 - diff: 15.87mlTrain batch 22/32 - 242.5ms/batch - loss: 29.79497 - diff: 15.66mlTrain batch 23/32 - 241.4ms/batch - loss: 29.55303 - diff: 15.66mlTrain batch 24/32 - 242.2ms/batch - loss: 29.58136 - diff: 15.76mlTrain batch 25/32 - 241.9ms/batch - loss: 29.59391 - diff: 15.69mlTrain batch 26/32 - 241.9ms/batch - loss: 29.66136 - diff: 15.79mlTrain batch 27/32 - 242.6ms/batch - loss: 30.09882 - diff: 15.92mlTrain batch 28/32 - 241.7ms/batch - loss: 29.92318 - diff: 15.96mlTrain batch 29/32 - 242.1ms/batch - loss: 29.34746 - diff: 15.77mlTrain batch 30/32 - 241.7ms/batch - loss: 28.78803 - diff: 15.62mlTrain batch 31/32 - 242.3ms/batch - loss: 28.10634 - diff: 15.41mlTrain batch 32/32 - 79.4ms/batch - loss: 31.37675 - diff: 15.61mlTrain batch 32/32 - 11.8s 79.4ms/batch - loss: 31.37675 - diff: 15.61ml
Test 1.1s: val_loss: 281.39157 - diff: 58.89ml

Epoch 51: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 241.3ms/batch - loss: 15.53827 - diff: 12.30mlTrain batch 2/32 - 242.0ms/batch - loss: 13.02783 - diff: 11.16mlTrain batch 3/32 - 241.8ms/batch - loss: 17.39103 - diff: 12.32mlTrain batch 4/32 - 242.1ms/batch - loss: 17.58134 - diff: 12.28mlTrain batch 5/32 - 241.7ms/batch - loss: 17.55795 - diff: 12.25mlTrain batch 6/32 - 241.5ms/batch - loss: 16.27672 - diff: 11.81mlTrain batch 7/32 - 242.0ms/batch - loss: 16.96679 - diff: 12.22mlTrain batch 8/32 - 242.0ms/batch - loss: 18.64670 - diff: 13.04mlTrain batch 9/32 - 242.0ms/batch - loss: 19.08395 - diff: 13.27mlTrain batch 10/32 - 241.3ms/batch - loss: 19.44444 - diff: 13.51mlTrain batch 11/32 - 242.4ms/batch - loss: 38.27118 - diff: 16.22mlTrain batch 12/32 - 241.3ms/batch - loss: 36.63733 - diff: 15.94mlTrain batch 13/32 - 241.5ms/batch - loss: 36.45801 - diff: 15.98mlTrain batch 14/32 - 241.0ms/batch - loss: 34.88862 - diff: 15.74mlTrain batch 15/32 - 241.8ms/batch - loss: 34.27229 - diff: 15.74mlTrain batch 16/32 - 241.7ms/batch - loss: 33.62020 - diff: 15.78mlTrain batch 17/32 - 242.0ms/batch - loss: 32.72787 - diff: 15.61mlTrain batch 18/32 - 241.7ms/batch - loss: 32.17533 - diff: 15.49mlTrain batch 19/32 - 242.1ms/batch - loss: 31.62887 - diff: 15.46mlTrain batch 20/32 - 242.0ms/batch - loss: 31.25336 - diff: 15.55mlTrain batch 21/32 - 242.5ms/batch - loss: 30.70203 - diff: 15.56mlTrain batch 22/32 - 242.0ms/batch - loss: 30.36839 - diff: 15.60mlTrain batch 23/32 - 242.6ms/batch - loss: 29.58868 - diff: 15.45mlTrain batch 24/32 - 242.1ms/batch - loss: 31.14047 - diff: 15.83mlTrain batch 25/32 - 243.7ms/batch - loss: 30.80999 - diff: 15.83mlTrain batch 26/32 - 241.9ms/batch - loss: 31.00322 - diff: 15.98mlTrain batch 27/32 - 241.6ms/batch - loss: 30.76792 - diff: 15.91mlTrain batch 28/32 - 241.9ms/batch - loss: 30.20674 - diff: 15.77mlTrain batch 29/32 - 241.9ms/batch - loss: 29.97803 - diff: 15.85mlTrain batch 30/32 - 242.6ms/batch - loss: 29.58687 - diff: 15.74mlTrain batch 31/32 - 241.8ms/batch - loss: 29.13269 - diff: 15.63mlTrain batch 32/32 - 77.9ms/batch - loss: 29.73008 - diff: 15.62mlTrain batch 32/32 - 12.8s 77.9ms/batch - loss: 29.73008 - diff: 15.62ml
Test 1.1s: val_loss: 545.32338 - diff: 86.12ml

Epoch 52: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 241.4ms/batch - loss: 28.40962 - diff: 15.06mlTrain batch 2/32 - 241.6ms/batch - loss: 18.96832 - diff: 12.46mlTrain batch 3/32 - 241.4ms/batch - loss: 61.72098 - diff: 18.13mlTrain batch 4/32 - 242.4ms/batch - loss: 54.98383 - diff: 17.96mlTrain batch 5/32 - 241.7ms/batch - loss: 52.66105 - diff: 18.01mlTrain batch 6/32 - 242.7ms/batch - loss: 54.56710 - diff: 19.18mlTrain batch 7/32 - 241.2ms/batch - loss: 54.20735 - diff: 19.73mlTrain batch 8/32 - 241.8ms/batch - loss: 52.01361 - diff: 19.36mlTrain batch 9/32 - 242.2ms/batch - loss: 50.12043 - diff: 18.84mlTrain batch 10/32 - 242.1ms/batch - loss: 47.30041 - diff: 18.47mlTrain batch 11/32 - 242.6ms/batch - loss: 44.84378 - diff: 17.99mlTrain batch 12/32 - 241.6ms/batch - loss: 42.85610 - diff: 17.59mlTrain batch 13/32 - 242.1ms/batch - loss: 41.03726 - diff: 17.06mlTrain batch 14/32 - 241.9ms/batch - loss: 39.17210 - diff: 16.61mlTrain batch 15/32 - 244.1ms/batch - loss: 37.66608 - diff: 16.27mlTrain batch 16/32 - 241.5ms/batch - loss: 36.14175 - diff: 15.96mlTrain batch 17/32 - 242.1ms/batch - loss: 35.60738 - diff: 16.07mlTrain batch 18/32 - 241.4ms/batch - loss: 34.28837 - diff: 15.80mlTrain batch 19/32 - 242.9ms/batch - loss: 34.07580 - diff: 16.03mlTrain batch 20/32 - 241.8ms/batch - loss: 33.84702 - diff: 16.14mlTrain batch 21/32 - 242.1ms/batch - loss: 32.86283 - diff: 15.94mlTrain batch 22/32 - 241.7ms/batch - loss: 32.23408 - diff: 15.84mlTrain batch 23/32 - 242.1ms/batch - loss: 31.28159 - diff: 15.63mlTrain batch 24/32 - 242.1ms/batch - loss: 31.12944 - diff: 15.60mlTrain batch 25/32 - 243.9ms/batch - loss: 30.90534 - diff: 15.63mlTrain batch 26/32 - 242.1ms/batch - loss: 30.88109 - diff: 15.75mlTrain batch 27/32 - 244.2ms/batch - loss: 30.04376 - diff: 15.53mlTrain batch 28/32 - 242.6ms/batch - loss: 29.55784 - diff: 15.38mlTrain batch 29/32 - 244.3ms/batch - loss: 29.65057 - diff: 15.44mlTrain batch 30/32 - 242.0ms/batch - loss: 29.92080 - diff: 15.59mlTrain batch 31/32 - 241.9ms/batch - loss: 29.27537 - diff: 15.44mlTrain batch 32/32 - 77.8ms/batch - loss: 32.07562 - diff: 15.60mlTrain batch 32/32 - 11.3s 77.8ms/batch - loss: 32.07562 - diff: 15.60ml
Test 1.1s: val_loss: 322.28364 - diff: 65.80ml

Epoch 53: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 241.7ms/batch - loss: 11.76147 - diff: 12.25mlTrain batch 2/32 - 241.7ms/batch - loss: 20.58490 - diff: 14.56mlTrain batch 3/32 - 241.4ms/batch - loss: 17.52558 - diff: 13.69mlTrain batch 4/32 - 241.9ms/batch - loss: 17.56257 - diff: 13.65mlTrain batch 5/32 - 241.6ms/batch - loss: 17.78083 - diff: 13.64mlTrain batch 6/32 - 242.1ms/batch - loss: 17.48238 - diff: 13.56mlTrain batch 7/32 - 241.5ms/batch - loss: 16.67568 - diff: 13.19mlTrain batch 8/32 - 241.7ms/batch - loss: 16.03542 - diff: 12.86mlTrain batch 9/32 - 241.7ms/batch - loss: 15.18331 - diff: 12.42mlTrain batch 10/32 - 243.7ms/batch - loss: 16.57474 - diff: 12.81mlTrain batch 11/32 - 241.6ms/batch - loss: 18.54024 - diff: 13.46mlTrain batch 12/32 - 241.9ms/batch - loss: 19.36936 - diff: 13.73mlTrain batch 13/32 - 241.9ms/batch - loss: 28.15978 - diff: 14.94mlTrain batch 14/32 - 242.8ms/batch - loss: 27.48980 - diff: 14.89mlTrain batch 15/32 - 241.5ms/batch - loss: 26.37578 - diff: 14.65mlTrain batch 16/32 - 242.1ms/batch - loss: 28.31535 - diff: 15.01mlTrain batch 17/32 - 241.7ms/batch - loss: 27.44748 - diff: 14.81mlTrain batch 18/32 - 244.4ms/batch - loss: 26.62541 - diff: 14.61mlTrain batch 19/32 - 242.3ms/batch - loss: 25.83663 - diff: 14.40mlTrain batch 20/32 - 244.3ms/batch - loss: 26.44678 - diff: 14.74mlTrain batch 21/32 - 242.0ms/batch - loss: 25.73693 - diff: 14.54mlTrain batch 22/32 - 242.2ms/batch - loss: 25.35533 - diff: 14.47mlTrain batch 23/32 - 241.3ms/batch - loss: 24.68705 - diff: 14.32mlTrain batch 24/32 - 243.0ms/batch - loss: 24.46538 - diff: 14.29mlTrain batch 25/32 - 241.6ms/batch - loss: 23.98441 - diff: 14.23mlTrain batch 26/32 - 243.3ms/batch - loss: 23.35182 - diff: 14.01mlTrain batch 27/32 - 242.0ms/batch - loss: 22.96640 - diff: 13.92mlTrain batch 28/32 - 242.9ms/batch - loss: 22.49903 - diff: 13.79mlTrain batch 29/32 - 241.6ms/batch - loss: 22.02766 - diff: 13.64mlTrain batch 30/32 - 243.7ms/batch - loss: 21.43415 - diff: 13.41mlTrain batch 31/32 - 241.5ms/batch - loss: 20.95802 - diff: 13.27mlTrain batch 32/32 - 78.1ms/batch - loss: 20.90100 - diff: 13.21mlTrain batch 32/32 - 12.5s 78.1ms/batch - loss: 20.90100 - diff: 13.21ml
Test 1.1s: val_loss: 386.72779 - diff: 70.94ml

Epoch 54: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 241.4ms/batch - loss: 7.85374 - diff: 8.47mlTrain batch 2/32 - 241.9ms/batch - loss: 31.21060 - diff: 14.56mlTrain batch 3/32 - 241.3ms/batch - loss: 24.02682 - diff: 13.13mlTrain batch 4/32 - 241.9ms/batch - loss: 21.51957 - diff: 13.00mlTrain batch 5/32 - 241.7ms/batch - loss: 20.28791 - diff: 12.75mlTrain batch 6/32 - 244.2ms/batch - loss: 32.43239 - diff: 15.64mlTrain batch 7/32 - 241.6ms/batch - loss: 28.49203 - diff: 14.35mlTrain batch 8/32 - 244.0ms/batch - loss: 30.10443 - diff: 14.45mlTrain batch 9/32 - 241.9ms/batch - loss: 30.76118 - diff: 14.98mlTrain batch 10/32 - 242.7ms/batch - loss: 28.66870 - diff: 14.43mlTrain batch 11/32 - 241.4ms/batch - loss: 27.02184 - diff: 13.98mlTrain batch 12/32 - 241.9ms/batch - loss: 25.69450 - diff: 13.70mlTrain batch 13/32 - 241.9ms/batch - loss: 26.37618 - diff: 14.27mlTrain batch 14/32 - 242.0ms/batch - loss: 25.69983 - diff: 14.20mlTrain batch 15/32 - 242.0ms/batch - loss: 25.16770 - diff: 14.13mlTrain batch 16/32 - 243.4ms/batch - loss: 24.60717 - diff: 14.02mlTrain batch 17/32 - 242.4ms/batch - loss: 24.81558 - diff: 14.19mlTrain batch 18/32 - 242.6ms/batch - loss: 24.72896 - diff: 14.24mlTrain batch 19/32 - 241.4ms/batch - loss: 24.01453 - diff: 14.10mlTrain batch 20/32 - 242.2ms/batch - loss: 24.10154 - diff: 14.22mlTrain batch 21/32 - 242.5ms/batch - loss: 23.20140 - diff: 13.90mlTrain batch 22/32 - 241.8ms/batch - loss: 22.93673 - diff: 13.79mlTrain batch 23/32 - 242.1ms/batch - loss: 24.00454 - diff: 14.16mlTrain batch 24/32 - 241.9ms/batch - loss: 23.96213 - diff: 14.18mlTrain batch 25/32 - 243.4ms/batch - loss: 24.42997 - diff: 14.40mlTrain batch 26/32 - 242.0ms/batch - loss: 24.12471 - diff: 14.33mlTrain batch 27/32 - 242.5ms/batch - loss: 23.78506 - diff: 14.25mlTrain batch 28/32 - 242.0ms/batch - loss: 24.19536 - diff: 14.34mlTrain batch 29/32 - 241.4ms/batch - loss: 23.99870 - diff: 14.32mlTrain batch 30/32 - 242.1ms/batch - loss: 23.74823 - diff: 14.23mlTrain batch 31/32 - 242.5ms/batch - loss: 23.48413 - diff: 14.20mlTrain batch 32/32 - 78.5ms/batch - loss: 23.58058 - diff: 14.17mlTrain batch 32/32 - 11.8s 78.5ms/batch - loss: 23.58058 - diff: 14.17ml
Test 1.1s: val_loss: 401.49443 - diff: 72.82ml

Epoch 55: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 241.5ms/batch - loss: 15.76250 - diff: 12.52mlTrain batch 2/32 - 242.2ms/batch - loss: 22.14816 - diff: 15.10mlTrain batch 3/32 - 241.6ms/batch - loss: 29.88463 - diff: 17.79mlTrain batch 4/32 - 241.9ms/batch - loss: 25.27655 - diff: 16.13mlTrain batch 5/32 - 242.5ms/batch - loss: 23.48532 - diff: 15.55mlTrain batch 6/32 - 242.6ms/batch - loss: 24.16881 - diff: 15.76mlTrain batch 7/32 - 241.8ms/batch - loss: 46.71540 - diff: 19.02mlTrain batch 8/32 - 241.8ms/batch - loss: 42.60445 - diff: 18.15mlTrain batch 9/32 - 241.9ms/batch - loss: 43.03516 - diff: 18.67mlTrain batch 10/32 - 242.9ms/batch - loss: 41.06479 - diff: 18.34mlTrain batch 11/32 - 241.3ms/batch - loss: 38.43880 - diff: 17.67mlTrain batch 12/32 - 244.3ms/batch - loss: 37.79205 - diff: 17.65mlTrain batch 13/32 - 241.9ms/batch - loss: 36.71644 - diff: 17.50mlTrain batch 14/32 - 244.0ms/batch - loss: 36.33730 - diff: 17.40mlTrain batch 15/32 - 242.2ms/batch - loss: 34.58991 - diff: 16.85mlTrain batch 16/32 - 244.1ms/batch - loss: 33.37016 - diff: 16.55mlTrain batch 17/32 - 241.7ms/batch - loss: 32.39403 - diff: 16.35mlTrain batch 18/32 - 241.9ms/batch - loss: 31.72522 - diff: 16.28mlTrain batch 19/32 - 242.5ms/batch - loss: 30.73576 - diff: 16.03mlTrain batch 20/32 - 241.9ms/batch - loss: 30.03637 - diff: 15.88mlTrain batch 21/32 - 241.7ms/batch - loss: 28.95975 - diff: 15.51mlTrain batch 22/32 - 243.9ms/batch - loss: 28.65110 - diff: 15.47mlTrain batch 23/32 - 241.9ms/batch - loss: 28.26430 - diff: 15.36mlTrain batch 24/32 - 241.6ms/batch - loss: 27.41723 - diff: 15.09mlTrain batch 25/32 - 243.4ms/batch - loss: 27.10142 - diff: 15.07mlTrain batch 26/32 - 241.8ms/batch - loss: 27.70537 - diff: 15.39mlTrain batch 27/32 - 242.0ms/batch - loss: 27.55523 - diff: 15.35mlTrain batch 28/32 - 242.4ms/batch - loss: 26.93144 - diff: 15.14mlTrain batch 29/32 - 242.0ms/batch - loss: 27.13277 - diff: 15.20mlTrain batch 30/32 - 242.6ms/batch - loss: 27.07163 - diff: 15.25mlTrain batch 31/32 - 241.9ms/batch - loss: 27.37718 - diff: 15.35mlTrain batch 32/32 - 77.8ms/batch - loss: 29.70089 - diff: 15.46mlTrain batch 32/32 - 11.6s 77.8ms/batch - loss: 29.70089 - diff: 15.46ml
Test 1.1s: val_loss: 198.47957 - diff: 50.20ml

Epoch 56: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 242.2ms/batch - loss: 11.79765 - diff: 10.74mlTrain batch 2/32 - 243.7ms/batch - loss: 22.44149 - diff: 12.17mlTrain batch 3/32 - 242.0ms/batch - loss: 17.99458 - diff: 11.40mlTrain batch 4/32 - 243.8ms/batch - loss: 15.90740 - diff: 11.17mlTrain batch 5/32 - 241.9ms/batch - loss: 17.19953 - diff: 11.43mlTrain batch 6/32 - 243.8ms/batch - loss: 15.64349 - diff: 11.16mlTrain batch 7/32 - 242.0ms/batch - loss: 15.58648 - diff: 11.42mlTrain batch 8/32 - 243.3ms/batch - loss: 14.91707 - diff: 11.15mlTrain batch 9/32 - 242.4ms/batch - loss: 14.68179 - diff: 11.37mlTrain batch 10/32 - 244.1ms/batch - loss: 15.10734 - diff: 11.65mlTrain batch 11/32 - 242.3ms/batch - loss: 17.88371 - diff: 12.72mlTrain batch 12/32 - 244.3ms/batch - loss: 17.55459 - diff: 12.60mlTrain batch 13/32 - 242.0ms/batch - loss: 16.96670 - diff: 12.37mlTrain batch 14/32 - 243.3ms/batch - loss: 17.74115 - diff: 12.67mlTrain batch 15/32 - 242.2ms/batch - loss: 17.60954 - diff: 12.67mlTrain batch 16/32 - 243.4ms/batch - loss: 17.98778 - diff: 12.93mlTrain batch 17/32 - 241.8ms/batch - loss: 17.71396 - diff: 12.93mlTrain batch 18/32 - 243.5ms/batch - loss: 17.42646 - diff: 12.88mlTrain batch 19/32 - 241.8ms/batch - loss: 17.96040 - diff: 13.13mlTrain batch 20/32 - 242.0ms/batch - loss: 17.95492 - diff: 13.09mlTrain batch 21/32 - 241.6ms/batch - loss: 17.49553 - diff: 12.92mlTrain batch 22/32 - 244.0ms/batch - loss: 17.63156 - diff: 13.01mlTrain batch 23/32 - 242.0ms/batch - loss: 19.72247 - diff: 13.48mlTrain batch 24/32 - 244.0ms/batch - loss: 19.64281 - diff: 13.52mlTrain batch 25/32 - 242.4ms/batch - loss: 19.58938 - diff: 13.55mlTrain batch 26/32 - 244.4ms/batch - loss: 20.37210 - diff: 13.88mlTrain batch 27/32 - 242.5ms/batch - loss: 21.68344 - diff: 14.30mlTrain batch 28/32 - 243.9ms/batch - loss: 21.30273 - diff: 14.15mlTrain batch 29/32 - 241.8ms/batch - loss: 21.20612 - diff: 14.11mlTrain batch 30/32 - 244.1ms/batch - loss: 20.97628 - diff: 14.04mlTrain batch 31/32 - 241.5ms/batch - loss: 23.25500 - diff: 14.49mlTrain batch 32/32 - 78.1ms/batch - loss: 26.83875 - diff: 14.69mlTrain batch 32/32 - 11.7s 78.1ms/batch - loss: 26.83875 - diff: 14.69ml
Test 1.1s: val_loss: 239.97242 - diff: 54.61ml

Epoch 57: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 241.7ms/batch - loss: 48.37390 - diff: 23.96mlTrain batch 2/32 - 242.7ms/batch - loss: 35.65366 - diff: 18.96mlTrain batch 3/32 - 241.9ms/batch - loss: 27.85406 - diff: 16.55mlTrain batch 4/32 - 242.0ms/batch - loss: 25.15981 - diff: 15.55mlTrain batch 5/32 - 241.9ms/batch - loss: 22.49758 - diff: 14.45mlTrain batch 6/32 - 242.5ms/batch - loss: 23.07182 - diff: 14.63mlTrain batch 7/32 - 241.7ms/batch - loss: 22.40009 - diff: 14.24mlTrain batch 8/32 - 242.2ms/batch - loss: 21.61318 - diff: 13.99mlTrain batch 9/32 - 242.0ms/batch - loss: 21.05957 - diff: 13.74mlTrain batch 10/32 - 243.9ms/batch - loss: 22.01876 - diff: 13.99mlTrain batch 11/32 - 242.0ms/batch - loss: 20.83493 - diff: 13.55mlTrain batch 12/32 - 244.0ms/batch - loss: 21.98766 - diff: 13.99mlTrain batch 13/32 - 243.0ms/batch - loss: 21.23518 - diff: 13.72mlTrain batch 14/32 - 244.4ms/batch - loss: 21.15826 - diff: 13.74mlTrain batch 15/32 - 241.8ms/batch - loss: 20.48873 - diff: 13.54mlTrain batch 16/32 - 242.0ms/batch - loss: 20.28099 - diff: 13.53mlTrain batch 17/32 - 241.9ms/batch - loss: 19.74302 - diff: 13.33mlTrain batch 18/32 - 241.5ms/batch - loss: 20.21374 - diff: 13.47mlTrain batch 19/32 - 242.7ms/batch - loss: 20.05913 - diff: 13.53mlTrain batch 20/32 - 241.7ms/batch - loss: 20.39452 - diff: 13.60mlTrain batch 21/32 - 242.1ms/batch - loss: 21.18612 - diff: 13.99mlTrain batch 22/32 - 242.5ms/batch - loss: 21.43014 - diff: 14.05mlTrain batch 23/32 - 244.3ms/batch - loss: 28.36680 - diff: 14.75mlTrain batch 24/32 - 242.7ms/batch - loss: 28.21591 - diff: 14.82mlTrain batch 25/32 - 243.4ms/batch - loss: 27.38746 - diff: 14.59mlTrain batch 26/32 - 242.3ms/batch - loss: 26.63086 - diff: 14.37mlTrain batch 27/32 - 242.3ms/batch - loss: 26.46528 - diff: 14.40mlTrain batch 28/32 - 241.8ms/batch - loss: 25.76594 - diff: 14.19mlTrain batch 29/32 - 242.6ms/batch - loss: 25.91431 - diff: 14.29mlTrain batch 30/32 - 242.5ms/batch - loss: 25.60108 - diff: 14.23mlTrain batch 31/32 - 241.9ms/batch - loss: 25.06251 - diff: 14.08mlTrain batch 32/32 - 79.0ms/batch - loss: 26.67821 - diff: 14.19mlTrain batch 32/32 - 11.7s 79.0ms/batch - loss: 26.67821 - diff: 14.19ml
Test 1.1s: val_loss: 385.47329 - diff: 70.58ml

Epoch 58: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 241.8ms/batch - loss: 12.53168 - diff: 12.86mlTrain batch 2/32 - 242.0ms/batch - loss: 15.29349 - diff: 13.73mlTrain batch 3/32 - 241.4ms/batch - loss: 12.54580 - diff: 12.27mlTrain batch 4/32 - 242.0ms/batch - loss: 16.48207 - diff: 12.78mlTrain batch 5/32 - 241.8ms/batch - loss: 18.13029 - diff: 13.54mlTrain batch 6/32 - 242.6ms/batch - loss: 18.80904 - diff: 13.75mlTrain batch 7/32 - 241.9ms/batch - loss: 17.79418 - diff: 13.45mlTrain batch 8/32 - 242.0ms/batch - loss: 17.84002 - diff: 13.24mlTrain batch 9/32 - 242.0ms/batch - loss: 19.76738 - diff: 13.78mlTrain batch 10/32 - 244.4ms/batch - loss: 20.37132 - diff: 14.07mlTrain batch 11/32 - 241.6ms/batch - loss: 20.54569 - diff: 14.02mlTrain batch 12/32 - 242.0ms/batch - loss: 21.29927 - diff: 14.46mlTrain batch 13/32 - 242.0ms/batch - loss: 20.28334 - diff: 14.01mlTrain batch 14/32 - 244.4ms/batch - loss: 20.31726 - diff: 14.17mlTrain batch 15/32 - 241.7ms/batch - loss: 19.63935 - diff: 13.95mlTrain batch 16/32 - 244.4ms/batch - loss: 19.03297 - diff: 13.67mlTrain batch 17/32 - 242.0ms/batch - loss: 19.01001 - diff: 13.67mlTrain batch 18/32 - 243.7ms/batch - loss: 18.95999 - diff: 13.63mlTrain batch 19/32 - 241.7ms/batch - loss: 18.45426 - diff: 13.44mlTrain batch 20/32 - 243.9ms/batch - loss: 18.23138 - diff: 13.40mlTrain batch 21/32 - 241.5ms/batch - loss: 22.56841 - diff: 14.47mlTrain batch 22/32 - 243.6ms/batch - loss: 22.36384 - diff: 14.36mlTrain batch 23/32 - 242.5ms/batch - loss: 22.19296 - diff: 14.37mlTrain batch 24/32 - 242.7ms/batch - loss: 21.56817 - diff: 14.16mlTrain batch 25/32 - 242.0ms/batch - loss: 21.30463 - diff: 14.05mlTrain batch 26/32 - 244.4ms/batch - loss: 21.16610 - diff: 14.02mlTrain batch 27/32 - 241.6ms/batch - loss: 20.78881 - diff: 13.91mlTrain batch 28/32 - 244.0ms/batch - loss: 20.88929 - diff: 13.94mlTrain batch 29/32 - 242.3ms/batch - loss: 22.75044 - diff: 14.32mlTrain batch 30/32 - 242.4ms/batch - loss: 22.32124 - diff: 14.19mlTrain batch 31/32 - 241.9ms/batch - loss: 21.99781 - diff: 14.08mlTrain batch 32/32 - 78.3ms/batch - loss: 24.65465 - diff: 14.26mlTrain batch 32/32 - 11.3s 78.3ms/batch - loss: 24.65465 - diff: 14.26ml
Test 1.2s: val_loss: 277.02895 - diff: 58.38ml

Epoch 59: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 241.6ms/batch - loss: 12.28326 - diff: 12.24mlTrain batch 2/32 - 241.8ms/batch - loss: 9.90029 - diff: 10.61mlTrain batch 3/32 - 241.9ms/batch - loss: 13.10892 - diff: 11.50mlTrain batch 4/32 - 242.1ms/batch - loss: 12.32629 - diff: 11.15mlTrain batch 5/32 - 242.0ms/batch - loss: 13.00524 - diff: 11.38mlTrain batch 6/32 - 242.5ms/batch - loss: 13.75544 - diff: 11.85mlTrain batch 7/32 - 241.9ms/batch - loss: 13.03049 - diff: 11.61mlTrain batch 8/32 - 243.7ms/batch - loss: 12.92721 - diff: 11.51mlTrain batch 9/32 - 244.1ms/batch - loss: 13.83001 - diff: 11.85mlTrain batch 10/32 - 241.9ms/batch - loss: 13.41961 - diff: 11.62mlTrain batch 11/32 - 243.2ms/batch - loss: 14.68636 - diff: 12.11mlTrain batch 12/32 - 241.9ms/batch - loss: 14.67489 - diff: 12.13mlTrain batch 13/32 - 243.7ms/batch - loss: 14.46167 - diff: 12.04mlTrain batch 14/32 - 242.1ms/batch - loss: 16.25530 - diff: 12.41mlTrain batch 15/32 - 242.5ms/batch - loss: 16.60249 - diff: 12.44mlTrain batch 16/32 - 241.7ms/batch - loss: 15.97341 - diff: 12.09mlTrain batch 17/32 - 244.4ms/batch - loss: 15.66284 - diff: 11.98mlTrain batch 18/32 - 242.1ms/batch - loss: 15.96086 - diff: 12.20mlTrain batch 19/32 - 243.0ms/batch - loss: 15.75788 - diff: 12.19mlTrain batch 20/32 - 241.4ms/batch - loss: 15.34041 - diff: 12.04mlTrain batch 21/32 - 243.0ms/batch - loss: 15.46258 - diff: 12.14mlTrain batch 22/32 - 241.8ms/batch - loss: 16.41378 - diff: 12.51mlTrain batch 23/32 - 242.1ms/batch - loss: 16.19935 - diff: 12.44mlTrain batch 24/32 - 242.0ms/batch - loss: 16.08928 - diff: 12.45mlTrain batch 25/32 - 244.4ms/batch - loss: 21.11760 - diff: 13.09mlTrain batch 26/32 - 241.8ms/batch - loss: 21.70129 - diff: 13.28mlTrain batch 27/32 - 243.4ms/batch - loss: 21.23132 - diff: 13.15mlTrain batch 28/32 - 242.2ms/batch - loss: 22.42485 - diff: 13.54mlTrain batch 29/32 - 244.3ms/batch - loss: 22.93010 - diff: 13.81mlTrain batch 30/32 - 242.0ms/batch - loss: 24.45132 - diff: 14.16mlTrain batch 31/32 - 243.4ms/batch - loss: 24.30840 - diff: 14.16mlTrain batch 32/32 - 79.4ms/batch - loss: 24.35415 - diff: 14.12mlTrain batch 32/32 - 11.4s 79.4ms/batch - loss: 24.35415 - diff: 14.12ml
Test 1.1s: val_loss: 170.86285 - diff: 44.78ml
Epoch    60: reducing learning rate of group 0 to 3.1250e-05.

Epoch 60: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 241.8ms/batch - loss: 10.97916 - diff: 11.12mlTrain batch 2/32 - 242.5ms/batch - loss: 10.91064 - diff: 11.27mlTrain batch 3/32 - 241.9ms/batch - loss: 9.57738 - diff: 10.43mlTrain batch 4/32 - 241.9ms/batch - loss: 9.90929 - diff: 10.58mlTrain batch 5/32 - 241.7ms/batch - loss: 10.58551 - diff: 10.47mlTrain batch 6/32 - 241.9ms/batch - loss: 10.30822 - diff: 10.35mlTrain batch 7/32 - 241.9ms/batch - loss: 11.22118 - diff: 10.85mlTrain batch 8/32 - 242.8ms/batch - loss: 18.27342 - diff: 12.63mlTrain batch 9/32 - 242.7ms/batch - loss: 19.46928 - diff: 13.04mlTrain batch 10/32 - 241.9ms/batch - loss: 20.37267 - diff: 13.38mlTrain batch 11/32 - 244.4ms/batch - loss: 19.88905 - diff: 13.39mlTrain batch 12/32 - 242.0ms/batch - loss: 19.07331 - diff: 13.15mlTrain batch 13/32 - 242.1ms/batch - loss: 18.20512 - diff: 12.77mlTrain batch 14/32 - 241.8ms/batch - loss: 18.93380 - diff: 13.06mlTrain batch 15/32 - 243.7ms/batch - loss: 18.02443 - diff: 12.65mlTrain batch 16/32 - 242.6ms/batch - loss: 18.04944 - diff: 12.72mlTrain batch 17/32 - 244.1ms/batch - loss: 17.35760 - diff: 12.42mlTrain batch 18/32 - 241.5ms/batch - loss: 17.60727 - diff: 12.58mlTrain batch 19/32 - 243.2ms/batch - loss: 17.93028 - diff: 12.70mlTrain batch 20/32 - 245.4ms/batch - loss: 17.40928 - diff: 12.49mlTrain batch 21/32 - 242.2ms/batch - loss: 17.43361 - diff: 12.61mlTrain batch 22/32 - 241.7ms/batch - loss: 17.40822 - diff: 12.61mlTrain batch 23/32 - 243.2ms/batch - loss: 17.01898 - diff: 12.46mlTrain batch 24/32 - 242.1ms/batch - loss: 16.78703 - diff: 12.38mlTrain batch 25/32 - 244.2ms/batch - loss: 16.72606 - diff: 12.33mlTrain batch 26/32 - 242.7ms/batch - loss: 16.85120 - diff: 12.41mlTrain batch 27/32 - 244.4ms/batch - loss: 16.81250 - diff: 12.41mlTrain batch 28/32 - 242.2ms/batch - loss: 16.63693 - diff: 12.37mlTrain batch 29/32 - 243.6ms/batch - loss: 16.65783 - diff: 12.41mlTrain batch 30/32 - 242.7ms/batch - loss: 17.18429 - diff: 12.41mlTrain batch 31/32 - 244.0ms/batch - loss: 16.85474 - diff: 12.30mlTrain batch 32/32 - 78.6ms/batch - loss: 17.90505 - diff: 12.38mlTrain batch 32/32 - 12.4s 78.6ms/batch - loss: 17.90505 - diff: 12.38ml
Test 1.1s: val_loss: 134.25872 - diff: 39.87ml

Epoch 61: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 241.6ms/batch - loss: 15.56324 - diff: 13.30mlTrain batch 2/32 - 241.8ms/batch - loss: 17.60357 - diff: 14.14mlTrain batch 3/32 - 242.1ms/batch - loss: 16.55289 - diff: 14.07mlTrain batch 4/32 - 242.5ms/batch - loss: 20.29166 - diff: 15.10mlTrain batch 5/32 - 242.2ms/batch - loss: 17.93805 - diff: 14.10mlTrain batch 6/32 - 244.3ms/batch - loss: 17.34359 - diff: 13.89mlTrain batch 7/32 - 241.8ms/batch - loss: 16.57839 - diff: 13.59mlTrain batch 8/32 - 242.3ms/batch - loss: 16.39263 - diff: 12.99mlTrain batch 9/32 - 241.3ms/batch - loss: 15.91798 - diff: 12.86mlTrain batch 10/32 - 241.8ms/batch - loss: 15.47808 - diff: 12.52mlTrain batch 11/32 - 241.9ms/batch - loss: 14.54368 - diff: 12.06mlTrain batch 12/32 - 242.1ms/batch - loss: 14.57681 - diff: 12.15mlTrain batch 13/32 - 242.2ms/batch - loss: 14.92743 - diff: 12.29mlTrain batch 14/32 - 244.1ms/batch - loss: 14.36773 - diff: 12.04mlTrain batch 15/32 - 241.8ms/batch - loss: 13.85405 - diff: 11.74mlTrain batch 16/32 - 242.2ms/batch - loss: 13.93947 - diff: 11.84mlTrain batch 17/32 - 241.7ms/batch - loss: 13.92578 - diff: 11.78mlTrain batch 18/32 - 243.3ms/batch - loss: 14.00013 - diff: 11.73mlTrain batch 19/32 - 242.9ms/batch - loss: 18.50510 - diff: 12.77mlTrain batch 20/32 - 243.3ms/batch - loss: 18.56656 - diff: 12.87mlTrain batch 21/32 - 241.7ms/batch - loss: 18.04593 - diff: 12.63mlTrain batch 22/32 - 244.3ms/batch - loss: 17.85176 - diff: 12.53mlTrain batch 23/32 - 241.9ms/batch - loss: 18.00309 - diff: 12.64mlTrain batch 24/32 - 242.3ms/batch - loss: 17.70135 - diff: 12.55mlTrain batch 25/32 - 241.6ms/batch - loss: 17.48044 - diff: 12.47mlTrain batch 26/32 - 244.2ms/batch - loss: 18.40697 - diff: 12.82mlTrain batch 27/32 - 241.7ms/batch - loss: 18.72874 - diff: 13.00mlTrain batch 28/32 - 244.4ms/batch - loss: 18.52802 - diff: 12.87mlTrain batch 29/32 - 242.7ms/batch - loss: 18.40529 - diff: 12.84mlTrain batch 30/32 - 242.6ms/batch - loss: 18.66958 - diff: 13.01mlTrain batch 31/32 - 242.0ms/batch - loss: 18.41263 - diff: 12.94mlTrain batch 32/32 - 79.1ms/batch - loss: 18.83359 - diff: 12.95mlTrain batch 32/32 - 11.9s 79.1ms/batch - loss: 18.83359 - diff: 12.95ml
Test 1.2s: val_loss: 352.63003 - diff: 68.39ml

Epoch 62: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 241.5ms/batch - loss: 16.48849 - diff: 13.68mlTrain batch 2/32 - 242.4ms/batch - loss: 13.17224 - diff: 12.23mlTrain batch 3/32 - 241.9ms/batch - loss: 18.26498 - diff: 13.89mlTrain batch 4/32 - 242.2ms/batch - loss: 16.65760 - diff: 13.06mlTrain batch 5/32 - 243.0ms/batch - loss: 17.64129 - diff: 13.36mlTrain batch 6/32 - 243.8ms/batch - loss: 17.39642 - diff: 13.41mlTrain batch 7/32 - 241.8ms/batch - loss: 16.12971 - diff: 12.89mlTrain batch 8/32 - 243.5ms/batch - loss: 14.52209 - diff: 11.98mlTrain batch 9/32 - 241.9ms/batch - loss: 15.37944 - diff: 12.26mlTrain batch 10/32 - 244.0ms/batch - loss: 14.92978 - diff: 12.07mlTrain batch 11/32 - 241.9ms/batch - loss: 16.21391 - diff: 12.63mlTrain batch 12/32 - 242.3ms/batch - loss: 15.28747 - diff: 12.13mlTrain batch 13/32 - 242.0ms/batch - loss: 16.04192 - diff: 12.49mlTrain batch 14/32 - 243.7ms/batch - loss: 16.54702 - diff: 12.74mlTrain batch 15/32 - 241.9ms/batch - loss: 15.97464 - diff: 12.53mlTrain batch 16/32 - 244.6ms/batch - loss: 15.77784 - diff: 12.47mlTrain batch 17/32 - 242.6ms/batch - loss: 15.16414 - diff: 12.19mlTrain batch 18/32 - 242.8ms/batch - loss: 14.98851 - diff: 12.10mlTrain batch 19/32 - 242.0ms/batch - loss: 14.57256 - diff: 11.89mlTrain batch 20/32 - 242.2ms/batch - loss: 14.21617 - diff: 11.78mlTrain batch 21/32 - 242.0ms/batch - loss: 13.81651 - diff: 11.61mlTrain batch 22/32 - 244.6ms/batch - loss: 13.89074 - diff: 11.69mlTrain batch 23/32 - 242.2ms/batch - loss: 13.86840 - diff: 11.66mlTrain batch 24/32 - 244.2ms/batch - loss: 18.18748 - diff: 12.48mlTrain batch 25/32 - 241.9ms/batch - loss: 18.35065 - diff: 12.53mlTrain batch 26/32 - 243.7ms/batch - loss: 18.07166 - diff: 12.48mlTrain batch 27/32 - 242.1ms/batch - loss: 19.13781 - diff: 12.66mlTrain batch 28/32 - 243.2ms/batch - loss: 19.87731 - diff: 13.02mlTrain batch 29/32 - 242.0ms/batch - loss: 19.33904 - diff: 12.77mlTrain batch 30/32 - 243.9ms/batch - loss: 19.20387 - diff: 12.73mlTrain batch 31/32 - 241.8ms/batch - loss: 18.89738 - diff: 12.66mlTrain batch 32/32 - 79.4ms/batch - loss: 20.58926 - diff: 12.79mlTrain batch 32/32 - 11.5s 79.4ms/batch - loss: 20.58926 - diff: 12.79ml
Test 1.2s: val_loss: 411.64365 - diff: 74.31ml

Epoch 63: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 241.9ms/batch - loss: 5.58556 - diff: 7.32mlTrain batch 2/32 - 242.9ms/batch - loss: 6.49088 - diff: 7.57mlTrain batch 3/32 - 241.9ms/batch - loss: 25.78324 - diff: 14.69mlTrain batch 4/32 - 242.2ms/batch - loss: 22.26473 - diff: 13.92mlTrain batch 5/32 - 241.7ms/batch - loss: 22.72063 - diff: 14.60mlTrain batch 6/32 - 242.6ms/batch - loss: 23.56926 - diff: 15.26mlTrain batch 7/32 - 242.5ms/batch - loss: 21.90264 - diff: 14.42mlTrain batch 8/32 - 244.2ms/batch - loss: 21.11088 - diff: 14.13mlTrain batch 9/32 - 241.8ms/batch - loss: 22.63496 - diff: 15.01mlTrain batch 10/32 - 244.0ms/batch - loss: 21.49711 - diff: 14.57mlTrain batch 11/32 - 242.7ms/batch - loss: 21.34216 - diff: 14.64mlTrain batch 12/32 - 244.3ms/batch - loss: 20.17783 - diff: 14.12mlTrain batch 13/32 - 242.2ms/batch - loss: 19.18652 - diff: 13.73mlTrain batch 14/32 - 243.7ms/batch - loss: 19.02992 - diff: 13.77mlTrain batch 15/32 - 242.3ms/batch - loss: 18.11061 - diff: 13.28mlTrain batch 16/32 - 243.6ms/batch - loss: 17.60067 - diff: 13.15mlTrain batch 17/32 - 241.9ms/batch - loss: 17.02046 - diff: 12.93mlTrain batch 18/32 - 243.7ms/batch - loss: 16.30819 - diff: 12.57mlTrain batch 19/32 - 242.5ms/batch - loss: 16.88929 - diff: 12.76mlTrain batch 20/32 - 242.2ms/batch - loss: 16.62511 - diff: 12.61mlTrain batch 21/32 - 242.1ms/batch - loss: 16.12894 - diff: 12.37mlTrain batch 22/32 - 244.5ms/batch - loss: 15.83426 - diff: 12.29mlTrain batch 23/32 - 242.7ms/batch - loss: 17.67098 - diff: 12.87mlTrain batch 24/32 - 244.6ms/batch - loss: 17.42222 - diff: 12.78mlTrain batch 25/32 - 242.0ms/batch - loss: 17.01860 - diff: 12.61mlTrain batch 26/32 - 242.3ms/batch - loss: 16.95677 - diff: 12.61mlTrain batch 27/32 - 241.7ms/batch - loss: 16.53536 - diff: 12.44mlTrain batch 28/32 - 244.2ms/batch - loss: 16.28847 - diff: 12.34mlTrain batch 29/32 - 242.3ms/batch - loss: 16.61463 - diff: 12.45mlTrain batch 30/32 - 244.2ms/batch - loss: 16.55087 - diff: 12.48mlTrain batch 31/32 - 242.0ms/batch - loss: 16.33793 - diff: 12.36mlTrain batch 32/32 - 78.9ms/batch - loss: 18.05021 - diff: 12.47mlTrain batch 32/32 - 11.4s 78.9ms/batch - loss: 18.05021 - diff: 12.47ml
Test 1.2s: val_loss: 299.34877 - diff: 61.79ml

Epoch 64: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 247.1ms/batch - loss: 14.78859 - diff: 13.71mlTrain batch 2/32 - 241.9ms/batch - loss: 46.30988 - diff: 17.84mlTrain batch 3/32 - 242.3ms/batch - loss: 32.89498 - diff: 13.94mlTrain batch 4/32 - 242.1ms/batch - loss: 26.27415 - diff: 12.40mlTrain batch 5/32 - 243.0ms/batch - loss: 26.18285 - diff: 13.48mlTrain batch 6/32 - 242.3ms/batch - loss: 25.65275 - diff: 13.85mlTrain batch 7/32 - 242.1ms/batch - loss: 22.72540 - diff: 12.96mlTrain batch 8/32 - 242.1ms/batch - loss: 21.32163 - diff: 12.67mlTrain batch 9/32 - 242.0ms/batch - loss: 21.00417 - diff: 12.86mlTrain batch 10/32 - 241.5ms/batch - loss: 19.69551 - diff: 12.56mlTrain batch 11/32 - 244.0ms/batch - loss: 18.50691 - diff: 12.17mlTrain batch 12/32 - 241.9ms/batch - loss: 17.98919 - diff: 12.13mlTrain batch 13/32 - 242.1ms/batch - loss: 17.50055 - diff: 12.03mlTrain batch 14/32 - 241.7ms/batch - loss: 18.09471 - diff: 12.46mlTrain batch 15/32 - 242.0ms/batch - loss: 18.89379 - diff: 12.77mlTrain batch 16/32 - 243.2ms/batch - loss: 18.83317 - diff: 12.80mlTrain batch 17/32 - 242.2ms/batch - loss: 18.77677 - diff: 12.89mlTrain batch 18/32 - 241.3ms/batch - loss: 19.53748 - diff: 13.15mlTrain batch 19/32 - 241.9ms/batch - loss: 19.12237 - diff: 13.02mlTrain batch 20/32 - 242.1ms/batch - loss: 18.46302 - diff: 12.75mlTrain batch 21/32 - 244.5ms/batch - loss: 18.05211 - diff: 12.60mlTrain batch 22/32 - 242.3ms/batch - loss: 18.07976 - diff: 12.60mlTrain batch 23/32 - 244.3ms/batch - loss: 18.61957 - diff: 12.68mlTrain batch 24/32 - 242.1ms/batch - loss: 18.50831 - diff: 12.66mlTrain batch 25/32 - 244.6ms/batch - loss: 18.26024 - diff: 12.58mlTrain batch 26/32 - 243.6ms/batch - loss: 17.83945 - diff: 12.44mlTrain batch 27/32 - 242.1ms/batch - loss: 17.64784 - diff: 12.43mlTrain batch 28/32 - 242.3ms/batch - loss: 17.32113 - diff: 12.30mlTrain batch 29/32 - 244.4ms/batch - loss: 17.16942 - diff: 12.24mlTrain batch 30/32 - 242.0ms/batch - loss: 16.82675 - diff: 12.15mlTrain batch 31/32 - 242.1ms/batch - loss: 16.67014 - diff: 12.12mlTrain batch 32/32 - 79.8ms/batch - loss: 17.33655 - diff: 12.15mlTrain batch 32/32 - 12.3s 79.8ms/batch - loss: 17.33655 - diff: 12.15ml
Test 1.2s: val_loss: 185.86598 - diff: 48.97ml

Epoch 65: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 244.7ms/batch - loss: 9.39013 - diff: 9.13mlTrain batch 2/32 - 242.2ms/batch - loss: 10.83471 - diff: 10.35mlTrain batch 3/32 - 241.7ms/batch - loss: 18.16470 - diff: 12.08mlTrain batch 4/32 - 241.7ms/batch - loss: 18.29657 - diff: 12.51mlTrain batch 5/32 - 243.3ms/batch - loss: 15.97797 - diff: 11.57mlTrain batch 6/32 - 241.7ms/batch - loss: 14.64269 - diff: 11.10mlTrain batch 7/32 - 244.5ms/batch - loss: 13.58704 - diff: 10.81mlTrain batch 8/32 - 242.0ms/batch - loss: 13.59118 - diff: 10.96mlTrain batch 9/32 - 244.0ms/batch - loss: 12.98385 - diff: 10.81mlTrain batch 10/32 - 242.7ms/batch - loss: 13.01575 - diff: 10.98mlTrain batch 11/32 - 242.0ms/batch - loss: 19.31134 - diff: 12.78mlTrain batch 12/32 - 243.1ms/batch - loss: 18.27743 - diff: 12.43mlTrain batch 13/32 - 241.9ms/batch - loss: 17.97111 - diff: 12.39mlTrain batch 14/32 - 244.2ms/batch - loss: 20.13630 - diff: 12.87mlTrain batch 15/32 - 241.8ms/batch - loss: 19.24807 - diff: 12.54mlTrain batch 16/32 - 244.3ms/batch - loss: 19.35725 - diff: 12.73mlTrain batch 17/32 - 242.0ms/batch - loss: 20.36207 - diff: 13.23mlTrain batch 18/32 - 243.3ms/batch - loss: 20.03658 - diff: 13.15mlTrain batch 19/32 - 242.6ms/batch - loss: 19.24750 - diff: 12.84mlTrain batch 20/32 - 243.4ms/batch - loss: 18.72176 - diff: 12.71mlTrain batch 21/32 - 241.8ms/batch - loss: 18.71985 - diff: 12.71mlTrain batch 22/32 - 244.1ms/batch - loss: 18.37586 - diff: 12.66mlTrain batch 23/32 - 242.7ms/batch - loss: 18.16357 - diff: 12.59mlTrain batch 24/32 - 244.3ms/batch - loss: 17.65451 - diff: 12.45mlTrain batch 25/32 - 241.7ms/batch - loss: 17.40049 - diff: 12.37mlTrain batch 26/32 - 244.3ms/batch - loss: 16.94510 - diff: 12.18mlTrain batch 27/32 - 241.8ms/batch - loss: 16.86726 - diff: 12.17mlTrain batch 28/32 - 244.3ms/batch - loss: 16.56515 - diff: 12.09mlTrain batch 29/32 - 241.9ms/batch - loss: 16.23592 - diff: 11.95mlTrain batch 30/32 - 244.3ms/batch - loss: 16.21893 - diff: 12.00mlTrain batch 31/32 - 241.8ms/batch - loss: 16.12204 - diff: 11.98mlTrain batch 32/32 - 78.9ms/batch - loss: 16.42923 - diff: 11.98mlTrain batch 32/32 - 11.7s 78.9ms/batch - loss: 16.42923 - diff: 11.98ml
Test 1.1s: val_loss: 349.67205 - diff: 68.25ml

Epoch 66: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 242.0ms/batch - loss: 9.62446 - diff: 10.52mlTrain batch 2/32 - 241.5ms/batch - loss: 11.50113 - diff: 10.95mlTrain batch 3/32 - 242.0ms/batch - loss: 13.52910 - diff: 11.64mlTrain batch 4/32 - 242.5ms/batch - loss: 13.60560 - diff: 12.02mlTrain batch 5/32 - 241.9ms/batch - loss: 15.17491 - diff: 12.60mlTrain batch 6/32 - 242.1ms/batch - loss: 14.82247 - diff: 12.54mlTrain batch 7/32 - 241.9ms/batch - loss: 14.13677 - diff: 12.10mlTrain batch 8/32 - 244.4ms/batch - loss: 13.55162 - diff: 11.80mlTrain batch 9/32 - 242.1ms/batch - loss: 12.63029 - diff: 11.35mlTrain batch 10/32 - 244.1ms/batch - loss: 12.38116 - diff: 11.24mlTrain batch 11/32 - 242.4ms/batch - loss: 12.01164 - diff: 11.05mlTrain batch 12/32 - 244.3ms/batch - loss: 11.87701 - diff: 11.06mlTrain batch 13/32 - 241.3ms/batch - loss: 11.37797 - diff: 10.80mlTrain batch 14/32 - 244.3ms/batch - loss: 11.07193 - diff: 10.62mlTrain batch 15/32 - 242.2ms/batch - loss: 11.98816 - diff: 11.02mlTrain batch 16/32 - 243.2ms/batch - loss: 11.93719 - diff: 10.97mlTrain batch 17/32 - 242.1ms/batch - loss: 12.08696 - diff: 11.01mlTrain batch 18/32 - 241.9ms/batch - loss: 12.43604 - diff: 11.18mlTrain batch 19/32 - 243.7ms/batch - loss: 12.43816 - diff: 11.21mlTrain batch 20/32 - 241.9ms/batch - loss: 12.14858 - diff: 11.05mlTrain batch 21/32 - 244.3ms/batch - loss: 11.91107 - diff: 10.93mlTrain batch 22/32 - 241.9ms/batch - loss: 11.73382 - diff: 10.89mlTrain batch 23/32 - 242.2ms/batch - loss: 11.80057 - diff: 10.92mlTrain batch 24/32 - 241.8ms/batch - loss: 11.77024 - diff: 10.94mlTrain batch 25/32 - 242.0ms/batch - loss: 16.52834 - diff: 12.05mlTrain batch 26/32 - 244.4ms/batch - loss: 16.42950 - diff: 12.09mlTrain batch 27/32 - 242.9ms/batch - loss: 16.16937 - diff: 12.02mlTrain batch 28/32 - 243.8ms/batch - loss: 15.79661 - diff: 11.86mlTrain batch 29/32 - 242.1ms/batch - loss: 15.49717 - diff: 11.76mlTrain batch 30/32 - 244.3ms/batch - loss: 17.18700 - diff: 12.29mlTrain batch 31/32 - 242.1ms/batch - loss: 16.82615 - diff: 12.17mlTrain batch 32/32 - 79.4ms/batch - loss: 20.58148 - diff: 12.39mlTrain batch 32/32 - 11.9s 79.4ms/batch - loss: 20.58148 - diff: 12.39ml
Test 1.2s: val_loss: 320.70558 - diff: 66.05ml

Epoch 67: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 241.5ms/batch - loss: 33.40969 - diff: 19.49mlTrain batch 2/32 - 243.9ms/batch - loss: 21.33789 - diff: 14.84mlTrain batch 3/32 - 242.4ms/batch - loss: 22.13756 - diff: 15.01mlTrain batch 4/32 - 244.0ms/batch - loss: 19.83566 - diff: 14.34mlTrain batch 5/32 - 242.7ms/batch - loss: 18.36496 - diff: 13.65mlTrain batch 6/32 - 243.4ms/batch - loss: 21.19355 - diff: 14.57mlTrain batch 7/32 - 242.3ms/batch - loss: 20.75255 - diff: 14.57mlTrain batch 8/32 - 244.2ms/batch - loss: 21.30592 - diff: 14.57mlTrain batch 9/32 - 241.9ms/batch - loss: 20.27367 - diff: 14.26mlTrain batch 10/32 - 242.8ms/batch - loss: 19.00410 - diff: 13.78mlTrain batch 11/32 - 242.0ms/batch - loss: 19.11733 - diff: 13.77mlTrain batch 12/32 - 242.1ms/batch - loss: 18.68450 - diff: 13.60mlTrain batch 13/32 - 242.7ms/batch - loss: 18.22070 - diff: 13.44mlTrain batch 14/32 - 244.4ms/batch - loss: 20.71652 - diff: 14.13mlTrain batch 15/32 - 241.9ms/batch - loss: 20.28803 - diff: 14.07mlTrain batch 16/32 - 243.4ms/batch - loss: 26.35463 - diff: 15.45mlTrain batch 17/32 - 241.8ms/batch - loss: 25.12546 - diff: 15.00mlTrain batch 18/32 - 242.0ms/batch - loss: 24.61412 - diff: 14.84mlTrain batch 19/32 - 242.0ms/batch - loss: 23.71489 - diff: 14.55mlTrain batch 20/32 - 244.5ms/batch - loss: 24.02210 - diff: 14.77mlTrain batch 21/32 - 241.9ms/batch - loss: 23.35452 - diff: 14.51mlTrain batch 22/32 - 243.8ms/batch - loss: 22.75680 - diff: 14.28mlTrain batch 23/32 - 241.9ms/batch - loss: 23.43257 - diff: 14.53mlTrain batch 24/32 - 244.3ms/batch - loss: 25.26565 - diff: 15.04mlTrain batch 25/32 - 241.9ms/batch - loss: 24.60078 - diff: 14.83mlTrain batch 26/32 - 243.4ms/batch - loss: 24.28087 - diff: 14.78mlTrain batch 27/32 - 242.0ms/batch - loss: 24.17775 - diff: 14.78mlTrain batch 28/32 - 242.5ms/batch - loss: 23.67223 - diff: 14.56mlTrain batch 29/32 - 242.4ms/batch - loss: 23.81022 - diff: 14.73mlTrain batch 30/32 - 244.1ms/batch - loss: 24.51593 - diff: 15.01mlTrain batch 31/32 - 241.9ms/batch - loss: 24.08217 - diff: 14.88mlTrain batch 32/32 - 78.6ms/batch - loss: 25.03555 - diff: 14.94mlTrain batch 32/32 - 11.9s 78.6ms/batch - loss: 25.03555 - diff: 14.94ml
Test 1.2s: val_loss: 403.14981 - diff: 74.15ml

Epoch 68: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 241.9ms/batch - loss: 28.74946 - diff: 15.99mlTrain batch 2/32 - 241.9ms/batch - loss: 27.70607 - diff: 15.38mlTrain batch 3/32 - 241.5ms/batch - loss: 36.20480 - diff: 18.20mlTrain batch 4/32 - 242.2ms/batch - loss: 30.49981 - diff: 16.61mlTrain batch 5/32 - 241.4ms/batch - loss: 28.24672 - diff: 15.55mlTrain batch 6/32 - 241.7ms/batch - loss: 24.51727 - diff: 14.10mlTrain batch 7/32 - 243.1ms/batch - loss: 21.67042 - diff: 13.17mlTrain batch 8/32 - 243.2ms/batch - loss: 19.76725 - diff: 12.56mlTrain batch 9/32 - 242.3ms/batch - loss: 18.15623 - diff: 11.95mlTrain batch 10/32 - 242.3ms/batch - loss: 16.94589 - diff: 11.57mlTrain batch 11/32 - 242.9ms/batch - loss: 16.13822 - diff: 11.35mlTrain batch 12/32 - 242.3ms/batch - loss: 15.39754 - diff: 11.13mlTrain batch 13/32 - 242.0ms/batch - loss: 14.88160 - diff: 10.94mlTrain batch 14/32 - 244.2ms/batch - loss: 14.92660 - diff: 11.12mlTrain batch 15/32 - 242.6ms/batch - loss: 14.33278 - diff: 10.89mlTrain batch 16/32 - 241.9ms/batch - loss: 13.72253 - diff: 10.65mlTrain batch 17/32 - 241.9ms/batch - loss: 13.35492 - diff: 10.56mlTrain batch 18/32 - 244.4ms/batch - loss: 14.18529 - diff: 10.88mlTrain batch 19/32 - 241.9ms/batch - loss: 14.62989 - diff: 11.13mlTrain batch 20/32 - 244.7ms/batch - loss: 14.94516 - diff: 11.31mlTrain batch 21/32 - 242.0ms/batch - loss: 15.04737 - diff: 11.45mlTrain batch 22/32 - 243.9ms/batch - loss: 14.61330 - diff: 11.28mlTrain batch 23/32 - 242.1ms/batch - loss: 14.32659 - diff: 11.13mlTrain batch 24/32 - 243.8ms/batch - loss: 15.02160 - diff: 11.39mlTrain batch 25/32 - 241.9ms/batch - loss: 14.63331 - diff: 11.24mlTrain batch 26/32 - 243.6ms/batch - loss: 14.55079 - diff: 11.19mlTrain batch 27/32 - 242.7ms/batch - loss: 14.32816 - diff: 11.09mlTrain batch 28/32 - 244.1ms/batch - loss: 14.36320 - diff: 11.12mlTrain batch 29/32 - 242.0ms/batch - loss: 14.59932 - diff: 11.22mlTrain batch 30/32 - 244.7ms/batch - loss: 14.81576 - diff: 11.38mlTrain batch 31/32 - 241.9ms/batch - loss: 14.57932 - diff: 11.29mlTrain batch 32/32 - 78.2ms/batch - loss: 17.95033 - diff: 11.52mlTrain batch 32/32 - 11.6s 78.2ms/batch - loss: 17.95033 - diff: 11.52ml
Test 1.2s: val_loss: 660.92116 - diff: 96.23ml

Epoch 69: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 241.5ms/batch - loss: 5.33889 - diff: 6.21mlTrain batch 2/32 - 242.9ms/batch - loss: 4.98677 - diff: 6.66mlTrain batch 3/32 - 241.9ms/batch - loss: 8.13274 - diff: 8.00mlTrain batch 4/32 - 241.8ms/batch - loss: 7.53881 - diff: 8.14mlTrain batch 5/32 - 242.0ms/batch - loss: 8.81531 - diff: 8.96mlTrain batch 6/32 - 244.3ms/batch - loss: 8.65836 - diff: 8.84mlTrain batch 7/32 - 242.5ms/batch - loss: 8.27304 - diff: 8.62mlTrain batch 8/32 - 241.9ms/batch - loss: 10.89881 - diff: 9.96mlTrain batch 9/32 - 244.2ms/batch - loss: 10.30561 - diff: 9.70mlTrain batch 10/32 - 242.3ms/batch - loss: 9.98793 - diff: 9.45mlTrain batch 11/32 - 243.8ms/batch - loss: 9.59339 - diff: 9.30mlTrain batch 12/32 - 242.1ms/batch - loss: 10.86337 - diff: 9.94mlTrain batch 13/32 - 242.2ms/batch - loss: 11.09206 - diff: 10.04mlTrain batch 14/32 - 242.6ms/batch - loss: 10.78328 - diff: 9.90mlTrain batch 15/32 - 243.4ms/batch - loss: 10.32106 - diff: 9.68mlTrain batch 16/32 - 241.7ms/batch - loss: 11.11174 - diff: 10.00mlTrain batch 17/32 - 244.2ms/batch - loss: 10.73014 - diff: 9.76mlTrain batch 18/32 - 242.0ms/batch - loss: 11.21020 - diff: 10.03mlTrain batch 19/32 - 244.4ms/batch - loss: 11.32135 - diff: 10.12mlTrain batch 20/32 - 241.8ms/batch - loss: 10.99363 - diff: 9.93mlTrain batch 21/32 - 244.7ms/batch - loss: 10.78334 - diff: 9.87mlTrain batch 22/32 - 241.7ms/batch - loss: 10.48040 - diff: 9.70mlTrain batch 23/32 - 243.8ms/batch - loss: 17.50601 - diff: 10.89mlTrain batch 24/32 - 242.3ms/batch - loss: 17.42647 - diff: 10.95mlTrain batch 25/32 - 241.8ms/batch - loss: 17.57451 - diff: 11.15mlTrain batch 26/32 - 243.8ms/batch - loss: 17.99648 - diff: 11.41mlTrain batch 27/32 - 242.8ms/batch - loss: 17.83304 - diff: 11.40mlTrain batch 28/32 - 243.3ms/batch - loss: 18.83385 - diff: 11.77mlTrain batch 29/32 - 241.9ms/batch - loss: 18.53107 - diff: 11.70mlTrain batch 30/32 - 244.4ms/batch - loss: 18.81129 - diff: 11.84mlTrain batch 31/32 - 242.8ms/batch - loss: 19.16742 - diff: 12.04mlTrain batch 32/32 - 78.5ms/batch - loss: 19.48453 - diff: 12.06mlTrain batch 32/32 - 11.7s 78.5ms/batch - loss: 19.48453 - diff: 12.06ml
Test 1.1s: val_loss: 397.04088 - diff: 72.37ml

Epoch 70: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 241.8ms/batch - loss: 9.18019 - diff: 9.98mlTrain batch 2/32 - 242.0ms/batch - loss: 17.05521 - diff: 11.85mlTrain batch 3/32 - 242.2ms/batch - loss: 14.64985 - diff: 10.89mlTrain batch 4/32 - 244.4ms/batch - loss: 14.53901 - diff: 10.95mlTrain batch 5/32 - 241.7ms/batch - loss: 18.85376 - diff: 13.00mlTrain batch 6/32 - 241.7ms/batch - loss: 19.60009 - diff: 13.08mlTrain batch 7/32 - 241.8ms/batch - loss: 18.33069 - diff: 12.78mlTrain batch 8/32 - 244.2ms/batch - loss: 18.04142 - diff: 12.87mlTrain batch 9/32 - 242.3ms/batch - loss: 16.76419 - diff: 12.30mlTrain batch 10/32 - 244.2ms/batch - loss: 15.76766 - diff: 11.88mlTrain batch 11/32 - 241.7ms/batch - loss: 15.69493 - diff: 12.00mlTrain batch 12/32 - 242.0ms/batch - loss: 14.75291 - diff: 11.55mlTrain batch 13/32 - 242.2ms/batch - loss: 13.93854 - diff: 11.16mlTrain batch 14/32 - 244.0ms/batch - loss: 13.41353 - diff: 10.98mlTrain batch 15/32 - 242.7ms/batch - loss: 13.38247 - diff: 11.11mlTrain batch 16/32 - 243.4ms/batch - loss: 14.85996 - diff: 11.68mlTrain batch 17/32 - 242.1ms/batch - loss: 14.24252 - diff: 11.42mlTrain batch 18/32 - 242.1ms/batch - loss: 13.97059 - diff: 11.34mlTrain batch 19/32 - 241.5ms/batch - loss: 13.61739 - diff: 11.20mlTrain batch 20/32 - 244.1ms/batch - loss: 14.00057 - diff: 11.46mlTrain batch 21/32 - 241.7ms/batch - loss: 13.76606 - diff: 11.34mlTrain batch 22/32 - 241.8ms/batch - loss: 13.38055 - diff: 11.09mlTrain batch 23/32 - 242.2ms/batch - loss: 13.49023 - diff: 11.13mlTrain batch 24/32 - 243.9ms/batch - loss: 13.35287 - diff: 11.07mlTrain batch 25/32 - 242.2ms/batch - loss: 13.42800 - diff: 11.11mlTrain batch 26/32 - 244.1ms/batch - loss: 13.07247 - diff: 10.93mlTrain batch 27/32 - 241.9ms/batch - loss: 12.97824 - diff: 10.94mlTrain batch 28/32 - 243.4ms/batch - loss: 12.68081 - diff: 10.81mlTrain batch 29/32 - 242.8ms/batch - loss: 12.40792 - diff: 10.68mlTrain batch 30/32 - 243.7ms/batch - loss: 12.18931 - diff: 10.58mlTrain batch 31/32 - 242.4ms/batch - loss: 12.57854 - diff: 10.66mlTrain batch 32/32 - 78.6ms/batch - loss: 50.65962 - diff: 11.28mlTrain batch 32/32 - 11.8s 78.6ms/batch - loss: 50.65962 - diff: 11.28ml
Test 1.1s: val_loss: 187.89253 - diff: 49.12ml
Epoch    71: reducing learning rate of group 0 to 1.5625e-05.

Epoch 71: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 241.9ms/batch - loss: 10.01242 - diff: 10.17mlTrain batch 2/32 - 243.1ms/batch - loss: 7.09862 - diff: 8.45mlTrain batch 3/32 - 242.0ms/batch - loss: 8.74152 - diff: 9.15mlTrain batch 4/32 - 242.1ms/batch - loss: 9.39882 - diff: 9.66mlTrain batch 5/32 - 242.1ms/batch - loss: 14.72204 - diff: 11.57mlTrain batch 6/32 - 243.8ms/batch - loss: 14.01809 - diff: 11.36mlTrain batch 7/32 - 241.9ms/batch - loss: 15.58586 - diff: 11.61mlTrain batch 8/32 - 244.5ms/batch - loss: 14.63165 - diff: 11.18mlTrain batch 9/32 - 242.6ms/batch - loss: 13.61056 - diff: 10.79mlTrain batch 10/32 - 243.7ms/batch - loss: 13.18287 - diff: 10.69mlTrain batch 11/32 - 241.7ms/batch - loss: 14.26324 - diff: 10.74mlTrain batch 12/32 - 244.4ms/batch - loss: 14.12024 - diff: 10.82mlTrain batch 13/32 - 241.8ms/batch - loss: 13.49742 - diff: 10.55mlTrain batch 14/32 - 243.4ms/batch - loss: 13.23771 - diff: 10.53mlTrain batch 15/32 - 241.8ms/batch - loss: 13.61004 - diff: 10.67mlTrain batch 16/32 - 243.5ms/batch - loss: 17.88933 - diff: 12.02mlTrain batch 17/32 - 241.9ms/batch - loss: 17.37303 - diff: 11.90mlTrain batch 18/32 - 244.1ms/batch - loss: 17.60593 - diff: 12.07mlTrain batch 19/32 - 241.7ms/batch - loss: 17.48478 - diff: 12.13mlTrain batch 20/32 - 244.3ms/batch - loss: 17.19761 - diff: 12.02mlTrain batch 21/32 - 242.8ms/batch - loss: 16.85348 - diff: 11.97mlTrain batch 22/32 - 243.8ms/batch - loss: 16.88962 - diff: 12.08mlTrain batch 23/32 - 242.0ms/batch - loss: 16.49297 - diff: 11.94mlTrain batch 24/32 - 244.3ms/batch - loss: 16.00865 - diff: 11.75mlTrain batch 25/32 - 242.0ms/batch - loss: 15.75712 - diff: 11.67mlTrain batch 26/32 - 243.8ms/batch - loss: 15.83714 - diff: 11.70mlTrain batch 27/32 - 242.9ms/batch - loss: 15.54547 - diff: 11.60mlTrain batch 28/32 - 243.7ms/batch - loss: 15.38099 - diff: 11.55mlTrain batch 29/32 - 241.6ms/batch - loss: 15.69239 - diff: 11.75mlTrain batch 30/32 - 242.5ms/batch - loss: 15.44174 - diff: 11.66mlTrain batch 31/32 - 241.6ms/batch - loss: 15.31971 - diff: 11.60mlTrain batch 32/32 - 77.9ms/batch - loss: 15.46522 - diff: 11.59mlTrain batch 32/32 - 11.6s 77.9ms/batch - loss: 15.46522 - diff: 11.59ml
Test 1.1s: val_loss: 439.62060 - diff: 76.76ml

Epoch 72: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 241.7ms/batch - loss: 14.62729 - diff: 13.46mlTrain batch 2/32 - 242.1ms/batch - loss: 13.60641 - diff: 12.55mlTrain batch 3/32 - 241.8ms/batch - loss: 11.70508 - diff: 10.99mlTrain batch 4/32 - 243.8ms/batch - loss: 18.55358 - diff: 13.63mlTrain batch 5/32 - 241.8ms/batch - loss: 16.51834 - diff: 13.00mlTrain batch 6/32 - 242.2ms/batch - loss: 16.29945 - diff: 12.74mlTrain batch 7/32 - 242.1ms/batch - loss: 16.04774 - diff: 12.55mlTrain batch 8/32 - 243.6ms/batch - loss: 15.74693 - diff: 12.30mlTrain batch 9/32 - 242.0ms/batch - loss: 14.83431 - diff: 11.93mlTrain batch 10/32 - 242.2ms/batch - loss: 14.67945 - diff: 11.95mlTrain batch 11/32 - 242.2ms/batch - loss: 14.81279 - diff: 12.05mlTrain batch 12/32 - 244.2ms/batch - loss: 15.38650 - diff: 12.28mlTrain batch 13/32 - 242.5ms/batch - loss: 15.14854 - diff: 12.25mlTrain batch 14/32 - 243.5ms/batch - loss: 15.31198 - diff: 12.27mlTrain batch 15/32 - 242.0ms/batch - loss: 15.09797 - diff: 12.11mlTrain batch 16/32 - 244.4ms/batch - loss: 14.54551 - diff: 11.86mlTrain batch 17/32 - 242.7ms/batch - loss: 13.94812 - diff: 11.59mlTrain batch 18/32 - 244.4ms/batch - loss: 13.85246 - diff: 11.54mlTrain batch 19/32 - 242.0ms/batch - loss: 15.52062 - diff: 12.15mlTrain batch 20/32 - 243.3ms/batch - loss: 14.92030 - diff: 11.85mlTrain batch 21/32 - 242.3ms/batch - loss: 14.94872 - diff: 11.95mlTrain batch 22/32 - 242.5ms/batch - loss: 15.49602 - diff: 11.98mlTrain batch 23/32 - 242.1ms/batch - loss: 19.70455 - diff: 12.91mlTrain batch 24/32 - 244.4ms/batch - loss: 19.39021 - diff: 12.82mlTrain batch 25/32 - 242.2ms/batch - loss: 18.94808 - diff: 12.65mlTrain batch 26/32 - 244.3ms/batch - loss: 18.68896 - diff: 12.52mlTrain batch 27/32 - 243.1ms/batch - loss: 18.17976 - diff: 12.35mlTrain batch 28/32 - 243.7ms/batch - loss: 17.66247 - diff: 12.10mlTrain batch 29/32 - 242.6ms/batch - loss: 17.29311 - diff: 11.95mlTrain batch 30/32 - 243.1ms/batch - loss: 17.20241 - diff: 11.99mlTrain batch 31/32 - 242.1ms/batch - loss: 16.80586 - diff: 11.84mlTrain batch 32/32 - 77.8ms/batch - loss: 18.19863 - diff: 11.88mlTrain batch 32/32 - 11.3s 77.8ms/batch - loss: 18.19863 - diff: 11.88ml
Test 1.1s: val_loss: 352.49275 - diff: 68.13ml

Epoch 73: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 242.0ms/batch - loss: 8.00227 - diff: 8.84mlTrain batch 2/32 - 242.7ms/batch - loss: 9.27940 - diff: 9.79mlTrain batch 3/32 - 241.9ms/batch - loss: 31.45764 - diff: 15.28mlTrain batch 4/32 - 242.1ms/batch - loss: 25.15077 - diff: 13.46mlTrain batch 5/32 - 242.4ms/batch - loss: 24.48525 - diff: 14.22mlTrain batch 6/32 - 242.8ms/batch - loss: 21.75293 - diff: 13.52mlTrain batch 7/32 - 241.9ms/batch - loss: 22.68056 - diff: 14.20mlTrain batch 8/32 - 243.9ms/batch - loss: 20.67420 - diff: 13.35mlTrain batch 9/32 - 242.2ms/batch - loss: 19.20459 - diff: 12.79mlTrain batch 10/32 - 242.5ms/batch - loss: 19.54511 - diff: 13.19mlTrain batch 11/32 - 241.6ms/batch - loss: 18.34274 - diff: 12.78mlTrain batch 12/32 - 244.0ms/batch - loss: 17.25879 - diff: 12.32mlTrain batch 13/32 - 243.5ms/batch - loss: 17.89313 - diff: 12.57mlTrain batch 14/32 - 242.1ms/batch - loss: 17.16491 - diff: 12.38mlTrain batch 15/32 - 242.5ms/batch - loss: 16.36017 - diff: 12.05mlTrain batch 16/32 - 244.2ms/batch - loss: 15.86141 - diff: 11.85mlTrain batch 17/32 - 242.2ms/batch - loss: 15.34959 - diff: 11.61mlTrain batch 18/32 - 244.3ms/batch - loss: 19.54978 - diff: 12.84mlTrain batch 19/32 - 241.6ms/batch - loss: 18.95450 - diff: 12.63mlTrain batch 20/32 - 243.1ms/batch - loss: 19.07325 - diff: 12.76mlTrain batch 21/32 - 242.4ms/batch - loss: 18.82717 - diff: 12.70mlTrain batch 22/32 - 243.2ms/batch - loss: 18.72187 - diff: 12.80mlTrain batch 23/32 - 241.9ms/batch - loss: 18.93651 - diff: 12.99mlTrain batch 24/32 - 242.0ms/batch - loss: 19.05903 - diff: 13.10mlTrain batch 25/32 - 242.1ms/batch - loss: 18.65170 - diff: 12.97mlTrain batch 26/32 - 244.4ms/batch - loss: 18.37086 - diff: 12.93mlTrain batch 27/32 - 242.0ms/batch - loss: 18.44018 - diff: 12.94mlTrain batch 28/32 - 244.3ms/batch - loss: 18.01187 - diff: 12.77mlTrain batch 29/32 - 242.2ms/batch - loss: 17.87000 - diff: 12.76mlTrain batch 30/32 - 244.3ms/batch - loss: 18.08567 - diff: 12.91mlTrain batch 31/32 - 242.1ms/batch - loss: 18.00970 - diff: 12.91mlTrain batch 32/32 - 79.7ms/batch - loss: 18.74617 - diff: 12.96mlTrain batch 32/32 - 11.5s 79.7ms/batch - loss: 18.74617 - diff: 12.96ml
Test 1.1s: val_loss: 303.28238 - diff: 63.24ml

Epoch 74: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 242.3ms/batch - loss: 12.34515 - diff: 10.36mlTrain batch 2/32 - 244.4ms/batch - loss: 42.12802 - diff: 18.75mlTrain batch 3/32 - 242.5ms/batch - loss: 37.69005 - diff: 19.27mlTrain batch 4/32 - 243.9ms/batch - loss: 35.38564 - diff: 18.72mlTrain batch 5/32 - 242.7ms/batch - loss: 30.82647 - diff: 17.34mlTrain batch 6/32 - 244.1ms/batch - loss: 29.16496 - diff: 17.07mlTrain batch 7/32 - 241.8ms/batch - loss: 25.88231 - diff: 15.91mlTrain batch 8/32 - 242.0ms/batch - loss: 23.47048 - diff: 14.90mlTrain batch 9/32 - 243.6ms/batch - loss: 21.95952 - diff: 14.31mlTrain batch 10/32 - 241.9ms/batch - loss: 20.18435 - diff: 13.55mlTrain batch 11/32 - 244.2ms/batch - loss: 18.94054 - diff: 13.09mlTrain batch 12/32 - 242.2ms/batch - loss: 17.76687 - diff: 12.56mlTrain batch 13/32 - 244.4ms/batch - loss: 16.76652 - diff: 12.17mlTrain batch 14/32 - 241.7ms/batch - loss: 16.08897 - diff: 11.91mlTrain batch 15/32 - 244.4ms/batch - loss: 15.75748 - diff: 11.91mlTrain batch 16/32 - 242.6ms/batch - loss: 15.36576 - diff: 11.78mlTrain batch 17/32 - 244.3ms/batch - loss: 14.85833 - diff: 11.57mlTrain batch 18/32 - 242.5ms/batch - loss: 14.47944 - diff: 11.48mlTrain batch 19/32 - 243.5ms/batch - loss: 14.16155 - diff: 11.40mlTrain batch 20/32 - 241.6ms/batch - loss: 13.75790 - diff: 11.23mlTrain batch 21/32 - 243.4ms/batch - loss: 13.83922 - diff: 11.30mlTrain batch 22/32 - 241.9ms/batch - loss: 14.90112 - diff: 11.67mlTrain batch 23/32 - 244.5ms/batch - loss: 14.62203 - diff: 11.57mlTrain batch 24/32 - 242.7ms/batch - loss: 14.86087 - diff: 11.72mlTrain batch 25/32 - 244.2ms/batch - loss: 14.50691 - diff: 11.57mlTrain batch 26/32 - 241.7ms/batch - loss: 14.13092 - diff: 11.37mlTrain batch 27/32 - 244.2ms/batch - loss: 14.46643 - diff: 11.59mlTrain batch 28/32 - 242.0ms/batch - loss: 14.24613 - diff: 11.47mlTrain batch 29/32 - 243.4ms/batch - loss: 14.02792 - diff: 11.39mlTrain batch 30/32 - 241.9ms/batch - loss: 13.70973 - diff: 11.24mlTrain batch 31/32 - 244.6ms/batch - loss: 13.64672 - diff: 11.25mlTrain batch 32/32 - 80.2ms/batch - loss: 13.84375 - diff: 11.24mlTrain batch 32/32 - 11.3s 80.2ms/batch - loss: 13.84375 - diff: 11.24ml
Test 1.1s: val_loss: 345.13527 - diff: 67.13ml

Epoch 75: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 242.0ms/batch - loss: 8.93666 - diff: 9.02mlTrain batch 2/32 - 243.1ms/batch - loss: 7.18813 - diff: 8.33mlTrain batch 3/32 - 241.7ms/batch - loss: 7.10370 - diff: 8.55mlTrain batch 4/32 - 243.0ms/batch - loss: 8.38448 - diff: 8.89mlTrain batch 5/32 - 242.3ms/batch - loss: 8.15482 - diff: 8.62mlTrain batch 6/32 - 244.3ms/batch - loss: 9.70559 - diff: 9.48mlTrain batch 7/32 - 242.4ms/batch - loss: 9.15127 - diff: 9.30mlTrain batch 8/32 - 243.9ms/batch - loss: 10.39743 - diff: 9.98mlTrain batch 9/32 - 242.4ms/batch - loss: 10.55695 - diff: 10.15mlTrain batch 10/32 - 242.0ms/batch - loss: 10.60624 - diff: 10.22mlTrain batch 11/32 - 242.0ms/batch - loss: 10.08757 - diff: 9.95mlTrain batch 12/32 - 244.2ms/batch - loss: 11.70890 - diff: 10.59mlTrain batch 13/32 - 242.8ms/batch - loss: 11.42645 - diff: 10.57mlTrain batch 14/32 - 243.0ms/batch - loss: 12.39771 - diff: 11.12mlTrain batch 15/32 - 241.8ms/batch - loss: 12.09837 - diff: 10.96mlTrain batch 16/32 - 243.1ms/batch - loss: 11.92715 - diff: 10.92mlTrain batch 17/32 - 242.4ms/batch - loss: 11.54256 - diff: 10.75mlTrain batch 18/32 - 244.2ms/batch - loss: 11.36336 - diff: 10.71mlTrain batch 19/32 - 242.2ms/batch - loss: 11.14741 - diff: 10.56mlTrain batch 20/32 - 244.3ms/batch - loss: 10.90450 - diff: 10.45mlTrain batch 21/32 - 241.7ms/batch - loss: 11.51066 - diff: 10.78mlTrain batch 22/32 - 244.4ms/batch - loss: 11.25452 - diff: 10.67mlTrain batch 23/32 - 242.8ms/batch - loss: 11.05067 - diff: 10.54mlTrain batch 24/32 - 243.4ms/batch - loss: 14.48248 - diff: 11.38mlTrain batch 25/32 - 242.7ms/batch - loss: 13.97683 - diff: 11.10mlTrain batch 26/32 - 241.8ms/batch - loss: 13.57750 - diff: 10.92mlTrain batch 27/32 - 244.4ms/batch - loss: 13.27532 - diff: 10.79mlTrain batch 28/32 - 241.8ms/batch - loss: 14.20649 - diff: 11.24mlTrain batch 29/32 - 242.1ms/batch - loss: 14.04356 - diff: 11.20mlTrain batch 30/32 - 242.0ms/batch - loss: 13.82410 - diff: 11.15mlTrain batch 31/32 - 242.4ms/batch - loss: 14.27446 - diff: 11.38mlTrain batch 32/32 - 79.6ms/batch - loss: 16.08350 - diff: 11.50mlTrain batch 32/32 - 11.5s 79.6ms/batch - loss: 16.08350 - diff: 11.50ml
Test 1.1s: val_loss: 285.37465 - diff: 61.38ml

Epoch 76: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 241.6ms/batch - loss: 1.90730 - diff: 4.46mlTrain batch 2/32 - 243.8ms/batch - loss: 5.71561 - diff: 7.31mlTrain batch 3/32 - 242.0ms/batch - loss: 7.10703 - diff: 8.12mlTrain batch 4/32 - 242.0ms/batch - loss: 8.22870 - diff: 8.66mlTrain batch 5/32 - 241.9ms/batch - loss: 8.01424 - diff: 8.57mlTrain batch 6/32 - 241.9ms/batch - loss: 10.70393 - diff: 9.88mlTrain batch 7/32 - 244.2ms/batch - loss: 13.55873 - diff: 10.95mlTrain batch 8/32 - 242.0ms/batch - loss: 14.47331 - diff: 11.68mlTrain batch 9/32 - 243.9ms/batch - loss: 13.39632 - diff: 11.18mlTrain batch 10/32 - 242.5ms/batch - loss: 12.98359 - diff: 11.14mlTrain batch 11/32 - 242.3ms/batch - loss: 13.31892 - diff: 11.30mlTrain batch 12/32 - 242.1ms/batch - loss: 21.44334 - diff: 13.53mlTrain batch 13/32 - 243.4ms/batch - loss: 20.94443 - diff: 13.31mlTrain batch 14/32 - 241.9ms/batch - loss: 19.76684 - diff: 12.81mlTrain batch 15/32 - 244.2ms/batch - loss: 18.80809 - diff: 12.45mlTrain batch 16/32 - 242.1ms/batch - loss: 18.17486 - diff: 12.34mlTrain batch 17/32 - 242.2ms/batch - loss: 17.34302 - diff: 11.94mlTrain batch 18/32 - 241.6ms/batch - loss: 17.15290 - diff: 11.89mlTrain batch 19/32 - 242.0ms/batch - loss: 16.86660 - diff: 11.81mlTrain batch 20/32 - 241.9ms/batch - loss: 16.61707 - diff: 11.69mlTrain batch 21/32 - 244.5ms/batch - loss: 16.32795 - diff: 11.65mlTrain batch 22/32 - 242.2ms/batch - loss: 15.92321 - diff: 11.52mlTrain batch 23/32 - 244.3ms/batch - loss: 15.85279 - diff: 11.60mlTrain batch 24/32 - 241.9ms/batch - loss: 16.09152 - diff: 11.81mlTrain batch 25/32 - 243.9ms/batch - loss: 16.44462 - diff: 11.93mlTrain batch 26/32 - 242.6ms/batch - loss: 16.40411 - diff: 11.99mlTrain batch 27/32 - 244.3ms/batch - loss: 16.20319 - diff: 11.93mlTrain batch 28/32 - 242.6ms/batch - loss: 16.16474 - diff: 11.94mlTrain batch 29/32 - 244.0ms/batch - loss: 15.72977 - diff: 11.74mlTrain batch 30/32 - 242.8ms/batch - loss: 15.57513 - diff: 11.69mlTrain batch 31/32 - 243.9ms/batch - loss: 15.70331 - diff: 11.81mlTrain batch 32/32 - 78.7ms/batch - loss: 16.77119 - diff: 11.87mlTrain batch 32/32 - 11.5s 78.7ms/batch - loss: 16.77119 - diff: 11.87ml
Test 1.1s: val_loss: 328.35841 - diff: 66.80ml

Epoch 77: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 242.0ms/batch - loss: 4.50985 - diff: 6.60mlTrain batch 2/32 - 243.7ms/batch - loss: 5.18375 - diff: 7.26mlTrain batch 3/32 - 241.6ms/batch - loss: 5.56368 - diff: 7.21mlTrain batch 4/32 - 244.4ms/batch - loss: 5.88637 - diff: 7.44mlTrain batch 5/32 - 242.3ms/batch - loss: 10.79238 - diff: 10.05mlTrain batch 6/32 - 243.5ms/batch - loss: 10.35358 - diff: 9.72mlTrain batch 7/32 - 241.7ms/batch - loss: 9.70344 - diff: 9.41mlTrain batch 8/32 - 243.1ms/batch - loss: 13.40869 - diff: 10.71mlTrain batch 9/32 - 242.0ms/batch - loss: 13.01246 - diff: 10.59mlTrain batch 10/32 - 243.9ms/batch - loss: 12.39331 - diff: 10.39mlTrain batch 11/32 - 242.6ms/batch - loss: 11.83385 - diff: 10.21mlTrain batch 12/32 - 244.3ms/batch - loss: 11.62804 - diff: 10.16mlTrain batch 13/32 - 242.1ms/batch - loss: 11.32540 - diff: 10.09mlTrain batch 14/32 - 244.3ms/batch - loss: 14.52298 - diff: 11.15mlTrain batch 15/32 - 241.7ms/batch - loss: 14.32661 - diff: 11.09mlTrain batch 16/32 - 243.0ms/batch - loss: 13.84232 - diff: 10.92mlTrain batch 17/32 - 242.0ms/batch - loss: 14.28256 - diff: 11.18mlTrain batch 18/32 - 244.5ms/batch - loss: 13.75996 - diff: 10.96mlTrain batch 19/32 - 242.4ms/batch - loss: 13.48670 - diff: 10.90mlTrain batch 20/32 - 242.7ms/batch - loss: 13.13089 - diff: 10.74mlTrain batch 21/32 - 243.6ms/batch - loss: 12.94771 - diff: 10.67mlTrain batch 22/32 - 244.0ms/batch - loss: 12.78429 - diff: 10.64mlTrain batch 23/32 - 241.8ms/batch - loss: 12.53595 - diff: 10.54mlTrain batch 24/32 - 242.3ms/batch - loss: 12.40756 - diff: 10.42mlTrain batch 25/32 - 242.3ms/batch - loss: 12.64209 - diff: 10.64mlTrain batch 26/32 - 244.3ms/batch - loss: 12.55730 - diff: 10.58mlTrain batch 27/32 - 243.1ms/batch - loss: 12.78155 - diff: 10.72mlTrain batch 28/32 - 244.0ms/batch - loss: 13.18818 - diff: 10.81mlTrain batch 29/32 - 241.3ms/batch - loss: 12.99457 - diff: 10.70mlTrain batch 30/32 - 242.9ms/batch - loss: 13.14496 - diff: 10.81mlTrain batch 31/32 - 241.6ms/batch - loss: 13.02302 - diff: 10.77mlTrain batch 32/32 - 79.2ms/batch - loss: 13.10810 - diff: 10.75mlTrain batch 32/32 - 12.0s 79.2ms/batch - loss: 13.10810 - diff: 10.75ml
Test 1.1s: val_loss: 340.60867 - diff: 67.82ml

Epoch 78: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 241.3ms/batch - loss: 5.60786 - diff: 8.52mlTrain batch 2/32 - 244.2ms/batch - loss: 7.67218 - diff: 9.32mlTrain batch 3/32 - 241.6ms/batch - loss: 7.27584 - diff: 8.85mlTrain batch 4/32 - 242.0ms/batch - loss: 12.55435 - diff: 11.63mlTrain batch 5/32 - 241.9ms/batch - loss: 12.35231 - diff: 11.19mlTrain batch 6/32 - 243.2ms/batch - loss: 12.01105 - diff: 10.88mlTrain batch 7/32 - 241.9ms/batch - loss: 10.95408 - diff: 10.36mlTrain batch 8/32 - 244.2ms/batch - loss: 10.21980 - diff: 9.90mlTrain batch 9/32 - 242.8ms/batch - loss: 10.12384 - diff: 9.99mlTrain batch 10/32 - 243.4ms/batch - loss: 15.66965 - diff: 11.95mlTrain batch 11/32 - 241.7ms/batch - loss: 14.89246 - diff: 11.68mlTrain batch 12/32 - 244.4ms/batch - loss: 14.56293 - diff: 11.65mlTrain batch 13/32 - 242.5ms/batch - loss: 15.28833 - diff: 12.08mlTrain batch 14/32 - 243.5ms/batch - loss: 14.70816 - diff: 11.85mlTrain batch 15/32 - 241.7ms/batch - loss: 14.29846 - diff: 11.67mlTrain batch 16/32 - 242.4ms/batch - loss: 13.65770 - diff: 11.35mlTrain batch 17/32 - 241.7ms/batch - loss: 13.14489 - diff: 11.10mlTrain batch 18/32 - 244.5ms/batch - loss: 13.77984 - diff: 11.43mlTrain batch 19/32 - 242.1ms/batch - loss: 13.79849 - diff: 11.48mlTrain batch 20/32 - 244.5ms/batch - loss: 13.40059 - diff: 11.27mlTrain batch 21/32 - 242.2ms/batch - loss: 13.18727 - diff: 11.26mlTrain batch 22/32 - 244.5ms/batch - loss: 12.98343 - diff: 11.17mlTrain batch 23/32 - 242.2ms/batch - loss: 12.54987 - diff: 10.91mlTrain batch 24/32 - 242.0ms/batch - loss: 12.84375 - diff: 11.09mlTrain batch 25/32 - 242.0ms/batch - loss: 12.48819 - diff: 10.91mlTrain batch 26/32 - 244.3ms/batch - loss: 12.39231 - diff: 10.86mlTrain batch 27/32 - 242.5ms/batch - loss: 13.85466 - diff: 11.30mlTrain batch 28/32 - 243.2ms/batch - loss: 13.62648 - diff: 11.20mlTrain batch 29/32 - 242.2ms/batch - loss: 13.75555 - diff: 11.26mlTrain batch 30/32 - 242.5ms/batch - loss: 13.96288 - diff: 11.40mlTrain batch 31/32 - 241.8ms/batch - loss: 14.05142 - diff: 11.42mlTrain batch 32/32 - 79.2ms/batch - loss: 14.52808 - diff: 11.47mlTrain batch 32/32 - 11.3s 79.2ms/batch - loss: 14.52808 - diff: 11.47ml
Test 1.2s: val_loss: 291.36826 - diff: 62.25ml

Epoch 79: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 243.3ms/batch - loss: 20.25666 - diff: 16.13mlTrain batch 2/32 - 244.3ms/batch - loss: 13.64374 - diff: 12.83mlTrain batch 3/32 - 241.6ms/batch - loss: 21.23498 - diff: 15.87mlTrain batch 4/32 - 241.8ms/batch - loss: 26.17077 - diff: 17.72mlTrain batch 5/32 - 244.3ms/batch - loss: 26.00481 - diff: 17.72mlTrain batch 6/32 - 242.2ms/batch - loss: 22.61273 - diff: 15.89mlTrain batch 7/32 - 244.3ms/batch - loss: 20.74851 - diff: 15.01mlTrain batch 8/32 - 241.8ms/batch - loss: 19.06054 - diff: 14.16mlTrain batch 9/32 - 242.1ms/batch - loss: 17.99561 - diff: 13.75mlTrain batch 10/32 - 242.0ms/batch - loss: 17.24492 - diff: 13.44mlTrain batch 11/32 - 244.5ms/batch - loss: 17.78266 - diff: 13.57mlTrain batch 12/32 - 242.0ms/batch - loss: 16.84994 - diff: 13.12mlTrain batch 13/32 - 244.8ms/batch - loss: 16.04613 - diff: 12.72mlTrain batch 14/32 - 242.2ms/batch - loss: 21.44292 - diff: 14.12mlTrain batch 15/32 - 242.9ms/batch - loss: 25.38741 - diff: 15.36mlTrain batch 16/32 - 241.3ms/batch - loss: 24.35941 - diff: 15.04mlTrain batch 17/32 - 243.1ms/batch - loss: 23.57580 - diff: 14.82mlTrain batch 18/32 - 242.1ms/batch - loss: 22.96725 - diff: 14.51mlTrain batch 19/32 - 243.2ms/batch - loss: 22.26012 - diff: 14.28mlTrain batch 20/32 - 242.2ms/batch - loss: 22.14449 - diff: 14.36mlTrain batch 21/32 - 244.1ms/batch - loss: 22.04636 - diff: 14.37mlTrain batch 22/32 - 241.3ms/batch - loss: 21.24581 - diff: 14.03mlTrain batch 23/32 - 242.2ms/batch - loss: 21.93444 - diff: 14.20mlTrain batch 24/32 - 242.0ms/batch - loss: 21.35590 - diff: 14.03mlTrain batch 25/32 - 244.3ms/batch - loss: 20.78243 - diff: 13.83mlTrain batch 26/32 - 241.9ms/batch - loss: 20.37723 - diff: 13.68mlTrain batch 27/32 - 242.6ms/batch - loss: 19.73318 - diff: 13.40mlTrain batch 28/32 - 242.1ms/batch - loss: 19.25921 - diff: 13.23mlTrain batch 29/32 - 243.9ms/batch - loss: 18.83006 - diff: 13.10mlTrain batch 30/32 - 241.5ms/batch - loss: 18.36052 - diff: 12.88mlTrain batch 31/32 - 244.1ms/batch - loss: 19.59124 - diff: 13.24mlTrain batch 32/32 - 79.9ms/batch - loss: 21.00951 - diff: 13.34mlTrain batch 32/32 - 11.8s 79.9ms/batch - loss: 21.00951 - diff: 13.34ml
Test 1.2s: val_loss: 248.09548 - diff: 57.10ml

Epoch 80: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 242.0ms/batch - loss: 83.61394 - diff: 31.40mlTrain batch 2/32 - 242.1ms/batch - loss: 43.20998 - diff: 18.20mlTrain batch 3/32 - 242.1ms/batch - loss: 31.02295 - diff: 14.70mlTrain batch 4/32 - 244.2ms/batch - loss: 29.23718 - diff: 14.94mlTrain batch 5/32 - 241.9ms/batch - loss: 27.49259 - diff: 15.18mlTrain batch 6/32 - 243.5ms/batch - loss: 25.53630 - diff: 14.66mlTrain batch 7/32 - 241.8ms/batch - loss: 24.47143 - diff: 14.57mlTrain batch 8/32 - 242.0ms/batch - loss: 22.05352 - diff: 13.72mlTrain batch 9/32 - 241.8ms/batch - loss: 23.05485 - diff: 14.28mlTrain batch 10/32 - 244.4ms/batch - loss: 21.69765 - diff: 13.81mlTrain batch 11/32 - 241.8ms/batch - loss: 20.16735 - diff: 13.26mlTrain batch 12/32 - 242.1ms/batch - loss: 19.01959 - diff: 12.84mlTrain batch 13/32 - 242.0ms/batch - loss: 17.95483 - diff: 12.47mlTrain batch 14/32 - 242.2ms/batch - loss: 18.83261 - diff: 12.87mlTrain batch 15/32 - 241.9ms/batch - loss: 18.10543 - diff: 12.55mlTrain batch 16/32 - 242.1ms/batch - loss: 17.38228 - diff: 12.23mlTrain batch 17/32 - 241.8ms/batch - loss: 16.51033 - diff: 11.83mlTrain batch 18/32 - 244.4ms/batch - loss: 16.75211 - diff: 11.98mlTrain batch 19/32 - 242.4ms/batch - loss: 16.20382 - diff: 11.76mlTrain batch 20/32 - 244.1ms/batch - loss: 16.07749 - diff: 11.75mlTrain batch 21/32 - 242.5ms/batch - loss: 15.68403 - diff: 11.64mlTrain batch 22/32 - 243.6ms/batch - loss: 15.26652 - diff: 11.49mlTrain batch 23/32 - 241.6ms/batch - loss: 14.91580 - diff: 11.38mlTrain batch 24/32 - 243.2ms/batch - loss: 14.55674 - diff: 11.24mlTrain batch 25/32 - 242.1ms/batch - loss: 14.76591 - diff: 11.33mlTrain batch 26/32 - 241.9ms/batch - loss: 14.32914 - diff: 11.13mlTrain batch 27/32 - 242.5ms/batch - loss: 14.85818 - diff: 11.41mlTrain batch 28/32 - 244.5ms/batch - loss: 15.00531 - diff: 11.57mlTrain batch 29/32 - 241.4ms/batch - loss: 15.30559 - diff: 11.70mlTrain batch 30/32 - 244.3ms/batch - loss: 14.92723 - diff: 11.51mlTrain batch 31/32 - 242.7ms/batch - loss: 14.59405 - diff: 11.36mlTrain batch 32/32 - 79.3ms/batch - loss: 14.80285 - diff: 11.35mlTrain batch 32/32 - 11.9s 79.3ms/batch - loss: 14.80285 - diff: 11.35ml
Test 1.2s: val_loss: 309.16876 - diff: 63.62ml

Epoch 81: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 241.8ms/batch - loss: 4.38432 - diff: 7.20mlTrain batch 2/32 - 242.5ms/batch - loss: 6.03062 - diff: 8.27mlTrain batch 3/32 - 242.0ms/batch - loss: 11.57592 - diff: 10.90mlTrain batch 4/32 - 243.3ms/batch - loss: 10.81542 - diff: 10.49mlTrain batch 5/32 - 242.8ms/batch - loss: 9.75497 - diff: 10.01mlTrain batch 6/32 - 243.7ms/batch - loss: 9.54173 - diff: 9.88mlTrain batch 7/32 - 241.8ms/batch - loss: 11.26951 - diff: 10.68mlTrain batch 8/32 - 243.7ms/batch - loss: 11.24591 - diff: 10.66mlTrain batch 9/32 - 242.1ms/batch - loss: 11.28077 - diff: 10.67mlTrain batch 10/32 - 243.4ms/batch - loss: 10.95409 - diff: 10.57mlTrain batch 11/32 - 242.0ms/batch - loss: 10.85014 - diff: 10.50mlTrain batch 12/32 - 244.5ms/batch - loss: 10.61684 - diff: 10.38mlTrain batch 13/32 - 242.1ms/batch - loss: 10.00313 - diff: 10.01mlTrain batch 14/32 - 244.5ms/batch - loss: 9.47412 - diff: 9.66mlTrain batch 15/32 - 241.9ms/batch - loss: 14.73036 - diff: 11.16mlTrain batch 16/32 - 241.9ms/batch - loss: 14.23875 - diff: 10.95mlTrain batch 17/32 - 242.6ms/batch - loss: 13.97864 - diff: 10.95mlTrain batch 18/32 - 242.4ms/batch - loss: 13.89548 - diff: 10.98mlTrain batch 19/32 - 244.2ms/batch - loss: 13.74095 - diff: 11.02mlTrain batch 20/32 - 242.0ms/batch - loss: 13.43480 - diff: 10.90mlTrain batch 21/32 - 244.4ms/batch - loss: 13.10018 - diff: 10.77mlTrain batch 22/32 - 241.7ms/batch - loss: 13.32337 - diff: 10.83mlTrain batch 23/32 - 244.2ms/batch - loss: 13.22541 - diff: 10.80mlTrain batch 24/32 - 242.2ms/batch - loss: 13.96421 - diff: 11.23mlTrain batch 25/32 - 243.9ms/batch - loss: 14.39340 - diff: 11.48mlTrain batch 26/32 - 241.7ms/batch - loss: 14.52341 - diff: 11.53mlTrain batch 27/32 - 241.9ms/batch - loss: 14.51669 - diff: 11.50mlTrain batch 28/32 - 242.0ms/batch - loss: 15.91616 - diff: 11.97mlTrain batch 29/32 - 243.4ms/batch - loss: 15.94537 - diff: 12.07mlTrain batch 30/32 - 241.8ms/batch - loss: 15.77685 - diff: 12.07mlTrain batch 31/32 - 244.4ms/batch - loss: 15.80601 - diff: 12.11mlTrain batch 32/32 - 79.1ms/batch - loss: 16.03961 - diff: 12.10mlTrain batch 32/32 - 11.2s 79.1ms/batch - loss: 16.03961 - diff: 12.10ml
Test 1.2s: val_loss: 233.62377 - diff: 54.42ml
Epoch    82: reducing learning rate of group 0 to 7.8125e-06.

Epoch 82: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 241.7ms/batch - loss: 23.11894 - diff: 15.88mlTrain batch 2/32 - 242.8ms/batch - loss: 15.65728 - diff: 12.33mlTrain batch 3/32 - 241.9ms/batch - loss: 13.36737 - diff: 11.36mlTrain batch 4/32 - 244.2ms/batch - loss: 11.68362 - diff: 10.41mlTrain batch 5/32 - 241.9ms/batch - loss: 10.29020 - diff: 9.73mlTrain batch 6/32 - 242.4ms/batch - loss: 9.99880 - diff: 9.60mlTrain batch 7/32 - 241.8ms/batch - loss: 11.30414 - diff: 10.37mlTrain batch 8/32 - 242.0ms/batch - loss: 11.02629 - diff: 10.33mlTrain batch 9/32 - 241.9ms/batch - loss: 15.08582 - diff: 11.71mlTrain batch 10/32 - 242.2ms/batch - loss: 16.13066 - diff: 12.39mlTrain batch 11/32 - 242.0ms/batch - loss: 14.85486 - diff: 11.68mlTrain batch 12/32 - 243.5ms/batch - loss: 13.94606 - diff: 11.25mlTrain batch 13/32 - 242.4ms/batch - loss: 16.81030 - diff: 12.45mlTrain batch 14/32 - 243.4ms/batch - loss: 18.24169 - diff: 13.12mlTrain batch 15/32 - 242.0ms/batch - loss: 17.29817 - diff: 12.69mlTrain batch 16/32 - 243.5ms/batch - loss: 16.64767 - diff: 12.43mlTrain batch 17/32 - 242.5ms/batch - loss: 15.94486 - diff: 12.11mlTrain batch 18/32 - 242.0ms/batch - loss: 15.53441 - diff: 12.00mlTrain batch 19/32 - 241.9ms/batch - loss: 14.92360 - diff: 11.69mlTrain batch 20/32 - 243.8ms/batch - loss: 14.94038 - diff: 11.79mlTrain batch 21/32 - 241.5ms/batch - loss: 14.66600 - diff: 11.70mlTrain batch 22/32 - 243.4ms/batch - loss: 14.19905 - diff: 11.47mlTrain batch 23/32 - 243.0ms/batch - loss: 14.47338 - diff: 11.67mlTrain batch 24/32 - 243.8ms/batch - loss: 14.24326 - diff: 11.59mlTrain batch 25/32 - 242.6ms/batch - loss: 13.81145 - diff: 11.37mlTrain batch 26/32 - 243.1ms/batch - loss: 15.24773 - diff: 11.90mlTrain batch 27/32 - 241.8ms/batch - loss: 14.93167 - diff: 11.75mlTrain batch 28/32 - 244.2ms/batch - loss: 15.04426 - diff: 11.82mlTrain batch 29/32 - 242.7ms/batch - loss: 14.66687 - diff: 11.63mlTrain batch 30/32 - 244.4ms/batch - loss: 14.39102 - diff: 11.49mlTrain batch 31/32 - 241.5ms/batch - loss: 18.23574 - diff: 12.36mlTrain batch 32/32 - 79.3ms/batch - loss: 19.38401 - diff: 12.44mlTrain batch 32/32 - 11.9s 79.3ms/batch - loss: 19.38401 - diff: 12.44ml
Test 1.1s: val_loss: 229.27540 - diff: 54.38ml

Epoch 83: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 241.9ms/batch - loss: 34.20086 - diff: 20.20mlTrain batch 2/32 - 244.0ms/batch - loss: 19.41085 - diff: 13.31mlTrain batch 3/32 - 242.0ms/batch - loss: 14.56626 - diff: 11.25mlTrain batch 4/32 - 243.7ms/batch - loss: 12.44226 - diff: 10.69mlTrain batch 5/32 - 241.5ms/batch - loss: 14.07929 - diff: 11.70mlTrain batch 6/32 - 244.4ms/batch - loss: 12.45990 - diff: 10.78mlTrain batch 7/32 - 242.0ms/batch - loss: 11.21135 - diff: 10.12mlTrain batch 8/32 - 242.1ms/batch - loss: 10.59070 - diff: 9.86mlTrain batch 9/32 - 241.8ms/batch - loss: 9.93522 - diff: 9.57mlTrain batch 10/32 - 243.0ms/batch - loss: 9.81090 - diff: 9.55mlTrain batch 11/32 - 242.0ms/batch - loss: 9.76146 - diff: 9.54mlTrain batch 12/32 - 244.4ms/batch - loss: 10.55296 - diff: 10.06mlTrain batch 13/32 - 242.5ms/batch - loss: 10.46667 - diff: 10.05mlTrain batch 14/32 - 244.2ms/batch - loss: 9.85212 - diff: 9.65mlTrain batch 15/32 - 242.0ms/batch - loss: 10.07296 - diff: 9.77mlTrain batch 16/32 - 242.1ms/batch - loss: 10.31238 - diff: 9.89mlTrain batch 17/32 - 241.6ms/batch - loss: 11.66526 - diff: 10.20mlTrain batch 18/32 - 243.0ms/batch - loss: 11.46191 - diff: 10.14mlTrain batch 19/32 - 241.1ms/batch - loss: 11.10147 - diff: 10.00mlTrain batch 20/32 - 244.2ms/batch - loss: 10.78870 - diff: 9.86mlTrain batch 21/32 - 242.1ms/batch - loss: 10.75331 - diff: 9.92mlTrain batch 22/32 - 243.6ms/batch - loss: 10.76345 - diff: 10.02mlTrain batch 23/32 - 241.6ms/batch - loss: 10.67576 - diff: 9.99mlTrain batch 24/32 - 243.2ms/batch - loss: 10.74003 - diff: 10.02mlTrain batch 25/32 - 242.9ms/batch - loss: 10.69240 - diff: 10.01mlTrain batch 26/32 - 243.5ms/batch - loss: 10.39200 - diff: 9.84mlTrain batch 27/32 - 241.4ms/batch - loss: 10.51402 - diff: 9.93mlTrain batch 28/32 - 244.6ms/batch - loss: 10.52233 - diff: 9.94mlTrain batch 29/32 - 241.9ms/batch - loss: 10.54394 - diff: 10.00mlTrain batch 30/32 - 244.3ms/batch - loss: 10.72342 - diff: 10.09mlTrain batch 31/32 - 241.9ms/batch - loss: 10.57237 - diff: 10.01mlTrain batch 32/32 - 79.7ms/batch - loss: 51.63049 - diff: 10.91mlTrain batch 32/32 - 11.6s 79.7ms/batch - loss: 51.63049 - diff: 10.91ml
Test 1.1s: val_loss: 101.38034 - diff: 34.47ml

Epoch 84: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 242.3ms/batch - loss: 15.23730 - diff: 13.36mlTrain batch 2/32 - 244.3ms/batch - loss: 11.41006 - diff: 11.44mlTrain batch 3/32 - 241.9ms/batch - loss: 9.52863 - diff: 10.36mlTrain batch 4/32 - 242.5ms/batch - loss: 9.53063 - diff: 10.26mlTrain batch 5/32 - 241.9ms/batch - loss: 20.44423 - diff: 13.43mlTrain batch 6/32 - 242.1ms/batch - loss: 18.46703 - diff: 12.85mlTrain batch 7/32 - 241.8ms/batch - loss: 16.92178 - diff: 12.17mlTrain batch 8/32 - 243.3ms/batch - loss: 17.14309 - diff: 12.50mlTrain batch 9/32 - 241.7ms/batch - loss: 15.71451 - diff: 11.86mlTrain batch 10/32 - 244.2ms/batch - loss: 15.08745 - diff: 11.64mlTrain batch 11/32 - 242.4ms/batch - loss: 16.40732 - diff: 12.20mlTrain batch 12/32 - 244.4ms/batch - loss: 16.94584 - diff: 12.22mlTrain batch 13/32 - 241.3ms/batch - loss: 16.83073 - diff: 12.36mlTrain batch 14/32 - 242.8ms/batch - loss: 16.39114 - diff: 12.17mlTrain batch 15/32 - 242.4ms/batch - loss: 15.75867 - diff: 11.94mlTrain batch 16/32 - 244.4ms/batch - loss: 15.43650 - diff: 11.70mlTrain batch 17/32 - 241.8ms/batch - loss: 15.29804 - diff: 11.63mlTrain batch 18/32 - 242.0ms/batch - loss: 14.67018 - diff: 11.33mlTrain batch 19/32 - 242.0ms/batch - loss: 14.32995 - diff: 11.20mlTrain batch 20/32 - 242.0ms/batch - loss: 14.19279 - diff: 11.14mlTrain batch 21/32 - 242.3ms/batch - loss: 13.62004 - diff: 10.87mlTrain batch 22/32 - 244.2ms/batch - loss: 13.63698 - diff: 10.93mlTrain batch 23/32 - 241.9ms/batch - loss: 13.44541 - diff: 10.91mlTrain batch 24/32 - 243.1ms/batch - loss: 13.28923 - diff: 10.87mlTrain batch 25/32 - 241.7ms/batch - loss: 13.08773 - diff: 10.83mlTrain batch 26/32 - 243.4ms/batch - loss: 12.74944 - diff: 10.67mlTrain batch 27/32 - 242.2ms/batch - loss: 12.58279 - diff: 10.61mlTrain batch 28/32 - 243.9ms/batch - loss: 12.95539 - diff: 10.85mlTrain batch 29/32 - 241.9ms/batch - loss: 13.41211 - diff: 11.02mlTrain batch 30/32 - 243.5ms/batch - loss: 13.72639 - diff: 11.21mlTrain batch 31/32 - 241.7ms/batch - loss: 13.69395 - diff: 11.26mlTrain batch 32/32 - 79.2ms/batch - loss: 14.33439 - diff: 11.32mlTrain batch 32/32 - 12.8s 79.2ms/batch - loss: 14.33439 - diff: 11.32ml
Test 1.2s: val_loss: 373.17858 - diff: 70.77ml

Epoch 85: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 242.0ms/batch - loss: 8.40343 - diff: 10.35mlTrain batch 2/32 - 242.7ms/batch - loss: 9.03308 - diff: 10.45mlTrain batch 3/32 - 241.3ms/batch - loss: 6.98692 - diff: 9.00mlTrain batch 4/32 - 242.1ms/batch - loss: 7.43295 - diff: 9.04mlTrain batch 5/32 - 242.5ms/batch - loss: 9.41739 - diff: 9.80mlTrain batch 6/32 - 243.8ms/batch - loss: 8.60775 - diff: 9.34mlTrain batch 7/32 - 241.3ms/batch - loss: 9.29247 - diff: 9.73mlTrain batch 8/32 - 244.4ms/batch - loss: 8.91358 - diff: 9.46mlTrain batch 9/32 - 241.5ms/batch - loss: 8.46238 - diff: 9.14mlTrain batch 10/32 - 243.9ms/batch - loss: 8.47213 - diff: 9.23mlTrain batch 11/32 - 241.6ms/batch - loss: 9.73452 - diff: 10.03mlTrain batch 12/32 - 243.4ms/batch - loss: 9.47539 - diff: 9.78mlTrain batch 13/32 - 241.6ms/batch - loss: 9.30910 - diff: 9.68mlTrain batch 14/32 - 242.1ms/batch - loss: 9.53397 - diff: 9.94mlTrain batch 15/32 - 241.4ms/batch - loss: 9.03941 - diff: 9.58mlTrain batch 16/32 - 242.9ms/batch - loss: 9.08159 - diff: 9.57mlTrain batch 17/32 - 241.6ms/batch - loss: 10.17807 - diff: 10.08mlTrain batch 18/32 - 243.9ms/batch - loss: 10.53702 - diff: 10.32mlTrain batch 19/32 - 241.7ms/batch - loss: 11.60268 - diff: 10.76mlTrain batch 20/32 - 244.3ms/batch - loss: 12.73432 - diff: 11.20mlTrain batch 21/32 - 241.3ms/batch - loss: 12.35331 - diff: 11.01mlTrain batch 22/32 - 243.5ms/batch - loss: 12.11227 - diff: 10.92mlTrain batch 23/32 - 242.0ms/batch - loss: 23.45420 - diff: 12.96mlTrain batch 24/32 - 242.1ms/batch - loss: 23.08896 - diff: 12.98mlTrain batch 25/32 - 242.1ms/batch - loss: 22.56009 - diff: 12.87mlTrain batch 26/32 - 243.6ms/batch - loss: 22.19003 - diff: 12.80mlTrain batch 27/32 - 241.8ms/batch - loss: 21.94033 - diff: 12.80mlTrain batch 28/32 - 245.3ms/batch - loss: 21.53739 - diff: 12.73mlTrain batch 29/32 - 241.8ms/batch - loss: 21.85270 - diff: 12.96mlTrain batch 30/32 - 242.3ms/batch - loss: 21.47851 - diff: 12.86mlTrain batch 31/32 - 242.0ms/batch - loss: 21.16183 - diff: 12.74mlTrain batch 32/32 - 79.4ms/batch - loss: 24.15452 - diff: 12.90mlTrain batch 32/32 - 12.0s 79.4ms/batch - loss: 24.15452 - diff: 12.90ml
Test 1.1s: val_loss: 327.22917 - diff: 65.00ml

Epoch 86: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 241.9ms/batch - loss: 10.73969 - diff: 10.37mlTrain batch 2/32 - 242.9ms/batch - loss: 7.76105 - diff: 8.45mlTrain batch 3/32 - 241.9ms/batch - loss: 6.87942 - diff: 7.97mlTrain batch 4/32 - 242.0ms/batch - loss: 7.35153 - diff: 8.45mlTrain batch 5/32 - 241.9ms/batch - loss: 6.62778 - diff: 7.98mlTrain batch 6/32 - 244.0ms/batch - loss: 7.55856 - diff: 8.49mlTrain batch 7/32 - 242.1ms/batch - loss: 13.37801 - diff: 10.98mlTrain batch 8/32 - 244.0ms/batch - loss: 13.07869 - diff: 11.02mlTrain batch 9/32 - 242.0ms/batch - loss: 12.70498 - diff: 10.98mlTrain batch 10/32 - 243.4ms/batch - loss: 11.77609 - diff: 10.47mlTrain batch 11/32 - 241.7ms/batch - loss: 11.41330 - diff: 10.42mlTrain batch 12/32 - 243.5ms/batch - loss: 10.75939 - diff: 10.00mlTrain batch 13/32 - 242.8ms/batch - loss: 11.27176 - diff: 10.35mlTrain batch 14/32 - 243.4ms/batch - loss: 10.85430 - diff: 10.14mlTrain batch 15/32 - 241.6ms/batch - loss: 10.31704 - diff: 9.83mlTrain batch 16/32 - 242.3ms/batch - loss: 12.58473 - diff: 10.60mlTrain batch 17/32 - 242.1ms/batch - loss: 12.33822 - diff: 10.54mlTrain batch 18/32 - 244.2ms/batch - loss: 12.07055 - diff: 10.47mlTrain batch 19/32 - 242.1ms/batch - loss: 12.27225 - diff: 10.64mlTrain batch 20/32 - 243.5ms/batch - loss: 12.14562 - diff: 10.62mlTrain batch 21/32 - 242.0ms/batch - loss: 12.11229 - diff: 10.63mlTrain batch 22/32 - 244.5ms/batch - loss: 11.74004 - diff: 10.46mlTrain batch 23/32 - 241.9ms/batch - loss: 11.87811 - diff: 10.56mlTrain batch 24/32 - 244.2ms/batch - loss: 12.59120 - diff: 10.93mlTrain batch 25/32 - 242.2ms/batch - loss: 12.29767 - diff: 10.77mlTrain batch 26/32 - 244.0ms/batch - loss: 12.00507 - diff: 10.62mlTrain batch 27/32 - 242.2ms/batch - loss: 12.17458 - diff: 10.76mlTrain batch 28/32 - 244.0ms/batch - loss: 12.59822 - diff: 10.93mlTrain batch 29/32 - 242.2ms/batch - loss: 12.33779 - diff: 10.81mlTrain batch 30/32 - 244.0ms/batch - loss: 12.10037 - diff: 10.68mlTrain batch 31/32 - 241.7ms/batch - loss: 12.24045 - diff: 10.80mlTrain batch 32/32 - 79.7ms/batch - loss: 12.58633 - diff: 10.81mlTrain batch 32/32 - 11.1s 79.7ms/batch - loss: 12.58633 - diff: 10.81ml
Test 1.1s: val_loss: 328.53357 - diff: 66.21ml

Epoch 87: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 241.3ms/batch - loss: 18.86513 - diff: 14.30mlTrain batch 2/32 - 242.9ms/batch - loss: 14.27921 - diff: 11.71mlTrain batch 3/32 - 245.0ms/batch - loss: 16.55343 - diff: 12.64mlTrain batch 4/32 - 244.3ms/batch - loss: 14.79223 - diff: 12.16mlTrain batch 5/32 - 242.1ms/batch - loss: 13.32301 - diff: 11.43mlTrain batch 6/32 - 242.6ms/batch - loss: 12.24189 - diff: 10.95mlTrain batch 7/32 - 244.4ms/batch - loss: 11.28868 - diff: 10.31mlTrain batch 8/32 - 242.2ms/batch - loss: 10.58723 - diff: 9.91mlTrain batch 9/32 - 243.9ms/batch - loss: 10.24988 - diff: 9.75mlTrain batch 10/32 - 242.2ms/batch - loss: 9.77981 - diff: 9.45mlTrain batch 11/32 - 244.1ms/batch - loss: 9.13640 - diff: 9.07mlTrain batch 12/32 - 242.3ms/batch - loss: 8.82048 - diff: 8.96mlTrain batch 13/32 - 244.0ms/batch - loss: 8.38186 - diff: 8.70mlTrain batch 14/32 - 242.8ms/batch - loss: 18.44660 - diff: 11.11mlTrain batch 15/32 - 243.6ms/batch - loss: 17.50750 - diff: 10.80mlTrain batch 16/32 - 241.8ms/batch - loss: 17.57070 - diff: 11.13mlTrain batch 17/32 - 242.7ms/batch - loss: 16.97213 - diff: 11.04mlTrain batch 18/32 - 242.0ms/batch - loss: 16.33695 - diff: 10.87mlTrain batch 19/32 - 244.2ms/batch - loss: 15.67110 - diff: 10.62mlTrain batch 20/32 - 242.4ms/batch - loss: 15.69109 - diff: 10.73mlTrain batch 21/32 - 244.3ms/batch - loss: 15.23610 - diff: 10.57mlTrain batch 22/32 - 242.7ms/batch - loss: 16.35586 - diff: 11.10mlTrain batch 23/32 - 244.2ms/batch - loss: 16.05415 - diff: 11.03mlTrain batch 24/32 - 241.8ms/batch - loss: 15.64313 - diff: 10.92mlTrain batch 25/32 - 243.5ms/batch - loss: 16.04700 - diff: 11.24mlTrain batch 26/32 - 242.4ms/batch - loss: 16.24477 - diff: 11.45mlTrain batch 27/32 - 243.3ms/batch - loss: 15.74048 - diff: 11.23mlTrain batch 28/32 - 242.3ms/batch - loss: 16.34368 - diff: 11.51mlTrain batch 29/32 - 242.5ms/batch - loss: 16.07386 - diff: 11.45mlTrain batch 30/32 - 241.8ms/batch - loss: 15.78406 - diff: 11.36mlTrain batch 31/32 - 244.2ms/batch - loss: 15.50566 - diff: 11.29mlTrain batch 32/32 - 80.3ms/batch - loss: 17.24841 - diff: 11.42mlTrain batch 32/32 - 11.4s 80.3ms/batch - loss: 17.24841 - diff: 11.42ml
Test 1.2s: val_loss: 331.43582 - diff: 66.38ml

Epoch 88: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 241.6ms/batch - loss: 7.99310 - diff: 8.27mlTrain batch 2/32 - 242.1ms/batch - loss: 8.97196 - diff: 9.69mlTrain batch 3/32 - 241.8ms/batch - loss: 8.54808 - diff: 9.64mlTrain batch 4/32 - 241.9ms/batch - loss: 51.77529 - diff: 19.05mlTrain batch 5/32 - 242.2ms/batch - loss: 42.81894 - diff: 16.98mlTrain batch 6/32 - 244.1ms/batch - loss: 36.83919 - diff: 15.47mlTrain batch 7/32 - 242.1ms/batch - loss: 32.48084 - diff: 14.46mlTrain batch 8/32 - 244.2ms/batch - loss: 29.83482 - diff: 13.72mlTrain batch 9/32 - 241.9ms/batch - loss: 27.34277 - diff: 13.18mlTrain batch 10/32 - 244.5ms/batch - loss: 25.51579 - diff: 12.74mlTrain batch 11/32 - 241.8ms/batch - loss: 23.85030 - diff: 12.33mlTrain batch 12/32 - 242.0ms/batch - loss: 23.29047 - diff: 12.40mlTrain batch 13/32 - 242.6ms/batch - loss: 22.24910 - diff: 12.26mlTrain batch 14/32 - 243.7ms/batch - loss: 21.78968 - diff: 12.35mlTrain batch 15/32 - 242.0ms/batch - loss: 21.05213 - diff: 12.21mlTrain batch 16/32 - 242.0ms/batch - loss: 21.62289 - diff: 12.72mlTrain batch 17/32 - 241.8ms/batch - loss: 21.12694 - diff: 12.62mlTrain batch 18/32 - 245.5ms/batch - loss: 20.22000 - diff: 12.33mlTrain batch 19/32 - 242.6ms/batch - loss: 20.71464 - diff: 12.71mlTrain batch 20/32 - 242.3ms/batch - loss: 19.88826 - diff: 12.41mlTrain batch 21/32 - 242.0ms/batch - loss: 19.86457 - diff: 12.51mlTrain batch 22/32 - 244.5ms/batch - loss: 19.61884 - diff: 12.47mlTrain batch 23/32 - 242.2ms/batch - loss: 19.63026 - diff: 12.56mlTrain batch 24/32 - 244.4ms/batch - loss: 20.67789 - diff: 13.04mlTrain batch 25/32 - 242.2ms/batch - loss: 21.95268 - diff: 13.47mlTrain batch 26/32 - 244.2ms/batch - loss: 21.68848 - diff: 13.45mlTrain batch 27/32 - 242.5ms/batch - loss: 21.23493 - diff: 13.32mlTrain batch 28/32 - 244.3ms/batch - loss: 20.61310 - diff: 13.07mlTrain batch 29/32 - 242.3ms/batch - loss: 20.26961 - diff: 12.98mlTrain batch 30/32 - 244.0ms/batch - loss: 19.86923 - diff: 12.87mlTrain batch 31/32 - 244.3ms/batch - loss: 19.42937 - diff: 12.70mlTrain batch 32/32 - 79.0ms/batch - loss: 20.99932 - diff: 12.80mlTrain batch 32/32 - 11.6s 79.0ms/batch - loss: 20.99932 - diff: 12.80ml
Test 1.1s: val_loss: 326.83512 - diff: 65.99ml

Epoch 89: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 241.6ms/batch - loss: 5.94235 - diff: 7.87mlTrain batch 2/32 - 244.1ms/batch - loss: 13.20890 - diff: 11.67mlTrain batch 3/32 - 242.5ms/batch - loss: 11.17780 - diff: 10.26mlTrain batch 4/32 - 243.0ms/batch - loss: 14.54445 - diff: 12.14mlTrain batch 5/32 - 242.2ms/batch - loss: 13.09826 - diff: 11.59mlTrain batch 6/32 - 244.2ms/batch - loss: 11.52969 - diff: 10.65mlTrain batch 7/32 - 241.7ms/batch - loss: 16.06496 - diff: 12.53mlTrain batch 8/32 - 244.3ms/batch - loss: 14.48966 - diff: 11.73mlTrain batch 9/32 - 242.3ms/batch - loss: 13.29730 - diff: 11.15mlTrain batch 10/32 - 244.4ms/batch - loss: 12.22027 - diff: 10.54mlTrain batch 11/32 - 241.9ms/batch - loss: 11.73053 - diff: 10.32mlTrain batch 12/32 - 242.1ms/batch - loss: 11.86622 - diff: 10.56mlTrain batch 13/32 - 241.9ms/batch - loss: 12.22710 - diff: 10.75mlTrain batch 14/32 - 243.3ms/batch - loss: 15.16267 - diff: 11.94mlTrain batch 15/32 - 242.2ms/batch - loss: 14.31819 - diff: 11.49mlTrain batch 16/32 - 242.4ms/batch - loss: 14.30519 - diff: 11.58mlTrain batch 17/32 - 241.9ms/batch - loss: 13.89827 - diff: 11.42mlTrain batch 18/32 - 244.3ms/batch - loss: 13.59358 - diff: 11.36mlTrain batch 19/32 - 241.9ms/batch - loss: 13.21983 - diff: 11.22mlTrain batch 20/32 - 244.6ms/batch - loss: 14.12225 - diff: 11.43mlTrain batch 21/32 - 241.9ms/batch - loss: 13.75245 - diff: 11.30mlTrain batch 22/32 - 244.4ms/batch - loss: 13.51085 - diff: 11.20mlTrain batch 23/32 - 242.1ms/batch - loss: 17.53253 - diff: 12.26mlTrain batch 24/32 - 244.2ms/batch - loss: 17.64583 - diff: 12.44mlTrain batch 25/32 - 242.7ms/batch - loss: 17.28883 - diff: 12.29mlTrain batch 26/32 - 243.8ms/batch - loss: 16.82650 - diff: 12.12mlTrain batch 27/32 - 242.3ms/batch - loss: 16.45492 - diff: 11.99mlTrain batch 28/32 - 244.2ms/batch - loss: 16.16135 - diff: 11.89mlTrain batch 29/32 - 244.3ms/batch - loss: 15.99091 - diff: 11.87mlTrain batch 30/32 - 241.9ms/batch - loss: 15.57231 - diff: 11.65mlTrain batch 31/32 - 244.3ms/batch - loss: 15.19823 - diff: 11.49mlTrain batch 32/32 - 80.1ms/batch - loss: 16.99126 - diff: 11.61mlTrain batch 32/32 - 11.3s 80.1ms/batch - loss: 16.99126 - diff: 11.61ml
Test 1.2s: val_loss: 261.94928 - diff: 58.59ml

Epoch 90: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 241.9ms/batch - loss: 32.36053 - diff: 20.66mlTrain batch 2/32 - 244.2ms/batch - loss: 17.54505 - diff: 12.96mlTrain batch 3/32 - 243.2ms/batch - loss: 15.05927 - diff: 12.13mlTrain batch 4/32 - 242.4ms/batch - loss: 14.05083 - diff: 11.98mlTrain batch 5/32 - 241.9ms/batch - loss: 12.46815 - diff: 10.99mlTrain batch 6/32 - 241.9ms/batch - loss: 11.33816 - diff: 10.36mlTrain batch 7/32 - 244.3ms/batch - loss: 13.55143 - diff: 11.45mlTrain batch 8/32 - 242.8ms/batch - loss: 12.72075 - diff: 11.02mlTrain batch 9/32 - 242.0ms/batch - loss: 11.61672 - diff: 10.48mlTrain batch 10/32 - 241.8ms/batch - loss: 13.95972 - diff: 11.50mlTrain batch 11/32 - 242.1ms/batch - loss: 13.28504 - diff: 11.23mlTrain batch 12/32 - 243.2ms/batch - loss: 12.66095 - diff: 10.97mlTrain batch 13/32 - 242.0ms/batch - loss: 12.59272 - diff: 10.94mlTrain batch 14/32 - 242.5ms/batch - loss: 12.31248 - diff: 10.86mlTrain batch 15/32 - 244.0ms/batch - loss: 11.87678 - diff: 10.62mlTrain batch 16/32 - 241.6ms/batch - loss: 11.57336 - diff: 10.49mlTrain batch 17/32 - 244.4ms/batch - loss: 11.67789 - diff: 10.64mlTrain batch 18/32 - 241.7ms/batch - loss: 11.37900 - diff: 10.45mlTrain batch 19/32 - 243.1ms/batch - loss: 12.24722 - diff: 10.92mlTrain batch 20/32 - 242.4ms/batch - loss: 11.90816 - diff: 10.73mlTrain batch 21/32 - 244.3ms/batch - loss: 11.59922 - diff: 10.52mlTrain batch 22/32 - 241.9ms/batch - loss: 11.47967 - diff: 10.49mlTrain batch 23/32 - 244.4ms/batch - loss: 13.51855 - diff: 11.09mlTrain batch 24/32 - 242.9ms/batch - loss: 13.79579 - diff: 11.23mlTrain batch 25/32 - 244.3ms/batch - loss: 15.29456 - diff: 11.66mlTrain batch 26/32 - 242.0ms/batch - loss: 14.94531 - diff: 11.52mlTrain batch 27/32 - 244.6ms/batch - loss: 14.56450 - diff: 11.34mlTrain batch 28/32 - 241.6ms/batch - loss: 15.00413 - diff: 11.38mlTrain batch 29/32 - 242.0ms/batch - loss: 15.42195 - diff: 11.57mlTrain batch 30/32 - 241.3ms/batch - loss: 15.49043 - diff: 11.61mlTrain batch 31/32 - 241.9ms/batch - loss: 15.19401 - diff: 11.50mlTrain batch 32/32 - 79.7ms/batch - loss: 17.04929 - diff: 11.66mlTrain batch 32/32 - 11.9s 79.7ms/batch - loss: 17.04929 - diff: 11.66ml
Test 1.2s: val_loss: 280.63683 - diff: 59.97ml

Epoch 91: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 242.4ms/batch - loss: 3.39413 - diff: 6.24mlTrain batch 2/32 - 244.2ms/batch - loss: 3.86980 - diff: 6.23mlTrain batch 3/32 - 242.5ms/batch - loss: 3.43662 - diff: 5.81mlTrain batch 4/32 - 243.3ms/batch - loss: 3.71564 - diff: 6.05mlTrain batch 5/32 - 241.8ms/batch - loss: 4.52185 - diff: 6.46mlTrain batch 6/32 - 244.3ms/batch - loss: 4.93240 - diff: 6.82mlTrain batch 7/32 - 242.0ms/batch - loss: 5.39442 - diff: 6.99mlTrain batch 8/32 - 244.2ms/batch - loss: 5.06700 - diff: 6.83mlTrain batch 9/32 - 241.9ms/batch - loss: 6.18221 - diff: 7.53mlTrain batch 10/32 - 244.5ms/batch - loss: 6.17185 - diff: 7.52mlTrain batch 11/32 - 242.1ms/batch - loss: 6.39143 - diff: 7.69mlTrain batch 12/32 - 244.0ms/batch - loss: 6.50274 - diff: 7.86mlTrain batch 13/32 - 242.7ms/batch - loss: 6.73481 - diff: 8.06mlTrain batch 14/32 - 243.8ms/batch - loss: 16.02336 - diff: 10.34mlTrain batch 15/32 - 241.9ms/batch - loss: 15.96731 - diff: 10.56mlTrain batch 16/32 - 244.0ms/batch - loss: 15.72070 - diff: 10.52mlTrain batch 17/32 - 242.0ms/batch - loss: 15.81208 - diff: 10.76mlTrain batch 18/32 - 242.2ms/batch - loss: 15.13167 - diff: 10.48mlTrain batch 19/32 - 241.7ms/batch - loss: 14.75314 - diff: 10.42mlTrain batch 20/32 - 244.4ms/batch - loss: 15.05992 - diff: 10.73mlTrain batch 21/32 - 242.5ms/batch - loss: 14.97676 - diff: 10.71mlTrain batch 22/32 - 243.8ms/batch - loss: 15.02065 - diff: 10.85mlTrain batch 23/32 - 242.0ms/batch - loss: 14.61943 - diff: 10.69mlTrain batch 24/32 - 244.3ms/batch - loss: 14.24299 - diff: 10.55mlTrain batch 25/32 - 242.4ms/batch - loss: 13.86122 - diff: 10.41mlTrain batch 26/32 - 244.5ms/batch - loss: 14.01021 - diff: 10.62mlTrain batch 27/32 - 242.4ms/batch - loss: 15.86598 - diff: 11.21mlTrain batch 28/32 - 241.9ms/batch - loss: 15.82212 - diff: 11.28mlTrain batch 29/32 - 244.4ms/batch - loss: 15.52392 - diff: 11.19mlTrain batch 30/32 - 242.1ms/batch - loss: 15.07667 - diff: 10.97mlTrain batch 31/32 - 242.1ms/batch - loss: 15.15068 - diff: 11.08mlTrain batch 32/32 - 79.3ms/batch - loss: 20.40934 - diff: 11.37mlTrain batch 32/32 - 11.3s 79.3ms/batch - loss: 20.40934 - diff: 11.37ml
Test 1.1s: val_loss: 240.30490 - diff: 56.05ml

Epoch 92: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 241.6ms/batch - loss: 8.03811 - diff: 9.79mlTrain batch 2/32 - 244.1ms/batch - loss: 5.44300 - diff: 7.62mlTrain batch 3/32 - 242.0ms/batch - loss: 5.05377 - diff: 7.33mlTrain batch 4/32 - 244.1ms/batch - loss: 7.28210 - diff: 8.23mlTrain batch 5/32 - 241.9ms/batch - loss: 7.39425 - diff: 8.33mlTrain batch 6/32 - 244.5ms/batch - loss: 7.19436 - diff: 8.23mlTrain batch 7/32 - 242.0ms/batch - loss: 6.93914 - diff: 8.11mlTrain batch 8/32 - 244.3ms/batch - loss: 6.83911 - diff: 8.04mlTrain batch 9/32 - 241.7ms/batch - loss: 7.34090 - diff: 8.48mlTrain batch 10/32 - 244.1ms/batch - loss: 8.72889 - diff: 9.19mlTrain batch 11/32 - 242.4ms/batch - loss: 8.78044 - diff: 9.24mlTrain batch 12/32 - 244.3ms/batch - loss: 8.32538 - diff: 8.99mlTrain batch 13/32 - 242.2ms/batch - loss: 17.28951 - diff: 11.24mlTrain batch 14/32 - 244.2ms/batch - loss: 17.02309 - diff: 11.39mlTrain batch 15/32 - 243.0ms/batch - loss: 18.23145 - diff: 12.12mlTrain batch 16/32 - 244.2ms/batch - loss: 17.62152 - diff: 11.97mlTrain batch 17/32 - 243.4ms/batch - loss: 16.84198 - diff: 11.66mlTrain batch 18/32 - 243.9ms/batch - loss: 16.31822 - diff: 11.55mlTrain batch 19/32 - 242.8ms/batch - loss: 16.06900 - diff: 11.56mlTrain batch 20/32 - 242.2ms/batch - loss: 15.78798 - diff: 11.45mlTrain batch 21/32 - 242.3ms/batch - loss: 15.44170 - diff: 11.36mlTrain batch 22/32 - 241.8ms/batch - loss: 14.98572 - diff: 11.13mlTrain batch 23/32 - 242.0ms/batch - loss: 14.67050 - diff: 11.04mlTrain batch 24/32 - 244.4ms/batch - loss: 14.38981 - diff: 10.88mlTrain batch 25/32 - 242.0ms/batch - loss: 14.01848 - diff: 10.73mlTrain batch 26/32 - 242.0ms/batch - loss: 13.71117 - diff: 10.65mlTrain batch 27/32 - 244.1ms/batch - loss: 13.39204 - diff: 10.52mlTrain batch 28/32 - 242.4ms/batch - loss: 13.55712 - diff: 10.68mlTrain batch 29/32 - 243.9ms/batch - loss: 13.46969 - diff: 10.71mlTrain batch 30/32 - 242.8ms/batch - loss: 13.43486 - diff: 10.77mlTrain batch 31/32 - 243.9ms/batch - loss: 13.29436 - diff: 10.74mlTrain batch 32/32 - 78.2ms/batch - loss: 16.66749 - diff: 10.95mlTrain batch 32/32 - 11.3s 78.2ms/batch - loss: 16.66749 - diff: 10.95ml
Test 1.1s: val_loss: 253.39409 - diff: 56.93ml
Epoch    93: reducing learning rate of group 0 to 3.9063e-06.

Epoch 93: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 241.8ms/batch - loss: 4.92065 - diff: 6.82mlTrain batch 2/32 - 242.8ms/batch - loss: 8.40124 - diff: 8.47mlTrain batch 3/32 - 242.0ms/batch - loss: 7.27188 - diff: 7.77mlTrain batch 4/32 - 244.6ms/batch - loss: 10.65036 - diff: 9.72mlTrain batch 5/32 - 244.5ms/batch - loss: 9.49988 - diff: 9.11mlTrain batch 6/32 - 242.0ms/batch - loss: 8.46523 - diff: 8.57mlTrain batch 7/32 - 242.4ms/batch - loss: 9.04259 - diff: 9.16mlTrain batch 8/32 - 243.9ms/batch - loss: 10.56792 - diff: 9.86mlTrain batch 9/32 - 242.0ms/batch - loss: 10.27250 - diff: 9.83mlTrain batch 10/32 - 243.4ms/batch - loss: 9.90476 - diff: 9.76mlTrain batch 11/32 - 242.0ms/batch - loss: 9.83549 - diff: 9.79mlTrain batch 12/32 - 244.3ms/batch - loss: 31.50923 - diff: 13.68mlTrain batch 13/32 - 241.8ms/batch - loss: 29.65838 - diff: 13.36mlTrain batch 14/32 - 243.8ms/batch - loss: 28.39624 - diff: 13.27mlTrain batch 15/32 - 242.4ms/batch - loss: 27.29824 - diff: 13.16mlTrain batch 16/32 - 244.1ms/batch - loss: 26.62255 - diff: 13.18mlTrain batch 17/32 - 242.4ms/batch - loss: 25.48332 - diff: 12.87mlTrain batch 18/32 - 242.2ms/batch - loss: 24.41562 - diff: 12.54mlTrain batch 19/32 - 241.9ms/batch - loss: 23.34201 - diff: 12.24mlTrain batch 20/32 - 243.3ms/batch - loss: 23.30315 - diff: 12.44mlTrain batch 21/32 - 241.8ms/batch - loss: 22.35206 - diff: 12.13mlTrain batch 22/32 - 244.5ms/batch - loss: 21.83964 - diff: 12.09mlTrain batch 23/32 - 242.3ms/batch - loss: 21.46984 - diff: 12.14mlTrain batch 24/32 - 244.4ms/batch - loss: 21.34088 - diff: 12.23mlTrain batch 25/32 - 242.1ms/batch - loss: 20.58832 - diff: 11.97mlTrain batch 26/32 - 244.4ms/batch - loss: 20.69903 - diff: 12.21mlTrain batch 27/32 - 242.2ms/batch - loss: 20.19231 - diff: 12.09mlTrain batch 28/32 - 242.6ms/batch - loss: 20.28807 - diff: 12.24mlTrain batch 29/32 - 242.2ms/batch - loss: 19.72719 - diff: 12.02mlTrain batch 30/32 - 241.6ms/batch - loss: 19.53814 - diff: 12.08mlTrain batch 31/32 - 243.1ms/batch - loss: 19.03618 - diff: 11.89mlTrain batch 32/32 - 78.3ms/batch - loss: 19.21541 - diff: 11.88mlTrain batch 32/32 - 11.1s 78.3ms/batch - loss: 19.21541 - diff: 11.88ml
Test 1.1s: val_loss: 369.90376 - diff: 69.36ml

Epoch 94: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 242.0ms/batch - loss: 18.77151 - diff: 15.05mlTrain batch 2/32 - 244.1ms/batch - loss: 41.56221 - diff: 21.25mlTrain batch 3/32 - 241.4ms/batch - loss: 31.16550 - diff: 17.67mlTrain batch 4/32 - 243.6ms/batch - loss: 24.35199 - diff: 14.56mlTrain batch 5/32 - 242.1ms/batch - loss: 20.30498 - diff: 12.69mlTrain batch 6/32 - 243.4ms/batch - loss: 20.28322 - diff: 13.10mlTrain batch 7/32 - 241.9ms/batch - loss: 18.30587 - diff: 12.41mlTrain batch 8/32 - 243.3ms/batch - loss: 16.68936 - diff: 11.75mlTrain batch 9/32 - 242.1ms/batch - loss: 15.45725 - diff: 11.22mlTrain batch 10/32 - 243.0ms/batch - loss: 14.65625 - diff: 10.98mlTrain batch 11/32 - 242.4ms/batch - loss: 13.68923 - diff: 10.58mlTrain batch 12/32 - 242.1ms/batch - loss: 13.35363 - diff: 10.63mlTrain batch 13/32 - 241.9ms/batch - loss: 13.05145 - diff: 10.59mlTrain batch 14/32 - 243.5ms/batch - loss: 12.58255 - diff: 10.44mlTrain batch 15/32 - 242.6ms/batch - loss: 12.04366 - diff: 10.14mlTrain batch 16/32 - 242.7ms/batch - loss: 12.34836 - diff: 10.38mlTrain batch 17/32 - 247.8ms/batch - loss: 14.79102 - diff: 11.27mlTrain batch 18/32 - 242.1ms/batch - loss: 14.57572 - diff: 11.26mlTrain batch 19/32 - 241.9ms/batch - loss: 13.97400 - diff: 11.01mlTrain batch 20/32 - 244.3ms/batch - loss: 14.43381 - diff: 11.28mlTrain batch 21/32 - 242.0ms/batch - loss: 14.35042 - diff: 11.29mlTrain batch 22/32 - 244.3ms/batch - loss: 14.12052 - diff: 11.26mlTrain batch 23/32 - 241.9ms/batch - loss: 13.78287 - diff: 11.10mlTrain batch 24/32 - 244.3ms/batch - loss: 14.11850 - diff: 11.25mlTrain batch 25/32 - 241.7ms/batch - loss: 13.85018 - diff: 11.15mlTrain batch 26/32 - 243.6ms/batch - loss: 15.19921 - diff: 11.63mlTrain batch 27/32 - 242.1ms/batch - loss: 15.16649 - diff: 11.69mlTrain batch 28/32 - 243.4ms/batch - loss: 15.25287 - diff: 11.76mlTrain batch 29/32 - 242.2ms/batch - loss: 14.87913 - diff: 11.59mlTrain batch 30/32 - 244.2ms/batch - loss: 14.72450 - diff: 11.55mlTrain batch 31/32 - 241.9ms/batch - loss: 14.45284 - diff: 11.45mlTrain batch 32/32 - 78.0ms/batch - loss: 15.22707 - diff: 11.52mlTrain batch 32/32 - 12.3s 78.0ms/batch - loss: 15.22707 - diff: 11.52ml
Test 1.2s: val_loss: 373.55549 - diff: 70.80ml

Epoch 95: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 241.5ms/batch - loss: 2.94595 - diff: 5.67mlTrain batch 2/32 - 242.0ms/batch - loss: 2.53800 - diff: 5.48mlTrain batch 3/32 - 241.9ms/batch - loss: 3.85567 - diff: 6.03mlTrain batch 4/32 - 243.5ms/batch - loss: 5.04465 - diff: 6.69mlTrain batch 5/32 - 242.4ms/batch - loss: 5.14727 - diff: 6.90mlTrain batch 6/32 - 244.1ms/batch - loss: 5.76386 - diff: 7.38mlTrain batch 7/32 - 241.8ms/batch - loss: 5.66156 - diff: 7.40mlTrain batch 8/32 - 243.7ms/batch - loss: 10.48283 - diff: 9.37mlTrain batch 9/32 - 241.9ms/batch - loss: 10.03496 - diff: 9.25mlTrain batch 10/32 - 243.6ms/batch - loss: 9.97502 - diff: 9.35mlTrain batch 11/32 - 242.5ms/batch - loss: 10.91425 - diff: 9.93mlTrain batch 12/32 - 243.6ms/batch - loss: 10.30398 - diff: 9.59mlTrain batch 13/32 - 241.8ms/batch - loss: 9.91112 - diff: 9.49mlTrain batch 14/32 - 244.4ms/batch - loss: 10.21877 - diff: 9.54mlTrain batch 15/32 - 241.8ms/batch - loss: 10.33101 - diff: 9.72mlTrain batch 16/32 - 244.1ms/batch - loss: 9.98567 - diff: 9.58mlTrain batch 17/32 - 241.9ms/batch - loss: 9.86263 - diff: 9.52mlTrain batch 18/32 - 244.0ms/batch - loss: 9.47256 - diff: 9.30mlTrain batch 19/32 - 242.2ms/batch - loss: 9.63905 - diff: 9.43mlTrain batch 20/32 - 244.1ms/batch - loss: 9.33444 - diff: 9.27mlTrain batch 21/32 - 243.4ms/batch - loss: 9.34256 - diff: 9.31mlTrain batch 22/32 - 242.1ms/batch - loss: 9.25503 - diff: 9.29mlTrain batch 23/32 - 242.0ms/batch - loss: 9.15198 - diff: 9.27mlTrain batch 24/32 - 243.4ms/batch - loss: 9.16084 - diff: 9.24mlTrain batch 25/32 - 242.0ms/batch - loss: 9.36622 - diff: 9.38mlTrain batch 26/32 - 242.2ms/batch - loss: 9.11990 - diff: 9.22mlTrain batch 27/32 - 242.5ms/batch - loss: 9.08359 - diff: 9.22mlTrain batch 28/32 - 243.8ms/batch - loss: 9.15838 - diff: 9.33mlTrain batch 29/32 - 241.9ms/batch - loss: 9.72254 - diff: 9.63mlTrain batch 30/32 - 244.2ms/batch - loss: 9.88428 - diff: 9.73mlTrain batch 31/32 - 242.5ms/batch - loss: 9.87849 - diff: 9.73mlTrain batch 32/32 - 78.2ms/batch - loss: 10.91841 - diff: 9.83mlTrain batch 32/32 - 11.8s 78.2ms/batch - loss: 10.91841 - diff: 9.83ml
Test 1.2s: val_loss: 365.58055 - diff: 69.34ml

Epoch 96: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 242.0ms/batch - loss: 18.07384 - diff: 16.12mlTrain batch 2/32 - 242.3ms/batch - loss: 88.53898 - diff: 30.21mlTrain batch 3/32 - 241.9ms/batch - loss: 62.36285 - diff: 23.51mlTrain batch 4/32 - 242.7ms/batch - loss: 48.59486 - diff: 19.73mlTrain batch 5/32 - 241.6ms/batch - loss: 40.36072 - diff: 17.73mlTrain batch 6/32 - 243.9ms/batch - loss: 34.20990 - diff: 15.75mlTrain batch 7/32 - 242.4ms/batch - loss: 31.23654 - diff: 15.14mlTrain batch 8/32 - 244.2ms/batch - loss: 27.70249 - diff: 14.01mlTrain batch 9/32 - 242.9ms/batch - loss: 26.07765 - diff: 13.86mlTrain batch 10/32 - 244.0ms/batch - loss: 24.49383 - diff: 13.42mlTrain batch 11/32 - 242.3ms/batch - loss: 22.95347 - diff: 13.10mlTrain batch 12/32 - 242.8ms/batch - loss: 21.49696 - diff: 12.65mlTrain batch 13/32 - 241.8ms/batch - loss: 20.66383 - diff: 12.44mlTrain batch 14/32 - 244.0ms/batch - loss: 19.42732 - diff: 11.98mlTrain batch 15/32 - 242.1ms/batch - loss: 18.65618 - diff: 11.81mlTrain batch 16/32 - 242.4ms/batch - loss: 18.20428 - diff: 11.78mlTrain batch 17/32 - 242.2ms/batch - loss: 17.47180 - diff: 11.56mlTrain batch 18/32 - 244.4ms/batch - loss: 17.50567 - diff: 11.72mlTrain batch 19/32 - 241.8ms/batch - loss: 16.83364 - diff: 11.48mlTrain batch 20/32 - 244.3ms/batch - loss: 19.41358 - diff: 12.46mlTrain batch 21/32 - 242.3ms/batch - loss: 19.52879 - diff: 12.64mlTrain batch 22/32 - 242.1ms/batch - loss: 18.79680 - diff: 12.34mlTrain batch 23/32 - 244.3ms/batch - loss: 18.24414 - diff: 12.14mlTrain batch 24/32 - 242.6ms/batch - loss: 17.78629 - diff: 12.03mlTrain batch 25/32 - 243.2ms/batch - loss: 17.27170 - diff: 11.85mlTrain batch 26/32 - 242.3ms/batch - loss: 16.77508 - diff: 11.67mlTrain batch 27/32 - 244.0ms/batch - loss: 16.35206 - diff: 11.52mlTrain batch 28/32 - 242.8ms/batch - loss: 16.03297 - diff: 11.43mlTrain batch 29/32 - 243.6ms/batch - loss: 15.70239 - diff: 11.33mlTrain batch 30/32 - 241.6ms/batch - loss: 15.36011 - diff: 11.21mlTrain batch 31/32 - 244.3ms/batch - loss: 15.18763 - diff: 11.22mlTrain batch 32/32 - 79.0ms/batch - loss: 15.96405 - diff: 11.29mlTrain batch 32/32 - 11.4s 79.0ms/batch - loss: 15.96405 - diff: 11.29ml
Test 1.1s: val_loss: 274.60878 - diff: 60.12ml

Epoch 97: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 241.8ms/batch - loss: 8.37315 - diff: 9.41mlTrain batch 2/32 - 242.3ms/batch - loss: 6.31245 - diff: 8.36mlTrain batch 3/32 - 241.9ms/batch - loss: 6.45473 - diff: 8.35mlTrain batch 4/32 - 243.7ms/batch - loss: 7.31645 - diff: 8.70mlTrain batch 5/32 - 241.8ms/batch - loss: 7.36011 - diff: 8.84mlTrain batch 6/32 - 243.4ms/batch - loss: 7.16878 - diff: 8.63mlTrain batch 7/32 - 242.0ms/batch - loss: 6.87017 - diff: 8.38mlTrain batch 8/32 - 243.7ms/batch - loss: 16.31196 - diff: 11.11mlTrain batch 9/32 - 242.8ms/batch - loss: 15.02129 - diff: 10.53mlTrain batch 10/32 - 244.0ms/batch - loss: 15.29693 - diff: 10.84mlTrain batch 11/32 - 241.9ms/batch - loss: 17.70588 - diff: 12.10mlTrain batch 12/32 - 244.4ms/batch - loss: 17.28720 - diff: 11.96mlTrain batch 13/32 - 242.7ms/batch - loss: 16.86405 - diff: 11.83mlTrain batch 14/32 - 244.3ms/batch - loss: 16.11022 - diff: 11.64mlTrain batch 15/32 - 241.6ms/batch - loss: 15.27725 - diff: 11.26mlTrain batch 16/32 - 241.9ms/batch - loss: 14.99052 - diff: 11.23mlTrain batch 17/32 - 242.6ms/batch - loss: 14.72667 - diff: 11.21mlTrain batch 18/32 - 243.7ms/batch - loss: 14.27188 - diff: 11.03mlTrain batch 19/32 - 241.9ms/batch - loss: 14.07389 - diff: 11.02mlTrain batch 20/32 - 244.3ms/batch - loss: 14.22820 - diff: 11.14mlTrain batch 21/32 - 242.5ms/batch - loss: 15.17649 - diff: 11.58mlTrain batch 22/32 - 242.8ms/batch - loss: 14.60638 - diff: 11.30mlTrain batch 23/32 - 241.8ms/batch - loss: 14.47311 - diff: 11.29mlTrain batch 24/32 - 244.5ms/batch - loss: 14.13369 - diff: 11.07mlTrain batch 25/32 - 242.1ms/batch - loss: 13.84808 - diff: 10.98mlTrain batch 26/32 - 243.5ms/batch - loss: 13.55290 - diff: 10.86mlTrain batch 27/32 - 242.0ms/batch - loss: 13.41073 - diff: 10.77mlTrain batch 28/32 - 244.3ms/batch - loss: 13.59686 - diff: 10.92mlTrain batch 29/32 - 242.8ms/batch - loss: 13.70146 - diff: 11.05mlTrain batch 30/32 - 243.6ms/batch - loss: 13.44457 - diff: 10.95mlTrain batch 31/32 - 242.1ms/batch - loss: 13.52483 - diff: 11.07mlTrain batch 32/32 - 78.8ms/batch - loss: 14.15234 - diff: 11.12mlTrain batch 32/32 - 11.8s 78.8ms/batch - loss: 14.15234 - diff: 11.12ml
Test 1.2s: val_loss: 312.85570 - diff: 64.69ml

Epoch 98: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 241.4ms/batch - loss: 5.67488 - diff: 7.10mlTrain batch 2/32 - 244.3ms/batch - loss: 6.01315 - diff: 7.69mlTrain batch 3/32 - 242.1ms/batch - loss: 8.68735 - diff: 9.23mlTrain batch 4/32 - 244.3ms/batch - loss: 7.19242 - diff: 8.22mlTrain batch 5/32 - 242.0ms/batch - loss: 8.70366 - diff: 9.18mlTrain batch 6/32 - 242.0ms/batch - loss: 8.51734 - diff: 9.07mlTrain batch 7/32 - 242.8ms/batch - loss: 8.92726 - diff: 9.30mlTrain batch 8/32 - 242.0ms/batch - loss: 9.35598 - diff: 9.56mlTrain batch 9/32 - 241.9ms/batch - loss: 9.28102 - diff: 9.62mlTrain batch 10/32 - 243.7ms/batch - loss: 8.58514 - diff: 9.13mlTrain batch 11/32 - 242.3ms/batch - loss: 8.33769 - diff: 9.07mlTrain batch 12/32 - 242.0ms/batch - loss: 8.34525 - diff: 9.13mlTrain batch 13/32 - 241.5ms/batch - loss: 11.06216 - diff: 10.19mlTrain batch 14/32 - 242.0ms/batch - loss: 10.52108 - diff: 9.92mlTrain batch 15/32 - 241.8ms/batch - loss: 10.29605 - diff: 9.77mlTrain batch 16/32 - 243.3ms/batch - loss: 13.00640 - diff: 10.77mlTrain batch 17/32 - 242.5ms/batch - loss: 12.36883 - diff: 10.40mlTrain batch 18/32 - 244.1ms/batch - loss: 12.09674 - diff: 10.33mlTrain batch 19/32 - 241.8ms/batch - loss: 12.42050 - diff: 10.58mlTrain batch 20/32 - 244.1ms/batch - loss: 12.08325 - diff: 10.42mlTrain batch 21/32 - 241.3ms/batch - loss: 12.09074 - diff: 10.46mlTrain batch 22/32 - 242.6ms/batch - loss: 11.78290 - diff: 10.32mlTrain batch 23/32 - 243.1ms/batch - loss: 11.88872 - diff: 10.39mlTrain batch 24/32 - 243.8ms/batch - loss: 13.49818 - diff: 11.01mlTrain batch 25/32 - 242.0ms/batch - loss: 13.17189 - diff: 10.90mlTrain batch 26/32 - 244.4ms/batch - loss: 12.96780 - diff: 10.83mlTrain batch 27/32 - 242.8ms/batch - loss: 12.62201 - diff: 10.66mlTrain batch 28/32 - 243.5ms/batch - loss: 12.79204 - diff: 10.80mlTrain batch 29/32 - 241.9ms/batch - loss: 12.66757 - diff: 10.76mlTrain batch 30/32 - 244.0ms/batch - loss: 12.33949 - diff: 10.59mlTrain batch 31/32 - 241.9ms/batch - loss: 12.30183 - diff: 10.65mlTrain batch 32/32 - 78.6ms/batch - loss: 12.94871 - diff: 10.69mlTrain batch 32/32 - 11.5s 78.6ms/batch - loss: 12.94871 - diff: 10.69ml
Test 1.1s: val_loss: 300.46793 - diff: 62.22ml

Epoch 99: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 241.6ms/batch - loss: 43.95992 - diff: 22.20mlTrain batch 2/32 - 243.4ms/batch - loss: 24.59568 - diff: 14.76mlTrain batch 3/32 - 242.6ms/batch - loss: 17.92792 - diff: 12.11mlTrain batch 4/32 - 244.3ms/batch - loss: 15.20729 - diff: 11.28mlTrain batch 5/32 - 242.2ms/batch - loss: 15.00216 - diff: 11.69mlTrain batch 6/32 - 242.2ms/batch - loss: 14.11496 - diff: 11.31mlTrain batch 7/32 - 242.7ms/batch - loss: 14.62996 - diff: 11.47mlTrain batch 8/32 - 243.4ms/batch - loss: 14.00696 - diff: 11.07mlTrain batch 9/32 - 242.1ms/batch - loss: 12.80060 - diff: 10.46mlTrain batch 10/32 - 242.4ms/batch - loss: 12.97900 - diff: 10.69mlTrain batch 11/32 - 242.4ms/batch - loss: 12.50348 - diff: 10.53mlTrain batch 12/32 - 244.4ms/batch - loss: 16.67837 - diff: 11.79mlTrain batch 13/32 - 242.1ms/batch - loss: 15.58473 - diff: 11.26mlTrain batch 14/32 - 243.9ms/batch - loss: 15.25403 - diff: 11.31mlTrain batch 15/32 - 242.7ms/batch - loss: 14.73766 - diff: 11.16mlTrain batch 16/32 - 244.5ms/batch - loss: 14.16828 - diff: 10.93mlTrain batch 17/32 - 242.2ms/batch - loss: 13.75053 - diff: 10.82mlTrain batch 18/32 - 244.3ms/batch - loss: 13.70539 - diff: 10.85mlTrain batch 19/32 - 242.2ms/batch - loss: 13.34242 - diff: 10.75mlTrain batch 20/32 - 243.5ms/batch - loss: 13.07025 - diff: 10.62mlTrain batch 21/32 - 242.1ms/batch - loss: 13.25649 - diff: 10.75mlTrain batch 22/32 - 244.5ms/batch - loss: 13.06572 - diff: 10.70mlTrain batch 23/32 - 242.2ms/batch - loss: 12.72270 - diff: 10.54mlTrain batch 24/32 - 242.6ms/batch - loss: 13.07035 - diff: 10.79mlTrain batch 25/32 - 242.0ms/batch - loss: 12.73465 - diff: 10.62mlTrain batch 26/32 - 243.9ms/batch - loss: 12.48634 - diff: 10.50mlTrain batch 27/32 - 242.1ms/batch - loss: 12.41386 - diff: 10.53mlTrain batch 28/32 - 244.2ms/batch - loss: 12.26863 - diff: 10.49mlTrain batch 29/32 - 242.9ms/batch - loss: 12.55493 - diff: 10.64mlTrain batch 30/32 - 244.5ms/batch - loss: 12.70272 - diff: 10.76mlTrain batch 31/32 - 242.5ms/batch - loss: 12.54246 - diff: 10.69mlTrain batch 32/32 - 78.8ms/batch - loss: 12.85916 - diff: 10.69mlTrain batch 32/32 - 11.8s 78.8ms/batch - loss: 12.85916 - diff: 10.69ml
Test 1.2s: val_loss: 279.75214 - diff: 60.14ml

Epoch 100: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 241.2ms/batch - loss: 10.16852 - diff: 10.36mlTrain batch 2/32 - 244.3ms/batch - loss: 11.41753 - diff: 9.55mlTrain batch 3/32 - 246.4ms/batch - loss: 8.30103 - diff: 8.00mlTrain batch 4/32 - 242.4ms/batch - loss: 7.53628 - diff: 7.94mlTrain batch 5/32 - 241.8ms/batch - loss: 7.70112 - diff: 8.43mlTrain batch 6/32 - 243.1ms/batch - loss: 6.98588 - diff: 8.04mlTrain batch 7/32 - 241.7ms/batch - loss: 6.96403 - diff: 8.08mlTrain batch 8/32 - 243.2ms/batch - loss: 8.10848 - diff: 8.77mlTrain batch 9/32 - 242.3ms/batch - loss: 7.72369 - diff: 8.58mlTrain batch 10/32 - 244.4ms/batch - loss: 8.79866 - diff: 9.35mlTrain batch 11/32 - 242.9ms/batch - loss: 8.55751 - diff: 9.29mlTrain batch 12/32 - 242.9ms/batch - loss: 8.79319 - diff: 9.44mlTrain batch 13/32 - 242.1ms/batch - loss: 8.94637 - diff: 9.57mlTrain batch 14/32 - 244.4ms/batch - loss: 8.72755 - diff: 9.47mlTrain batch 15/32 - 242.5ms/batch - loss: 8.36378 - diff: 9.22mlTrain batch 16/32 - 244.2ms/batch - loss: 8.70575 - diff: 9.32mlTrain batch 17/32 - 243.3ms/batch - loss: 8.53760 - diff: 9.23mlTrain batch 18/32 - 244.1ms/batch - loss: 9.12245 - diff: 9.51mlTrain batch 19/32 - 242.4ms/batch - loss: 13.51219 - diff: 10.66mlTrain batch 20/32 - 244.4ms/batch - loss: 14.24878 - diff: 11.01mlTrain batch 21/32 - 242.1ms/batch - loss: 13.68735 - diff: 10.73mlTrain batch 22/32 - 244.6ms/batch - loss: 13.47456 - diff: 10.66mlTrain batch 23/32 - 242.3ms/batch - loss: 13.34344 - diff: 10.64mlTrain batch 24/32 - 243.9ms/batch - loss: 13.49415 - diff: 10.71mlTrain batch 25/32 - 242.1ms/batch - loss: 13.10333 - diff: 10.54mlTrain batch 26/32 - 243.3ms/batch - loss: 13.12281 - diff: 10.61mlTrain batch 27/32 - 243.0ms/batch - loss: 12.95638 - diff: 10.56mlTrain batch 28/32 - 243.5ms/batch - loss: 13.06291 - diff: 10.66mlTrain batch 29/32 - 242.7ms/batch - loss: 12.90512 - diff: 10.64mlTrain batch 30/32 - 244.3ms/batch - loss: 12.58359 - diff: 10.48mlTrain batch 31/32 - 242.9ms/batch - loss: 12.38589 - diff: 10.39mlTrain batch 32/32 - 78.7ms/batch - loss: 12.54977 - diff: 10.39mlTrain batch 32/32 - 11.9s 78.7ms/batch - loss: 12.54977 - diff: 10.39ml
Test 1.2s: val_loss: 225.37353 - diff: 54.17ml

Epoch 101: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 241.5ms/batch - loss: 15.13881 - diff: 13.12mlTrain batch 2/32 - 242.2ms/batch - loss: 10.99749 - diff: 10.39mlTrain batch 3/32 - 242.9ms/batch - loss: 8.51462 - diff: 8.88mlTrain batch 4/32 - 244.2ms/batch - loss: 7.07792 - diff: 8.06mlTrain batch 5/32 - 242.1ms/batch - loss: 7.11845 - diff: 8.18mlTrain batch 6/32 - 242.6ms/batch - loss: 7.33567 - diff: 8.49mlTrain batch 7/32 - 242.4ms/batch - loss: 8.92506 - diff: 9.44mlTrain batch 8/32 - 243.5ms/batch - loss: 15.92993 - diff: 11.91mlTrain batch 9/32 - 242.2ms/batch - loss: 14.76753 - diff: 11.45mlTrain batch 10/32 - 242.5ms/batch - loss: 13.98831 - diff: 11.20mlTrain batch 11/32 - 242.1ms/batch - loss: 13.27948 - diff: 10.86mlTrain batch 12/32 - 244.5ms/batch - loss: 13.17737 - diff: 11.02mlTrain batch 13/32 - 242.4ms/batch - loss: 13.24095 - diff: 10.98mlTrain batch 14/32 - 243.6ms/batch - loss: 15.22241 - diff: 11.75mlTrain batch 15/32 - 242.0ms/batch - loss: 15.35688 - diff: 11.95mlTrain batch 16/32 - 244.1ms/batch - loss: 14.84667 - diff: 11.71mlTrain batch 17/32 - 242.1ms/batch - loss: 14.45062 - diff: 11.58mlTrain batch 18/32 - 244.5ms/batch - loss: 14.07070 - diff: 11.41mlTrain batch 19/32 - 242.2ms/batch - loss: 13.57730 - diff: 11.17mlTrain batch 20/32 - 244.6ms/batch - loss: 13.13986 - diff: 10.96mlTrain batch 21/32 - 242.7ms/batch - loss: 12.78367 - diff: 10.78mlTrain batch 22/32 - 243.2ms/batch - loss: 12.38965 - diff: 10.60mlTrain batch 23/32 - 242.3ms/batch - loss: 12.11761 - diff: 10.43mlTrain batch 24/32 - 244.1ms/batch - loss: 11.97441 - diff: 10.40mlTrain batch 25/32 - 242.2ms/batch - loss: 11.79166 - diff: 10.31mlTrain batch 26/32 - 244.2ms/batch - loss: 12.27203 - diff: 10.63mlTrain batch 27/32 - 242.6ms/batch - loss: 11.95848 - diff: 10.47mlTrain batch 28/32 - 244.5ms/batch - loss: 11.63869 - diff: 10.28mlTrain batch 29/32 - 242.4ms/batch - loss: 11.64090 - diff: 10.31mlTrain batch 30/32 - 244.5ms/batch - loss: 11.68367 - diff: 10.40mlTrain batch 31/32 - 241.9ms/batch - loss: 11.54757 - diff: 10.35mlTrain batch 32/32 - 78.8ms/batch - loss: 12.42910 - diff: 10.43mlTrain batch 32/32 - 11.7s 78.8ms/batch - loss: 12.42910 - diff: 10.43ml
Test 1.1s: val_loss: 369.05924 - diff: 70.21ml

Epoch 102: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 242.6ms/batch - loss: 18.11449 - diff: 11.93mlTrain batch 2/32 - 244.1ms/batch - loss: 12.60497 - diff: 10.29mlTrain batch 3/32 - 241.6ms/batch - loss: 10.89722 - diff: 9.84mlTrain batch 4/32 - 242.2ms/batch - loss: 9.62436 - diff: 8.97mlTrain batch 5/32 - 242.7ms/batch - loss: 8.55724 - diff: 8.52mlTrain batch 6/32 - 243.9ms/batch - loss: 8.41260 - diff: 8.61mlTrain batch 7/32 - 242.7ms/batch - loss: 7.68293 - diff: 8.29mlTrain batch 8/32 - 242.8ms/batch - loss: 7.98733 - diff: 8.62mlTrain batch 9/32 - 241.1ms/batch - loss: 10.86263 - diff: 10.00mlTrain batch 10/32 - 242.4ms/batch - loss: 11.53598 - diff: 10.47mlTrain batch 11/32 - 242.0ms/batch - loss: 10.96019 - diff: 10.14mlTrain batch 12/32 - 244.3ms/batch - loss: 10.62272 - diff: 10.02mlTrain batch 13/32 - 242.7ms/batch - loss: 11.59841 - diff: 10.53mlTrain batch 14/32 - 242.1ms/batch - loss: 11.30604 - diff: 10.31mlTrain batch 15/32 - 241.8ms/batch - loss: 10.91123 - diff: 10.12mlTrain batch 16/32 - 242.3ms/batch - loss: 11.04324 - diff: 10.23mlTrain batch 17/32 - 242.6ms/batch - loss: 12.24383 - diff: 10.77mlTrain batch 18/32 - 243.4ms/batch - loss: 16.54184 - diff: 11.82mlTrain batch 19/32 - 241.9ms/batch - loss: 15.86068 - diff: 11.54mlTrain batch 20/32 - 244.4ms/batch - loss: 15.20234 - diff: 11.24mlTrain batch 21/32 - 242.2ms/batch - loss: 14.65917 - diff: 11.01mlTrain batch 22/32 - 243.6ms/batch - loss: 14.18947 - diff: 10.83mlTrain batch 23/32 - 241.5ms/batch - loss: 14.27852 - diff: 10.96mlTrain batch 24/32 - 243.2ms/batch - loss: 14.22553 - diff: 10.98mlTrain batch 25/32 - 241.9ms/batch - loss: 13.85531 - diff: 10.85mlTrain batch 26/32 - 247.8ms/batch - loss: 13.49065 - diff: 10.71mlTrain batch 27/32 - 241.9ms/batch - loss: 13.34203 - diff: 10.70mlTrain batch 28/32 - 243.4ms/batch - loss: 13.54630 - diff: 10.84mlTrain batch 29/32 - 242.1ms/batch - loss: 14.00615 - diff: 11.07mlTrain batch 30/32 - 244.5ms/batch - loss: 13.75626 - diff: 10.98mlTrain batch 31/32 - 242.1ms/batch - loss: 13.56325 - diff: 10.89mlTrain batch 32/32 - 78.1ms/batch - loss: 14.10400 - diff: 10.94mlTrain batch 32/32 - 11.6s 78.1ms/batch - loss: 14.10400 - diff: 10.94ml
Test 1.2s: val_loss: 332.56230 - diff: 66.23ml

Epoch 103: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 241.6ms/batch - loss: 19.32437 - diff: 15.53mlTrain batch 2/32 - 242.0ms/batch - loss: 13.96261 - diff: 12.52mlTrain batch 3/32 - 242.1ms/batch - loss: 10.51021 - diff: 10.24mlTrain batch 4/32 - 244.4ms/batch - loss: 8.57375 - diff: 9.03mlTrain batch 5/32 - 242.9ms/batch - loss: 9.03563 - diff: 9.49mlTrain batch 6/32 - 243.4ms/batch - loss: 8.40947 - diff: 9.04mlTrain batch 7/32 - 241.8ms/batch - loss: 7.59383 - diff: 8.44mlTrain batch 8/32 - 241.9ms/batch - loss: 8.02926 - diff: 8.80mlTrain batch 9/32 - 241.9ms/batch - loss: 7.78912 - diff: 8.59mlTrain batch 10/32 - 241.3ms/batch - loss: 7.37599 - diff: 8.32mlTrain batch 11/32 - 242.2ms/batch - loss: 7.61513 - diff: 8.55mlTrain batch 12/32 - 241.9ms/batch - loss: 7.41227 - diff: 8.37mlTrain batch 13/32 - 244.1ms/batch - loss: 9.50316 - diff: 9.22mlTrain batch 14/32 - 242.0ms/batch - loss: 9.14550 - diff: 9.05mlTrain batch 15/32 - 244.0ms/batch - loss: 10.19842 - diff: 9.54mlTrain batch 16/32 - 241.8ms/batch - loss: 9.77419 - diff: 9.33mlTrain batch 17/32 - 242.6ms/batch - loss: 9.62027 - diff: 9.23mlTrain batch 18/32 - 242.6ms/batch - loss: 9.99392 - diff: 9.53mlTrain batch 19/32 - 242.4ms/batch - loss: 9.66033 - diff: 9.35mlTrain batch 20/32 - 242.0ms/batch - loss: 9.52476 - diff: 9.28mlTrain batch 21/32 - 242.5ms/batch - loss: 9.22311 - diff: 9.12mlTrain batch 22/32 - 242.9ms/batch - loss: 8.93724 - diff: 8.97mlTrain batch 23/32 - 242.5ms/batch - loss: 8.80001 - diff: 8.92mlTrain batch 24/32 - 242.3ms/batch - loss: 8.87910 - diff: 9.00mlTrain batch 25/32 - 244.5ms/batch - loss: 16.36561 - diff: 10.44mlTrain batch 26/32 - 242.4ms/batch - loss: 16.15329 - diff: 10.48mlTrain batch 27/32 - 244.1ms/batch - loss: 15.81414 - diff: 10.41mlTrain batch 28/32 - 242.5ms/batch - loss: 15.86474 - diff: 10.59mlTrain batch 29/32 - 244.0ms/batch - loss: 15.43611 - diff: 10.42mlTrain batch 30/32 - 243.0ms/batch - loss: 15.11940 - diff: 10.35mlTrain batch 31/32 - 243.1ms/batch - loss: 14.93474 - diff: 10.35mlTrain batch 32/32 - 78.4ms/batch - loss: 14.83831 - diff: 10.29mlTrain batch 32/32 - 11.2s 78.4ms/batch - loss: 14.83831 - diff: 10.29ml
Test 1.1s: val_loss: 328.82896 - diff: 66.00ml
Epoch   104: reducing learning rate of group 0 to 1.9531e-06.

Epoch 104: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 241.5ms/batch - loss: 12.11076 - diff: 11.28mlTrain batch 2/32 - 243.9ms/batch - loss: 9.27383 - diff: 9.99mlTrain batch 3/32 - 241.4ms/batch - loss: 7.70617 - diff: 9.06mlTrain batch 4/32 - 240.9ms/batch - loss: 7.47621 - diff: 8.64mlTrain batch 5/32 - 242.0ms/batch - loss: 7.97849 - diff: 9.05mlTrain batch 6/32 - 246.2ms/batch - loss: 7.83605 - diff: 8.99mlTrain batch 7/32 - 242.2ms/batch - loss: 7.94080 - diff: 9.17mlTrain batch 8/32 - 242.4ms/batch - loss: 8.02476 - diff: 8.92mlTrain batch 9/32 - 242.3ms/batch - loss: 8.29899 - diff: 9.22mlTrain batch 10/32 - 243.6ms/batch - loss: 8.03205 - diff: 9.11mlTrain batch 11/32 - 242.1ms/batch - loss: 7.89085 - diff: 8.98mlTrain batch 12/32 - 244.3ms/batch - loss: 7.79716 - diff: 8.95mlTrain batch 13/32 - 242.6ms/batch - loss: 7.80739 - diff: 8.95mlTrain batch 14/32 - 244.3ms/batch - loss: 7.62076 - diff: 8.82mlTrain batch 15/32 - 242.3ms/batch - loss: 7.93214 - diff: 9.02mlTrain batch 16/32 - 243.6ms/batch - loss: 7.84644 - diff: 9.03mlTrain batch 17/32 - 242.0ms/batch - loss: 7.65553 - diff: 8.87mlTrain batch 18/32 - 243.6ms/batch - loss: 7.45594 - diff: 8.71mlTrain batch 19/32 - 241.9ms/batch - loss: 7.77288 - diff: 8.95mlTrain batch 20/32 - 244.0ms/batch - loss: 7.89145 - diff: 9.04mlTrain batch 21/32 - 242.3ms/batch - loss: 7.76513 - diff: 8.96mlTrain batch 22/32 - 243.7ms/batch - loss: 8.14777 - diff: 9.15mlTrain batch 23/32 - 243.0ms/batch - loss: 8.66637 - diff: 9.37mlTrain batch 24/32 - 244.2ms/batch - loss: 8.42197 - diff: 9.18mlTrain batch 25/32 - 243.2ms/batch - loss: 10.21627 - diff: 9.78mlTrain batch 26/32 - 242.9ms/batch - loss: 9.98900 - diff: 9.70mlTrain batch 27/32 - 242.2ms/batch - loss: 11.03331 - diff: 10.21mlTrain batch 28/32 - 244.3ms/batch - loss: 11.21530 - diff: 10.35mlTrain batch 29/32 - 242.3ms/batch - loss: 11.15383 - diff: 10.30mlTrain batch 30/32 - 244.4ms/batch - loss: 11.03617 - diff: 10.24mlTrain batch 31/32 - 242.4ms/batch - loss: 10.88952 - diff: 10.16mlTrain batch 32/32 - 79.5ms/batch - loss: 10.93990 - diff: 10.14mlTrain batch 32/32 - 11.6s 79.5ms/batch - loss: 10.93990 - diff: 10.14ml
Test 1.1s: val_loss: 267.85984 - diff: 58.75ml

Epoch 105: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 241.2ms/batch - loss: 15.23341 - diff: 13.08mlTrain batch 2/32 - 242.7ms/batch - loss: 74.17459 - diff: 25.21mlTrain batch 3/32 - 242.1ms/batch - loss: 57.97651 - diff: 22.48mlTrain batch 4/32 - 242.2ms/batch - loss: 46.05042 - diff: 19.53mlTrain batch 5/32 - 242.5ms/batch - loss: 41.33178 - diff: 18.78mlTrain batch 6/32 - 242.1ms/batch - loss: 40.86555 - diff: 19.56mlTrain batch 7/32 - 243.9ms/batch - loss: 36.19594 - diff: 18.09mlTrain batch 8/32 - 242.2ms/batch - loss: 33.30983 - diff: 17.26mlTrain batch 9/32 - 244.6ms/batch - loss: 30.40922 - diff: 16.35mlTrain batch 10/32 - 242.2ms/batch - loss: 28.06198 - diff: 15.55mlTrain batch 11/32 - 242.4ms/batch - loss: 26.21708 - diff: 15.04mlTrain batch 12/32 - 242.1ms/batch - loss: 24.59679 - diff: 14.51mlTrain batch 13/32 - 244.3ms/batch - loss: 23.56176 - diff: 14.26mlTrain batch 14/32 - 242.0ms/batch - loss: 22.54781 - diff: 14.00mlTrain batch 15/32 - 242.7ms/batch - loss: 21.86654 - diff: 13.87mlTrain batch 16/32 - 242.9ms/batch - loss: 21.64601 - diff: 13.92mlTrain batch 17/32 - 244.3ms/batch - loss: 21.06194 - diff: 13.76mlTrain batch 18/32 - 242.1ms/batch - loss: 20.19129 - diff: 13.35mlTrain batch 19/32 - 244.5ms/batch - loss: 19.26086 - diff: 12.89mlTrain batch 20/32 - 242.0ms/batch - loss: 18.91537 - diff: 12.82mlTrain batch 21/32 - 244.3ms/batch - loss: 18.18494 - diff: 12.48mlTrain batch 22/32 - 242.6ms/batch - loss: 17.74934 - diff: 12.35mlTrain batch 23/32 - 244.4ms/batch - loss: 17.21481 - diff: 12.12mlTrain batch 24/32 - 241.6ms/batch - loss: 16.83343 - diff: 11.94mlTrain batch 25/32 - 243.1ms/batch - loss: 16.32681 - diff: 11.72mlTrain batch 26/32 - 242.6ms/batch - loss: 15.85741 - diff: 11.51mlTrain batch 27/32 - 246.8ms/batch - loss: 16.78368 - diff: 11.85mlTrain batch 28/32 - 242.2ms/batch - loss: 16.79667 - diff: 11.91mlTrain batch 29/32 - 244.6ms/batch - loss: 16.46990 - diff: 11.77mlTrain batch 30/32 - 242.6ms/batch - loss: 17.32566 - diff: 12.10mlTrain batch 31/32 - 244.1ms/batch - loss: 17.02434 - diff: 12.05mlTrain batch 32/32 - 80.2ms/batch - loss: 19.23486 - diff: 12.22mlTrain batch 32/32 - 11.9s 80.2ms/batch - loss: 19.23486 - diff: 12.22ml
Test 1.1s: val_loss: 323.80702 - diff: 66.05ml

Epoch 106: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 241.7ms/batch - loss: 23.87171 - diff: 18.95mlTrain batch 2/32 - 242.7ms/batch - loss: 13.51662 - diff: 12.42mlTrain batch 3/32 - 242.0ms/batch - loss: 9.96862 - diff: 10.30mlTrain batch 4/32 - 243.5ms/batch - loss: 8.87844 - diff: 9.63mlTrain batch 5/32 - 242.1ms/batch - loss: 7.81731 - diff: 8.93mlTrain batch 6/32 - 244.2ms/batch - loss: 7.96406 - diff: 9.17mlTrain batch 7/32 - 241.8ms/batch - loss: 7.39188 - diff: 8.79mlTrain batch 8/32 - 242.4ms/batch - loss: 7.59858 - diff: 8.96mlTrain batch 9/32 - 242.2ms/batch - loss: 7.37889 - diff: 8.81mlTrain batch 10/32 - 244.3ms/batch - loss: 7.14407 - diff: 8.63mlTrain batch 11/32 - 241.9ms/batch - loss: 7.08039 - diff: 8.57mlTrain batch 12/32 - 244.3ms/batch - loss: 7.29009 - diff: 8.69mlTrain batch 13/32 - 245.6ms/batch - loss: 6.94436 - diff: 8.45mlTrain batch 14/32 - 242.4ms/batch - loss: 7.04872 - diff: 8.62mlTrain batch 15/32 - 242.3ms/batch - loss: 6.81936 - diff: 8.45mlTrain batch 16/32 - 243.5ms/batch - loss: 6.63345 - diff: 8.32mlTrain batch 17/32 - 242.5ms/batch - loss: 6.58366 - diff: 8.30mlTrain batch 18/32 - 243.0ms/batch - loss: 9.28519 - diff: 9.06mlTrain batch 19/32 - 242.3ms/batch - loss: 9.18320 - diff: 9.00mlTrain batch 20/32 - 243.9ms/batch - loss: 9.08898 - diff: 9.00mlTrain batch 21/32 - 242.8ms/batch - loss: 8.91323 - diff: 8.93mlTrain batch 22/32 - 244.4ms/batch - loss: 8.81703 - diff: 8.91mlTrain batch 23/32 - 242.4ms/batch - loss: 8.67615 - diff: 8.84mlTrain batch 24/32 - 244.5ms/batch - loss: 9.88679 - diff: 9.31mlTrain batch 25/32 - 242.4ms/batch - loss: 10.30026 - diff: 9.55mlTrain batch 26/32 - 244.5ms/batch - loss: 15.70790 - diff: 10.92mlTrain batch 27/32 - 242.6ms/batch - loss: 15.34771 - diff: 10.82mlTrain batch 28/32 - 244.2ms/batch - loss: 15.40602 - diff: 10.91mlTrain batch 29/32 - 242.1ms/batch - loss: 15.04590 - diff: 10.76mlTrain batch 30/32 - 243.9ms/batch - loss: 14.71423 - diff: 10.66mlTrain batch 31/32 - 242.7ms/batch - loss: 14.49305 - diff: 10.57mlTrain batch 32/32 - 79.8ms/batch - loss: 16.69199 - diff: 10.75mlTrain batch 32/32 - 11.6s 79.8ms/batch - loss: 16.69199 - diff: 10.75ml
Test 1.1s: val_loss: 260.50480 - diff: 58.40ml

Epoch 107: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 241.8ms/batch - loss: 3.89380 - diff: 6.60mlTrain batch 2/32 - 241.9ms/batch - loss: 7.33594 - diff: 8.51mlTrain batch 3/32 - 242.2ms/batch - loss: 11.96078 - diff: 10.83mlTrain batch 4/32 - 244.4ms/batch - loss: 15.70006 - diff: 12.57mlTrain batch 5/32 - 241.9ms/batch - loss: 15.76607 - diff: 12.42mlTrain batch 6/32 - 242.6ms/batch - loss: 13.69710 - diff: 11.27mlTrain batch 7/32 - 241.5ms/batch - loss: 12.85980 - diff: 10.82mlTrain batch 8/32 - 243.6ms/batch - loss: 12.36982 - diff: 10.48mlTrain batch 9/32 - 241.6ms/batch - loss: 12.08525 - diff: 10.43mlTrain batch 10/32 - 243.0ms/batch - loss: 12.24606 - diff: 10.71mlTrain batch 11/32 - 243.5ms/batch - loss: 11.66839 - diff: 10.43mlTrain batch 12/32 - 242.8ms/batch - loss: 11.19777 - diff: 10.23mlTrain batch 13/32 - 242.2ms/batch - loss: 10.54113 - diff: 9.87mlTrain batch 14/32 - 242.1ms/batch - loss: 9.98150 - diff: 9.54mlTrain batch 15/32 - 246.8ms/batch - loss: 20.14878 - diff: 11.93mlTrain batch 16/32 - 242.4ms/batch - loss: 19.14333 - diff: 11.57mlTrain batch 17/32 - 242.9ms/batch - loss: 18.58522 - diff: 11.46mlTrain batch 18/32 - 244.2ms/batch - loss: 17.76613 - diff: 11.16mlTrain batch 19/32 - 242.2ms/batch - loss: 17.27898 - diff: 11.08mlTrain batch 20/32 - 243.3ms/batch - loss: 16.61081 - diff: 10.88mlTrain batch 21/32 - 242.9ms/batch - loss: 15.96487 - diff: 10.63mlTrain batch 22/32 - 243.8ms/batch - loss: 15.50998 - diff: 10.46mlTrain batch 23/32 - 242.2ms/batch - loss: 15.10483 - diff: 10.32mlTrain batch 24/32 - 243.0ms/batch - loss: 14.66989 - diff: 10.20mlTrain batch 25/32 - 242.5ms/batch - loss: 14.29299 - diff: 10.11mlTrain batch 26/32 - 244.3ms/batch - loss: 13.83268 - diff: 9.91mlTrain batch 27/32 - 242.8ms/batch - loss: 14.11948 - diff: 10.12mlTrain batch 28/32 - 242.7ms/batch - loss: 14.28398 - diff: 10.29mlTrain batch 29/32 - 242.1ms/batch - loss: 14.85096 - diff: 10.63mlTrain batch 30/32 - 244.4ms/batch - loss: 14.72710 - diff: 10.66mlTrain batch 31/32 - 242.8ms/batch - loss: 14.85370 - diff: 10.81mlTrain batch 32/32 - 79.3ms/batch - loss: 15.36880 - diff: 10.85mlTrain batch 32/32 - 12.0s 79.3ms/batch - loss: 15.36880 - diff: 10.85ml
Test 1.1s: val_loss: 315.61597 - diff: 64.28ml

Epoch 108: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 241.7ms/batch - loss: 6.64469 - diff: 8.78mlTrain batch 2/32 - 242.4ms/batch - loss: 6.25189 - diff: 8.44mlTrain batch 3/32 - 241.7ms/batch - loss: 18.70419 - diff: 13.42mlTrain batch 4/32 - 242.5ms/batch - loss: 15.36450 - diff: 11.82mlTrain batch 5/32 - 241.9ms/batch - loss: 13.17242 - diff: 10.66mlTrain batch 6/32 - 243.8ms/batch - loss: 12.10422 - diff: 10.19mlTrain batch 7/32 - 241.7ms/batch - loss: 10.71622 - diff: 9.44mlTrain batch 8/32 - 242.7ms/batch - loss: 9.88281 - diff: 9.02mlTrain batch 9/32 - 242.6ms/batch - loss: 9.70082 - diff: 9.13mlTrain batch 10/32 - 243.5ms/batch - loss: 9.18719 - diff: 8.85mlTrain batch 11/32 - 242.1ms/batch - loss: 10.05548 - diff: 9.45mlTrain batch 12/32 - 243.8ms/batch - loss: 10.19718 - diff: 9.65mlTrain batch 13/32 - 242.1ms/batch - loss: 13.91978 - diff: 10.43mlTrain batch 14/32 - 243.9ms/batch - loss: 13.26053 - diff: 10.15mlTrain batch 15/32 - 244.0ms/batch - loss: 12.87110 - diff: 10.02mlTrain batch 16/32 - 243.3ms/batch - loss: 13.25814 - diff: 10.36mlTrain batch 17/32 - 242.1ms/batch - loss: 13.64759 - diff: 10.65mlTrain batch 18/32 - 244.3ms/batch - loss: 13.14529 - diff: 10.43mlTrain batch 19/32 - 242.7ms/batch - loss: 13.53629 - diff: 10.67mlTrain batch 20/32 - 244.6ms/batch - loss: 13.88599 - diff: 10.95mlTrain batch 21/32 - 244.3ms/batch - loss: 13.69024 - diff: 10.86mlTrain batch 22/32 - 242.5ms/batch - loss: 15.86543 - diff: 11.64mlTrain batch 23/32 - 242.7ms/batch - loss: 15.45048 - diff: 11.46mlTrain batch 24/32 - 244.3ms/batch - loss: 15.08079 - diff: 11.29mlTrain batch 25/32 - 242.9ms/batch - loss: 14.99858 - diff: 11.31mlTrain batch 26/32 - 243.5ms/batch - loss: 14.62915 - diff: 11.15mlTrain batch 27/32 - 241.3ms/batch - loss: 15.58648 - diff: 11.61mlTrain batch 28/32 - 244.5ms/batch - loss: 15.16338 - diff: 11.36mlTrain batch 29/32 - 242.6ms/batch - loss: 15.76628 - diff: 11.63mlTrain batch 30/32 - 243.1ms/batch - loss: 15.91799 - diff: 11.79mlTrain batch 31/32 - 242.4ms/batch - loss: 16.43086 - diff: 11.96mlTrain batch 32/32 - 78.4ms/batch - loss: 16.85243 - diff: 11.99mlTrain batch 32/32 - 12.4s 78.4ms/batch - loss: 16.85243 - diff: 11.99ml
Test 1.2s: val_loss: 294.34301 - diff: 62.02ml

Epoch 109: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 241.1ms/batch - loss: 24.73690 - diff: 17.52mlTrain batch 2/32 - 244.5ms/batch - loss: 15.52569 - diff: 13.11mlTrain batch 3/32 - 241.2ms/batch - loss: 13.39899 - diff: 11.86mlTrain batch 4/32 - 242.2ms/batch - loss: 12.01055 - diff: 11.15mlTrain batch 5/32 - 242.3ms/batch - loss: 11.34863 - diff: 10.90mlTrain batch 6/32 - 244.2ms/batch - loss: 11.38862 - diff: 10.87mlTrain batch 7/32 - 242.1ms/batch - loss: 11.36142 - diff: 10.97mlTrain batch 8/32 - 243.5ms/batch - loss: 12.93138 - diff: 11.85mlTrain batch 9/32 - 242.1ms/batch - loss: 11.96915 - diff: 11.35mlTrain batch 10/32 - 243.5ms/batch - loss: 12.19560 - diff: 11.62mlTrain batch 11/32 - 243.2ms/batch - loss: 11.50715 - diff: 11.18mlTrain batch 12/32 - 243.3ms/batch - loss: 13.23759 - diff: 11.94mlTrain batch 13/32 - 242.5ms/batch - loss: 13.46899 - diff: 11.99mlTrain batch 14/32 - 244.2ms/batch - loss: 12.94485 - diff: 11.76mlTrain batch 15/32 - 242.6ms/batch - loss: 12.39121 - diff: 11.45mlTrain batch 16/32 - 244.6ms/batch - loss: 12.88317 - diff: 11.69mlTrain batch 17/32 - 242.2ms/batch - loss: 13.40194 - diff: 11.98mlTrain batch 18/32 - 244.7ms/batch - loss: 12.90422 - diff: 11.74mlTrain batch 19/32 - 242.1ms/batch - loss: 12.85386 - diff: 11.71mlTrain batch 20/32 - 243.4ms/batch - loss: 13.04833 - diff: 11.75mlTrain batch 21/32 - 242.2ms/batch - loss: 12.64434 - diff: 11.50mlTrain batch 22/32 - 244.4ms/batch - loss: 12.32591 - diff: 11.35mlTrain batch 23/32 - 244.4ms/batch - loss: 12.18755 - diff: 11.28mlTrain batch 24/32 - 242.0ms/batch - loss: 12.03984 - diff: 11.22mlTrain batch 25/32 - 242.2ms/batch - loss: 12.21489 - diff: 11.24mlTrain batch 26/32 - 246.3ms/batch - loss: 16.34902 - diff: 12.30mlTrain batch 27/32 - 246.8ms/batch - loss: 15.93182 - diff: 12.11mlTrain batch 28/32 - 242.2ms/batch - loss: 15.58332 - diff: 11.98mlTrain batch 29/32 - 241.7ms/batch - loss: 15.19770 - diff: 11.78mlTrain batch 30/32 - 244.6ms/batch - loss: 14.89052 - diff: 11.65mlTrain batch 31/32 - 242.2ms/batch - loss: 16.81732 - diff: 12.25mlTrain batch 32/32 - 78.1ms/batch - loss: 17.37025 - diff: 12.29mlTrain batch 32/32 - 12.2s 78.1ms/batch - loss: 17.37025 - diff: 12.29ml
Test 1.1s: val_loss: 214.58746 - diff: 52.23ml

Epoch 110: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 247.4ms/batch - loss: 6.02631 - diff: 6.04mlTrain batch 2/32 - 244.8ms/batch - loss: 5.30448 - diff: 6.51mlTrain batch 3/32 - 244.3ms/batch - loss: 5.68531 - diff: 7.12mlTrain batch 4/32 - 243.1ms/batch - loss: 7.68278 - diff: 8.45mlTrain batch 5/32 - 242.1ms/batch - loss: 18.32497 - diff: 12.05mlTrain batch 6/32 - 242.5ms/batch - loss: 16.83918 - diff: 11.45mlTrain batch 7/32 - 242.6ms/batch - loss: 16.05438 - diff: 11.30mlTrain batch 8/32 - 242.7ms/batch - loss: 15.03481 - diff: 11.01mlTrain batch 9/32 - 242.2ms/batch - loss: 13.69635 - diff: 10.40mlTrain batch 10/32 - 242.7ms/batch - loss: 16.33188 - diff: 11.72mlTrain batch 11/32 - 242.6ms/batch - loss: 15.35044 - diff: 11.33mlTrain batch 12/32 - 242.8ms/batch - loss: 15.72352 - diff: 11.58mlTrain batch 13/32 - 242.5ms/batch - loss: 15.00586 - diff: 11.39mlTrain batch 14/32 - 244.5ms/batch - loss: 15.07372 - diff: 11.53mlTrain batch 15/32 - 242.3ms/batch - loss: 17.25301 - diff: 12.48mlTrain batch 16/32 - 244.2ms/batch - loss: 16.65095 - diff: 12.19mlTrain batch 17/32 - 242.5ms/batch - loss: 16.07738 - diff: 11.97mlTrain batch 18/32 - 244.0ms/batch - loss: 15.65450 - diff: 11.82mlTrain batch 19/32 - 243.0ms/batch - loss: 15.01511 - diff: 11.52mlTrain batch 20/32 - 244.2ms/batch - loss: 14.78184 - diff: 11.45mlTrain batch 21/32 - 242.9ms/batch - loss: 14.66404 - diff: 11.52mlTrain batch 22/32 - 242.6ms/batch - loss: 14.51963 - diff: 11.47mlTrain batch 23/32 - 243.2ms/batch - loss: 14.10232 - diff: 11.30mlTrain batch 24/32 - 242.2ms/batch - loss: 13.60147 - diff: 11.03mlTrain batch 25/32 - 242.3ms/batch - loss: 13.30703 - diff: 10.93mlTrain batch 26/32 - 244.6ms/batch - loss: 13.18007 - diff: 10.88mlTrain batch 27/32 - 242.9ms/batch - loss: 13.01876 - diff: 10.83mlTrain batch 28/32 - 244.0ms/batch - loss: 12.74518 - diff: 10.70mlTrain batch 29/32 - 242.3ms/batch - loss: 12.48248 - diff: 10.58mlTrain batch 30/32 - 243.8ms/batch - loss: 12.87712 - diff: 10.79mlTrain batch 31/32 - 242.7ms/batch - loss: 12.66163 - diff: 10.71mlTrain batch 32/32 - 78.8ms/batch - loss: 13.00308 - diff: 10.74mlTrain batch 32/32 - 11.3s 78.8ms/batch - loss: 13.00308 - diff: 10.74ml
Test 1.2s: val_loss: 307.04151 - diff: 63.83ml

Epoch 111: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 241.8ms/batch - loss: 21.50863 - diff: 16.53mlTrain batch 2/32 - 242.0ms/batch - loss: 19.95188 - diff: 16.03mlTrain batch 3/32 - 241.9ms/batch - loss: 15.58936 - diff: 13.62mlTrain batch 4/32 - 242.5ms/batch - loss: 12.87020 - diff: 11.95mlTrain batch 5/32 - 242.5ms/batch - loss: 11.47381 - diff: 11.16mlTrain batch 6/32 - 244.3ms/batch - loss: 12.22997 - diff: 11.39mlTrain batch 7/32 - 241.6ms/batch - loss: 12.28779 - diff: 11.34mlTrain batch 8/32 - 244.6ms/batch - loss: 12.00308 - diff: 11.07mlTrain batch 9/32 - 242.4ms/batch - loss: 14.94007 - diff: 12.44mlTrain batch 10/32 - 244.4ms/batch - loss: 13.96412 - diff: 11.98mlTrain batch 11/32 - 242.4ms/batch - loss: 13.79275 - diff: 12.05mlTrain batch 12/32 - 243.5ms/batch - loss: 13.80412 - diff: 12.15mlTrain batch 13/32 - 242.3ms/batch - loss: 13.69993 - diff: 12.09mlTrain batch 14/32 - 243.8ms/batch - loss: 13.06196 - diff: 11.75mlTrain batch 15/32 - 242.5ms/batch - loss: 13.10182 - diff: 11.86mlTrain batch 16/32 - 244.4ms/batch - loss: 12.95700 - diff: 11.79mlTrain batch 17/32 - 242.2ms/batch - loss: 13.88675 - diff: 12.16mlTrain batch 18/32 - 242.9ms/batch - loss: 13.33475 - diff: 11.83mlTrain batch 19/32 - 242.0ms/batch - loss: 13.32193 - diff: 11.85mlTrain batch 20/32 - 243.8ms/batch - loss: 12.95143 - diff: 11.62mlTrain batch 21/32 - 246.3ms/batch - loss: 12.66725 - diff: 11.48mlTrain batch 22/32 - 242.3ms/batch - loss: 12.56436 - diff: 11.45mlTrain batch 23/32 - 242.4ms/batch - loss: 13.84286 - diff: 11.98mlTrain batch 24/32 - 244.7ms/batch - loss: 13.40689 - diff: 11.72mlTrain batch 25/32 - 242.1ms/batch - loss: 13.06984 - diff: 11.54mlTrain batch 26/32 - 244.1ms/batch - loss: 12.91482 - diff: 11.48mlTrain batch 27/32 - 243.0ms/batch - loss: 12.72418 - diff: 11.42mlTrain batch 28/32 - 244.5ms/batch - loss: 12.60762 - diff: 11.37mlTrain batch 29/32 - 242.6ms/batch - loss: 16.75036 - diff: 12.21mlTrain batch 30/32 - 244.4ms/batch - loss: 16.33545 - diff: 12.04mlTrain batch 31/32 - 242.6ms/batch - loss: 16.16581 - diff: 12.01mlTrain batch 32/32 - 78.7ms/batch - loss: 17.17398 - diff: 12.10mlTrain batch 32/32 - 11.7s 78.7ms/batch - loss: 17.17398 - diff: 12.10ml
Test 1.1s: val_loss: 243.85412 - diff: 56.07ml

Epoch 112: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 242.0ms/batch - loss: 5.60122 - diff: 8.09mlTrain batch 2/32 - 244.6ms/batch - loss: 8.78451 - diff: 9.07mlTrain batch 3/32 - 241.7ms/batch - loss: 7.61725 - diff: 8.70mlTrain batch 4/32 - 244.5ms/batch - loss: 7.41728 - diff: 8.49mlTrain batch 5/32 - 241.5ms/batch - loss: 8.65721 - diff: 8.90mlTrain batch 6/32 - 244.4ms/batch - loss: 9.05098 - diff: 9.26mlTrain batch 7/32 - 241.5ms/batch - loss: 8.85449 - diff: 9.24mlTrain batch 8/32 - 242.2ms/batch - loss: 10.17297 - diff: 9.63mlTrain batch 9/32 - 241.9ms/batch - loss: 9.51376 - diff: 9.27mlTrain batch 10/32 - 243.6ms/batch - loss: 9.41551 - diff: 9.34mlTrain batch 11/32 - 242.3ms/batch - loss: 9.30805 - diff: 9.30mlTrain batch 12/32 - 244.0ms/batch - loss: 8.97160 - diff: 9.18mlTrain batch 13/32 - 242.0ms/batch - loss: 8.50340 - diff: 8.90mlTrain batch 14/32 - 244.4ms/batch - loss: 8.08461 - diff: 8.62mlTrain batch 15/32 - 242.8ms/batch - loss: 8.43125 - diff: 8.87mlTrain batch 16/32 - 244.3ms/batch - loss: 8.18429 - diff: 8.77mlTrain batch 17/32 - 242.4ms/batch - loss: 7.91202 - diff: 8.62mlTrain batch 18/32 - 244.5ms/batch - loss: 7.99865 - diff: 8.67mlTrain batch 19/32 - 242.6ms/batch - loss: 7.73560 - diff: 8.47mlTrain batch 20/32 - 244.2ms/batch - loss: 12.25749 - diff: 9.74mlTrain batch 21/32 - 242.9ms/batch - loss: 11.90882 - diff: 9.63mlTrain batch 22/32 - 244.2ms/batch - loss: 11.74867 - diff: 9.63mlTrain batch 23/32 - 242.6ms/batch - loss: 11.37182 - diff: 9.46mlTrain batch 24/32 - 242.4ms/batch - loss: 11.91959 - diff: 9.76mlTrain batch 25/32 - 244.4ms/batch - loss: 12.84690 - diff: 10.19mlTrain batch 26/32 - 242.1ms/batch - loss: 12.56356 - diff: 10.06mlTrain batch 27/32 - 244.4ms/batch - loss: 12.26716 - diff: 9.93mlTrain batch 28/32 - 241.9ms/batch - loss: 11.95129 - diff: 9.78mlTrain batch 29/32 - 244.3ms/batch - loss: 11.81309 - diff: 9.75mlTrain batch 30/32 - 241.5ms/batch - loss: 12.00752 - diff: 9.92mlTrain batch 31/32 - 244.4ms/batch - loss: 12.08152 - diff: 10.03mlTrain batch 32/32 - 79.7ms/batch - loss: 12.73787 - diff: 10.10mlTrain batch 32/32 - 11.9s 79.7ms/batch - loss: 12.73787 - diff: 10.10ml
Test 1.1s: val_loss: 276.65566 - diff: 59.98ml

Epoch 113: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 241.6ms/batch - loss: 28.92797 - diff: 20.18mlTrain batch 2/32 - 241.1ms/batch - loss: 16.56289 - diff: 13.53mlTrain batch 3/32 - 242.0ms/batch - loss: 14.42083 - diff: 12.81mlTrain batch 4/32 - 244.5ms/batch - loss: 11.92635 - diff: 11.27mlTrain batch 5/32 - 242.8ms/batch - loss: 12.16547 - diff: 11.38mlTrain batch 6/32 - 243.6ms/batch - loss: 10.82658 - diff: 10.62mlTrain batch 7/32 - 241.6ms/batch - loss: 10.27897 - diff: 10.36mlTrain batch 8/32 - 244.6ms/batch - loss: 9.36666 - diff: 9.69mlTrain batch 9/32 - 242.1ms/batch - loss: 8.98146 - diff: 9.50mlTrain batch 10/32 - 244.0ms/batch - loss: 8.99058 - diff: 9.60mlTrain batch 11/32 - 242.1ms/batch - loss: 8.63867 - diff: 9.42mlTrain batch 12/32 - 245.2ms/batch - loss: 8.20155 - diff: 9.18mlTrain batch 13/32 - 243.0ms/batch - loss: 7.97159 - diff: 8.97mlTrain batch 14/32 - 243.1ms/batch - loss: 7.62813 - diff: 8.78mlTrain batch 15/32 - 242.0ms/batch - loss: 8.52737 - diff: 9.17mlTrain batch 16/32 - 243.7ms/batch - loss: 8.60211 - diff: 9.29mlTrain batch 17/32 - 242.1ms/batch - loss: 8.33827 - diff: 9.14mlTrain batch 18/32 - 244.5ms/batch - loss: 8.15388 - diff: 9.03mlTrain batch 19/32 - 242.0ms/batch - loss: 8.50697 - diff: 9.23mlTrain batch 20/32 - 244.5ms/batch - loss: 8.26872 - diff: 9.09mlTrain batch 21/32 - 242.7ms/batch - loss: 8.65451 - diff: 9.32mlTrain batch 22/32 - 244.2ms/batch - loss: 8.78288 - diff: 9.35mlTrain batch 23/32 - 242.1ms/batch - loss: 8.79982 - diff: 9.36mlTrain batch 24/32 - 244.6ms/batch - loss: 9.01001 - diff: 9.51mlTrain batch 25/32 - 243.0ms/batch - loss: 8.85869 - diff: 9.42mlTrain batch 26/32 - 242.9ms/batch - loss: 9.28109 - diff: 9.66mlTrain batch 27/32 - 242.1ms/batch - loss: 9.68765 - diff: 9.91mlTrain batch 28/32 - 244.6ms/batch - loss: 9.49761 - diff: 9.79mlTrain batch 29/32 - 243.8ms/batch - loss: 9.81755 - diff: 9.95mlTrain batch 30/32 - 244.0ms/batch - loss: 9.93033 - diff: 10.04mlTrain batch 31/32 - 255.0ms/batch - loss: 9.83540 - diff: 10.01mlTrain batch 32/32 - 78.3ms/batch - loss: 40.30327 - diff: 10.58mlTrain batch 32/32 - 11.9s 78.3ms/batch - loss: 40.30327 - diff: 10.58ml
Test 1.2s: val_loss: 124.83665 - diff: 39.48ml

Epoch 114: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 241.6ms/batch - loss: 34.15158 - diff: 20.02mlTrain batch 2/32 - 242.1ms/batch - loss: 18.69221 - diff: 13.10mlTrain batch 3/32 - 241.8ms/batch - loss: 14.56250 - diff: 11.38mlTrain batch 4/32 - 244.2ms/batch - loss: 13.87856 - diff: 11.29mlTrain batch 5/32 - 242.5ms/batch - loss: 11.87177 - diff: 10.23mlTrain batch 6/32 - 242.9ms/batch - loss: 10.49204 - diff: 9.60mlTrain batch 7/32 - 241.7ms/batch - loss: 11.86939 - diff: 10.55mlTrain batch 8/32 - 241.6ms/batch - loss: 11.78371 - diff: 10.73mlTrain batch 9/32 - 241.9ms/batch - loss: 10.74954 - diff: 10.16mlTrain batch 10/32 - 243.0ms/batch - loss: 17.62861 - diff: 12.40mlTrain batch 11/32 - 241.8ms/batch - loss: 18.26590 - diff: 12.99mlTrain batch 12/32 - 244.1ms/batch - loss: 17.11349 - diff: 12.50mlTrain batch 13/32 - 241.8ms/batch - loss: 16.20160 - diff: 12.05mlTrain batch 14/32 - 243.3ms/batch - loss: 25.57220 - diff: 14.05mlTrain batch 15/32 - 242.1ms/batch - loss: 24.35820 - diff: 13.67mlTrain batch 16/32 - 243.3ms/batch - loss: 23.75587 - diff: 13.55mlTrain batch 17/32 - 241.7ms/batch - loss: 23.48509 - diff: 13.69mlTrain batch 18/32 - 244.0ms/batch - loss: 22.50873 - diff: 13.36mlTrain batch 19/32 - 242.6ms/batch - loss: 22.31682 - diff: 13.45mlTrain batch 20/32 - 244.3ms/batch - loss: 21.50507 - diff: 13.21mlTrain batch 21/32 - 242.9ms/batch - loss: 20.62821 - diff: 12.86mlTrain batch 22/32 - 243.2ms/batch - loss: 19.88744 - diff: 12.58mlTrain batch 23/32 - 242.6ms/batch - loss: 19.19348 - diff: 12.33mlTrain batch 24/32 - 243.9ms/batch - loss: 18.56731 - diff: 12.11mlTrain batch 25/32 - 242.8ms/batch - loss: 18.13322 - diff: 12.00mlTrain batch 26/32 - 243.6ms/batch - loss: 17.80764 - diff: 11.97mlTrain batch 27/32 - 242.5ms/batch - loss: 17.41954 - diff: 11.84mlTrain batch 28/32 - 244.2ms/batch - loss: 17.19129 - diff: 11.77mlTrain batch 29/32 - 242.8ms/batch - loss: 16.72976 - diff: 11.58mlTrain batch 30/32 - 243.6ms/batch - loss: 16.30871 - diff: 11.38mlTrain batch 31/32 - 242.1ms/batch - loss: 16.61332 - diff: 11.58mlTrain batch 32/32 - 78.4ms/batch - loss: 18.25680 - diff: 11.72mlTrain batch 32/32 - 12.6s 78.4ms/batch - loss: 18.25680 - diff: 11.72ml
Test 1.1s: val_loss: 318.04047 - diff: 64.80ml
Epoch   115: reducing learning rate of group 0 to 9.7656e-07.

Epoch 115: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 241.6ms/batch - loss: 4.37960 - diff: 6.41mlTrain batch 2/32 - 242.7ms/batch - loss: 4.85773 - diff: 7.47mlTrain batch 3/32 - 242.2ms/batch - loss: 4.69796 - diff: 7.20mlTrain batch 4/32 - 242.2ms/batch - loss: 4.24208 - diff: 6.90mlTrain batch 5/32 - 241.9ms/batch - loss: 4.93724 - diff: 7.07mlTrain batch 6/32 - 243.4ms/batch - loss: 4.84091 - diff: 6.94mlTrain batch 7/32 - 242.7ms/batch - loss: 6.40506 - diff: 7.91mlTrain batch 8/32 - 242.5ms/batch - loss: 6.13653 - diff: 7.80mlTrain batch 9/32 - 242.4ms/batch - loss: 6.43659 - diff: 8.10mlTrain batch 10/32 - 243.2ms/batch - loss: 6.34754 - diff: 8.03mlTrain batch 11/32 - 242.0ms/batch - loss: 7.09567 - diff: 8.38mlTrain batch 12/32 - 242.1ms/batch - loss: 6.77458 - diff: 8.14mlTrain batch 13/32 - 241.8ms/batch - loss: 6.87897 - diff: 8.25mlTrain batch 14/32 - 243.1ms/batch - loss: 6.78517 - diff: 8.17mlTrain batch 15/32 - 243.7ms/batch - loss: 7.68623 - diff: 8.73mlTrain batch 16/32 - 242.4ms/batch - loss: 7.71682 - diff: 8.73mlTrain batch 17/32 - 241.9ms/batch - loss: 7.65013 - diff: 8.71mlTrain batch 18/32 - 241.6ms/batch - loss: 7.48850 - diff: 8.53mlTrain batch 19/32 - 243.4ms/batch - loss: 7.38836 - diff: 8.52mlTrain batch 20/32 - 242.7ms/batch - loss: 7.33605 - diff: 8.46mlTrain batch 21/32 - 246.9ms/batch - loss: 7.15594 - diff: 8.36mlTrain batch 22/32 - 242.6ms/batch - loss: 6.94363 - diff: 8.21mlTrain batch 23/32 - 242.0ms/batch - loss: 6.75179 - diff: 8.09mlTrain batch 24/32 - 242.1ms/batch - loss: 6.68390 - diff: 8.06mlTrain batch 25/32 - 242.1ms/batch - loss: 7.51781 - diff: 8.49mlTrain batch 26/32 - 242.5ms/batch - loss: 7.45878 - diff: 8.46mlTrain batch 27/32 - 242.9ms/batch - loss: 8.32833 - diff: 8.89mlTrain batch 28/32 - 243.5ms/batch - loss: 12.35595 - diff: 9.96mlTrain batch 29/32 - 242.1ms/batch - loss: 12.68464 - diff: 10.17mlTrain batch 30/32 - 242.5ms/batch - loss: 14.18685 - diff: 10.79mlTrain batch 31/32 - 242.2ms/batch - loss: 14.96493 - diff: 11.20mlTrain batch 32/32 - 78.0ms/batch - loss: 15.08431 - diff: 11.19mlTrain batch 32/32 - 13.3s 78.0ms/batch - loss: 15.08431 - diff: 11.19ml
Test 1.1s: val_loss: 232.53323 - diff: 53.86ml

Epoch 116: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 241.9ms/batch - loss: 59.44766 - diff: 26.33mlTrain batch 2/32 - 241.9ms/batch - loss: 32.44339 - diff: 17.22mlTrain batch 3/32 - 242.1ms/batch - loss: 22.58669 - diff: 13.23mlTrain batch 4/32 - 243.1ms/batch - loss: 20.41127 - diff: 13.29mlTrain batch 5/32 - 242.1ms/batch - loss: 17.18596 - diff: 12.07mlTrain batch 6/32 - 243.5ms/batch - loss: 15.52636 - diff: 11.59mlTrain batch 7/32 - 242.8ms/batch - loss: 13.55374 - diff: 10.53mlTrain batch 8/32 - 243.1ms/batch - loss: 12.58280 - diff: 10.25mlTrain batch 9/32 - 242.0ms/batch - loss: 12.36758 - diff: 10.30mlTrain batch 10/32 - 242.6ms/batch - loss: 12.13930 - diff: 10.26mlTrain batch 11/32 - 242.0ms/batch - loss: 18.27754 - diff: 11.66mlTrain batch 12/32 - 244.3ms/batch - loss: 17.22361 - diff: 11.36mlTrain batch 13/32 - 242.6ms/batch - loss: 16.46581 - diff: 11.13mlTrain batch 14/32 - 244.4ms/batch - loss: 15.78170 - diff: 10.94mlTrain batch 15/32 - 242.6ms/batch - loss: 15.79084 - diff: 11.06mlTrain batch 16/32 - 243.0ms/batch - loss: 15.63897 - diff: 11.03mlTrain batch 17/32 - 243.2ms/batch - loss: 15.12084 - diff: 10.92mlTrain batch 18/32 - 242.0ms/batch - loss: 14.94339 - diff: 10.94mlTrain batch 19/32 - 242.6ms/batch - loss: 14.42537 - diff: 10.74mlTrain batch 20/32 - 242.3ms/batch - loss: 14.03008 - diff: 10.56mlTrain batch 21/32 - 242.6ms/batch - loss: 13.79127 - diff: 10.54mlTrain batch 22/32 - 242.1ms/batch - loss: 13.34055 - diff: 10.35mlTrain batch 23/32 - 242.3ms/batch - loss: 13.43661 - diff: 10.52mlTrain batch 24/32 - 241.9ms/batch - loss: 12.99944 - diff: 10.33mlTrain batch 25/32 - 242.2ms/batch - loss: 13.37588 - diff: 10.53mlTrain batch 26/32 - 242.2ms/batch - loss: 13.40442 - diff: 10.58mlTrain batch 27/32 - 244.2ms/batch - loss: 13.16879 - diff: 10.53mlTrain batch 28/32 - 241.7ms/batch - loss: 12.84738 - diff: 10.39mlTrain batch 29/32 - 242.1ms/batch - loss: 13.09283 - diff: 10.55mlTrain batch 30/32 - 241.5ms/batch - loss: 13.19283 - diff: 10.66mlTrain batch 31/32 - 242.5ms/batch - loss: 13.01935 - diff: 10.64mlTrain batch 32/32 - 78.2ms/batch - loss: 13.14503 - diff: 10.63mlTrain batch 32/32 - 12.1s 78.2ms/batch - loss: 13.14503 - diff: 10.63ml
Test 1.2s: val_loss: 279.61051 - diff: 60.36ml

Epoch 117: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 241.8ms/batch - loss: 5.04593 - diff: 7.08mlTrain batch 2/32 - 243.9ms/batch - loss: 4.18357 - diff: 6.46mlTrain batch 3/32 - 241.6ms/batch - loss: 5.58070 - diff: 7.36mlTrain batch 4/32 - 244.1ms/batch - loss: 6.71014 - diff: 8.25mlTrain batch 5/32 - 242.5ms/batch - loss: 6.46406 - diff: 8.18mlTrain batch 6/32 - 244.4ms/batch - loss: 6.28390 - diff: 8.12mlTrain batch 7/32 - 242.4ms/batch - loss: 5.92093 - diff: 7.87mlTrain batch 8/32 - 243.5ms/batch - loss: 5.56444 - diff: 7.60mlTrain batch 9/32 - 242.3ms/batch - loss: 5.39212 - diff: 7.50mlTrain batch 10/32 - 243.6ms/batch - loss: 6.11777 - diff: 7.93mlTrain batch 11/32 - 242.1ms/batch - loss: 6.58989 - diff: 8.28mlTrain batch 12/32 - 244.1ms/batch - loss: 8.03482 - diff: 8.88mlTrain batch 13/32 - 242.3ms/batch - loss: 7.72311 - diff: 8.68mlTrain batch 14/32 - 244.6ms/batch - loss: 7.33744 - diff: 8.39mlTrain batch 15/32 - 242.5ms/batch - loss: 7.39923 - diff: 8.47mlTrain batch 16/32 - 244.6ms/batch - loss: 13.26582 - diff: 9.87mlTrain batch 17/32 - 242.7ms/batch - loss: 13.48717 - diff: 10.09mlTrain batch 18/32 - 244.2ms/batch - loss: 14.22588 - diff: 10.53mlTrain batch 19/32 - 242.1ms/batch - loss: 13.97385 - diff: 10.53mlTrain batch 20/32 - 243.7ms/batch - loss: 13.52623 - diff: 10.39mlTrain batch 21/32 - 242.9ms/batch - loss: 13.09045 - diff: 10.21mlTrain batch 22/32 - 242.4ms/batch - loss: 14.69407 - diff: 10.89mlTrain batch 23/32 - 242.3ms/batch - loss: 14.62485 - diff: 10.95mlTrain batch 24/32 - 243.4ms/batch - loss: 14.88738 - diff: 11.20mlTrain batch 25/32 - 242.8ms/batch - loss: 15.05456 - diff: 11.37mlTrain batch 26/32 - 244.5ms/batch - loss: 14.80989 - diff: 11.32mlTrain batch 27/32 - 245.0ms/batch - loss: 14.45527 - diff: 11.16mlTrain batch 28/32 - 242.3ms/batch - loss: 14.12324 - diff: 11.01mlTrain batch 29/32 - 243.0ms/batch - loss: 13.94958 - diff: 10.95mlTrain batch 30/32 - 242.2ms/batch - loss: 14.02979 - diff: 11.07mlTrain batch 31/32 - 242.7ms/batch - loss: 13.64093 - diff: 10.87mlTrain batch 32/32 - 78.5ms/batch - loss: 13.81562 - diff: 10.87mlTrain batch 32/32 - 11.6s 78.5ms/batch - loss: 13.81562 - diff: 10.87ml
Test 1.1s: val_loss: 312.56997 - diff: 64.20ml

Epoch 118: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 241.4ms/batch - loss: 6.07980 - diff: 7.67mlTrain batch 2/32 - 241.9ms/batch - loss: 6.34473 - diff: 8.11mlTrain batch 3/32 - 242.5ms/batch - loss: 8.96064 - diff: 9.94mlTrain batch 4/32 - 243.4ms/batch - loss: 8.08878 - diff: 9.33mlTrain batch 5/32 - 242.6ms/batch - loss: 7.67935 - diff: 9.04mlTrain batch 6/32 - 242.8ms/batch - loss: 7.39205 - diff: 8.91mlTrain batch 7/32 - 242.1ms/batch - loss: 7.33124 - diff: 8.78mlTrain batch 8/32 - 244.2ms/batch - loss: 9.26221 - diff: 9.71mlTrain batch 9/32 - 242.2ms/batch - loss: 9.64704 - diff: 9.99mlTrain batch 10/32 - 242.4ms/batch - loss: 9.08171 - diff: 9.65mlTrain batch 11/32 - 242.5ms/batch - loss: 10.22311 - diff: 10.21mlTrain batch 12/32 - 243.1ms/batch - loss: 9.82862 - diff: 10.00mlTrain batch 13/32 - 242.6ms/batch - loss: 9.73939 - diff: 9.95mlTrain batch 14/32 - 242.8ms/batch - loss: 9.56783 - diff: 9.91mlTrain batch 15/32 - 243.8ms/batch - loss: 9.70639 - diff: 9.99mlTrain batch 16/32 - 242.5ms/batch - loss: 9.36209 - diff: 9.72mlTrain batch 17/32 - 244.3ms/batch - loss: 9.38446 - diff: 9.73mlTrain batch 18/32 - 242.3ms/batch - loss: 9.21277 - diff: 9.64mlTrain batch 19/32 - 244.4ms/batch - loss: 8.94411 - diff: 9.48mlTrain batch 20/32 - 242.0ms/batch - loss: 8.73227 - diff: 9.38mlTrain batch 21/32 - 242.5ms/batch - loss: 8.68058 - diff: 9.34mlTrain batch 22/32 - 244.5ms/batch - loss: 8.91821 - diff: 9.52mlTrain batch 23/32 - 245.4ms/batch - loss: 11.40272 - diff: 10.23mlTrain batch 24/32 - 244.6ms/batch - loss: 11.13534 - diff: 10.12mlTrain batch 25/32 - 242.0ms/batch - loss: 10.84501 - diff: 9.98mlTrain batch 26/32 - 243.4ms/batch - loss: 10.68229 - diff: 9.93mlTrain batch 27/32 - 242.6ms/batch - loss: 10.51793 - diff: 9.85mlTrain batch 28/32 - 243.8ms/batch - loss: 10.83883 - diff: 10.04mlTrain batch 29/32 - 242.4ms/batch - loss: 10.63899 - diff: 9.94mlTrain batch 30/32 - 244.3ms/batch - loss: 10.50375 - diff: 9.85mlTrain batch 31/32 - 242.3ms/batch - loss: 10.38195 - diff: 9.81mlTrain batch 32/32 - 78.4ms/batch - loss: 16.64947 - diff: 10.16mlTrain batch 32/32 - 11.4s 78.4ms/batch - loss: 16.64947 - diff: 10.16ml
Test 1.2s: val_loss: 222.33184 - diff: 53.31ml

Epoch 119: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 241.6ms/batch - loss: 5.02239 - diff: 7.36mlTrain batch 2/32 - 242.1ms/batch - loss: 14.35462 - diff: 12.35mlTrain batch 3/32 - 241.4ms/batch - loss: 12.62815 - diff: 11.75mlTrain batch 4/32 - 242.0ms/batch - loss: 11.15808 - diff: 10.72mlTrain batch 5/32 - 241.7ms/batch - loss: 10.56193 - diff: 10.35mlTrain batch 6/32 - 242.4ms/batch - loss: 9.80091 - diff: 9.97mlTrain batch 7/32 - 242.6ms/batch - loss: 9.27349 - diff: 9.73mlTrain batch 8/32 - 243.7ms/batch - loss: 9.71727 - diff: 10.02mlTrain batch 9/32 - 242.4ms/batch - loss: 8.99277 - diff: 9.62mlTrain batch 10/32 - 243.6ms/batch - loss: 8.78548 - diff: 9.40mlTrain batch 11/32 - 242.4ms/batch - loss: 10.38061 - diff: 9.98mlTrain batch 12/32 - 244.0ms/batch - loss: 9.92312 - diff: 9.77mlTrain batch 13/32 - 242.1ms/batch - loss: 9.67217 - diff: 9.63mlTrain batch 14/32 - 244.6ms/batch - loss: 9.31699 - diff: 9.48mlTrain batch 15/32 - 243.0ms/batch - loss: 9.18803 - diff: 9.44mlTrain batch 16/32 - 242.5ms/batch - loss: 16.31937 - diff: 11.09mlTrain batch 17/32 - 242.2ms/batch - loss: 15.68308 - diff: 10.86mlTrain batch 18/32 - 244.3ms/batch - loss: 15.13855 - diff: 10.65mlTrain batch 19/32 - 242.2ms/batch - loss: 14.71750 - diff: 10.51mlTrain batch 20/32 - 244.4ms/batch - loss: 14.31220 - diff: 10.38mlTrain batch 21/32 - 242.9ms/batch - loss: 14.14755 - diff: 10.38mlTrain batch 22/32 - 244.5ms/batch - loss: 13.71409 - diff: 10.23mlTrain batch 23/32 - 242.6ms/batch - loss: 13.70456 - diff: 10.33mlTrain batch 24/32 - 244.3ms/batch - loss: 13.26786 - diff: 10.14mlTrain batch 25/32 - 242.2ms/batch - loss: 13.22605 - diff: 10.21mlTrain batch 26/32 - 244.0ms/batch - loss: 12.86452 - diff: 10.04mlTrain batch 27/32 - 243.0ms/batch - loss: 12.82698 - diff: 10.07mlTrain batch 28/32 - 244.2ms/batch - loss: 12.73279 - diff: 10.07mlTrain batch 29/32 - 244.6ms/batch - loss: 12.47305 - diff: 9.93mlTrain batch 30/32 - 244.1ms/batch - loss: 12.43719 - diff: 9.93mlTrain batch 31/32 - 242.2ms/batch - loss: 12.48869 - diff: 10.01mlTrain batch 32/32 - 78.3ms/batch - loss: 12.55174 - diff: 10.00mlTrain batch 32/32 - 10.9s 78.3ms/batch - loss: 12.55174 - diff: 10.00ml
Test 1.2s: val_loss: 305.87108 - diff: 64.09ml

Epoch 120: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 242.1ms/batch - loss: 5.23230 - diff: 8.00mlTrain batch 2/32 - 244.8ms/batch - loss: 5.40937 - diff: 7.58mlTrain batch 3/32 - 242.1ms/batch - loss: 12.35230 - diff: 11.30mlTrain batch 4/32 - 242.6ms/batch - loss: 10.01981 - diff: 9.74mlTrain batch 5/32 - 242.0ms/batch - loss: 9.74501 - diff: 9.61mlTrain batch 6/32 - 244.3ms/batch - loss: 8.80858 - diff: 9.01mlTrain batch 7/32 - 242.5ms/batch - loss: 8.78550 - diff: 9.00mlTrain batch 8/32 - 244.2ms/batch - loss: 8.74141 - diff: 8.91mlTrain batch 9/32 - 243.1ms/batch - loss: 10.00412 - diff: 9.58mlTrain batch 10/32 - 244.1ms/batch - loss: 9.40807 - diff: 9.25mlTrain batch 11/32 - 243.1ms/batch - loss: 9.45721 - diff: 9.40mlTrain batch 12/32 - 243.0ms/batch - loss: 11.87496 - diff: 10.48mlTrain batch 13/32 - 242.4ms/batch - loss: 11.23671 - diff: 10.13mlTrain batch 14/32 - 244.3ms/batch - loss: 10.82464 - diff: 9.97mlTrain batch 15/32 - 242.2ms/batch - loss: 10.40820 - diff: 9.79mlTrain batch 16/32 - 244.5ms/batch - loss: 11.17508 - diff: 10.23mlTrain batch 17/32 - 242.8ms/batch - loss: 10.90452 - diff: 10.15mlTrain batch 18/32 - 243.8ms/batch - loss: 10.50186 - diff: 9.95mlTrain batch 19/32 - 242.2ms/batch - loss: 10.39345 - diff: 9.91mlTrain batch 20/32 - 244.5ms/batch - loss: 10.06626 - diff: 9.73mlTrain batch 21/32 - 242.6ms/batch - loss: 10.12803 - diff: 9.85mlTrain batch 22/32 - 244.7ms/batch - loss: 10.01302 - diff: 9.76mlTrain batch 23/32 - 242.4ms/batch - loss: 11.79622 - diff: 10.45mlTrain batch 24/32 - 244.3ms/batch - loss: 11.52138 - diff: 10.34mlTrain batch 25/32 - 242.6ms/batch - loss: 11.26711 - diff: 10.20mlTrain batch 26/32 - 244.8ms/batch - loss: 10.97268 - diff: 10.04mlTrain batch 27/32 - 242.9ms/batch - loss: 11.29021 - diff: 10.22mlTrain batch 28/32 - 244.3ms/batch - loss: 12.31617 - diff: 10.72mlTrain batch 29/32 - 242.7ms/batch - loss: 12.41922 - diff: 10.81mlTrain batch 30/32 - 244.4ms/batch - loss: 12.07257 - diff: 10.60mlTrain batch 31/32 - 242.6ms/batch - loss: 12.09864 - diff: 10.65mlTrain batch 32/32 - 78.8ms/batch - loss: 20.38794 - diff: 11.03mlTrain batch 32/32 - 11.0s 78.8ms/batch - loss: 20.38794 - diff: 11.03ml
Test 1.2s: val_loss: 200.93782 - diff: 50.53ml

Epoch 121: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 241.4ms/batch - loss: 5.13078 - diff: 7.61mlTrain batch 2/32 - 244.3ms/batch - loss: 4.02905 - diff: 6.56mlTrain batch 3/32 - 242.1ms/batch - loss: 4.33379 - diff: 7.02mlTrain batch 4/32 - 243.6ms/batch - loss: 4.59379 - diff: 7.17mlTrain batch 5/32 - 242.2ms/batch - loss: 15.92817 - diff: 11.28mlTrain batch 6/32 - 242.9ms/batch - loss: 13.68595 - diff: 10.29mlTrain batch 7/32 - 243.2ms/batch - loss: 12.00525 - diff: 9.48mlTrain batch 8/32 - 244.0ms/batch - loss: 11.69665 - diff: 9.50mlTrain batch 9/32 - 242.2ms/batch - loss: 11.01231 - diff: 9.27mlTrain batch 10/32 - 244.7ms/batch - loss: 10.18399 - diff: 8.86mlTrain batch 11/32 - 246.3ms/batch - loss: 15.63513 - diff: 10.54mlTrain batch 12/32 - 242.4ms/batch - loss: 15.54745 - diff: 10.64mlTrain batch 13/32 - 242.1ms/batch - loss: 14.92033 - diff: 10.54mlTrain batch 14/32 - 243.0ms/batch - loss: 14.21626 - diff: 10.31mlTrain batch 15/32 - 242.4ms/batch - loss: 14.53335 - diff: 10.54mlTrain batch 16/32 - 244.5ms/batch - loss: 13.97394 - diff: 10.35mlTrain batch 17/32 - 243.0ms/batch - loss: 13.59492 - diff: 10.31mlTrain batch 18/32 - 244.2ms/batch - loss: 13.11577 - diff: 10.12mlTrain batch 19/32 - 242.0ms/batch - loss: 12.68989 - diff: 9.98mlTrain batch 20/32 - 245.1ms/batch - loss: 12.24282 - diff: 9.76mlTrain batch 21/32 - 242.3ms/batch - loss: 12.03506 - diff: 9.75mlTrain batch 22/32 - 244.5ms/batch - loss: 12.05285 - diff: 9.83mlTrain batch 23/32 - 242.3ms/batch - loss: 12.03217 - diff: 9.86mlTrain batch 24/32 - 244.1ms/batch - loss: 11.75449 - diff: 9.75mlTrain batch 25/32 - 243.1ms/batch - loss: 12.38721 - diff: 10.09mlTrain batch 26/32 - 242.8ms/batch - loss: 12.16485 - diff: 10.04mlTrain batch 27/32 - 244.2ms/batch - loss: 11.99382 - diff: 10.03mlTrain batch 28/32 - 242.0ms/batch - loss: 12.30007 - diff: 10.17mlTrain batch 29/32 - 244.5ms/batch - loss: 12.08596 - diff: 10.07mlTrain batch 30/32 - 246.6ms/batch - loss: 12.07068 - diff: 10.08mlTrain batch 31/32 - 243.4ms/batch - loss: 11.89095 - diff: 10.02mlTrain batch 32/32 - 79.0ms/batch - loss: 12.75924 - diff: 10.09mlTrain batch 32/32 - 11.8s 79.0ms/batch - loss: 12.75924 - diff: 10.09ml
Test 1.2s: val_loss: 318.76039 - diff: 65.57ml

Epoch 122: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 241.9ms/batch - loss: 11.82482 - diff: 12.26mlTrain batch 2/32 - 242.1ms/batch - loss: 8.71558 - diff: 10.18mlTrain batch 3/32 - 242.8ms/batch - loss: 8.78264 - diff: 10.40mlTrain batch 4/32 - 242.4ms/batch - loss: 10.18625 - diff: 11.10mlTrain batch 5/32 - 242.3ms/batch - loss: 10.69472 - diff: 11.53mlTrain batch 6/32 - 242.4ms/batch - loss: 9.65928 - diff: 10.76mlTrain batch 7/32 - 242.1ms/batch - loss: 8.83742 - diff: 10.24mlTrain batch 8/32 - 242.9ms/batch - loss: 8.48809 - diff: 9.89mlTrain batch 9/32 - 242.6ms/batch - loss: 9.10651 - diff: 10.06mlTrain batch 10/32 - 243.5ms/batch - loss: 8.86889 - diff: 9.88mlTrain batch 11/32 - 244.0ms/batch - loss: 8.62821 - diff: 9.64mlTrain batch 12/32 - 242.7ms/batch - loss: 8.17329 - diff: 9.30mlTrain batch 13/32 - 242.1ms/batch - loss: 7.66459 - diff: 8.87mlTrain batch 14/32 - 244.3ms/batch - loss: 7.42449 - diff: 8.73mlTrain batch 15/32 - 242.5ms/batch - loss: 7.64775 - diff: 8.87mlTrain batch 16/32 - 244.5ms/batch - loss: 8.39635 - diff: 9.34mlTrain batch 17/32 - 242.4ms/batch - loss: 8.11804 - diff: 9.12mlTrain batch 18/32 - 244.9ms/batch - loss: 7.98698 - diff: 9.04mlTrain batch 19/32 - 242.4ms/batch - loss: 7.68263 - diff: 8.81mlTrain batch 20/32 - 243.2ms/batch - loss: 7.52779 - diff: 8.69mlTrain batch 21/32 - 241.9ms/batch - loss: 7.38497 - diff: 8.62mlTrain batch 22/32 - 243.7ms/batch - loss: 11.88374 - diff: 9.73mlTrain batch 23/32 - 242.1ms/batch - loss: 11.64724 - diff: 9.64mlTrain batch 24/32 - 242.5ms/batch - loss: 11.36623 - diff: 9.54mlTrain batch 25/32 - 246.5ms/batch - loss: 11.09319 - diff: 9.43mlTrain batch 26/32 - 242.5ms/batch - loss: 10.80020 - diff: 9.29mlTrain batch 27/32 - 243.3ms/batch - loss: 11.03330 - diff: 9.47mlTrain batch 28/32 - 251.1ms/batch - loss: 10.83735 - diff: 9.39mlTrain batch 29/32 - 242.6ms/batch - loss: 10.66699 - diff: 9.31mlTrain batch 30/32 - 244.0ms/batch - loss: 10.77019 - diff: 9.40mlTrain batch 31/32 - 242.1ms/batch - loss: 10.91964 - diff: 9.51mlTrain batch 32/32 - 78.4ms/batch - loss: 14.79594 - diff: 9.75mlTrain batch 32/32 - 12.8s 78.4ms/batch - loss: 14.79594 - diff: 9.75ml
Test 1.2s: val_loss: 329.13330 - diff: 66.52ml

Epoch 123: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 241.3ms/batch - loss: 6.21909 - diff: 8.03mlTrain batch 2/32 - 246.1ms/batch - loss: 41.01015 - diff: 20.92mlTrain batch 3/32 - 246.0ms/batch - loss: 28.38299 - diff: 15.79mlTrain batch 4/32 - 242.3ms/batch - loss: 27.52500 - diff: 16.34mlTrain batch 5/32 - 241.9ms/batch - loss: 22.86710 - diff: 14.39mlTrain batch 6/32 - 243.9ms/batch - loss: 21.05742 - diff: 13.77mlTrain batch 7/32 - 241.9ms/batch - loss: 19.07095 - diff: 13.02mlTrain batch 8/32 - 245.2ms/batch - loss: 17.18612 - diff: 12.28mlTrain batch 9/32 - 241.8ms/batch - loss: 17.69892 - diff: 12.79mlTrain batch 10/32 - 244.2ms/batch - loss: 16.10796 - diff: 11.91mlTrain batch 11/32 - 242.6ms/batch - loss: 15.15791 - diff: 11.44mlTrain batch 12/32 - 242.4ms/batch - loss: 14.53310 - diff: 11.21mlTrain batch 13/32 - 242.1ms/batch - loss: 13.78674 - diff: 10.89mlTrain batch 14/32 - 244.3ms/batch - loss: 13.20524 - diff: 10.68mlTrain batch 15/32 - 242.9ms/batch - loss: 17.02227 - diff: 11.81mlTrain batch 16/32 - 242.9ms/batch - loss: 16.26752 - diff: 11.52mlTrain batch 17/32 - 242.1ms/batch - loss: 16.04566 - diff: 11.53mlTrain batch 18/32 - 244.5ms/batch - loss: 16.06713 - diff: 11.69mlTrain batch 19/32 - 242.6ms/batch - loss: 15.43472 - diff: 11.42mlTrain batch 20/32 - 242.3ms/batch - loss: 14.76982 - diff: 11.08mlTrain batch 21/32 - 242.7ms/batch - loss: 14.59894 - diff: 10.99mlTrain batch 22/32 - 242.3ms/batch - loss: 14.25552 - diff: 10.90mlTrain batch 23/32 - 242.2ms/batch - loss: 14.26681 - diff: 11.03mlTrain batch 24/32 - 243.7ms/batch - loss: 13.82757 - diff: 10.85mlTrain batch 25/32 - 242.6ms/batch - loss: 13.64933 - diff: 10.86mlTrain batch 26/32 - 242.6ms/batch - loss: 13.30738 - diff: 10.70mlTrain batch 27/32 - 242.7ms/batch - loss: 13.08852 - diff: 10.64mlTrain batch 28/32 - 243.4ms/batch - loss: 12.91624 - diff: 10.59mlTrain batch 29/32 - 242.0ms/batch - loss: 12.61067 - diff: 10.43mlTrain batch 30/32 - 244.3ms/batch - loss: 12.56343 - diff: 10.43mlTrain batch 31/32 - 241.7ms/batch - loss: 12.42099 - diff: 10.40mlTrain batch 32/32 - 77.9ms/batch - loss: 13.44498 - diff: 10.50mlTrain batch 32/32 - 12.6s 77.9ms/batch - loss: 13.44498 - diff: 10.50ml
Test 1.2s: val_loss: 386.68009 - diff: 71.12ml

Epoch 124: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 241.6ms/batch - loss: 4.77154 - diff: 7.03mlTrain batch 2/32 - 241.9ms/batch - loss: 6.59159 - diff: 7.78mlTrain batch 3/32 - 242.0ms/batch - loss: 5.50929 - diff: 6.77mlTrain batch 4/32 - 244.5ms/batch - loss: 9.27347 - diff: 8.97mlTrain batch 5/32 - 241.7ms/batch - loss: 9.03824 - diff: 8.76mlTrain batch 6/32 - 243.1ms/batch - loss: 10.02521 - diff: 9.32mlTrain batch 7/32 - 241.7ms/batch - loss: 11.13994 - diff: 10.09mlTrain batch 8/32 - 242.2ms/batch - loss: 10.71529 - diff: 9.80mlTrain batch 9/32 - 242.3ms/batch - loss: 10.93207 - diff: 9.85mlTrain batch 10/32 - 244.2ms/batch - loss: 21.99519 - diff: 12.58mlTrain batch 11/32 - 242.6ms/batch - loss: 21.25208 - diff: 12.57mlTrain batch 12/32 - 241.8ms/batch - loss: 20.02905 - diff: 12.26mlTrain batch 13/32 - 242.4ms/batch - loss: 18.88464 - diff: 11.93mlTrain batch 14/32 - 242.4ms/batch - loss: 17.83942 - diff: 11.60mlTrain batch 15/32 - 244.6ms/batch - loss: 17.35493 - diff: 11.59mlTrain batch 16/32 - 241.6ms/batch - loss: 16.56012 - diff: 11.34mlTrain batch 17/32 - 244.2ms/batch - loss: 15.86860 - diff: 11.09mlTrain batch 18/32 - 241.9ms/batch - loss: 15.26137 - diff: 10.92mlTrain batch 19/32 - 244.3ms/batch - loss: 14.79815 - diff: 10.82mlTrain batch 20/32 - 241.9ms/batch - loss: 14.30139 - diff: 10.63mlTrain batch 21/32 - 242.1ms/batch - loss: 14.19896 - diff: 10.67mlTrain batch 22/32 - 241.7ms/batch - loss: 13.86686 - diff: 10.56mlTrain batch 23/32 - 242.1ms/batch - loss: 13.83699 - diff: 10.68mlTrain batch 24/32 - 243.3ms/batch - loss: 13.41562 - diff: 10.45mlTrain batch 25/32 - 242.1ms/batch - loss: 13.13132 - diff: 10.37mlTrain batch 26/32 - 242.7ms/batch - loss: 12.77458 - diff: 10.19mlTrain batch 27/32 - 242.7ms/batch - loss: 12.72767 - diff: 10.22mlTrain batch 28/32 - 241.6ms/batch - loss: 12.35596 - diff: 10.05mlTrain batch 29/32 - 242.5ms/batch - loss: 12.04715 - diff: 9.89mlTrain batch 30/32 - 241.6ms/batch - loss: 11.89816 - diff: 9.83mlTrain batch 31/32 - 242.6ms/batch - loss: 11.65593 - diff: 9.73mlTrain batch 32/32 - 78.5ms/batch - loss: 13.15962 - diff: 9.88mlTrain batch 32/32 - 12.3s 78.5ms/batch - loss: 13.15962 - diff: 9.88ml
Test 1.1s: val_loss: 353.67013 - diff: 68.84ml

Epoch 125: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 241.5ms/batch - loss: 4.76962 - diff: 7.48mlTrain batch 2/32 - 242.3ms/batch - loss: 7.23781 - diff: 8.45mlTrain batch 3/32 - 241.8ms/batch - loss: 5.59523 - diff: 7.31mlTrain batch 4/32 - 242.3ms/batch - loss: 4.62231 - diff: 6.62mlTrain batch 5/32 - 242.4ms/batch - loss: 6.39251 - diff: 7.75mlTrain batch 6/32 - 244.0ms/batch - loss: 11.24865 - diff: 10.03mlTrain batch 7/32 - 242.2ms/batch - loss: 10.23524 - diff: 9.56mlTrain batch 8/32 - 244.2ms/batch - loss: 9.88001 - diff: 9.40mlTrain batch 9/32 - 242.3ms/batch - loss: 9.56947 - diff: 9.24mlTrain batch 10/32 - 243.3ms/batch - loss: 9.07613 - diff: 9.04mlTrain batch 11/32 - 242.8ms/batch - loss: 10.15718 - diff: 9.73mlTrain batch 12/32 - 243.7ms/batch - loss: 9.50315 - diff: 9.33mlTrain batch 13/32 - 242.5ms/batch - loss: 9.43495 - diff: 9.37mlTrain batch 14/32 - 243.8ms/batch - loss: 9.06398 - diff: 9.23mlTrain batch 15/32 - 242.2ms/batch - loss: 8.99966 - diff: 9.21mlTrain batch 16/32 - 244.4ms/batch - loss: 8.78034 - diff: 9.09mlTrain batch 17/32 - 242.4ms/batch - loss: 8.60656 - diff: 9.04mlTrain batch 18/32 - 242.4ms/batch - loss: 8.44512 - diff: 8.94mlTrain batch 19/32 - 242.4ms/batch - loss: 8.73235 - diff: 9.03mlTrain batch 20/32 - 244.6ms/batch - loss: 8.81829 - diff: 9.15mlTrain batch 21/32 - 242.2ms/batch - loss: 8.70936 - diff: 9.16mlTrain batch 22/32 - 243.9ms/batch - loss: 8.66766 - diff: 9.17mlTrain batch 23/32 - 242.1ms/batch - loss: 8.52068 - diff: 9.12mlTrain batch 24/32 - 243.9ms/batch - loss: 18.96546 - diff: 10.93mlTrain batch 25/32 - 242.6ms/batch - loss: 19.03687 - diff: 11.18mlTrain batch 26/32 - 244.4ms/batch - loss: 18.54909 - diff: 11.03mlTrain batch 27/32 - 242.1ms/batch - loss: 18.81240 - diff: 11.30mlTrain batch 28/32 - 242.3ms/batch - loss: 18.80250 - diff: 11.43mlTrain batch 29/32 - 242.6ms/batch - loss: 18.26625 - diff: 11.24mlTrain batch 30/32 - 243.9ms/batch - loss: 17.96622 - diff: 11.19mlTrain batch 31/32 - 242.4ms/batch - loss: 17.70386 - diff: 11.17mlTrain batch 32/32 - 80.0ms/batch - loss: 18.07464 - diff: 11.18mlTrain batch 32/32 - 11.3s 80.0ms/batch - loss: 18.07464 - diff: 11.18ml
Test 1.1s: val_loss: 346.37640 - diff: 68.27ml
Epoch   126: reducing learning rate of group 0 to 4.8828e-07.

Epoch 126: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 241.9ms/batch - loss: 2.80321 - diff: 5.53mlTrain batch 2/32 - 242.7ms/batch - loss: 2.93309 - diff: 5.75mlTrain batch 3/32 - 242.4ms/batch - loss: 13.01520 - diff: 10.61mlTrain batch 4/32 - 243.8ms/batch - loss: 11.48460 - diff: 10.17mlTrain batch 5/32 - 242.0ms/batch - loss: 9.60283 - diff: 9.00mlTrain batch 6/32 - 242.5ms/batch - loss: 13.73616 - diff: 10.71mlTrain batch 7/32 - 242.2ms/batch - loss: 12.99191 - diff: 10.39mlTrain batch 8/32 - 243.6ms/batch - loss: 11.81929 - diff: 9.81mlTrain batch 9/32 - 242.1ms/batch - loss: 11.34282 - diff: 9.60mlTrain batch 10/32 - 242.3ms/batch - loss: 11.04864 - diff: 9.62mlTrain batch 11/32 - 242.4ms/batch - loss: 10.21452 - diff: 9.14mlTrain batch 12/32 - 244.8ms/batch - loss: 9.63457 - diff: 8.91mlTrain batch 13/32 - 242.7ms/batch - loss: 9.72881 - diff: 8.88mlTrain batch 14/32 - 244.2ms/batch - loss: 9.23619 - diff: 8.66mlTrain batch 15/32 - 242.4ms/batch - loss: 8.86880 - diff: 8.52mlTrain batch 16/32 - 244.5ms/batch - loss: 9.01977 - diff: 8.61mlTrain batch 17/32 - 242.8ms/batch - loss: 8.76724 - diff: 8.52mlTrain batch 18/32 - 243.9ms/batch - loss: 8.74976 - diff: 8.58mlTrain batch 19/32 - 243.1ms/batch - loss: 8.49323 - diff: 8.47mlTrain batch 20/32 - 243.8ms/batch - loss: 8.41280 - diff: 8.45mlTrain batch 21/32 - 242.2ms/batch - loss: 8.33563 - diff: 8.45mlTrain batch 22/32 - 243.8ms/batch - loss: 8.14630 - diff: 8.34mlTrain batch 23/32 - 242.3ms/batch - loss: 8.59098 - diff: 8.60mlTrain batch 24/32 - 244.4ms/batch - loss: 8.49048 - diff: 8.59mlTrain batch 25/32 - 243.2ms/batch - loss: 8.65781 - diff: 8.77mlTrain batch 26/32 - 244.6ms/batch - loss: 13.85705 - diff: 10.02mlTrain batch 27/32 - 242.3ms/batch - loss: 13.59358 - diff: 9.92mlTrain batch 28/32 - 244.2ms/batch - loss: 13.27172 - diff: 9.80mlTrain batch 29/32 - 242.3ms/batch - loss: 13.31294 - diff: 9.90mlTrain batch 30/32 - 244.5ms/batch - loss: 12.96110 - diff: 9.76mlTrain batch 31/32 - 242.9ms/batch - loss: 13.38540 - diff: 10.01mlTrain batch 32/32 - 79.9ms/batch - loss: 13.39171 - diff: 9.98mlTrain batch 32/32 - 11.0s 79.9ms/batch - loss: 13.39171 - diff: 9.98ml
Test 1.2s: val_loss: 320.94346 - diff: 65.59ml

Epoch 127: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 241.8ms/batch - loss: 5.87686 - diff: 8.06mlTrain batch 2/32 - 244.4ms/batch - loss: 13.98788 - diff: 12.71mlTrain batch 3/32 - 243.1ms/batch - loss: 10.89951 - diff: 10.62mlTrain batch 4/32 - 244.1ms/batch - loss: 11.98309 - diff: 11.47mlTrain batch 5/32 - 242.4ms/batch - loss: 10.31759 - diff: 10.32mlTrain batch 6/32 - 243.8ms/batch - loss: 9.95888 - diff: 10.16mlTrain batch 7/32 - 242.1ms/batch - loss: 9.21597 - diff: 9.70mlTrain batch 8/32 - 242.7ms/batch - loss: 9.23110 - diff: 9.79mlTrain batch 9/32 - 242.5ms/batch - loss: 9.00521 - diff: 9.65mlTrain batch 10/32 - 243.3ms/batch - loss: 8.74217 - diff: 9.39mlTrain batch 11/32 - 242.8ms/batch - loss: 8.27064 - diff: 9.06mlTrain batch 12/32 - 242.5ms/batch - loss: 8.61439 - diff: 9.15mlTrain batch 13/32 - 244.6ms/batch - loss: 8.24623 - diff: 8.96mlTrain batch 14/32 - 242.2ms/batch - loss: 7.84707 - diff: 8.71mlTrain batch 15/32 - 244.2ms/batch - loss: 7.68906 - diff: 8.55mlTrain batch 16/32 - 242.8ms/batch - loss: 7.67452 - diff: 8.56mlTrain batch 17/32 - 244.5ms/batch - loss: 8.91076 - diff: 9.22mlTrain batch 18/32 - 242.9ms/batch - loss: 8.60436 - diff: 9.06mlTrain batch 19/32 - 242.4ms/batch - loss: 8.52826 - diff: 9.06mlTrain batch 20/32 - 243.7ms/batch - loss: 8.45869 - diff: 9.09mlTrain batch 21/32 - 244.2ms/batch - loss: 9.14794 - diff: 9.47mlTrain batch 22/32 - 243.0ms/batch - loss: 9.80407 - diff: 9.81mlTrain batch 23/32 - 242.4ms/batch - loss: 9.66356 - diff: 9.75mlTrain batch 24/32 - 242.0ms/batch - loss: 9.60037 - diff: 9.72mlTrain batch 25/32 - 244.4ms/batch - loss: 9.36226 - diff: 9.56mlTrain batch 26/32 - 243.1ms/batch - loss: 12.28396 - diff: 10.44mlTrain batch 27/32 - 244.0ms/batch - loss: 12.17066 - diff: 10.44mlTrain batch 28/32 - 243.3ms/batch - loss: 12.01326 - diff: 10.37mlTrain batch 29/32 - 244.0ms/batch - loss: 11.72251 - diff: 10.21mlTrain batch 30/32 - 242.1ms/batch - loss: 11.51369 - diff: 10.13mlTrain batch 31/32 - 244.6ms/batch - loss: 15.28431 - diff: 10.98mlTrain batch 32/32 - 80.0ms/batch - loss: 15.22901 - diff: 10.94mlTrain batch 32/32 - 11.1s 80.0ms/batch - loss: 15.22901 - diff: 10.94ml
Test 1.1s: val_loss: 219.40263 - diff: 52.75ml

Epoch 128: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 241.8ms/batch - loss: 9.69681 - diff: 10.44mlTrain batch 2/32 - 244.7ms/batch - loss: 8.89242 - diff: 9.78mlTrain batch 3/32 - 242.9ms/batch - loss: 7.54346 - diff: 9.16mlTrain batch 4/32 - 243.5ms/batch - loss: 6.46014 - diff: 8.28mlTrain batch 5/32 - 242.8ms/batch - loss: 9.64939 - diff: 10.20mlTrain batch 6/32 - 244.4ms/batch - loss: 8.97387 - diff: 9.77mlTrain batch 7/32 - 242.5ms/batch - loss: 8.46424 - diff: 9.45mlTrain batch 8/32 - 244.2ms/batch - loss: 7.85902 - diff: 9.00mlTrain batch 9/32 - 246.8ms/batch - loss: 8.01034 - diff: 9.15mlTrain batch 10/32 - 244.5ms/batch - loss: 7.73709 - diff: 9.05mlTrain batch 11/32 - 242.7ms/batch - loss: 7.38081 - diff: 8.76mlTrain batch 12/32 - 244.2ms/batch - loss: 9.22971 - diff: 9.69mlTrain batch 13/32 - 242.4ms/batch - loss: 11.02396 - diff: 10.58mlTrain batch 14/32 - 243.7ms/batch - loss: 10.70439 - diff: 10.37mlTrain batch 15/32 - 242.4ms/batch - loss: 11.55974 - diff: 10.79mlTrain batch 16/32 - 244.2ms/batch - loss: 11.05918 - diff: 10.51mlTrain batch 17/32 - 242.4ms/batch - loss: 10.69828 - diff: 10.30mlTrain batch 18/32 - 244.6ms/batch - loss: 10.47674 - diff: 10.13mlTrain batch 19/32 - 242.2ms/batch - loss: 13.26131 - diff: 11.10mlTrain batch 20/32 - 244.1ms/batch - loss: 12.92237 - diff: 10.94mlTrain batch 21/32 - 242.5ms/batch - loss: 12.75782 - diff: 10.85mlTrain batch 22/32 - 244.3ms/batch - loss: 12.98240 - diff: 11.04mlTrain batch 23/32 - 242.4ms/batch - loss: 13.09549 - diff: 11.18mlTrain batch 24/32 - 244.0ms/batch - loss: 17.42652 - diff: 12.19mlTrain batch 25/32 - 242.1ms/batch - loss: 16.84688 - diff: 11.92mlTrain batch 26/32 - 244.2ms/batch - loss: 16.29631 - diff: 11.66mlTrain batch 27/32 - 242.1ms/batch - loss: 15.87489 - diff: 11.47mlTrain batch 28/32 - 244.0ms/batch - loss: 15.45372 - diff: 11.30mlTrain batch 29/32 - 243.0ms/batch - loss: 15.15410 - diff: 11.21mlTrain batch 30/32 - 244.4ms/batch - loss: 14.82128 - diff: 11.08mlTrain batch 31/32 - 242.0ms/batch - loss: 15.44240 - diff: 11.33mlTrain batch 32/32 - 79.8ms/batch - loss: 16.18667 - diff: 11.39mlTrain batch 32/32 - 11.9s 79.8ms/batch - loss: 16.18667 - diff: 11.39ml
Test 1.2s: val_loss: 299.20530 - diff: 62.90ml

Epoch 129: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 241.6ms/batch - loss: 4.85742 - diff: 7.16mlTrain batch 2/32 - 242.0ms/batch - loss: 5.27186 - diff: 7.23mlTrain batch 3/32 - 242.9ms/batch - loss: 4.77419 - diff: 6.56mlTrain batch 4/32 - 244.3ms/batch - loss: 7.10557 - diff: 8.17mlTrain batch 5/32 - 242.3ms/batch - loss: 6.30086 - diff: 7.59mlTrain batch 6/32 - 244.3ms/batch - loss: 5.93317 - diff: 7.48mlTrain batch 7/32 - 241.5ms/batch - loss: 5.56736 - diff: 7.25mlTrain batch 8/32 - 244.2ms/batch - loss: 6.62008 - diff: 8.03mlTrain batch 9/32 - 242.1ms/batch - loss: 6.50308 - diff: 7.87mlTrain batch 10/32 - 244.4ms/batch - loss: 7.67035 - diff: 8.54mlTrain batch 11/32 - 242.4ms/batch - loss: 7.17551 - diff: 8.22mlTrain batch 12/32 - 244.1ms/batch - loss: 7.59391 - diff: 8.54mlTrain batch 13/32 - 242.3ms/batch - loss: 7.68484 - diff: 8.58mlTrain batch 14/32 - 244.3ms/batch - loss: 8.10117 - diff: 8.92mlTrain batch 15/32 - 242.9ms/batch - loss: 8.02683 - diff: 8.89mlTrain batch 16/32 - 244.0ms/batch - loss: 8.99824 - diff: 9.43mlTrain batch 17/32 - 242.2ms/batch - loss: 8.88639 - diff: 9.39mlTrain batch 18/32 - 242.8ms/batch - loss: 8.50141 - diff: 9.12mlTrain batch 19/32 - 242.1ms/batch - loss: 8.49180 - diff: 9.10mlTrain batch 20/32 - 244.2ms/batch - loss: 9.82390 - diff: 9.76mlTrain batch 21/32 - 242.6ms/batch - loss: 9.58282 - diff: 9.64mlTrain batch 22/32 - 244.4ms/batch - loss: 9.28498 - diff: 9.45mlTrain batch 23/32 - 242.1ms/batch - loss: 9.35044 - diff: 9.48mlTrain batch 24/32 - 243.9ms/batch - loss: 12.03551 - diff: 10.28mlTrain batch 25/32 - 242.6ms/batch - loss: 11.77277 - diff: 10.17mlTrain batch 26/32 - 244.5ms/batch - loss: 11.75670 - diff: 10.13mlTrain batch 27/32 - 242.2ms/batch - loss: 12.79897 - diff: 10.62mlTrain batch 28/32 - 244.3ms/batch - loss: 12.47079 - diff: 10.46mlTrain batch 29/32 - 242.5ms/batch - loss: 12.39296 - diff: 10.47mlTrain batch 30/32 - 244.3ms/batch - loss: 12.09873 - diff: 10.30mlTrain batch 31/32 - 242.1ms/batch - loss: 12.14040 - diff: 10.38mlTrain batch 32/32 - 79.6ms/batch - loss: 12.16882 - diff: 10.36mlTrain batch 32/32 - 11.5s 79.6ms/batch - loss: 12.16882 - diff: 10.36ml
Test 1.1s: val_loss: 257.82834 - diff: 57.59ml

Epoch 130: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 241.3ms/batch - loss: 5.44843 - diff: 8.09mlTrain batch 2/32 - 244.2ms/batch - loss: 22.80756 - diff: 14.25mlTrain batch 3/32 - 242.6ms/batch - loss: 29.53043 - diff: 16.39mlTrain batch 4/32 - 242.4ms/batch - loss: 24.61345 - diff: 15.08mlTrain batch 5/32 - 242.3ms/batch - loss: 22.96473 - diff: 14.80mlTrain batch 6/32 - 242.7ms/batch - loss: 21.22463 - diff: 14.36mlTrain batch 7/32 - 242.2ms/batch - loss: 19.99279 - diff: 14.16mlTrain batch 8/32 - 242.1ms/batch - loss: 18.78871 - diff: 13.63mlTrain batch 9/32 - 242.2ms/batch - loss: 17.11557 - diff: 12.84mlTrain batch 10/32 - 244.1ms/batch - loss: 17.94936 - diff: 13.27mlTrain batch 11/32 - 242.0ms/batch - loss: 16.75614 - diff: 12.64mlTrain batch 12/32 - 243.5ms/batch - loss: 19.03033 - diff: 13.51mlTrain batch 13/32 - 242.2ms/batch - loss: 17.99433 - diff: 12.99mlTrain batch 14/32 - 244.4ms/batch - loss: 17.22861 - diff: 12.63mlTrain batch 15/32 - 243.0ms/batch - loss: 16.55754 - diff: 12.34mlTrain batch 16/32 - 243.7ms/batch - loss: 15.90371 - diff: 12.07mlTrain batch 17/32 - 242.4ms/batch - loss: 15.27320 - diff: 11.77mlTrain batch 18/32 - 244.6ms/batch - loss: 14.99750 - diff: 11.70mlTrain batch 19/32 - 243.0ms/batch - loss: 14.73123 - diff: 11.64mlTrain batch 20/32 - 243.1ms/batch - loss: 14.55189 - diff: 11.58mlTrain batch 21/32 - 242.0ms/batch - loss: 14.13759 - diff: 11.40mlTrain batch 22/32 - 245.2ms/batch - loss: 13.60052 - diff: 11.10mlTrain batch 23/32 - 242.2ms/batch - loss: 17.33499 - diff: 12.19mlTrain batch 24/32 - 244.1ms/batch - loss: 16.84872 - diff: 12.02mlTrain batch 25/32 - 242.5ms/batch - loss: 16.45864 - diff: 11.85mlTrain batch 26/32 - 244.5ms/batch - loss: 16.03198 - diff: 11.62mlTrain batch 27/32 - 242.6ms/batch - loss: 15.64556 - diff: 11.45mlTrain batch 28/32 - 244.1ms/batch - loss: 15.25657 - diff: 11.30mlTrain batch 29/32 - 242.6ms/batch - loss: 15.03505 - diff: 11.22mlTrain batch 30/32 - 244.0ms/batch - loss: 14.63172 - diff: 11.04mlTrain batch 31/32 - 242.8ms/batch - loss: 14.27761 - diff: 10.87mlTrain batch 32/32 - 79.2ms/batch - loss: 14.35557 - diff: 10.85mlTrain batch 32/32 - 11.9s 79.2ms/batch - loss: 14.35557 - diff: 10.85ml
Test 1.2s: val_loss: 303.44707 - diff: 63.77ml

Epoch 131: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 242.4ms/batch - loss: 4.64409 - diff: 6.72mlTrain batch 2/32 - 244.3ms/batch - loss: 3.98558 - diff: 6.03mlTrain batch 3/32 - 241.6ms/batch - loss: 4.15183 - diff: 6.25mlTrain batch 4/32 - 244.0ms/batch - loss: 9.16297 - diff: 9.24mlTrain batch 5/32 - 242.0ms/batch - loss: 7.87230 - diff: 8.44mlTrain batch 6/32 - 242.4ms/batch - loss: 7.27487 - diff: 8.16mlTrain batch 7/32 - 246.6ms/batch - loss: 7.40534 - diff: 8.39mlTrain batch 8/32 - 242.3ms/batch - loss: 8.20742 - diff: 8.86mlTrain batch 9/32 - 241.9ms/batch - loss: 8.85802 - diff: 9.30mlTrain batch 10/32 - 244.3ms/batch - loss: 8.70353 - diff: 9.27mlTrain batch 11/32 - 242.0ms/batch - loss: 13.64303 - diff: 11.01mlTrain batch 12/32 - 244.5ms/batch - loss: 12.71050 - diff: 10.55mlTrain batch 13/32 - 242.8ms/batch - loss: 11.96766 - diff: 10.17mlTrain batch 14/32 - 244.3ms/batch - loss: 11.86130 - diff: 10.25mlTrain batch 15/32 - 242.2ms/batch - loss: 11.45041 - diff: 10.12mlTrain batch 16/32 - 243.6ms/batch - loss: 11.61043 - diff: 10.27mlTrain batch 17/32 - 242.6ms/batch - loss: 11.24893 - diff: 10.15mlTrain batch 18/32 - 244.0ms/batch - loss: 10.97923 - diff: 10.06mlTrain batch 19/32 - 242.3ms/batch - loss: 10.55196 - diff: 9.85mlTrain batch 20/32 - 243.9ms/batch - loss: 10.26386 - diff: 9.70mlTrain batch 21/32 - 242.3ms/batch - loss: 10.10334 - diff: 9.66mlTrain batch 22/32 - 242.9ms/batch - loss: 9.78620 - diff: 9.45mlTrain batch 23/32 - 242.3ms/batch - loss: 9.44763 - diff: 9.24mlTrain batch 24/32 - 242.4ms/batch - loss: 9.36359 - diff: 9.25mlTrain batch 25/32 - 244.6ms/batch - loss: 9.56103 - diff: 9.41mlTrain batch 26/32 - 244.3ms/batch - loss: 9.29214 - diff: 9.26mlTrain batch 27/32 - 243.1ms/batch - loss: 9.51248 - diff: 9.42mlTrain batch 28/32 - 242.2ms/batch - loss: 9.37932 - diff: 9.37mlTrain batch 29/32 - 244.0ms/batch - loss: 10.06826 - diff: 9.59mlTrain batch 30/32 - 242.8ms/batch - loss: 9.90077 - diff: 9.52mlTrain batch 31/32 - 244.5ms/batch - loss: 9.74235 - diff: 9.45mlTrain batch 32/32 - 79.7ms/batch - loss: 9.67428 - diff: 9.38mlTrain batch 32/32 - 11.5s 79.7ms/batch - loss: 9.67428 - diff: 9.38ml
Test 1.1s: val_loss: 266.17906 - diff: 59.55ml

Epoch 132: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 242.0ms/batch - loss: 3.85043 - diff: 6.56mlTrain batch 2/32 - 242.2ms/batch - loss: 10.43646 - diff: 10.76mlTrain batch 3/32 - 241.6ms/batch - loss: 11.44650 - diff: 11.29mlTrain batch 4/32 - 244.1ms/batch - loss: 9.80253 - diff: 10.18mlTrain batch 5/32 - 242.0ms/batch - loss: 9.76509 - diff: 10.11mlTrain batch 6/32 - 244.4ms/batch - loss: 9.61305 - diff: 10.10mlTrain batch 7/32 - 242.7ms/batch - loss: 8.68038 - diff: 9.49mlTrain batch 8/32 - 244.6ms/batch - loss: 8.00463 - diff: 9.04mlTrain batch 9/32 - 242.2ms/batch - loss: 8.06445 - diff: 9.20mlTrain batch 10/32 - 243.6ms/batch - loss: 7.81243 - diff: 9.05mlTrain batch 11/32 - 242.0ms/batch - loss: 8.38325 - diff: 9.41mlTrain batch 12/32 - 244.4ms/batch - loss: 8.06500 - diff: 9.21mlTrain batch 13/32 - 242.2ms/batch - loss: 7.93177 - diff: 9.16mlTrain batch 14/32 - 244.4ms/batch - loss: 8.11820 - diff: 9.27mlTrain batch 15/32 - 242.2ms/batch - loss: 7.74378 - diff: 8.98mlTrain batch 16/32 - 244.1ms/batch - loss: 8.60631 - diff: 9.49mlTrain batch 17/32 - 242.6ms/batch - loss: 8.27149 - diff: 9.28mlTrain batch 18/32 - 244.1ms/batch - loss: 8.55058 - diff: 9.37mlTrain batch 19/32 - 242.1ms/batch - loss: 8.40775 - diff: 9.29mlTrain batch 20/32 - 244.6ms/batch - loss: 8.62420 - diff: 9.48mlTrain batch 21/32 - 242.6ms/batch - loss: 8.58055 - diff: 9.43mlTrain batch 22/32 - 244.4ms/batch - loss: 9.05222 - diff: 9.73mlTrain batch 23/32 - 242.1ms/batch - loss: 8.96965 - diff: 9.69mlTrain batch 24/32 - 244.3ms/batch - loss: 8.72082 - diff: 9.50mlTrain batch 25/32 - 243.1ms/batch - loss: 8.58800 - diff: 9.44mlTrain batch 26/32 - 243.9ms/batch - loss: 8.52890 - diff: 9.41mlTrain batch 27/32 - 242.4ms/batch - loss: 8.69818 - diff: 9.47mlTrain batch 28/32 - 244.3ms/batch - loss: 14.12645 - diff: 10.76mlTrain batch 29/32 - 242.5ms/batch - loss: 13.72292 - diff: 10.55mlTrain batch 30/32 - 244.3ms/batch - loss: 13.91110 - diff: 10.74mlTrain batch 31/32 - 242.2ms/batch - loss: 13.53171 - diff: 10.56mlTrain batch 32/32 - 79.0ms/batch - loss: 14.62532 - diff: 10.66mlTrain batch 32/32 - 11.5s 79.0ms/batch - loss: 14.62532 - diff: 10.66ml
Test 1.1s: val_loss: 281.05558 - diff: 61.15ml

Epoch 133: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 241.5ms/batch - loss: 14.21627 - diff: 12.43mlTrain batch 2/32 - 244.4ms/batch - loss: 15.85934 - diff: 13.66mlTrain batch 3/32 - 242.4ms/batch - loss: 12.65151 - diff: 11.93mlTrain batch 4/32 - 241.9ms/batch - loss: 10.51693 - diff: 10.69mlTrain batch 5/32 - 241.6ms/batch - loss: 10.75684 - diff: 10.94mlTrain batch 6/32 - 241.7ms/batch - loss: 9.72168 - diff: 10.24mlTrain batch 7/32 - 245.3ms/batch - loss: 8.81084 - diff: 9.57mlTrain batch 8/32 - 244.6ms/batch - loss: 8.90337 - diff: 9.49mlTrain batch 9/32 - 242.3ms/batch - loss: 8.28707 - diff: 9.14mlTrain batch 10/32 - 242.5ms/batch - loss: 7.91691 - diff: 8.89mlTrain batch 11/32 - 244.1ms/batch - loss: 8.11918 - diff: 8.92mlTrain batch 12/32 - 242.8ms/batch - loss: 15.26052 - diff: 10.96mlTrain batch 13/32 - 242.9ms/batch - loss: 15.82419 - diff: 11.41mlTrain batch 14/32 - 242.4ms/batch - loss: 15.25647 - diff: 11.24mlTrain batch 15/32 - 244.4ms/batch - loss: 14.91090 - diff: 11.19mlTrain batch 16/32 - 242.7ms/batch - loss: 14.23258 - diff: 10.89mlTrain batch 17/32 - 244.8ms/batch - loss: 13.91501 - diff: 10.72mlTrain batch 18/32 - 242.8ms/batch - loss: 13.32866 - diff: 10.47mlTrain batch 19/32 - 244.5ms/batch - loss: 12.73929 - diff: 10.17mlTrain batch 20/32 - 244.6ms/batch - loss: 12.47719 - diff: 10.12mlTrain batch 21/32 - 244.5ms/batch - loss: 12.33655 - diff: 10.12mlTrain batch 22/32 - 242.4ms/batch - loss: 11.91438 - diff: 9.91mlTrain batch 23/32 - 244.6ms/batch - loss: 11.58675 - diff: 9.78mlTrain batch 24/32 - 241.9ms/batch - loss: 12.61320 - diff: 10.24mlTrain batch 25/32 - 244.4ms/batch - loss: 12.37379 - diff: 10.14mlTrain batch 26/32 - 243.0ms/batch - loss: 12.09867 - diff: 10.04mlTrain batch 27/32 - 244.5ms/batch - loss: 11.76572 - diff: 9.88mlTrain batch 28/32 - 242.7ms/batch - loss: 11.48734 - diff: 9.75mlTrain batch 29/32 - 244.2ms/batch - loss: 11.30111 - diff: 9.70mlTrain batch 30/32 - 242.1ms/batch - loss: 11.15479 - diff: 9.64mlTrain batch 31/32 - 244.3ms/batch - loss: 10.97440 - diff: 9.56mlTrain batch 32/32 - 79.5ms/batch - loss: 19.34749 - diff: 9.91mlTrain batch 32/32 - 11.5s 79.5ms/batch - loss: 19.34749 - diff: 9.91ml
Test 1.2s: val_loss: 199.09950 - diff: 50.21ml

Epoch 134: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 241.5ms/batch - loss: 5.31954 - diff: 6.74mlTrain batch 2/32 - 244.4ms/batch - loss: 6.51120 - diff: 8.08mlTrain batch 3/32 - 241.4ms/batch - loss: 5.32107 - diff: 7.10mlTrain batch 4/32 - 244.5ms/batch - loss: 4.72024 - diff: 6.76mlTrain batch 5/32 - 244.6ms/batch - loss: 4.45230 - diff: 6.59mlTrain batch 6/32 - 244.7ms/batch - loss: 4.51297 - diff: 6.73mlTrain batch 7/32 - 242.3ms/batch - loss: 6.16227 - diff: 7.83mlTrain batch 8/32 - 244.1ms/batch - loss: 8.21551 - diff: 8.84mlTrain batch 9/32 - 242.3ms/batch - loss: 9.61998 - diff: 9.75mlTrain batch 10/32 - 244.5ms/batch - loss: 9.18106 - diff: 9.49mlTrain batch 11/32 - 242.5ms/batch - loss: 8.60435 - diff: 9.11mlTrain batch 12/32 - 244.7ms/batch - loss: 8.45174 - diff: 8.99mlTrain batch 13/32 - 242.6ms/batch - loss: 8.39159 - diff: 8.99mlTrain batch 14/32 - 242.6ms/batch - loss: 9.38651 - diff: 9.54mlTrain batch 15/32 - 243.2ms/batch - loss: 9.33474 - diff: 9.56mlTrain batch 16/32 - 242.5ms/batch - loss: 9.09488 - diff: 9.46mlTrain batch 17/32 - 242.6ms/batch - loss: 8.97434 - diff: 9.40mlTrain batch 18/32 - 244.3ms/batch - loss: 8.68241 - diff: 9.23mlTrain batch 19/32 - 243.0ms/batch - loss: 8.50813 - diff: 9.07mlTrain batch 20/32 - 242.5ms/batch - loss: 8.35209 - diff: 8.96mlTrain batch 21/32 - 242.9ms/batch - loss: 8.16231 - diff: 8.84mlTrain batch 22/32 - 243.2ms/batch - loss: 8.28006 - diff: 8.90mlTrain batch 23/32 - 242.8ms/batch - loss: 8.12251 - diff: 8.84mlTrain batch 24/32 - 242.2ms/batch - loss: 7.92918 - diff: 8.71mlTrain batch 25/32 - 244.3ms/batch - loss: 8.14541 - diff: 8.86mlTrain batch 26/32 - 242.5ms/batch - loss: 8.53512 - diff: 9.12mlTrain batch 27/32 - 243.6ms/batch - loss: 8.55863 - diff: 9.18mlTrain batch 28/32 - 242.6ms/batch - loss: 8.60923 - diff: 9.21mlTrain batch 29/32 - 244.6ms/batch - loss: 8.54436 - diff: 9.16mlTrain batch 30/32 - 242.6ms/batch - loss: 9.27144 - diff: 9.49mlTrain batch 31/32 - 244.1ms/batch - loss: 9.06323 - diff: 9.36mlTrain batch 32/32 - 79.9ms/batch - loss: 9.77479 - diff: 9.44mlTrain batch 32/32 - 11.7s 79.9ms/batch - loss: 9.77479 - diff: 9.44ml
Test 1.2s: val_loss: 281.01707 - diff: 61.24ml

Epoch 135: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 242.0ms/batch - loss: 2.64901 - diff: 5.27mlTrain batch 2/32 - 244.3ms/batch - loss: 7.64932 - diff: 9.02mlTrain batch 3/32 - 242.4ms/batch - loss: 6.78695 - diff: 8.45mlTrain batch 4/32 - 242.3ms/batch - loss: 6.45475 - diff: 8.25mlTrain batch 5/32 - 244.6ms/batch - loss: 18.39720 - diff: 11.80mlTrain batch 6/32 - 243.4ms/batch - loss: 16.58589 - diff: 11.11mlTrain batch 7/32 - 244.6ms/batch - loss: 15.96514 - diff: 11.16mlTrain batch 8/32 - 242.3ms/batch - loss: 14.62749 - diff: 10.66mlTrain batch 9/32 - 244.2ms/batch - loss: 14.58440 - diff: 10.88mlTrain batch 10/32 - 242.3ms/batch - loss: 14.41708 - diff: 11.03mlTrain batch 11/32 - 243.3ms/batch - loss: 14.33803 - diff: 11.21mlTrain batch 12/32 - 242.4ms/batch - loss: 13.81037 - diff: 11.09mlTrain batch 13/32 - 243.9ms/batch - loss: 13.20386 - diff: 10.85mlTrain batch 14/32 - 242.9ms/batch - loss: 12.56622 - diff: 10.55mlTrain batch 15/32 - 244.3ms/batch - loss: 12.47972 - diff: 10.52mlTrain batch 16/32 - 242.5ms/batch - loss: 12.66323 - diff: 10.70mlTrain batch 17/32 - 244.5ms/batch - loss: 12.25713 - diff: 10.52mlTrain batch 18/32 - 242.5ms/batch - loss: 11.84951 - diff: 10.35mlTrain batch 19/32 - 244.4ms/batch - loss: 11.56046 - diff: 10.20mlTrain batch 20/32 - 242.5ms/batch - loss: 11.12896 - diff: 9.95mlTrain batch 21/32 - 244.4ms/batch - loss: 10.86763 - diff: 9.84mlTrain batch 22/32 - 242.9ms/batch - loss: 13.46112 - diff: 10.72mlTrain batch 23/32 - 244.5ms/batch - loss: 14.06010 - diff: 11.07mlTrain batch 24/32 - 242.3ms/batch - loss: 13.66838 - diff: 10.91mlTrain batch 25/32 - 244.5ms/batch - loss: 13.43725 - diff: 10.85mlTrain batch 26/32 - 243.1ms/batch - loss: 13.18361 - diff: 10.75mlTrain batch 27/32 - 244.2ms/batch - loss: 12.87681 - diff: 10.62mlTrain batch 28/32 - 242.4ms/batch - loss: 12.52079 - diff: 10.42mlTrain batch 29/32 - 243.9ms/batch - loss: 12.50905 - diff: 10.48mlTrain batch 30/32 - 242.4ms/batch - loss: 12.21130 - diff: 10.33mlTrain batch 31/32 - 244.2ms/batch - loss: 12.26597 - diff: 10.42mlTrain batch 32/32 - 79.3ms/batch - loss: 14.99888 - diff: 10.60mlTrain batch 32/32 - 11.6s 79.3ms/batch - loss: 14.99888 - diff: 10.60ml
Test 1.2s: val_loss: 353.98348 - diff: 67.87ml

Epoch 136: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 242.5ms/batch - loss: 15.33258 - diff: 13.43mlTrain batch 2/32 - 243.7ms/batch - loss: 11.73584 - diff: 11.44mlTrain batch 3/32 - 242.4ms/batch - loss: 10.18261 - diff: 10.41mlTrain batch 4/32 - 244.6ms/batch - loss: 9.27269 - diff: 9.84mlTrain batch 5/32 - 242.5ms/batch - loss: 12.43258 - diff: 11.34mlTrain batch 6/32 - 242.9ms/batch - loss: 11.94952 - diff: 11.28mlTrain batch 7/32 - 242.9ms/batch - loss: 11.76414 - diff: 11.13mlTrain batch 8/32 - 244.5ms/batch - loss: 10.99161 - diff: 10.71mlTrain batch 9/32 - 242.4ms/batch - loss: 10.54739 - diff: 10.47mlTrain batch 10/32 - 244.7ms/batch - loss: 10.07190 - diff: 10.19mlTrain batch 11/32 - 242.6ms/batch - loss: 9.83517 - diff: 10.01mlTrain batch 12/32 - 243.6ms/batch - loss: 10.46514 - diff: 10.32mlTrain batch 13/32 - 242.5ms/batch - loss: 10.26707 - diff: 10.21mlTrain batch 14/32 - 244.5ms/batch - loss: 10.08893 - diff: 10.08mlTrain batch 15/32 - 242.2ms/batch - loss: 9.83422 - diff: 9.97mlTrain batch 16/32 - 243.6ms/batch - loss: 9.58950 - diff: 9.82mlTrain batch 17/32 - 242.6ms/batch - loss: 10.19594 - diff: 10.20mlTrain batch 18/32 - 244.0ms/batch - loss: 10.02819 - diff: 10.15mlTrain batch 19/32 - 242.8ms/batch - loss: 9.65060 - diff: 9.90mlTrain batch 20/32 - 243.6ms/batch - loss: 9.41363 - diff: 9.74mlTrain batch 21/32 - 242.3ms/batch - loss: 9.11428 - diff: 9.55mlTrain batch 22/32 - 243.8ms/batch - loss: 9.28809 - diff: 9.67mlTrain batch 23/32 - 242.8ms/batch - loss: 9.15386 - diff: 9.59mlTrain batch 24/32 - 244.3ms/batch - loss: 9.57767 - diff: 9.84mlTrain batch 25/32 - 242.8ms/batch - loss: 9.27430 - diff: 9.63mlTrain batch 26/32 - 244.1ms/batch - loss: 9.26811 - diff: 9.60mlTrain batch 27/32 - 242.2ms/batch - loss: 9.48488 - diff: 9.76mlTrain batch 28/32 - 244.5ms/batch - loss: 9.68170 - diff: 9.86mlTrain batch 29/32 - 242.3ms/batch - loss: 14.93182 - diff: 11.09mlTrain batch 30/32 - 244.3ms/batch - loss: 14.61504 - diff: 10.90mlTrain batch 31/32 - 242.5ms/batch - loss: 14.34273 - diff: 10.78mlTrain batch 32/32 - 79.7ms/batch - loss: 14.32019 - diff: 10.74mlTrain batch 32/32 - 11.9s 79.7ms/batch - loss: 14.32019 - diff: 10.74ml
Test 1.2s: val_loss: 261.91477 - diff: 59.00ml
Epoch   137: reducing learning rate of group 0 to 2.4414e-07.

Epoch 137: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 241.4ms/batch - loss: 17.49227 - diff: 15.11mlTrain batch 2/32 - 243.1ms/batch - loss: 13.59022 - diff: 12.83mlTrain batch 3/32 - 242.2ms/batch - loss: 14.34760 - diff: 13.15mlTrain batch 4/32 - 244.1ms/batch - loss: 16.75381 - diff: 14.22mlTrain batch 5/32 - 242.0ms/batch - loss: 15.68900 - diff: 13.79mlTrain batch 6/32 - 244.1ms/batch - loss: 14.85236 - diff: 13.46mlTrain batch 7/32 - 242.8ms/batch - loss: 13.25824 - diff: 12.49mlTrain batch 8/32 - 244.4ms/batch - loss: 12.94908 - diff: 12.27mlTrain batch 9/32 - 242.5ms/batch - loss: 12.87017 - diff: 12.22mlTrain batch 10/32 - 244.5ms/batch - loss: 12.00357 - diff: 11.65mlTrain batch 11/32 - 243.0ms/batch - loss: 11.86283 - diff: 11.55mlTrain batch 12/32 - 244.4ms/batch - loss: 11.23977 - diff: 11.15mlTrain batch 13/32 - 243.2ms/batch - loss: 10.81202 - diff: 10.82mlTrain batch 14/32 - 244.2ms/batch - loss: 11.13736 - diff: 11.06mlTrain batch 15/32 - 242.1ms/batch - loss: 10.61449 - diff: 10.67mlTrain batch 16/32 - 244.3ms/batch - loss: 10.18616 - diff: 10.37mlTrain batch 17/32 - 243.7ms/batch - loss: 15.62732 - diff: 11.71mlTrain batch 18/32 - 242.3ms/batch - loss: 15.94608 - diff: 11.81mlTrain batch 19/32 - 242.3ms/batch - loss: 15.24420 - diff: 11.47mlTrain batch 20/32 - 244.1ms/batch - loss: 14.77822 - diff: 11.32mlTrain batch 21/32 - 242.2ms/batch - loss: 14.52298 - diff: 11.24mlTrain batch 22/32 - 244.3ms/batch - loss: 15.15566 - diff: 11.62mlTrain batch 23/32 - 242.4ms/batch - loss: 14.59641 - diff: 11.30mlTrain batch 24/32 - 244.8ms/batch - loss: 14.73446 - diff: 11.41mlTrain batch 25/32 - 242.5ms/batch - loss: 14.40955 - diff: 11.31mlTrain batch 26/32 - 244.4ms/batch - loss: 14.27405 - diff: 11.33mlTrain batch 27/32 - 246.4ms/batch - loss: 13.90534 - diff: 11.17mlTrain batch 28/32 - 242.0ms/batch - loss: 14.09637 - diff: 11.36mlTrain batch 29/32 - 241.5ms/batch - loss: 13.70765 - diff: 11.13mlTrain batch 30/32 - 242.9ms/batch - loss: 13.32121 - diff: 10.92mlTrain batch 31/32 - 242.8ms/batch - loss: 13.29724 - diff: 10.93mlTrain batch 32/32 - 79.3ms/batch - loss: 13.38239 - diff: 10.91mlTrain batch 32/32 - 12.2s 79.3ms/batch - loss: 13.38239 - diff: 10.91ml
Test 1.1s: val_loss: 318.46866 - diff: 64.85ml

Epoch 138: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 241.5ms/batch - loss: 3.24866 - diff: 5.65mlTrain batch 2/32 - 241.9ms/batch - loss: 6.14524 - diff: 7.51mlTrain batch 3/32 - 242.1ms/batch - loss: 4.84412 - diff: 6.69mlTrain batch 4/32 - 244.4ms/batch - loss: 5.04630 - diff: 7.03mlTrain batch 5/32 - 242.4ms/batch - loss: 10.37399 - diff: 9.38mlTrain batch 6/32 - 243.7ms/batch - loss: 13.36802 - diff: 11.04mlTrain batch 7/32 - 242.1ms/batch - loss: 16.27627 - diff: 12.49mlTrain batch 8/32 - 244.4ms/batch - loss: 14.71022 - diff: 11.78mlTrain batch 9/32 - 242.2ms/batch - loss: 14.78931 - diff: 11.94mlTrain batch 10/32 - 243.6ms/batch - loss: 14.94589 - diff: 11.98mlTrain batch 11/32 - 242.2ms/batch - loss: 14.31566 - diff: 11.66mlTrain batch 12/32 - 244.1ms/batch - loss: 13.27948 - diff: 11.08mlTrain batch 13/32 - 243.8ms/batch - loss: 12.63710 - diff: 10.84mlTrain batch 14/32 - 244.4ms/batch - loss: 12.20785 - diff: 10.70mlTrain batch 15/32 - 242.7ms/batch - loss: 11.55692 - diff: 10.32mlTrain batch 16/32 - 244.1ms/batch - loss: 17.89017 - diff: 11.80mlTrain batch 17/32 - 242.0ms/batch - loss: 17.65595 - diff: 11.87mlTrain batch 18/32 - 244.2ms/batch - loss: 16.99051 - diff: 11.65mlTrain batch 19/32 - 242.1ms/batch - loss: 16.58956 - diff: 11.54mlTrain batch 20/32 - 244.1ms/batch - loss: 16.16315 - diff: 11.37mlTrain batch 21/32 - 242.7ms/batch - loss: 16.16029 - diff: 11.50mlTrain batch 22/32 - 244.3ms/batch - loss: 15.80848 - diff: 11.44mlTrain batch 23/32 - 242.6ms/batch - loss: 15.22452 - diff: 11.16mlTrain batch 24/32 - 243.9ms/batch - loss: 14.94180 - diff: 11.09mlTrain batch 25/32 - 242.1ms/batch - loss: 14.62337 - diff: 11.01mlTrain batch 26/32 - 244.1ms/batch - loss: 14.85425 - diff: 11.18mlTrain batch 27/32 - 243.1ms/batch - loss: 14.50760 - diff: 11.04mlTrain batch 28/32 - 244.0ms/batch - loss: 14.10769 - diff: 10.88mlTrain batch 29/32 - 242.5ms/batch - loss: 13.86618 - diff: 10.81mlTrain batch 30/32 - 244.2ms/batch - loss: 13.48333 - diff: 10.60mlTrain batch 31/32 - 242.7ms/batch - loss: 13.28428 - diff: 10.54mlTrain batch 32/32 - 79.3ms/batch - loss: 14.03666 - diff: 10.60mlTrain batch 32/32 - 12.2s 79.3ms/batch - loss: 14.03666 - diff: 10.60ml
Test 1.2s: val_loss: 279.32480 - diff: 60.37ml

Epoch 139: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 241.6ms/batch - loss: 4.24911 - diff: 7.27mlTrain batch 2/32 - 242.0ms/batch - loss: 8.17836 - diff: 9.78mlTrain batch 3/32 - 242.5ms/batch - loss: 20.49523 - diff: 13.47mlTrain batch 4/32 - 243.5ms/batch - loss: 16.47023 - diff: 11.74mlTrain batch 5/32 - 242.4ms/batch - loss: 14.10677 - diff: 10.79mlTrain batch 6/32 - 243.8ms/batch - loss: 16.79339 - diff: 12.36mlTrain batch 7/32 - 242.5ms/batch - loss: 15.16502 - diff: 11.61mlTrain batch 8/32 - 242.9ms/batch - loss: 13.65482 - diff: 10.82mlTrain batch 9/32 - 242.2ms/batch - loss: 12.85146 - diff: 10.53mlTrain batch 10/32 - 243.5ms/batch - loss: 13.04771 - diff: 10.70mlTrain batch 11/32 - 242.0ms/batch - loss: 13.43285 - diff: 11.03mlTrain batch 12/32 - 242.5ms/batch - loss: 13.33617 - diff: 11.16mlTrain batch 13/32 - 242.8ms/batch - loss: 17.56486 - diff: 12.48mlTrain batch 14/32 - 242.4ms/batch - loss: 17.50451 - diff: 12.61mlTrain batch 15/32 - 242.2ms/batch - loss: 16.72468 - diff: 12.28mlTrain batch 16/32 - 244.2ms/batch - loss: 16.08894 - diff: 12.01mlTrain batch 17/32 - 242.4ms/batch - loss: 15.64193 - diff: 11.86mlTrain batch 18/32 - 244.3ms/batch - loss: 14.96368 - diff: 11.58mlTrain batch 19/32 - 242.6ms/batch - loss: 14.28743 - diff: 11.22mlTrain batch 20/32 - 243.7ms/batch - loss: 13.93769 - diff: 11.05mlTrain batch 21/32 - 242.0ms/batch - loss: 13.64546 - diff: 11.01mlTrain batch 22/32 - 244.3ms/batch - loss: 13.90231 - diff: 11.16mlTrain batch 23/32 - 242.9ms/batch - loss: 13.52071 - diff: 10.99mlTrain batch 24/32 - 243.9ms/batch - loss: 13.27906 - diff: 10.89mlTrain batch 25/32 - 242.1ms/batch - loss: 13.04812 - diff: 10.82mlTrain batch 26/32 - 244.2ms/batch - loss: 12.82425 - diff: 10.76mlTrain batch 27/32 - 243.1ms/batch - loss: 12.93265 - diff: 10.82mlTrain batch 28/32 - 242.7ms/batch - loss: 12.58829 - diff: 10.64mlTrain batch 29/32 - 242.1ms/batch - loss: 12.56757 - diff: 10.69mlTrain batch 30/32 - 242.4ms/batch - loss: 12.38729 - diff: 10.61mlTrain batch 31/32 - 244.5ms/batch - loss: 12.06269 - diff: 10.43mlTrain batch 32/32 - 80.0ms/batch - loss: 13.37097 - diff: 10.54mlTrain batch 32/32 - 11.3s 80.0ms/batch - loss: 13.37097 - diff: 10.54ml
Test 1.1s: val_loss: 360.22669 - diff: 69.69ml

Epoch 140: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 242.0ms/batch - loss: 16.46499 - diff: 15.04mlTrain batch 2/32 - 244.4ms/batch - loss: 14.90103 - diff: 13.68mlTrain batch 3/32 - 242.3ms/batch - loss: 11.87348 - diff: 11.71mlTrain batch 4/32 - 243.5ms/batch - loss: 10.27680 - diff: 10.83mlTrain batch 5/32 - 241.9ms/batch - loss: 10.58030 - diff: 11.12mlTrain batch 6/32 - 243.4ms/batch - loss: 10.61880 - diff: 11.23mlTrain batch 7/32 - 242.5ms/batch - loss: 10.91589 - diff: 11.34mlTrain batch 8/32 - 242.5ms/batch - loss: 9.97113 - diff: 10.71mlTrain batch 9/32 - 242.9ms/batch - loss: 9.68631 - diff: 10.48mlTrain batch 10/32 - 241.8ms/batch - loss: 10.19916 - diff: 10.69mlTrain batch 11/32 - 246.9ms/batch - loss: 9.93534 - diff: 10.51mlTrain batch 12/32 - 242.5ms/batch - loss: 10.08780 - diff: 10.49mlTrain batch 13/32 - 244.3ms/batch - loss: 9.64428 - diff: 10.23mlTrain batch 14/32 - 242.0ms/batch - loss: 9.86107 - diff: 10.42mlTrain batch 15/32 - 244.7ms/batch - loss: 10.30939 - diff: 10.57mlTrain batch 16/32 - 242.7ms/batch - loss: 10.33982 - diff: 10.55mlTrain batch 17/32 - 243.6ms/batch - loss: 10.85295 - diff: 10.80mlTrain batch 18/32 - 242.4ms/batch - loss: 10.47463 - diff: 10.52mlTrain batch 19/32 - 244.2ms/batch - loss: 10.36614 - diff: 10.48mlTrain batch 20/32 - 241.9ms/batch - loss: 10.08254 - diff: 10.30mlTrain batch 21/32 - 244.6ms/batch - loss: 10.01753 - diff: 10.29mlTrain batch 22/32 - 245.6ms/batch - loss: 10.17006 - diff: 10.41mlTrain batch 23/32 - 243.1ms/batch - loss: 9.98993 - diff: 10.28mlTrain batch 24/32 - 242.4ms/batch - loss: 9.89005 - diff: 10.21mlTrain batch 25/32 - 244.4ms/batch - loss: 9.69376 - diff: 10.09mlTrain batch 26/32 - 242.2ms/batch - loss: 9.78054 - diff: 10.10mlTrain batch 27/32 - 242.9ms/batch - loss: 10.26243 - diff: 10.35mlTrain batch 28/32 - 243.0ms/batch - loss: 15.00514 - diff: 11.39mlTrain batch 29/32 - 243.9ms/batch - loss: 14.66604 - diff: 11.23mlTrain batch 30/32 - 241.9ms/batch - loss: 14.44733 - diff: 11.16mlTrain batch 31/32 - 243.7ms/batch - loss: 14.14436 - diff: 11.02mlTrain batch 32/32 - 78.9ms/batch - loss: 15.19425 - diff: 11.12mlTrain batch 32/32 - 12.2s 78.9ms/batch - loss: 15.19425 - diff: 11.12ml
Test 1.1s: val_loss: 303.31077 - diff: 63.22ml

Epoch 141: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 241.9ms/batch - loss: 7.43765 - diff: 9.24mlTrain batch 2/32 - 242.9ms/batch - loss: 5.27480 - diff: 7.42mlTrain batch 3/32 - 241.7ms/batch - loss: 6.85045 - diff: 8.32mlTrain batch 4/32 - 244.0ms/batch - loss: 6.32903 - diff: 7.93mlTrain batch 5/32 - 242.4ms/batch - loss: 6.05278 - diff: 7.79mlTrain batch 6/32 - 242.2ms/batch - loss: 6.57523 - diff: 7.89mlTrain batch 7/32 - 245.9ms/batch - loss: 6.25309 - diff: 7.67mlTrain batch 8/32 - 242.2ms/batch - loss: 6.27379 - diff: 7.57mlTrain batch 9/32 - 242.7ms/batch - loss: 5.96525 - diff: 7.46mlTrain batch 10/32 - 244.3ms/batch - loss: 5.76150 - diff: 7.42mlTrain batch 11/32 - 242.8ms/batch - loss: 5.65041 - diff: 7.40mlTrain batch 12/32 - 244.3ms/batch - loss: 5.85210 - diff: 7.59mlTrain batch 13/32 - 243.0ms/batch - loss: 5.91071 - diff: 7.50mlTrain batch 14/32 - 243.9ms/batch - loss: 5.66727 - diff: 7.31mlTrain batch 15/32 - 242.8ms/batch - loss: 6.48322 - diff: 7.79mlTrain batch 16/32 - 243.6ms/batch - loss: 6.48983 - diff: 7.85mlTrain batch 17/32 - 242.4ms/batch - loss: 6.31131 - diff: 7.75mlTrain batch 18/32 - 244.1ms/batch - loss: 6.21309 - diff: 7.69mlTrain batch 19/32 - 241.4ms/batch - loss: 6.90629 - diff: 8.06mlTrain batch 20/32 - 244.1ms/batch - loss: 10.18966 - diff: 9.26mlTrain batch 21/32 - 242.6ms/batch - loss: 9.98504 - diff: 9.17mlTrain batch 22/32 - 244.2ms/batch - loss: 9.90581 - diff: 9.24mlTrain batch 23/32 - 242.4ms/batch - loss: 9.63845 - diff: 9.13mlTrain batch 24/32 - 244.5ms/batch - loss: 9.44115 - diff: 9.04mlTrain batch 25/32 - 242.4ms/batch - loss: 9.83296 - diff: 9.26mlTrain batch 26/32 - 244.0ms/batch - loss: 12.87626 - diff: 10.03mlTrain batch 27/32 - 242.4ms/batch - loss: 12.59864 - diff: 9.94mlTrain batch 28/32 - 244.5ms/batch - loss: 12.66921 - diff: 9.98mlTrain batch 29/32 - 244.2ms/batch - loss: 12.36120 - diff: 9.87mlTrain batch 30/32 - 242.0ms/batch - loss: 12.14446 - diff: 9.79mlTrain batch 31/32 - 242.5ms/batch - loss: 11.87694 - diff: 9.69mlTrain batch 32/32 - 78.3ms/batch - loss: 12.97795 - diff: 9.79mlTrain batch 32/32 - 11.4s 78.3ms/batch - loss: 12.97795 - diff: 9.79ml
Test 1.1s: val_loss: 317.97052 - diff: 64.83ml

Epoch 142: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 242.6ms/batch - loss: 3.74397 - diff: 5.99mlTrain batch 2/32 - 242.6ms/batch - loss: 5.16570 - diff: 6.35mlTrain batch 3/32 - 241.9ms/batch - loss: 5.35388 - diff: 6.73mlTrain batch 4/32 - 244.3ms/batch - loss: 5.47282 - diff: 6.87mlTrain batch 5/32 - 241.9ms/batch - loss: 6.41069 - diff: 7.61mlTrain batch 6/32 - 241.9ms/batch - loss: 12.02326 - diff: 9.92mlTrain batch 7/32 - 242.2ms/batch - loss: 11.55644 - diff: 9.71mlTrain batch 8/32 - 244.5ms/batch - loss: 10.62183 - diff: 9.29mlTrain batch 9/32 - 242.4ms/batch - loss: 11.18393 - diff: 9.86mlTrain batch 10/32 - 244.3ms/batch - loss: 11.71711 - diff: 10.26mlTrain batch 11/32 - 242.5ms/batch - loss: 11.50994 - diff: 10.17mlTrain batch 12/32 - 243.9ms/batch - loss: 11.79166 - diff: 10.42mlTrain batch 13/32 - 242.8ms/batch - loss: 12.15023 - diff: 10.69mlTrain batch 14/32 - 244.4ms/batch - loss: 11.72863 - diff: 10.49mlTrain batch 15/32 - 242.2ms/batch - loss: 11.10721 - diff: 10.14mlTrain batch 16/32 - 243.6ms/batch - loss: 10.63876 - diff: 9.94mlTrain batch 17/32 - 242.3ms/batch - loss: 11.03695 - diff: 10.23mlTrain batch 18/32 - 244.0ms/batch - loss: 10.72065 - diff: 10.04mlTrain batch 19/32 - 243.2ms/batch - loss: 10.57316 - diff: 10.01mlTrain batch 20/32 - 244.6ms/batch - loss: 11.14814 - diff: 10.30mlTrain batch 21/32 - 242.4ms/batch - loss: 11.19214 - diff: 10.25mlTrain batch 22/32 - 244.4ms/batch - loss: 10.86005 - diff: 10.08mlTrain batch 23/32 - 242.6ms/batch - loss: 13.94936 - diff: 11.03mlTrain batch 24/32 - 244.4ms/batch - loss: 13.51989 - diff: 10.82mlTrain batch 25/32 - 242.2ms/batch - loss: 13.46229 - diff: 10.83mlTrain batch 26/32 - 242.4ms/batch - loss: 13.14758 - diff: 10.69mlTrain batch 27/32 - 242.0ms/batch - loss: 12.84590 - diff: 10.54mlTrain batch 28/32 - 244.6ms/batch - loss: 12.66039 - diff: 10.52mlTrain batch 29/32 - 242.8ms/batch - loss: 12.55318 - diff: 10.49mlTrain batch 30/32 - 244.5ms/batch - loss: 12.92085 - diff: 10.72mlTrain batch 31/32 - 242.7ms/batch - loss: 12.59891 - diff: 10.54mlTrain batch 32/32 - 79.8ms/batch - loss: 12.73740 - diff: 10.53mlTrain batch 32/32 - 11.1s 79.8ms/batch - loss: 12.73740 - diff: 10.53ml
Test 1.1s: val_loss: 328.06940 - diff: 66.09ml

Epoch 143: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 241.5ms/batch - loss: 5.91456 - diff: 7.80mlTrain batch 2/32 - 244.3ms/batch - loss: 13.00537 - diff: 11.35mlTrain batch 3/32 - 242.0ms/batch - loss: 15.84505 - diff: 13.40mlTrain batch 4/32 - 244.2ms/batch - loss: 16.68617 - diff: 13.96mlTrain batch 5/32 - 241.9ms/batch - loss: 14.65523 - diff: 12.75mlTrain batch 6/32 - 244.4ms/batch - loss: 12.81880 - diff: 11.56mlTrain batch 7/32 - 241.7ms/batch - loss: 13.77663 - diff: 12.08mlTrain batch 8/32 - 242.2ms/batch - loss: 13.55974 - diff: 11.89mlTrain batch 9/32 - 242.5ms/batch - loss: 12.51374 - diff: 11.41mlTrain batch 10/32 - 243.6ms/batch - loss: 12.76577 - diff: 11.75mlTrain batch 11/32 - 243.1ms/batch - loss: 12.38029 - diff: 11.58mlTrain batch 12/32 - 244.0ms/batch - loss: 11.69514 - diff: 11.23mlTrain batch 13/32 - 242.3ms/batch - loss: 11.17938 - diff: 10.93mlTrain batch 14/32 - 244.3ms/batch - loss: 12.47854 - diff: 11.46mlTrain batch 15/32 - 242.8ms/batch - loss: 12.57847 - diff: 11.54mlTrain batch 16/32 - 244.4ms/batch - loss: 12.16593 - diff: 11.19mlTrain batch 17/32 - 242.4ms/batch - loss: 13.29354 - diff: 11.71mlTrain batch 18/32 - 246.5ms/batch - loss: 12.72637 - diff: 11.41mlTrain batch 19/32 - 242.6ms/batch - loss: 13.52821 - diff: 11.66mlTrain batch 20/32 - 244.3ms/batch - loss: 13.55963 - diff: 11.73mlTrain batch 21/32 - 242.6ms/batch - loss: 13.59081 - diff: 11.80mlTrain batch 22/32 - 244.4ms/batch - loss: 13.30019 - diff: 11.69mlTrain batch 23/32 - 242.4ms/batch - loss: 12.81903 - diff: 11.36mlTrain batch 24/32 - 244.6ms/batch - loss: 13.47393 - diff: 11.70mlTrain batch 25/32 - 242.8ms/batch - loss: 13.06545 - diff: 11.45mlTrain batch 26/32 - 244.4ms/batch - loss: 16.29108 - diff: 12.11mlTrain batch 27/32 - 243.3ms/batch - loss: 16.08634 - diff: 12.10mlTrain batch 28/32 - 244.3ms/batch - loss: 15.73163 - diff: 11.89mlTrain batch 29/32 - 243.1ms/batch - loss: 16.18201 - diff: 12.11mlTrain batch 30/32 - 243.8ms/batch - loss: 15.86882 - diff: 11.98mlTrain batch 31/32 - 243.0ms/batch - loss: 15.93131 - diff: 12.07mlTrain batch 32/32 - 78.9ms/batch - loss: 15.89433 - diff: 12.03mlTrain batch 32/32 - 11.4s 78.9ms/batch - loss: 15.89433 - diff: 12.03ml
Test 1.1s: val_loss: 320.48657 - diff: 65.33ml

Epoch 144: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 241.6ms/batch - loss: 6.90616 - diff: 9.13mlTrain batch 2/32 - 243.8ms/batch - loss: 8.66131 - diff: 9.44mlTrain batch 3/32 - 242.3ms/batch - loss: 7.46337 - diff: 8.75mlTrain batch 4/32 - 244.2ms/batch - loss: 7.03588 - diff: 8.47mlTrain batch 5/32 - 242.8ms/batch - loss: 6.61187 - diff: 8.26mlTrain batch 6/32 - 244.3ms/batch - loss: 6.15073 - diff: 7.97mlTrain batch 7/32 - 242.6ms/batch - loss: 5.99684 - diff: 7.93mlTrain batch 8/32 - 244.3ms/batch - loss: 7.17357 - diff: 8.65mlTrain batch 9/32 - 242.0ms/batch - loss: 7.47306 - diff: 8.87mlTrain batch 10/32 - 243.2ms/batch - loss: 7.20642 - diff: 8.66mlTrain batch 11/32 - 242.2ms/batch - loss: 6.95410 - diff: 8.54mlTrain batch 12/32 - 244.4ms/batch - loss: 7.48826 - diff: 8.79mlTrain batch 13/32 - 242.8ms/batch - loss: 7.36301 - diff: 8.66mlTrain batch 14/32 - 244.5ms/batch - loss: 7.27955 - diff: 8.65mlTrain batch 15/32 - 245.5ms/batch - loss: 7.20752 - diff: 8.62mlTrain batch 16/32 - 244.2ms/batch - loss: 8.12872 - diff: 9.15mlTrain batch 17/32 - 243.0ms/batch - loss: 8.20318 - diff: 9.22mlTrain batch 18/32 - 244.4ms/batch - loss: 8.03630 - diff: 9.13mlTrain batch 19/32 - 242.5ms/batch - loss: 8.00913 - diff: 9.10mlTrain batch 20/32 - 244.7ms/batch - loss: 7.74277 - diff: 8.92mlTrain batch 21/32 - 242.3ms/batch - loss: 7.57768 - diff: 8.84mlTrain batch 22/32 - 244.7ms/batch - loss: 7.37467 - diff: 8.69mlTrain batch 23/32 - 242.8ms/batch - loss: 7.26764 - diff: 8.62mlTrain batch 24/32 - 244.3ms/batch - loss: 7.63441 - diff: 8.87mlTrain batch 25/32 - 242.8ms/batch - loss: 7.47184 - diff: 8.77mlTrain batch 26/32 - 244.4ms/batch - loss: 7.40606 - diff: 8.75mlTrain batch 27/32 - 242.4ms/batch - loss: 7.45362 - diff: 8.83mlTrain batch 28/32 - 243.9ms/batch - loss: 7.41891 - diff: 8.80mlTrain batch 29/32 - 243.2ms/batch - loss: 7.43919 - diff: 8.83mlTrain batch 30/32 - 244.4ms/batch - loss: 7.27852 - diff: 8.70mlTrain batch 31/32 - 243.1ms/batch - loss: 11.13322 - diff: 9.67mlTrain batch 32/32 - 79.5ms/batch - loss: 11.33817 - diff: 9.67mlTrain batch 32/32 - 11.3s 79.5ms/batch - loss: 11.33817 - diff: 9.67ml
Test 1.2s: val_loss: 203.09819 - diff: 51.02ml

Epoch 145: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 243.0ms/batch - loss: 1.84326 - diff: 4.25mlTrain batch 2/32 - 243.2ms/batch - loss: 2.69053 - diff: 4.84mlTrain batch 3/32 - 242.4ms/batch - loss: 3.50441 - diff: 5.81mlTrain batch 4/32 - 244.5ms/batch - loss: 4.02027 - diff: 6.28mlTrain batch 5/32 - 242.4ms/batch - loss: 4.64312 - diff: 6.78mlTrain batch 6/32 - 242.8ms/batch - loss: 12.09179 - diff: 9.91mlTrain batch 7/32 - 243.8ms/batch - loss: 13.06546 - diff: 10.63mlTrain batch 8/32 - 242.6ms/batch - loss: 11.73363 - diff: 9.91mlTrain batch 9/32 - 243.5ms/batch - loss: 24.32325 - diff: 12.99mlTrain batch 10/32 - 242.2ms/batch - loss: 22.40782 - diff: 12.37mlTrain batch 11/32 - 244.4ms/batch - loss: 20.65054 - diff: 11.76mlTrain batch 12/32 - 241.9ms/batch - loss: 19.59018 - diff: 11.59mlTrain batch 13/32 - 244.0ms/batch - loss: 18.76442 - diff: 11.37mlTrain batch 14/32 - 241.7ms/batch - loss: 17.67152 - diff: 10.95mlTrain batch 15/32 - 244.4ms/batch - loss: 19.22875 - diff: 11.66mlTrain batch 16/32 - 242.6ms/batch - loss: 18.20703 - diff: 11.27mlTrain batch 17/32 - 243.8ms/batch - loss: 17.25602 - diff: 10.87mlTrain batch 18/32 - 242.1ms/batch - loss: 16.49570 - diff: 10.59mlTrain batch 19/32 - 244.4ms/batch - loss: 16.03593 - diff: 10.53mlTrain batch 20/32 - 242.7ms/batch - loss: 15.58808 - diff: 10.44mlTrain batch 21/32 - 244.2ms/batch - loss: 15.53308 - diff: 10.54mlTrain batch 22/32 - 242.6ms/batch - loss: 15.43469 - diff: 10.68mlTrain batch 23/32 - 244.4ms/batch - loss: 15.80751 - diff: 11.01mlTrain batch 24/32 - 242.4ms/batch - loss: 15.41918 - diff: 10.91mlTrain batch 25/32 - 243.9ms/batch - loss: 14.98854 - diff: 10.73mlTrain batch 26/32 - 243.1ms/batch - loss: 16.43273 - diff: 11.24mlTrain batch 27/32 - 244.3ms/batch - loss: 16.40470 - diff: 11.27mlTrain batch 28/32 - 242.3ms/batch - loss: 15.91234 - diff: 11.03mlTrain batch 29/32 - 244.4ms/batch - loss: 15.77376 - diff: 11.06mlTrain batch 30/32 - 242.1ms/batch - loss: 15.62133 - diff: 11.04mlTrain batch 31/32 - 244.4ms/batch - loss: 15.28355 - diff: 10.92mlTrain batch 32/32 - 79.4ms/batch - loss: 15.25465 - diff: 10.89mlTrain batch 32/32 - 11.9s 79.4ms/batch - loss: 15.25465 - diff: 10.89ml
Test 1.2s: val_loss: 358.70201 - diff: 68.92ml

Epoch 146: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 242.1ms/batch - loss: 2.77363 - diff: 5.07mlTrain batch 2/32 - 244.2ms/batch - loss: 7.36053 - diff: 6.83mlTrain batch 3/32 - 243.0ms/batch - loss: 7.65258 - diff: 8.13mlTrain batch 4/32 - 244.2ms/batch - loss: 8.73527 - diff: 8.73mlTrain batch 5/32 - 241.8ms/batch - loss: 8.37480 - diff: 8.71mlTrain batch 6/32 - 241.8ms/batch - loss: 8.49507 - diff: 8.98mlTrain batch 7/32 - 244.3ms/batch - loss: 7.92114 - diff: 8.74mlTrain batch 8/32 - 243.6ms/batch - loss: 9.47230 - diff: 9.64mlTrain batch 9/32 - 242.2ms/batch - loss: 9.30183 - diff: 9.49mlTrain batch 10/32 - 243.6ms/batch - loss: 9.07540 - diff: 9.36mlTrain batch 11/32 - 242.6ms/batch - loss: 8.53350 - diff: 9.05mlTrain batch 12/32 - 244.4ms/batch - loss: 8.55850 - diff: 9.04mlTrain batch 13/32 - 243.6ms/batch - loss: 8.69007 - diff: 9.17mlTrain batch 14/32 - 244.0ms/batch - loss: 8.41860 - diff: 9.01mlTrain batch 15/32 - 242.9ms/batch - loss: 8.43607 - diff: 9.07mlTrain batch 16/32 - 243.3ms/batch - loss: 8.40522 - diff: 9.05mlTrain batch 17/32 - 242.6ms/batch - loss: 8.54351 - diff: 9.19mlTrain batch 18/32 - 244.2ms/batch - loss: 15.42386 - diff: 10.84mlTrain batch 19/32 - 242.5ms/batch - loss: 14.82181 - diff: 10.61mlTrain batch 20/32 - 243.9ms/batch - loss: 14.86109 - diff: 10.75mlTrain batch 21/32 - 242.1ms/batch - loss: 14.29462 - diff: 10.51mlTrain batch 22/32 - 242.8ms/batch - loss: 13.92994 - diff: 10.39mlTrain batch 23/32 - 242.1ms/batch - loss: 13.51613 - diff: 10.22mlTrain batch 24/32 - 244.0ms/batch - loss: 13.03951 - diff: 9.99mlTrain batch 25/32 - 242.0ms/batch - loss: 12.95621 - diff: 10.01mlTrain batch 26/32 - 244.1ms/batch - loss: 12.59052 - diff: 9.87mlTrain batch 27/32 - 252.0ms/batch - loss: 12.25874 - diff: 9.73mlTrain batch 28/32 - 242.4ms/batch - loss: 12.75808 - diff: 10.04mlTrain batch 29/32 - 242.6ms/batch - loss: 12.52765 - diff: 9.97mlTrain batch 30/32 - 242.9ms/batch - loss: 12.32431 - diff: 9.92mlTrain batch 31/32 - 242.4ms/batch - loss: 12.17340 - diff: 9.92mlTrain batch 32/32 - 79.5ms/batch - loss: 12.42505 - diff: 9.94mlTrain batch 32/32 - 12.5s 79.5ms/batch - loss: 12.42505 - diff: 9.94ml
Test 1.2s: val_loss: 267.58883 - diff: 58.80ml

Epoch 147: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 241.9ms/batch - loss: 4.42227 - diff: 6.50mlTrain batch 2/32 - 243.4ms/batch - loss: 10.26317 - diff: 10.53mlTrain batch 3/32 - 241.9ms/batch - loss: 8.73385 - diff: 9.64mlTrain batch 4/32 - 244.4ms/batch - loss: 7.13191 - diff: 8.33mlTrain batch 5/32 - 242.9ms/batch - loss: 9.19670 - diff: 9.72mlTrain batch 6/32 - 244.4ms/batch - loss: 8.52653 - diff: 9.48mlTrain batch 7/32 - 242.2ms/batch - loss: 10.51019 - diff: 10.38mlTrain batch 8/32 - 242.4ms/batch - loss: 10.67857 - diff: 10.65mlTrain batch 9/32 - 245.3ms/batch - loss: 9.93870 - diff: 10.22mlTrain batch 10/32 - 243.3ms/batch - loss: 9.57985 - diff: 10.08mlTrain batch 11/32 - 242.4ms/batch - loss: 10.42116 - diff: 10.58mlTrain batch 12/32 - 244.3ms/batch - loss: 10.43818 - diff: 10.55mlTrain batch 13/32 - 242.3ms/batch - loss: 9.85452 - diff: 10.20mlTrain batch 14/32 - 242.5ms/batch - loss: 9.49233 - diff: 9.97mlTrain batch 15/32 - 242.0ms/batch - loss: 9.91008 - diff: 10.21mlTrain batch 16/32 - 242.3ms/batch - loss: 9.75516 - diff: 10.13mlTrain batch 17/32 - 241.4ms/batch - loss: 9.29220 - diff: 9.84mlTrain batch 18/32 - 243.0ms/batch - loss: 17.04797 - diff: 11.50mlTrain batch 19/32 - 243.4ms/batch - loss: 16.49630 - diff: 11.33mlTrain batch 20/32 - 244.8ms/batch - loss: 16.06640 - diff: 11.20mlTrain batch 21/32 - 242.2ms/batch - loss: 15.66328 - diff: 11.05mlTrain batch 22/32 - 243.9ms/batch - loss: 15.30813 - diff: 10.97mlTrain batch 23/32 - 242.9ms/batch - loss: 14.76883 - diff: 10.74mlTrain batch 24/32 - 243.6ms/batch - loss: 14.31432 - diff: 10.51mlTrain batch 25/32 - 242.3ms/batch - loss: 14.57582 - diff: 10.72mlTrain batch 26/32 - 244.6ms/batch - loss: 14.22959 - diff: 10.58mlTrain batch 27/32 - 243.7ms/batch - loss: 13.98232 - diff: 10.50mlTrain batch 28/32 - 244.1ms/batch - loss: 13.62071 - diff: 10.34mlTrain batch 29/32 - 242.2ms/batch - loss: 13.32873 - diff: 10.23mlTrain batch 30/32 - 246.1ms/batch - loss: 13.50531 - diff: 10.44mlTrain batch 31/32 - 245.3ms/batch - loss: 13.24930 - diff: 10.34mlTrain batch 32/32 - 77.6ms/batch - loss: 14.43358 - diff: 10.43mlTrain batch 32/32 - 12.4s 77.6ms/batch - loss: 14.43358 - diff: 10.43ml
Test 1.1s: val_loss: 282.20084 - diff: 61.16ml
Epoch   148: reducing learning rate of group 0 to 1.2207e-07.

Epoch 148: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 241.7ms/batch - loss: 6.81353 - diff: 8.55mlTrain batch 2/32 - 243.8ms/batch - loss: 4.27808 - diff: 6.16mlTrain batch 3/32 - 242.1ms/batch - loss: 5.84336 - diff: 7.66mlTrain batch 4/32 - 244.2ms/batch - loss: 7.21501 - diff: 8.58mlTrain batch 5/32 - 242.7ms/batch - loss: 6.43890 - diff: 8.08mlTrain batch 6/32 - 243.3ms/batch - loss: 8.17213 - diff: 8.75mlTrain batch 7/32 - 242.3ms/batch - loss: 7.60040 - diff: 8.42mlTrain batch 8/32 - 243.4ms/batch - loss: 7.53074 - diff: 8.49mlTrain batch 9/32 - 242.2ms/batch - loss: 8.37613 - diff: 9.09mlTrain batch 10/32 - 243.6ms/batch - loss: 8.36899 - diff: 9.13mlTrain batch 11/32 - 242.4ms/batch - loss: 9.30055 - diff: 9.58mlTrain batch 12/32 - 244.2ms/batch - loss: 8.94671 - diff: 9.41mlTrain batch 13/32 - 242.8ms/batch - loss: 8.62786 - diff: 9.28mlTrain batch 14/32 - 242.8ms/batch - loss: 8.62430 - diff: 9.37mlTrain batch 15/32 - 242.2ms/batch - loss: 8.91275 - diff: 9.53mlTrain batch 16/32 - 244.5ms/batch - loss: 9.42946 - diff: 9.82mlTrain batch 17/32 - 242.1ms/batch - loss: 14.93369 - diff: 11.14mlTrain batch 18/32 - 244.0ms/batch - loss: 14.48064 - diff: 10.97mlTrain batch 19/32 - 242.9ms/batch - loss: 14.35625 - diff: 11.04mlTrain batch 20/32 - 244.4ms/batch - loss: 14.49265 - diff: 11.21mlTrain batch 21/32 - 242.4ms/batch - loss: 14.18094 - diff: 11.13mlTrain batch 22/32 - 244.0ms/batch - loss: 13.81059 - diff: 10.99mlTrain batch 23/32 - 242.8ms/batch - loss: 14.12364 - diff: 11.24mlTrain batch 24/32 - 244.2ms/batch - loss: 13.67599 - diff: 11.01mlTrain batch 25/32 - 243.2ms/batch - loss: 13.51989 - diff: 10.96mlTrain batch 26/32 - 244.1ms/batch - loss: 13.30996 - diff: 10.90mlTrain batch 27/32 - 242.0ms/batch - loss: 13.16569 - diff: 10.87mlTrain batch 28/32 - 243.7ms/batch - loss: 12.87233 - diff: 10.75mlTrain batch 29/32 - 242.0ms/batch - loss: 12.69731 - diff: 10.66mlTrain batch 30/32 - 244.4ms/batch - loss: 12.73680 - diff: 10.75mlTrain batch 31/32 - 242.6ms/batch - loss: 12.38703 - diff: 10.55mlTrain batch 32/32 - 79.3ms/batch - loss: 12.45890 - diff: 10.53mlTrain batch 32/32 - 10.6s 79.3ms/batch - loss: 12.45890 - diff: 10.53ml
Test 1.1s: val_loss: 347.82284 - diff: 67.88ml

Epoch 149: current best loss = 68.57713, at epoch 4
Train batch 1/32 - 241.6ms/batch - loss: 7.48921 - diff: 9.36mlTrain batch 2/32 - 241.9ms/batch - loss: 5.17975 - diff: 7.47mlTrain batch 3/32 - 245.5ms/batch - loss: 5.15841 - diff: 7.17mlTrain batch 4/32 - 242.5ms/batch - loss: 7.83025 - diff: 8.72mlTrain batch 5/32 - 242.2ms/batch - loss: 12.69935 - diff: 11.26mlTrain batch 6/32 - 244.5ms/batch - loss: 11.06959 - diff: 10.38mlTrain batch 7/32 - 242.4ms/batch - loss: 9.96184 - diff: 9.72mlTrain batch 8/32 - 244.2ms/batch - loss: 28.09852 - diff: 13.66mlTrain batch 9/32 - 241.9ms/batch - loss: 25.39234 - diff: 12.79mlTrain batch 10/32 - 244.1ms/batch - loss: 24.32683 - diff: 12.82mlTrain batch 11/32 - 242.7ms/batch - loss: 22.58323 - diff: 12.32mlTrain batch 12/32 - 244.4ms/batch - loss: 21.06594 - diff: 11.92mlTrain batch 13/32 - 243.3ms/batch - loss: 19.67770 - diff: 11.44mlTrain batch 14/32 - 244.2ms/batch - loss: 19.03731 - diff: 11.48mlTrain batch 15/32 - 242.4ms/batch - loss: 18.81335 - diff: 11.59mlTrain batch 16/32 - 244.0ms/batch - loss: 17.97412 - diff: 11.29mlTrain batch 17/32 - 243.2ms/batch - loss: 18.14658 - diff: 11.54mlTrain batch 18/32 - 244.1ms/batch - loss: 20.09414 - diff: 12.37mlTrain batch 19/32 - 243.4ms/batch - loss: 19.45958 - diff: 12.20mlTrain batch 20/32 - 244.1ms/batch - loss: 19.27576 - diff: 12.18mlTrain batch 21/32 - 242.4ms/batch - loss: 18.47966 - diff: 11.84mlTrain batch 22/32 - 244.4ms/batch - loss: 17.92054 - diff: 11.71mlTrain batch 23/32 - 243.4ms/batch - loss: 17.32473 - diff: 11.48mlTrain batch 24/32 - 244.4ms/batch - loss: 17.00112 - diff: 11.44mlTrain batch 25/32 - 242.3ms/batch - loss: 16.75367 - diff: 11.42mlTrain batch 26/32 - 244.4ms/batch - loss: 16.31235 - diff: 11.26mlTrain batch 27/32 - 242.3ms/batch - loss: 16.15866 - diff: 11.25mlTrain batch 28/32 - 244.4ms/batch - loss: 15.68694 - diff: 11.02mlTrain batch 29/32 - 242.0ms/batch - loss: 15.34221 - diff: 10.92mlTrain batch 30/32 - 244.8ms/batch - loss: 14.98694 - diff: 10.76mlTrain batch 31/32 - 242.4ms/batch - loss: 14.76825 - diff: 10.69mlTrain batch 32/32 - 79.0ms/batch - loss: 17.26847 - diff: 10.89mlTrain batch 32/32 - 10.6s 79.0ms/batch - loss: 17.26847 - diff: 10.89ml
Test 1.1s: val_loss: 270.79201 - diff: 59.97ml

Traceback (most recent call last):
  File "train.py", line 266, in <module>
    plot_results(train_losses, test_losses, title=f"Loss {target_label}", save_as=exp_name + "_loss")
  File "/home/allochi/tfm/workspace/lib/utils.py", line 393, in plot_results
    plt.plot(train_values, "r", label="train")
  File "/home/allochi/.conda/envs/DL_env/lib/python3.8/site-packages/matplotlib/pyplot.py", line 2824, in plot
    return gca().plot(
  File "/home/allochi/.conda/envs/DL_env/lib/python3.8/site-packages/matplotlib/pyplot.py", line 2352, in gca
    return gcf().gca(**kwargs)
  File "/home/allochi/.conda/envs/DL_env/lib/python3.8/site-packages/matplotlib/pyplot.py", line 731, in gcf
    return figure()
  File "/home/allochi/.conda/envs/DL_env/lib/python3.8/site-packages/matplotlib/pyplot.py", line 671, in figure
    figManager = new_figure_manager(num, figsize=figsize,
  File "/home/allochi/.conda/envs/DL_env/lib/python3.8/site-packages/matplotlib/pyplot.py", line 299, in new_figure_manager
    return _backend_mod.new_figure_manager(*args, **kwargs)
  File "/home/allochi/.conda/envs/DL_env/lib/python3.8/site-packages/matplotlib/backend_bases.py", line 3494, in new_figure_manager
    return cls.new_figure_manager_given_figure(num, fig)
  File "/home/allochi/.conda/envs/DL_env/lib/python3.8/site-packages/matplotlib/backends/_backend_tk.py", line 868, in new_figure_manager_given_figure
    window = tk.Tk(className="matplotlib")
  File "/home/allochi/.conda/envs/DL_env/lib/python3.8/tkinter/__init__.py", line 2261, in __init__
    self.tk = _tkinter.create(screenName, baseName, className, interactive, wantobjects, useTk, sync, use)
_tkinter.TclError: couldn't connect to display "localhost:10.0"
