nohup: ignoring input
Running experiment 2CH_preproc1_150x150_bySlices_dataset_allViews_Systole_DenseNet121_0_Adam-0.001_MAE_DA3
Going to train with the GPU in the slot 0 -> device model: GeForce RTX 2080
Model architecture:
 DenseNet121_0(
  (first_conv): Sequential(
    (0): Conv2d(30, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (pretrained_block): Sequential(
    (0): _DenseBlock(
      (denselayer1): _DenseLayer(
        (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer2): _DenseLayer(
        (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer3): _DenseLayer(
        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer4): _DenseLayer(
        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer5): _DenseLayer(
        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer6): _DenseLayer(
        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
    (1): _Transition(
      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)
    )
    (2): _DenseBlock(
      (denselayer1): _DenseLayer(
        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer2): _DenseLayer(
        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer3): _DenseLayer(
        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer4): _DenseLayer(
        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer5): _DenseLayer(
        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer6): _DenseLayer(
        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer7): _DenseLayer(
        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer8): _DenseLayer(
        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer9): _DenseLayer(
        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer10): _DenseLayer(
        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer11): _DenseLayer(
        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer12): _DenseLayer(
        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
    (3): _Transition(
      (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)
    )
    (4): _DenseBlock(
      (denselayer1): _DenseLayer(
        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer2): _DenseLayer(
        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer3): _DenseLayer(
        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer4): _DenseLayer(
        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer5): _DenseLayer(
        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer6): _DenseLayer(
        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer7): _DenseLayer(
        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer8): _DenseLayer(
        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer9): _DenseLayer(
        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer10): _DenseLayer(
        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer11): _DenseLayer(
        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer12): _DenseLayer(
        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer13): _DenseLayer(
        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer14): _DenseLayer(
        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer15): _DenseLayer(
        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer16): _DenseLayer(
        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer17): _DenseLayer(
        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer18): _DenseLayer(
        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer19): _DenseLayer(
        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer20): _DenseLayer(
        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer21): _DenseLayer(
        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer22): _DenseLayer(
        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer23): _DenseLayer(
        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer24): _DenseLayer(
        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
    (5): _Transition(
      (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)
    )
    (6): _DenseBlock(
      (denselayer1): _DenseLayer(
        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer2): _DenseLayer(
        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer3): _DenseLayer(
        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer4): _DenseLayer(
        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer5): _DenseLayer(
        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer6): _DenseLayer(
        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer7): _DenseLayer(
        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer8): _DenseLayer(
        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer9): _DenseLayer(
        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer10): _DenseLayer(
        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer11): _DenseLayer(
        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer12): _DenseLayer(
        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer13): _DenseLayer(
        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer14): _DenseLayer(
        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer15): _DenseLayer(
        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer16): _DenseLayer(
        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
    (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (reduction_block): Sequential(
    (0): AdaptiveAvgPool2d(output_size=(1, 1))
    (1): Flatten()
  )
  (dense_block): Sequential(
    (0): Linear(in_features=1024, out_features=512, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.4, inplace=False)
    (3): Linear(in_features=512, out_features=1, bias=True)
  )
) 


############################
# TRAIN PHASE:  150 epochs #
############################

Epoch 0: 
Train batch 1/32 - 124.6ms/batch - loss: 4.76519 - diff: 76.24mlTrain batch 2/32 - 76.0ms/batch - loss: 4.87813 - diff: 78.05mlTrain batch 3/32 - 84.2ms/batch - loss: 4.54415 - diff: 72.71mlTrain batch 4/32 - 62.8ms/batch - loss: 4.76710 - diff: 76.27mlTrain batch 5/32 - 84.4ms/batch - loss: 4.62118 - diff: 73.94mlTrain batch 6/32 - 91.2ms/batch - loss: 4.47085 - diff: 71.53mlTrain batch 7/32 - 80.2ms/batch - loss: 4.36638 - diff: 69.86mlTrain batch 8/32 - 79.9ms/batch - loss: 4.35513 - diff: 69.68mlTrain batch 9/32 - 80.3ms/batch - loss: 4.21568 - diff: 67.45mlTrain batch 10/32 - 79.2ms/batch - loss: 4.09035 - diff: 65.45mlTrain batch 11/32 - 79.3ms/batch - loss: 4.00561 - diff: 64.09mlTrain batch 12/32 - 91.8ms/batch - loss: 3.93857 - diff: 63.02mlTrain batch 13/32 - 98.4ms/batch - loss: 3.96867 - diff: 63.50mlTrain batch 14/32 - 88.5ms/batch - loss: 3.89000 - diff: 62.24mlTrain batch 15/32 - 82.9ms/batch - loss: 3.84990 - diff: 61.60mlTrain batch 16/32 - 65.4ms/batch - loss: 3.79477 - diff: 60.72mlTrain batch 17/32 - 74.3ms/batch - loss: 3.69871 - diff: 59.18mlTrain batch 18/32 - 76.7ms/batch - loss: 3.58484 - diff: 57.36mlTrain batch 19/32 - 98.9ms/batch - loss: 3.58179 - diff: 57.31mlTrain batch 20/32 - 95.5ms/batch - loss: 3.58231 - diff: 57.32mlTrain batch 21/32 - 110.8ms/batch - loss: 3.50469 - diff: 56.07mlTrain batch 22/32 - 107.3ms/batch - loss: 3.46767 - diff: 55.48mlTrain batch 23/32 - 94.1ms/batch - loss: 3.42052 - diff: 54.73mlTrain batch 24/32 - 96.0ms/batch - loss: 3.33825 - diff: 53.41mlTrain batch 25/32 - 72.7ms/batch - loss: 3.29191 - diff: 52.67mlTrain batch 26/32 - 80.4ms/batch - loss: 3.25298 - diff: 52.05mlTrain batch 27/32 - 68.8ms/batch - loss: 3.20020 - diff: 51.20mlTrain batch 28/32 - 94.6ms/batch - loss: 3.17362 - diff: 50.78mlTrain batch 29/32 - 75.2ms/batch - loss: 3.12237 - diff: 49.96mlTrain batch 30/32 - 81.8ms/batch - loss: 3.07458 - diff: 49.19mlTrain batch 31/32 - 63.3ms/batch - loss: 3.05073 - diff: 48.81mlTrain batch 32/32 - 91.4ms/batch - loss: 3.14957 - diff: 48.91mlTrain batch 32/32 - 16.3s 91.4ms/batch - loss: 3.14957 - diff: 48.91ml
Test 0.8s: val_loss: 2.19467 - diff: 33.48ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Systole_DenseNet121_0_Adam-0.001_MAE_DA3_best

Epoch 1: current best loss = 2.19467, at epoch 0
Train batch 1/32 - 89.4ms/batch - loss: 4.39618 - diff: 70.34mlTrain batch 2/32 - 78.5ms/batch - loss: 3.12890 - diff: 50.06mlTrain batch 3/32 - 79.7ms/batch - loss: 2.72987 - diff: 43.68mlTrain batch 4/32 - 92.8ms/batch - loss: 2.49899 - diff: 39.98mlTrain batch 5/32 - 77.8ms/batch - loss: 2.36723 - diff: 37.88mlTrain batch 6/32 - 67.6ms/batch - loss: 2.27471 - diff: 36.40mlTrain batch 7/32 - 80.5ms/batch - loss: 2.28722 - diff: 36.60mlTrain batch 8/32 - 91.8ms/batch - loss: 2.30768 - diff: 36.92mlTrain batch 9/32 - 78.2ms/batch - loss: 2.27381 - diff: 36.38mlTrain batch 10/32 - 75.8ms/batch - loss: 2.23379 - diff: 35.74mlTrain batch 11/32 - 76.8ms/batch - loss: 2.18676 - diff: 34.99mlTrain batch 12/32 - 73.9ms/batch - loss: 2.13471 - diff: 34.16mlTrain batch 13/32 - 76.3ms/batch - loss: 2.15007 - diff: 34.40mlTrain batch 14/32 - 82.8ms/batch - loss: 2.12847 - diff: 34.06mlTrain batch 15/32 - 101.3ms/batch - loss: 2.07877 - diff: 33.26mlTrain batch 16/32 - 81.7ms/batch - loss: 2.10139 - diff: 33.62mlTrain batch 17/32 - 62.6ms/batch - loss: 2.09189 - diff: 33.47mlTrain batch 18/32 - 83.6ms/batch - loss: 2.07514 - diff: 33.20mlTrain batch 19/32 - 62.2ms/batch - loss: 2.04482 - diff: 32.72mlTrain batch 20/32 - 76.9ms/batch - loss: 2.03225 - diff: 32.52mlTrain batch 21/32 - 81.4ms/batch - loss: 2.03271 - diff: 32.52mlTrain batch 22/32 - 67.7ms/batch - loss: 2.05152 - diff: 32.82mlTrain batch 23/32 - 84.0ms/batch - loss: 2.05044 - diff: 32.81mlTrain batch 24/32 - 57.9ms/batch - loss: 2.02528 - diff: 32.40mlTrain batch 25/32 - 58.1ms/batch - loss: 2.00828 - diff: 32.13mlTrain batch 26/32 - 95.8ms/batch - loss: 2.03281 - diff: 32.53mlTrain batch 27/32 - 110.0ms/batch - loss: 2.02899 - diff: 32.46mlTrain batch 28/32 - 111.9ms/batch - loss: 2.02217 - diff: 32.35mlTrain batch 29/32 - 60.6ms/batch - loss: 2.02072 - diff: 32.33mlTrain batch 30/32 - 84.0ms/batch - loss: 2.00408 - diff: 32.07mlTrain batch 31/32 - 60.7ms/batch - loss: 1.99178 - diff: 31.87mlTrain batch 32/32 - 81.1ms/batch - loss: 2.04400 - diff: 31.89mlTrain batch 32/32 - 15.7s 81.1ms/batch - loss: 2.04400 - diff: 31.89ml
Test 0.9s: val_loss: 3.86400 - diff: 59.69ml

Epoch 2: current best loss = 2.19467, at epoch 0
Train batch 1/32 - 106.7ms/batch - loss: 1.73890 - diff: 27.82mlTrain batch 2/32 - 95.4ms/batch - loss: 1.60702 - diff: 25.71mlTrain batch 3/32 - 94.8ms/batch - loss: 1.54811 - diff: 24.77mlTrain batch 4/32 - 89.2ms/batch - loss: 1.68251 - diff: 26.92mlTrain batch 5/32 - 62.9ms/batch - loss: 1.60227 - diff: 25.64mlTrain batch 6/32 - 75.2ms/batch - loss: 1.68487 - diff: 26.96mlTrain batch 7/32 - 88.0ms/batch - loss: 1.70298 - diff: 27.25mlTrain batch 8/32 - 74.3ms/batch - loss: 1.84897 - diff: 29.58mlTrain batch 9/32 - 59.5ms/batch - loss: 1.81652 - diff: 29.06mlTrain batch 10/32 - 96.1ms/batch - loss: 1.87732 - diff: 30.04mlTrain batch 11/32 - 99.2ms/batch - loss: 1.94836 - diff: 31.17mlTrain batch 12/32 - 89.1ms/batch - loss: 1.86261 - diff: 29.80mlTrain batch 13/32 - 120.1ms/batch - loss: 1.98806 - diff: 31.81mlTrain batch 14/32 - 99.3ms/batch - loss: 2.00426 - diff: 32.07mlTrain batch 15/32 - 107.4ms/batch - loss: 2.05301 - diff: 32.85mlTrain batch 16/32 - 90.0ms/batch - loss: 2.02618 - diff: 32.42mlTrain batch 17/32 - 62.7ms/batch - loss: 1.98182 - diff: 31.71mlTrain batch 18/32 - 81.7ms/batch - loss: 1.99230 - diff: 31.88mlTrain batch 19/32 - 83.7ms/batch - loss: 1.93963 - diff: 31.03mlTrain batch 20/32 - 74.3ms/batch - loss: 1.91344 - diff: 30.61mlTrain batch 21/32 - 76.9ms/batch - loss: 1.87603 - diff: 30.02mlTrain batch 22/32 - 75.2ms/batch - loss: 1.86113 - diff: 29.78mlTrain batch 23/32 - 76.6ms/batch - loss: 1.83412 - diff: 29.35mlTrain batch 24/32 - 88.2ms/batch - loss: 1.86537 - diff: 29.85mlTrain batch 25/32 - 64.1ms/batch - loss: 1.85126 - diff: 29.62mlTrain batch 26/32 - 93.7ms/batch - loss: 1.82815 - diff: 29.25mlTrain batch 27/32 - 94.6ms/batch - loss: 1.79771 - diff: 28.76mlTrain batch 28/32 - 95.9ms/batch - loss: 1.81820 - diff: 29.09mlTrain batch 29/32 - 102.5ms/batch - loss: 1.82621 - diff: 29.22mlTrain batch 30/32 - 71.8ms/batch - loss: 1.82628 - diff: 29.22mlTrain batch 31/32 - 83.8ms/batch - loss: 1.81141 - diff: 28.98mlTrain batch 32/32 - 65.1ms/batch - loss: 1.84145 - diff: 28.93mlTrain batch 32/32 - 15.8s 65.1ms/batch - loss: 1.84145 - diff: 28.93ml
Test 1.0s: val_loss: 1.85938 - diff: 27.76ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Systole_DenseNet121_0_Adam-0.001_MAE_DA3_best

Epoch 3: current best loss = 1.85938, at epoch 2
Train batch 1/32 - 91.1ms/batch - loss: 1.36035 - diff: 21.77mlTrain batch 2/32 - 94.0ms/batch - loss: 1.64302 - diff: 26.29mlTrain batch 3/32 - 78.3ms/batch - loss: 1.77522 - diff: 28.40mlTrain batch 4/32 - 126.3ms/batch - loss: 1.70996 - diff: 27.36mlTrain batch 5/32 - 62.2ms/batch - loss: 1.66004 - diff: 26.56mlTrain batch 6/32 - 66.9ms/batch - loss: 1.86227 - diff: 29.80mlTrain batch 7/32 - 108.0ms/batch - loss: 1.91792 - diff: 30.69mlTrain batch 8/32 - 104.5ms/batch - loss: 1.88936 - diff: 30.23mlTrain batch 9/32 - 78.2ms/batch - loss: 1.93945 - diff: 31.03mlTrain batch 10/32 - 85.5ms/batch - loss: 1.94205 - diff: 31.07mlTrain batch 11/32 - 75.1ms/batch - loss: 1.91337 - diff: 30.61mlTrain batch 12/32 - 80.8ms/batch - loss: 1.95265 - diff: 31.24mlTrain batch 13/32 - 85.1ms/batch - loss: 2.04902 - diff: 32.78mlTrain batch 14/32 - 76.3ms/batch - loss: 1.99578 - diff: 31.93mlTrain batch 15/32 - 75.3ms/batch - loss: 1.97040 - diff: 31.53mlTrain batch 16/32 - 89.5ms/batch - loss: 1.96498 - diff: 31.44mlTrain batch 17/32 - 76.2ms/batch - loss: 1.95536 - diff: 31.29mlTrain batch 18/32 - 99.4ms/batch - loss: 1.91746 - diff: 30.68mlTrain batch 19/32 - 76.1ms/batch - loss: 1.89049 - diff: 30.25mlTrain batch 20/32 - 79.6ms/batch - loss: 1.88510 - diff: 30.16mlTrain batch 21/32 - 70.7ms/batch - loss: 1.88667 - diff: 30.19mlTrain batch 22/32 - 80.8ms/batch - loss: 1.87257 - diff: 29.96mlTrain batch 23/32 - 71.6ms/batch - loss: 1.85883 - diff: 29.74mlTrain batch 24/32 - 78.2ms/batch - loss: 1.85438 - diff: 29.67mlTrain batch 25/32 - 84.0ms/batch - loss: 1.89711 - diff: 30.35mlTrain batch 26/32 - 97.3ms/batch - loss: 1.88472 - diff: 30.16mlTrain batch 27/32 - 68.4ms/batch - loss: 1.85201 - diff: 29.63mlTrain batch 28/32 - 88.6ms/batch - loss: 1.83576 - diff: 29.37mlTrain batch 29/32 - 78.2ms/batch - loss: 1.83137 - diff: 29.30mlTrain batch 30/32 - 98.3ms/batch - loss: 1.81468 - diff: 29.03mlTrain batch 31/32 - 64.4ms/batch - loss: 1.81543 - diff: 29.05mlTrain batch 32/32 - 58.0ms/batch - loss: 1.86838 - diff: 29.08mlTrain batch 32/32 - 16.5s 58.0ms/batch - loss: 1.86838 - diff: 29.08ml
Test 0.9s: val_loss: 1.83962 - diff: 28.46ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Systole_DenseNet121_0_Adam-0.001_MAE_DA3_best

Epoch 4: current best loss = 1.83962, at epoch 3
Train batch 1/32 - 129.6ms/batch - loss: 1.47584 - diff: 23.61mlTrain batch 2/32 - 116.9ms/batch - loss: 1.83603 - diff: 29.38mlTrain batch 3/32 - 75.2ms/batch - loss: 2.54376 - diff: 40.70mlTrain batch 4/32 - 80.0ms/batch - loss: 2.16050 - diff: 34.57mlTrain batch 5/32 - 94.5ms/batch - loss: 2.06973 - diff: 33.12mlTrain batch 6/32 - 92.3ms/batch - loss: 2.19244 - diff: 35.08mlTrain batch 7/32 - 85.2ms/batch - loss: 2.08628 - diff: 33.38mlTrain batch 8/32 - 72.1ms/batch - loss: 2.01403 - diff: 32.22mlTrain batch 9/32 - 82.2ms/batch - loss: 1.91496 - diff: 30.64mlTrain batch 10/32 - 91.9ms/batch - loss: 1.86556 - diff: 29.85mlTrain batch 11/32 - 94.3ms/batch - loss: 1.83694 - diff: 29.39mlTrain batch 12/32 - 66.3ms/batch - loss: 1.78539 - diff: 28.57mlTrain batch 13/32 - 62.2ms/batch - loss: 1.73964 - diff: 27.83mlTrain batch 14/32 - 62.0ms/batch - loss: 1.80116 - diff: 28.82mlTrain batch 15/32 - 60.1ms/batch - loss: 1.79643 - diff: 28.74mlTrain batch 16/32 - 75.0ms/batch - loss: 1.77765 - diff: 28.44mlTrain batch 17/32 - 80.5ms/batch - loss: 1.75037 - diff: 28.01mlTrain batch 18/32 - 68.7ms/batch - loss: 1.73193 - diff: 27.71mlTrain batch 19/32 - 58.8ms/batch - loss: 1.75298 - diff: 28.05mlTrain batch 20/32 - 71.9ms/batch - loss: 1.75200 - diff: 28.03mlTrain batch 21/32 - 60.2ms/batch - loss: 1.76316 - diff: 28.21mlTrain batch 22/32 - 80.1ms/batch - loss: 1.77857 - diff: 28.46mlTrain batch 23/32 - 88.0ms/batch - loss: 1.78490 - diff: 28.56mlTrain batch 24/32 - 80.6ms/batch - loss: 1.77752 - diff: 28.44mlTrain batch 25/32 - 92.9ms/batch - loss: 1.78364 - diff: 28.54mlTrain batch 26/32 - 76.4ms/batch - loss: 1.76269 - diff: 28.20mlTrain batch 27/32 - 66.6ms/batch - loss: 1.77360 - diff: 28.38mlTrain batch 28/32 - 76.6ms/batch - loss: 1.76598 - diff: 28.26mlTrain batch 29/32 - 68.2ms/batch - loss: 1.74854 - diff: 27.98mlTrain batch 30/32 - 75.2ms/batch - loss: 1.74716 - diff: 27.95mlTrain batch 31/32 - 61.1ms/batch - loss: 1.74873 - diff: 27.98mlTrain batch 32/32 - 49.8ms/batch - loss: 1.78423 - diff: 27.95mlTrain batch 32/32 - 16.7s 49.8ms/batch - loss: 1.78423 - diff: 27.95ml
Test 0.8s: val_loss: 1.68832 - diff: 26.41ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Systole_DenseNet121_0_Adam-0.001_MAE_DA3_best

Epoch 5: current best loss = 1.68832, at epoch 4
Train batch 1/32 - 95.0ms/batch - loss: 2.05561 - diff: 32.89mlTrain batch 2/32 - 81.8ms/batch - loss: 2.07563 - diff: 33.21mlTrain batch 3/32 - 78.1ms/batch - loss: 1.91775 - diff: 30.68mlTrain batch 4/32 - 131.8ms/batch - loss: 1.93355 - diff: 30.94mlTrain batch 5/32 - 80.9ms/batch - loss: 1.92112 - diff: 30.74mlTrain batch 6/32 - 77.5ms/batch - loss: 2.17375 - diff: 34.78mlTrain batch 7/32 - 79.2ms/batch - loss: 2.02963 - diff: 32.47mlTrain batch 8/32 - 56.6ms/batch - loss: 1.99697 - diff: 31.95mlTrain batch 9/32 - 77.7ms/batch - loss: 1.90293 - diff: 30.45mlTrain batch 10/32 - 91.3ms/batch - loss: 1.91325 - diff: 30.61mlTrain batch 11/32 - 93.2ms/batch - loss: 1.86768 - diff: 29.88mlTrain batch 12/32 - 90.3ms/batch - loss: 1.94183 - diff: 31.07mlTrain batch 13/32 - 95.6ms/batch - loss: 1.92810 - diff: 30.85mlTrain batch 14/32 - 79.7ms/batch - loss: 1.87541 - diff: 30.01mlTrain batch 15/32 - 117.2ms/batch - loss: 1.81533 - diff: 29.05mlTrain batch 16/32 - 102.8ms/batch - loss: 1.82726 - diff: 29.24mlTrain batch 17/32 - 80.7ms/batch - loss: 1.80717 - diff: 28.91mlTrain batch 18/32 - 102.3ms/batch - loss: 1.79909 - diff: 28.79mlTrain batch 19/32 - 59.7ms/batch - loss: 1.76804 - diff: 28.29mlTrain batch 20/32 - 60.9ms/batch - loss: 1.76721 - diff: 28.28mlTrain batch 21/32 - 77.3ms/batch - loss: 1.72946 - diff: 27.67mlTrain batch 22/32 - 79.3ms/batch - loss: 1.72910 - diff: 27.67mlTrain batch 23/32 - 78.0ms/batch - loss: 1.73276 - diff: 27.72mlTrain batch 24/32 - 90.0ms/batch - loss: 1.76925 - diff: 28.31mlTrain batch 25/32 - 87.7ms/batch - loss: 1.76198 - diff: 28.19mlTrain batch 26/32 - 73.4ms/batch - loss: 1.76774 - diff: 28.28mlTrain batch 27/32 - 70.6ms/batch - loss: 1.74178 - diff: 27.87mlTrain batch 28/32 - 73.7ms/batch - loss: 1.71723 - diff: 27.48mlTrain batch 29/32 - 85.7ms/batch - loss: 1.72347 - diff: 27.58mlTrain batch 30/32 - 101.3ms/batch - loss: 1.73913 - diff: 27.83mlTrain batch 31/32 - 67.3ms/batch - loss: 1.73595 - diff: 27.78mlTrain batch 32/32 - 80.9ms/batch - loss: 1.76870 - diff: 27.74mlTrain batch 32/32 - 15.8s 80.9ms/batch - loss: 1.76870 - diff: 27.74ml
Test 0.9s: val_loss: 1.62373 - diff: 25.24ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Systole_DenseNet121_0_Adam-0.001_MAE_DA3_best

Epoch 6: current best loss = 1.62373, at epoch 5
Train batch 1/32 - 112.1ms/batch - loss: 1.26812 - diff: 20.29mlTrain batch 2/32 - 97.3ms/batch - loss: 1.45078 - diff: 23.21mlTrain batch 3/32 - 95.9ms/batch - loss: 1.71808 - diff: 27.49mlTrain batch 4/32 - 86.6ms/batch - loss: 1.58239 - diff: 25.32mlTrain batch 5/32 - 82.6ms/batch - loss: 1.58218 - diff: 25.31mlTrain batch 6/32 - 74.9ms/batch - loss: 1.56216 - diff: 24.99mlTrain batch 7/32 - 111.9ms/batch - loss: 1.50706 - diff: 24.11mlTrain batch 8/32 - 58.8ms/batch - loss: 1.57857 - diff: 25.26mlTrain batch 9/32 - 115.9ms/batch - loss: 1.61167 - diff: 25.79mlTrain batch 10/32 - 73.5ms/batch - loss: 1.57333 - diff: 25.17mlTrain batch 11/32 - 71.1ms/batch - loss: 1.62982 - diff: 26.08mlTrain batch 12/32 - 80.8ms/batch - loss: 1.59843 - diff: 25.57mlTrain batch 13/32 - 66.1ms/batch - loss: 1.60767 - diff: 25.72mlTrain batch 14/32 - 79.9ms/batch - loss: 1.62208 - diff: 25.95mlTrain batch 15/32 - 78.5ms/batch - loss: 1.59883 - diff: 25.58mlTrain batch 16/32 - 78.8ms/batch - loss: 1.73168 - diff: 27.71mlTrain batch 17/32 - 91.7ms/batch - loss: 1.71418 - diff: 27.43mlTrain batch 18/32 - 92.5ms/batch - loss: 1.73737 - diff: 27.80mlTrain batch 19/32 - 93.3ms/batch - loss: 1.69877 - diff: 27.18mlTrain batch 20/32 - 98.2ms/batch - loss: 1.71835 - diff: 27.49mlTrain batch 21/32 - 88.9ms/batch - loss: 1.70431 - diff: 27.27mlTrain batch 22/32 - 78.3ms/batch - loss: 1.67554 - diff: 26.81mlTrain batch 23/32 - 105.5ms/batch - loss: 1.65604 - diff: 26.50mlTrain batch 24/32 - 77.1ms/batch - loss: 1.67289 - diff: 26.77mlTrain batch 25/32 - 74.9ms/batch - loss: 1.64765 - diff: 26.36mlTrain batch 26/32 - 94.5ms/batch - loss: 1.64884 - diff: 26.38mlTrain batch 27/32 - 88.5ms/batch - loss: 1.67228 - diff: 26.76mlTrain batch 28/32 - 96.9ms/batch - loss: 1.65274 - diff: 26.44mlTrain batch 29/32 - 94.5ms/batch - loss: 1.63178 - diff: 26.11mlTrain batch 30/32 - 71.4ms/batch - loss: 1.63000 - diff: 26.08mlTrain batch 31/32 - 71.4ms/batch - loss: 1.66531 - diff: 26.64mlTrain batch 32/32 - 75.7ms/batch - loss: 1.70355 - diff: 26.64mlTrain batch 32/32 - 16.3s 75.7ms/batch - loss: 1.70355 - diff: 26.64ml
Test 1.0s: val_loss: 1.60621 - diff: 25.03ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Systole_DenseNet121_0_Adam-0.001_MAE_DA3_best

Epoch 7: current best loss = 1.60621, at epoch 6
Train batch 1/32 - 73.3ms/batch - loss: 1.87533 - diff: 30.01mlTrain batch 2/32 - 81.8ms/batch - loss: 1.72711 - diff: 27.63mlTrain batch 3/32 - 77.9ms/batch - loss: 1.72899 - diff: 27.66mlTrain batch 4/32 - 77.6ms/batch - loss: 1.68568 - diff: 26.97mlTrain batch 5/32 - 61.7ms/batch - loss: 1.58599 - diff: 25.38mlTrain batch 6/32 - 63.4ms/batch - loss: 1.55987 - diff: 24.96mlTrain batch 7/32 - 96.5ms/batch - loss: 1.53171 - diff: 24.51mlTrain batch 8/32 - 106.8ms/batch - loss: 1.55306 - diff: 24.85mlTrain batch 9/32 - 97.6ms/batch - loss: 1.68068 - diff: 26.89mlTrain batch 10/32 - 101.1ms/batch - loss: 1.66351 - diff: 26.62mlTrain batch 11/32 - 77.4ms/batch - loss: 1.69547 - diff: 27.13mlTrain batch 12/32 - 99.3ms/batch - loss: 1.65237 - diff: 26.44mlTrain batch 13/32 - 78.0ms/batch - loss: 1.63421 - diff: 26.15mlTrain batch 14/32 - 135.3ms/batch - loss: 1.63901 - diff: 26.22mlTrain batch 15/32 - 90.9ms/batch - loss: 1.64303 - diff: 26.29mlTrain batch 16/32 - 109.0ms/batch - loss: 1.68486 - diff: 26.96mlTrain batch 17/32 - 81.2ms/batch - loss: 1.69890 - diff: 27.18mlTrain batch 18/32 - 82.1ms/batch - loss: 1.70104 - diff: 27.22mlTrain batch 19/32 - 98.2ms/batch - loss: 1.68772 - diff: 27.00mlTrain batch 20/32 - 62.0ms/batch - loss: 1.67484 - diff: 26.80mlTrain batch 21/32 - 93.0ms/batch - loss: 1.71934 - diff: 27.51mlTrain batch 22/32 - 60.9ms/batch - loss: 1.70482 - diff: 27.28mlTrain batch 23/32 - 79.3ms/batch - loss: 1.71482 - diff: 27.44mlTrain batch 24/32 - 69.0ms/batch - loss: 1.68704 - diff: 26.99mlTrain batch 25/32 - 92.4ms/batch - loss: 1.67750 - diff: 26.84mlTrain batch 26/32 - 69.5ms/batch - loss: 1.65107 - diff: 26.42mlTrain batch 27/32 - 72.1ms/batch - loss: 1.67727 - diff: 26.84mlTrain batch 28/32 - 76.9ms/batch - loss: 1.67792 - diff: 26.85mlTrain batch 29/32 - 88.1ms/batch - loss: 1.66249 - diff: 26.60mlTrain batch 30/32 - 87.9ms/batch - loss: 1.70788 - diff: 27.33mlTrain batch 31/32 - 91.5ms/batch - loss: 1.68497 - diff: 26.96mlTrain batch 32/32 - 63.3ms/batch - loss: 1.72895 - diff: 26.97mlTrain batch 32/32 - 16.4s 63.3ms/batch - loss: 1.72895 - diff: 26.97ml
Test 0.9s: val_loss: 1.61671 - diff: 25.14ml

Epoch 8: current best loss = 1.60621, at epoch 6
Train batch 1/32 - 109.6ms/batch - loss: 1.98822 - diff: 31.81mlTrain batch 2/32 - 74.4ms/batch - loss: 2.42195 - diff: 38.75mlTrain batch 3/32 - 97.4ms/batch - loss: 2.59314 - diff: 41.49mlTrain batch 4/32 - 109.3ms/batch - loss: 2.18584 - diff: 34.97mlTrain batch 5/32 - 84.4ms/batch - loss: 1.99079 - diff: 31.85mlTrain batch 6/32 - 101.1ms/batch - loss: 1.78842 - diff: 28.61mlTrain batch 7/32 - 77.5ms/batch - loss: 1.73164 - diff: 27.71mlTrain batch 8/32 - 72.2ms/batch - loss: 1.80197 - diff: 28.83mlTrain batch 9/32 - 85.8ms/batch - loss: 1.81398 - diff: 29.02mlTrain batch 10/32 - 84.0ms/batch - loss: 1.79828 - diff: 28.77mlTrain batch 11/32 - 80.6ms/batch - loss: 1.73227 - diff: 27.72mlTrain batch 12/32 - 96.0ms/batch - loss: 1.75554 - diff: 28.09mlTrain batch 13/32 - 66.6ms/batch - loss: 1.73175 - diff: 27.71mlTrain batch 14/32 - 97.4ms/batch - loss: 1.73029 - diff: 27.68mlTrain batch 15/32 - 84.7ms/batch - loss: 1.68250 - diff: 26.92mlTrain batch 16/32 - 59.5ms/batch - loss: 1.67544 - diff: 26.81mlTrain batch 17/32 - 86.5ms/batch - loss: 1.64826 - diff: 26.37mlTrain batch 18/32 - 75.7ms/batch - loss: 1.60062 - diff: 25.61mlTrain batch 19/32 - 77.7ms/batch - loss: 1.61587 - diff: 25.85mlTrain batch 20/32 - 76.7ms/batch - loss: 1.60542 - diff: 25.69mlTrain batch 21/32 - 70.3ms/batch - loss: 1.58945 - diff: 25.43mlTrain batch 22/32 - 88.5ms/batch - loss: 1.61392 - diff: 25.82mlTrain batch 23/32 - 78.3ms/batch - loss: 1.60609 - diff: 25.70mlTrain batch 24/32 - 85.5ms/batch - loss: 1.64790 - diff: 26.37mlTrain batch 25/32 - 113.0ms/batch - loss: 1.64934 - diff: 26.39mlTrain batch 26/32 - 73.7ms/batch - loss: 1.64361 - diff: 26.30mlTrain batch 27/32 - 83.7ms/batch - loss: 1.64587 - diff: 26.33mlTrain batch 28/32 - 91.7ms/batch - loss: 1.64597 - diff: 26.34mlTrain batch 29/32 - 61.9ms/batch - loss: 1.64634 - diff: 26.34mlTrain batch 30/32 - 57.1ms/batch - loss: 1.63651 - diff: 26.18mlTrain batch 31/32 - 88.4ms/batch - loss: 1.62622 - diff: 26.02mlTrain batch 32/32 - 57.6ms/batch - loss: 1.63929 - diff: 25.92mlTrain batch 32/32 - 14.9s 57.6ms/batch - loss: 1.63929 - diff: 25.92ml
Test 0.9s: val_loss: 1.57150 - diff: 24.16ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Systole_DenseNet121_0_Adam-0.001_MAE_DA3_best

Epoch 9: current best loss = 1.57150, at epoch 8
Train batch 1/32 - 97.3ms/batch - loss: 1.48150 - diff: 23.70mlTrain batch 2/32 - 66.8ms/batch - loss: 1.71154 - diff: 27.38mlTrain batch 3/32 - 57.9ms/batch - loss: 1.47723 - diff: 23.64mlTrain batch 4/32 - 72.7ms/batch - loss: 1.45800 - diff: 23.33mlTrain batch 5/32 - 81.5ms/batch - loss: 1.52056 - diff: 24.33mlTrain batch 6/32 - 81.7ms/batch - loss: 1.48164 - diff: 23.71mlTrain batch 7/32 - 65.9ms/batch - loss: 1.43795 - diff: 23.01mlTrain batch 8/32 - 94.2ms/batch - loss: 1.43037 - diff: 22.89mlTrain batch 9/32 - 106.8ms/batch - loss: 1.36933 - diff: 21.91mlTrain batch 10/32 - 83.7ms/batch - loss: 1.48596 - diff: 23.78mlTrain batch 11/32 - 72.1ms/batch - loss: 1.43442 - diff: 22.95mlTrain batch 12/32 - 76.8ms/batch - loss: 1.41897 - diff: 22.70mlTrain batch 13/32 - 61.4ms/batch - loss: 1.45067 - diff: 23.21mlTrain batch 14/32 - 61.1ms/batch - loss: 1.49336 - diff: 23.89mlTrain batch 15/32 - 63.8ms/batch - loss: 1.52767 - diff: 24.44mlTrain batch 16/32 - 94.6ms/batch - loss: 1.54562 - diff: 24.73mlTrain batch 17/32 - 97.0ms/batch - loss: 1.59574 - diff: 25.53mlTrain batch 18/32 - 80.4ms/batch - loss: 1.62827 - diff: 26.05mlTrain batch 19/32 - 60.8ms/batch - loss: 1.70456 - diff: 27.27mlTrain batch 20/32 - 76.3ms/batch - loss: 1.67442 - diff: 26.79mlTrain batch 21/32 - 80.7ms/batch - loss: 1.65485 - diff: 26.48mlTrain batch 22/32 - 86.4ms/batch - loss: 1.64247 - diff: 26.28mlTrain batch 23/32 - 90.8ms/batch - loss: 1.65260 - diff: 26.44mlTrain batch 24/32 - 79.8ms/batch - loss: 1.67226 - diff: 26.76mlTrain batch 25/32 - 94.3ms/batch - loss: 1.70078 - diff: 27.21mlTrain batch 26/32 - 81.7ms/batch - loss: 1.70171 - diff: 27.23mlTrain batch 27/32 - 90.0ms/batch - loss: 1.71385 - diff: 27.42mlTrain batch 28/32 - 84.5ms/batch - loss: 1.69150 - diff: 27.06mlTrain batch 29/32 - 92.3ms/batch - loss: 1.67686 - diff: 26.83mlTrain batch 30/32 - 78.3ms/batch - loss: 1.66518 - diff: 26.64mlTrain batch 31/32 - 95.6ms/batch - loss: 1.67914 - diff: 26.87mlTrain batch 32/32 - 71.1ms/batch - loss: 1.69070 - diff: 26.75mlTrain batch 32/32 - 17.2s 71.1ms/batch - loss: 1.69070 - diff: 26.75ml
Test 0.9s: val_loss: 1.70939 - diff: 25.96ml

Epoch 10: current best loss = 1.57150, at epoch 8
Train batch 1/32 - 97.4ms/batch - loss: 1.31331 - diff: 21.01mlTrain batch 2/32 - 74.8ms/batch - loss: 1.49648 - diff: 23.94mlTrain batch 3/32 - 86.8ms/batch - loss: 1.37795 - diff: 22.05mlTrain batch 4/32 - 83.3ms/batch - loss: 1.42687 - diff: 22.83mlTrain batch 5/32 - 89.9ms/batch - loss: 1.37871 - diff: 22.06mlTrain batch 6/32 - 94.4ms/batch - loss: 1.50605 - diff: 24.10mlTrain batch 7/32 - 59.5ms/batch - loss: 1.48294 - diff: 23.73mlTrain batch 8/32 - 71.3ms/batch - loss: 1.56977 - diff: 25.12mlTrain batch 9/32 - 96.7ms/batch - loss: 1.52168 - diff: 24.35mlTrain batch 10/32 - 99.0ms/batch - loss: 1.59617 - diff: 25.54mlTrain batch 11/32 - 103.8ms/batch - loss: 1.61338 - diff: 25.81mlTrain batch 12/32 - 61.4ms/batch - loss: 1.59973 - diff: 25.60mlTrain batch 13/32 - 111.9ms/batch - loss: 1.63397 - diff: 26.14mlTrain batch 14/32 - 62.2ms/batch - loss: 1.61463 - diff: 25.83mlTrain batch 15/32 - 66.0ms/batch - loss: 1.68700 - diff: 26.99mlTrain batch 16/32 - 63.0ms/batch - loss: 1.68785 - diff: 27.01mlTrain batch 17/32 - 95.3ms/batch - loss: 1.69748 - diff: 27.16mlTrain batch 18/32 - 91.6ms/batch - loss: 1.69224 - diff: 27.08mlTrain batch 19/32 - 82.0ms/batch - loss: 1.69296 - diff: 27.09mlTrain batch 20/32 - 67.5ms/batch - loss: 1.67693 - diff: 26.83mlTrain batch 21/32 - 98.7ms/batch - loss: 1.64901 - diff: 26.38mlTrain batch 22/32 - 93.1ms/batch - loss: 1.63848 - diff: 26.22mlTrain batch 23/32 - 91.6ms/batch - loss: 1.63320 - diff: 26.13mlTrain batch 24/32 - 87.4ms/batch - loss: 1.67982 - diff: 26.88mlTrain batch 25/32 - 91.7ms/batch - loss: 1.65664 - diff: 26.51mlTrain batch 26/32 - 126.2ms/batch - loss: 1.66755 - diff: 26.68mlTrain batch 27/32 - 75.1ms/batch - loss: 1.65681 - diff: 26.51mlTrain batch 28/32 - 99.4ms/batch - loss: 1.65106 - diff: 26.42mlTrain batch 29/32 - 68.8ms/batch - loss: 1.64912 - diff: 26.39mlTrain batch 30/32 - 74.3ms/batch - loss: 1.64418 - diff: 26.31mlTrain batch 31/32 - 62.7ms/batch - loss: 1.64837 - diff: 26.37mlTrain batch 32/32 - 91.7ms/batch - loss: 1.68855 - diff: 26.38mlTrain batch 32/32 - 17.2s 91.7ms/batch - loss: 1.68855 - diff: 26.38ml
Test 0.8s: val_loss: 1.76839 - diff: 27.33ml

Epoch 11: current best loss = 1.57150, at epoch 8
Train batch 1/32 - 107.5ms/batch - loss: 1.78171 - diff: 28.51mlTrain batch 2/32 - 80.3ms/batch - loss: 1.44308 - diff: 23.09mlTrain batch 3/32 - 77.5ms/batch - loss: 1.51397 - diff: 24.22mlTrain batch 4/32 - 75.3ms/batch - loss: 1.48635 - diff: 23.78mlTrain batch 5/32 - 82.1ms/batch - loss: 1.62805 - diff: 26.05mlTrain batch 6/32 - 115.9ms/batch - loss: 1.55159 - diff: 24.83mlTrain batch 7/32 - 64.0ms/batch - loss: 1.50167 - diff: 24.03mlTrain batch 8/32 - 92.5ms/batch - loss: 1.84833 - diff: 29.57mlTrain batch 9/32 - 68.4ms/batch - loss: 1.84594 - diff: 29.54mlTrain batch 10/32 - 66.8ms/batch - loss: 1.75664 - diff: 28.11mlTrain batch 11/32 - 72.1ms/batch - loss: 1.72792 - diff: 27.65mlTrain batch 12/32 - 76.8ms/batch - loss: 1.66173 - diff: 26.59mlTrain batch 13/32 - 79.2ms/batch - loss: 1.64024 - diff: 26.24mlTrain batch 14/32 - 80.1ms/batch - loss: 1.61121 - diff: 25.78mlTrain batch 15/32 - 94.8ms/batch - loss: 1.61207 - diff: 25.79mlTrain batch 16/32 - 90.0ms/batch - loss: 1.64415 - diff: 26.31mlTrain batch 17/32 - 66.6ms/batch - loss: 1.68386 - diff: 26.94mlTrain batch 18/32 - 104.4ms/batch - loss: 1.69196 - diff: 27.07mlTrain batch 19/32 - 83.6ms/batch - loss: 1.69019 - diff: 27.04mlTrain batch 20/32 - 103.0ms/batch - loss: 1.69234 - diff: 27.08mlTrain batch 21/32 - 81.5ms/batch - loss: 1.71424 - diff: 27.43mlTrain batch 22/32 - 60.0ms/batch - loss: 1.69106 - diff: 27.06mlTrain batch 23/32 - 87.5ms/batch - loss: 1.70641 - diff: 27.30mlTrain batch 24/32 - 86.9ms/batch - loss: 1.69280 - diff: 27.08mlTrain batch 25/32 - 83.9ms/batch - loss: 1.65859 - diff: 26.54mlTrain batch 26/32 - 61.7ms/batch - loss: 1.65816 - diff: 26.53mlTrain batch 27/32 - 72.6ms/batch - loss: 1.64500 - diff: 26.32mlTrain batch 28/32 - 63.3ms/batch - loss: 1.63205 - diff: 26.11mlTrain batch 29/32 - 86.1ms/batch - loss: 1.61561 - diff: 25.85mlTrain batch 30/32 - 63.5ms/batch - loss: 1.60630 - diff: 25.70mlTrain batch 31/32 - 64.9ms/batch - loss: 1.60554 - diff: 25.69mlTrain batch 32/32 - 76.5ms/batch - loss: 1.64425 - diff: 25.69mlTrain batch 32/32 - 15.8s 76.5ms/batch - loss: 1.64425 - diff: 25.69ml
Test 0.9s: val_loss: 1.64038 - diff: 25.09ml

Epoch 12: current best loss = 1.57150, at epoch 8
Train batch 1/32 - 93.5ms/batch - loss: 0.87641 - diff: 14.02mlTrain batch 2/32 - 99.1ms/batch - loss: 1.12457 - diff: 17.99mlTrain batch 3/32 - 101.3ms/batch - loss: 1.52753 - diff: 24.44mlTrain batch 4/32 - 90.7ms/batch - loss: 1.45423 - diff: 23.27mlTrain batch 5/32 - 74.0ms/batch - loss: 1.49544 - diff: 23.93mlTrain batch 6/32 - 100.0ms/batch - loss: 1.40037 - diff: 22.41mlTrain batch 7/32 - 113.6ms/batch - loss: 1.37300 - diff: 21.97mlTrain batch 8/32 - 86.2ms/batch - loss: 1.39848 - diff: 22.38mlTrain batch 9/32 - 94.5ms/batch - loss: 1.39312 - diff: 22.29mlTrain batch 10/32 - 92.1ms/batch - loss: 1.45013 - diff: 23.20mlTrain batch 11/32 - 79.2ms/batch - loss: 1.46393 - diff: 23.42mlTrain batch 12/32 - 91.6ms/batch - loss: 1.41951 - diff: 22.71mlTrain batch 13/32 - 61.5ms/batch - loss: 1.43516 - diff: 22.96mlTrain batch 14/32 - 76.6ms/batch - loss: 1.43788 - diff: 23.01mlTrain batch 15/32 - 82.5ms/batch - loss: 1.43459 - diff: 22.95mlTrain batch 16/32 - 91.0ms/batch - loss: 1.47987 - diff: 23.68mlTrain batch 17/32 - 84.9ms/batch - loss: 1.48135 - diff: 23.70mlTrain batch 18/32 - 75.9ms/batch - loss: 1.52864 - diff: 24.46mlTrain batch 19/32 - 103.7ms/batch - loss: 1.56550 - diff: 25.05mlTrain batch 20/32 - 92.3ms/batch - loss: 1.57249 - diff: 25.16mlTrain batch 21/32 - 102.7ms/batch - loss: 1.56966 - diff: 25.11mlTrain batch 22/32 - 115.1ms/batch - loss: 1.56667 - diff: 25.07mlTrain batch 23/32 - 119.0ms/batch - loss: 1.57045 - diff: 25.13mlTrain batch 24/32 - 104.0ms/batch - loss: 1.65447 - diff: 26.47mlTrain batch 25/32 - 80.7ms/batch - loss: 1.63655 - diff: 26.18mlTrain batch 26/32 - 88.6ms/batch - loss: 1.62206 - diff: 25.95mlTrain batch 27/32 - 77.6ms/batch - loss: 1.61841 - diff: 25.89mlTrain batch 28/32 - 73.1ms/batch - loss: 1.61602 - diff: 25.86mlTrain batch 29/32 - 82.9ms/batch - loss: 1.64032 - diff: 26.25mlTrain batch 30/32 - 90.8ms/batch - loss: 1.63326 - diff: 26.13mlTrain batch 31/32 - 82.1ms/batch - loss: 1.63056 - diff: 26.09mlTrain batch 32/32 - 81.4ms/batch - loss: 1.64073 - diff: 25.97mlTrain batch 32/32 - 15.6s 81.4ms/batch - loss: 1.64073 - diff: 25.97ml
Test 0.9s: val_loss: 1.74269 - diff: 26.37ml

Epoch 13: current best loss = 1.57150, at epoch 8
Train batch 1/32 - 107.8ms/batch - loss: 1.46966 - diff: 23.51mlTrain batch 2/32 - 96.9ms/batch - loss: 1.56741 - diff: 25.08mlTrain batch 3/32 - 82.3ms/batch - loss: 1.51885 - diff: 24.30mlTrain batch 4/32 - 104.0ms/batch - loss: 1.45975 - diff: 23.36mlTrain batch 5/32 - 96.9ms/batch - loss: 1.38131 - diff: 22.10mlTrain batch 6/32 - 92.0ms/batch - loss: 1.53037 - diff: 24.49mlTrain batch 7/32 - 90.9ms/batch - loss: 1.56675 - diff: 25.07mlTrain batch 8/32 - 94.7ms/batch - loss: 1.54521 - diff: 24.72mlTrain batch 9/32 - 111.4ms/batch - loss: 1.53321 - diff: 24.53mlTrain batch 10/32 - 109.0ms/batch - loss: 1.50184 - diff: 24.03mlTrain batch 11/32 - 85.2ms/batch - loss: 1.53347 - diff: 24.54mlTrain batch 12/32 - 99.6ms/batch - loss: 1.59879 - diff: 25.58mlTrain batch 13/32 - 78.8ms/batch - loss: 1.58499 - diff: 25.36mlTrain batch 14/32 - 103.5ms/batch - loss: 1.55041 - diff: 24.81mlTrain batch 15/32 - 66.5ms/batch - loss: 1.54365 - diff: 24.70mlTrain batch 16/32 - 82.1ms/batch - loss: 1.53265 - diff: 24.52mlTrain batch 17/32 - 89.3ms/batch - loss: 1.56210 - diff: 24.99mlTrain batch 18/32 - 87.0ms/batch - loss: 1.55192 - diff: 24.83mlTrain batch 19/32 - 85.0ms/batch - loss: 1.55084 - diff: 24.81mlTrain batch 20/32 - 78.8ms/batch - loss: 1.57768 - diff: 25.24mlTrain batch 21/32 - 84.0ms/batch - loss: 1.57546 - diff: 25.21mlTrain batch 22/32 - 76.9ms/batch - loss: 1.62086 - diff: 25.93mlTrain batch 23/32 - 132.2ms/batch - loss: 1.67278 - diff: 26.76mlTrain batch 24/32 - 61.1ms/batch - loss: 1.65931 - diff: 26.55mlTrain batch 25/32 - 71.3ms/batch - loss: 1.64907 - diff: 26.39mlTrain batch 26/32 - 90.0ms/batch - loss: 1.66368 - diff: 26.62mlTrain batch 27/32 - 72.9ms/batch - loss: 1.66980 - diff: 26.72mlTrain batch 28/32 - 76.7ms/batch - loss: 1.64902 - diff: 26.38mlTrain batch 29/32 - 85.3ms/batch - loss: 1.64167 - diff: 26.27mlTrain batch 30/32 - 84.3ms/batch - loss: 1.66954 - diff: 26.71mlTrain batch 31/32 - 81.6ms/batch - loss: 1.65672 - diff: 26.51mlTrain batch 32/32 - 81.4ms/batch - loss: 1.67136 - diff: 26.41mlTrain batch 32/32 - 16.0s 81.4ms/batch - loss: 1.67136 - diff: 26.41ml
Test 1.0s: val_loss: 1.92637 - diff: 29.36ml

Epoch 14: current best loss = 1.57150, at epoch 8
Train batch 1/32 - 67.1ms/batch - loss: 1.25181 - diff: 20.03mlTrain batch 2/32 - 60.3ms/batch - loss: 1.93330 - diff: 30.93mlTrain batch 3/32 - 94.5ms/batch - loss: 1.77054 - diff: 28.33mlTrain batch 4/32 - 112.6ms/batch - loss: 1.74054 - diff: 27.85mlTrain batch 5/32 - 74.0ms/batch - loss: 1.68505 - diff: 26.96mlTrain batch 6/32 - 84.1ms/batch - loss: 1.67542 - diff: 26.81mlTrain batch 7/32 - 72.8ms/batch - loss: 1.66742 - diff: 26.68mlTrain batch 8/32 - 79.2ms/batch - loss: 1.76365 - diff: 28.22mlTrain batch 9/32 - 73.4ms/batch - loss: 1.82155 - diff: 29.14mlTrain batch 10/32 - 76.1ms/batch - loss: 1.80258 - diff: 28.84mlTrain batch 11/32 - 78.4ms/batch - loss: 1.83947 - diff: 29.43mlTrain batch 12/32 - 60.0ms/batch - loss: 1.80675 - diff: 28.91mlTrain batch 13/32 - 72.4ms/batch - loss: 1.75419 - diff: 28.07mlTrain batch 14/32 - 63.7ms/batch - loss: 1.72267 - diff: 27.56mlTrain batch 15/32 - 102.0ms/batch - loss: 1.75000 - diff: 28.00mlTrain batch 16/32 - 60.3ms/batch - loss: 1.71551 - diff: 27.45mlTrain batch 17/32 - 122.5ms/batch - loss: 1.67337 - diff: 26.77mlTrain batch 18/32 - 118.2ms/batch - loss: 1.69602 - diff: 27.14mlTrain batch 19/32 - 92.9ms/batch - loss: 1.73161 - diff: 27.71mlTrain batch 20/32 - 136.4ms/batch - loss: 1.71603 - diff: 27.46mlTrain batch 21/32 - 72.6ms/batch - loss: 1.71772 - diff: 27.48mlTrain batch 22/32 - 102.5ms/batch - loss: 1.71302 - diff: 27.41mlTrain batch 23/32 - 74.9ms/batch - loss: 1.70936 - diff: 27.35mlTrain batch 24/32 - 79.2ms/batch - loss: 1.70403 - diff: 27.26mlTrain batch 25/32 - 74.2ms/batch - loss: 1.67515 - diff: 26.80mlTrain batch 26/32 - 84.3ms/batch - loss: 1.67674 - diff: 26.83mlTrain batch 27/32 - 99.5ms/batch - loss: 1.66614 - diff: 26.66mlTrain batch 28/32 - 89.1ms/batch - loss: 1.64192 - diff: 26.27mlTrain batch 29/32 - 96.0ms/batch - loss: 1.65221 - diff: 26.44mlTrain batch 30/32 - 88.4ms/batch - loss: 1.65778 - diff: 26.52mlTrain batch 31/32 - 75.1ms/batch - loss: 1.67285 - diff: 26.77mlTrain batch 32/32 - 76.8ms/batch - loss: 1.70711 - diff: 26.74mlTrain batch 32/32 - 17.1s 76.8ms/batch - loss: 1.70711 - diff: 26.74ml
Test 0.9s: val_loss: 1.65562 - diff: 25.77ml

Epoch 15: current best loss = 1.57150, at epoch 8
Train batch 1/32 - 110.7ms/batch - loss: 1.26102 - diff: 20.18mlTrain batch 2/32 - 77.7ms/batch - loss: 1.47597 - diff: 23.62mlTrain batch 3/32 - 84.0ms/batch - loss: 1.31567 - diff: 21.05mlTrain batch 4/32 - 94.1ms/batch - loss: 1.33507 - diff: 21.36mlTrain batch 5/32 - 78.7ms/batch - loss: 1.42972 - diff: 22.88mlTrain batch 6/32 - 72.3ms/batch - loss: 1.47745 - diff: 23.64mlTrain batch 7/32 - 70.8ms/batch - loss: 1.53022 - diff: 24.48mlTrain batch 8/32 - 100.9ms/batch - loss: 1.49732 - diff: 23.96mlTrain batch 9/32 - 65.2ms/batch - loss: 1.58638 - diff: 25.38mlTrain batch 10/32 - 98.3ms/batch - loss: 1.61730 - diff: 25.88mlTrain batch 11/32 - 79.0ms/batch - loss: 1.58135 - diff: 25.30mlTrain batch 12/32 - 73.3ms/batch - loss: 1.55710 - diff: 24.91mlTrain batch 13/32 - 68.5ms/batch - loss: 1.50299 - diff: 24.05mlTrain batch 14/32 - 87.7ms/batch - loss: 1.53391 - diff: 24.54mlTrain batch 15/32 - 62.6ms/batch - loss: 1.63806 - diff: 26.21mlTrain batch 16/32 - 83.3ms/batch - loss: 1.65488 - diff: 26.48mlTrain batch 17/32 - 72.1ms/batch - loss: 1.69345 - diff: 27.10mlTrain batch 18/32 - 71.5ms/batch - loss: 1.65519 - diff: 26.48mlTrain batch 19/32 - 68.0ms/batch - loss: 1.65605 - diff: 26.50mlTrain batch 20/32 - 68.9ms/batch - loss: 1.65324 - diff: 26.45mlTrain batch 21/32 - 74.1ms/batch - loss: 1.64398 - diff: 26.30mlTrain batch 22/32 - 97.2ms/batch - loss: 1.63705 - diff: 26.19mlTrain batch 23/32 - 77.8ms/batch - loss: 1.64995 - diff: 26.40mlTrain batch 24/32 - 79.7ms/batch - loss: 1.64852 - diff: 26.38mlTrain batch 25/32 - 76.9ms/batch - loss: 1.62661 - diff: 26.03mlTrain batch 26/32 - 89.5ms/batch - loss: 1.62521 - diff: 26.00mlTrain batch 27/32 - 78.0ms/batch - loss: 1.61207 - diff: 25.79mlTrain batch 28/32 - 83.4ms/batch - loss: 1.63982 - diff: 26.24mlTrain batch 29/32 - 76.5ms/batch - loss: 1.61723 - diff: 25.88mlTrain batch 30/32 - 60.2ms/batch - loss: 1.60211 - diff: 25.63mlTrain batch 31/32 - 60.0ms/batch - loss: 1.61975 - diff: 25.92mlTrain batch 32/32 - 73.7ms/batch - loss: 1.66220 - diff: 25.93mlTrain batch 32/32 - 16.7s 73.7ms/batch - loss: 1.66220 - diff: 25.93ml
Test 0.9s: val_loss: 1.65348 - diff: 25.44ml

Epoch 16: current best loss = 1.57150, at epoch 8
Train batch 1/32 - 74.9ms/batch - loss: 1.75495 - diff: 28.08mlTrain batch 2/32 - 61.4ms/batch - loss: 1.70105 - diff: 27.22mlTrain batch 3/32 - 79.7ms/batch - loss: 1.77242 - diff: 28.36mlTrain batch 4/32 - 95.1ms/batch - loss: 1.80031 - diff: 28.81mlTrain batch 5/32 - 90.6ms/batch - loss: 1.70630 - diff: 27.30mlTrain batch 6/32 - 104.9ms/batch - loss: 1.72723 - diff: 27.64mlTrain batch 7/32 - 89.3ms/batch - loss: 1.70146 - diff: 27.22mlTrain batch 8/32 - 89.0ms/batch - loss: 1.61412 - diff: 25.83mlTrain batch 9/32 - 73.7ms/batch - loss: 1.60778 - diff: 25.72mlTrain batch 10/32 - 95.1ms/batch - loss: 1.68019 - diff: 26.88mlTrain batch 11/32 - 78.8ms/batch - loss: 1.65595 - diff: 26.50mlTrain batch 12/32 - 89.5ms/batch - loss: 1.59028 - diff: 25.44mlTrain batch 13/32 - 90.6ms/batch - loss: 1.57026 - diff: 25.12mlTrain batch 14/32 - 83.0ms/batch - loss: 1.71883 - diff: 27.50mlTrain batch 15/32 - 68.1ms/batch - loss: 1.76636 - diff: 28.26mlTrain batch 16/32 - 80.5ms/batch - loss: 1.77498 - diff: 28.40mlTrain batch 17/32 - 99.4ms/batch - loss: 1.74074 - diff: 27.85mlTrain batch 18/32 - 82.5ms/batch - loss: 1.72359 - diff: 27.58mlTrain batch 19/32 - 66.7ms/batch - loss: 1.69968 - diff: 27.19mlTrain batch 20/32 - 63.3ms/batch - loss: 1.68006 - diff: 26.88mlTrain batch 21/32 - 69.9ms/batch - loss: 1.65683 - diff: 26.51mlTrain batch 22/32 - 72.8ms/batch - loss: 1.62506 - diff: 26.00mlTrain batch 23/32 - 75.6ms/batch - loss: 1.60511 - diff: 25.68mlTrain batch 24/32 - 87.1ms/batch - loss: 1.58589 - diff: 25.37mlTrain batch 25/32 - 106.0ms/batch - loss: 1.59210 - diff: 25.47mlTrain batch 26/32 - 78.3ms/batch - loss: 1.58225 - diff: 25.32mlTrain batch 27/32 - 70.1ms/batch - loss: 1.58010 - diff: 25.28mlTrain batch 28/32 - 71.9ms/batch - loss: 1.57759 - diff: 25.24mlTrain batch 29/32 - 71.7ms/batch - loss: 1.59178 - diff: 25.47mlTrain batch 30/32 - 71.6ms/batch - loss: 1.60541 - diff: 25.69mlTrain batch 31/32 - 67.5ms/batch - loss: 1.60564 - diff: 25.69mlTrain batch 32/32 - 93.1ms/batch - loss: 1.65691 - diff: 25.74mlTrain batch 32/32 - 16.3s 93.1ms/batch - loss: 1.65691 - diff: 25.74ml
Test 1.0s: val_loss: 1.58911 - diff: 24.79ml

Epoch 17: current best loss = 1.57150, at epoch 8
Train batch 1/32 - 77.8ms/batch - loss: 2.44394 - diff: 39.10mlTrain batch 2/32 - 74.3ms/batch - loss: 1.99959 - diff: 31.99mlTrain batch 3/32 - 100.5ms/batch - loss: 1.69909 - diff: 27.19mlTrain batch 4/32 - 64.0ms/batch - loss: 1.67037 - diff: 26.73mlTrain batch 5/32 - 74.9ms/batch - loss: 1.75499 - diff: 28.08mlTrain batch 6/32 - 72.4ms/batch - loss: 1.64120 - diff: 26.26mlTrain batch 7/32 - 72.6ms/batch - loss: 1.60890 - diff: 25.74mlTrain batch 8/32 - 79.4ms/batch - loss: 1.71226 - diff: 27.40mlTrain batch 9/32 - 105.0ms/batch - loss: 1.71737 - diff: 27.48mlTrain batch 10/32 - 78.4ms/batch - loss: 1.72017 - diff: 27.52mlTrain batch 11/32 - 64.9ms/batch - loss: 1.70262 - diff: 27.24mlTrain batch 12/32 - 78.0ms/batch - loss: 1.65118 - diff: 26.42mlTrain batch 13/32 - 81.3ms/batch - loss: 1.66601 - diff: 26.66mlTrain batch 14/32 - 80.9ms/batch - loss: 1.70841 - diff: 27.33mlTrain batch 15/32 - 81.3ms/batch - loss: 1.68351 - diff: 26.94mlTrain batch 16/32 - 70.2ms/batch - loss: 1.67758 - diff: 26.84mlTrain batch 17/32 - 58.8ms/batch - loss: 1.65719 - diff: 26.52mlTrain batch 18/32 - 72.0ms/batch - loss: 1.67789 - diff: 26.85mlTrain batch 19/32 - 62.5ms/batch - loss: 1.66437 - diff: 26.63mlTrain batch 20/32 - 73.6ms/batch - loss: 1.63299 - diff: 26.13mlTrain batch 21/32 - 76.6ms/batch - loss: 1.62768 - diff: 26.04mlTrain batch 22/32 - 80.2ms/batch - loss: 1.63141 - diff: 26.10mlTrain batch 23/32 - 81.4ms/batch - loss: 1.62343 - diff: 25.97mlTrain batch 24/32 - 68.5ms/batch - loss: 1.61503 - diff: 25.84mlTrain batch 25/32 - 79.4ms/batch - loss: 1.60127 - diff: 25.62mlTrain batch 26/32 - 97.5ms/batch - loss: 1.60284 - diff: 25.65mlTrain batch 27/32 - 63.9ms/batch - loss: 1.59653 - diff: 25.54mlTrain batch 28/32 - 84.5ms/batch - loss: 1.64297 - diff: 26.29mlTrain batch 29/32 - 83.7ms/batch - loss: 1.63643 - diff: 26.18mlTrain batch 30/32 - 65.9ms/batch - loss: 1.62111 - diff: 25.94mlTrain batch 31/32 - 66.1ms/batch - loss: 1.60710 - diff: 25.71mlTrain batch 32/32 - 69.4ms/batch - loss: 1.66051 - diff: 25.77mlTrain batch 32/32 - 16.5s 69.4ms/batch - loss: 1.66051 - diff: 25.77ml
Test 0.9s: val_loss: 1.52787 - diff: 23.72ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Systole_DenseNet121_0_Adam-0.001_MAE_DA3_best

Epoch 18: current best loss = 1.52787, at epoch 17
Train batch 1/32 - 112.7ms/batch - loss: 2.12703 - diff: 34.03mlTrain batch 2/32 - 104.1ms/batch - loss: 1.80788 - diff: 28.93mlTrain batch 3/32 - 76.5ms/batch - loss: 1.69977 - diff: 27.20mlTrain batch 4/32 - 63.0ms/batch - loss: 1.57846 - diff: 25.26mlTrain batch 5/32 - 73.5ms/batch - loss: 1.54273 - diff: 24.68mlTrain batch 6/32 - 95.9ms/batch - loss: 1.54348 - diff: 24.70mlTrain batch 7/32 - 106.8ms/batch - loss: 1.62613 - diff: 26.02mlTrain batch 8/32 - 101.0ms/batch - loss: 1.57921 - diff: 25.27mlTrain batch 9/32 - 65.8ms/batch - loss: 1.52594 - diff: 24.42mlTrain batch 10/32 - 81.5ms/batch - loss: 1.49965 - diff: 23.99mlTrain batch 11/32 - 73.9ms/batch - loss: 1.50747 - diff: 24.12mlTrain batch 12/32 - 76.4ms/batch - loss: 1.68794 - diff: 27.01mlTrain batch 13/32 - 68.5ms/batch - loss: 1.66729 - diff: 26.68mlTrain batch 14/32 - 83.3ms/batch - loss: 1.65409 - diff: 26.47mlTrain batch 15/32 - 83.7ms/batch - loss: 1.65539 - diff: 26.49mlTrain batch 16/32 - 65.9ms/batch - loss: 1.62960 - diff: 26.07mlTrain batch 17/32 - 83.4ms/batch - loss: 1.66436 - diff: 26.63mlTrain batch 18/32 - 81.8ms/batch - loss: 1.66216 - diff: 26.59mlTrain batch 19/32 - 90.2ms/batch - loss: 1.62830 - diff: 26.05mlTrain batch 20/32 - 135.6ms/batch - loss: 1.64515 - diff: 26.32mlTrain batch 21/32 - 74.4ms/batch - loss: 1.63405 - diff: 26.14mlTrain batch 22/32 - 87.7ms/batch - loss: 1.64093 - diff: 26.25mlTrain batch 23/32 - 76.7ms/batch - loss: 1.63722 - diff: 26.20mlTrain batch 24/32 - 72.3ms/batch - loss: 1.63942 - diff: 26.23mlTrain batch 25/32 - 84.7ms/batch - loss: 1.64296 - diff: 26.29mlTrain batch 26/32 - 72.3ms/batch - loss: 1.66580 - diff: 26.65mlTrain batch 27/32 - 67.8ms/batch - loss: 1.64976 - diff: 26.40mlTrain batch 28/32 - 71.0ms/batch - loss: 1.67587 - diff: 26.81mlTrain batch 29/32 - 73.3ms/batch - loss: 1.68064 - diff: 26.89mlTrain batch 30/32 - 83.3ms/batch - loss: 1.66088 - diff: 26.57mlTrain batch 31/32 - 66.9ms/batch - loss: 1.64692 - diff: 26.35mlTrain batch 32/32 - 77.4ms/batch - loss: 1.65910 - diff: 26.24mlTrain batch 32/32 - 17.6s 77.4ms/batch - loss: 1.65910 - diff: 26.24ml
Test 1.1s: val_loss: 1.55585 - diff: 22.98ml

Epoch 19: current best loss = 1.52787, at epoch 17
Train batch 1/32 - 96.2ms/batch - loss: 1.42006 - diff: 22.72mlTrain batch 2/32 - 76.1ms/batch - loss: 1.35826 - diff: 21.73mlTrain batch 3/32 - 84.4ms/batch - loss: 1.22897 - diff: 19.66mlTrain batch 4/32 - 119.0ms/batch - loss: 1.21185 - diff: 19.39mlTrain batch 5/32 - 92.5ms/batch - loss: 1.27847 - diff: 20.46mlTrain batch 6/32 - 71.8ms/batch - loss: 1.41635 - diff: 22.66mlTrain batch 7/32 - 89.4ms/batch - loss: 1.53302 - diff: 24.53mlTrain batch 8/32 - 77.4ms/batch - loss: 1.48425 - diff: 23.75mlTrain batch 9/32 - 94.1ms/batch - loss: 1.54195 - diff: 24.67mlTrain batch 10/32 - 74.6ms/batch - loss: 1.53168 - diff: 24.51mlTrain batch 11/32 - 99.2ms/batch - loss: 1.59768 - diff: 25.56mlTrain batch 12/32 - 76.4ms/batch - loss: 1.59922 - diff: 25.59mlTrain batch 13/32 - 75.9ms/batch - loss: 1.60635 - diff: 25.70mlTrain batch 14/32 - 79.7ms/batch - loss: 1.61141 - diff: 25.78mlTrain batch 15/32 - 89.9ms/batch - loss: 1.59688 - diff: 25.55mlTrain batch 16/32 - 77.7ms/batch - loss: 1.57741 - diff: 25.24mlTrain batch 17/32 - 93.7ms/batch - loss: 1.60976 - diff: 25.76mlTrain batch 18/32 - 73.8ms/batch - loss: 1.59237 - diff: 25.48mlTrain batch 19/32 - 150.7ms/batch - loss: 1.57824 - diff: 25.25mlTrain batch 20/32 - 84.5ms/batch - loss: 1.57687 - diff: 25.23mlTrain batch 21/32 - 95.9ms/batch - loss: 1.58177 - diff: 25.31mlTrain batch 22/32 - 78.7ms/batch - loss: 1.58261 - diff: 25.32mlTrain batch 23/32 - 67.7ms/batch - loss: 1.62590 - diff: 26.01mlTrain batch 24/32 - 87.5ms/batch - loss: 1.59754 - diff: 25.56mlTrain batch 25/32 - 87.6ms/batch - loss: 1.59184 - diff: 25.47mlTrain batch 26/32 - 73.1ms/batch - loss: 1.58676 - diff: 25.39mlTrain batch 27/32 - 110.8ms/batch - loss: 1.58400 - diff: 25.34mlTrain batch 28/32 - 109.0ms/batch - loss: 1.59864 - diff: 25.58mlTrain batch 29/32 - 80.2ms/batch - loss: 1.59588 - diff: 25.53mlTrain batch 30/32 - 82.7ms/batch - loss: 1.57890 - diff: 25.26mlTrain batch 31/32 - 89.2ms/batch - loss: 1.55718 - diff: 24.91mlTrain batch 32/32 - 92.0ms/batch - loss: 1.58446 - diff: 24.87mlTrain batch 32/32 - 15.9s 92.0ms/batch - loss: 1.58446 - diff: 24.87ml
Test 0.8s: val_loss: 1.45701 - diff: 22.71ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Systole_DenseNet121_0_Adam-0.001_MAE_DA3_best

Epoch 20: current best loss = 1.45701, at epoch 19
Train batch 1/32 - 94.9ms/batch - loss: 1.53132 - diff: 24.50mlTrain batch 2/32 - 64.0ms/batch - loss: 1.64036 - diff: 26.25mlTrain batch 3/32 - 94.3ms/batch - loss: 1.76293 - diff: 28.21mlTrain batch 4/32 - 80.0ms/batch - loss: 1.77998 - diff: 28.48mlTrain batch 5/32 - 84.1ms/batch - loss: 1.73147 - diff: 27.70mlTrain batch 6/32 - 85.8ms/batch - loss: 1.69194 - diff: 27.07mlTrain batch 7/32 - 64.9ms/batch - loss: 1.58468 - diff: 25.35mlTrain batch 8/32 - 96.4ms/batch - loss: 1.56337 - diff: 25.01mlTrain batch 9/32 - 94.7ms/batch - loss: 1.55589 - diff: 24.89mlTrain batch 10/32 - 95.4ms/batch - loss: 1.65610 - diff: 26.50mlTrain batch 11/32 - 62.4ms/batch - loss: 1.70593 - diff: 27.29mlTrain batch 12/32 - 58.5ms/batch - loss: 1.70559 - diff: 27.29mlTrain batch 13/32 - 96.9ms/batch - loss: 1.73445 - diff: 27.75mlTrain batch 14/32 - 86.4ms/batch - loss: 1.72810 - diff: 27.65mlTrain batch 15/32 - 106.8ms/batch - loss: 1.71871 - diff: 27.50mlTrain batch 16/32 - 102.1ms/batch - loss: 1.68886 - diff: 27.02mlTrain batch 17/32 - 87.6ms/batch - loss: 1.69416 - diff: 27.11mlTrain batch 18/32 - 92.4ms/batch - loss: 1.67690 - diff: 26.83mlTrain batch 19/32 - 78.1ms/batch - loss: 1.64868 - diff: 26.38mlTrain batch 20/32 - 63.7ms/batch - loss: 1.72424 - diff: 27.59mlTrain batch 21/32 - 72.8ms/batch - loss: 1.71486 - diff: 27.44mlTrain batch 22/32 - 123.4ms/batch - loss: 1.67345 - diff: 26.78mlTrain batch 23/32 - 73.5ms/batch - loss: 1.63308 - diff: 26.13mlTrain batch 24/32 - 75.8ms/batch - loss: 1.62788 - diff: 26.05mlTrain batch 25/32 - 102.4ms/batch - loss: 1.61373 - diff: 25.82mlTrain batch 26/32 - 106.0ms/batch - loss: 1.63378 - diff: 26.14mlTrain batch 27/32 - 86.9ms/batch - loss: 1.62118 - diff: 25.94mlTrain batch 28/32 - 94.4ms/batch - loss: 1.60124 - diff: 25.62mlTrain batch 29/32 - 79.0ms/batch - loss: 1.59648 - diff: 25.54mlTrain batch 30/32 - 91.1ms/batch - loss: 1.63910 - diff: 26.23mlTrain batch 31/32 - 87.2ms/batch - loss: 1.67683 - diff: 26.83mlTrain batch 32/32 - 67.9ms/batch - loss: 1.67314 - diff: 26.65mlTrain batch 32/32 - 17.0s 67.9ms/batch - loss: 1.67314 - diff: 26.65ml
Test 0.9s: val_loss: 1.51380 - diff: 23.84ml

Epoch 21: current best loss = 1.45701, at epoch 19
Train batch 1/32 - 76.7ms/batch - loss: 1.32346 - diff: 21.18mlTrain batch 2/32 - 57.8ms/batch - loss: 1.55111 - diff: 24.82mlTrain batch 3/32 - 107.8ms/batch - loss: 1.56906 - diff: 25.11mlTrain batch 4/32 - 107.0ms/batch - loss: 1.64467 - diff: 26.31mlTrain batch 5/32 - 78.6ms/batch - loss: 1.53391 - diff: 24.54mlTrain batch 6/32 - 90.4ms/batch - loss: 1.58737 - diff: 25.40mlTrain batch 7/32 - 75.2ms/batch - loss: 1.58158 - diff: 25.31mlTrain batch 8/32 - 61.6ms/batch - loss: 1.55579 - diff: 24.89mlTrain batch 9/32 - 64.7ms/batch - loss: 1.53219 - diff: 24.52mlTrain batch 10/32 - 82.4ms/batch - loss: 1.52030 - diff: 24.32mlTrain batch 11/32 - 65.5ms/batch - loss: 1.56490 - diff: 25.04mlTrain batch 12/32 - 82.4ms/batch - loss: 1.52787 - diff: 24.45mlTrain batch 13/32 - 70.1ms/batch - loss: 1.50847 - diff: 24.14mlTrain batch 14/32 - 62.4ms/batch - loss: 1.48540 - diff: 23.77mlTrain batch 15/32 - 77.8ms/batch - loss: 1.47925 - diff: 23.67mlTrain batch 16/32 - 79.5ms/batch - loss: 1.49417 - diff: 23.91mlTrain batch 17/32 - 90.9ms/batch - loss: 1.47130 - diff: 23.54mlTrain batch 18/32 - 90.6ms/batch - loss: 1.49997 - diff: 24.00mlTrain batch 19/32 - 65.1ms/batch - loss: 1.49125 - diff: 23.86mlTrain batch 20/32 - 100.4ms/batch - loss: 1.48629 - diff: 23.78mlTrain batch 21/32 - 79.6ms/batch - loss: 1.48928 - diff: 23.83mlTrain batch 22/32 - 62.5ms/batch - loss: 1.52148 - diff: 24.34mlTrain batch 23/32 - 85.7ms/batch - loss: 1.56136 - diff: 24.98mlTrain batch 24/32 - 99.8ms/batch - loss: 1.54439 - diff: 24.71mlTrain batch 25/32 - 81.5ms/batch - loss: 1.52190 - diff: 24.35mlTrain batch 26/32 - 87.8ms/batch - loss: 1.60691 - diff: 25.71mlTrain batch 27/32 - 78.8ms/batch - loss: 1.59522 - diff: 25.52mlTrain batch 28/32 - 91.0ms/batch - loss: 1.57360 - diff: 25.18mlTrain batch 29/32 - 81.4ms/batch - loss: 1.57090 - diff: 25.13mlTrain batch 30/32 - 96.9ms/batch - loss: 1.56277 - diff: 25.00mlTrain batch 31/32 - 63.4ms/batch - loss: 1.57426 - diff: 25.19mlTrain batch 32/32 - 55.5ms/batch - loss: 1.60970 - diff: 25.18mlTrain batch 32/32 - 17.4s 55.5ms/batch - loss: 1.60970 - diff: 25.18ml
Test 1.1s: val_loss: 1.52262 - diff: 23.34ml

Epoch 22: current best loss = 1.45701, at epoch 19
Train batch 1/32 - 99.8ms/batch - loss: 2.00702 - diff: 32.11mlTrain batch 2/32 - 77.3ms/batch - loss: 1.97084 - diff: 31.53mlTrain batch 3/32 - 98.9ms/batch - loss: 1.79324 - diff: 28.69mlTrain batch 4/32 - 97.4ms/batch - loss: 1.68185 - diff: 26.91mlTrain batch 5/32 - 69.9ms/batch - loss: 1.60495 - diff: 25.68mlTrain batch 6/32 - 72.8ms/batch - loss: 1.48448 - diff: 23.75mlTrain batch 7/32 - 80.5ms/batch - loss: 1.45561 - diff: 23.29mlTrain batch 8/32 - 88.4ms/batch - loss: 1.48415 - diff: 23.75mlTrain batch 9/32 - 71.7ms/batch - loss: 1.51791 - diff: 24.29mlTrain batch 10/32 - 80.0ms/batch - loss: 1.55141 - diff: 24.82mlTrain batch 11/32 - 62.1ms/batch - loss: 1.54021 - diff: 24.64mlTrain batch 12/32 - 81.4ms/batch - loss: 1.53471 - diff: 24.56mlTrain batch 13/32 - 79.5ms/batch - loss: 1.58048 - diff: 25.29mlTrain batch 14/32 - 119.9ms/batch - loss: 1.55115 - diff: 24.82mlTrain batch 15/32 - 75.0ms/batch - loss: 1.54230 - diff: 24.68mlTrain batch 16/32 - 74.0ms/batch - loss: 1.51065 - diff: 24.17mlTrain batch 17/32 - 64.9ms/batch - loss: 1.53166 - diff: 24.51mlTrain batch 18/32 - 75.0ms/batch - loss: 1.54948 - diff: 24.79mlTrain batch 19/32 - 78.8ms/batch - loss: 1.60760 - diff: 25.72mlTrain batch 20/32 - 103.4ms/batch - loss: 1.60133 - diff: 25.62mlTrain batch 21/32 - 93.1ms/batch - loss: 1.57033 - diff: 25.13mlTrain batch 22/32 - 94.0ms/batch - loss: 1.60597 - diff: 25.70mlTrain batch 23/32 - 63.5ms/batch - loss: 1.58294 - diff: 25.33mlTrain batch 24/32 - 77.9ms/batch - loss: 1.56495 - diff: 25.04mlTrain batch 25/32 - 73.6ms/batch - loss: 1.56854 - diff: 25.10mlTrain batch 26/32 - 79.3ms/batch - loss: 1.55445 - diff: 24.87mlTrain batch 27/32 - 87.2ms/batch - loss: 1.56279 - diff: 25.00mlTrain batch 28/32 - 80.3ms/batch - loss: 1.55923 - diff: 24.95mlTrain batch 29/32 - 59.7ms/batch - loss: 1.55512 - diff: 24.88mlTrain batch 30/32 - 61.1ms/batch - loss: 1.54649 - diff: 24.74mlTrain batch 31/32 - 85.2ms/batch - loss: 1.55423 - diff: 24.87mlTrain batch 32/32 - 58.3ms/batch - loss: 1.59098 - diff: 24.87mlTrain batch 32/32 - 15.8s 58.3ms/batch - loss: 1.59098 - diff: 24.87ml
Test 0.9s: val_loss: 1.62444 - diff: 25.12ml

Epoch 23: current best loss = 1.45701, at epoch 19
Train batch 1/32 - 111.8ms/batch - loss: 1.72145 - diff: 27.54mlTrain batch 2/32 - 62.6ms/batch - loss: 1.77274 - diff: 28.36mlTrain batch 3/32 - 74.3ms/batch - loss: 1.55010 - diff: 24.80mlTrain batch 4/32 - 81.9ms/batch - loss: 1.55534 - diff: 24.89mlTrain batch 5/32 - 73.8ms/batch - loss: 1.50027 - diff: 24.00mlTrain batch 6/32 - 89.8ms/batch - loss: 1.48172 - diff: 23.71mlTrain batch 7/32 - 80.3ms/batch - loss: 1.45287 - diff: 23.25mlTrain batch 8/32 - 137.2ms/batch - loss: 1.51620 - diff: 24.26mlTrain batch 9/32 - 103.7ms/batch - loss: 1.48585 - diff: 23.77mlTrain batch 10/32 - 116.6ms/batch - loss: 1.49815 - diff: 23.97mlTrain batch 11/32 - 82.7ms/batch - loss: 1.53466 - diff: 24.55mlTrain batch 12/32 - 94.4ms/batch - loss: 1.51898 - diff: 24.30mlTrain batch 13/32 - 96.0ms/batch - loss: 1.53133 - diff: 24.50mlTrain batch 14/32 - 113.9ms/batch - loss: 1.63353 - diff: 26.14mlTrain batch 15/32 - 98.1ms/batch - loss: 1.61975 - diff: 25.92mlTrain batch 16/32 - 77.8ms/batch - loss: 1.70715 - diff: 27.31mlTrain batch 17/32 - 93.4ms/batch - loss: 1.67079 - diff: 26.73mlTrain batch 18/32 - 99.2ms/batch - loss: 1.71592 - diff: 27.45mlTrain batch 19/32 - 87.2ms/batch - loss: 1.69372 - diff: 27.10mlTrain batch 20/32 - 108.3ms/batch - loss: 1.68215 - diff: 26.91mlTrain batch 21/32 - 64.0ms/batch - loss: 1.67656 - diff: 26.82mlTrain batch 22/32 - 106.4ms/batch - loss: 1.65966 - diff: 26.55mlTrain batch 23/32 - 58.8ms/batch - loss: 1.67394 - diff: 26.78mlTrain batch 24/32 - 98.6ms/batch - loss: 1.67344 - diff: 26.78mlTrain batch 25/32 - 70.9ms/batch - loss: 1.67008 - diff: 26.72mlTrain batch 26/32 - 67.7ms/batch - loss: 1.66024 - diff: 26.56mlTrain batch 27/32 - 61.0ms/batch - loss: 1.64771 - diff: 26.36mlTrain batch 28/32 - 72.8ms/batch - loss: 1.66239 - diff: 26.60mlTrain batch 29/32 - 61.5ms/batch - loss: 1.65739 - diff: 26.52mlTrain batch 30/32 - 86.3ms/batch - loss: 1.64297 - diff: 26.29mlTrain batch 31/32 - 85.8ms/batch - loss: 1.61810 - diff: 25.89mlTrain batch 32/32 - 72.8ms/batch - loss: 1.62657 - diff: 25.77mlTrain batch 32/32 - 16.7s 72.8ms/batch - loss: 1.62657 - diff: 25.77ml
Test 1.0s: val_loss: 1.63717 - diff: 24.80ml

Epoch 24: current best loss = 1.45701, at epoch 19
Train batch 1/32 - 108.7ms/batch - loss: 1.28181 - diff: 20.51mlTrain batch 2/32 - 119.0ms/batch - loss: 1.54647 - diff: 24.74mlTrain batch 3/32 - 97.8ms/batch - loss: 1.61815 - diff: 25.89mlTrain batch 4/32 - 63.4ms/batch - loss: 1.47448 - diff: 23.59mlTrain batch 5/32 - 98.3ms/batch - loss: 1.40185 - diff: 22.43mlTrain batch 6/32 - 95.4ms/batch - loss: 1.37194 - diff: 21.95mlTrain batch 7/32 - 92.2ms/batch - loss: 1.37970 - diff: 22.08mlTrain batch 8/32 - 79.4ms/batch - loss: 1.35974 - diff: 21.76mlTrain batch 9/32 - 82.2ms/batch - loss: 1.34113 - diff: 21.46mlTrain batch 10/32 - 85.8ms/batch - loss: 1.27782 - diff: 20.45mlTrain batch 11/32 - 90.4ms/batch - loss: 1.43890 - diff: 23.02mlTrain batch 12/32 - 91.4ms/batch - loss: 1.38800 - diff: 22.21mlTrain batch 13/32 - 96.4ms/batch - loss: 1.35877 - diff: 21.74mlTrain batch 14/32 - 77.8ms/batch - loss: 1.35182 - diff: 21.63mlTrain batch 15/32 - 85.7ms/batch - loss: 1.33390 - diff: 21.34mlTrain batch 16/32 - 95.4ms/batch - loss: 1.37187 - diff: 21.95mlTrain batch 17/32 - 99.8ms/batch - loss: 1.36168 - diff: 21.79mlTrain batch 18/32 - 113.2ms/batch - loss: 1.40167 - diff: 22.43mlTrain batch 19/32 - 70.5ms/batch - loss: 1.50280 - diff: 24.04mlTrain batch 20/32 - 95.5ms/batch - loss: 1.51251 - diff: 24.20mlTrain batch 21/32 - 72.0ms/batch - loss: 1.49123 - diff: 23.86mlTrain batch 22/32 - 92.5ms/batch - loss: 1.48224 - diff: 23.72mlTrain batch 23/32 - 101.8ms/batch - loss: 1.46975 - diff: 23.52mlTrain batch 24/32 - 110.3ms/batch - loss: 1.44096 - diff: 23.06mlTrain batch 25/32 - 80.8ms/batch - loss: 1.47901 - diff: 23.66mlTrain batch 26/32 - 99.5ms/batch - loss: 1.48715 - diff: 23.79mlTrain batch 27/32 - 86.7ms/batch - loss: 1.46891 - diff: 23.50mlTrain batch 28/32 - 104.1ms/batch - loss: 1.48389 - diff: 23.74mlTrain batch 29/32 - 82.5ms/batch - loss: 1.50648 - diff: 24.10mlTrain batch 30/32 - 99.8ms/batch - loss: 1.50243 - diff: 24.04mlTrain batch 31/32 - 67.1ms/batch - loss: 1.49868 - diff: 23.98mlTrain batch 32/32 - 62.1ms/batch - loss: 1.53704 - diff: 23.99mlTrain batch 32/32 - 16.1s 62.1ms/batch - loss: 1.53704 - diff: 23.99ml
Test 0.9s: val_loss: 1.62368 - diff: 24.86ml

Epoch 25: current best loss = 1.45701, at epoch 19
Train batch 1/32 - 97.7ms/batch - loss: 1.18162 - diff: 18.91mlTrain batch 2/32 - 98.0ms/batch - loss: 1.54808 - diff: 24.77mlTrain batch 3/32 - 76.6ms/batch - loss: 1.50498 - diff: 24.08mlTrain batch 4/32 - 87.4ms/batch - loss: 1.45682 - diff: 23.31mlTrain batch 5/32 - 89.8ms/batch - loss: 1.41135 - diff: 22.58mlTrain batch 6/32 - 94.4ms/batch - loss: 1.40390 - diff: 22.46mlTrain batch 7/32 - 91.7ms/batch - loss: 1.45438 - diff: 23.27mlTrain batch 8/32 - 62.0ms/batch - loss: 1.43765 - diff: 23.00mlTrain batch 9/32 - 86.5ms/batch - loss: 1.43340 - diff: 22.93mlTrain batch 10/32 - 94.4ms/batch - loss: 1.51085 - diff: 24.17mlTrain batch 11/32 - 85.3ms/batch - loss: 1.59254 - diff: 25.48mlTrain batch 12/32 - 118.4ms/batch - loss: 1.58003 - diff: 25.28mlTrain batch 13/32 - 76.4ms/batch - loss: 1.58077 - diff: 25.29mlTrain batch 14/32 - 93.3ms/batch - loss: 1.57375 - diff: 25.18mlTrain batch 15/32 - 98.1ms/batch - loss: 1.55126 - diff: 24.82mlTrain batch 16/32 - 105.0ms/batch - loss: 1.56657 - diff: 25.07mlTrain batch 17/32 - 80.0ms/batch - loss: 1.53761 - diff: 24.60mlTrain batch 18/32 - 91.2ms/batch - loss: 1.61340 - diff: 25.81mlTrain batch 19/32 - 115.3ms/batch - loss: 1.60598 - diff: 25.70mlTrain batch 20/32 - 99.3ms/batch - loss: 1.58812 - diff: 25.41mlTrain batch 21/32 - 89.3ms/batch - loss: 1.61119 - diff: 25.78mlTrain batch 22/32 - 81.9ms/batch - loss: 1.59108 - diff: 25.46mlTrain batch 23/32 - 85.0ms/batch - loss: 1.59594 - diff: 25.54mlTrain batch 24/32 - 103.1ms/batch - loss: 1.59962 - diff: 25.59mlTrain batch 25/32 - 81.9ms/batch - loss: 1.57509 - diff: 25.20mlTrain batch 26/32 - 85.4ms/batch - loss: 1.56618 - diff: 25.06mlTrain batch 27/32 - 79.0ms/batch - loss: 1.55332 - diff: 24.85mlTrain batch 28/32 - 80.2ms/batch - loss: 1.53819 - diff: 24.61mlTrain batch 29/32 - 61.8ms/batch - loss: 1.53452 - diff: 24.55mlTrain batch 30/32 - 68.0ms/batch - loss: 1.52221 - diff: 24.36mlTrain batch 31/32 - 66.5ms/batch - loss: 1.55085 - diff: 24.81mlTrain batch 32/32 - 55.7ms/batch - loss: 1.60320 - diff: 24.87mlTrain batch 32/32 - 16.2s 55.7ms/batch - loss: 1.60320 - diff: 24.87ml
Test 0.9s: val_loss: 1.51942 - diff: 23.50ml

Epoch 26: current best loss = 1.45701, at epoch 19
Train batch 1/32 - 114.0ms/batch - loss: 1.14963 - diff: 18.39mlTrain batch 2/32 - 96.9ms/batch - loss: 1.48008 - diff: 23.68mlTrain batch 3/32 - 77.9ms/batch - loss: 1.37725 - diff: 22.04mlTrain batch 4/32 - 87.0ms/batch - loss: 1.49041 - diff: 23.85mlTrain batch 5/32 - 63.2ms/batch - loss: 1.37721 - diff: 22.04mlTrain batch 6/32 - 84.3ms/batch - loss: 1.37880 - diff: 22.06mlTrain batch 7/32 - 88.1ms/batch - loss: 1.32841 - diff: 21.25mlTrain batch 8/32 - 73.0ms/batch - loss: 1.33707 - diff: 21.39mlTrain batch 9/32 - 95.4ms/batch - loss: 1.37349 - diff: 21.98mlTrain batch 10/32 - 67.3ms/batch - loss: 1.38670 - diff: 22.19mlTrain batch 11/32 - 72.0ms/batch - loss: 1.43025 - diff: 22.88mlTrain batch 12/32 - 83.6ms/batch - loss: 1.50227 - diff: 24.04mlTrain batch 13/32 - 80.4ms/batch - loss: 1.50143 - diff: 24.02mlTrain batch 14/32 - 93.1ms/batch - loss: 1.48309 - diff: 23.73mlTrain batch 15/32 - 80.3ms/batch - loss: 1.45156 - diff: 23.22mlTrain batch 16/32 - 90.3ms/batch - loss: 1.46867 - diff: 23.50mlTrain batch 17/32 - 85.2ms/batch - loss: 1.51205 - diff: 24.19mlTrain batch 18/32 - 61.2ms/batch - loss: 1.50537 - diff: 24.09mlTrain batch 19/32 - 90.8ms/batch - loss: 1.47643 - diff: 23.62mlTrain batch 20/32 - 78.0ms/batch - loss: 1.45109 - diff: 23.22mlTrain batch 21/32 - 98.9ms/batch - loss: 1.49622 - diff: 23.94mlTrain batch 22/32 - 74.1ms/batch - loss: 1.47835 - diff: 23.65mlTrain batch 23/32 - 73.1ms/batch - loss: 1.49136 - diff: 23.86mlTrain batch 24/32 - 78.6ms/batch - loss: 1.48444 - diff: 23.75mlTrain batch 25/32 - 62.1ms/batch - loss: 1.52737 - diff: 24.44mlTrain batch 26/32 - 106.5ms/batch - loss: 1.51267 - diff: 24.20mlTrain batch 27/32 - 98.4ms/batch - loss: 1.53052 - diff: 24.49mlTrain batch 28/32 - 73.1ms/batch - loss: 1.54389 - diff: 24.70mlTrain batch 29/32 - 95.9ms/batch - loss: 1.53631 - diff: 24.58mlTrain batch 30/32 - 101.1ms/batch - loss: 1.54316 - diff: 24.69mlTrain batch 31/32 - 88.8ms/batch - loss: 1.56077 - diff: 24.97mlTrain batch 32/32 - 54.1ms/batch - loss: 1.57069 - diff: 24.86mlTrain batch 32/32 - 16.4s 54.1ms/batch - loss: 1.57069 - diff: 24.86ml
Test 1.0s: val_loss: 1.45083 - diff: 22.63ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Systole_DenseNet121_0_Adam-0.001_MAE_DA3_best

Epoch 27: current best loss = 1.45083, at epoch 26
Train batch 1/32 - 103.4ms/batch - loss: 1.71987 - diff: 27.52mlTrain batch 2/32 - 90.4ms/batch - loss: 1.32970 - diff: 21.28mlTrain batch 3/32 - 87.7ms/batch - loss: 1.40654 - diff: 22.50mlTrain batch 4/32 - 91.0ms/batch - loss: 1.59360 - diff: 25.50mlTrain batch 5/32 - 86.1ms/batch - loss: 1.68264 - diff: 26.92mlTrain batch 6/32 - 80.8ms/batch - loss: 1.74391 - diff: 27.90mlTrain batch 7/32 - 70.5ms/batch - loss: 1.69917 - diff: 27.19mlTrain batch 8/32 - 83.4ms/batch - loss: 1.68457 - diff: 26.95mlTrain batch 9/32 - 79.7ms/batch - loss: 1.62378 - diff: 25.98mlTrain batch 10/32 - 90.5ms/batch - loss: 1.55833 - diff: 24.93mlTrain batch 11/32 - 62.2ms/batch - loss: 1.57656 - diff: 25.22mlTrain batch 12/32 - 89.4ms/batch - loss: 1.60206 - diff: 25.63mlTrain batch 13/32 - 94.8ms/batch - loss: 1.55406 - diff: 24.86mlTrain batch 14/32 - 61.3ms/batch - loss: 1.51527 - diff: 24.24mlTrain batch 15/32 - 89.0ms/batch - loss: 1.49912 - diff: 23.99mlTrain batch 16/32 - 85.2ms/batch - loss: 1.48704 - diff: 23.79mlTrain batch 17/32 - 89.3ms/batch - loss: 1.45057 - diff: 23.21mlTrain batch 18/32 - 76.7ms/batch - loss: 1.46789 - diff: 23.49mlTrain batch 19/32 - 62.1ms/batch - loss: 1.43309 - diff: 22.93mlTrain batch 20/32 - 115.4ms/batch - loss: 1.43158 - diff: 22.91mlTrain batch 21/32 - 102.8ms/batch - loss: 1.51370 - diff: 24.22mlTrain batch 22/32 - 86.2ms/batch - loss: 1.50282 - diff: 24.05mlTrain batch 23/32 - 84.8ms/batch - loss: 1.52548 - diff: 24.41mlTrain batch 24/32 - 86.6ms/batch - loss: 1.51679 - diff: 24.27mlTrain batch 25/32 - 87.1ms/batch - loss: 1.55138 - diff: 24.82mlTrain batch 26/32 - 73.9ms/batch - loss: 1.53702 - diff: 24.59mlTrain batch 27/32 - 99.1ms/batch - loss: 1.52044 - diff: 24.33mlTrain batch 28/32 - 82.1ms/batch - loss: 1.52938 - diff: 24.47mlTrain batch 29/32 - 97.2ms/batch - loss: 1.54213 - diff: 24.67mlTrain batch 30/32 - 93.4ms/batch - loss: 1.54512 - diff: 24.72mlTrain batch 31/32 - 65.1ms/batch - loss: 1.54398 - diff: 24.70mlTrain batch 32/32 - 80.3ms/batch - loss: 1.58860 - diff: 24.73mlTrain batch 32/32 - 16.8s 80.3ms/batch - loss: 1.58860 - diff: 24.73ml
Test 0.9s: val_loss: 1.46490 - diff: 22.70ml

Epoch 28: current best loss = 1.45083, at epoch 26
Train batch 1/32 - 72.1ms/batch - loss: 1.65160 - diff: 26.43mlTrain batch 2/32 - 66.7ms/batch - loss: 1.26014 - diff: 20.16mlTrain batch 3/32 - 92.9ms/batch - loss: 1.22694 - diff: 19.63mlTrain batch 4/32 - 93.9ms/batch - loss: 1.45803 - diff: 23.33mlTrain batch 5/32 - 96.3ms/batch - loss: 1.48850 - diff: 23.82mlTrain batch 6/32 - 64.3ms/batch - loss: 1.47778 - diff: 23.64mlTrain batch 7/32 - 66.7ms/batch - loss: 1.73924 - diff: 27.83mlTrain batch 8/32 - 104.2ms/batch - loss: 1.70702 - diff: 27.31mlTrain batch 9/32 - 96.3ms/batch - loss: 1.65338 - diff: 26.45mlTrain batch 10/32 - 91.2ms/batch - loss: 1.59850 - diff: 25.58mlTrain batch 11/32 - 80.9ms/batch - loss: 1.61151 - diff: 25.78mlTrain batch 12/32 - 75.8ms/batch - loss: 1.65899 - diff: 26.54mlTrain batch 13/32 - 82.2ms/batch - loss: 1.64919 - diff: 26.39mlTrain batch 14/32 - 98.7ms/batch - loss: 1.63918 - diff: 26.23mlTrain batch 15/32 - 103.6ms/batch - loss: 1.61385 - diff: 25.82mlTrain batch 16/32 - 89.6ms/batch - loss: 1.58299 - diff: 25.33mlTrain batch 17/32 - 87.2ms/batch - loss: 1.56504 - diff: 25.04mlTrain batch 18/32 - 131.4ms/batch - loss: 1.57859 - diff: 25.26mlTrain batch 19/32 - 84.6ms/batch - loss: 1.57048 - diff: 25.13mlTrain batch 20/32 - 121.5ms/batch - loss: 1.54380 - diff: 24.70mlTrain batch 21/32 - 79.9ms/batch - loss: 1.53408 - diff: 24.55mlTrain batch 22/32 - 73.9ms/batch - loss: 1.52253 - diff: 24.36mlTrain batch 23/32 - 82.3ms/batch - loss: 1.54236 - diff: 24.68mlTrain batch 24/32 - 62.8ms/batch - loss: 1.52087 - diff: 24.33mlTrain batch 25/32 - 98.0ms/batch - loss: 1.51853 - diff: 24.30mlTrain batch 26/32 - 79.7ms/batch - loss: 1.54088 - diff: 24.65mlTrain batch 27/32 - 72.1ms/batch - loss: 1.54145 - diff: 24.66mlTrain batch 28/32 - 80.1ms/batch - loss: 1.54807 - diff: 24.77mlTrain batch 29/32 - 80.6ms/batch - loss: 1.53292 - diff: 24.53mlTrain batch 30/32 - 83.0ms/batch - loss: 1.54066 - diff: 24.65mlTrain batch 31/32 - 78.2ms/batch - loss: 1.54309 - diff: 24.69mlTrain batch 32/32 - 78.6ms/batch - loss: 1.57248 - diff: 24.66mlTrain batch 32/32 - 16.4s 78.6ms/batch - loss: 1.57248 - diff: 24.66ml
Test 1.0s: val_loss: 1.51000 - diff: 23.35ml

Epoch 29: current best loss = 1.45083, at epoch 26
Train batch 1/32 - 112.9ms/batch - loss: 1.35252 - diff: 21.64mlTrain batch 2/32 - 98.3ms/batch - loss: 1.38086 - diff: 22.09mlTrain batch 3/32 - 88.0ms/batch - loss: 1.74727 - diff: 27.96mlTrain batch 4/32 - 65.1ms/batch - loss: 1.73927 - diff: 27.83mlTrain batch 5/32 - 60.8ms/batch - loss: 1.84065 - diff: 29.45mlTrain batch 6/32 - 61.6ms/batch - loss: 1.76648 - diff: 28.26mlTrain batch 7/32 - 80.2ms/batch - loss: 1.67582 - diff: 26.81mlTrain batch 8/32 - 63.1ms/batch - loss: 1.81218 - diff: 28.99mlTrain batch 9/32 - 79.4ms/batch - loss: 1.87955 - diff: 30.07mlTrain batch 10/32 - 107.7ms/batch - loss: 1.98918 - diff: 31.83mlTrain batch 11/32 - 87.5ms/batch - loss: 2.01381 - diff: 32.22mlTrain batch 12/32 - 69.9ms/batch - loss: 1.97470 - diff: 31.60mlTrain batch 13/32 - 75.3ms/batch - loss: 1.90979 - diff: 30.56mlTrain batch 14/32 - 111.8ms/batch - loss: 1.84136 - diff: 29.46mlTrain batch 15/32 - 85.2ms/batch - loss: 1.81595 - diff: 29.06mlTrain batch 16/32 - 78.8ms/batch - loss: 1.80546 - diff: 28.89mlTrain batch 17/32 - 78.1ms/batch - loss: 1.77259 - diff: 28.36mlTrain batch 18/32 - 94.5ms/batch - loss: 1.76443 - diff: 28.23mlTrain batch 19/32 - 90.7ms/batch - loss: 1.72637 - diff: 27.62mlTrain batch 20/32 - 102.8ms/batch - loss: 1.71305 - diff: 27.41mlTrain batch 21/32 - 62.5ms/batch - loss: 1.70231 - diff: 27.24mlTrain batch 22/32 - 62.6ms/batch - loss: 1.68036 - diff: 26.89mlTrain batch 23/32 - 85.9ms/batch - loss: 1.65372 - diff: 26.46mlTrain batch 24/32 - 62.9ms/batch - loss: 1.66182 - diff: 26.59mlTrain batch 25/32 - 78.1ms/batch - loss: 1.64860 - diff: 26.38mlTrain batch 26/32 - 62.5ms/batch - loss: 1.65533 - diff: 26.49mlTrain batch 27/32 - 83.3ms/batch - loss: 1.63898 - diff: 26.22mlTrain batch 28/32 - 93.6ms/batch - loss: 1.62079 - diff: 25.93mlTrain batch 29/32 - 87.8ms/batch - loss: 1.61346 - diff: 25.82mlTrain batch 30/32 - 80.9ms/batch - loss: 1.59377 - diff: 25.50mlTrain batch 31/32 - 78.3ms/batch - loss: 1.60160 - diff: 25.63mlTrain batch 32/32 - 79.2ms/batch - loss: 1.62869 - diff: 25.58mlTrain batch 32/32 - 17.9s 79.2ms/batch - loss: 1.62869 - diff: 25.58ml
Test 1.0s: val_loss: 1.53499 - diff: 22.47ml

Epoch 30: current best loss = 1.45083, at epoch 26
Train batch 1/32 - 92.1ms/batch - loss: 1.23689 - diff: 19.79mlTrain batch 2/32 - 81.9ms/batch - loss: 1.20545 - diff: 19.29mlTrain batch 3/32 - 103.3ms/batch - loss: 1.25626 - diff: 20.10mlTrain batch 4/32 - 77.2ms/batch - loss: 1.29118 - diff: 20.66mlTrain batch 5/32 - 78.8ms/batch - loss: 1.41859 - diff: 22.70mlTrain batch 6/32 - 73.6ms/batch - loss: 1.39613 - diff: 22.34mlTrain batch 7/32 - 74.1ms/batch - loss: 1.42143 - diff: 22.74mlTrain batch 8/32 - 81.2ms/batch - loss: 1.41638 - diff: 22.66mlTrain batch 9/32 - 88.1ms/batch - loss: 1.42790 - diff: 22.85mlTrain batch 10/32 - 94.0ms/batch - loss: 1.44059 - diff: 23.05mlTrain batch 11/32 - 93.6ms/batch - loss: 1.44241 - diff: 23.08mlTrain batch 12/32 - 79.4ms/batch - loss: 1.42407 - diff: 22.79mlTrain batch 13/32 - 67.7ms/batch - loss: 1.40020 - diff: 22.40mlTrain batch 14/32 - 72.3ms/batch - loss: 1.41667 - diff: 22.67mlTrain batch 15/32 - 80.9ms/batch - loss: 1.39891 - diff: 22.38mlTrain batch 16/32 - 66.2ms/batch - loss: 1.38789 - diff: 22.21mlTrain batch 17/32 - 80.6ms/batch - loss: 1.43161 - diff: 22.91mlTrain batch 18/32 - 104.5ms/batch - loss: 1.44062 - diff: 23.05mlTrain batch 19/32 - 96.8ms/batch - loss: 1.48097 - diff: 23.70mlTrain batch 20/32 - 85.7ms/batch - loss: 1.46517 - diff: 23.44mlTrain batch 21/32 - 69.6ms/batch - loss: 1.48827 - diff: 23.81mlTrain batch 22/32 - 116.9ms/batch - loss: 1.51676 - diff: 24.27mlTrain batch 23/32 - 80.8ms/batch - loss: 1.49904 - diff: 23.98mlTrain batch 24/32 - 62.8ms/batch - loss: 1.53311 - diff: 24.53mlTrain batch 25/32 - 87.5ms/batch - loss: 1.51256 - diff: 24.20mlTrain batch 26/32 - 81.4ms/batch - loss: 1.52631 - diff: 24.42mlTrain batch 27/32 - 74.0ms/batch - loss: 1.50931 - diff: 24.15mlTrain batch 28/32 - 93.5ms/batch - loss: 1.50887 - diff: 24.14mlTrain batch 29/32 - 65.0ms/batch - loss: 1.49209 - diff: 23.87mlTrain batch 30/32 - 67.0ms/batch - loss: 1.54570 - diff: 24.73mlTrain batch 31/32 - 86.5ms/batch - loss: 1.55422 - diff: 24.87mlTrain batch 32/32 - 92.4ms/batch - loss: 1.60020 - diff: 24.90mlTrain batch 32/32 - 17.9s 92.4ms/batch - loss: 1.60020 - diff: 24.90ml
Test 0.9s: val_loss: 1.40220 - diff: 21.75ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Systole_DenseNet121_0_Adam-0.001_MAE_DA3_best

Epoch 31: current best loss = 1.40220, at epoch 30
Train batch 1/32 - 74.9ms/batch - loss: 0.98401 - diff: 15.74mlTrain batch 2/32 - 86.0ms/batch - loss: 1.26022 - diff: 20.16mlTrain batch 3/32 - 83.6ms/batch - loss: 1.38779 - diff: 22.20mlTrain batch 4/32 - 63.2ms/batch - loss: 1.28171 - diff: 20.51mlTrain batch 5/32 - 76.4ms/batch - loss: 1.27888 - diff: 20.46mlTrain batch 6/32 - 73.9ms/batch - loss: 1.67404 - diff: 26.78mlTrain batch 7/32 - 87.0ms/batch - loss: 1.55490 - diff: 24.88mlTrain batch 8/32 - 87.7ms/batch - loss: 1.57455 - diff: 25.19mlTrain batch 9/32 - 80.0ms/batch - loss: 1.55746 - diff: 24.92mlTrain batch 10/32 - 120.9ms/batch - loss: 1.63462 - diff: 26.15mlTrain batch 11/32 - 112.5ms/batch - loss: 1.65914 - diff: 26.55mlTrain batch 12/32 - 104.9ms/batch - loss: 1.64558 - diff: 26.33mlTrain batch 13/32 - 115.6ms/batch - loss: 1.63671 - diff: 26.19mlTrain batch 14/32 - 92.9ms/batch - loss: 1.62177 - diff: 25.95mlTrain batch 15/32 - 100.9ms/batch - loss: 1.63051 - diff: 26.09mlTrain batch 16/32 - 108.0ms/batch - loss: 1.61492 - diff: 25.84mlTrain batch 17/32 - 137.0ms/batch - loss: 1.59329 - diff: 25.49mlTrain batch 18/32 - 80.8ms/batch - loss: 1.60333 - diff: 25.65mlTrain batch 19/32 - 93.9ms/batch - loss: 1.55547 - diff: 24.89mlTrain batch 20/32 - 72.0ms/batch - loss: 1.55895 - diff: 24.94mlTrain batch 21/32 - 88.7ms/batch - loss: 1.52373 - diff: 24.38mlTrain batch 22/32 - 60.5ms/batch - loss: 1.54109 - diff: 24.66mlTrain batch 23/32 - 75.1ms/batch - loss: 1.53695 - diff: 24.59mlTrain batch 24/32 - 81.2ms/batch - loss: 1.52095 - diff: 24.34mlTrain batch 25/32 - 96.3ms/batch - loss: 1.51692 - diff: 24.27mlTrain batch 26/32 - 117.3ms/batch - loss: 1.53499 - diff: 24.56mlTrain batch 27/32 - 117.4ms/batch - loss: 1.52053 - diff: 24.33mlTrain batch 28/32 - 89.1ms/batch - loss: 1.54004 - diff: 24.64mlTrain batch 29/32 - 90.8ms/batch - loss: 1.53388 - diff: 24.54mlTrain batch 30/32 - 85.8ms/batch - loss: 1.56134 - diff: 24.98mlTrain batch 31/32 - 79.8ms/batch - loss: 1.56020 - diff: 24.96mlTrain batch 32/32 - 58.3ms/batch - loss: 1.56550 - diff: 24.83mlTrain batch 32/32 - 16.0s 58.3ms/batch - loss: 1.56550 - diff: 24.83ml
Test 1.0s: val_loss: 1.59459 - diff: 24.72ml

Epoch 32: current best loss = 1.40220, at epoch 30
Train batch 1/32 - 117.3ms/batch - loss: 1.20915 - diff: 19.35mlTrain batch 2/32 - 69.8ms/batch - loss: 1.32341 - diff: 21.17mlTrain batch 3/32 - 81.6ms/batch - loss: 1.50711 - diff: 24.11mlTrain batch 4/32 - 98.1ms/batch - loss: 1.47596 - diff: 23.62mlTrain batch 5/32 - 76.9ms/batch - loss: 1.55470 - diff: 24.88mlTrain batch 6/32 - 90.5ms/batch - loss: 1.56812 - diff: 25.09mlTrain batch 7/32 - 73.8ms/batch - loss: 1.55906 - diff: 24.94mlTrain batch 8/32 - 77.9ms/batch - loss: 1.56327 - diff: 25.01mlTrain batch 9/32 - 73.6ms/batch - loss: 1.56152 - diff: 24.98mlTrain batch 10/32 - 79.0ms/batch - loss: 1.70145 - diff: 27.22mlTrain batch 11/32 - 94.7ms/batch - loss: 1.67087 - diff: 26.73mlTrain batch 12/32 - 102.8ms/batch - loss: 1.66051 - diff: 26.57mlTrain batch 13/32 - 104.6ms/batch - loss: 1.71241 - diff: 27.40mlTrain batch 14/32 - 108.4ms/batch - loss: 1.66554 - diff: 26.65mlTrain batch 15/32 - 94.9ms/batch - loss: 1.61699 - diff: 25.87mlTrain batch 16/32 - 94.8ms/batch - loss: 1.57375 - diff: 25.18mlTrain batch 17/32 - 85.3ms/batch - loss: 1.58003 - diff: 25.28mlTrain batch 18/32 - 77.2ms/batch - loss: 1.59999 - diff: 25.60mlTrain batch 19/32 - 78.9ms/batch - loss: 1.60692 - diff: 25.71mlTrain batch 20/32 - 81.4ms/batch - loss: 1.59413 - diff: 25.51mlTrain batch 21/32 - 76.6ms/batch - loss: 1.57919 - diff: 25.27mlTrain batch 22/32 - 72.8ms/batch - loss: 1.56175 - diff: 24.99mlTrain batch 23/32 - 87.1ms/batch - loss: 1.56119 - diff: 24.98mlTrain batch 24/32 - 78.1ms/batch - loss: 1.54715 - diff: 24.75mlTrain batch 25/32 - 84.6ms/batch - loss: 1.54100 - diff: 24.66mlTrain batch 26/32 - 62.7ms/batch - loss: 1.51742 - diff: 24.28mlTrain batch 27/32 - 85.9ms/batch - loss: 1.50271 - diff: 24.04mlTrain batch 28/32 - 65.3ms/batch - loss: 1.49185 - diff: 23.87mlTrain batch 29/32 - 86.7ms/batch - loss: 1.48247 - diff: 23.72mlTrain batch 30/32 - 79.1ms/batch - loss: 1.48772 - diff: 23.80mlTrain batch 31/32 - 62.9ms/batch - loss: 1.48908 - diff: 23.83mlTrain batch 32/32 - 78.3ms/batch - loss: 1.53148 - diff: 23.85mlTrain batch 32/32 - 16.8s 78.3ms/batch - loss: 1.53148 - diff: 23.85ml
Test 1.0s: val_loss: 1.43995 - diff: 22.76ml

Epoch 33: current best loss = 1.40220, at epoch 30
Train batch 1/32 - 84.7ms/batch - loss: 1.17000 - diff: 18.72mlTrain batch 2/32 - 98.2ms/batch - loss: 1.27887 - diff: 20.46mlTrain batch 3/32 - 82.0ms/batch - loss: 1.44839 - diff: 23.17mlTrain batch 4/32 - 81.2ms/batch - loss: 1.45932 - diff: 23.35mlTrain batch 5/32 - 77.1ms/batch - loss: 1.65847 - diff: 26.54mlTrain batch 6/32 - 61.6ms/batch - loss: 1.62704 - diff: 26.03mlTrain batch 7/32 - 72.7ms/batch - loss: 1.59822 - diff: 25.57mlTrain batch 8/32 - 60.4ms/batch - loss: 1.64358 - diff: 26.30mlTrain batch 9/32 - 110.7ms/batch - loss: 1.68224 - diff: 26.92mlTrain batch 10/32 - 62.4ms/batch - loss: 1.68789 - diff: 27.01mlTrain batch 11/32 - 105.3ms/batch - loss: 1.64681 - diff: 26.35mlTrain batch 12/32 - 97.6ms/batch - loss: 1.60588 - diff: 25.69mlTrain batch 13/32 - 69.7ms/batch - loss: 1.55943 - diff: 24.95mlTrain batch 14/32 - 94.3ms/batch - loss: 1.52931 - diff: 24.47mlTrain batch 15/32 - 89.0ms/batch - loss: 1.52846 - diff: 24.46mlTrain batch 16/32 - 70.2ms/batch - loss: 1.52116 - diff: 24.34mlTrain batch 17/32 - 79.3ms/batch - loss: 1.48304 - diff: 23.73mlTrain batch 18/32 - 80.3ms/batch - loss: 1.46728 - diff: 23.48mlTrain batch 19/32 - 81.3ms/batch - loss: 1.51595 - diff: 24.26mlTrain batch 20/32 - 84.3ms/batch - loss: 1.50613 - diff: 24.10mlTrain batch 21/32 - 75.6ms/batch - loss: 1.49780 - diff: 23.96mlTrain batch 22/32 - 75.4ms/batch - loss: 1.49004 - diff: 23.84mlTrain batch 23/32 - 82.3ms/batch - loss: 1.46444 - diff: 23.43mlTrain batch 24/32 - 78.1ms/batch - loss: 1.46385 - diff: 23.42mlTrain batch 25/32 - 72.3ms/batch - loss: 1.46488 - diff: 23.44mlTrain batch 26/32 - 83.4ms/batch - loss: 1.46627 - diff: 23.46mlTrain batch 27/32 - 97.8ms/batch - loss: 1.46716 - diff: 23.47mlTrain batch 28/32 - 65.0ms/batch - loss: 1.49945 - diff: 23.99mlTrain batch 29/32 - 107.0ms/batch - loss: 1.49980 - diff: 24.00mlTrain batch 30/32 - 58.2ms/batch - loss: 1.49057 - diff: 23.85mlTrain batch 31/32 - 84.3ms/batch - loss: 1.51233 - diff: 24.20mlTrain batch 32/32 - 57.2ms/batch - loss: 1.52587 - diff: 24.11mlTrain batch 32/32 - 16.3s 57.2ms/batch - loss: 1.52587 - diff: 24.11ml
Test 1.0s: val_loss: 1.52723 - diff: 22.82ml

Epoch 34: current best loss = 1.40220, at epoch 30
Train batch 1/32 - 110.1ms/batch - loss: 1.52132 - diff: 24.34mlTrain batch 2/32 - 94.8ms/batch - loss: 1.54914 - diff: 24.79mlTrain batch 3/32 - 98.4ms/batch - loss: 1.62994 - diff: 26.08mlTrain batch 4/32 - 96.4ms/batch - loss: 1.48373 - diff: 23.74mlTrain batch 5/32 - 100.5ms/batch - loss: 1.57909 - diff: 25.27mlTrain batch 6/32 - 78.5ms/batch - loss: 1.59377 - diff: 25.50mlTrain batch 7/32 - 93.7ms/batch - loss: 1.48092 - diff: 23.69mlTrain batch 8/32 - 76.5ms/batch - loss: 1.44453 - diff: 23.11mlTrain batch 9/32 - 86.5ms/batch - loss: 1.42945 - diff: 22.87mlTrain batch 10/32 - 90.9ms/batch - loss: 1.45770 - diff: 23.32mlTrain batch 11/32 - 90.6ms/batch - loss: 1.51627 - diff: 24.26mlTrain batch 12/32 - 82.9ms/batch - loss: 1.49140 - diff: 23.86mlTrain batch 13/32 - 76.5ms/batch - loss: 1.46086 - diff: 23.37mlTrain batch 14/32 - 92.9ms/batch - loss: 1.48295 - diff: 23.73mlTrain batch 15/32 - 95.3ms/batch - loss: 1.46720 - diff: 23.48mlTrain batch 16/32 - 60.1ms/batch - loss: 1.49270 - diff: 23.88mlTrain batch 17/32 - 61.5ms/batch - loss: 1.46776 - diff: 23.48mlTrain batch 18/32 - 87.1ms/batch - loss: 1.48997 - diff: 23.84mlTrain batch 19/32 - 89.5ms/batch - loss: 1.56147 - diff: 24.98mlTrain batch 20/32 - 83.5ms/batch - loss: 1.56651 - diff: 25.06mlTrain batch 21/32 - 92.5ms/batch - loss: 1.54299 - diff: 24.69mlTrain batch 22/32 - 83.3ms/batch - loss: 1.52394 - diff: 24.38mlTrain batch 23/32 - 81.7ms/batch - loss: 1.49868 - diff: 23.98mlTrain batch 24/32 - 83.4ms/batch - loss: 1.48441 - diff: 23.75mlTrain batch 25/32 - 87.2ms/batch - loss: 1.47855 - diff: 23.66mlTrain batch 26/32 - 96.6ms/batch - loss: 1.49869 - diff: 23.98mlTrain batch 27/32 - 90.8ms/batch - loss: 1.49832 - diff: 23.97mlTrain batch 28/32 - 77.0ms/batch - loss: 1.49685 - diff: 23.95mlTrain batch 29/32 - 64.8ms/batch - loss: 1.48287 - diff: 23.73mlTrain batch 30/32 - 79.3ms/batch - loss: 1.49285 - diff: 23.89mlTrain batch 31/32 - 68.2ms/batch - loss: 1.47281 - diff: 23.56mlTrain batch 32/32 - 79.1ms/batch - loss: 1.48888 - diff: 23.49mlTrain batch 32/32 - 16.3s 79.1ms/batch - loss: 1.48888 - diff: 23.49ml
Test 0.9s: val_loss: 1.42526 - diff: 22.22ml

Epoch 35: current best loss = 1.40220, at epoch 30
Train batch 1/32 - 119.9ms/batch - loss: 1.13174 - diff: 18.11mlTrain batch 2/32 - 78.2ms/batch - loss: 1.14077 - diff: 18.25mlTrain batch 3/32 - 88.0ms/batch - loss: 1.13409 - diff: 18.15mlTrain batch 4/32 - 76.3ms/batch - loss: 1.31612 - diff: 21.06mlTrain batch 5/32 - 83.6ms/batch - loss: 1.61337 - diff: 25.81mlTrain batch 6/32 - 79.8ms/batch - loss: 1.58511 - diff: 25.36mlTrain batch 7/32 - 77.2ms/batch - loss: 1.59209 - diff: 25.47mlTrain batch 8/32 - 61.8ms/batch - loss: 1.54233 - diff: 24.68mlTrain batch 9/32 - 102.1ms/batch - loss: 1.54283 - diff: 24.69mlTrain batch 10/32 - 67.8ms/batch - loss: 1.53336 - diff: 24.53mlTrain batch 11/32 - 76.6ms/batch - loss: 1.49490 - diff: 23.92mlTrain batch 12/32 - 69.0ms/batch - loss: 1.50418 - diff: 24.07mlTrain batch 13/32 - 89.2ms/batch - loss: 1.47845 - diff: 23.66mlTrain batch 14/32 - 94.7ms/batch - loss: 1.46396 - diff: 23.42mlTrain batch 15/32 - 85.7ms/batch - loss: 1.46664 - diff: 23.47mlTrain batch 16/32 - 74.4ms/batch - loss: 1.50476 - diff: 24.08mlTrain batch 17/32 - 74.5ms/batch - loss: 1.48003 - diff: 23.68mlTrain batch 18/32 - 67.3ms/batch - loss: 1.48375 - diff: 23.74mlTrain batch 19/32 - 87.0ms/batch - loss: 1.45361 - diff: 23.26mlTrain batch 20/32 - 96.8ms/batch - loss: 1.46100 - diff: 23.38mlTrain batch 21/32 - 62.1ms/batch - loss: 1.45531 - diff: 23.28mlTrain batch 22/32 - 77.1ms/batch - loss: 1.45002 - diff: 23.20mlTrain batch 23/32 - 69.3ms/batch - loss: 1.47584 - diff: 23.61mlTrain batch 24/32 - 72.6ms/batch - loss: 1.47513 - diff: 23.60mlTrain batch 25/32 - 88.0ms/batch - loss: 1.46671 - diff: 23.47mlTrain batch 26/32 - 71.8ms/batch - loss: 1.47947 - diff: 23.67mlTrain batch 27/32 - 60.9ms/batch - loss: 1.46737 - diff: 23.48mlTrain batch 28/32 - 81.4ms/batch - loss: 1.45163 - diff: 23.23mlTrain batch 29/32 - 59.1ms/batch - loss: 1.47928 - diff: 23.67mlTrain batch 30/32 - 70.1ms/batch - loss: 1.46363 - diff: 23.42mlTrain batch 31/32 - 82.6ms/batch - loss: 1.45800 - diff: 23.33mlTrain batch 32/32 - 93.3ms/batch - loss: 1.55032 - diff: 23.56mlTrain batch 32/32 - 16.0s 93.3ms/batch - loss: 1.55032 - diff: 23.56ml
Test 1.0s: val_loss: 1.50546 - diff: 22.92ml

Epoch 36: current best loss = 1.40220, at epoch 30
Train batch 1/32 - 94.1ms/batch - loss: 1.46209 - diff: 23.39mlTrain batch 2/32 - 71.8ms/batch - loss: 1.92543 - diff: 30.81mlTrain batch 3/32 - 97.4ms/batch - loss: 1.67644 - diff: 26.82mlTrain batch 4/32 - 101.6ms/batch - loss: 1.68726 - diff: 27.00mlTrain batch 5/32 - 93.9ms/batch - loss: 1.82132 - diff: 29.14mlTrain batch 6/32 - 71.3ms/batch - loss: 1.76941 - diff: 28.31mlTrain batch 7/32 - 74.4ms/batch - loss: 1.70051 - diff: 27.21mlTrain batch 8/32 - 82.7ms/batch - loss: 1.57183 - diff: 25.15mlTrain batch 9/32 - 85.8ms/batch - loss: 1.52615 - diff: 24.42mlTrain batch 10/32 - 82.3ms/batch - loss: 1.50484 - diff: 24.08mlTrain batch 11/32 - 64.3ms/batch - loss: 1.46044 - diff: 23.37mlTrain batch 12/32 - 63.0ms/batch - loss: 1.51294 - diff: 24.21mlTrain batch 13/32 - 72.1ms/batch - loss: 1.50544 - diff: 24.09mlTrain batch 14/32 - 61.3ms/batch - loss: 1.47419 - diff: 23.59mlTrain batch 15/32 - 64.0ms/batch - loss: 1.50892 - diff: 24.14mlTrain batch 16/32 - 65.7ms/batch - loss: 1.51011 - diff: 24.16mlTrain batch 17/32 - 79.0ms/batch - loss: 1.47979 - diff: 23.68mlTrain batch 18/32 - 71.9ms/batch - loss: 1.50494 - diff: 24.08mlTrain batch 19/32 - 65.7ms/batch - loss: 1.49996 - diff: 24.00mlTrain batch 20/32 - 133.8ms/batch - loss: 1.50541 - diff: 24.09mlTrain batch 21/32 - 83.1ms/batch - loss: 1.51185 - diff: 24.19mlTrain batch 22/32 - 63.8ms/batch - loss: 1.48972 - diff: 23.84mlTrain batch 23/32 - 91.5ms/batch - loss: 1.47197 - diff: 23.55mlTrain batch 24/32 - 91.2ms/batch - loss: 1.47035 - diff: 23.53mlTrain batch 25/32 - 90.6ms/batch - loss: 1.48782 - diff: 23.81mlTrain batch 26/32 - 97.8ms/batch - loss: 1.49992 - diff: 24.00mlTrain batch 27/32 - 82.4ms/batch - loss: 1.49870 - diff: 23.98mlTrain batch 28/32 - 62.5ms/batch - loss: 1.49383 - diff: 23.90mlTrain batch 29/32 - 73.5ms/batch - loss: 1.48215 - diff: 23.71mlTrain batch 30/32 - 80.2ms/batch - loss: 1.48912 - diff: 23.83mlTrain batch 31/32 - 67.3ms/batch - loss: 1.46915 - diff: 23.51mlTrain batch 32/32 - 57.8ms/batch - loss: 1.51279 - diff: 23.54mlTrain batch 32/32 - 16.6s 57.8ms/batch - loss: 1.51279 - diff: 23.54ml
Test 0.9s: val_loss: 1.44275 - diff: 22.47ml

Epoch 37: current best loss = 1.40220, at epoch 30
Train batch 1/32 - 88.1ms/batch - loss: 1.71636 - diff: 27.46mlTrain batch 2/32 - 95.0ms/batch - loss: 1.56779 - diff: 25.08mlTrain batch 3/32 - 96.3ms/batch - loss: 1.36595 - diff: 21.86mlTrain batch 4/32 - 102.8ms/batch - loss: 1.42528 - diff: 22.80mlTrain batch 5/32 - 90.4ms/batch - loss: 1.40670 - diff: 22.51mlTrain batch 6/32 - 112.9ms/batch - loss: 1.37459 - diff: 21.99mlTrain batch 7/32 - 97.6ms/batch - loss: 1.35452 - diff: 21.67mlTrain batch 8/32 - 58.7ms/batch - loss: 1.30307 - diff: 20.85mlTrain batch 9/32 - 96.2ms/batch - loss: 1.30654 - diff: 20.90mlTrain batch 10/32 - 62.3ms/batch - loss: 1.29229 - diff: 20.68mlTrain batch 11/32 - 75.4ms/batch - loss: 1.27578 - diff: 20.41mlTrain batch 12/32 - 61.1ms/batch - loss: 1.28030 - diff: 20.48mlTrain batch 13/32 - 92.6ms/batch - loss: 1.31873 - diff: 21.10mlTrain batch 14/32 - 62.3ms/batch - loss: 1.34204 - diff: 21.47mlTrain batch 15/32 - 90.9ms/batch - loss: 1.54754 - diff: 24.76mlTrain batch 16/32 - 105.0ms/batch - loss: 1.54411 - diff: 24.71mlTrain batch 17/32 - 88.2ms/batch - loss: 1.49848 - diff: 23.98mlTrain batch 18/32 - 61.1ms/batch - loss: 1.50318 - diff: 24.05mlTrain batch 19/32 - 75.1ms/batch - loss: 1.48810 - diff: 23.81mlTrain batch 20/32 - 77.0ms/batch - loss: 1.48708 - diff: 23.79mlTrain batch 21/32 - 99.2ms/batch - loss: 1.46755 - diff: 23.48mlTrain batch 22/32 - 101.0ms/batch - loss: 1.44624 - diff: 23.14mlTrain batch 23/32 - 111.7ms/batch - loss: 1.45203 - diff: 23.23mlTrain batch 24/32 - 94.3ms/batch - loss: 1.46025 - diff: 23.36mlTrain batch 25/32 - 100.1ms/batch - loss: 1.45856 - diff: 23.34mlTrain batch 26/32 - 98.5ms/batch - loss: 1.45406 - diff: 23.26mlTrain batch 27/32 - 87.9ms/batch - loss: 1.46364 - diff: 23.42mlTrain batch 28/32 - 102.3ms/batch - loss: 1.46486 - diff: 23.44mlTrain batch 29/32 - 83.1ms/batch - loss: 1.48169 - diff: 23.71mlTrain batch 30/32 - 62.5ms/batch - loss: 1.46939 - diff: 23.51mlTrain batch 31/32 - 74.7ms/batch - loss: 1.47022 - diff: 23.52mlTrain batch 32/32 - 78.7ms/batch - loss: 1.47915 - diff: 23.42mlTrain batch 32/32 - 17.6s 78.7ms/batch - loss: 1.47915 - diff: 23.42ml
Test 0.9s: val_loss: 1.47763 - diff: 22.82ml

Epoch 38: current best loss = 1.40220, at epoch 30
Train batch 1/32 - 78.1ms/batch - loss: 1.37552 - diff: 22.01mlTrain batch 2/32 - 61.9ms/batch - loss: 1.29769 - diff: 20.76mlTrain batch 3/32 - 84.6ms/batch - loss: 1.40608 - diff: 22.50mlTrain batch 4/32 - 99.8ms/batch - loss: 1.37204 - diff: 21.95mlTrain batch 5/32 - 108.8ms/batch - loss: 1.40418 - diff: 22.47mlTrain batch 6/32 - 121.3ms/batch - loss: 1.37154 - diff: 21.94mlTrain batch 7/32 - 77.4ms/batch - loss: 1.50646 - diff: 24.10mlTrain batch 8/32 - 106.0ms/batch - loss: 1.42752 - diff: 22.84mlTrain batch 9/32 - 76.4ms/batch - loss: 1.47895 - diff: 23.66mlTrain batch 10/32 - 91.7ms/batch - loss: 1.49582 - diff: 23.93mlTrain batch 11/32 - 81.1ms/batch - loss: 1.48205 - diff: 23.71mlTrain batch 12/32 - 89.2ms/batch - loss: 1.47743 - diff: 23.64mlTrain batch 13/32 - 80.8ms/batch - loss: 1.50311 - diff: 24.05mlTrain batch 14/32 - 111.1ms/batch - loss: 1.48400 - diff: 23.74mlTrain batch 15/32 - 103.3ms/batch - loss: 1.49362 - diff: 23.90mlTrain batch 16/32 - 98.7ms/batch - loss: 1.49687 - diff: 23.95mlTrain batch 17/32 - 79.6ms/batch - loss: 1.55722 - diff: 24.92mlTrain batch 18/32 - 93.0ms/batch - loss: 1.54953 - diff: 24.79mlTrain batch 19/32 - 85.6ms/batch - loss: 1.54952 - diff: 24.79mlTrain batch 20/32 - 103.6ms/batch - loss: 1.52210 - diff: 24.35mlTrain batch 21/32 - 93.2ms/batch - loss: 1.49670 - diff: 23.95mlTrain batch 22/32 - 104.9ms/batch - loss: 1.48788 - diff: 23.81mlTrain batch 23/32 - 81.7ms/batch - loss: 1.46441 - diff: 23.43mlTrain batch 24/32 - 98.2ms/batch - loss: 1.45923 - diff: 23.35mlTrain batch 25/32 - 87.2ms/batch - loss: 1.50465 - diff: 24.07mlTrain batch 26/32 - 99.8ms/batch - loss: 1.49326 - diff: 23.89mlTrain batch 27/32 - 112.9ms/batch - loss: 1.48677 - diff: 23.79mlTrain batch 28/32 - 113.1ms/batch - loss: 1.47503 - diff: 23.60mlTrain batch 29/32 - 73.1ms/batch - loss: 1.46203 - diff: 23.39mlTrain batch 30/32 - 71.2ms/batch - loss: 1.48375 - diff: 23.74mlTrain batch 31/32 - 95.7ms/batch - loss: 1.47626 - diff: 23.62mlTrain batch 32/32 - 73.9ms/batch - loss: 1.54883 - diff: 23.77mlTrain batch 32/32 - 17.1s 73.9ms/batch - loss: 1.54883 - diff: 23.77ml
Test 1.0s: val_loss: 1.45275 - diff: 22.23ml

Epoch 39: current best loss = 1.40220, at epoch 30
Train batch 1/32 - 127.4ms/batch - loss: 1.45479 - diff: 23.28mlTrain batch 2/32 - 95.6ms/batch - loss: 1.18790 - diff: 19.01mlTrain batch 3/32 - 74.2ms/batch - loss: 1.16668 - diff: 18.67mlTrain batch 4/32 - 69.8ms/batch - loss: 1.25795 - diff: 20.13mlTrain batch 5/32 - 76.8ms/batch - loss: 1.32121 - diff: 21.14mlTrain batch 6/32 - 68.0ms/batch - loss: 1.34463 - diff: 21.51mlTrain batch 7/32 - 70.3ms/batch - loss: 1.43003 - diff: 22.88mlTrain batch 8/32 - 64.2ms/batch - loss: 1.36688 - diff: 21.87mlTrain batch 9/32 - 98.5ms/batch - loss: 1.35106 - diff: 21.62mlTrain batch 10/32 - 72.2ms/batch - loss: 1.36868 - diff: 21.90mlTrain batch 11/32 - 92.1ms/batch - loss: 1.38972 - diff: 22.24mlTrain batch 12/32 - 100.0ms/batch - loss: 1.38076 - diff: 22.09mlTrain batch 13/32 - 93.8ms/batch - loss: 1.37850 - diff: 22.06mlTrain batch 14/32 - 90.6ms/batch - loss: 1.43576 - diff: 22.97mlTrain batch 15/32 - 82.4ms/batch - loss: 1.45669 - diff: 23.31mlTrain batch 16/32 - 74.1ms/batch - loss: 1.49192 - diff: 23.87mlTrain batch 17/32 - 78.4ms/batch - loss: 1.47049 - diff: 23.53mlTrain batch 18/32 - 111.5ms/batch - loss: 1.48421 - diff: 23.75mlTrain batch 19/32 - 76.8ms/batch - loss: 1.46518 - diff: 23.44mlTrain batch 20/32 - 92.6ms/batch - loss: 1.50454 - diff: 24.07mlTrain batch 21/32 - 95.0ms/batch - loss: 1.48266 - diff: 23.72mlTrain batch 22/32 - 61.4ms/batch - loss: 1.46707 - diff: 23.47mlTrain batch 23/32 - 73.4ms/batch - loss: 1.55394 - diff: 24.86mlTrain batch 24/32 - 97.2ms/batch - loss: 1.58525 - diff: 25.36mlTrain batch 25/32 - 80.8ms/batch - loss: 1.57432 - diff: 25.19mlTrain batch 26/32 - 64.1ms/batch - loss: 1.58133 - diff: 25.30mlTrain batch 27/32 - 134.1ms/batch - loss: 1.55584 - diff: 24.89mlTrain batch 28/32 - 96.6ms/batch - loss: 1.54047 - diff: 24.65mlTrain batch 29/32 - 62.6ms/batch - loss: 1.53391 - diff: 24.54mlTrain batch 30/32 - 88.7ms/batch - loss: 1.53367 - diff: 24.54mlTrain batch 31/32 - 85.3ms/batch - loss: 1.51447 - diff: 24.23mlTrain batch 32/32 - 55.6ms/batch - loss: 1.59859 - diff: 24.42mlTrain batch 32/32 - 16.1s 55.6ms/batch - loss: 1.59859 - diff: 24.42ml
Test 0.8s: val_loss: 1.66235 - diff: 25.85ml

Epoch 40: current best loss = 1.40220, at epoch 30
Train batch 1/32 - 147.6ms/batch - loss: 1.84716 - diff: 29.55mlTrain batch 2/32 - 112.3ms/batch - loss: 1.61308 - diff: 25.81mlTrain batch 3/32 - 83.0ms/batch - loss: 1.34166 - diff: 21.47mlTrain batch 4/32 - 85.2ms/batch - loss: 1.32440 - diff: 21.19mlTrain batch 5/32 - 94.0ms/batch - loss: 1.38297 - diff: 22.13mlTrain batch 6/32 - 105.5ms/batch - loss: 1.37289 - diff: 21.97mlTrain batch 7/32 - 85.7ms/batch - loss: 1.36536 - diff: 21.85mlTrain batch 8/32 - 118.1ms/batch - loss: 1.35490 - diff: 21.68mlTrain batch 9/32 - 72.5ms/batch - loss: 1.34863 - diff: 21.58mlTrain batch 10/32 - 82.0ms/batch - loss: 1.38356 - diff: 22.14mlTrain batch 11/32 - 81.3ms/batch - loss: 1.44070 - diff: 23.05mlTrain batch 12/32 - 107.2ms/batch - loss: 1.40612 - diff: 22.50mlTrain batch 13/32 - 91.2ms/batch - loss: 1.43340 - diff: 22.93mlTrain batch 14/32 - 95.9ms/batch - loss: 1.40386 - diff: 22.46mlTrain batch 15/32 - 79.4ms/batch - loss: 1.45150 - diff: 23.22mlTrain batch 16/32 - 93.7ms/batch - loss: 1.41755 - diff: 22.68mlTrain batch 17/32 - 94.2ms/batch - loss: 1.42093 - diff: 22.73mlTrain batch 18/32 - 113.1ms/batch - loss: 1.41368 - diff: 22.62mlTrain batch 19/32 - 105.6ms/batch - loss: 1.41353 - diff: 22.62mlTrain batch 20/32 - 95.9ms/batch - loss: 1.39848 - diff: 22.38mlTrain batch 21/32 - 100.1ms/batch - loss: 1.41660 - diff: 22.67mlTrain batch 22/32 - 98.1ms/batch - loss: 1.38300 - diff: 22.13mlTrain batch 23/32 - 97.9ms/batch - loss: 1.37616 - diff: 22.02mlTrain batch 24/32 - 96.2ms/batch - loss: 1.38747 - diff: 22.20mlTrain batch 25/32 - 65.8ms/batch - loss: 1.38248 - diff: 22.12mlTrain batch 26/32 - 82.1ms/batch - loss: 1.43363 - diff: 22.94mlTrain batch 27/32 - 84.5ms/batch - loss: 1.44938 - diff: 23.19mlTrain batch 28/32 - 100.3ms/batch - loss: 1.42596 - diff: 22.82mlTrain batch 29/32 - 90.3ms/batch - loss: 1.48083 - diff: 23.69mlTrain batch 30/32 - 107.3ms/batch - loss: 1.47833 - diff: 23.65mlTrain batch 31/32 - 66.9ms/batch - loss: 1.47133 - diff: 23.54mlTrain batch 32/32 - 108.7ms/batch - loss: 1.50529 - diff: 23.54mlTrain batch 32/32 - 16.9s 108.7ms/batch - loss: 1.50529 - diff: 23.54ml
Test 0.9s: val_loss: 1.48308 - diff: 22.78ml

Epoch 41: current best loss = 1.40220, at epoch 30
Train batch 1/32 - 96.7ms/batch - loss: 1.87087 - diff: 29.93mlTrain batch 2/32 - 95.2ms/batch - loss: 1.58242 - diff: 25.32mlTrain batch 3/32 - 79.4ms/batch - loss: 1.49985 - diff: 24.00mlTrain batch 4/32 - 96.2ms/batch - loss: 1.70095 - diff: 27.22mlTrain batch 5/32 - 76.4ms/batch - loss: 1.72374 - diff: 27.58mlTrain batch 6/32 - 87.4ms/batch - loss: 1.91311 - diff: 30.61mlTrain batch 7/32 - 93.6ms/batch - loss: 1.78504 - diff: 28.56mlTrain batch 8/32 - 88.4ms/batch - loss: 1.67822 - diff: 26.85mlTrain batch 9/32 - 72.2ms/batch - loss: 1.75654 - diff: 28.10mlTrain batch 10/32 - 86.8ms/batch - loss: 1.72871 - diff: 27.66mlTrain batch 11/32 - 73.2ms/batch - loss: 1.69910 - diff: 27.19mlTrain batch 12/32 - 79.4ms/batch - loss: 1.68503 - diff: 26.96mlTrain batch 13/32 - 75.6ms/batch - loss: 1.64913 - diff: 26.39mlTrain batch 14/32 - 103.5ms/batch - loss: 1.64313 - diff: 26.29mlTrain batch 15/32 - 80.8ms/batch - loss: 1.62612 - diff: 26.02mlTrain batch 16/32 - 95.4ms/batch - loss: 1.61732 - diff: 25.88mlTrain batch 17/32 - 115.4ms/batch - loss: 1.59614 - diff: 25.54mlTrain batch 18/32 - 103.6ms/batch - loss: 1.56739 - diff: 25.08mlTrain batch 19/32 - 74.0ms/batch - loss: 1.55639 - diff: 24.90mlTrain batch 20/32 - 78.0ms/batch - loss: 1.53173 - diff: 24.51mlTrain batch 21/32 - 88.7ms/batch - loss: 1.52122 - diff: 24.34mlTrain batch 22/32 - 81.5ms/batch - loss: 1.52037 - diff: 24.33mlTrain batch 23/32 - 71.0ms/batch - loss: 1.52087 - diff: 24.33mlTrain batch 24/32 - 82.3ms/batch - loss: 1.50176 - diff: 24.03mlTrain batch 25/32 - 76.5ms/batch - loss: 1.51970 - diff: 24.32mlTrain batch 26/32 - 74.7ms/batch - loss: 1.55725 - diff: 24.92mlTrain batch 27/32 - 70.7ms/batch - loss: 1.54163 - diff: 24.67mlTrain batch 28/32 - 75.0ms/batch - loss: 1.53175 - diff: 24.51mlTrain batch 29/32 - 96.6ms/batch - loss: 1.51858 - diff: 24.30mlTrain batch 30/32 - 80.2ms/batch - loss: 1.51994 - diff: 24.32mlTrain batch 31/32 - 68.1ms/batch - loss: 1.50730 - diff: 24.12mlTrain batch 32/32 - 57.2ms/batch - loss: 1.51066 - diff: 23.99mlTrain batch 32/32 - 16.0s 57.2ms/batch - loss: 1.51066 - diff: 23.99ml
Test 0.8s: val_loss: 1.55559 - diff: 23.41ml
Epoch    42: reducing learning rate of group 0 to 5.0000e-04.

Epoch 42: current best loss = 1.40220, at epoch 30
Train batch 1/32 - 105.1ms/batch - loss: 1.37610 - diff: 22.02mlTrain batch 2/32 - 76.6ms/batch - loss: 1.16916 - diff: 18.71mlTrain batch 3/32 - 77.0ms/batch - loss: 1.27800 - diff: 20.45mlTrain batch 4/32 - 76.4ms/batch - loss: 1.21441 - diff: 19.43mlTrain batch 5/32 - 80.3ms/batch - loss: 1.24216 - diff: 19.87mlTrain batch 6/32 - 63.7ms/batch - loss: 1.31041 - diff: 20.97mlTrain batch 7/32 - 87.8ms/batch - loss: 1.40604 - diff: 22.50mlTrain batch 8/32 - 111.3ms/batch - loss: 1.42827 - diff: 22.85mlTrain batch 9/32 - 77.5ms/batch - loss: 1.35500 - diff: 21.68mlTrain batch 10/32 - 79.0ms/batch - loss: 1.39576 - diff: 22.33mlTrain batch 11/32 - 64.2ms/batch - loss: 1.43952 - diff: 23.03mlTrain batch 12/32 - 121.6ms/batch - loss: 1.40606 - diff: 22.50mlTrain batch 13/32 - 88.3ms/batch - loss: 1.39964 - diff: 22.39mlTrain batch 14/32 - 61.6ms/batch - loss: 1.39647 - diff: 22.34mlTrain batch 15/32 - 95.6ms/batch - loss: 1.41067 - diff: 22.57mlTrain batch 16/32 - 109.5ms/batch - loss: 1.37998 - diff: 22.08mlTrain batch 17/32 - 90.8ms/batch - loss: 1.48108 - diff: 23.70mlTrain batch 18/32 - 88.0ms/batch - loss: 1.45777 - diff: 23.32mlTrain batch 19/32 - 79.3ms/batch - loss: 1.45736 - diff: 23.32mlTrain batch 20/32 - 80.6ms/batch - loss: 1.45511 - diff: 23.28mlTrain batch 21/32 - 64.7ms/batch - loss: 1.44755 - diff: 23.16mlTrain batch 22/32 - 62.6ms/batch - loss: 1.46061 - diff: 23.37mlTrain batch 23/32 - 108.5ms/batch - loss: 1.45509 - diff: 23.28mlTrain batch 24/32 - 95.4ms/batch - loss: 1.47112 - diff: 23.54mlTrain batch 25/32 - 86.7ms/batch - loss: 1.45444 - diff: 23.27mlTrain batch 26/32 - 77.6ms/batch - loss: 1.47801 - diff: 23.65mlTrain batch 27/32 - 90.2ms/batch - loss: 1.46951 - diff: 23.51mlTrain batch 28/32 - 112.3ms/batch - loss: 1.47199 - diff: 23.55mlTrain batch 29/32 - 84.8ms/batch - loss: 1.48161 - diff: 23.71mlTrain batch 30/32 - 87.9ms/batch - loss: 1.47958 - diff: 23.67mlTrain batch 31/32 - 83.3ms/batch - loss: 1.46356 - diff: 23.42mlTrain batch 32/32 - 90.4ms/batch - loss: 1.50976 - diff: 23.46mlTrain batch 32/32 - 17.9s 90.4ms/batch - loss: 1.50976 - diff: 23.46ml
Test 0.9s: val_loss: 1.51941 - diff: 23.05ml

Epoch 43: current best loss = 1.40220, at epoch 30
Train batch 1/32 - 110.6ms/batch - loss: 2.21771 - diff: 35.48mlTrain batch 2/32 - 87.8ms/batch - loss: 1.85590 - diff: 29.69mlTrain batch 3/32 - 96.2ms/batch - loss: 1.77934 - diff: 28.47mlTrain batch 4/32 - 77.9ms/batch - loss: 1.58127 - diff: 25.30mlTrain batch 5/32 - 101.7ms/batch - loss: 1.69202 - diff: 27.07mlTrain batch 6/32 - 98.0ms/batch - loss: 1.59677 - diff: 25.55mlTrain batch 7/32 - 93.0ms/batch - loss: 1.57193 - diff: 25.15mlTrain batch 8/32 - 76.8ms/batch - loss: 1.53759 - diff: 24.60mlTrain batch 9/32 - 82.7ms/batch - loss: 1.47234 - diff: 23.56mlTrain batch 10/32 - 75.5ms/batch - loss: 1.49290 - diff: 23.89mlTrain batch 11/32 - 79.1ms/batch - loss: 1.51183 - diff: 24.19mlTrain batch 12/32 - 84.4ms/batch - loss: 1.51560 - diff: 24.25mlTrain batch 13/32 - 67.8ms/batch - loss: 1.52904 - diff: 24.46mlTrain batch 14/32 - 83.4ms/batch - loss: 1.63155 - diff: 26.10mlTrain batch 15/32 - 97.4ms/batch - loss: 1.63981 - diff: 26.24mlTrain batch 16/32 - 97.8ms/batch - loss: 1.61310 - diff: 25.81mlTrain batch 17/32 - 104.8ms/batch - loss: 1.58845 - diff: 25.42mlTrain batch 18/32 - 82.0ms/batch - loss: 1.57485 - diff: 25.20mlTrain batch 19/32 - 70.6ms/batch - loss: 1.61022 - diff: 25.76mlTrain batch 20/32 - 89.7ms/batch - loss: 1.61263 - diff: 25.80mlTrain batch 21/32 - 80.1ms/batch - loss: 1.60176 - diff: 25.63mlTrain batch 22/32 - 77.0ms/batch - loss: 1.59510 - diff: 25.52mlTrain batch 23/32 - 85.4ms/batch - loss: 1.58010 - diff: 25.28mlTrain batch 24/32 - 86.2ms/batch - loss: 1.56685 - diff: 25.07mlTrain batch 25/32 - 72.1ms/batch - loss: 1.55360 - diff: 24.86mlTrain batch 26/32 - 73.5ms/batch - loss: 1.55009 - diff: 24.80mlTrain batch 27/32 - 100.1ms/batch - loss: 1.56313 - diff: 25.01mlTrain batch 28/32 - 114.1ms/batch - loss: 1.53761 - diff: 24.60mlTrain batch 29/32 - 94.9ms/batch - loss: 1.54260 - diff: 24.68mlTrain batch 30/32 - 99.5ms/batch - loss: 1.56544 - diff: 25.05mlTrain batch 31/32 - 65.8ms/batch - loss: 1.56264 - diff: 25.00mlTrain batch 32/32 - 93.3ms/batch - loss: 1.58135 - diff: 24.93mlTrain batch 32/32 - 17.1s 93.3ms/batch - loss: 1.58135 - diff: 24.93ml
Test 0.9s: val_loss: 1.44521 - diff: 22.51ml

Epoch 44: current best loss = 1.40220, at epoch 30
Train batch 1/32 - 70.1ms/batch - loss: 2.93969 - diff: 47.04mlTrain batch 2/32 - 61.7ms/batch - loss: 2.25616 - diff: 36.10mlTrain batch 3/32 - 105.6ms/batch - loss: 1.69833 - diff: 27.17mlTrain batch 4/32 - 69.6ms/batch - loss: 1.74197 - diff: 27.87mlTrain batch 5/32 - 96.8ms/batch - loss: 1.63973 - diff: 26.24mlTrain batch 6/32 - 99.7ms/batch - loss: 1.67035 - diff: 26.73mlTrain batch 7/32 - 79.3ms/batch - loss: 1.66653 - diff: 26.66mlTrain batch 8/32 - 92.2ms/batch - loss: 1.60047 - diff: 25.61mlTrain batch 9/32 - 63.7ms/batch - loss: 1.57387 - diff: 25.18mlTrain batch 10/32 - 108.2ms/batch - loss: 1.53689 - diff: 24.59mlTrain batch 11/32 - 90.9ms/batch - loss: 1.48806 - diff: 23.81mlTrain batch 12/32 - 95.2ms/batch - loss: 1.49756 - diff: 23.96mlTrain batch 13/32 - 102.2ms/batch - loss: 1.48336 - diff: 23.73mlTrain batch 14/32 - 89.8ms/batch - loss: 1.52329 - diff: 24.37mlTrain batch 15/32 - 108.3ms/batch - loss: 1.49769 - diff: 23.96mlTrain batch 16/32 - 76.0ms/batch - loss: 1.49544 - diff: 23.93mlTrain batch 17/32 - 103.3ms/batch - loss: 1.54492 - diff: 24.72mlTrain batch 18/32 - 80.5ms/batch - loss: 1.53518 - diff: 24.56mlTrain batch 19/32 - 58.8ms/batch - loss: 1.51926 - diff: 24.31mlTrain batch 20/32 - 58.5ms/batch - loss: 1.50433 - diff: 24.07mlTrain batch 21/32 - 59.3ms/batch - loss: 1.50579 - diff: 24.09mlTrain batch 22/32 - 59.8ms/batch - loss: 1.49877 - diff: 23.98mlTrain batch 23/32 - 99.8ms/batch - loss: 1.50917 - diff: 24.15mlTrain batch 24/32 - 74.8ms/batch - loss: 1.48426 - diff: 23.75mlTrain batch 25/32 - 73.1ms/batch - loss: 1.48078 - diff: 23.69mlTrain batch 26/32 - 99.9ms/batch - loss: 1.45285 - diff: 23.25mlTrain batch 27/32 - 111.6ms/batch - loss: 1.44732 - diff: 23.16mlTrain batch 28/32 - 76.9ms/batch - loss: 1.42564 - diff: 22.81mlTrain batch 29/32 - 91.2ms/batch - loss: 1.41943 - diff: 22.71mlTrain batch 30/32 - 63.5ms/batch - loss: 1.42589 - diff: 22.81mlTrain batch 31/32 - 93.1ms/batch - loss: 1.40979 - diff: 22.56mlTrain batch 32/32 - 57.8ms/batch - loss: 1.45983 - diff: 22.62mlTrain batch 32/32 - 15.6s 57.8ms/batch - loss: 1.45983 - diff: 22.62ml
Test 0.9s: val_loss: 1.41324 - diff: 21.86ml

Epoch 45: current best loss = 1.40220, at epoch 30
Going to unfreeze the pretrained weights
Train batch 1/32 - 150.5ms/batch - loss: 1.34377 - diff: 21.50mlTrain batch 2/32 - 143.8ms/batch - loss: 1.46811 - diff: 23.49mlTrain batch 3/32 - 133.4ms/batch - loss: 1.41905 - diff: 22.70mlTrain batch 4/32 - 117.6ms/batch - loss: 1.44366 - diff: 23.10mlTrain batch 5/32 - 138.5ms/batch - loss: 1.54623 - diff: 24.74mlTrain batch 6/32 - 105.2ms/batch - loss: 1.66667 - diff: 26.67mlTrain batch 7/32 - 183.4ms/batch - loss: 1.78202 - diff: 28.51mlTrain batch 8/32 - 191.2ms/batch - loss: 1.82277 - diff: 29.16mlTrain batch 9/32 - 165.6ms/batch - loss: 1.90022 - diff: 30.40mlTrain batch 10/32 - 165.6ms/batch - loss: 1.95830 - diff: 31.33mlTrain batch 11/32 - 157.1ms/batch - loss: 1.91076 - diff: 30.57mlTrain batch 12/32 - 169.7ms/batch - loss: 1.92822 - diff: 30.85mlTrain batch 13/32 - 196.3ms/batch - loss: 1.90277 - diff: 30.44mlTrain batch 14/32 - 214.7ms/batch - loss: 1.91828 - diff: 30.69mlTrain batch 15/32 - 198.2ms/batch - loss: 1.90455 - diff: 30.47mlTrain batch 16/32 - 146.9ms/batch - loss: 1.94175 - diff: 31.07mlTrain batch 17/32 - 176.1ms/batch - loss: 1.90017 - diff: 30.40mlTrain batch 18/32 - 151.7ms/batch - loss: 1.87677 - diff: 30.03mlTrain batch 19/32 - 174.9ms/batch - loss: 1.85814 - diff: 29.73mlTrain batch 20/32 - 159.9ms/batch - loss: 1.84360 - diff: 29.50mlTrain batch 21/32 - 164.4ms/batch - loss: 1.83228 - diff: 29.32mlTrain batch 22/32 - 148.3ms/batch - loss: 1.81508 - diff: 29.04mlTrain batch 23/32 - 118.8ms/batch - loss: 1.82472 - diff: 29.20mlTrain batch 24/32 - 176.6ms/batch - loss: 1.83891 - diff: 29.42mlTrain batch 25/32 - 176.1ms/batch - loss: 1.80861 - diff: 28.94mlTrain batch 26/32 - 165.8ms/batch - loss: 1.79737 - diff: 28.76mlTrain batch 27/32 - 162.8ms/batch - loss: 1.80695 - diff: 28.91mlTrain batch 28/32 - 164.9ms/batch - loss: 1.78982 - diff: 28.64mlTrain batch 29/32 - 160.8ms/batch - loss: 1.78900 - diff: 28.62mlTrain batch 30/32 - 165.2ms/batch - loss: 1.80361 - diff: 28.86mlTrain batch 31/32 - 108.3ms/batch - loss: 1.80182 - diff: 28.83mlTrain batch 32/32 - 125.2ms/batch - loss: 1.81448 - diff: 28.71mlTrain batch 32/32 - 15.9s 125.2ms/batch - loss: 1.81448 - diff: 28.71ml
Test 0.9s: val_loss: 1.73342 - diff: 25.54ml

Epoch 46: current best loss = 1.40220, at epoch 30
Train batch 1/32 - 165.1ms/batch - loss: 1.77778 - diff: 28.44mlTrain batch 2/32 - 134.1ms/batch - loss: 2.03149 - diff: 32.50mlTrain batch 3/32 - 140.5ms/batch - loss: 1.65309 - diff: 26.45mlTrain batch 4/32 - 138.5ms/batch - loss: 1.71507 - diff: 27.44mlTrain batch 5/32 - 153.9ms/batch - loss: 1.69271 - diff: 27.08mlTrain batch 6/32 - 178.2ms/batch - loss: 1.68168 - diff: 26.91mlTrain batch 7/32 - 164.2ms/batch - loss: 1.63238 - diff: 26.12mlTrain batch 8/32 - 177.3ms/batch - loss: 1.79284 - diff: 28.69mlTrain batch 9/32 - 141.4ms/batch - loss: 1.77763 - diff: 28.44mlTrain batch 10/32 - 147.7ms/batch - loss: 1.81946 - diff: 29.11mlTrain batch 11/32 - 113.5ms/batch - loss: 1.81630 - diff: 29.06mlTrain batch 12/32 - 155.5ms/batch - loss: 1.80163 - diff: 28.83mlTrain batch 13/32 - 156.7ms/batch - loss: 1.76970 - diff: 28.32mlTrain batch 14/32 - 103.3ms/batch - loss: 1.75447 - diff: 28.07mlTrain batch 15/32 - 106.9ms/batch - loss: 1.75603 - diff: 28.10mlTrain batch 16/32 - 160.9ms/batch - loss: 1.73595 - diff: 27.78mlTrain batch 17/32 - 150.1ms/batch - loss: 1.72815 - diff: 27.65mlTrain batch 18/32 - 198.6ms/batch - loss: 1.69211 - diff: 27.07mlTrain batch 19/32 - 153.0ms/batch - loss: 1.67852 - diff: 26.86mlTrain batch 20/32 - 157.5ms/batch - loss: 1.72628 - diff: 27.62mlTrain batch 21/32 - 122.4ms/batch - loss: 1.72145 - diff: 27.54mlTrain batch 22/32 - 139.4ms/batch - loss: 1.73162 - diff: 27.71mlTrain batch 23/32 - 126.3ms/batch - loss: 1.70644 - diff: 27.30mlTrain batch 24/32 - 139.8ms/batch - loss: 1.71776 - diff: 27.48mlTrain batch 25/32 - 189.3ms/batch - loss: 1.72475 - diff: 27.60mlTrain batch 26/32 - 180.6ms/batch - loss: 1.73507 - diff: 27.76mlTrain batch 27/32 - 197.2ms/batch - loss: 1.72587 - diff: 27.61mlTrain batch 28/32 - 212.8ms/batch - loss: 1.70367 - diff: 27.26mlTrain batch 29/32 - 217.2ms/batch - loss: 1.68555 - diff: 26.97mlTrain batch 30/32 - 186.5ms/batch - loss: 1.69133 - diff: 27.06mlTrain batch 31/32 - 147.4ms/batch - loss: 1.69182 - diff: 27.07mlTrain batch 32/32 - 147.4ms/batch - loss: 1.70940 - diff: 26.98mlTrain batch 32/32 - 16.3s 147.4ms/batch - loss: 1.70940 - diff: 26.98ml
Test 0.9s: val_loss: 1.87518 - diff: 29.22ml

Epoch 47: current best loss = 1.40220, at epoch 30
Train batch 1/32 - 183.1ms/batch - loss: 1.78595 - diff: 28.58mlTrain batch 2/32 - 140.9ms/batch - loss: 1.99531 - diff: 31.92mlTrain batch 3/32 - 127.8ms/batch - loss: 1.74669 - diff: 27.95mlTrain batch 4/32 - 125.6ms/batch - loss: 1.61863 - diff: 25.90mlTrain batch 5/32 - 171.2ms/batch - loss: 1.63585 - diff: 26.17mlTrain batch 6/32 - 165.1ms/batch - loss: 1.61208 - diff: 25.79mlTrain batch 7/32 - 168.2ms/batch - loss: 1.60773 - diff: 25.72mlTrain batch 8/32 - 108.0ms/batch - loss: 1.56972 - diff: 25.12mlTrain batch 9/32 - 114.9ms/batch - loss: 1.63430 - diff: 26.15mlTrain batch 10/32 - 129.2ms/batch - loss: 1.59677 - diff: 25.55mlTrain batch 11/32 - 175.3ms/batch - loss: 1.59117 - diff: 25.46mlTrain batch 12/32 - 187.2ms/batch - loss: 1.52795 - diff: 24.45mlTrain batch 13/32 - 170.0ms/batch - loss: 1.51559 - diff: 24.25mlTrain batch 14/32 - 193.7ms/batch - loss: 1.52594 - diff: 24.42mlTrain batch 15/32 - 174.0ms/batch - loss: 1.56608 - diff: 25.06mlTrain batch 16/32 - 177.5ms/batch - loss: 1.53240 - diff: 24.52mlTrain batch 17/32 - 130.4ms/batch - loss: 1.58938 - diff: 25.43mlTrain batch 18/32 - 111.4ms/batch - loss: 1.57343 - diff: 25.17mlTrain batch 19/32 - 143.1ms/batch - loss: 1.54067 - diff: 24.65mlTrain batch 20/32 - 132.1ms/batch - loss: 1.52628 - diff: 24.42mlTrain batch 21/32 - 126.8ms/batch - loss: 1.55983 - diff: 24.96mlTrain batch 22/32 - 141.3ms/batch - loss: 1.58044 - diff: 25.29mlTrain batch 23/32 - 153.4ms/batch - loss: 1.57643 - diff: 25.22mlTrain batch 24/32 - 163.4ms/batch - loss: 1.56027 - diff: 24.96mlTrain batch 25/32 - 131.8ms/batch - loss: 1.54413 - diff: 24.71mlTrain batch 26/32 - 107.1ms/batch - loss: 1.53230 - diff: 24.52mlTrain batch 27/32 - 137.4ms/batch - loss: 1.56731 - diff: 25.08mlTrain batch 28/32 - 150.0ms/batch - loss: 1.55560 - diff: 24.89mlTrain batch 29/32 - 152.2ms/batch - loss: 1.55657 - diff: 24.91mlTrain batch 30/32 - 157.2ms/batch - loss: 1.55998 - diff: 24.96mlTrain batch 31/32 - 150.2ms/batch - loss: 1.55508 - diff: 24.88mlTrain batch 32/32 - 167.4ms/batch - loss: 1.56113 - diff: 24.76mlTrain batch 32/32 - 17.0s 167.4ms/batch - loss: 1.56113 - diff: 24.76ml
Test 0.9s: val_loss: 1.48208 - diff: 23.02ml

Epoch 48: current best loss = 1.40220, at epoch 30
Train batch 1/32 - 185.4ms/batch - loss: 1.16064 - diff: 18.57mlTrain batch 2/32 - 194.4ms/batch - loss: 1.40783 - diff: 22.53mlTrain batch 3/32 - 163.3ms/batch - loss: 1.30988 - diff: 20.96mlTrain batch 4/32 - 119.3ms/batch - loss: 1.37031 - diff: 21.93mlTrain batch 5/32 - 192.1ms/batch - loss: 1.44216 - diff: 23.07mlTrain batch 6/32 - 135.7ms/batch - loss: 1.49191 - diff: 23.87mlTrain batch 7/32 - 166.2ms/batch - loss: 1.43558 - diff: 22.97mlTrain batch 8/32 - 203.7ms/batch - loss: 1.37677 - diff: 22.03mlTrain batch 9/32 - 179.5ms/batch - loss: 1.36522 - diff: 21.84mlTrain batch 10/32 - 138.3ms/batch - loss: 1.38571 - diff: 22.17mlTrain batch 11/32 - 111.4ms/batch - loss: 1.39939 - diff: 22.39mlTrain batch 12/32 - 159.8ms/batch - loss: 1.38806 - diff: 22.21mlTrain batch 13/32 - 182.7ms/batch - loss: 1.37444 - diff: 21.99mlTrain batch 14/32 - 152.0ms/batch - loss: 1.40069 - diff: 22.41mlTrain batch 15/32 - 156.9ms/batch - loss: 1.39516 - diff: 22.32mlTrain batch 16/32 - 122.7ms/batch - loss: 1.41598 - diff: 22.66mlTrain batch 17/32 - 179.5ms/batch - loss: 1.39711 - diff: 22.35mlTrain batch 18/32 - 188.0ms/batch - loss: 1.41394 - diff: 22.62mlTrain batch 19/32 - 196.5ms/batch - loss: 1.41670 - diff: 22.67mlTrain batch 20/32 - 168.0ms/batch - loss: 1.40823 - diff: 22.53mlTrain batch 21/32 - 136.6ms/batch - loss: 1.38648 - diff: 22.18mlTrain batch 22/32 - 180.1ms/batch - loss: 1.39141 - diff: 22.26mlTrain batch 23/32 - 186.5ms/batch - loss: 1.37539 - diff: 22.01mlTrain batch 24/32 - 203.9ms/batch - loss: 1.36949 - diff: 21.91mlTrain batch 25/32 - 174.9ms/batch - loss: 1.46405 - diff: 23.42mlTrain batch 26/32 - 187.7ms/batch - loss: 1.48353 - diff: 23.74mlTrain batch 27/32 - 170.6ms/batch - loss: 1.47583 - diff: 23.61mlTrain batch 28/32 - 160.4ms/batch - loss: 1.46611 - diff: 23.46mlTrain batch 29/32 - 142.0ms/batch - loss: 1.47717 - diff: 23.63mlTrain batch 30/32 - 179.5ms/batch - loss: 1.46859 - diff: 23.50mlTrain batch 31/32 - 144.9ms/batch - loss: 1.47223 - diff: 23.56mlTrain batch 32/32 - 177.0ms/batch - loss: 1.49073 - diff: 23.49mlTrain batch 32/32 - 17.0s 177.0ms/batch - loss: 1.49073 - diff: 23.49ml
Test 1.1s: val_loss: 1.15083 - diff: 18.02ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Systole_DenseNet121_0_Adam-0.001_MAE_DA3_best

Epoch 49: current best loss = 1.15083, at epoch 48
Train batch 1/32 - 200.3ms/batch - loss: 1.01109 - diff: 16.18mlTrain batch 2/32 - 215.2ms/batch - loss: 1.65336 - diff: 26.45mlTrain batch 3/32 - 209.5ms/batch - loss: 1.52410 - diff: 24.39mlTrain batch 4/32 - 142.7ms/batch - loss: 1.40366 - diff: 22.46mlTrain batch 5/32 - 120.6ms/batch - loss: 1.39289 - diff: 22.29mlTrain batch 6/32 - 178.1ms/batch - loss: 1.31665 - diff: 21.07mlTrain batch 7/32 - 135.1ms/batch - loss: 1.30807 - diff: 20.93mlTrain batch 8/32 - 110.6ms/batch - loss: 1.34209 - diff: 21.47mlTrain batch 9/32 - 181.2ms/batch - loss: 1.30092 - diff: 20.81mlTrain batch 10/32 - 159.8ms/batch - loss: 1.31131 - diff: 20.98mlTrain batch 11/32 - 163.6ms/batch - loss: 1.33726 - diff: 21.40mlTrain batch 12/32 - 178.1ms/batch - loss: 1.32899 - diff: 21.26mlTrain batch 13/32 - 136.8ms/batch - loss: 1.35765 - diff: 21.72mlTrain batch 14/32 - 175.1ms/batch - loss: 1.35430 - diff: 21.67mlTrain batch 15/32 - 170.4ms/batch - loss: 1.36907 - diff: 21.91mlTrain batch 16/32 - 177.1ms/batch - loss: 1.41799 - diff: 22.69mlTrain batch 17/32 - 134.6ms/batch - loss: 1.41436 - diff: 22.63mlTrain batch 18/32 - 123.4ms/batch - loss: 1.38064 - diff: 22.09mlTrain batch 19/32 - 170.6ms/batch - loss: 1.37436 - diff: 21.99mlTrain batch 20/32 - 183.4ms/batch - loss: 1.38414 - diff: 22.15mlTrain batch 21/32 - 181.3ms/batch - loss: 1.36172 - diff: 21.79mlTrain batch 22/32 - 197.0ms/batch - loss: 1.34222 - diff: 21.48mlTrain batch 23/32 - 177.0ms/batch - loss: 1.37063 - diff: 21.93mlTrain batch 24/32 - 167.0ms/batch - loss: 1.34057 - diff: 21.45mlTrain batch 25/32 - 128.7ms/batch - loss: 1.34898 - diff: 21.58mlTrain batch 26/32 - 125.7ms/batch - loss: 1.37253 - diff: 21.96mlTrain batch 27/32 - 208.5ms/batch - loss: 1.36688 - diff: 21.87mlTrain batch 28/32 - 161.9ms/batch - loss: 1.36357 - diff: 21.82mlTrain batch 29/32 - 184.4ms/batch - loss: 1.37539 - diff: 22.01mlTrain batch 30/32 - 197.0ms/batch - loss: 1.38831 - diff: 22.21mlTrain batch 31/32 - 118.1ms/batch - loss: 1.37362 - diff: 21.98mlTrain batch 32/32 - 134.7ms/batch - loss: 1.42560 - diff: 22.05mlTrain batch 32/32 - 16.9s 134.7ms/batch - loss: 1.42560 - diff: 22.05ml
Test 1.0s: val_loss: 1.20457 - diff: 18.41ml

Epoch 50: current best loss = 1.15083, at epoch 48
Train batch 1/32 - 238.2ms/batch - loss: 1.48627 - diff: 23.78mlTrain batch 2/32 - 124.4ms/batch - loss: 1.31946 - diff: 21.11mlTrain batch 3/32 - 166.1ms/batch - loss: 1.22796 - diff: 19.65mlTrain batch 4/32 - 185.5ms/batch - loss: 1.26888 - diff: 20.30mlTrain batch 5/32 - 179.8ms/batch - loss: 1.32111 - diff: 21.14mlTrain batch 6/32 - 171.5ms/batch - loss: 1.30115 - diff: 20.82mlTrain batch 7/32 - 151.8ms/batch - loss: 1.29811 - diff: 20.77mlTrain batch 8/32 - 180.1ms/batch - loss: 1.27884 - diff: 20.46mlTrain batch 9/32 - 244.0ms/batch - loss: 1.22760 - diff: 19.64mlTrain batch 10/32 - 211.1ms/batch - loss: 1.20781 - diff: 19.32mlTrain batch 11/32 - 154.8ms/batch - loss: 1.18445 - diff: 18.95mlTrain batch 12/32 - 123.0ms/batch - loss: 1.19295 - diff: 19.09mlTrain batch 13/32 - 154.5ms/batch - loss: 1.17121 - diff: 18.74mlTrain batch 14/32 - 140.9ms/batch - loss: 1.20755 - diff: 19.32mlTrain batch 15/32 - 137.3ms/batch - loss: 1.26500 - diff: 20.24mlTrain batch 16/32 - 185.4ms/batch - loss: 1.24295 - diff: 19.89mlTrain batch 17/32 - 167.4ms/batch - loss: 1.23545 - diff: 19.77mlTrain batch 18/32 - 190.0ms/batch - loss: 1.22616 - diff: 19.62mlTrain batch 19/32 - 156.7ms/batch - loss: 1.30243 - diff: 20.84mlTrain batch 20/32 - 171.1ms/batch - loss: 1.30113 - diff: 20.82mlTrain batch 21/32 - 122.3ms/batch - loss: 1.31841 - diff: 21.09mlTrain batch 22/32 - 121.9ms/batch - loss: 1.32537 - diff: 21.21mlTrain batch 23/32 - 182.8ms/batch - loss: 1.32231 - diff: 21.16mlTrain batch 24/32 - 174.6ms/batch - loss: 1.31556 - diff: 21.05mlTrain batch 25/32 - 162.4ms/batch - loss: 1.31556 - diff: 21.05mlTrain batch 26/32 - 181.4ms/batch - loss: 1.33515 - diff: 21.36mlTrain batch 27/32 - 157.1ms/batch - loss: 1.32323 - diff: 21.17mlTrain batch 28/32 - 144.0ms/batch - loss: 1.32056 - diff: 21.13mlTrain batch 29/32 - 135.0ms/batch - loss: 1.32622 - diff: 21.22mlTrain batch 30/32 - 148.0ms/batch - loss: 1.34980 - diff: 21.60mlTrain batch 31/32 - 166.4ms/batch - loss: 1.34538 - diff: 21.53mlTrain batch 32/32 - 134.0ms/batch - loss: 1.37719 - diff: 21.52mlTrain batch 32/32 - 16.3s 134.0ms/batch - loss: 1.37719 - diff: 21.52ml
Test 1.0s: val_loss: 1.60365 - diff: 23.85ml

Epoch 51: current best loss = 1.15083, at epoch 48
Train batch 1/32 - 142.2ms/batch - loss: 1.27420 - diff: 20.39mlTrain batch 2/32 - 170.7ms/batch - loss: 1.28597 - diff: 20.58mlTrain batch 3/32 - 172.3ms/batch - loss: 1.84592 - diff: 29.53mlTrain batch 4/32 - 137.3ms/batch - loss: 1.68337 - diff: 26.93mlTrain batch 5/32 - 192.6ms/batch - loss: 1.57334 - diff: 25.17mlTrain batch 6/32 - 136.2ms/batch - loss: 1.66229 - diff: 26.60mlTrain batch 7/32 - 133.2ms/batch - loss: 1.52489 - diff: 24.40mlTrain batch 8/32 - 148.0ms/batch - loss: 1.47947 - diff: 23.67mlTrain batch 9/32 - 142.8ms/batch - loss: 1.43439 - diff: 22.95mlTrain batch 10/32 - 195.2ms/batch - loss: 1.40275 - diff: 22.44mlTrain batch 11/32 - 164.1ms/batch - loss: 1.38080 - diff: 22.09mlTrain batch 12/32 - 171.7ms/batch - loss: 1.33964 - diff: 21.43mlTrain batch 13/32 - 145.2ms/batch - loss: 1.33895 - diff: 21.42mlTrain batch 14/32 - 192.2ms/batch - loss: 1.33511 - diff: 21.36mlTrain batch 15/32 - 144.7ms/batch - loss: 1.32734 - diff: 21.24mlTrain batch 16/32 - 141.2ms/batch - loss: 1.31904 - diff: 21.10mlTrain batch 17/32 - 163.3ms/batch - loss: 1.32467 - diff: 21.19mlTrain batch 18/32 - 111.7ms/batch - loss: 1.33073 - diff: 21.29mlTrain batch 19/32 - 181.0ms/batch - loss: 1.35949 - diff: 21.75mlTrain batch 20/32 - 146.9ms/batch - loss: 1.38005 - diff: 22.08mlTrain batch 21/32 - 186.3ms/batch - loss: 1.36014 - diff: 21.76mlTrain batch 22/32 - 115.6ms/batch - loss: 1.35612 - diff: 21.70mlTrain batch 23/32 - 190.3ms/batch - loss: 1.34877 - diff: 21.58mlTrain batch 24/32 - 180.9ms/batch - loss: 1.33025 - diff: 21.28mlTrain batch 25/32 - 185.2ms/batch - loss: 1.30697 - diff: 20.91mlTrain batch 26/32 - 192.1ms/batch - loss: 1.31417 - diff: 21.03mlTrain batch 27/32 - 155.9ms/batch - loss: 1.29870 - diff: 20.78mlTrain batch 28/32 - 201.1ms/batch - loss: 1.28232 - diff: 20.52mlTrain batch 29/32 - 134.6ms/batch - loss: 1.27420 - diff: 20.39mlTrain batch 30/32 - 147.0ms/batch - loss: 1.26932 - diff: 20.31mlTrain batch 31/32 - 162.4ms/batch - loss: 1.26426 - diff: 20.23mlTrain batch 32/32 - 123.0ms/batch - loss: 1.29737 - diff: 20.24mlTrain batch 32/32 - 16.0s 123.0ms/batch - loss: 1.29737 - diff: 20.24ml
Test 0.9s: val_loss: 1.03565 - diff: 16.01ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Systole_DenseNet121_0_Adam-0.001_MAE_DA3_best

Epoch 52: current best loss = 1.03565, at epoch 51
Train batch 1/32 - 128.0ms/batch - loss: 1.52489 - diff: 24.40mlTrain batch 2/32 - 111.5ms/batch - loss: 2.42582 - diff: 38.81mlTrain batch 3/32 - 173.8ms/batch - loss: 1.92829 - diff: 30.85mlTrain batch 4/32 - 145.7ms/batch - loss: 1.78454 - diff: 28.55mlTrain batch 5/32 - 139.6ms/batch - loss: 1.74277 - diff: 27.88mlTrain batch 6/32 - 116.8ms/batch - loss: 1.62743 - diff: 26.04mlTrain batch 7/32 - 153.8ms/batch - loss: 1.57032 - diff: 25.13mlTrain batch 8/32 - 186.1ms/batch - loss: 1.57104 - diff: 25.14mlTrain batch 9/32 - 123.1ms/batch - loss: 1.54129 - diff: 24.66mlTrain batch 10/32 - 115.0ms/batch - loss: 1.47330 - diff: 23.57mlTrain batch 11/32 - 119.0ms/batch - loss: 1.44083 - diff: 23.05mlTrain batch 12/32 - 169.3ms/batch - loss: 1.45402 - diff: 23.26mlTrain batch 13/32 - 110.7ms/batch - loss: 1.45491 - diff: 23.28mlTrain batch 14/32 - 110.0ms/batch - loss: 1.41839 - diff: 22.69mlTrain batch 15/32 - 181.8ms/batch - loss: 1.40783 - diff: 22.53mlTrain batch 16/32 - 221.4ms/batch - loss: 1.37637 - diff: 22.02mlTrain batch 17/32 - 185.2ms/batch - loss: 1.36007 - diff: 21.76mlTrain batch 18/32 - 186.3ms/batch - loss: 1.33411 - diff: 21.35mlTrain batch 19/32 - 154.5ms/batch - loss: 1.31882 - diff: 21.10mlTrain batch 20/32 - 169.1ms/batch - loss: 1.30036 - diff: 20.81mlTrain batch 21/32 - 159.2ms/batch - loss: 1.29113 - diff: 20.66mlTrain batch 22/32 - 175.4ms/batch - loss: 1.30302 - diff: 20.85mlTrain batch 23/32 - 128.3ms/batch - loss: 1.28935 - diff: 20.63mlTrain batch 24/32 - 163.7ms/batch - loss: 1.27222 - diff: 20.36mlTrain batch 25/32 - 144.6ms/batch - loss: 1.27132 - diff: 20.34mlTrain batch 26/32 - 172.1ms/batch - loss: 1.26365 - diff: 20.22mlTrain batch 27/32 - 210.8ms/batch - loss: 1.26182 - diff: 20.19mlTrain batch 28/32 - 177.3ms/batch - loss: 1.26509 - diff: 20.24mlTrain batch 29/32 - 169.4ms/batch - loss: 1.26416 - diff: 20.23mlTrain batch 30/32 - 166.8ms/batch - loss: 1.25571 - diff: 20.09mlTrain batch 31/32 - 153.3ms/batch - loss: 1.25496 - diff: 20.08mlTrain batch 32/32 - 137.1ms/batch - loss: 1.30238 - diff: 20.15mlTrain batch 32/32 - 17.0s 137.1ms/batch - loss: 1.30238 - diff: 20.15ml
Test 1.0s: val_loss: 1.19375 - diff: 17.87ml

Epoch 53: current best loss = 1.03565, at epoch 51
Train batch 1/32 - 206.1ms/batch - loss: 0.86979 - diff: 13.92mlTrain batch 2/32 - 176.6ms/batch - loss: 1.03610 - diff: 16.58mlTrain batch 3/32 - 165.9ms/batch - loss: 1.05459 - diff: 16.87mlTrain batch 4/32 - 157.0ms/batch - loss: 0.96715 - diff: 15.47mlTrain batch 5/32 - 143.6ms/batch - loss: 0.97979 - diff: 15.68mlTrain batch 6/32 - 169.8ms/batch - loss: 0.94821 - diff: 15.17mlTrain batch 7/32 - 178.1ms/batch - loss: 0.95197 - diff: 15.23mlTrain batch 8/32 - 182.8ms/batch - loss: 0.96593 - diff: 15.45mlTrain batch 9/32 - 166.1ms/batch - loss: 0.98520 - diff: 15.76mlTrain batch 10/32 - 135.9ms/batch - loss: 0.95794 - diff: 15.33mlTrain batch 11/32 - 176.8ms/batch - loss: 0.99205 - diff: 15.87mlTrain batch 12/32 - 135.1ms/batch - loss: 1.03922 - diff: 16.63mlTrain batch 13/32 - 127.1ms/batch - loss: 1.04966 - diff: 16.79mlTrain batch 14/32 - 123.3ms/batch - loss: 1.07078 - diff: 17.13mlTrain batch 15/32 - 157.4ms/batch - loss: 1.07286 - diff: 17.17mlTrain batch 16/32 - 190.9ms/batch - loss: 1.13196 - diff: 18.11mlTrain batch 17/32 - 157.8ms/batch - loss: 1.12660 - diff: 18.03mlTrain batch 18/32 - 190.2ms/batch - loss: 1.11054 - diff: 17.77mlTrain batch 19/32 - 158.8ms/batch - loss: 1.09832 - diff: 17.57mlTrain batch 20/32 - 139.2ms/batch - loss: 1.09532 - diff: 17.53mlTrain batch 21/32 - 163.8ms/batch - loss: 1.09097 - diff: 17.46mlTrain batch 22/32 - 148.3ms/batch - loss: 1.09705 - diff: 17.55mlTrain batch 23/32 - 126.0ms/batch - loss: 1.10039 - diff: 17.61mlTrain batch 24/32 - 117.7ms/batch - loss: 1.10455 - diff: 17.67mlTrain batch 25/32 - 203.8ms/batch - loss: 1.12542 - diff: 18.01mlTrain batch 26/32 - 195.3ms/batch - loss: 1.15328 - diff: 18.45mlTrain batch 27/32 - 123.3ms/batch - loss: 1.15306 - diff: 18.45mlTrain batch 28/32 - 102.6ms/batch - loss: 1.15032 - diff: 18.41mlTrain batch 29/32 - 173.5ms/batch - loss: 1.14456 - diff: 18.31mlTrain batch 30/32 - 151.7ms/batch - loss: 1.17268 - diff: 18.76mlTrain batch 31/32 - 136.1ms/batch - loss: 1.16820 - diff: 18.69mlTrain batch 32/32 - 107.1ms/batch - loss: 1.19993 - diff: 18.71mlTrain batch 32/32 - 17.1s 107.1ms/batch - loss: 1.19993 - diff: 18.71ml
Test 1.0s: val_loss: 1.24876 - diff: 19.63ml

Epoch 54: current best loss = 1.03565, at epoch 51
Train batch 1/32 - 208.7ms/batch - loss: 1.27502 - diff: 20.40mlTrain batch 2/32 - 200.6ms/batch - loss: 1.02212 - diff: 16.35mlTrain batch 3/32 - 162.8ms/batch - loss: 0.92823 - diff: 14.85mlTrain batch 4/32 - 169.3ms/batch - loss: 0.97171 - diff: 15.55mlTrain batch 5/32 - 152.6ms/batch - loss: 1.01595 - diff: 16.26mlTrain batch 6/32 - 184.7ms/batch - loss: 1.09535 - diff: 17.53mlTrain batch 7/32 - 182.2ms/batch - loss: 1.10338 - diff: 17.65mlTrain batch 8/32 - 174.1ms/batch - loss: 1.03946 - diff: 16.63mlTrain batch 9/32 - 153.4ms/batch - loss: 1.04526 - diff: 16.72mlTrain batch 10/32 - 211.8ms/batch - loss: 1.05840 - diff: 16.93mlTrain batch 11/32 - 121.9ms/batch - loss: 1.08560 - diff: 17.37mlTrain batch 12/32 - 138.5ms/batch - loss: 1.08191 - diff: 17.31mlTrain batch 13/32 - 143.2ms/batch - loss: 1.06473 - diff: 17.04mlTrain batch 14/32 - 173.7ms/batch - loss: 1.07133 - diff: 17.14mlTrain batch 15/32 - 136.8ms/batch - loss: 1.11192 - diff: 17.79mlTrain batch 16/32 - 185.8ms/batch - loss: 1.13409 - diff: 18.15mlTrain batch 17/32 - 150.4ms/batch - loss: 1.14188 - diff: 18.27mlTrain batch 18/32 - 124.8ms/batch - loss: 1.13633 - diff: 18.18mlTrain batch 19/32 - 157.1ms/batch - loss: 1.12571 - diff: 18.01mlTrain batch 20/32 - 175.2ms/batch - loss: 1.11363 - diff: 17.82mlTrain batch 21/32 - 184.7ms/batch - loss: 1.12001 - diff: 17.92mlTrain batch 22/32 - 191.3ms/batch - loss: 1.13994 - diff: 18.24mlTrain batch 23/32 - 163.1ms/batch - loss: 1.12535 - diff: 18.01mlTrain batch 24/32 - 191.1ms/batch - loss: 1.18579 - diff: 18.97mlTrain batch 25/32 - 166.4ms/batch - loss: 1.20498 - diff: 19.28mlTrain batch 26/32 - 184.1ms/batch - loss: 1.20047 - diff: 19.21mlTrain batch 27/32 - 160.9ms/batch - loss: 1.20389 - diff: 19.26mlTrain batch 28/32 - 163.5ms/batch - loss: 1.19936 - diff: 19.19mlTrain batch 29/32 - 179.3ms/batch - loss: 1.21235 - diff: 19.40mlTrain batch 30/32 - 159.1ms/batch - loss: 1.20594 - diff: 19.30mlTrain batch 31/32 - 201.3ms/batch - loss: 1.20556 - diff: 19.29mlTrain batch 32/32 - 175.5ms/batch - loss: 1.22996 - diff: 19.27mlTrain batch 32/32 - 17.7s 175.5ms/batch - loss: 1.22996 - diff: 19.27ml
Test 1.0s: val_loss: 0.99711 - diff: 15.45ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Systole_DenseNet121_0_Adam-0.001_MAE_DA3_best

Epoch 55: current best loss = 0.99711, at epoch 54
Train batch 1/32 - 168.3ms/batch - loss: 0.56898 - diff: 9.10mlTrain batch 2/32 - 166.1ms/batch - loss: 0.93028 - diff: 14.88mlTrain batch 3/32 - 145.5ms/batch - loss: 0.90147 - diff: 14.42mlTrain batch 4/32 - 151.0ms/batch - loss: 0.94867 - diff: 15.18mlTrain batch 5/32 - 156.5ms/batch - loss: 1.27188 - diff: 20.35mlTrain batch 6/32 - 187.9ms/batch - loss: 1.25081 - diff: 20.01mlTrain batch 7/32 - 149.6ms/batch - loss: 1.22866 - diff: 19.66mlTrain batch 8/32 - 179.6ms/batch - loss: 1.28932 - diff: 20.63mlTrain batch 9/32 - 152.8ms/batch - loss: 1.26831 - diff: 20.29mlTrain batch 10/32 - 172.9ms/batch - loss: 1.25131 - diff: 20.02mlTrain batch 11/32 - 163.4ms/batch - loss: 1.20838 - diff: 19.33mlTrain batch 12/32 - 180.0ms/batch - loss: 1.23562 - diff: 19.77mlTrain batch 13/32 - 170.7ms/batch - loss: 1.21460 - diff: 19.43mlTrain batch 14/32 - 194.3ms/batch - loss: 1.18596 - diff: 18.98mlTrain batch 15/32 - 153.3ms/batch - loss: 1.22723 - diff: 19.64mlTrain batch 16/32 - 139.5ms/batch - loss: 1.21925 - diff: 19.51mlTrain batch 17/32 - 169.2ms/batch - loss: 1.19969 - diff: 19.20mlTrain batch 18/32 - 108.4ms/batch - loss: 1.20473 - diff: 19.28mlTrain batch 19/32 - 111.9ms/batch - loss: 1.18139 - diff: 18.90mlTrain batch 20/32 - 153.7ms/batch - loss: 1.16357 - diff: 18.62mlTrain batch 21/32 - 160.1ms/batch - loss: 1.16470 - diff: 18.64mlTrain batch 22/32 - 188.8ms/batch - loss: 1.18021 - diff: 18.88mlTrain batch 23/32 - 160.7ms/batch - loss: 1.17032 - diff: 18.73mlTrain batch 24/32 - 188.6ms/batch - loss: 1.14671 - diff: 18.35mlTrain batch 25/32 - 154.5ms/batch - loss: 1.14699 - diff: 18.35mlTrain batch 26/32 - 148.6ms/batch - loss: 1.14364 - diff: 18.30mlTrain batch 27/32 - 151.2ms/batch - loss: 1.12962 - diff: 18.07mlTrain batch 28/32 - 164.0ms/batch - loss: 1.11857 - diff: 17.90mlTrain batch 29/32 - 153.7ms/batch - loss: 1.11927 - diff: 17.91mlTrain batch 30/32 - 177.4ms/batch - loss: 1.11621 - diff: 17.86mlTrain batch 31/32 - 148.1ms/batch - loss: 1.11650 - diff: 17.86mlTrain batch 32/32 - 181.0ms/batch - loss: 1.14782 - diff: 17.88mlTrain batch 32/32 - 17.4s 181.0ms/batch - loss: 1.14782 - diff: 17.88ml
Test 1.0s: val_loss: 1.20102 - diff: 18.69ml

Epoch 56: current best loss = 0.99711, at epoch 54
Train batch 1/32 - 126.3ms/batch - loss: 0.70694 - diff: 11.31mlTrain batch 2/32 - 134.7ms/batch - loss: 0.78506 - diff: 12.56mlTrain batch 3/32 - 171.0ms/batch - loss: 1.13463 - diff: 18.15mlTrain batch 4/32 - 189.3ms/batch - loss: 1.19748 - diff: 19.16mlTrain batch 5/32 - 119.6ms/batch - loss: 1.21287 - diff: 19.41mlTrain batch 6/32 - 142.2ms/batch - loss: 1.29749 - diff: 20.76mlTrain batch 7/32 - 168.9ms/batch - loss: 1.25158 - diff: 20.03mlTrain batch 8/32 - 139.3ms/batch - loss: 1.25035 - diff: 20.01mlTrain batch 9/32 - 176.6ms/batch - loss: 1.34963 - diff: 21.59mlTrain batch 10/32 - 178.6ms/batch - loss: 1.28679 - diff: 20.59mlTrain batch 11/32 - 118.2ms/batch - loss: 1.25399 - diff: 20.06mlTrain batch 12/32 - 134.2ms/batch - loss: 1.22899 - diff: 19.66mlTrain batch 13/32 - 166.9ms/batch - loss: 1.22498 - diff: 19.60mlTrain batch 14/32 - 180.1ms/batch - loss: 1.23670 - diff: 19.79mlTrain batch 15/32 - 177.2ms/batch - loss: 1.21719 - diff: 19.48mlTrain batch 16/32 - 147.2ms/batch - loss: 1.19435 - diff: 19.11mlTrain batch 17/32 - 179.0ms/batch - loss: 1.20898 - diff: 19.34mlTrain batch 18/32 - 130.0ms/batch - loss: 1.22951 - diff: 19.67mlTrain batch 19/32 - 175.9ms/batch - loss: 1.23330 - diff: 19.73mlTrain batch 20/32 - 155.6ms/batch - loss: 1.23399 - diff: 19.74mlTrain batch 21/32 - 164.5ms/batch - loss: 1.21656 - diff: 19.46mlTrain batch 22/32 - 144.6ms/batch - loss: 1.21553 - diff: 19.45mlTrain batch 23/32 - 150.2ms/batch - loss: 1.20382 - diff: 19.26mlTrain batch 24/32 - 190.4ms/batch - loss: 1.20144 - diff: 19.22mlTrain batch 25/32 - 154.5ms/batch - loss: 1.21775 - diff: 19.48mlTrain batch 26/32 - 120.4ms/batch - loss: 1.20923 - diff: 19.35mlTrain batch 27/32 - 133.8ms/batch - loss: 1.20769 - diff: 19.32mlTrain batch 28/32 - 112.5ms/batch - loss: 1.23061 - diff: 19.69mlTrain batch 29/32 - 156.8ms/batch - loss: 1.22398 - diff: 19.58mlTrain batch 30/32 - 170.9ms/batch - loss: 1.20761 - diff: 19.32mlTrain batch 31/32 - 167.6ms/batch - loss: 1.19870 - diff: 19.18mlTrain batch 32/32 - 161.3ms/batch - loss: 1.20155 - diff: 19.08mlTrain batch 32/32 - 17.6s 161.3ms/batch - loss: 1.20155 - diff: 19.08ml
Test 1.0s: val_loss: 0.99609 - diff: 15.34ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Systole_DenseNet121_0_Adam-0.001_MAE_DA3_best

Epoch 57: current best loss = 0.99609, at epoch 56
Train batch 1/32 - 246.3ms/batch - loss: 0.90049 - diff: 14.41mlTrain batch 2/32 - 158.2ms/batch - loss: 0.92504 - diff: 14.80mlTrain batch 3/32 - 176.3ms/batch - loss: 0.89139 - diff: 14.26mlTrain batch 4/32 - 192.6ms/batch - loss: 0.86874 - diff: 13.90mlTrain batch 5/32 - 174.6ms/batch - loss: 0.86610 - diff: 13.86mlTrain batch 6/32 - 140.0ms/batch - loss: 0.91638 - diff: 14.66mlTrain batch 7/32 - 180.4ms/batch - loss: 0.93638 - diff: 14.98mlTrain batch 8/32 - 178.5ms/batch - loss: 0.96764 - diff: 15.48mlTrain batch 9/32 - 191.9ms/batch - loss: 0.96761 - diff: 15.48mlTrain batch 10/32 - 159.8ms/batch - loss: 1.02263 - diff: 16.36mlTrain batch 11/32 - 141.1ms/batch - loss: 1.04552 - diff: 16.73mlTrain batch 12/32 - 119.5ms/batch - loss: 1.07077 - diff: 17.13mlTrain batch 13/32 - 133.9ms/batch - loss: 1.11937 - diff: 17.91mlTrain batch 14/32 - 149.4ms/batch - loss: 1.11490 - diff: 17.84mlTrain batch 15/32 - 171.0ms/batch - loss: 1.09390 - diff: 17.50mlTrain batch 16/32 - 169.1ms/batch - loss: 1.14362 - diff: 18.30mlTrain batch 17/32 - 169.0ms/batch - loss: 1.13202 - diff: 18.11mlTrain batch 18/32 - 166.2ms/batch - loss: 1.11530 - diff: 17.84mlTrain batch 19/32 - 185.5ms/batch - loss: 1.10972 - diff: 17.76mlTrain batch 20/32 - 174.4ms/batch - loss: 1.11477 - diff: 17.84mlTrain batch 21/32 - 159.1ms/batch - loss: 1.09826 - diff: 17.57mlTrain batch 22/32 - 185.2ms/batch - loss: 1.09453 - diff: 17.51mlTrain batch 23/32 - 166.2ms/batch - loss: 1.08475 - diff: 17.36mlTrain batch 24/32 - 144.1ms/batch - loss: 1.09702 - diff: 17.55mlTrain batch 25/32 - 150.7ms/batch - loss: 1.08298 - diff: 17.33mlTrain batch 26/32 - 161.5ms/batch - loss: 1.08444 - diff: 17.35mlTrain batch 27/32 - 189.9ms/batch - loss: 1.11000 - diff: 17.76mlTrain batch 28/32 - 152.0ms/batch - loss: 1.12165 - diff: 17.95mlTrain batch 29/32 - 111.6ms/batch - loss: 1.11576 - diff: 17.85mlTrain batch 30/32 - 140.4ms/batch - loss: 1.12100 - diff: 17.94mlTrain batch 31/32 - 144.0ms/batch - loss: 1.11003 - diff: 17.76mlTrain batch 32/32 - 103.3ms/batch - loss: 1.12394 - diff: 17.71mlTrain batch 32/32 - 16.8s 103.3ms/batch - loss: 1.12394 - diff: 17.71ml
Test 1.1s: val_loss: 1.07114 - diff: 16.79ml

Epoch 58: current best loss = 0.99609, at epoch 56
Train batch 1/32 - 183.9ms/batch - loss: 1.27034 - diff: 20.33mlTrain batch 2/32 - 167.4ms/batch - loss: 1.18330 - diff: 18.93mlTrain batch 3/32 - 196.8ms/batch - loss: 1.06756 - diff: 17.08mlTrain batch 4/32 - 202.3ms/batch - loss: 0.99098 - diff: 15.86mlTrain batch 5/32 - 140.1ms/batch - loss: 1.09084 - diff: 17.45mlTrain batch 6/32 - 142.1ms/batch - loss: 1.08550 - diff: 17.37mlTrain batch 7/32 - 152.3ms/batch - loss: 1.03567 - diff: 16.57mlTrain batch 8/32 - 153.0ms/batch - loss: 1.00215 - diff: 16.03mlTrain batch 9/32 - 118.1ms/batch - loss: 1.00346 - diff: 16.06mlTrain batch 10/32 - 181.0ms/batch - loss: 0.99317 - diff: 15.89mlTrain batch 11/32 - 161.1ms/batch - loss: 0.97236 - diff: 15.56mlTrain batch 12/32 - 126.0ms/batch - loss: 0.95640 - diff: 15.30mlTrain batch 13/32 - 132.6ms/batch - loss: 1.00859 - diff: 16.14mlTrain batch 14/32 - 133.5ms/batch - loss: 1.01218 - diff: 16.19mlTrain batch 15/32 - 132.5ms/batch - loss: 0.99667 - diff: 15.95mlTrain batch 16/32 - 173.3ms/batch - loss: 0.99797 - diff: 15.97mlTrain batch 17/32 - 174.0ms/batch - loss: 0.99485 - diff: 15.92mlTrain batch 18/32 - 126.1ms/batch - loss: 1.00675 - diff: 16.11mlTrain batch 19/32 - 188.3ms/batch - loss: 1.02566 - diff: 16.41mlTrain batch 20/32 - 172.8ms/batch - loss: 1.02313 - diff: 16.37mlTrain batch 21/32 - 186.0ms/batch - loss: 1.01179 - diff: 16.19mlTrain batch 22/32 - 178.3ms/batch - loss: 0.99929 - diff: 15.99mlTrain batch 23/32 - 136.0ms/batch - loss: 1.01653 - diff: 16.26mlTrain batch 24/32 - 134.3ms/batch - loss: 1.02480 - diff: 16.40mlTrain batch 25/32 - 170.1ms/batch - loss: 1.02930 - diff: 16.47mlTrain batch 26/32 - 136.3ms/batch - loss: 1.03040 - diff: 16.49mlTrain batch 27/32 - 129.4ms/batch - loss: 1.03820 - diff: 16.61mlTrain batch 28/32 - 180.7ms/batch - loss: 1.03441 - diff: 16.55mlTrain batch 29/32 - 186.3ms/batch - loss: 1.06734 - diff: 17.08mlTrain batch 30/32 - 187.9ms/batch - loss: 1.06698 - diff: 17.07mlTrain batch 31/32 - 157.2ms/batch - loss: 1.07920 - diff: 17.27mlTrain batch 32/32 - 155.0ms/batch - loss: 1.11353 - diff: 17.30mlTrain batch 32/32 - 17.4s 155.0ms/batch - loss: 1.11353 - diff: 17.30ml
Test 1.0s: val_loss: 1.04210 - diff: 16.14ml

Epoch 59: current best loss = 0.99609, at epoch 56
Train batch 1/32 - 207.0ms/batch - loss: 0.81688 - diff: 13.07mlTrain batch 2/32 - 165.7ms/batch - loss: 0.92842 - diff: 14.85mlTrain batch 3/32 - 168.2ms/batch - loss: 0.87741 - diff: 14.04mlTrain batch 4/32 - 166.9ms/batch - loss: 0.93077 - diff: 14.89mlTrain batch 5/32 - 190.5ms/batch - loss: 0.90369 - diff: 14.46mlTrain batch 6/32 - 176.6ms/batch - loss: 0.92282 - diff: 14.77mlTrain batch 7/32 - 133.1ms/batch - loss: 0.94413 - diff: 15.11mlTrain batch 8/32 - 115.3ms/batch - loss: 0.91916 - diff: 14.71mlTrain batch 9/32 - 145.5ms/batch - loss: 0.96677 - diff: 15.47mlTrain batch 10/32 - 109.6ms/batch - loss: 1.19842 - diff: 19.17mlTrain batch 11/32 - 152.8ms/batch - loss: 1.17129 - diff: 18.74mlTrain batch 12/32 - 203.8ms/batch - loss: 1.14031 - diff: 18.25mlTrain batch 13/32 - 148.4ms/batch - loss: 1.11401 - diff: 17.82mlTrain batch 14/32 - 114.5ms/batch - loss: 1.15695 - diff: 18.51mlTrain batch 15/32 - 117.5ms/batch - loss: 1.19207 - diff: 19.07mlTrain batch 16/32 - 181.0ms/batch - loss: 1.19879 - diff: 19.18mlTrain batch 17/32 - 164.0ms/batch - loss: 1.18843 - diff: 19.01mlTrain batch 18/32 - 159.6ms/batch - loss: 1.17221 - diff: 18.76mlTrain batch 19/32 - 162.3ms/batch - loss: 1.15680 - diff: 18.51mlTrain batch 20/32 - 103.0ms/batch - loss: 1.14895 - diff: 18.38mlTrain batch 21/32 - 127.1ms/batch - loss: 1.15007 - diff: 18.40mlTrain batch 22/32 - 155.2ms/batch - loss: 1.13412 - diff: 18.15mlTrain batch 23/32 - 150.8ms/batch - loss: 1.10944 - diff: 17.75mlTrain batch 24/32 - 153.9ms/batch - loss: 1.09630 - diff: 17.54mlTrain batch 25/32 - 125.4ms/batch - loss: 1.07871 - diff: 17.26mlTrain batch 26/32 - 173.1ms/batch - loss: 1.08100 - diff: 17.30mlTrain batch 27/32 - 166.8ms/batch - loss: 1.08560 - diff: 17.37mlTrain batch 28/32 - 132.9ms/batch - loss: 1.10876 - diff: 17.74mlTrain batch 29/32 - 143.4ms/batch - loss: 1.10786 - diff: 17.73mlTrain batch 30/32 - 168.7ms/batch - loss: 1.10241 - diff: 17.64mlTrain batch 31/32 - 116.9ms/batch - loss: 1.09270 - diff: 17.48mlTrain batch 32/32 - 110.4ms/batch - loss: 1.12193 - diff: 17.50mlTrain batch 32/32 - 16.8s 110.4ms/batch - loss: 1.12193 - diff: 17.50ml
Test 1.0s: val_loss: 1.11520 - diff: 17.19ml

Epoch 60: current best loss = 0.99609, at epoch 56
Train batch 1/32 - 218.7ms/batch - loss: 1.87411 - diff: 29.99mlTrain batch 2/32 - 162.7ms/batch - loss: 1.31331 - diff: 21.01mlTrain batch 3/32 - 166.5ms/batch - loss: 1.10782 - diff: 17.73mlTrain batch 4/32 - 143.0ms/batch - loss: 1.06558 - diff: 17.05mlTrain batch 5/32 - 147.7ms/batch - loss: 0.99493 - diff: 15.92mlTrain batch 6/32 - 178.2ms/batch - loss: 0.98565 - diff: 15.77mlTrain batch 7/32 - 169.4ms/batch - loss: 0.99732 - diff: 15.96mlTrain batch 8/32 - 174.7ms/batch - loss: 1.00939 - diff: 16.15mlTrain batch 9/32 - 143.6ms/batch - loss: 1.01488 - diff: 16.24mlTrain batch 10/32 - 153.5ms/batch - loss: 0.99847 - diff: 15.98mlTrain batch 11/32 - 181.9ms/batch - loss: 1.02228 - diff: 16.36mlTrain batch 12/32 - 171.6ms/batch - loss: 1.00542 - diff: 16.09mlTrain batch 13/32 - 174.5ms/batch - loss: 0.99736 - diff: 15.96mlTrain batch 14/32 - 157.9ms/batch - loss: 0.98253 - diff: 15.72mlTrain batch 15/32 - 210.2ms/batch - loss: 0.99367 - diff: 15.90mlTrain batch 16/32 - 185.8ms/batch - loss: 1.00532 - diff: 16.09mlTrain batch 17/32 - 155.4ms/batch - loss: 1.04397 - diff: 16.70mlTrain batch 18/32 - 207.1ms/batch - loss: 1.05802 - diff: 16.93mlTrain batch 19/32 - 151.3ms/batch - loss: 1.04291 - diff: 16.69mlTrain batch 20/32 - 189.8ms/batch - loss: 1.02554 - diff: 16.41mlTrain batch 21/32 - 110.4ms/batch - loss: 1.01857 - diff: 16.30mlTrain batch 22/32 - 194.0ms/batch - loss: 1.01416 - diff: 16.23mlTrain batch 23/32 - 164.4ms/batch - loss: 1.00444 - diff: 16.07mlTrain batch 24/32 - 209.8ms/batch - loss: 1.00991 - diff: 16.16mlTrain batch 25/32 - 153.8ms/batch - loss: 1.00994 - diff: 16.16mlTrain batch 26/32 - 164.1ms/batch - loss: 1.01147 - diff: 16.18mlTrain batch 27/32 - 184.8ms/batch - loss: 1.01882 - diff: 16.30mlTrain batch 28/32 - 183.6ms/batch - loss: 1.01598 - diff: 16.26mlTrain batch 29/32 - 152.1ms/batch - loss: 1.00891 - diff: 16.14mlTrain batch 30/32 - 135.9ms/batch - loss: 1.00423 - diff: 16.07mlTrain batch 31/32 - 156.4ms/batch - loss: 1.00081 - diff: 16.01mlTrain batch 32/32 - 192.3ms/batch - loss: 1.03984 - diff: 16.07mlTrain batch 32/32 - 17.1s 192.3ms/batch - loss: 1.03984 - diff: 16.07ml
Test 1.0s: val_loss: 1.09586 - diff: 17.16ml

Epoch 61: current best loss = 0.99609, at epoch 56
Train batch 1/32 - 187.5ms/batch - loss: 1.06740 - diff: 17.08mlTrain batch 2/32 - 106.1ms/batch - loss: 0.95885 - diff: 15.34mlTrain batch 3/32 - 176.8ms/batch - loss: 1.09681 - diff: 17.55mlTrain batch 4/32 - 118.5ms/batch - loss: 1.01430 - diff: 16.23mlTrain batch 5/32 - 138.4ms/batch - loss: 0.95477 - diff: 15.28mlTrain batch 6/32 - 128.0ms/batch - loss: 0.95288 - diff: 15.25mlTrain batch 7/32 - 129.3ms/batch - loss: 0.96426 - diff: 15.43mlTrain batch 8/32 - 116.7ms/batch - loss: 0.95927 - diff: 15.35mlTrain batch 9/32 - 190.4ms/batch - loss: 0.99034 - diff: 15.85mlTrain batch 10/32 - 122.9ms/batch - loss: 1.00764 - diff: 16.12mlTrain batch 11/32 - 138.2ms/batch - loss: 1.02446 - diff: 16.39mlTrain batch 12/32 - 132.3ms/batch - loss: 1.01183 - diff: 16.19mlTrain batch 13/32 - 166.1ms/batch - loss: 1.01837 - diff: 16.29mlTrain batch 14/32 - 184.9ms/batch - loss: 1.00286 - diff: 16.05mlTrain batch 15/32 - 155.8ms/batch - loss: 1.02681 - diff: 16.43mlTrain batch 16/32 - 111.4ms/batch - loss: 1.02750 - diff: 16.44mlTrain batch 17/32 - 153.4ms/batch - loss: 1.02721 - diff: 16.44mlTrain batch 18/32 - 178.7ms/batch - loss: 1.07922 - diff: 17.27mlTrain batch 19/32 - 161.5ms/batch - loss: 1.12457 - diff: 17.99mlTrain batch 20/32 - 172.6ms/batch - loss: 1.11221 - diff: 17.80mlTrain batch 21/32 - 127.0ms/batch - loss: 1.11085 - diff: 17.77mlTrain batch 22/32 - 110.3ms/batch - loss: 1.10467 - diff: 17.67mlTrain batch 23/32 - 173.4ms/batch - loss: 1.07981 - diff: 17.28mlTrain batch 24/32 - 207.7ms/batch - loss: 1.08254 - diff: 17.32mlTrain batch 25/32 - 193.9ms/batch - loss: 1.07720 - diff: 17.24mlTrain batch 26/32 - 196.7ms/batch - loss: 1.07536 - diff: 17.21mlTrain batch 27/32 - 175.1ms/batch - loss: 1.06520 - diff: 17.04mlTrain batch 28/32 - 156.3ms/batch - loss: 1.07074 - diff: 17.13mlTrain batch 29/32 - 145.1ms/batch - loss: 1.08592 - diff: 17.37mlTrain batch 30/32 - 111.0ms/batch - loss: 1.06565 - diff: 17.05mlTrain batch 31/32 - 112.8ms/batch - loss: 1.05178 - diff: 16.83mlTrain batch 32/32 - 110.5ms/batch - loss: 1.12277 - diff: 17.01mlTrain batch 32/32 - 17.1s 110.5ms/batch - loss: 1.12277 - diff: 17.01ml
Test 1.0s: val_loss: 1.11992 - diff: 16.97ml

Epoch 62: current best loss = 0.99609, at epoch 56
Train batch 1/32 - 234.6ms/batch - loss: 1.53083 - diff: 24.49mlTrain batch 2/32 - 158.8ms/batch - loss: 1.11527 - diff: 17.84mlTrain batch 3/32 - 165.6ms/batch - loss: 0.97877 - diff: 15.66mlTrain batch 4/32 - 172.0ms/batch - loss: 1.04320 - diff: 16.69mlTrain batch 5/32 - 168.7ms/batch - loss: 1.01937 - diff: 16.31mlTrain batch 6/32 - 165.3ms/batch - loss: 1.04309 - diff: 16.69mlTrain batch 7/32 - 161.9ms/batch - loss: 1.01805 - diff: 16.29mlTrain batch 8/32 - 165.5ms/batch - loss: 1.07445 - diff: 17.19mlTrain batch 9/32 - 116.8ms/batch - loss: 1.04611 - diff: 16.74mlTrain batch 10/32 - 190.4ms/batch - loss: 1.00721 - diff: 16.12mlTrain batch 11/32 - 148.2ms/batch - loss: 1.01724 - diff: 16.28mlTrain batch 12/32 - 186.6ms/batch - loss: 1.01087 - diff: 16.17mlTrain batch 13/32 - 142.2ms/batch - loss: 1.03926 - diff: 16.63mlTrain batch 14/32 - 168.1ms/batch - loss: 1.04898 - diff: 16.78mlTrain batch 15/32 - 166.3ms/batch - loss: 1.05668 - diff: 16.91mlTrain batch 16/32 - 133.0ms/batch - loss: 1.03533 - diff: 16.57mlTrain batch 17/32 - 156.8ms/batch - loss: 1.02427 - diff: 16.39mlTrain batch 18/32 - 190.6ms/batch - loss: 1.04466 - diff: 16.71mlTrain batch 19/32 - 190.9ms/batch - loss: 1.09196 - diff: 17.47mlTrain batch 20/32 - 172.8ms/batch - loss: 1.12330 - diff: 17.97mlTrain batch 21/32 - 161.1ms/batch - loss: 1.12650 - diff: 18.02mlTrain batch 22/32 - 144.1ms/batch - loss: 1.12141 - diff: 17.94mlTrain batch 23/32 - 196.7ms/batch - loss: 1.12518 - diff: 18.00mlTrain batch 24/32 - 151.6ms/batch - loss: 1.11755 - diff: 17.88mlTrain batch 25/32 - 177.3ms/batch - loss: 1.09774 - diff: 17.56mlTrain batch 26/32 - 173.1ms/batch - loss: 1.08639 - diff: 17.38mlTrain batch 27/32 - 159.9ms/batch - loss: 1.07759 - diff: 17.24mlTrain batch 28/32 - 148.0ms/batch - loss: 1.09461 - diff: 17.51mlTrain batch 29/32 - 143.7ms/batch - loss: 1.09792 - diff: 17.57mlTrain batch 30/32 - 159.7ms/batch - loss: 1.08440 - diff: 17.35mlTrain batch 31/32 - 146.1ms/batch - loss: 1.06982 - diff: 17.12mlTrain batch 32/32 - 155.2ms/batch - loss: 1.07874 - diff: 17.05mlTrain batch 32/32 - 17.8s 155.2ms/batch - loss: 1.07874 - diff: 17.05ml
Test 1.1s: val_loss: 1.45265 - diff: 22.09ml

Epoch 63: current best loss = 0.99609, at epoch 56
Train batch 1/32 - 157.5ms/batch - loss: 0.99130 - diff: 15.86mlTrain batch 2/32 - 193.3ms/batch - loss: 0.90816 - diff: 14.53mlTrain batch 3/32 - 114.7ms/batch - loss: 1.02865 - diff: 16.46mlTrain batch 4/32 - 123.7ms/batch - loss: 0.94547 - diff: 15.13mlTrain batch 5/32 - 123.4ms/batch - loss: 0.97784 - diff: 15.65mlTrain batch 6/32 - 117.0ms/batch - loss: 1.09910 - diff: 17.59mlTrain batch 7/32 - 122.9ms/batch - loss: 1.08641 - diff: 17.38mlTrain batch 8/32 - 121.8ms/batch - loss: 1.04666 - diff: 16.75mlTrain batch 9/32 - 146.2ms/batch - loss: 1.12534 - diff: 18.01mlTrain batch 10/32 - 154.6ms/batch - loss: 1.10814 - diff: 17.73mlTrain batch 11/32 - 150.8ms/batch - loss: 1.11296 - diff: 17.81mlTrain batch 12/32 - 161.6ms/batch - loss: 1.07941 - diff: 17.27mlTrain batch 13/32 - 158.3ms/batch - loss: 1.03962 - diff: 16.63mlTrain batch 14/32 - 130.7ms/batch - loss: 1.02621 - diff: 16.42mlTrain batch 15/32 - 149.8ms/batch - loss: 1.00345 - diff: 16.06mlTrain batch 16/32 - 162.7ms/batch - loss: 1.03281 - diff: 16.53mlTrain batch 17/32 - 145.5ms/batch - loss: 1.02398 - diff: 16.38mlTrain batch 18/32 - 171.4ms/batch - loss: 1.00997 - diff: 16.16mlTrain batch 19/32 - 156.7ms/batch - loss: 0.99437 - diff: 15.91mlTrain batch 20/32 - 154.0ms/batch - loss: 1.02459 - diff: 16.39mlTrain batch 21/32 - 124.0ms/batch - loss: 1.02073 - diff: 16.33mlTrain batch 22/32 - 140.7ms/batch - loss: 1.01673 - diff: 16.27mlTrain batch 23/32 - 132.3ms/batch - loss: 1.02161 - diff: 16.35mlTrain batch 24/32 - 187.3ms/batch - loss: 1.02625 - diff: 16.42mlTrain batch 25/32 - 157.1ms/batch - loss: 1.02406 - diff: 16.39mlTrain batch 26/32 - 158.4ms/batch - loss: 1.01690 - diff: 16.27mlTrain batch 27/32 - 143.2ms/batch - loss: 1.00665 - diff: 16.11mlTrain batch 28/32 - 144.8ms/batch - loss: 0.99330 - diff: 15.89mlTrain batch 29/32 - 153.2ms/batch - loss: 0.98258 - diff: 15.72mlTrain batch 30/32 - 111.1ms/batch - loss: 0.97962 - diff: 15.67mlTrain batch 31/32 - 134.6ms/batch - loss: 0.97633 - diff: 15.62mlTrain batch 32/32 - 171.5ms/batch - loss: 1.01236 - diff: 15.67mlTrain batch 32/32 - 16.8s 171.5ms/batch - loss: 1.01236 - diff: 15.67ml
Test 1.0s: val_loss: 1.12415 - diff: 16.91ml

Epoch 64: current best loss = 0.99609, at epoch 56
Train batch 1/32 - 153.1ms/batch - loss: 1.05484 - diff: 16.88mlTrain batch 2/32 - 162.4ms/batch - loss: 1.11581 - diff: 17.85mlTrain batch 3/32 - 149.2ms/batch - loss: 1.14772 - diff: 18.36mlTrain batch 4/32 - 191.1ms/batch - loss: 1.06062 - diff: 16.97mlTrain batch 5/32 - 152.9ms/batch - loss: 1.07176 - diff: 17.15mlTrain batch 6/32 - 123.0ms/batch - loss: 0.98383 - diff: 15.74mlTrain batch 7/32 - 148.9ms/batch - loss: 0.94725 - diff: 15.16mlTrain batch 8/32 - 167.4ms/batch - loss: 0.96586 - diff: 15.45mlTrain batch 9/32 - 161.4ms/batch - loss: 0.93988 - diff: 15.04mlTrain batch 10/32 - 152.2ms/batch - loss: 0.94945 - diff: 15.19mlTrain batch 11/32 - 164.8ms/batch - loss: 0.94469 - diff: 15.12mlTrain batch 12/32 - 120.1ms/batch - loss: 0.92404 - diff: 14.78mlTrain batch 13/32 - 196.4ms/batch - loss: 0.91852 - diff: 14.70mlTrain batch 14/32 - 157.0ms/batch - loss: 0.91756 - diff: 14.68mlTrain batch 15/32 - 135.2ms/batch - loss: 0.90855 - diff: 14.54mlTrain batch 16/32 - 120.9ms/batch - loss: 0.90978 - diff: 14.56mlTrain batch 17/32 - 141.5ms/batch - loss: 0.90087 - diff: 14.41mlTrain batch 18/32 - 121.3ms/batch - loss: 0.90402 - diff: 14.46mlTrain batch 19/32 - 145.0ms/batch - loss: 0.90911 - diff: 14.55mlTrain batch 20/32 - 133.4ms/batch - loss: 0.90818 - diff: 14.53mlTrain batch 21/32 - 134.3ms/batch - loss: 0.94518 - diff: 15.12mlTrain batch 22/32 - 118.5ms/batch - loss: 0.93895 - diff: 15.02mlTrain batch 23/32 - 177.0ms/batch - loss: 0.92977 - diff: 14.88mlTrain batch 24/32 - 179.8ms/batch - loss: 0.95913 - diff: 15.35mlTrain batch 25/32 - 151.7ms/batch - loss: 0.96283 - diff: 15.41mlTrain batch 26/32 - 199.8ms/batch - loss: 1.02527 - diff: 16.40mlTrain batch 27/32 - 123.0ms/batch - loss: 1.03188 - diff: 16.51mlTrain batch 28/32 - 170.0ms/batch - loss: 1.02534 - diff: 16.41mlTrain batch 29/32 - 170.8ms/batch - loss: 1.02648 - diff: 16.42mlTrain batch 30/32 - 157.4ms/batch - loss: 1.02196 - diff: 16.35mlTrain batch 31/32 - 135.1ms/batch - loss: 1.01035 - diff: 16.17mlTrain batch 32/32 - 150.0ms/batch - loss: 1.07747 - diff: 16.34mlTrain batch 32/32 - 15.1s 150.0ms/batch - loss: 1.07747 - diff: 16.34ml
Test 1.0s: val_loss: 1.29261 - diff: 20.19ml

Epoch 65: current best loss = 0.99609, at epoch 56
Train batch 1/32 - 199.1ms/batch - loss: 1.64303 - diff: 26.29mlTrain batch 2/32 - 132.1ms/batch - loss: 1.24595 - diff: 19.94mlTrain batch 3/32 - 142.2ms/batch - loss: 1.10381 - diff: 17.66mlTrain batch 4/32 - 105.8ms/batch - loss: 0.97493 - diff: 15.60mlTrain batch 5/32 - 195.5ms/batch - loss: 1.01237 - diff: 16.20mlTrain batch 6/32 - 201.4ms/batch - loss: 1.09346 - diff: 17.50mlTrain batch 7/32 - 132.1ms/batch - loss: 1.02546 - diff: 16.41mlTrain batch 8/32 - 163.3ms/batch - loss: 0.99822 - diff: 15.97mlTrain batch 9/32 - 176.3ms/batch - loss: 0.98711 - diff: 15.79mlTrain batch 10/32 - 162.8ms/batch - loss: 1.04298 - diff: 16.69mlTrain batch 11/32 - 140.6ms/batch - loss: 1.06332 - diff: 17.01mlTrain batch 12/32 - 188.1ms/batch - loss: 1.05955 - diff: 16.95mlTrain batch 13/32 - 173.6ms/batch - loss: 1.03066 - diff: 16.49mlTrain batch 14/32 - 129.5ms/batch - loss: 1.01088 - diff: 16.17mlTrain batch 15/32 - 146.7ms/batch - loss: 0.98267 - diff: 15.72mlTrain batch 16/32 - 167.7ms/batch - loss: 0.97149 - diff: 15.54mlTrain batch 17/32 - 159.7ms/batch - loss: 0.95083 - diff: 15.21mlTrain batch 18/32 - 176.4ms/batch - loss: 0.95690 - diff: 15.31mlTrain batch 19/32 - 129.0ms/batch - loss: 0.95509 - diff: 15.28mlTrain batch 20/32 - 151.5ms/batch - loss: 0.94534 - diff: 15.13mlTrain batch 21/32 - 188.3ms/batch - loss: 0.94226 - diff: 15.08mlTrain batch 22/32 - 159.7ms/batch - loss: 0.93713 - diff: 14.99mlTrain batch 23/32 - 134.6ms/batch - loss: 0.92457 - diff: 14.79mlTrain batch 24/32 - 118.4ms/batch - loss: 0.92411 - diff: 14.79mlTrain batch 25/32 - 121.7ms/batch - loss: 0.97412 - diff: 15.59mlTrain batch 26/32 - 157.6ms/batch - loss: 0.96542 - diff: 15.45mlTrain batch 27/32 - 148.8ms/batch - loss: 0.96659 - diff: 15.47mlTrain batch 28/32 - 174.5ms/batch - loss: 0.96611 - diff: 15.46mlTrain batch 29/32 - 134.0ms/batch - loss: 0.95964 - diff: 15.35mlTrain batch 30/32 - 177.5ms/batch - loss: 0.96295 - diff: 15.41mlTrain batch 31/32 - 136.2ms/batch - loss: 0.97759 - diff: 15.64mlTrain batch 32/32 - 186.1ms/batch - loss: 1.00808 - diff: 15.67mlTrain batch 32/32 - 17.4s 186.1ms/batch - loss: 1.00808 - diff: 15.67ml
Test 1.0s: val_loss: 1.30794 - diff: 19.84ml

Epoch 66: current best loss = 0.99609, at epoch 56
Train batch 1/32 - 153.4ms/batch - loss: 0.72748 - diff: 11.64mlTrain batch 2/32 - 140.1ms/batch - loss: 0.69490 - diff: 11.12mlTrain batch 3/32 - 141.6ms/batch - loss: 0.77178 - diff: 12.35mlTrain batch 4/32 - 155.1ms/batch - loss: 0.75348 - diff: 12.06mlTrain batch 5/32 - 169.0ms/batch - loss: 0.89723 - diff: 14.36mlTrain batch 6/32 - 141.6ms/batch - loss: 0.91221 - diff: 14.60mlTrain batch 7/32 - 174.6ms/batch - loss: 0.97306 - diff: 15.57mlTrain batch 8/32 - 169.6ms/batch - loss: 0.95732 - diff: 15.32mlTrain batch 9/32 - 160.7ms/batch - loss: 0.94311 - diff: 15.09mlTrain batch 10/32 - 105.0ms/batch - loss: 0.94014 - diff: 15.04mlTrain batch 11/32 - 133.4ms/batch - loss: 0.95766 - diff: 15.32mlTrain batch 12/32 - 110.4ms/batch - loss: 0.99770 - diff: 15.96mlTrain batch 13/32 - 124.2ms/batch - loss: 0.97882 - diff: 15.66mlTrain batch 14/32 - 184.1ms/batch - loss: 0.97515 - diff: 15.60mlTrain batch 15/32 - 195.8ms/batch - loss: 0.94773 - diff: 15.16mlTrain batch 16/32 - 175.7ms/batch - loss: 0.95275 - diff: 15.24mlTrain batch 17/32 - 150.3ms/batch - loss: 0.95458 - diff: 15.27mlTrain batch 18/32 - 120.1ms/batch - loss: 0.97062 - diff: 15.53mlTrain batch 19/32 - 164.9ms/batch - loss: 1.00149 - diff: 16.02mlTrain batch 20/32 - 166.2ms/batch - loss: 1.01794 - diff: 16.29mlTrain batch 21/32 - 154.7ms/batch - loss: 1.01472 - diff: 16.24mlTrain batch 22/32 - 173.8ms/batch - loss: 1.01412 - diff: 16.23mlTrain batch 23/32 - 123.1ms/batch - loss: 1.00718 - diff: 16.11mlTrain batch 24/32 - 130.8ms/batch - loss: 1.01215 - diff: 16.19mlTrain batch 25/32 - 178.5ms/batch - loss: 1.00073 - diff: 16.01mlTrain batch 26/32 - 196.5ms/batch - loss: 0.99357 - diff: 15.90mlTrain batch 27/32 - 129.0ms/batch - loss: 0.97479 - diff: 15.60mlTrain batch 28/32 - 202.2ms/batch - loss: 0.97839 - diff: 15.65mlTrain batch 29/32 - 143.5ms/batch - loss: 0.97979 - diff: 15.68mlTrain batch 30/32 - 170.8ms/batch - loss: 0.98107 - diff: 15.70mlTrain batch 31/32 - 188.6ms/batch - loss: 0.99234 - diff: 15.88mlTrain batch 32/32 - 154.3ms/batch - loss: 1.01441 - diff: 15.87mlTrain batch 32/32 - 17.6s 154.3ms/batch - loss: 1.01441 - diff: 15.87ml
Test 1.0s: val_loss: 1.11859 - diff: 17.07ml

Epoch 67: current best loss = 0.99609, at epoch 56
Train batch 1/32 - 201.1ms/batch - loss: 1.34095 - diff: 21.46mlTrain batch 2/32 - 173.6ms/batch - loss: 1.23829 - diff: 19.81mlTrain batch 3/32 - 173.5ms/batch - loss: 1.12279 - diff: 17.96mlTrain batch 4/32 - 112.5ms/batch - loss: 0.98309 - diff: 15.73mlTrain batch 5/32 - 173.4ms/batch - loss: 1.03455 - diff: 16.55mlTrain batch 6/32 - 121.1ms/batch - loss: 0.98378 - diff: 15.74mlTrain batch 7/32 - 171.5ms/batch - loss: 0.97086 - diff: 15.53mlTrain batch 8/32 - 168.5ms/batch - loss: 0.97850 - diff: 15.66mlTrain batch 9/32 - 136.8ms/batch - loss: 0.96648 - diff: 15.46mlTrain batch 10/32 - 171.1ms/batch - loss: 0.97137 - diff: 15.54mlTrain batch 11/32 - 131.5ms/batch - loss: 0.97568 - diff: 15.61mlTrain batch 12/32 - 138.3ms/batch - loss: 0.99321 - diff: 15.89mlTrain batch 13/32 - 137.1ms/batch - loss: 0.98842 - diff: 15.81mlTrain batch 14/32 - 163.6ms/batch - loss: 0.98302 - diff: 15.73mlTrain batch 15/32 - 170.3ms/batch - loss: 0.95308 - diff: 15.25mlTrain batch 16/32 - 171.7ms/batch - loss: 0.98950 - diff: 15.83mlTrain batch 17/32 - 165.3ms/batch - loss: 1.02651 - diff: 16.42mlTrain batch 18/32 - 183.1ms/batch - loss: 1.03128 - diff: 16.50mlTrain batch 19/32 - 161.0ms/batch - loss: 1.01981 - diff: 16.32mlTrain batch 20/32 - 172.5ms/batch - loss: 1.01192 - diff: 16.19mlTrain batch 21/32 - 182.9ms/batch - loss: 1.00505 - diff: 16.08mlTrain batch 22/32 - 169.0ms/batch - loss: 0.99357 - diff: 15.90mlTrain batch 23/32 - 150.4ms/batch - loss: 0.99365 - diff: 15.90mlTrain batch 24/32 - 152.7ms/batch - loss: 0.99616 - diff: 15.94mlTrain batch 25/32 - 137.0ms/batch - loss: 0.98878 - diff: 15.82mlTrain batch 26/32 - 108.2ms/batch - loss: 0.99209 - diff: 15.87mlTrain batch 27/32 - 168.6ms/batch - loss: 0.99615 - diff: 15.94mlTrain batch 28/32 - 128.6ms/batch - loss: 0.99131 - diff: 15.86mlTrain batch 29/32 - 194.2ms/batch - loss: 0.98080 - diff: 15.69mlTrain batch 30/32 - 135.3ms/batch - loss: 1.00725 - diff: 16.12mlTrain batch 31/32 - 148.7ms/batch - loss: 1.00503 - diff: 16.08mlTrain batch 32/32 - 165.3ms/batch - loss: 1.00534 - diff: 15.99mlTrain batch 32/32 - 17.3s 165.3ms/batch - loss: 1.00534 - diff: 15.99ml
Test 1.2s: val_loss: 1.10626 - diff: 17.20ml
Epoch    68: reducing learning rate of group 0 to 2.5000e-04.

Epoch 68: current best loss = 0.99609, at epoch 56
Train batch 1/32 - 200.3ms/batch - loss: 0.76324 - diff: 12.21mlTrain batch 2/32 - 148.3ms/batch - loss: 0.65509 - diff: 10.48mlTrain batch 3/32 - 167.6ms/batch - loss: 0.66446 - diff: 10.63mlTrain batch 4/32 - 127.5ms/batch - loss: 0.81580 - diff: 13.05mlTrain batch 5/32 - 145.0ms/batch - loss: 0.88245 - diff: 14.12mlTrain batch 6/32 - 141.1ms/batch - loss: 0.84868 - diff: 13.58mlTrain batch 7/32 - 211.1ms/batch - loss: 0.84578 - diff: 13.53mlTrain batch 8/32 - 181.4ms/batch - loss: 0.84237 - diff: 13.48mlTrain batch 9/32 - 145.8ms/batch - loss: 0.83744 - diff: 13.40mlTrain batch 10/32 - 145.8ms/batch - loss: 0.82548 - diff: 13.21mlTrain batch 11/32 - 139.5ms/batch - loss: 0.81672 - diff: 13.07mlTrain batch 12/32 - 162.6ms/batch - loss: 0.82329 - diff: 13.17mlTrain batch 13/32 - 121.4ms/batch - loss: 0.84315 - diff: 13.49mlTrain batch 14/32 - 175.2ms/batch - loss: 0.88380 - diff: 14.14mlTrain batch 15/32 - 181.0ms/batch - loss: 0.87265 - diff: 13.96mlTrain batch 16/32 - 130.0ms/batch - loss: 0.86966 - diff: 13.91mlTrain batch 17/32 - 132.1ms/batch - loss: 0.87436 - diff: 13.99mlTrain batch 18/32 - 165.4ms/batch - loss: 0.86350 - diff: 13.82mlTrain batch 19/32 - 139.3ms/batch - loss: 0.85046 - diff: 13.61mlTrain batch 20/32 - 159.7ms/batch - loss: 0.84433 - diff: 13.51mlTrain batch 21/32 - 142.6ms/batch - loss: 0.87426 - diff: 13.99mlTrain batch 22/32 - 179.4ms/batch - loss: 0.87454 - diff: 13.99mlTrain batch 23/32 - 171.1ms/batch - loss: 0.86775 - diff: 13.88mlTrain batch 24/32 - 204.3ms/batch - loss: 0.86363 - diff: 13.82mlTrain batch 25/32 - 176.5ms/batch - loss: 0.85725 - diff: 13.72mlTrain batch 26/32 - 174.5ms/batch - loss: 0.86181 - diff: 13.79mlTrain batch 27/32 - 144.4ms/batch - loss: 0.86589 - diff: 13.85mlTrain batch 28/32 - 158.1ms/batch - loss: 0.85929 - diff: 13.75mlTrain batch 29/32 - 188.1ms/batch - loss: 0.84797 - diff: 13.57mlTrain batch 30/32 - 106.6ms/batch - loss: 0.86062 - diff: 13.77mlTrain batch 31/32 - 105.3ms/batch - loss: 0.86211 - diff: 13.79mlTrain batch 32/32 - 99.6ms/batch - loss: 0.92708 - diff: 13.97mlTrain batch 32/32 - 16.9s 99.6ms/batch - loss: 0.92708 - diff: 13.97ml
Test 1.0s: val_loss: 1.12778 - diff: 17.39ml

Epoch 69: current best loss = 0.99609, at epoch 56
Train batch 1/32 - 157.1ms/batch - loss: 1.37610 - diff: 22.02mlTrain batch 2/32 - 113.1ms/batch - loss: 1.53922 - diff: 24.63mlTrain batch 3/32 - 152.9ms/batch - loss: 1.26168 - diff: 20.19mlTrain batch 4/32 - 119.1ms/batch - loss: 1.17581 - diff: 18.81mlTrain batch 5/32 - 147.0ms/batch - loss: 1.10586 - diff: 17.69mlTrain batch 6/32 - 207.1ms/batch - loss: 1.02058 - diff: 16.33mlTrain batch 7/32 - 182.7ms/batch - loss: 0.99504 - diff: 15.92mlTrain batch 8/32 - 152.8ms/batch - loss: 0.94869 - diff: 15.18mlTrain batch 9/32 - 180.6ms/batch - loss: 0.97455 - diff: 15.59mlTrain batch 10/32 - 170.6ms/batch - loss: 0.93630 - diff: 14.98mlTrain batch 11/32 - 144.6ms/batch - loss: 1.02889 - diff: 16.46mlTrain batch 12/32 - 212.1ms/batch - loss: 1.01102 - diff: 16.18mlTrain batch 13/32 - 159.5ms/batch - loss: 0.98242 - diff: 15.72mlTrain batch 14/32 - 156.6ms/batch - loss: 0.96825 - diff: 15.49mlTrain batch 15/32 - 165.1ms/batch - loss: 0.95486 - diff: 15.28mlTrain batch 16/32 - 119.6ms/batch - loss: 0.93961 - diff: 15.03mlTrain batch 17/32 - 190.0ms/batch - loss: 0.93106 - diff: 14.90mlTrain batch 18/32 - 127.3ms/batch - loss: 0.93459 - diff: 14.95mlTrain batch 19/32 - 141.7ms/batch - loss: 0.92038 - diff: 14.73mlTrain batch 20/32 - 200.1ms/batch - loss: 0.92789 - diff: 14.85mlTrain batch 21/32 - 150.8ms/batch - loss: 0.94168 - diff: 15.07mlTrain batch 22/32 - 154.4ms/batch - loss: 0.93224 - diff: 14.92mlTrain batch 23/32 - 173.4ms/batch - loss: 0.95607 - diff: 15.30mlTrain batch 24/32 - 198.5ms/batch - loss: 0.94585 - diff: 15.13mlTrain batch 25/32 - 142.4ms/batch - loss: 0.93149 - diff: 14.90mlTrain batch 26/32 - 174.2ms/batch - loss: 0.91864 - diff: 14.70mlTrain batch 27/32 - 156.0ms/batch - loss: 0.92252 - diff: 14.76mlTrain batch 28/32 - 148.8ms/batch - loss: 0.91654 - diff: 14.66mlTrain batch 29/32 - 139.1ms/batch - loss: 0.91937 - diff: 14.71mlTrain batch 30/32 - 147.0ms/batch - loss: 0.90954 - diff: 14.55mlTrain batch 31/32 - 190.5ms/batch - loss: 0.90443 - diff: 14.47mlTrain batch 32/32 - 146.2ms/batch - loss: 0.95692 - diff: 14.59mlTrain batch 32/32 - 16.4s 146.2ms/batch - loss: 0.95692 - diff: 14.59ml
Test 1.0s: val_loss: 1.05885 - diff: 16.17ml

Epoch 70: current best loss = 0.99609, at epoch 56
Train batch 1/32 - 190.1ms/batch - loss: 0.77447 - diff: 12.39mlTrain batch 2/32 - 167.6ms/batch - loss: 0.65952 - diff: 10.55mlTrain batch 3/32 - 161.7ms/batch - loss: 0.69521 - diff: 11.12mlTrain batch 4/32 - 132.0ms/batch - loss: 0.67631 - diff: 10.82mlTrain batch 5/32 - 168.1ms/batch - loss: 0.71132 - diff: 11.38mlTrain batch 6/32 - 124.2ms/batch - loss: 0.69282 - diff: 11.09mlTrain batch 7/32 - 161.2ms/batch - loss: 0.78570 - diff: 12.57mlTrain batch 8/32 - 171.3ms/batch - loss: 0.82367 - diff: 13.18mlTrain batch 9/32 - 173.0ms/batch - loss: 0.79340 - diff: 12.69mlTrain batch 10/32 - 200.8ms/batch - loss: 0.82882 - diff: 13.26mlTrain batch 11/32 - 156.5ms/batch - loss: 0.81961 - diff: 13.11mlTrain batch 12/32 - 133.6ms/batch - loss: 0.80743 - diff: 12.92mlTrain batch 13/32 - 177.1ms/batch - loss: 0.81342 - diff: 13.01mlTrain batch 14/32 - 196.2ms/batch - loss: 0.81341 - diff: 13.01mlTrain batch 15/32 - 171.6ms/batch - loss: 0.81042 - diff: 12.97mlTrain batch 16/32 - 193.3ms/batch - loss: 0.84900 - diff: 13.58mlTrain batch 17/32 - 143.9ms/batch - loss: 0.83412 - diff: 13.35mlTrain batch 18/32 - 163.6ms/batch - loss: 0.83570 - diff: 13.37mlTrain batch 19/32 - 154.2ms/batch - loss: 0.82969 - diff: 13.27mlTrain batch 20/32 - 145.1ms/batch - loss: 0.82515 - diff: 13.20mlTrain batch 21/32 - 171.1ms/batch - loss: 0.82046 - diff: 13.13mlTrain batch 22/32 - 131.7ms/batch - loss: 0.82189 - diff: 13.15mlTrain batch 23/32 - 141.6ms/batch - loss: 0.82271 - diff: 13.16mlTrain batch 24/32 - 109.6ms/batch - loss: 0.83035 - diff: 13.29mlTrain batch 25/32 - 157.3ms/batch - loss: 0.86110 - diff: 13.78mlTrain batch 26/32 - 140.5ms/batch - loss: 0.85626 - diff: 13.70mlTrain batch 27/32 - 155.6ms/batch - loss: 0.85570 - diff: 13.69mlTrain batch 28/32 - 169.5ms/batch - loss: 0.84268 - diff: 13.48mlTrain batch 29/32 - 163.2ms/batch - loss: 0.83779 - diff: 13.40mlTrain batch 30/32 - 180.0ms/batch - loss: 0.83244 - diff: 13.32mlTrain batch 31/32 - 157.3ms/batch - loss: 0.82964 - diff: 13.27mlTrain batch 32/32 - 132.5ms/batch - loss: 0.85764 - diff: 13.31mlTrain batch 32/32 - 16.7s 132.5ms/batch - loss: 0.85764 - diff: 13.31ml
Test 1.1s: val_loss: 1.14005 - diff: 17.18ml

Epoch 71: current best loss = 0.99609, at epoch 56
Train batch 1/32 - 196.2ms/batch - loss: 0.94114 - diff: 15.06mlTrain batch 2/32 - 195.7ms/batch - loss: 0.85675 - diff: 13.71mlTrain batch 3/32 - 172.0ms/batch - loss: 0.81415 - diff: 13.03mlTrain batch 4/32 - 138.1ms/batch - loss: 0.78880 - diff: 12.62mlTrain batch 5/32 - 177.9ms/batch - loss: 0.74963 - diff: 11.99mlTrain batch 6/32 - 146.8ms/batch - loss: 0.69474 - diff: 11.12mlTrain batch 7/32 - 128.4ms/batch - loss: 0.72294 - diff: 11.57mlTrain batch 8/32 - 127.0ms/batch - loss: 0.73102 - diff: 11.70mlTrain batch 9/32 - 149.6ms/batch - loss: 0.70748 - diff: 11.32mlTrain batch 10/32 - 116.7ms/batch - loss: 0.69020 - diff: 11.04mlTrain batch 11/32 - 148.2ms/batch - loss: 0.71346 - diff: 11.42mlTrain batch 12/32 - 135.9ms/batch - loss: 0.71524 - diff: 11.44mlTrain batch 13/32 - 167.1ms/batch - loss: 0.78100 - diff: 12.50mlTrain batch 14/32 - 165.4ms/batch - loss: 0.77614 - diff: 12.42mlTrain batch 15/32 - 177.8ms/batch - loss: 0.76088 - diff: 12.17mlTrain batch 16/32 - 178.9ms/batch - loss: 0.74856 - diff: 11.98mlTrain batch 17/32 - 148.7ms/batch - loss: 0.74106 - diff: 11.86mlTrain batch 18/32 - 171.5ms/batch - loss: 0.76838 - diff: 12.29mlTrain batch 19/32 - 166.3ms/batch - loss: 0.78606 - diff: 12.58mlTrain batch 20/32 - 166.2ms/batch - loss: 0.78212 - diff: 12.51mlTrain batch 21/32 - 112.6ms/batch - loss: 0.77984 - diff: 12.48mlTrain batch 22/32 - 172.1ms/batch - loss: 0.79160 - diff: 12.67mlTrain batch 23/32 - 113.2ms/batch - loss: 0.79568 - diff: 12.73mlTrain batch 24/32 - 190.4ms/batch - loss: 0.79314 - diff: 12.69mlTrain batch 25/32 - 178.2ms/batch - loss: 0.80759 - diff: 12.92mlTrain batch 26/32 - 193.0ms/batch - loss: 0.80134 - diff: 12.82mlTrain batch 27/32 - 173.0ms/batch - loss: 0.79661 - diff: 12.75mlTrain batch 28/32 - 152.2ms/batch - loss: 0.79689 - diff: 12.75mlTrain batch 29/32 - 184.9ms/batch - loss: 0.79817 - diff: 12.77mlTrain batch 30/32 - 178.1ms/batch - loss: 0.80695 - diff: 12.91mlTrain batch 31/32 - 154.1ms/batch - loss: 0.81547 - diff: 13.05mlTrain batch 32/32 - 141.8ms/batch - loss: 0.82765 - diff: 13.02mlTrain batch 32/32 - 17.4s 141.8ms/batch - loss: 0.82765 - diff: 13.02ml
Test 1.0s: val_loss: 1.11417 - diff: 17.20ml

Epoch 72: current best loss = 0.99609, at epoch 56
Train batch 1/32 - 194.2ms/batch - loss: 0.59806 - diff: 9.57mlTrain batch 2/32 - 166.8ms/batch - loss: 0.60277 - diff: 9.64mlTrain batch 3/32 - 138.8ms/batch - loss: 0.73523 - diff: 11.76mlTrain batch 4/32 - 154.4ms/batch - loss: 0.82368 - diff: 13.18mlTrain batch 5/32 - 154.5ms/batch - loss: 0.92219 - diff: 14.76mlTrain batch 6/32 - 161.3ms/batch - loss: 0.85880 - diff: 13.74mlTrain batch 7/32 - 183.4ms/batch - loss: 0.86491 - diff: 13.84mlTrain batch 8/32 - 153.6ms/batch - loss: 0.83901 - diff: 13.42mlTrain batch 9/32 - 134.5ms/batch - loss: 0.80338 - diff: 12.85mlTrain batch 10/32 - 185.9ms/batch - loss: 0.81913 - diff: 13.11mlTrain batch 11/32 - 173.4ms/batch - loss: 0.82819 - diff: 13.25mlTrain batch 12/32 - 163.8ms/batch - loss: 0.82105 - diff: 13.14mlTrain batch 13/32 - 174.8ms/batch - loss: 0.82490 - diff: 13.20mlTrain batch 14/32 - 161.9ms/batch - loss: 0.81697 - diff: 13.07mlTrain batch 15/32 - 157.7ms/batch - loss: 0.81795 - diff: 13.09mlTrain batch 16/32 - 185.9ms/batch - loss: 0.82128 - diff: 13.14mlTrain batch 17/32 - 195.9ms/batch - loss: 0.84613 - diff: 13.54mlTrain batch 18/32 - 156.8ms/batch - loss: 0.85712 - diff: 13.71mlTrain batch 19/32 - 162.0ms/batch - loss: 0.84936 - diff: 13.59mlTrain batch 20/32 - 157.8ms/batch - loss: 0.84070 - diff: 13.45mlTrain batch 21/32 - 162.2ms/batch - loss: 0.90509 - diff: 14.48mlTrain batch 22/32 - 173.6ms/batch - loss: 0.89813 - diff: 14.37mlTrain batch 23/32 - 164.8ms/batch - loss: 0.88083 - diff: 14.09mlTrain batch 24/32 - 150.8ms/batch - loss: 0.87290 - diff: 13.97mlTrain batch 25/32 - 155.7ms/batch - loss: 0.86106 - diff: 13.78mlTrain batch 26/32 - 149.0ms/batch - loss: 0.91501 - diff: 14.64mlTrain batch 27/32 - 139.5ms/batch - loss: 0.91006 - diff: 14.56mlTrain batch 28/32 - 178.2ms/batch - loss: 0.89892 - diff: 14.38mlTrain batch 29/32 - 157.0ms/batch - loss: 0.89369 - diff: 14.30mlTrain batch 30/32 - 110.3ms/batch - loss: 0.87992 - diff: 14.08mlTrain batch 31/32 - 149.2ms/batch - loss: 0.88745 - diff: 14.20mlTrain batch 32/32 - 134.0ms/batch - loss: 0.91502 - diff: 14.22mlTrain batch 32/32 - 17.3s 134.0ms/batch - loss: 0.91502 - diff: 14.22ml
Test 1.0s: val_loss: 1.09219 - diff: 16.31ml

Epoch 73: current best loss = 0.99609, at epoch 56
Train batch 1/32 - 189.6ms/batch - loss: 0.47657 - diff: 7.63mlTrain batch 2/32 - 187.9ms/batch - loss: 0.43596 - diff: 6.98mlTrain batch 3/32 - 178.6ms/batch - loss: 0.53744 - diff: 8.60mlTrain batch 4/32 - 196.9ms/batch - loss: 0.54269 - diff: 8.68mlTrain batch 5/32 - 149.8ms/batch - loss: 0.54934 - diff: 8.79mlTrain batch 6/32 - 138.9ms/batch - loss: 0.57107 - diff: 9.14mlTrain batch 7/32 - 172.8ms/batch - loss: 0.61935 - diff: 9.91mlTrain batch 8/32 - 171.9ms/batch - loss: 0.62612 - diff: 10.02mlTrain batch 9/32 - 131.8ms/batch - loss: 0.65751 - diff: 10.52mlTrain batch 10/32 - 201.5ms/batch - loss: 0.66594 - diff: 10.66mlTrain batch 11/32 - 181.5ms/batch - loss: 0.65251 - diff: 10.44mlTrain batch 12/32 - 160.7ms/batch - loss: 0.66829 - diff: 10.69mlTrain batch 13/32 - 170.7ms/batch - loss: 0.69042 - diff: 11.05mlTrain batch 14/32 - 165.5ms/batch - loss: 0.69616 - diff: 11.14mlTrain batch 15/32 - 136.0ms/batch - loss: 0.70895 - diff: 11.34mlTrain batch 16/32 - 143.4ms/batch - loss: 0.71164 - diff: 11.39mlTrain batch 17/32 - 141.8ms/batch - loss: 0.70492 - diff: 11.28mlTrain batch 18/32 - 134.8ms/batch - loss: 0.74156 - diff: 11.86mlTrain batch 19/32 - 145.2ms/batch - loss: 0.73330 - diff: 11.73mlTrain batch 20/32 - 168.9ms/batch - loss: 0.72521 - diff: 11.60mlTrain batch 21/32 - 187.4ms/batch - loss: 0.71704 - diff: 11.47mlTrain batch 22/32 - 151.0ms/batch - loss: 0.72083 - diff: 11.53mlTrain batch 23/32 - 184.3ms/batch - loss: 0.72946 - diff: 11.67mlTrain batch 24/32 - 162.2ms/batch - loss: 0.74016 - diff: 11.84mlTrain batch 25/32 - 178.6ms/batch - loss: 0.74394 - diff: 11.90mlTrain batch 26/32 - 171.5ms/batch - loss: 0.76149 - diff: 12.18mlTrain batch 27/32 - 195.9ms/batch - loss: 0.75282 - diff: 12.05mlTrain batch 28/32 - 187.7ms/batch - loss: 0.74657 - diff: 11.95mlTrain batch 29/32 - 164.1ms/batch - loss: 0.75887 - diff: 12.14mlTrain batch 30/32 - 152.1ms/batch - loss: 0.77713 - diff: 12.43mlTrain batch 31/32 - 118.8ms/batch - loss: 0.77115 - diff: 12.34mlTrain batch 32/32 - 117.7ms/batch - loss: 0.79487 - diff: 12.36mlTrain batch 32/32 - 17.3s 117.7ms/batch - loss: 0.79487 - diff: 12.36ml
Test 1.0s: val_loss: 1.35345 - diff: 20.57ml

Epoch 74: current best loss = 0.99609, at epoch 56
Train batch 1/32 - 194.9ms/batch - loss: 1.04697 - diff: 16.75mlTrain batch 2/32 - 141.0ms/batch - loss: 1.21979 - diff: 19.52mlTrain batch 3/32 - 127.8ms/batch - loss: 1.11174 - diff: 17.79mlTrain batch 4/32 - 169.1ms/batch - loss: 1.11235 - diff: 17.80mlTrain batch 5/32 - 157.5ms/batch - loss: 1.00110 - diff: 16.02mlTrain batch 6/32 - 210.3ms/batch - loss: 0.98650 - diff: 15.78mlTrain batch 7/32 - 209.7ms/batch - loss: 0.93340 - diff: 14.93mlTrain batch 8/32 - 225.7ms/batch - loss: 0.92133 - diff: 14.74mlTrain batch 9/32 - 163.7ms/batch - loss: 0.93129 - diff: 14.90mlTrain batch 10/32 - 142.7ms/batch - loss: 0.93189 - diff: 14.91mlTrain batch 11/32 - 167.2ms/batch - loss: 0.91753 - diff: 14.68mlTrain batch 12/32 - 189.4ms/batch - loss: 0.88388 - diff: 14.14mlTrain batch 13/32 - 155.3ms/batch - loss: 0.88098 - diff: 14.10mlTrain batch 14/32 - 177.3ms/batch - loss: 0.86020 - diff: 13.76mlTrain batch 15/32 - 172.3ms/batch - loss: 0.84147 - diff: 13.46mlTrain batch 16/32 - 174.6ms/batch - loss: 0.85049 - diff: 13.61mlTrain batch 17/32 - 154.8ms/batch - loss: 0.82814 - diff: 13.25mlTrain batch 18/32 - 175.4ms/batch - loss: 0.81593 - diff: 13.05mlTrain batch 19/32 - 204.5ms/batch - loss: 0.81311 - diff: 13.01mlTrain batch 20/32 - 168.2ms/batch - loss: 0.83365 - diff: 13.34mlTrain batch 21/32 - 171.5ms/batch - loss: 0.82845 - diff: 13.26mlTrain batch 22/32 - 168.7ms/batch - loss: 0.82220 - diff: 13.16mlTrain batch 23/32 - 133.5ms/batch - loss: 0.85913 - diff: 13.75mlTrain batch 24/32 - 144.7ms/batch - loss: 0.85768 - diff: 13.72mlTrain batch 25/32 - 141.9ms/batch - loss: 0.86384 - diff: 13.82mlTrain batch 26/32 - 177.7ms/batch - loss: 0.85292 - diff: 13.65mlTrain batch 27/32 - 151.6ms/batch - loss: 0.85247 - diff: 13.64mlTrain batch 28/32 - 165.6ms/batch - loss: 0.84376 - diff: 13.50mlTrain batch 29/32 - 195.0ms/batch - loss: 0.84461 - diff: 13.51mlTrain batch 30/32 - 178.5ms/batch - loss: 0.84431 - diff: 13.51mlTrain batch 31/32 - 124.5ms/batch - loss: 0.83856 - diff: 13.42mlTrain batch 32/32 - 124.0ms/batch - loss: 0.89335 - diff: 13.56mlTrain batch 32/32 - 16.3s 124.0ms/batch - loss: 0.89335 - diff: 13.56ml
Test 1.1s: val_loss: 0.98290 - diff: 15.24ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Systole_DenseNet121_0_Adam-0.001_MAE_DA3_best

Epoch 75: current best loss = 0.98290, at epoch 74
Train batch 1/32 - 196.6ms/batch - loss: 0.59928 - diff: 9.59mlTrain batch 2/32 - 185.7ms/batch - loss: 0.60183 - diff: 9.63mlTrain batch 3/32 - 182.1ms/batch - loss: 0.75697 - diff: 12.11mlTrain batch 4/32 - 135.8ms/batch - loss: 0.71873 - diff: 11.50mlTrain batch 5/32 - 173.3ms/batch - loss: 0.69963 - diff: 11.19mlTrain batch 6/32 - 198.4ms/batch - loss: 0.76155 - diff: 12.18mlTrain batch 7/32 - 181.7ms/batch - loss: 0.75477 - diff: 12.08mlTrain batch 8/32 - 187.6ms/batch - loss: 0.71378 - diff: 11.42mlTrain batch 9/32 - 160.2ms/batch - loss: 0.71442 - diff: 11.43mlTrain batch 10/32 - 144.9ms/batch - loss: 0.68530 - diff: 10.96mlTrain batch 11/32 - 109.5ms/batch - loss: 0.69121 - diff: 11.06mlTrain batch 12/32 - 87.8ms/batch - loss: 0.67493 - diff: 10.80mlTrain batch 13/32 - 218.7ms/batch - loss: 0.69781 - diff: 11.16mlTrain batch 14/32 - 200.2ms/batch - loss: 0.69486 - diff: 11.12mlTrain batch 15/32 - 201.3ms/batch - loss: 0.70758 - diff: 11.32mlTrain batch 16/32 - 170.6ms/batch - loss: 0.72420 - diff: 11.59mlTrain batch 17/32 - 174.6ms/batch - loss: 0.70607 - diff: 11.30mlTrain batch 18/32 - 177.6ms/batch - loss: 0.69533 - diff: 11.13mlTrain batch 19/32 - 131.8ms/batch - loss: 0.71732 - diff: 11.48mlTrain batch 20/32 - 144.8ms/batch - loss: 0.74433 - diff: 11.91mlTrain batch 21/32 - 133.2ms/batch - loss: 0.74527 - diff: 11.92mlTrain batch 22/32 - 172.6ms/batch - loss: 0.74318 - diff: 11.89mlTrain batch 23/32 - 126.9ms/batch - loss: 0.74046 - diff: 11.85mlTrain batch 24/32 - 149.0ms/batch - loss: 0.73170 - diff: 11.71mlTrain batch 25/32 - 146.6ms/batch - loss: 0.72343 - diff: 11.57mlTrain batch 26/32 - 176.9ms/batch - loss: 0.75903 - diff: 12.14mlTrain batch 27/32 - 156.8ms/batch - loss: 0.74684 - diff: 11.95mlTrain batch 28/32 - 184.0ms/batch - loss: 0.73384 - diff: 11.74mlTrain batch 29/32 - 158.9ms/batch - loss: 0.75529 - diff: 12.08mlTrain batch 30/32 - 190.5ms/batch - loss: 0.76399 - diff: 12.22mlTrain batch 31/32 - 159.6ms/batch - loss: 0.76589 - diff: 12.25mlTrain batch 32/32 - 158.3ms/batch - loss: 0.81621 - diff: 12.38mlTrain batch 32/32 - 15.7s 158.3ms/batch - loss: 0.81621 - diff: 12.38ml
Test 1.0s: val_loss: 1.19783 - diff: 17.70ml

Epoch 76: current best loss = 0.98290, at epoch 74
Train batch 1/32 - 205.4ms/batch - loss: 0.62652 - diff: 10.02mlTrain batch 2/32 - 156.4ms/batch - loss: 0.67287 - diff: 10.77mlTrain batch 3/32 - 178.1ms/batch - loss: 0.61463 - diff: 9.83mlTrain batch 4/32 - 220.4ms/batch - loss: 0.61893 - diff: 9.90mlTrain batch 5/32 - 195.1ms/batch - loss: 0.65003 - diff: 10.40mlTrain batch 6/32 - 188.6ms/batch - loss: 0.68202 - diff: 10.91mlTrain batch 7/32 - 160.3ms/batch - loss: 0.66430 - diff: 10.63mlTrain batch 8/32 - 131.7ms/batch - loss: 0.65557 - diff: 10.49mlTrain batch 9/32 - 202.5ms/batch - loss: 0.67727 - diff: 10.84mlTrain batch 10/32 - 198.8ms/batch - loss: 0.68953 - diff: 11.03mlTrain batch 11/32 - 198.2ms/batch - loss: 0.70472 - diff: 11.28mlTrain batch 12/32 - 168.6ms/batch - loss: 0.72103 - diff: 11.54mlTrain batch 13/32 - 166.1ms/batch - loss: 0.72586 - diff: 11.61mlTrain batch 14/32 - 179.5ms/batch - loss: 0.72191 - diff: 11.55mlTrain batch 15/32 - 200.2ms/batch - loss: 0.72530 - diff: 11.60mlTrain batch 16/32 - 142.3ms/batch - loss: 0.77065 - diff: 12.33mlTrain batch 17/32 - 170.9ms/batch - loss: 0.77158 - diff: 12.35mlTrain batch 18/32 - 185.0ms/batch - loss: 0.77223 - diff: 12.36mlTrain batch 19/32 - 151.5ms/batch - loss: 0.78728 - diff: 12.60mlTrain batch 20/32 - 116.7ms/batch - loss: 0.79851 - diff: 12.78mlTrain batch 21/32 - 186.4ms/batch - loss: 0.78556 - diff: 12.57mlTrain batch 22/32 - 191.1ms/batch - loss: 0.78406 - diff: 12.54mlTrain batch 23/32 - 154.7ms/batch - loss: 0.77800 - diff: 12.45mlTrain batch 24/32 - 166.7ms/batch - loss: 0.78808 - diff: 12.61mlTrain batch 25/32 - 161.9ms/batch - loss: 0.78705 - diff: 12.59mlTrain batch 26/32 - 179.3ms/batch - loss: 0.77603 - diff: 12.42mlTrain batch 27/32 - 157.7ms/batch - loss: 0.77525 - diff: 12.40mlTrain batch 28/32 - 154.7ms/batch - loss: 0.78221 - diff: 12.52mlTrain batch 29/32 - 142.6ms/batch - loss: 0.77289 - diff: 12.37mlTrain batch 30/32 - 149.7ms/batch - loss: 0.77936 - diff: 12.47mlTrain batch 31/32 - 131.4ms/batch - loss: 0.77341 - diff: 12.37mlTrain batch 32/32 - 159.2ms/batch - loss: 0.82117 - diff: 12.49mlTrain batch 32/32 - 17.9s 159.2ms/batch - loss: 0.82117 - diff: 12.49ml
Test 0.9s: val_loss: 1.01328 - diff: 15.59ml

Epoch 77: current best loss = 0.98290, at epoch 74
Train batch 1/32 - 160.4ms/batch - loss: 0.66739 - diff: 10.68mlTrain batch 2/32 - 162.6ms/batch - loss: 1.05201 - diff: 16.83mlTrain batch 3/32 - 178.4ms/batch - loss: 0.91985 - diff: 14.72mlTrain batch 4/32 - 182.9ms/batch - loss: 0.79190 - diff: 12.67mlTrain batch 5/32 - 180.2ms/batch - loss: 0.76072 - diff: 12.17mlTrain batch 6/32 - 134.7ms/batch - loss: 0.76681 - diff: 12.27mlTrain batch 7/32 - 169.8ms/batch - loss: 0.74056 - diff: 11.85mlTrain batch 8/32 - 187.3ms/batch - loss: 0.72958 - diff: 11.67mlTrain batch 9/32 - 192.1ms/batch - loss: 0.72007 - diff: 11.52mlTrain batch 10/32 - 203.1ms/batch - loss: 0.71531 - diff: 11.44mlTrain batch 11/32 - 165.7ms/batch - loss: 0.76961 - diff: 12.31mlTrain batch 12/32 - 185.9ms/batch - loss: 0.77902 - diff: 12.46mlTrain batch 13/32 - 160.3ms/batch - loss: 0.79374 - diff: 12.70mlTrain batch 14/32 - 184.6ms/batch - loss: 0.79906 - diff: 12.78mlTrain batch 15/32 - 186.4ms/batch - loss: 0.78547 - diff: 12.57mlTrain batch 16/32 - 202.9ms/batch - loss: 0.78126 - diff: 12.50mlTrain batch 17/32 - 165.0ms/batch - loss: 0.78900 - diff: 12.62mlTrain batch 18/32 - 121.6ms/batch - loss: 0.78227 - diff: 12.52mlTrain batch 19/32 - 162.7ms/batch - loss: 0.77923 - diff: 12.47mlTrain batch 20/32 - 184.5ms/batch - loss: 0.75997 - diff: 12.16mlTrain batch 21/32 - 117.1ms/batch - loss: 0.75116 - diff: 12.02mlTrain batch 22/32 - 140.0ms/batch - loss: 0.74200 - diff: 11.87mlTrain batch 23/32 - 159.4ms/batch - loss: 0.74820 - diff: 11.97mlTrain batch 24/32 - 157.0ms/batch - loss: 0.74379 - diff: 11.90mlTrain batch 25/32 - 152.4ms/batch - loss: 0.74408 - diff: 11.91mlTrain batch 26/32 - 125.5ms/batch - loss: 0.74477 - diff: 11.92mlTrain batch 27/32 - 147.1ms/batch - loss: 0.73908 - diff: 11.83mlTrain batch 28/32 - 192.2ms/batch - loss: 0.74160 - diff: 11.87mlTrain batch 29/32 - 175.2ms/batch - loss: 0.75978 - diff: 12.16mlTrain batch 30/32 - 166.3ms/batch - loss: 0.75483 - diff: 12.08mlTrain batch 31/32 - 176.6ms/batch - loss: 0.74948 - diff: 11.99mlTrain batch 32/32 - 150.1ms/batch - loss: 0.76700 - diff: 11.99mlTrain batch 32/32 - 16.8s 150.1ms/batch - loss: 0.76700 - diff: 11.99ml
Test 1.1s: val_loss: 0.99852 - diff: 15.47ml

Epoch 78: current best loss = 0.98290, at epoch 74
Train batch 1/32 - 150.9ms/batch - loss: 0.82809 - diff: 13.25mlTrain batch 2/32 - 129.5ms/batch - loss: 0.60860 - diff: 9.74mlTrain batch 3/32 - 158.3ms/batch - loss: 0.56219 - diff: 9.00mlTrain batch 4/32 - 155.5ms/batch - loss: 0.56913 - diff: 9.11mlTrain batch 5/32 - 121.4ms/batch - loss: 0.52717 - diff: 8.43mlTrain batch 6/32 - 122.5ms/batch - loss: 0.63571 - diff: 10.17mlTrain batch 7/32 - 167.2ms/batch - loss: 0.66690 - diff: 10.67mlTrain batch 8/32 - 154.7ms/batch - loss: 0.66889 - diff: 10.70mlTrain batch 9/32 - 135.8ms/batch - loss: 0.74323 - diff: 11.89mlTrain batch 10/32 - 194.4ms/batch - loss: 0.76636 - diff: 12.26mlTrain batch 11/32 - 135.8ms/batch - loss: 0.74622 - diff: 11.94mlTrain batch 12/32 - 181.4ms/batch - loss: 0.78256 - diff: 12.52mlTrain batch 13/32 - 176.0ms/batch - loss: 0.77841 - diff: 12.45mlTrain batch 14/32 - 152.6ms/batch - loss: 0.77586 - diff: 12.41mlTrain batch 15/32 - 146.9ms/batch - loss: 0.77854 - diff: 12.46mlTrain batch 16/32 - 186.9ms/batch - loss: 0.76793 - diff: 12.29mlTrain batch 17/32 - 163.5ms/batch - loss: 0.76666 - diff: 12.27mlTrain batch 18/32 - 116.0ms/batch - loss: 0.77099 - diff: 12.34mlTrain batch 19/32 - 168.4ms/batch - loss: 0.76096 - diff: 12.18mlTrain batch 20/32 - 171.2ms/batch - loss: 0.76186 - diff: 12.19mlTrain batch 21/32 - 156.7ms/batch - loss: 0.76319 - diff: 12.21mlTrain batch 22/32 - 110.5ms/batch - loss: 0.75428 - diff: 12.07mlTrain batch 23/32 - 182.0ms/batch - loss: 0.75048 - diff: 12.01mlTrain batch 24/32 - 151.7ms/batch - loss: 0.75166 - diff: 12.03mlTrain batch 25/32 - 176.5ms/batch - loss: 0.75719 - diff: 12.12mlTrain batch 26/32 - 153.7ms/batch - loss: 0.74298 - diff: 11.89mlTrain batch 27/32 - 161.5ms/batch - loss: 0.74461 - diff: 11.91mlTrain batch 28/32 - 106.4ms/batch - loss: 0.74442 - diff: 11.91mlTrain batch 29/32 - 110.7ms/batch - loss: 0.73515 - diff: 11.76mlTrain batch 30/32 - 161.6ms/batch - loss: 0.72917 - diff: 11.67mlTrain batch 31/32 - 166.4ms/batch - loss: 0.73507 - diff: 11.76mlTrain batch 32/32 - 93.5ms/batch - loss: 0.95473 - diff: 12.57mlTrain batch 32/32 - 16.8s 93.5ms/batch - loss: 0.95473 - diff: 12.57ml
Test 0.9s: val_loss: 1.08559 - diff: 16.38ml

Epoch 79: current best loss = 0.98290, at epoch 74
Train batch 1/32 - 188.1ms/batch - loss: 2.59831 - diff: 41.57mlTrain batch 2/32 - 142.2ms/batch - loss: 1.60571 - diff: 25.69mlTrain batch 3/32 - 172.3ms/batch - loss: 1.26313 - diff: 20.21mlTrain batch 4/32 - 202.8ms/batch - loss: 1.15357 - diff: 18.46mlTrain batch 5/32 - 181.8ms/batch - loss: 1.07442 - diff: 17.19mlTrain batch 6/32 - 181.8ms/batch - loss: 1.02043 - diff: 16.33mlTrain batch 7/32 - 175.5ms/batch - loss: 0.98517 - diff: 15.76mlTrain batch 8/32 - 185.9ms/batch - loss: 0.93292 - diff: 14.93mlTrain batch 9/32 - 136.1ms/batch - loss: 0.89478 - diff: 14.32mlTrain batch 10/32 - 124.2ms/batch - loss: 0.87325 - diff: 13.97mlTrain batch 11/32 - 163.8ms/batch - loss: 0.87029 - diff: 13.92mlTrain batch 12/32 - 180.2ms/batch - loss: 0.88375 - diff: 14.14mlTrain batch 13/32 - 169.4ms/batch - loss: 0.88117 - diff: 14.10mlTrain batch 14/32 - 179.2ms/batch - loss: 0.86697 - diff: 13.87mlTrain batch 15/32 - 152.2ms/batch - loss: 0.84602 - diff: 13.54mlTrain batch 16/32 - 161.5ms/batch - loss: 0.82761 - diff: 13.24mlTrain batch 17/32 - 166.5ms/batch - loss: 0.81857 - diff: 13.10mlTrain batch 18/32 - 111.1ms/batch - loss: 0.80394 - diff: 12.86mlTrain batch 19/32 - 161.8ms/batch - loss: 0.84025 - diff: 13.44mlTrain batch 20/32 - 161.2ms/batch - loss: 0.83940 - diff: 13.43mlTrain batch 21/32 - 181.2ms/batch - loss: 0.82516 - diff: 13.20mlTrain batch 22/32 - 154.5ms/batch - loss: 0.81525 - diff: 13.04mlTrain batch 23/32 - 184.4ms/batch - loss: 0.80894 - diff: 12.94mlTrain batch 24/32 - 155.9ms/batch - loss: 0.79924 - diff: 12.79mlTrain batch 25/32 - 162.8ms/batch - loss: 0.80413 - diff: 12.87mlTrain batch 26/32 - 195.3ms/batch - loss: 0.79162 - diff: 12.67mlTrain batch 27/32 - 187.0ms/batch - loss: 0.78228 - diff: 12.52mlTrain batch 28/32 - 168.0ms/batch - loss: 0.78483 - diff: 12.56mlTrain batch 29/32 - 190.2ms/batch - loss: 0.77629 - diff: 12.42mlTrain batch 30/32 - 93.3ms/batch - loss: 0.76195 - diff: 12.19mlTrain batch 31/32 - 85.8ms/batch - loss: 0.75928 - diff: 12.15mlTrain batch 32/32 - 70.6ms/batch - loss: 0.78282 - diff: 12.17mlTrain batch 32/32 - 17.1s 70.6ms/batch - loss: 0.78282 - diff: 12.17ml
Test 1.0s: val_loss: 1.05441 - diff: 16.04ml

Epoch 80: current best loss = 0.98290, at epoch 74
Train batch 1/32 - 156.2ms/batch - loss: 0.58028 - diff: 9.28mlTrain batch 2/32 - 125.2ms/batch - loss: 0.59096 - diff: 9.46mlTrain batch 3/32 - 165.1ms/batch - loss: 0.58501 - diff: 9.36mlTrain batch 4/32 - 176.2ms/batch - loss: 0.59754 - diff: 9.56mlTrain batch 5/32 - 150.4ms/batch - loss: 0.67719 - diff: 10.83mlTrain batch 6/32 - 147.9ms/batch - loss: 0.70720 - diff: 11.32mlTrain batch 7/32 - 173.6ms/batch - loss: 0.72976 - diff: 11.68mlTrain batch 8/32 - 174.2ms/batch - loss: 0.76640 - diff: 12.26mlTrain batch 9/32 - 164.8ms/batch - loss: 0.73457 - diff: 11.75mlTrain batch 10/32 - 193.2ms/batch - loss: 0.73395 - diff: 11.74mlTrain batch 11/32 - 218.2ms/batch - loss: 0.70800 - diff: 11.33mlTrain batch 12/32 - 184.8ms/batch - loss: 0.69898 - diff: 11.18mlTrain batch 13/32 - 158.3ms/batch - loss: 0.69250 - diff: 11.08mlTrain batch 14/32 - 166.3ms/batch - loss: 0.68519 - diff: 10.96mlTrain batch 15/32 - 177.3ms/batch - loss: 0.68140 - diff: 10.90mlTrain batch 16/32 - 184.7ms/batch - loss: 0.67995 - diff: 10.88mlTrain batch 17/32 - 152.1ms/batch - loss: 0.68724 - diff: 11.00mlTrain batch 18/32 - 126.9ms/batch - loss: 0.70171 - diff: 11.23mlTrain batch 19/32 - 117.7ms/batch - loss: 0.68879 - diff: 11.02mlTrain batch 20/32 - 141.5ms/batch - loss: 0.68611 - diff: 10.98mlTrain batch 21/32 - 133.2ms/batch - loss: 0.70163 - diff: 11.23mlTrain batch 22/32 - 148.9ms/batch - loss: 0.69980 - diff: 11.20mlTrain batch 23/32 - 142.3ms/batch - loss: 0.71065 - diff: 11.37mlTrain batch 24/32 - 200.3ms/batch - loss: 0.71064 - diff: 11.37mlTrain batch 25/32 - 155.4ms/batch - loss: 0.72067 - diff: 11.53mlTrain batch 26/32 - 179.9ms/batch - loss: 0.71192 - diff: 11.39mlTrain batch 27/32 - 171.4ms/batch - loss: 0.71245 - diff: 11.40mlTrain batch 28/32 - 161.6ms/batch - loss: 0.75298 - diff: 12.05mlTrain batch 29/32 - 142.0ms/batch - loss: 0.74989 - diff: 12.00mlTrain batch 30/32 - 164.5ms/batch - loss: 0.74307 - diff: 11.89mlTrain batch 31/32 - 183.7ms/batch - loss: 0.74016 - diff: 11.84mlTrain batch 32/32 - 131.3ms/batch - loss: 0.77255 - diff: 11.90mlTrain batch 32/32 - 16.4s 131.3ms/batch - loss: 0.77255 - diff: 11.90ml
Test 1.0s: val_loss: 1.43951 - diff: 21.93ml

Epoch 81: current best loss = 0.98290, at epoch 74
Train batch 1/32 - 125.5ms/batch - loss: 0.43177 - diff: 6.91mlTrain batch 2/32 - 158.4ms/batch - loss: 0.56691 - diff: 9.07mlTrain batch 3/32 - 185.0ms/batch - loss: 0.57506 - diff: 9.20mlTrain batch 4/32 - 140.5ms/batch - loss: 0.64088 - diff: 10.25mlTrain batch 5/32 - 152.4ms/batch - loss: 0.66439 - diff: 10.63mlTrain batch 6/32 - 117.0ms/batch - loss: 0.68246 - diff: 10.92mlTrain batch 7/32 - 202.6ms/batch - loss: 0.64466 - diff: 10.31mlTrain batch 8/32 - 177.4ms/batch - loss: 0.71578 - diff: 11.45mlTrain batch 9/32 - 157.0ms/batch - loss: 0.69302 - diff: 11.09mlTrain batch 10/32 - 147.1ms/batch - loss: 0.68028 - diff: 10.88mlTrain batch 11/32 - 191.5ms/batch - loss: 0.71404 - diff: 11.42mlTrain batch 12/32 - 203.8ms/batch - loss: 0.73726 - diff: 11.80mlTrain batch 13/32 - 166.3ms/batch - loss: 0.74595 - diff: 11.94mlTrain batch 14/32 - 159.9ms/batch - loss: 0.73729 - diff: 11.80mlTrain batch 15/32 - 179.2ms/batch - loss: 0.71802 - diff: 11.49mlTrain batch 16/32 - 148.6ms/batch - loss: 0.71055 - diff: 11.37mlTrain batch 17/32 - 143.2ms/batch - loss: 0.71701 - diff: 11.47mlTrain batch 18/32 - 185.4ms/batch - loss: 0.71153 - diff: 11.38mlTrain batch 19/32 - 159.9ms/batch - loss: 0.72488 - diff: 11.60mlTrain batch 20/32 - 159.6ms/batch - loss: 0.72782 - diff: 11.65mlTrain batch 21/32 - 204.4ms/batch - loss: 0.73523 - diff: 11.76mlTrain batch 22/32 - 131.0ms/batch - loss: 0.80493 - diff: 12.88mlTrain batch 23/32 - 143.4ms/batch - loss: 0.78997 - diff: 12.64mlTrain batch 24/32 - 169.6ms/batch - loss: 0.78182 - diff: 12.51mlTrain batch 25/32 - 189.8ms/batch - loss: 0.77715 - diff: 12.43mlTrain batch 26/32 - 173.5ms/batch - loss: 0.77134 - diff: 12.34mlTrain batch 27/32 - 185.9ms/batch - loss: 0.76171 - diff: 12.19mlTrain batch 28/32 - 179.8ms/batch - loss: 0.75741 - diff: 12.12mlTrain batch 29/32 - 145.6ms/batch - loss: 0.75420 - diff: 12.07mlTrain batch 30/32 - 108.6ms/batch - loss: 0.74983 - diff: 12.00mlTrain batch 31/32 - 202.1ms/batch - loss: 0.75070 - diff: 12.01mlTrain batch 32/32 - 110.7ms/batch - loss: 0.82359 - diff: 12.23mlTrain batch 32/32 - 17.1s 110.7ms/batch - loss: 0.82359 - diff: 12.23ml
Test 0.9s: val_loss: 1.06188 - diff: 16.38ml

Epoch 82: current best loss = 0.98290, at epoch 74
Train batch 1/32 - 225.1ms/batch - loss: 0.54366 - diff: 8.70mlTrain batch 2/32 - 166.3ms/batch - loss: 0.64431 - diff: 10.31mlTrain batch 3/32 - 163.7ms/batch - loss: 0.65381 - diff: 10.46mlTrain batch 4/32 - 174.3ms/batch - loss: 0.72535 - diff: 11.61mlTrain batch 5/32 - 133.8ms/batch - loss: 0.67703 - diff: 10.83mlTrain batch 6/32 - 133.6ms/batch - loss: 0.69161 - diff: 11.07mlTrain batch 7/32 - 145.3ms/batch - loss: 0.69119 - diff: 11.06mlTrain batch 8/32 - 166.1ms/batch - loss: 0.71125 - diff: 11.38mlTrain batch 9/32 - 159.9ms/batch - loss: 0.69719 - diff: 11.16mlTrain batch 10/32 - 184.0ms/batch - loss: 0.68435 - diff: 10.95mlTrain batch 11/32 - 182.9ms/batch - loss: 0.71698 - diff: 11.47mlTrain batch 12/32 - 110.4ms/batch - loss: 0.71865 - diff: 11.50mlTrain batch 13/32 - 176.9ms/batch - loss: 0.71878 - diff: 11.50mlTrain batch 14/32 - 141.9ms/batch - loss: 0.70179 - diff: 11.23mlTrain batch 15/32 - 152.3ms/batch - loss: 0.69972 - diff: 11.20mlTrain batch 16/32 - 165.0ms/batch - loss: 0.72003 - diff: 11.52mlTrain batch 17/32 - 170.7ms/batch - loss: 0.71031 - diff: 11.36mlTrain batch 18/32 - 172.3ms/batch - loss: 0.70910 - diff: 11.35mlTrain batch 19/32 - 183.1ms/batch - loss: 0.73312 - diff: 11.73mlTrain batch 20/32 - 183.9ms/batch - loss: 0.72281 - diff: 11.56mlTrain batch 21/32 - 111.8ms/batch - loss: 0.71492 - diff: 11.44mlTrain batch 22/32 - 163.4ms/batch - loss: 0.71240 - diff: 11.40mlTrain batch 23/32 - 211.9ms/batch - loss: 0.71652 - diff: 11.46mlTrain batch 24/32 - 176.1ms/batch - loss: 0.72369 - diff: 11.58mlTrain batch 25/32 - 199.4ms/batch - loss: 0.72618 - diff: 11.62mlTrain batch 26/32 - 172.1ms/batch - loss: 0.73367 - diff: 11.74mlTrain batch 27/32 - 180.6ms/batch - loss: 0.73841 - diff: 11.81mlTrain batch 28/32 - 183.0ms/batch - loss: 0.74977 - diff: 12.00mlTrain batch 29/32 - 145.1ms/batch - loss: 0.75587 - diff: 12.09mlTrain batch 30/32 - 149.7ms/batch - loss: 0.75646 - diff: 12.10mlTrain batch 31/32 - 135.3ms/batch - loss: 0.75612 - diff: 12.10mlTrain batch 32/32 - 165.0ms/batch - loss: 0.78126 - diff: 12.13mlTrain batch 32/32 - 17.8s 165.0ms/batch - loss: 0.78126 - diff: 12.13ml
Test 1.0s: val_loss: 0.94971 - diff: 14.74ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Systole_DenseNet121_0_Adam-0.001_MAE_DA3_best

Epoch 83: current best loss = 0.94971, at epoch 82
Train batch 1/32 - 151.3ms/batch - loss: 0.87337 - diff: 13.97mlTrain batch 2/32 - 153.0ms/batch - loss: 0.81048 - diff: 12.97mlTrain batch 3/32 - 159.8ms/batch - loss: 0.82377 - diff: 13.18mlTrain batch 4/32 - 141.4ms/batch - loss: 0.80230 - diff: 12.84mlTrain batch 5/32 - 189.6ms/batch - loss: 0.88337 - diff: 14.13mlTrain batch 6/32 - 155.1ms/batch - loss: 0.89012 - diff: 14.24mlTrain batch 7/32 - 183.6ms/batch - loss: 0.87344 - diff: 13.97mlTrain batch 8/32 - 186.1ms/batch - loss: 0.83910 - diff: 13.43mlTrain batch 9/32 - 195.5ms/batch - loss: 0.82557 - diff: 13.21mlTrain batch 10/32 - 178.7ms/batch - loss: 0.88981 - diff: 14.24mlTrain batch 11/32 - 188.6ms/batch - loss: 0.86849 - diff: 13.90mlTrain batch 12/32 - 172.4ms/batch - loss: 0.86937 - diff: 13.91mlTrain batch 13/32 - 170.0ms/batch - loss: 0.86408 - diff: 13.83mlTrain batch 14/32 - 171.4ms/batch - loss: 0.84322 - diff: 13.49mlTrain batch 15/32 - 186.1ms/batch - loss: 0.82627 - diff: 13.22mlTrain batch 16/32 - 153.1ms/batch - loss: 0.81056 - diff: 12.97mlTrain batch 17/32 - 158.7ms/batch - loss: 0.82475 - diff: 13.20mlTrain batch 18/32 - 143.7ms/batch - loss: 0.83441 - diff: 13.35mlTrain batch 19/32 - 171.8ms/batch - loss: 0.82347 - diff: 13.18mlTrain batch 20/32 - 153.0ms/batch - loss: 0.80866 - diff: 12.94mlTrain batch 21/32 - 172.7ms/batch - loss: 0.79289 - diff: 12.69mlTrain batch 22/32 - 129.3ms/batch - loss: 0.78508 - diff: 12.56mlTrain batch 23/32 - 193.9ms/batch - loss: 0.81037 - diff: 12.97mlTrain batch 24/32 - 124.7ms/batch - loss: 0.79887 - diff: 12.78mlTrain batch 25/32 - 117.9ms/batch - loss: 0.79947 - diff: 12.79mlTrain batch 26/32 - 160.1ms/batch - loss: 0.79374 - diff: 12.70mlTrain batch 27/32 - 112.2ms/batch - loss: 0.79755 - diff: 12.76mlTrain batch 28/32 - 131.2ms/batch - loss: 0.78870 - diff: 12.62mlTrain batch 29/32 - 193.8ms/batch - loss: 0.78521 - diff: 12.56mlTrain batch 30/32 - 120.9ms/batch - loss: 0.77793 - diff: 12.45mlTrain batch 31/32 - 161.1ms/batch - loss: 0.76760 - diff: 12.28mlTrain batch 32/32 - 169.8ms/batch - loss: 0.81927 - diff: 12.41mlTrain batch 32/32 - 17.0s 169.8ms/batch - loss: 0.81927 - diff: 12.41ml
Test 1.0s: val_loss: 0.93822 - diff: 14.10ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Systole_DenseNet121_0_Adam-0.001_MAE_DA3_best

Epoch 84: current best loss = 0.93822, at epoch 83
Train batch 1/32 - 127.5ms/batch - loss: 0.76682 - diff: 12.27mlTrain batch 2/32 - 112.4ms/batch - loss: 0.71680 - diff: 11.47mlTrain batch 3/32 - 152.3ms/batch - loss: 0.72516 - diff: 11.60mlTrain batch 4/32 - 108.9ms/batch - loss: 0.65438 - diff: 10.47mlTrain batch 5/32 - 146.0ms/batch - loss: 0.66268 - diff: 10.60mlTrain batch 6/32 - 109.4ms/batch - loss: 0.65224 - diff: 10.44mlTrain batch 7/32 - 177.7ms/batch - loss: 0.63128 - diff: 10.10mlTrain batch 8/32 - 197.2ms/batch - loss: 0.66061 - diff: 10.57mlTrain batch 9/32 - 161.6ms/batch - loss: 0.67891 - diff: 10.86mlTrain batch 10/32 - 156.7ms/batch - loss: 0.68757 - diff: 11.00mlTrain batch 11/32 - 154.6ms/batch - loss: 0.68993 - diff: 11.04mlTrain batch 12/32 - 149.8ms/batch - loss: 0.68446 - diff: 10.95mlTrain batch 13/32 - 171.0ms/batch - loss: 0.69260 - diff: 11.08mlTrain batch 14/32 - 174.4ms/batch - loss: 0.67715 - diff: 10.83mlTrain batch 15/32 - 165.6ms/batch - loss: 0.68497 - diff: 10.96mlTrain batch 16/32 - 130.3ms/batch - loss: 0.68881 - diff: 11.02mlTrain batch 17/32 - 108.2ms/batch - loss: 0.69359 - diff: 11.10mlTrain batch 18/32 - 136.6ms/batch - loss: 0.70284 - diff: 11.25mlTrain batch 19/32 - 143.4ms/batch - loss: 0.70382 - diff: 11.26mlTrain batch 20/32 - 182.8ms/batch - loss: 0.69130 - diff: 11.06mlTrain batch 21/32 - 186.9ms/batch - loss: 0.68922 - diff: 11.03mlTrain batch 22/32 - 163.6ms/batch - loss: 0.69452 - diff: 11.11mlTrain batch 23/32 - 151.6ms/batch - loss: 0.71931 - diff: 11.51mlTrain batch 24/32 - 175.6ms/batch - loss: 0.72267 - diff: 11.56mlTrain batch 25/32 - 185.1ms/batch - loss: 0.71636 - diff: 11.46mlTrain batch 26/32 - 205.1ms/batch - loss: 0.70755 - diff: 11.32mlTrain batch 27/32 - 107.0ms/batch - loss: 0.72313 - diff: 11.57mlTrain batch 28/32 - 167.6ms/batch - loss: 0.71895 - diff: 11.50mlTrain batch 29/32 - 160.7ms/batch - loss: 0.71358 - diff: 11.42mlTrain batch 30/32 - 155.1ms/batch - loss: 0.70841 - diff: 11.33mlTrain batch 31/32 - 131.5ms/batch - loss: 0.70526 - diff: 11.28mlTrain batch 32/32 - 144.1ms/batch - loss: 0.73610 - diff: 11.34mlTrain batch 32/32 - 16.3s 144.1ms/batch - loss: 0.73610 - diff: 11.34ml
Test 1.1s: val_loss: 1.04468 - diff: 16.24ml

Epoch 85: current best loss = 0.93822, at epoch 83
Train batch 1/32 - 198.2ms/batch - loss: 0.56279 - diff: 9.00mlTrain batch 2/32 - 190.0ms/batch - loss: 0.72311 - diff: 11.57mlTrain batch 3/32 - 188.5ms/batch - loss: 0.68675 - diff: 10.99mlTrain batch 4/32 - 153.6ms/batch - loss: 0.74386 - diff: 11.90mlTrain batch 5/32 - 158.5ms/batch - loss: 0.74731 - diff: 11.96mlTrain batch 6/32 - 173.8ms/batch - loss: 0.77739 - diff: 12.44mlTrain batch 7/32 - 130.9ms/batch - loss: 0.75690 - diff: 12.11mlTrain batch 8/32 - 107.8ms/batch - loss: 0.75316 - diff: 12.05mlTrain batch 9/32 - 122.3ms/batch - loss: 0.72142 - diff: 11.54mlTrain batch 10/32 - 103.8ms/batch - loss: 0.75444 - diff: 12.07mlTrain batch 11/32 - 142.9ms/batch - loss: 0.74180 - diff: 11.87mlTrain batch 12/32 - 108.1ms/batch - loss: 0.74981 - diff: 12.00mlTrain batch 13/32 - 189.2ms/batch - loss: 0.72840 - diff: 11.65mlTrain batch 14/32 - 184.5ms/batch - loss: 0.72328 - diff: 11.57mlTrain batch 15/32 - 178.5ms/batch - loss: 0.71739 - diff: 11.48mlTrain batch 16/32 - 169.7ms/batch - loss: 0.74243 - diff: 11.88mlTrain batch 17/32 - 197.7ms/batch - loss: 0.76425 - diff: 12.23mlTrain batch 18/32 - 164.8ms/batch - loss: 0.75301 - diff: 12.05mlTrain batch 19/32 - 184.7ms/batch - loss: 0.74018 - diff: 11.84mlTrain batch 20/32 - 122.5ms/batch - loss: 0.74182 - diff: 11.87mlTrain batch 21/32 - 136.8ms/batch - loss: 0.73697 - diff: 11.79mlTrain batch 22/32 - 102.9ms/batch - loss: 0.72670 - diff: 11.63mlTrain batch 23/32 - 186.8ms/batch - loss: 0.73635 - diff: 11.78mlTrain batch 24/32 - 167.8ms/batch - loss: 0.74105 - diff: 11.86mlTrain batch 25/32 - 162.5ms/batch - loss: 0.73246 - diff: 11.72mlTrain batch 26/32 - 176.6ms/batch - loss: 0.72921 - diff: 11.67mlTrain batch 27/32 - 184.2ms/batch - loss: 0.73774 - diff: 11.80mlTrain batch 28/32 - 147.9ms/batch - loss: 0.74064 - diff: 11.85mlTrain batch 29/32 - 182.2ms/batch - loss: 0.75177 - diff: 12.03mlTrain batch 30/32 - 187.3ms/batch - loss: 0.75505 - diff: 12.08mlTrain batch 31/32 - 185.6ms/batch - loss: 0.75422 - diff: 12.07mlTrain batch 32/32 - 135.6ms/batch - loss: 0.77430 - diff: 12.08mlTrain batch 32/32 - 15.7s 135.6ms/batch - loss: 0.77430 - diff: 12.08ml
Test 1.0s: val_loss: 1.00975 - diff: 15.55ml

Epoch 86: current best loss = 0.93822, at epoch 83
Train batch 1/32 - 197.3ms/batch - loss: 1.51838 - diff: 24.29mlTrain batch 2/32 - 172.1ms/batch - loss: 1.00563 - diff: 16.09mlTrain batch 3/32 - 197.5ms/batch - loss: 0.84656 - diff: 13.54mlTrain batch 4/32 - 174.8ms/batch - loss: 0.82929 - diff: 13.27mlTrain batch 5/32 - 200.5ms/batch - loss: 0.83032 - diff: 13.29mlTrain batch 6/32 - 198.9ms/batch - loss: 0.84281 - diff: 13.49mlTrain batch 7/32 - 176.1ms/batch - loss: 0.78889 - diff: 12.62mlTrain batch 8/32 - 164.2ms/batch - loss: 0.77928 - diff: 12.47mlTrain batch 9/32 - 159.0ms/batch - loss: 0.75220 - diff: 12.04mlTrain batch 10/32 - 118.7ms/batch - loss: 0.72339 - diff: 11.57mlTrain batch 11/32 - 146.8ms/batch - loss: 0.72423 - diff: 11.59mlTrain batch 12/32 - 192.9ms/batch - loss: 0.77687 - diff: 12.43mlTrain batch 13/32 - 147.5ms/batch - loss: 0.78482 - diff: 12.56mlTrain batch 14/32 - 123.4ms/batch - loss: 0.76846 - diff: 12.30mlTrain batch 15/32 - 172.8ms/batch - loss: 0.76533 - diff: 12.25mlTrain batch 16/32 - 169.4ms/batch - loss: 0.76252 - diff: 12.20mlTrain batch 17/32 - 157.0ms/batch - loss: 0.78914 - diff: 12.63mlTrain batch 18/32 - 106.2ms/batch - loss: 0.80302 - diff: 12.85mlTrain batch 19/32 - 145.9ms/batch - loss: 0.80778 - diff: 12.92mlTrain batch 20/32 - 229.7ms/batch - loss: 0.83952 - diff: 13.43mlTrain batch 21/32 - 137.3ms/batch - loss: 0.83549 - diff: 13.37mlTrain batch 22/32 - 148.1ms/batch - loss: 0.82363 - diff: 13.18mlTrain batch 23/32 - 166.9ms/batch - loss: 0.81477 - diff: 13.04mlTrain batch 24/32 - 163.4ms/batch - loss: 0.80909 - diff: 12.95mlTrain batch 25/32 - 134.1ms/batch - loss: 0.79792 - diff: 12.77mlTrain batch 26/32 - 111.1ms/batch - loss: 0.78507 - diff: 12.56mlTrain batch 27/32 - 133.1ms/batch - loss: 0.79019 - diff: 12.64mlTrain batch 28/32 - 159.5ms/batch - loss: 0.78794 - diff: 12.61mlTrain batch 29/32 - 158.5ms/batch - loss: 0.77695 - diff: 12.43mlTrain batch 30/32 - 167.2ms/batch - loss: 0.76792 - diff: 12.29mlTrain batch 31/32 - 165.1ms/batch - loss: 0.76697 - diff: 12.27mlTrain batch 32/32 - 180.1ms/batch - loss: 0.80816 - diff: 12.36mlTrain batch 32/32 - 16.7s 180.1ms/batch - loss: 0.80816 - diff: 12.36ml
Test 1.1s: val_loss: 0.99881 - diff: 14.97ml

Epoch 87: current best loss = 0.93822, at epoch 83
Train batch 1/32 - 195.4ms/batch - loss: 0.55215 - diff: 8.83mlTrain batch 2/32 - 172.8ms/batch - loss: 0.60963 - diff: 9.75mlTrain batch 3/32 - 174.5ms/batch - loss: 0.70022 - diff: 11.20mlTrain batch 4/32 - 244.0ms/batch - loss: 0.71863 - diff: 11.50mlTrain batch 5/32 - 146.3ms/batch - loss: 0.91171 - diff: 14.59mlTrain batch 6/32 - 188.6ms/batch - loss: 0.90779 - diff: 14.52mlTrain batch 7/32 - 168.6ms/batch - loss: 0.89193 - diff: 14.27mlTrain batch 8/32 - 188.8ms/batch - loss: 0.92925 - diff: 14.87mlTrain batch 9/32 - 165.0ms/batch - loss: 0.88780 - diff: 14.20mlTrain batch 10/32 - 180.9ms/batch - loss: 0.87919 - diff: 14.07mlTrain batch 11/32 - 160.9ms/batch - loss: 0.86233 - diff: 13.80mlTrain batch 12/32 - 133.0ms/batch - loss: 0.85997 - diff: 13.76mlTrain batch 13/32 - 151.1ms/batch - loss: 0.83912 - diff: 13.43mlTrain batch 14/32 - 115.9ms/batch - loss: 0.82599 - diff: 13.22mlTrain batch 15/32 - 173.1ms/batch - loss: 0.80255 - diff: 12.84mlTrain batch 16/32 - 179.5ms/batch - loss: 0.78507 - diff: 12.56mlTrain batch 17/32 - 162.2ms/batch - loss: 0.76238 - diff: 12.20mlTrain batch 18/32 - 179.1ms/batch - loss: 0.81013 - diff: 12.96mlTrain batch 19/32 - 159.9ms/batch - loss: 0.81123 - diff: 12.98mlTrain batch 20/32 - 205.9ms/batch - loss: 0.80242 - diff: 12.84mlTrain batch 21/32 - 173.5ms/batch - loss: 0.79173 - diff: 12.67mlTrain batch 22/32 - 184.1ms/batch - loss: 0.80541 - diff: 12.89mlTrain batch 23/32 - 175.0ms/batch - loss: 0.80065 - diff: 12.81mlTrain batch 24/32 - 126.7ms/batch - loss: 0.80422 - diff: 12.87mlTrain batch 25/32 - 205.5ms/batch - loss: 0.79093 - diff: 12.65mlTrain batch 26/32 - 119.4ms/batch - loss: 0.78394 - diff: 12.54mlTrain batch 27/32 - 145.8ms/batch - loss: 0.78569 - diff: 12.57mlTrain batch 28/32 - 117.3ms/batch - loss: 0.79033 - diff: 12.65mlTrain batch 29/32 - 145.5ms/batch - loss: 0.78930 - diff: 12.63mlTrain batch 30/32 - 127.3ms/batch - loss: 0.77928 - diff: 12.47mlTrain batch 31/32 - 127.0ms/batch - loss: 0.77663 - diff: 12.43mlTrain batch 32/32 - 107.8ms/batch - loss: 0.79066 - diff: 12.41mlTrain batch 32/32 - 17.2s 107.8ms/batch - loss: 0.79066 - diff: 12.41ml
Test 1.1s: val_loss: 0.93316 - diff: 14.44ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Systole_DenseNet121_0_Adam-0.001_MAE_DA3_best

Epoch 88: current best loss = 0.93316, at epoch 87
Train batch 1/32 - 202.0ms/batch - loss: 0.50026 - diff: 8.00mlTrain batch 2/32 - 175.7ms/batch - loss: 0.55663 - diff: 8.91mlTrain batch 3/32 - 190.4ms/batch - loss: 0.67505 - diff: 10.80mlTrain batch 4/32 - 170.2ms/batch - loss: 0.74688 - diff: 11.95mlTrain batch 5/32 - 136.9ms/batch - loss: 0.70889 - diff: 11.34mlTrain batch 6/32 - 159.3ms/batch - loss: 0.73887 - diff: 11.82mlTrain batch 7/32 - 178.0ms/batch - loss: 0.73685 - diff: 11.79mlTrain batch 8/32 - 154.3ms/batch - loss: 0.69884 - diff: 11.18mlTrain batch 9/32 - 170.3ms/batch - loss: 0.69229 - diff: 11.08mlTrain batch 10/32 - 176.9ms/batch - loss: 0.70099 - diff: 11.22mlTrain batch 11/32 - 180.6ms/batch - loss: 0.70568 - diff: 11.29mlTrain batch 12/32 - 183.0ms/batch - loss: 0.73426 - diff: 11.75mlTrain batch 13/32 - 181.5ms/batch - loss: 0.72337 - diff: 11.57mlTrain batch 14/32 - 184.3ms/batch - loss: 0.70277 - diff: 11.24mlTrain batch 15/32 - 179.0ms/batch - loss: 0.70167 - diff: 11.23mlTrain batch 16/32 - 157.6ms/batch - loss: 0.70111 - diff: 11.22mlTrain batch 17/32 - 195.3ms/batch - loss: 0.69174 - diff: 11.07mlTrain batch 18/32 - 202.1ms/batch - loss: 0.69455 - diff: 11.11mlTrain batch 19/32 - 163.4ms/batch - loss: 0.68922 - diff: 11.03mlTrain batch 20/32 - 180.0ms/batch - loss: 0.70445 - diff: 11.27mlTrain batch 21/32 - 166.4ms/batch - loss: 0.70669 - diff: 11.31mlTrain batch 22/32 - 111.9ms/batch - loss: 0.71094 - diff: 11.38mlTrain batch 23/32 - 134.8ms/batch - loss: 0.70324 - diff: 11.25mlTrain batch 24/32 - 140.1ms/batch - loss: 0.69883 - diff: 11.18mlTrain batch 25/32 - 167.5ms/batch - loss: 0.70522 - diff: 11.28mlTrain batch 26/32 - 163.3ms/batch - loss: 0.71933 - diff: 11.51mlTrain batch 27/32 - 148.6ms/batch - loss: 0.71795 - diff: 11.49mlTrain batch 28/32 - 179.5ms/batch - loss: 0.73367 - diff: 11.74mlTrain batch 29/32 - 172.9ms/batch - loss: 0.73600 - diff: 11.78mlTrain batch 30/32 - 138.7ms/batch - loss: 0.73788 - diff: 11.81mlTrain batch 31/32 - 165.2ms/batch - loss: 0.73240 - diff: 11.72mlTrain batch 32/32 - 179.4ms/batch - loss: 0.77225 - diff: 11.81mlTrain batch 32/32 - 17.5s 179.4ms/batch - loss: 0.77225 - diff: 11.81ml
Test 1.0s: val_loss: 0.98733 - diff: 15.15ml

Epoch 89: current best loss = 0.93316, at epoch 87
Train batch 1/32 - 205.5ms/batch - loss: 0.80376 - diff: 12.86mlTrain batch 2/32 - 164.9ms/batch - loss: 0.75707 - diff: 12.11mlTrain batch 3/32 - 132.0ms/batch - loss: 0.70073 - diff: 11.21mlTrain batch 4/32 - 116.4ms/batch - loss: 0.70805 - diff: 11.33mlTrain batch 5/32 - 164.9ms/batch - loss: 0.68597 - diff: 10.98mlTrain batch 6/32 - 140.9ms/batch - loss: 0.65062 - diff: 10.41mlTrain batch 7/32 - 151.6ms/batch - loss: 0.63397 - diff: 10.14mlTrain batch 8/32 - 109.8ms/batch - loss: 0.70605 - diff: 11.30mlTrain batch 9/32 - 142.4ms/batch - loss: 0.68800 - diff: 11.01mlTrain batch 10/32 - 141.7ms/batch - loss: 0.67109 - diff: 10.74mlTrain batch 11/32 - 164.3ms/batch - loss: 0.68167 - diff: 10.91mlTrain batch 12/32 - 113.9ms/batch - loss: 0.67981 - diff: 10.88mlTrain batch 13/32 - 140.6ms/batch - loss: 0.66757 - diff: 10.68mlTrain batch 14/32 - 111.2ms/batch - loss: 0.67253 - diff: 10.76mlTrain batch 15/32 - 151.2ms/batch - loss: 0.67109 - diff: 10.74mlTrain batch 16/32 - 163.8ms/batch - loss: 0.67467 - diff: 10.79mlTrain batch 17/32 - 130.8ms/batch - loss: 0.67817 - diff: 10.85mlTrain batch 18/32 - 111.4ms/batch - loss: 0.69964 - diff: 11.19mlTrain batch 19/32 - 129.6ms/batch - loss: 0.69447 - diff: 11.11mlTrain batch 20/32 - 106.9ms/batch - loss: 0.70062 - diff: 11.21mlTrain batch 21/32 - 141.5ms/batch - loss: 0.69468 - diff: 11.11mlTrain batch 22/32 - 111.8ms/batch - loss: 0.68927 - diff: 11.03mlTrain batch 23/32 - 157.8ms/batch - loss: 0.70086 - diff: 11.21mlTrain batch 24/32 - 172.8ms/batch - loss: 0.69565 - diff: 11.13mlTrain batch 25/32 - 137.7ms/batch - loss: 0.69017 - diff: 11.04mlTrain batch 26/32 - 149.1ms/batch - loss: 0.68994 - diff: 11.04mlTrain batch 27/32 - 172.5ms/batch - loss: 0.69334 - diff: 11.09mlTrain batch 28/32 - 168.5ms/batch - loss: 0.69556 - diff: 11.13mlTrain batch 29/32 - 138.7ms/batch - loss: 0.70007 - diff: 11.20mlTrain batch 30/32 - 167.0ms/batch - loss: 0.70682 - diff: 11.31mlTrain batch 31/32 - 139.4ms/batch - loss: 0.71040 - diff: 11.37mlTrain batch 32/32 - 114.4ms/batch - loss: 0.73009 - diff: 11.38mlTrain batch 32/32 - 17.3s 114.4ms/batch - loss: 0.73009 - diff: 11.38ml
Test 1.0s: val_loss: 1.00142 - diff: 15.54ml

Epoch 90: current best loss = 0.93316, at epoch 87
Train batch 1/32 - 229.7ms/batch - loss: 0.72619 - diff: 11.62mlTrain batch 2/32 - 190.9ms/batch - loss: 0.76100 - diff: 12.18mlTrain batch 3/32 - 169.5ms/batch - loss: 0.66320 - diff: 10.61mlTrain batch 4/32 - 170.5ms/batch - loss: 0.76258 - diff: 12.20mlTrain batch 5/32 - 159.5ms/batch - loss: 0.69477 - diff: 11.12mlTrain batch 6/32 - 171.2ms/batch - loss: 0.67610 - diff: 10.82mlTrain batch 7/32 - 158.0ms/batch - loss: 0.66791 - diff: 10.69mlTrain batch 8/32 - 181.5ms/batch - loss: 0.66248 - diff: 10.60mlTrain batch 9/32 - 142.2ms/batch - loss: 0.65135 - diff: 10.42mlTrain batch 10/32 - 178.0ms/batch - loss: 0.64469 - diff: 10.32mlTrain batch 11/32 - 165.5ms/batch - loss: 0.64096 - diff: 10.26mlTrain batch 12/32 - 180.4ms/batch - loss: 0.63838 - diff: 10.21mlTrain batch 13/32 - 175.3ms/batch - loss: 0.64618 - diff: 10.34mlTrain batch 14/32 - 160.3ms/batch - loss: 0.65703 - diff: 10.51mlTrain batch 15/32 - 166.9ms/batch - loss: 0.64506 - diff: 10.32mlTrain batch 16/32 - 172.4ms/batch - loss: 0.64029 - diff: 10.24mlTrain batch 17/32 - 181.2ms/batch - loss: 0.64973 - diff: 10.40mlTrain batch 18/32 - 132.4ms/batch - loss: 0.65600 - diff: 10.50mlTrain batch 19/32 - 128.1ms/batch - loss: 0.63865 - diff: 10.22mlTrain batch 20/32 - 149.9ms/batch - loss: 0.65055 - diff: 10.41mlTrain batch 21/32 - 157.9ms/batch - loss: 0.64069 - diff: 10.25mlTrain batch 22/32 - 171.7ms/batch - loss: 0.63267 - diff: 10.12mlTrain batch 23/32 - 164.8ms/batch - loss: 0.63618 - diff: 10.18mlTrain batch 24/32 - 181.8ms/batch - loss: 0.64445 - diff: 10.31mlTrain batch 25/32 - 136.9ms/batch - loss: 0.65479 - diff: 10.48mlTrain batch 26/32 - 155.5ms/batch - loss: 0.65796 - diff: 10.53mlTrain batch 27/32 - 155.0ms/batch - loss: 0.66451 - diff: 10.63mlTrain batch 28/32 - 150.7ms/batch - loss: 0.69727 - diff: 11.16mlTrain batch 29/32 - 199.2ms/batch - loss: 0.69815 - diff: 11.17mlTrain batch 30/32 - 206.8ms/batch - loss: 0.69978 - diff: 11.20mlTrain batch 31/32 - 132.0ms/batch - loss: 0.69523 - diff: 11.12mlTrain batch 32/32 - 146.3ms/batch - loss: 0.72672 - diff: 11.18mlTrain batch 32/32 - 17.5s 146.3ms/batch - loss: 0.72672 - diff: 11.18ml
Test 1.0s: val_loss: 1.07409 - diff: 16.81ml

Epoch 91: current best loss = 0.93316, at epoch 87
Train batch 1/32 - 123.8ms/batch - loss: 0.50361 - diff: 8.06mlTrain batch 2/32 - 136.4ms/batch - loss: 0.52075 - diff: 8.33mlTrain batch 3/32 - 176.5ms/batch - loss: 0.57843 - diff: 9.25mlTrain batch 4/32 - 128.3ms/batch - loss: 0.57484 - diff: 9.20mlTrain batch 5/32 - 144.9ms/batch - loss: 0.60338 - diff: 9.65mlTrain batch 6/32 - 107.5ms/batch - loss: 0.66053 - diff: 10.57mlTrain batch 7/32 - 184.7ms/batch - loss: 0.69605 - diff: 11.14mlTrain batch 8/32 - 191.6ms/batch - loss: 0.80963 - diff: 12.95mlTrain batch 9/32 - 158.5ms/batch - loss: 0.78034 - diff: 12.49mlTrain batch 10/32 - 170.2ms/batch - loss: 0.77281 - diff: 12.37mlTrain batch 11/32 - 180.2ms/batch - loss: 0.78234 - diff: 12.52mlTrain batch 12/32 - 110.5ms/batch - loss: 0.75253 - diff: 12.04mlTrain batch 13/32 - 163.5ms/batch - loss: 0.76636 - diff: 12.26mlTrain batch 14/32 - 128.7ms/batch - loss: 0.74310 - diff: 11.89mlTrain batch 15/32 - 177.3ms/batch - loss: 0.72990 - diff: 11.68mlTrain batch 16/32 - 153.5ms/batch - loss: 0.73114 - diff: 11.70mlTrain batch 17/32 - 166.0ms/batch - loss: 0.72278 - diff: 11.56mlTrain batch 18/32 - 147.6ms/batch - loss: 0.73268 - diff: 11.72mlTrain batch 19/32 - 151.1ms/batch - loss: 0.73818 - diff: 11.81mlTrain batch 20/32 - 169.8ms/batch - loss: 0.73918 - diff: 11.83mlTrain batch 21/32 - 147.9ms/batch - loss: 0.73887 - diff: 11.82mlTrain batch 22/32 - 183.3ms/batch - loss: 0.73334 - diff: 11.73mlTrain batch 23/32 - 174.4ms/batch - loss: 0.73231 - diff: 11.72mlTrain batch 24/32 - 183.0ms/batch - loss: 0.72772 - diff: 11.64mlTrain batch 25/32 - 184.8ms/batch - loss: 0.72249 - diff: 11.56mlTrain batch 26/32 - 170.2ms/batch - loss: 0.71575 - diff: 11.45mlTrain batch 27/32 - 156.0ms/batch - loss: 0.71821 - diff: 11.49mlTrain batch 28/32 - 188.8ms/batch - loss: 0.71826 - diff: 11.49mlTrain batch 29/32 - 193.1ms/batch - loss: 0.70726 - diff: 11.32mlTrain batch 30/32 - 132.3ms/batch - loss: 0.71792 - diff: 11.49mlTrain batch 31/32 - 117.1ms/batch - loss: 0.71204 - diff: 11.39mlTrain batch 32/32 - 132.3ms/batch - loss: 0.73275 - diff: 11.41mlTrain batch 32/32 - 16.0s 132.3ms/batch - loss: 0.73275 - diff: 11.41ml
Test 1.1s: val_loss: 1.21353 - diff: 18.80ml

Epoch 92: current best loss = 0.93316, at epoch 87
Train batch 1/32 - 159.9ms/batch - loss: 0.49809 - diff: 7.97mlTrain batch 2/32 - 134.9ms/batch - loss: 0.52982 - diff: 8.48mlTrain batch 3/32 - 168.9ms/batch - loss: 0.69741 - diff: 11.16mlTrain batch 4/32 - 162.7ms/batch - loss: 0.71770 - diff: 11.48mlTrain batch 5/32 - 180.8ms/batch - loss: 0.77951 - diff: 12.47mlTrain batch 6/32 - 188.2ms/batch - loss: 0.77949 - diff: 12.47mlTrain batch 7/32 - 164.2ms/batch - loss: 0.72806 - diff: 11.65mlTrain batch 8/32 - 196.2ms/batch - loss: 0.73283 - diff: 11.73mlTrain batch 9/32 - 130.8ms/batch - loss: 0.71027 - diff: 11.36mlTrain batch 10/32 - 124.1ms/batch - loss: 0.74548 - diff: 11.93mlTrain batch 11/32 - 170.8ms/batch - loss: 0.77189 - diff: 12.35mlTrain batch 12/32 - 161.0ms/batch - loss: 0.76786 - diff: 12.29mlTrain batch 13/32 - 167.1ms/batch - loss: 0.78354 - diff: 12.54mlTrain batch 14/32 - 176.8ms/batch - loss: 0.78984 - diff: 12.64mlTrain batch 15/32 - 152.7ms/batch - loss: 0.77234 - diff: 12.36mlTrain batch 16/32 - 160.5ms/batch - loss: 0.78740 - diff: 12.60mlTrain batch 17/32 - 139.7ms/batch - loss: 0.76663 - diff: 12.27mlTrain batch 18/32 - 136.1ms/batch - loss: 0.77680 - diff: 12.43mlTrain batch 19/32 - 166.0ms/batch - loss: 0.76423 - diff: 12.23mlTrain batch 20/32 - 186.2ms/batch - loss: 0.75943 - diff: 12.15mlTrain batch 21/32 - 181.3ms/batch - loss: 0.75986 - diff: 12.16mlTrain batch 22/32 - 197.7ms/batch - loss: 0.75633 - diff: 12.10mlTrain batch 23/32 - 175.3ms/batch - loss: 0.75296 - diff: 12.05mlTrain batch 24/32 - 202.6ms/batch - loss: 0.74536 - diff: 11.93mlTrain batch 25/32 - 186.3ms/batch - loss: 0.75196 - diff: 12.03mlTrain batch 26/32 - 174.0ms/batch - loss: 0.74387 - diff: 11.90mlTrain batch 27/32 - 133.8ms/batch - loss: 0.74681 - diff: 11.95mlTrain batch 28/32 - 132.4ms/batch - loss: 0.83520 - diff: 13.36mlTrain batch 29/32 - 148.8ms/batch - loss: 0.82285 - diff: 13.17mlTrain batch 30/32 - 169.2ms/batch - loss: 0.82450 - diff: 13.19mlTrain batch 31/32 - 165.3ms/batch - loss: 0.82221 - diff: 13.16mlTrain batch 32/32 - 206.2ms/batch - loss: 0.87251 - diff: 13.28mlTrain batch 32/32 - 16.6s 206.2ms/batch - loss: 0.87251 - diff: 13.28ml
Test 1.1s: val_loss: 1.00897 - diff: 15.50ml

Epoch 93: current best loss = 0.93316, at epoch 87
Train batch 1/32 - 176.8ms/batch - loss: 0.83886 - diff: 13.42mlTrain batch 2/32 - 111.3ms/batch - loss: 0.61504 - diff: 9.84mlTrain batch 3/32 - 143.8ms/batch - loss: 0.57652 - diff: 9.22mlTrain batch 4/32 - 114.2ms/batch - loss: 0.77925 - diff: 12.47mlTrain batch 5/32 - 167.0ms/batch - loss: 0.72468 - diff: 11.59mlTrain batch 6/32 - 157.3ms/batch - loss: 0.70276 - diff: 11.24mlTrain batch 7/32 - 194.7ms/batch - loss: 0.66584 - diff: 10.65mlTrain batch 8/32 - 187.9ms/batch - loss: 0.66196 - diff: 10.59mlTrain batch 9/32 - 152.2ms/batch - loss: 0.66293 - diff: 10.61mlTrain batch 10/32 - 195.9ms/batch - loss: 0.66820 - diff: 10.69mlTrain batch 11/32 - 170.1ms/batch - loss: 0.70141 - diff: 11.22mlTrain batch 12/32 - 166.0ms/batch - loss: 0.68506 - diff: 10.96mlTrain batch 13/32 - 156.8ms/batch - loss: 0.67805 - diff: 10.85mlTrain batch 14/32 - 169.1ms/batch - loss: 0.66530 - diff: 10.64mlTrain batch 15/32 - 179.4ms/batch - loss: 0.66516 - diff: 10.64mlTrain batch 16/32 - 148.3ms/batch - loss: 0.67324 - diff: 10.77mlTrain batch 17/32 - 167.6ms/batch - loss: 0.66711 - diff: 10.67mlTrain batch 18/32 - 160.8ms/batch - loss: 0.67007 - diff: 10.72mlTrain batch 19/32 - 136.3ms/batch - loss: 0.67428 - diff: 10.79mlTrain batch 20/32 - 196.5ms/batch - loss: 0.67029 - diff: 10.72mlTrain batch 21/32 - 209.0ms/batch - loss: 0.66140 - diff: 10.58mlTrain batch 22/32 - 124.8ms/batch - loss: 0.65000 - diff: 10.40mlTrain batch 23/32 - 159.3ms/batch - loss: 0.65257 - diff: 10.44mlTrain batch 24/32 - 148.3ms/batch - loss: 0.65907 - diff: 10.55mlTrain batch 25/32 - 170.5ms/batch - loss: 0.65029 - diff: 10.40mlTrain batch 26/32 - 159.8ms/batch - loss: 0.64789 - diff: 10.37mlTrain batch 27/32 - 159.3ms/batch - loss: 0.64249 - diff: 10.28mlTrain batch 28/32 - 131.5ms/batch - loss: 0.64832 - diff: 10.37mlTrain batch 29/32 - 155.3ms/batch - loss: 0.64514 - diff: 10.32mlTrain batch 30/32 - 146.5ms/batch - loss: 0.64017 - diff: 10.24mlTrain batch 31/32 - 129.2ms/batch - loss: 0.65332 - diff: 10.45mlTrain batch 32/32 - 136.4ms/batch - loss: 0.67533 - diff: 10.48mlTrain batch 32/32 - 16.1s 136.4ms/batch - loss: 0.67533 - diff: 10.48ml
Test 1.1s: val_loss: 1.02362 - diff: 15.76ml

Epoch 94: current best loss = 0.93316, at epoch 87
Train batch 1/32 - 175.3ms/batch - loss: 0.79713 - diff: 12.75mlTrain batch 2/32 - 164.9ms/batch - loss: 1.08590 - diff: 17.37mlTrain batch 3/32 - 144.4ms/batch - loss: 0.89274 - diff: 14.28mlTrain batch 4/32 - 175.8ms/batch - loss: 0.83907 - diff: 13.43mlTrain batch 5/32 - 161.2ms/batch - loss: 0.79088 - diff: 12.65mlTrain batch 6/32 - 135.9ms/batch - loss: 0.74067 - diff: 11.85mlTrain batch 7/32 - 164.9ms/batch - loss: 0.71866 - diff: 11.50mlTrain batch 8/32 - 112.8ms/batch - loss: 0.68800 - diff: 11.01mlTrain batch 9/32 - 158.8ms/batch - loss: 0.70970 - diff: 11.36mlTrain batch 10/32 - 177.2ms/batch - loss: 0.69289 - diff: 11.09mlTrain batch 11/32 - 126.3ms/batch - loss: 0.65862 - diff: 10.54mlTrain batch 12/32 - 133.0ms/batch - loss: 0.65461 - diff: 10.47mlTrain batch 13/32 - 172.2ms/batch - loss: 0.65557 - diff: 10.49mlTrain batch 14/32 - 167.0ms/batch - loss: 0.65277 - diff: 10.44mlTrain batch 15/32 - 140.7ms/batch - loss: 0.65416 - diff: 10.47mlTrain batch 16/32 - 162.4ms/batch - loss: 0.66435 - diff: 10.63mlTrain batch 17/32 - 204.6ms/batch - loss: 0.66361 - diff: 10.62mlTrain batch 18/32 - 176.7ms/batch - loss: 0.66450 - diff: 10.63mlTrain batch 19/32 - 149.9ms/batch - loss: 0.66613 - diff: 10.66mlTrain batch 20/32 - 168.4ms/batch - loss: 0.66668 - diff: 10.67mlTrain batch 21/32 - 140.4ms/batch - loss: 0.66466 - diff: 10.63mlTrain batch 22/32 - 139.8ms/batch - loss: 0.68258 - diff: 10.92mlTrain batch 23/32 - 161.3ms/batch - loss: 0.68424 - diff: 10.95mlTrain batch 24/32 - 194.7ms/batch - loss: 0.68472 - diff: 10.96mlTrain batch 25/32 - 139.7ms/batch - loss: 0.68591 - diff: 10.97mlTrain batch 26/32 - 158.5ms/batch - loss: 0.70197 - diff: 11.23mlTrain batch 27/32 - 137.7ms/batch - loss: 0.70026 - diff: 11.20mlTrain batch 28/32 - 168.5ms/batch - loss: 0.70020 - diff: 11.20mlTrain batch 29/32 - 150.9ms/batch - loss: 0.69045 - diff: 11.05mlTrain batch 30/32 - 161.4ms/batch - loss: 0.72239 - diff: 11.56mlTrain batch 31/32 - 146.2ms/batch - loss: 0.71346 - diff: 11.42mlTrain batch 32/32 - 164.0ms/batch - loss: 0.74219 - diff: 11.46mlTrain batch 32/32 - 18.4s 164.0ms/batch - loss: 0.74219 - diff: 11.46ml
Test 1.1s: val_loss: 0.97519 - diff: 14.85ml

Epoch 95: current best loss = 0.93316, at epoch 87
Train batch 1/32 - 189.4ms/batch - loss: 0.79400 - diff: 12.70mlTrain batch 2/32 - 153.0ms/batch - loss: 0.70048 - diff: 11.21mlTrain batch 3/32 - 192.2ms/batch - loss: 0.59726 - diff: 9.56mlTrain batch 4/32 - 109.4ms/batch - loss: 0.61312 - diff: 9.81mlTrain batch 5/32 - 153.9ms/batch - loss: 0.58235 - diff: 9.32mlTrain batch 6/32 - 127.7ms/batch - loss: 0.60895 - diff: 9.74mlTrain batch 7/32 - 187.9ms/batch - loss: 0.60311 - diff: 9.65mlTrain batch 8/32 - 153.1ms/batch - loss: 0.62541 - diff: 10.01mlTrain batch 9/32 - 165.8ms/batch - loss: 0.64862 - diff: 10.38mlTrain batch 10/32 - 180.1ms/batch - loss: 0.69085 - diff: 11.05mlTrain batch 11/32 - 173.9ms/batch - loss: 0.69707 - diff: 11.15mlTrain batch 12/32 - 183.8ms/batch - loss: 0.69314 - diff: 11.09mlTrain batch 13/32 - 174.4ms/batch - loss: 0.69741 - diff: 11.16mlTrain batch 14/32 - 170.6ms/batch - loss: 0.71240 - diff: 11.40mlTrain batch 15/32 - 125.9ms/batch - loss: 0.75848 - diff: 12.14mlTrain batch 16/32 - 137.8ms/batch - loss: 0.75447 - diff: 12.07mlTrain batch 17/32 - 148.7ms/batch - loss: 0.76136 - diff: 12.18mlTrain batch 18/32 - 148.6ms/batch - loss: 0.76174 - diff: 12.19mlTrain batch 19/32 - 151.4ms/batch - loss: 0.76635 - diff: 12.26mlTrain batch 20/32 - 147.2ms/batch - loss: 0.77437 - diff: 12.39mlTrain batch 21/32 - 176.8ms/batch - loss: 0.77679 - diff: 12.43mlTrain batch 22/32 - 172.3ms/batch - loss: 0.78850 - diff: 12.62mlTrain batch 23/32 - 175.2ms/batch - loss: 0.80217 - diff: 12.83mlTrain batch 24/32 - 197.9ms/batch - loss: 0.79176 - diff: 12.67mlTrain batch 25/32 - 121.7ms/batch - loss: 0.79617 - diff: 12.74mlTrain batch 26/32 - 128.5ms/batch - loss: 0.79037 - diff: 12.65mlTrain batch 27/32 - 154.4ms/batch - loss: 0.79503 - diff: 12.72mlTrain batch 28/32 - 158.9ms/batch - loss: 0.78757 - diff: 12.60mlTrain batch 29/32 - 185.4ms/batch - loss: 0.77315 - diff: 12.37mlTrain batch 30/32 - 173.4ms/batch - loss: 0.76784 - diff: 12.29mlTrain batch 31/32 - 163.3ms/batch - loss: 0.77742 - diff: 12.44mlTrain batch 32/32 - 168.8ms/batch - loss: 0.80120 - diff: 12.46mlTrain batch 32/32 - 17.5s 168.8ms/batch - loss: 0.80120 - diff: 12.46ml
Test 1.0s: val_loss: 1.21221 - diff: 18.12ml

Epoch 96: current best loss = 0.93316, at epoch 87
Train batch 1/32 - 179.4ms/batch - loss: 0.45747 - diff: 7.32mlTrain batch 2/32 - 165.5ms/batch - loss: 0.59112 - diff: 9.46mlTrain batch 3/32 - 145.5ms/batch - loss: 0.75176 - diff: 12.03mlTrain batch 4/32 - 109.9ms/batch - loss: 0.75725 - diff: 12.12mlTrain batch 5/32 - 143.5ms/batch - loss: 0.79084 - diff: 12.65mlTrain batch 6/32 - 152.3ms/batch - loss: 0.79208 - diff: 12.67mlTrain batch 7/32 - 157.1ms/batch - loss: 0.77310 - diff: 12.37mlTrain batch 8/32 - 169.7ms/batch - loss: 0.74057 - diff: 11.85mlTrain batch 9/32 - 182.8ms/batch - loss: 0.74787 - diff: 11.97mlTrain batch 10/32 - 164.0ms/batch - loss: 0.80454 - diff: 12.87mlTrain batch 11/32 - 177.6ms/batch - loss: 0.76746 - diff: 12.28mlTrain batch 12/32 - 190.3ms/batch - loss: 0.74764 - diff: 11.96mlTrain batch 13/32 - 169.9ms/batch - loss: 0.74225 - diff: 11.88mlTrain batch 14/32 - 175.8ms/batch - loss: 0.74833 - diff: 11.97mlTrain batch 15/32 - 180.3ms/batch - loss: 0.74323 - diff: 11.89mlTrain batch 16/32 - 181.1ms/batch - loss: 0.75891 - diff: 12.14mlTrain batch 17/32 - 166.2ms/batch - loss: 0.75955 - diff: 12.15mlTrain batch 18/32 - 170.1ms/batch - loss: 0.77562 - diff: 12.41mlTrain batch 19/32 - 135.8ms/batch - loss: 0.76266 - diff: 12.20mlTrain batch 20/32 - 130.9ms/batch - loss: 0.78677 - diff: 12.59mlTrain batch 21/32 - 184.8ms/batch - loss: 0.77766 - diff: 12.44mlTrain batch 22/32 - 139.6ms/batch - loss: 0.77758 - diff: 12.44mlTrain batch 23/32 - 142.8ms/batch - loss: 0.76710 - diff: 12.27mlTrain batch 24/32 - 136.4ms/batch - loss: 0.76275 - diff: 12.20mlTrain batch 25/32 - 189.7ms/batch - loss: 0.76004 - diff: 12.16mlTrain batch 26/32 - 109.6ms/batch - loss: 0.75747 - diff: 12.12mlTrain batch 27/32 - 170.7ms/batch - loss: 0.76138 - diff: 12.18mlTrain batch 28/32 - 179.0ms/batch - loss: 0.75609 - diff: 12.10mlTrain batch 29/32 - 145.1ms/batch - loss: 0.77012 - diff: 12.32mlTrain batch 30/32 - 139.4ms/batch - loss: 0.75907 - diff: 12.15mlTrain batch 31/32 - 165.9ms/batch - loss: 0.75001 - diff: 12.00mlTrain batch 32/32 - 165.8ms/batch - loss: 0.75836 - diff: 11.96mlTrain batch 32/32 - 17.2s 165.8ms/batch - loss: 0.75836 - diff: 11.96ml
Test 1.0s: val_loss: 1.03896 - diff: 15.88ml

Epoch 97: current best loss = 0.93316, at epoch 87
Train batch 1/32 - 151.4ms/batch - loss: 0.60793 - diff: 9.73mlTrain batch 2/32 - 130.1ms/batch - loss: 0.56798 - diff: 9.09mlTrain batch 3/32 - 175.8ms/batch - loss: 0.62308 - diff: 9.97mlTrain batch 4/32 - 193.1ms/batch - loss: 0.58007 - diff: 9.28mlTrain batch 5/32 - 175.3ms/batch - loss: 0.53402 - diff: 8.54mlTrain batch 6/32 - 214.9ms/batch - loss: 0.54288 - diff: 8.69mlTrain batch 7/32 - 185.7ms/batch - loss: 0.55779 - diff: 8.92mlTrain batch 8/32 - 183.2ms/batch - loss: 0.58897 - diff: 9.42mlTrain batch 9/32 - 152.8ms/batch - loss: 0.59599 - diff: 9.54mlTrain batch 10/32 - 127.6ms/batch - loss: 0.65066 - diff: 10.41mlTrain batch 11/32 - 168.5ms/batch - loss: 0.66763 - diff: 10.68mlTrain batch 12/32 - 180.1ms/batch - loss: 0.66291 - diff: 10.61mlTrain batch 13/32 - 121.8ms/batch - loss: 0.71130 - diff: 11.38mlTrain batch 14/32 - 167.0ms/batch - loss: 0.69412 - diff: 11.11mlTrain batch 15/32 - 103.6ms/batch - loss: 0.67486 - diff: 10.80mlTrain batch 16/32 - 215.3ms/batch - loss: 0.66975 - diff: 10.72mlTrain batch 17/32 - 160.7ms/batch - loss: 0.65527 - diff: 10.48mlTrain batch 18/32 - 180.6ms/batch - loss: 0.67030 - diff: 10.72mlTrain batch 19/32 - 172.1ms/batch - loss: 0.68606 - diff: 10.98mlTrain batch 20/32 - 204.5ms/batch - loss: 0.67636 - diff: 10.82mlTrain batch 21/32 - 203.9ms/batch - loss: 0.67876 - diff: 10.86mlTrain batch 22/32 - 185.3ms/batch - loss: 0.67231 - diff: 10.76mlTrain batch 23/32 - 195.0ms/batch - loss: 0.68723 - diff: 11.00mlTrain batch 24/32 - 139.7ms/batch - loss: 0.68488 - diff: 10.96mlTrain batch 25/32 - 177.0ms/batch - loss: 0.73959 - diff: 11.83mlTrain batch 26/32 - 163.6ms/batch - loss: 0.75135 - diff: 12.02mlTrain batch 27/32 - 149.7ms/batch - loss: 0.74443 - diff: 11.91mlTrain batch 28/32 - 183.6ms/batch - loss: 0.73605 - diff: 11.78mlTrain batch 29/32 - 161.5ms/batch - loss: 0.73330 - diff: 11.73mlTrain batch 30/32 - 143.2ms/batch - loss: 0.73253 - diff: 11.72mlTrain batch 31/32 - 173.1ms/batch - loss: 0.75262 - diff: 12.04mlTrain batch 32/32 - 114.7ms/batch - loss: 0.76688 - diff: 12.03mlTrain batch 32/32 - 18.0s 114.7ms/batch - loss: 0.76688 - diff: 12.03ml
Test 1.1s: val_loss: 0.96790 - diff: 14.86ml

Epoch 98: current best loss = 0.93316, at epoch 87
Train batch 1/32 - 158.1ms/batch - loss: 0.57506 - diff: 9.20mlTrain batch 2/32 - 156.6ms/batch - loss: 0.66516 - diff: 10.64mlTrain batch 3/32 - 168.7ms/batch - loss: 0.63222 - diff: 10.12mlTrain batch 4/32 - 140.7ms/batch - loss: 0.64526 - diff: 10.32mlTrain batch 5/32 - 149.0ms/batch - loss: 0.65436 - diff: 10.47mlTrain batch 6/32 - 181.4ms/batch - loss: 0.69679 - diff: 11.15mlTrain batch 7/32 - 152.9ms/batch - loss: 0.68040 - diff: 10.89mlTrain batch 8/32 - 145.7ms/batch - loss: 0.72466 - diff: 11.59mlTrain batch 9/32 - 124.0ms/batch - loss: 0.70611 - diff: 11.30mlTrain batch 10/32 - 132.5ms/batch - loss: 0.67745 - diff: 10.84mlTrain batch 11/32 - 139.9ms/batch - loss: 0.67639 - diff: 10.82mlTrain batch 12/32 - 189.6ms/batch - loss: 0.70930 - diff: 11.35mlTrain batch 13/32 - 145.7ms/batch - loss: 0.71271 - diff: 11.40mlTrain batch 14/32 - 179.2ms/batch - loss: 0.69399 - diff: 11.10mlTrain batch 15/32 - 124.9ms/batch - loss: 0.68976 - diff: 11.04mlTrain batch 16/32 - 139.7ms/batch - loss: 0.68539 - diff: 10.97mlTrain batch 17/32 - 174.1ms/batch - loss: 0.69381 - diff: 11.10mlTrain batch 18/32 - 186.9ms/batch - loss: 0.68975 - diff: 11.04mlTrain batch 19/32 - 165.0ms/batch - loss: 0.69244 - diff: 11.08mlTrain batch 20/32 - 180.5ms/batch - loss: 0.68118 - diff: 10.90mlTrain batch 21/32 - 111.8ms/batch - loss: 0.67381 - diff: 10.78mlTrain batch 22/32 - 110.4ms/batch - loss: 0.67508 - diff: 10.80mlTrain batch 23/32 - 165.4ms/batch - loss: 0.67820 - diff: 10.85mlTrain batch 24/32 - 166.0ms/batch - loss: 0.67372 - diff: 10.78mlTrain batch 25/32 - 174.4ms/batch - loss: 0.67661 - diff: 10.83mlTrain batch 26/32 - 188.2ms/batch - loss: 0.66877 - diff: 10.70mlTrain batch 27/32 - 173.9ms/batch - loss: 0.67403 - diff: 10.78mlTrain batch 28/32 - 145.2ms/batch - loss: 0.67915 - diff: 10.87mlTrain batch 29/32 - 140.1ms/batch - loss: 0.68779 - diff: 11.00mlTrain batch 30/32 - 112.8ms/batch - loss: 0.68579 - diff: 10.97mlTrain batch 31/32 - 181.6ms/batch - loss: 0.67755 - diff: 10.84mlTrain batch 32/32 - 168.1ms/batch - loss: 0.70776 - diff: 10.90mlTrain batch 32/32 - 16.5s 168.1ms/batch - loss: 0.70776 - diff: 10.90ml
Test 1.0s: val_loss: 1.05017 - diff: 16.16ml
Epoch    99: reducing learning rate of group 0 to 1.2500e-04.

Epoch 99: current best loss = 0.93316, at epoch 87
Train batch 1/32 - 221.4ms/batch - loss: 0.75956 - diff: 12.15mlTrain batch 2/32 - 162.1ms/batch - loss: 0.62576 - diff: 10.01mlTrain batch 3/32 - 144.0ms/batch - loss: 0.58070 - diff: 9.29mlTrain batch 4/32 - 164.5ms/batch - loss: 0.57705 - diff: 9.23mlTrain batch 5/32 - 182.8ms/batch - loss: 0.66833 - diff: 10.69mlTrain batch 6/32 - 123.9ms/batch - loss: 0.68595 - diff: 10.98mlTrain batch 7/32 - 146.9ms/batch - loss: 0.83654 - diff: 13.38mlTrain batch 8/32 - 130.3ms/batch - loss: 0.81171 - diff: 12.99mlTrain batch 9/32 - 158.1ms/batch - loss: 0.84229 - diff: 13.48mlTrain batch 10/32 - 144.0ms/batch - loss: 0.80834 - diff: 12.93mlTrain batch 11/32 - 179.7ms/batch - loss: 0.78948 - diff: 12.63mlTrain batch 12/32 - 155.5ms/batch - loss: 0.79375 - diff: 12.70mlTrain batch 13/32 - 173.7ms/batch - loss: 0.77006 - diff: 12.32mlTrain batch 14/32 - 179.8ms/batch - loss: 0.75673 - diff: 12.11mlTrain batch 15/32 - 207.9ms/batch - loss: 0.75324 - diff: 12.05mlTrain batch 16/32 - 164.6ms/batch - loss: 0.74262 - diff: 11.88mlTrain batch 17/32 - 195.9ms/batch - loss: 0.73189 - diff: 11.71mlTrain batch 18/32 - 178.0ms/batch - loss: 0.71785 - diff: 11.49mlTrain batch 19/32 - 151.5ms/batch - loss: 0.71324 - diff: 11.41mlTrain batch 20/32 - 158.4ms/batch - loss: 0.70911 - diff: 11.35mlTrain batch 21/32 - 139.9ms/batch - loss: 0.70779 - diff: 11.32mlTrain batch 22/32 - 158.2ms/batch - loss: 0.69964 - diff: 11.19mlTrain batch 23/32 - 146.4ms/batch - loss: 0.71427 - diff: 11.43mlTrain batch 24/32 - 147.5ms/batch - loss: 0.70368 - diff: 11.26mlTrain batch 25/32 - 159.1ms/batch - loss: 0.69338 - diff: 11.09mlTrain batch 26/32 - 167.1ms/batch - loss: 0.68038 - diff: 10.89mlTrain batch 27/32 - 104.4ms/batch - loss: 0.67536 - diff: 10.81mlTrain batch 28/32 - 134.4ms/batch - loss: 0.67125 - diff: 10.74mlTrain batch 29/32 - 103.5ms/batch - loss: 0.67226 - diff: 10.76mlTrain batch 30/32 - 171.3ms/batch - loss: 0.66028 - diff: 10.56mlTrain batch 31/32 - 164.5ms/batch - loss: 0.66646 - diff: 10.66mlTrain batch 32/32 - 157.6ms/batch - loss: 0.75466 - diff: 10.95mlTrain batch 32/32 - 16.0s 157.6ms/batch - loss: 0.75466 - diff: 10.95ml
Test 1.1s: val_loss: 1.06877 - diff: 16.19ml

Epoch 100: current best loss = 0.93316, at epoch 87
Train batch 1/32 - 191.0ms/batch - loss: 0.46693 - diff: 7.47mlTrain batch 2/32 - 204.3ms/batch - loss: 0.56792 - diff: 9.09mlTrain batch 3/32 - 138.2ms/batch - loss: 0.58018 - diff: 9.28mlTrain batch 4/32 - 175.7ms/batch - loss: 0.59889 - diff: 9.58mlTrain batch 5/32 - 170.8ms/batch - loss: 0.58238 - diff: 9.32mlTrain batch 6/32 - 148.7ms/batch - loss: 0.56176 - diff: 8.99mlTrain batch 7/32 - 178.9ms/batch - loss: 0.61714 - diff: 9.87mlTrain batch 8/32 - 137.4ms/batch - loss: 0.65817 - diff: 10.53mlTrain batch 9/32 - 150.9ms/batch - loss: 0.64895 - diff: 10.38mlTrain batch 10/32 - 159.2ms/batch - loss: 0.63530 - diff: 10.16mlTrain batch 11/32 - 163.4ms/batch - loss: 0.64156 - diff: 10.26mlTrain batch 12/32 - 155.8ms/batch - loss: 0.65744 - diff: 10.52mlTrain batch 13/32 - 156.8ms/batch - loss: 0.65666 - diff: 10.51mlTrain batch 14/32 - 157.2ms/batch - loss: 0.65968 - diff: 10.55mlTrain batch 15/32 - 171.8ms/batch - loss: 0.65690 - diff: 10.51mlTrain batch 16/32 - 147.0ms/batch - loss: 0.67029 - diff: 10.72mlTrain batch 17/32 - 180.1ms/batch - loss: 0.65373 - diff: 10.46mlTrain batch 18/32 - 161.5ms/batch - loss: 0.65386 - diff: 10.46mlTrain batch 19/32 - 201.5ms/batch - loss: 0.64259 - diff: 10.28mlTrain batch 20/32 - 147.0ms/batch - loss: 0.64530 - diff: 10.32mlTrain batch 21/32 - 161.5ms/batch - loss: 0.63782 - diff: 10.21mlTrain batch 22/32 - 158.3ms/batch - loss: 0.63358 - diff: 10.14mlTrain batch 23/32 - 214.1ms/batch - loss: 0.62803 - diff: 10.05mlTrain batch 24/32 - 158.1ms/batch - loss: 0.62946 - diff: 10.07mlTrain batch 25/32 - 180.8ms/batch - loss: 0.62982 - diff: 10.08mlTrain batch 26/32 - 146.3ms/batch - loss: 0.62736 - diff: 10.04mlTrain batch 27/32 - 137.2ms/batch - loss: 0.62580 - diff: 10.01mlTrain batch 28/32 - 163.8ms/batch - loss: 0.62023 - diff: 9.92mlTrain batch 29/32 - 183.3ms/batch - loss: 0.61412 - diff: 9.83mlTrain batch 30/32 - 201.4ms/batch - loss: 0.61694 - diff: 9.87mlTrain batch 31/32 - 163.5ms/batch - loss: 0.61533 - diff: 9.85mlTrain batch 32/32 - 137.3ms/batch - loss: 0.64960 - diff: 9.92mlTrain batch 32/32 - 17.3s 137.3ms/batch - loss: 0.64960 - diff: 9.92ml
Test 1.1s: val_loss: 0.92974 - diff: 14.16ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Systole_DenseNet121_0_Adam-0.001_MAE_DA3_best

Epoch 101: current best loss = 0.92974, at epoch 100
Train batch 1/32 - 190.7ms/batch - loss: 0.28349 - diff: 4.54mlTrain batch 2/32 - 133.2ms/batch - loss: 0.40432 - diff: 6.47mlTrain batch 3/32 - 148.5ms/batch - loss: 0.50191 - diff: 8.03mlTrain batch 4/32 - 176.5ms/batch - loss: 0.46599 - diff: 7.46mlTrain batch 5/32 - 167.7ms/batch - loss: 0.46756 - diff: 7.48mlTrain batch 6/32 - 142.9ms/batch - loss: 0.49277 - diff: 7.88mlTrain batch 7/32 - 172.7ms/batch - loss: 0.47950 - diff: 7.67mlTrain batch 8/32 - 181.2ms/batch - loss: 0.52579 - diff: 8.41mlTrain batch 9/32 - 181.7ms/batch - loss: 0.50576 - diff: 8.09mlTrain batch 10/32 - 164.0ms/batch - loss: 0.51112 - diff: 8.18mlTrain batch 11/32 - 115.5ms/batch - loss: 0.50176 - diff: 8.03mlTrain batch 12/32 - 140.5ms/batch - loss: 0.52548 - diff: 8.41mlTrain batch 13/32 - 143.8ms/batch - loss: 0.53587 - diff: 8.57mlTrain batch 14/32 - 171.7ms/batch - loss: 0.53668 - diff: 8.59mlTrain batch 15/32 - 156.7ms/batch - loss: 0.53042 - diff: 8.49mlTrain batch 16/32 - 127.2ms/batch - loss: 0.54460 - diff: 8.71mlTrain batch 17/32 - 109.9ms/batch - loss: 0.56481 - diff: 9.04mlTrain batch 18/32 - 108.0ms/batch - loss: 0.55755 - diff: 8.92mlTrain batch 19/32 - 132.0ms/batch - loss: 0.54946 - diff: 8.79mlTrain batch 20/32 - 139.9ms/batch - loss: 0.54650 - diff: 8.74mlTrain batch 21/32 - 158.6ms/batch - loss: 0.53473 - diff: 8.56mlTrain batch 22/32 - 146.1ms/batch - loss: 0.52293 - diff: 8.37mlTrain batch 23/32 - 159.8ms/batch - loss: 0.52662 - diff: 8.43mlTrain batch 24/32 - 214.6ms/batch - loss: 0.54025 - diff: 8.64mlTrain batch 25/32 - 151.4ms/batch - loss: 0.55334 - diff: 8.85mlTrain batch 26/32 - 198.4ms/batch - loss: 0.54604 - diff: 8.74mlTrain batch 27/32 - 172.2ms/batch - loss: 0.54011 - diff: 8.64mlTrain batch 28/32 - 196.8ms/batch - loss: 0.54899 - diff: 8.78mlTrain batch 29/32 - 149.4ms/batch - loss: 0.54756 - diff: 8.76mlTrain batch 30/32 - 181.1ms/batch - loss: 0.54005 - diff: 8.64mlTrain batch 31/32 - 139.2ms/batch - loss: 0.54259 - diff: 8.68mlTrain batch 32/32 - 117.4ms/batch - loss: 0.54773 - diff: 8.65mlTrain batch 32/32 - 16.9s 117.4ms/batch - loss: 0.54773 - diff: 8.65ml
Test 1.0s: val_loss: 0.98792 - diff: 15.07ml

Epoch 102: current best loss = 0.92974, at epoch 100
Train batch 1/32 - 127.2ms/batch - loss: 0.69364 - diff: 11.10mlTrain batch 2/32 - 110.0ms/batch - loss: 0.73673 - diff: 11.79mlTrain batch 3/32 - 177.9ms/batch - loss: 0.65259 - diff: 10.44mlTrain batch 4/32 - 124.5ms/batch - loss: 0.59159 - diff: 9.47mlTrain batch 5/32 - 109.7ms/batch - loss: 0.57816 - diff: 9.25mlTrain batch 6/32 - 122.8ms/batch - loss: 0.53825 - diff: 8.61mlTrain batch 7/32 - 110.9ms/batch - loss: 0.57862 - diff: 9.26mlTrain batch 8/32 - 126.1ms/batch - loss: 0.68056 - diff: 10.89mlTrain batch 9/32 - 127.9ms/batch - loss: 0.66459 - diff: 10.63mlTrain batch 10/32 - 113.0ms/batch - loss: 0.64283 - diff: 10.29mlTrain batch 11/32 - 126.9ms/batch - loss: 0.69704 - diff: 11.15mlTrain batch 12/32 - 147.3ms/batch - loss: 0.68473 - diff: 10.96mlTrain batch 13/32 - 159.7ms/batch - loss: 0.66170 - diff: 10.59mlTrain batch 14/32 - 157.1ms/batch - loss: 0.66388 - diff: 10.62mlTrain batch 15/32 - 149.8ms/batch - loss: 0.67798 - diff: 10.85mlTrain batch 16/32 - 160.3ms/batch - loss: 0.68374 - diff: 10.94mlTrain batch 17/32 - 141.9ms/batch - loss: 0.66563 - diff: 10.65mlTrain batch 18/32 - 139.5ms/batch - loss: 0.65865 - diff: 10.54mlTrain batch 19/32 - 150.3ms/batch - loss: 0.67613 - diff: 10.82mlTrain batch 20/32 - 189.0ms/batch - loss: 0.66733 - diff: 10.68mlTrain batch 21/32 - 142.5ms/batch - loss: 0.67391 - diff: 10.78mlTrain batch 22/32 - 159.9ms/batch - loss: 0.67528 - diff: 10.80mlTrain batch 23/32 - 195.7ms/batch - loss: 0.67130 - diff: 10.74mlTrain batch 24/32 - 189.7ms/batch - loss: 0.65677 - diff: 10.51mlTrain batch 25/32 - 167.0ms/batch - loss: 0.65891 - diff: 10.54mlTrain batch 26/32 - 184.0ms/batch - loss: 0.66007 - diff: 10.56mlTrain batch 27/32 - 171.4ms/batch - loss: 0.64999 - diff: 10.40mlTrain batch 28/32 - 177.2ms/batch - loss: 0.63751 - diff: 10.20mlTrain batch 29/32 - 192.2ms/batch - loss: 0.63801 - diff: 10.21mlTrain batch 30/32 - 163.3ms/batch - loss: 0.63425 - diff: 10.15mlTrain batch 31/32 - 144.4ms/batch - loss: 0.62472 - diff: 10.00mlTrain batch 32/32 - 157.9ms/batch - loss: 0.62487 - diff: 9.94mlTrain batch 32/32 - 16.9s 157.9ms/batch - loss: 0.62487 - diff: 9.94ml
Test 1.0s: val_loss: 0.94080 - diff: 14.38ml

Epoch 103: current best loss = 0.92974, at epoch 100
Train batch 1/32 - 208.2ms/batch - loss: 0.62220 - diff: 9.96mlTrain batch 2/32 - 106.3ms/batch - loss: 0.48429 - diff: 7.75mlTrain batch 3/32 - 135.1ms/batch - loss: 0.47113 - diff: 7.54mlTrain batch 4/32 - 210.1ms/batch - loss: 0.44158 - diff: 7.07mlTrain batch 5/32 - 179.3ms/batch - loss: 0.47016 - diff: 7.52mlTrain batch 6/32 - 163.8ms/batch - loss: 0.49636 - diff: 7.94mlTrain batch 7/32 - 120.9ms/batch - loss: 0.48879 - diff: 7.82mlTrain batch 8/32 - 128.5ms/batch - loss: 0.50267 - diff: 8.04mlTrain batch 9/32 - 177.7ms/batch - loss: 0.49488 - diff: 7.92mlTrain batch 10/32 - 169.3ms/batch - loss: 0.50049 - diff: 8.01mlTrain batch 11/32 - 171.7ms/batch - loss: 0.49711 - diff: 7.95mlTrain batch 12/32 - 177.6ms/batch - loss: 0.48436 - diff: 7.75mlTrain batch 13/32 - 173.8ms/batch - loss: 0.47995 - diff: 7.68mlTrain batch 14/32 - 133.3ms/batch - loss: 0.52521 - diff: 8.40mlTrain batch 15/32 - 164.2ms/batch - loss: 0.52697 - diff: 8.43mlTrain batch 16/32 - 128.0ms/batch - loss: 0.56870 - diff: 9.10mlTrain batch 17/32 - 172.1ms/batch - loss: 0.56430 - diff: 9.03mlTrain batch 18/32 - 119.7ms/batch - loss: 0.55480 - diff: 8.88mlTrain batch 19/32 - 157.7ms/batch - loss: 0.55178 - diff: 8.83mlTrain batch 20/32 - 144.0ms/batch - loss: 0.54763 - diff: 8.76mlTrain batch 21/32 - 113.3ms/batch - loss: 0.53982 - diff: 8.64mlTrain batch 22/32 - 135.7ms/batch - loss: 0.53339 - diff: 8.53mlTrain batch 23/32 - 170.1ms/batch - loss: 0.56589 - diff: 9.05mlTrain batch 24/32 - 180.2ms/batch - loss: 0.56565 - diff: 9.05mlTrain batch 25/32 - 117.4ms/batch - loss: 0.56340 - diff: 9.01mlTrain batch 26/32 - 116.4ms/batch - loss: 0.55768 - diff: 8.92mlTrain batch 27/32 - 162.8ms/batch - loss: 0.55007 - diff: 8.80mlTrain batch 28/32 - 142.7ms/batch - loss: 0.58215 - diff: 9.31mlTrain batch 29/32 - 124.5ms/batch - loss: 0.58105 - diff: 9.30mlTrain batch 30/32 - 108.5ms/batch - loss: 0.57660 - diff: 9.23mlTrain batch 31/32 - 116.3ms/batch - loss: 0.57069 - diff: 9.13mlTrain batch 32/32 - 106.6ms/batch - loss: 0.58508 - diff: 9.13mlTrain batch 32/32 - 17.0s 106.6ms/batch - loss: 0.58508 - diff: 9.13ml
Test 1.0s: val_loss: 1.03970 - diff: 15.78ml

Epoch 104: current best loss = 0.92974, at epoch 100
Train batch 1/32 - 153.0ms/batch - loss: 0.51379 - diff: 8.22mlTrain batch 2/32 - 147.1ms/batch - loss: 0.47277 - diff: 7.56mlTrain batch 3/32 - 193.6ms/batch - loss: 0.49437 - diff: 7.91mlTrain batch 4/32 - 169.1ms/batch - loss: 0.53796 - diff: 8.61mlTrain batch 5/32 - 183.7ms/batch - loss: 0.52979 - diff: 8.48mlTrain batch 6/32 - 162.1ms/batch - loss: 0.55396 - diff: 8.86mlTrain batch 7/32 - 171.8ms/batch - loss: 0.57099 - diff: 9.14mlTrain batch 8/32 - 173.6ms/batch - loss: 0.56471 - diff: 9.04mlTrain batch 9/32 - 157.7ms/batch - loss: 0.59613 - diff: 9.54mlTrain batch 10/32 - 161.8ms/batch - loss: 0.60667 - diff: 9.71mlTrain batch 11/32 - 194.2ms/batch - loss: 0.58958 - diff: 9.43mlTrain batch 12/32 - 209.3ms/batch - loss: 0.58839 - diff: 9.41mlTrain batch 13/32 - 139.9ms/batch - loss: 0.60320 - diff: 9.65mlTrain batch 14/32 - 170.4ms/batch - loss: 0.61611 - diff: 9.86mlTrain batch 15/32 - 133.6ms/batch - loss: 0.60584 - diff: 9.69mlTrain batch 16/32 - 162.3ms/batch - loss: 0.60425 - diff: 9.67mlTrain batch 17/32 - 167.8ms/batch - loss: 0.60374 - diff: 9.66mlTrain batch 18/32 - 184.5ms/batch - loss: 0.60084 - diff: 9.61mlTrain batch 19/32 - 164.6ms/batch - loss: 0.59053 - diff: 9.45mlTrain batch 20/32 - 149.4ms/batch - loss: 0.59556 - diff: 9.53mlTrain batch 21/32 - 183.7ms/batch - loss: 0.59504 - diff: 9.52mlTrain batch 22/32 - 179.9ms/batch - loss: 0.59480 - diff: 9.52mlTrain batch 23/32 - 165.0ms/batch - loss: 0.59518 - diff: 9.52mlTrain batch 24/32 - 199.0ms/batch - loss: 0.58616 - diff: 9.38mlTrain batch 25/32 - 125.2ms/batch - loss: 0.57985 - diff: 9.28mlTrain batch 26/32 - 149.2ms/batch - loss: 0.57801 - diff: 9.25mlTrain batch 27/32 - 168.3ms/batch - loss: 0.57819 - diff: 9.25mlTrain batch 28/32 - 152.2ms/batch - loss: 0.58123 - diff: 9.30mlTrain batch 29/32 - 174.9ms/batch - loss: 0.59140 - diff: 9.46mlTrain batch 30/32 - 158.5ms/batch - loss: 0.59229 - diff: 9.48mlTrain batch 31/32 - 150.0ms/batch - loss: 0.59965 - diff: 9.59mlTrain batch 32/32 - 123.4ms/batch - loss: 0.64852 - diff: 9.73mlTrain batch 32/32 - 17.5s 123.4ms/batch - loss: 0.64852 - diff: 9.73ml
Test 1.1s: val_loss: 1.02711 - diff: 16.00ml

Epoch 105: current best loss = 0.92974, at epoch 100
Train batch 1/32 - 149.1ms/batch - loss: 0.50042 - diff: 8.01mlTrain batch 2/32 - 112.0ms/batch - loss: 0.46735 - diff: 7.48mlTrain batch 3/32 - 172.4ms/batch - loss: 0.43639 - diff: 6.98mlTrain batch 4/32 - 167.0ms/batch - loss: 0.41983 - diff: 6.72mlTrain batch 5/32 - 172.9ms/batch - loss: 0.44516 - diff: 7.12mlTrain batch 6/32 - 171.7ms/batch - loss: 0.43197 - diff: 6.91mlTrain batch 7/32 - 168.7ms/batch - loss: 0.50405 - diff: 8.06mlTrain batch 8/32 - 177.3ms/batch - loss: 0.48512 - diff: 7.76mlTrain batch 9/32 - 152.5ms/batch - loss: 0.51468 - diff: 8.23mlTrain batch 10/32 - 141.0ms/batch - loss: 0.51725 - diff: 8.28mlTrain batch 11/32 - 140.4ms/batch - loss: 0.54236 - diff: 8.68mlTrain batch 12/32 - 202.2ms/batch - loss: 0.53991 - diff: 8.64mlTrain batch 13/32 - 152.7ms/batch - loss: 0.53842 - diff: 8.61mlTrain batch 14/32 - 181.3ms/batch - loss: 0.53323 - diff: 8.53mlTrain batch 15/32 - 174.7ms/batch - loss: 0.52772 - diff: 8.44mlTrain batch 16/32 - 162.3ms/batch - loss: 0.51962 - diff: 8.31mlTrain batch 17/32 - 183.7ms/batch - loss: 0.52279 - diff: 8.36mlTrain batch 18/32 - 138.4ms/batch - loss: 0.52129 - diff: 8.34mlTrain batch 19/32 - 184.3ms/batch - loss: 0.51372 - diff: 8.22mlTrain batch 20/32 - 163.7ms/batch - loss: 0.51476 - diff: 8.24mlTrain batch 21/32 - 196.2ms/batch - loss: 0.51240 - diff: 8.20mlTrain batch 22/32 - 157.5ms/batch - loss: 0.51192 - diff: 8.19mlTrain batch 23/32 - 184.4ms/batch - loss: 0.50456 - diff: 8.07mlTrain batch 24/32 - 139.7ms/batch - loss: 0.49759 - diff: 7.96mlTrain batch 25/32 - 135.3ms/batch - loss: 0.51307 - diff: 8.21mlTrain batch 26/32 - 196.1ms/batch - loss: 0.52030 - diff: 8.32mlTrain batch 27/32 - 192.4ms/batch - loss: 0.51970 - diff: 8.32mlTrain batch 28/32 - 181.2ms/batch - loss: 0.52281 - diff: 8.36mlTrain batch 29/32 - 166.8ms/batch - loss: 0.52483 - diff: 8.40mlTrain batch 30/32 - 121.8ms/batch - loss: 0.51984 - diff: 8.32mlTrain batch 31/32 - 138.1ms/batch - loss: 0.51747 - diff: 8.28mlTrain batch 32/32 - 139.3ms/batch - loss: 0.53308 - diff: 8.29mlTrain batch 32/32 - 16.3s 139.3ms/batch - loss: 0.53308 - diff: 8.29ml
Test 0.9s: val_loss: 0.92871 - diff: 14.40ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Systole_DenseNet121_0_Adam-0.001_MAE_DA3_best

Epoch 106: current best loss = 0.92871, at epoch 105
Train batch 1/32 - 198.2ms/batch - loss: 0.65972 - diff: 10.56mlTrain batch 2/32 - 177.1ms/batch - loss: 0.52673 - diff: 8.43mlTrain batch 3/32 - 166.1ms/batch - loss: 0.53399 - diff: 8.54mlTrain batch 4/32 - 147.4ms/batch - loss: 0.49884 - diff: 7.98mlTrain batch 5/32 - 152.4ms/batch - loss: 0.53826 - diff: 8.61mlTrain batch 6/32 - 155.8ms/batch - loss: 0.52892 - diff: 8.46mlTrain batch 7/32 - 180.2ms/batch - loss: 0.51224 - diff: 8.20mlTrain batch 8/32 - 193.4ms/batch - loss: 0.52066 - diff: 8.33mlTrain batch 9/32 - 197.8ms/batch - loss: 0.56884 - diff: 9.10mlTrain batch 10/32 - 156.6ms/batch - loss: 0.54211 - diff: 8.67mlTrain batch 11/32 - 148.8ms/batch - loss: 0.55733 - diff: 8.92mlTrain batch 12/32 - 137.6ms/batch - loss: 0.55151 - diff: 8.82mlTrain batch 13/32 - 141.6ms/batch - loss: 0.54202 - diff: 8.67mlTrain batch 14/32 - 160.0ms/batch - loss: 0.54479 - diff: 8.72mlTrain batch 15/32 - 180.0ms/batch - loss: 0.53811 - diff: 8.61mlTrain batch 16/32 - 125.9ms/batch - loss: 0.60594 - diff: 9.70mlTrain batch 17/32 - 164.6ms/batch - loss: 0.59530 - diff: 9.52mlTrain batch 18/32 - 137.3ms/batch - loss: 0.58348 - diff: 9.34mlTrain batch 19/32 - 164.6ms/batch - loss: 0.58745 - diff: 9.40mlTrain batch 20/32 - 188.6ms/batch - loss: 0.57895 - diff: 9.26mlTrain batch 21/32 - 185.2ms/batch - loss: 0.57512 - diff: 9.20mlTrain batch 22/32 - 146.7ms/batch - loss: 0.57087 - diff: 9.13mlTrain batch 23/32 - 145.0ms/batch - loss: 0.56720 - diff: 9.08mlTrain batch 24/32 - 157.1ms/batch - loss: 0.58399 - diff: 9.34mlTrain batch 25/32 - 155.8ms/batch - loss: 0.58546 - diff: 9.37mlTrain batch 26/32 - 177.6ms/batch - loss: 0.58358 - diff: 9.34mlTrain batch 27/32 - 188.1ms/batch - loss: 0.57850 - diff: 9.26mlTrain batch 28/32 - 135.1ms/batch - loss: 0.58523 - diff: 9.36mlTrain batch 29/32 - 140.3ms/batch - loss: 0.58846 - diff: 9.42mlTrain batch 30/32 - 149.1ms/batch - loss: 0.58315 - diff: 9.33mlTrain batch 31/32 - 138.0ms/batch - loss: 0.59074 - diff: 9.45mlTrain batch 32/32 - 180.0ms/batch - loss: 0.61110 - diff: 9.48mlTrain batch 32/32 - 15.9s 180.0ms/batch - loss: 0.61110 - diff: 9.48ml
Test 1.1s: val_loss: 0.97007 - diff: 14.61ml

Epoch 107: current best loss = 0.92871, at epoch 105
Train batch 1/32 - 212.7ms/batch - loss: 0.53238 - diff: 8.52mlTrain batch 2/32 - 201.9ms/batch - loss: 0.57092 - diff: 9.13mlTrain batch 3/32 - 192.3ms/batch - loss: 0.50482 - diff: 8.08mlTrain batch 4/32 - 147.2ms/batch - loss: 0.49318 - diff: 7.89mlTrain batch 5/32 - 144.0ms/batch - loss: 0.51235 - diff: 8.20mlTrain batch 6/32 - 113.0ms/batch - loss: 0.57625 - diff: 9.22mlTrain batch 7/32 - 170.4ms/batch - loss: 0.57822 - diff: 9.25mlTrain batch 8/32 - 178.4ms/batch - loss: 0.57999 - diff: 9.28mlTrain batch 9/32 - 151.0ms/batch - loss: 0.58943 - diff: 9.43mlTrain batch 10/32 - 161.5ms/batch - loss: 0.57554 - diff: 9.21mlTrain batch 11/32 - 111.3ms/batch - loss: 0.57795 - diff: 9.25mlTrain batch 12/32 - 133.2ms/batch - loss: 0.57886 - diff: 9.26mlTrain batch 13/32 - 192.4ms/batch - loss: 0.60283 - diff: 9.65mlTrain batch 14/32 - 229.4ms/batch - loss: 0.60168 - diff: 9.63mlTrain batch 15/32 - 153.8ms/batch - loss: 0.58803 - diff: 9.41mlTrain batch 16/32 - 120.8ms/batch - loss: 0.58491 - diff: 9.36mlTrain batch 17/32 - 186.2ms/batch - loss: 0.58876 - diff: 9.42mlTrain batch 18/32 - 178.5ms/batch - loss: 0.57602 - diff: 9.22mlTrain batch 19/32 - 176.4ms/batch - loss: 0.57234 - diff: 9.16mlTrain batch 20/32 - 180.7ms/batch - loss: 0.56273 - diff: 9.00mlTrain batch 21/32 - 167.7ms/batch - loss: 0.56122 - diff: 8.98mlTrain batch 22/32 - 149.7ms/batch - loss: 0.56224 - diff: 9.00mlTrain batch 23/32 - 192.8ms/batch - loss: 0.56821 - diff: 9.09mlTrain batch 24/32 - 165.9ms/batch - loss: 0.56977 - diff: 9.12mlTrain batch 25/32 - 182.4ms/batch - loss: 0.56783 - diff: 9.09mlTrain batch 26/32 - 179.3ms/batch - loss: 0.56459 - diff: 9.03mlTrain batch 27/32 - 168.5ms/batch - loss: 0.56920 - diff: 9.11mlTrain batch 28/32 - 140.2ms/batch - loss: 0.57270 - diff: 9.16mlTrain batch 29/32 - 191.6ms/batch - loss: 0.57359 - diff: 9.18mlTrain batch 30/32 - 187.2ms/batch - loss: 0.56708 - diff: 9.07mlTrain batch 31/32 - 142.1ms/batch - loss: 0.56844 - diff: 9.09mlTrain batch 32/32 - 137.3ms/batch - loss: 0.57770 - diff: 9.08mlTrain batch 32/32 - 17.2s 137.3ms/batch - loss: 0.57770 - diff: 9.08ml
Test 1.1s: val_loss: 0.95034 - diff: 14.77ml

Epoch 108: current best loss = 0.92871, at epoch 105
Train batch 1/32 - 154.6ms/batch - loss: 0.55209 - diff: 8.83mlTrain batch 2/32 - 130.8ms/batch - loss: 0.59814 - diff: 9.57mlTrain batch 3/32 - 103.6ms/batch - loss: 0.57886 - diff: 9.26mlTrain batch 4/32 - 139.3ms/batch - loss: 0.63603 - diff: 10.18mlTrain batch 5/32 - 170.7ms/batch - loss: 0.57774 - diff: 9.24mlTrain batch 6/32 - 155.9ms/batch - loss: 0.56923 - diff: 9.11mlTrain batch 7/32 - 140.0ms/batch - loss: 0.59774 - diff: 9.56mlTrain batch 8/32 - 147.9ms/batch - loss: 0.59276 - diff: 9.48mlTrain batch 9/32 - 165.8ms/batch - loss: 0.57237 - diff: 9.16mlTrain batch 10/32 - 167.8ms/batch - loss: 0.57288 - diff: 9.17mlTrain batch 11/32 - 136.7ms/batch - loss: 0.56010 - diff: 8.96mlTrain batch 12/32 - 165.1ms/batch - loss: 0.55501 - diff: 8.88mlTrain batch 13/32 - 165.0ms/batch - loss: 0.58682 - diff: 9.39mlTrain batch 14/32 - 147.4ms/batch - loss: 0.57826 - diff: 9.25mlTrain batch 15/32 - 154.6ms/batch - loss: 0.56377 - diff: 9.02mlTrain batch 16/32 - 163.4ms/batch - loss: 0.55579 - diff: 8.89mlTrain batch 17/32 - 194.8ms/batch - loss: 0.55427 - diff: 8.87mlTrain batch 18/32 - 161.3ms/batch - loss: 0.55068 - diff: 8.81mlTrain batch 19/32 - 205.7ms/batch - loss: 0.54120 - diff: 8.66mlTrain batch 20/32 - 176.2ms/batch - loss: 0.53613 - diff: 8.58mlTrain batch 21/32 - 183.3ms/batch - loss: 0.53394 - diff: 8.54mlTrain batch 22/32 - 160.5ms/batch - loss: 0.53786 - diff: 8.61mlTrain batch 23/32 - 168.9ms/batch - loss: 0.54067 - diff: 8.65mlTrain batch 24/32 - 172.3ms/batch - loss: 0.54385 - diff: 8.70mlTrain batch 25/32 - 202.4ms/batch - loss: 0.54242 - diff: 8.68mlTrain batch 26/32 - 140.7ms/batch - loss: 0.53666 - diff: 8.59mlTrain batch 27/32 - 124.0ms/batch - loss: 0.53494 - diff: 8.56mlTrain batch 28/32 - 176.2ms/batch - loss: 0.53332 - diff: 8.53mlTrain batch 29/32 - 197.7ms/batch - loss: 0.53112 - diff: 8.50mlTrain batch 30/32 - 192.6ms/batch - loss: 0.53377 - diff: 8.54mlTrain batch 31/32 - 153.2ms/batch - loss: 0.52837 - diff: 8.45mlTrain batch 32/32 - 162.6ms/batch - loss: 0.54480 - diff: 8.47mlTrain batch 32/32 - 17.6s 162.6ms/batch - loss: 0.54480 - diff: 8.47ml
Test 1.0s: val_loss: 0.95551 - diff: 14.94ml

Epoch 109: current best loss = 0.92871, at epoch 105
Train batch 1/32 - 150.4ms/batch - loss: 0.67581 - diff: 10.81mlTrain batch 2/32 - 120.7ms/batch - loss: 0.56271 - diff: 9.00mlTrain batch 3/32 - 156.1ms/batch - loss: 0.52460 - diff: 8.39mlTrain batch 4/32 - 128.4ms/batch - loss: 0.63333 - diff: 10.13mlTrain batch 5/32 - 115.3ms/batch - loss: 0.61267 - diff: 9.80mlTrain batch 6/32 - 178.4ms/batch - loss: 0.55479 - diff: 8.88mlTrain batch 7/32 - 189.7ms/batch - loss: 0.54708 - diff: 8.75mlTrain batch 8/32 - 190.3ms/batch - loss: 0.61958 - diff: 9.91mlTrain batch 9/32 - 134.3ms/batch - loss: 0.62714 - diff: 10.03mlTrain batch 10/32 - 116.1ms/batch - loss: 0.61725 - diff: 9.88mlTrain batch 11/32 - 117.0ms/batch - loss: 0.60495 - diff: 9.68mlTrain batch 12/32 - 146.2ms/batch - loss: 0.58722 - diff: 9.40mlTrain batch 13/32 - 209.3ms/batch - loss: 0.56992 - diff: 9.12mlTrain batch 14/32 - 164.7ms/batch - loss: 0.55991 - diff: 8.96mlTrain batch 15/32 - 145.0ms/batch - loss: 0.55381 - diff: 8.86mlTrain batch 16/32 - 114.0ms/batch - loss: 0.56158 - diff: 8.99mlTrain batch 17/32 - 190.9ms/batch - loss: 0.57185 - diff: 9.15mlTrain batch 18/32 - 191.6ms/batch - loss: 0.56572 - diff: 9.05mlTrain batch 19/32 - 197.4ms/batch - loss: 0.56758 - diff: 9.08mlTrain batch 20/32 - 145.6ms/batch - loss: 0.56377 - diff: 9.02mlTrain batch 21/32 - 195.0ms/batch - loss: 0.55727 - diff: 8.92mlTrain batch 22/32 - 177.7ms/batch - loss: 0.54720 - diff: 8.76mlTrain batch 23/32 - 174.8ms/batch - loss: 0.54900 - diff: 8.78mlTrain batch 24/32 - 121.7ms/batch - loss: 0.53859 - diff: 8.62mlTrain batch 25/32 - 134.0ms/batch - loss: 0.53690 - diff: 8.59mlTrain batch 26/32 - 103.8ms/batch - loss: 0.54129 - diff: 8.66mlTrain batch 27/32 - 136.8ms/batch - loss: 0.54264 - diff: 8.68mlTrain batch 28/32 - 109.2ms/batch - loss: 0.53796 - diff: 8.61mlTrain batch 29/32 - 128.4ms/batch - loss: 0.54328 - diff: 8.69mlTrain batch 30/32 - 156.2ms/batch - loss: 0.54411 - diff: 8.71mlTrain batch 31/32 - 117.1ms/batch - loss: 0.56747 - diff: 9.08mlTrain batch 32/32 - 202.4ms/batch - loss: 0.58482 - diff: 9.09mlTrain batch 32/32 - 16.1s 202.4ms/batch - loss: 0.58482 - diff: 9.09ml
Test 1.0s: val_loss: 0.94269 - diff: 14.60ml

Epoch 110: current best loss = 0.92871, at epoch 105
Train batch 1/32 - 194.6ms/batch - loss: 0.44646 - diff: 7.14mlTrain batch 2/32 - 140.7ms/batch - loss: 0.42311 - diff: 6.77mlTrain batch 3/32 - 156.4ms/batch - loss: 0.50613 - diff: 8.10mlTrain batch 4/32 - 176.2ms/batch - loss: 0.49238 - diff: 7.88mlTrain batch 5/32 - 169.3ms/batch - loss: 0.46589 - diff: 7.45mlTrain batch 6/32 - 174.0ms/batch - loss: 0.46715 - diff: 7.47mlTrain batch 7/32 - 147.1ms/batch - loss: 0.48334 - diff: 7.73mlTrain batch 8/32 - 161.0ms/batch - loss: 0.49095 - diff: 7.86mlTrain batch 9/32 - 186.4ms/batch - loss: 0.49912 - diff: 7.99mlTrain batch 10/32 - 165.6ms/batch - loss: 0.51665 - diff: 8.27mlTrain batch 11/32 - 138.1ms/batch - loss: 0.52949 - diff: 8.47mlTrain batch 12/32 - 148.7ms/batch - loss: 0.54199 - diff: 8.67mlTrain batch 13/32 - 155.3ms/batch - loss: 0.52685 - diff: 8.43mlTrain batch 14/32 - 141.3ms/batch - loss: 0.55373 - diff: 8.86mlTrain batch 15/32 - 141.4ms/batch - loss: 0.56411 - diff: 9.03mlTrain batch 16/32 - 199.7ms/batch - loss: 0.55698 - diff: 8.91mlTrain batch 17/32 - 121.2ms/batch - loss: 0.55518 - diff: 8.88mlTrain batch 18/32 - 216.3ms/batch - loss: 0.55308 - diff: 8.85mlTrain batch 19/32 - 194.3ms/batch - loss: 0.54557 - diff: 8.73mlTrain batch 20/32 - 192.6ms/batch - loss: 0.53540 - diff: 8.57mlTrain batch 21/32 - 214.2ms/batch - loss: 0.53422 - diff: 8.55mlTrain batch 22/32 - 173.5ms/batch - loss: 0.52728 - diff: 8.44mlTrain batch 23/32 - 184.2ms/batch - loss: 0.53928 - diff: 8.63mlTrain batch 24/32 - 145.3ms/batch - loss: 0.53866 - diff: 8.62mlTrain batch 25/32 - 143.8ms/batch - loss: 0.53408 - diff: 8.55mlTrain batch 26/32 - 168.9ms/batch - loss: 0.52884 - diff: 8.46mlTrain batch 27/32 - 152.4ms/batch - loss: 0.53857 - diff: 8.62mlTrain batch 28/32 - 184.4ms/batch - loss: 0.54277 - diff: 8.68mlTrain batch 29/32 - 127.9ms/batch - loss: 0.54043 - diff: 8.65mlTrain batch 30/32 - 170.4ms/batch - loss: 0.53750 - diff: 8.60mlTrain batch 31/32 - 187.6ms/batch - loss: 0.54264 - diff: 8.68mlTrain batch 32/32 - 173.5ms/batch - loss: 0.57227 - diff: 8.75mlTrain batch 32/32 - 16.9s 173.5ms/batch - loss: 0.57227 - diff: 8.75ml
Test 1.1s: val_loss: 0.89711 - diff: 13.72ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Systole_DenseNet121_0_Adam-0.001_MAE_DA3_best

Epoch 111: current best loss = 0.89711, at epoch 110
Train batch 1/32 - 136.6ms/batch - loss: 0.36444 - diff: 5.83mlTrain batch 2/32 - 119.3ms/batch - loss: 0.56961 - diff: 9.11mlTrain batch 3/32 - 95.3ms/batch - loss: 0.62906 - diff: 10.06mlTrain batch 4/32 - 90.1ms/batch - loss: 0.62983 - diff: 10.08mlTrain batch 5/32 - 182.2ms/batch - loss: 0.60940 - diff: 9.75mlTrain batch 6/32 - 200.0ms/batch - loss: 0.60762 - diff: 9.72mlTrain batch 7/32 - 134.1ms/batch - loss: 0.60281 - diff: 9.64mlTrain batch 8/32 - 147.9ms/batch - loss: 0.60311 - diff: 9.65mlTrain batch 9/32 - 187.2ms/batch - loss: 0.62639 - diff: 10.02mlTrain batch 10/32 - 141.6ms/batch - loss: 0.59722 - diff: 9.56mlTrain batch 11/32 - 184.3ms/batch - loss: 0.61984 - diff: 9.92mlTrain batch 12/32 - 188.0ms/batch - loss: 0.62573 - diff: 10.01mlTrain batch 13/32 - 222.9ms/batch - loss: 0.61249 - diff: 9.80mlTrain batch 14/32 - 174.0ms/batch - loss: 0.60575 - diff: 9.69mlTrain batch 15/32 - 131.2ms/batch - loss: 0.59574 - diff: 9.53mlTrain batch 16/32 - 123.0ms/batch - loss: 0.58824 - diff: 9.41mlTrain batch 17/32 - 174.1ms/batch - loss: 0.58491 - diff: 9.36mlTrain batch 18/32 - 191.8ms/batch - loss: 0.62632 - diff: 10.02mlTrain batch 19/32 - 161.2ms/batch - loss: 0.62434 - diff: 9.99mlTrain batch 20/32 - 197.0ms/batch - loss: 0.61509 - diff: 9.84mlTrain batch 21/32 - 154.1ms/batch - loss: 0.60035 - diff: 9.61mlTrain batch 22/32 - 218.8ms/batch - loss: 0.59393 - diff: 9.50mlTrain batch 23/32 - 162.5ms/batch - loss: 0.60088 - diff: 9.61mlTrain batch 24/32 - 171.2ms/batch - loss: 0.58926 - diff: 9.43mlTrain batch 25/32 - 161.3ms/batch - loss: 0.58818 - diff: 9.41mlTrain batch 26/32 - 159.7ms/batch - loss: 0.58348 - diff: 9.34mlTrain batch 27/32 - 163.5ms/batch - loss: 0.57692 - diff: 9.23mlTrain batch 28/32 - 172.4ms/batch - loss: 0.58906 - diff: 9.42mlTrain batch 29/32 - 150.6ms/batch - loss: 0.58802 - diff: 9.41mlTrain batch 30/32 - 153.6ms/batch - loss: 0.58312 - diff: 9.33mlTrain batch 31/32 - 145.4ms/batch - loss: 0.58146 - diff: 9.30mlTrain batch 32/32 - 154.3ms/batch - loss: 0.60516 - diff: 9.34mlTrain batch 32/32 - 16.2s 154.3ms/batch - loss: 0.60516 - diff: 9.34ml
Test 1.0s: val_loss: 0.96383 - diff: 14.91ml

Epoch 112: current best loss = 0.89711, at epoch 110
Train batch 1/32 - 211.2ms/batch - loss: 0.45647 - diff: 7.30mlTrain batch 2/32 - 129.6ms/batch - loss: 0.44580 - diff: 7.13mlTrain batch 3/32 - 182.3ms/batch - loss: 0.44657 - diff: 7.15mlTrain batch 4/32 - 161.7ms/batch - loss: 0.48085 - diff: 7.69mlTrain batch 5/32 - 201.9ms/batch - loss: 0.47580 - diff: 7.61mlTrain batch 6/32 - 186.0ms/batch - loss: 0.52167 - diff: 8.35mlTrain batch 7/32 - 166.4ms/batch - loss: 0.50407 - diff: 8.07mlTrain batch 8/32 - 143.7ms/batch - loss: 0.51398 - diff: 8.22mlTrain batch 9/32 - 190.9ms/batch - loss: 0.51787 - diff: 8.29mlTrain batch 10/32 - 156.1ms/batch - loss: 0.51795 - diff: 8.29mlTrain batch 11/32 - 147.7ms/batch - loss: 0.57277 - diff: 9.16mlTrain batch 12/32 - 121.3ms/batch - loss: 0.59643 - diff: 9.54mlTrain batch 13/32 - 143.0ms/batch - loss: 0.58069 - diff: 9.29mlTrain batch 14/32 - 179.5ms/batch - loss: 0.56658 - diff: 9.07mlTrain batch 15/32 - 166.0ms/batch - loss: 0.57032 - diff: 9.13mlTrain batch 16/32 - 171.5ms/batch - loss: 0.56997 - diff: 9.12mlTrain batch 17/32 - 139.6ms/batch - loss: 0.55539 - diff: 8.89mlTrain batch 18/32 - 153.4ms/batch - loss: 0.56697 - diff: 9.07mlTrain batch 19/32 - 202.4ms/batch - loss: 0.55976 - diff: 8.96mlTrain batch 20/32 - 172.2ms/batch - loss: 0.55379 - diff: 8.86mlTrain batch 21/32 - 175.9ms/batch - loss: 0.56848 - diff: 9.10mlTrain batch 22/32 - 175.5ms/batch - loss: 0.57623 - diff: 9.22mlTrain batch 23/32 - 188.6ms/batch - loss: 0.56699 - diff: 9.07mlTrain batch 24/32 - 198.7ms/batch - loss: 0.57198 - diff: 9.15mlTrain batch 25/32 - 212.2ms/batch - loss: 0.57662 - diff: 9.23mlTrain batch 26/32 - 171.2ms/batch - loss: 0.56884 - diff: 9.10mlTrain batch 27/32 - 136.5ms/batch - loss: 0.56303 - diff: 9.01mlTrain batch 28/32 - 147.0ms/batch - loss: 0.56264 - diff: 9.00mlTrain batch 29/32 - 148.6ms/batch - loss: 0.57851 - diff: 9.26mlTrain batch 30/32 - 162.3ms/batch - loss: 0.58493 - diff: 9.36mlTrain batch 31/32 - 145.6ms/batch - loss: 0.58376 - diff: 9.34mlTrain batch 32/32 - 208.8ms/batch - loss: 0.59562 - diff: 9.33mlTrain batch 32/32 - 15.0s 208.8ms/batch - loss: 0.59562 - diff: 9.33ml
Test 1.1s: val_loss: 0.92072 - diff: 13.97ml

Epoch 113: current best loss = 0.89711, at epoch 110
Train batch 1/32 - 203.1ms/batch - loss: 0.41637 - diff: 6.66mlTrain batch 2/32 - 150.8ms/batch - loss: 0.49737 - diff: 7.96mlTrain batch 3/32 - 194.4ms/batch - loss: 0.50579 - diff: 8.09mlTrain batch 4/32 - 160.0ms/batch - loss: 0.50738 - diff: 8.12mlTrain batch 5/32 - 162.4ms/batch - loss: 0.55523 - diff: 8.88mlTrain batch 6/32 - 131.3ms/batch - loss: 0.54485 - diff: 8.72mlTrain batch 7/32 - 197.7ms/batch - loss: 0.57197 - diff: 9.15mlTrain batch 8/32 - 134.7ms/batch - loss: 0.55496 - diff: 8.88mlTrain batch 9/32 - 133.8ms/batch - loss: 0.57469 - diff: 9.20mlTrain batch 10/32 - 165.8ms/batch - loss: 0.58849 - diff: 9.42mlTrain batch 11/32 - 160.9ms/batch - loss: 0.62041 - diff: 9.93mlTrain batch 12/32 - 160.3ms/batch - loss: 0.61221 - diff: 9.80mlTrain batch 13/32 - 169.0ms/batch - loss: 0.60744 - diff: 9.72mlTrain batch 14/32 - 146.6ms/batch - loss: 0.59746 - diff: 9.56mlTrain batch 15/32 - 183.7ms/batch - loss: 0.59380 - diff: 9.50mlTrain batch 16/32 - 130.3ms/batch - loss: 0.58648 - diff: 9.38mlTrain batch 17/32 - 146.9ms/batch - loss: 0.57473 - diff: 9.20mlTrain batch 18/32 - 110.9ms/batch - loss: 0.60460 - diff: 9.67mlTrain batch 19/32 - 197.9ms/batch - loss: 0.59497 - diff: 9.52mlTrain batch 20/32 - 162.1ms/batch - loss: 0.59133 - diff: 9.46mlTrain batch 21/32 - 185.4ms/batch - loss: 0.58532 - diff: 9.37mlTrain batch 22/32 - 148.3ms/batch - loss: 0.58183 - diff: 9.31mlTrain batch 23/32 - 181.0ms/batch - loss: 0.58113 - diff: 9.30mlTrain batch 24/32 - 139.0ms/batch - loss: 0.58116 - diff: 9.30mlTrain batch 25/32 - 200.2ms/batch - loss: 0.57664 - diff: 9.23mlTrain batch 26/32 - 161.4ms/batch - loss: 0.57659 - diff: 9.23mlTrain batch 27/32 - 153.5ms/batch - loss: 0.58687 - diff: 9.39mlTrain batch 28/32 - 210.8ms/batch - loss: 0.58392 - diff: 9.34mlTrain batch 29/32 - 182.7ms/batch - loss: 0.58417 - diff: 9.35mlTrain batch 30/32 - 153.5ms/batch - loss: 0.57816 - diff: 9.25mlTrain batch 31/32 - 139.9ms/batch - loss: 0.58210 - diff: 9.31mlTrain batch 32/32 - 139.7ms/batch - loss: 0.60609 - diff: 9.35mlTrain batch 32/32 - 18.1s 139.7ms/batch - loss: 0.60609 - diff: 9.35ml
Test 1.1s: val_loss: 0.92973 - diff: 14.27ml

Epoch 114: current best loss = 0.89711, at epoch 110
Train batch 1/32 - 190.9ms/batch - loss: 0.52647 - diff: 8.42mlTrain batch 2/32 - 170.6ms/batch - loss: 0.53873 - diff: 8.62mlTrain batch 3/32 - 173.1ms/batch - loss: 0.46875 - diff: 7.50mlTrain batch 4/32 - 188.1ms/batch - loss: 0.43323 - diff: 6.93mlTrain batch 5/32 - 193.6ms/batch - loss: 0.50714 - diff: 8.11mlTrain batch 6/32 - 140.0ms/batch - loss: 0.51517 - diff: 8.24mlTrain batch 7/32 - 251.7ms/batch - loss: 0.51828 - diff: 8.29mlTrain batch 8/32 - 182.5ms/batch - loss: 0.52928 - diff: 8.47mlTrain batch 9/32 - 180.6ms/batch - loss: 0.52851 - diff: 8.46mlTrain batch 10/32 - 143.3ms/batch - loss: 0.52122 - diff: 8.34mlTrain batch 11/32 - 155.8ms/batch - loss: 0.52738 - diff: 8.44mlTrain batch 12/32 - 151.1ms/batch - loss: 0.52011 - diff: 8.32mlTrain batch 13/32 - 149.9ms/batch - loss: 0.50920 - diff: 8.15mlTrain batch 14/32 - 115.6ms/batch - loss: 0.52311 - diff: 8.37mlTrain batch 15/32 - 201.3ms/batch - loss: 0.52812 - diff: 8.45mlTrain batch 16/32 - 166.8ms/batch - loss: 0.52137 - diff: 8.34mlTrain batch 17/32 - 147.3ms/batch - loss: 0.50866 - diff: 8.14mlTrain batch 18/32 - 190.7ms/batch - loss: 0.51081 - diff: 8.17mlTrain batch 19/32 - 159.6ms/batch - loss: 0.50366 - diff: 8.06mlTrain batch 20/32 - 188.2ms/batch - loss: 0.51401 - diff: 8.22mlTrain batch 21/32 - 174.7ms/batch - loss: 0.52733 - diff: 8.44mlTrain batch 22/32 - 157.4ms/batch - loss: 0.52603 - diff: 8.42mlTrain batch 23/32 - 168.7ms/batch - loss: 0.52577 - diff: 8.41mlTrain batch 24/32 - 179.7ms/batch - loss: 0.51471 - diff: 8.24mlTrain batch 25/32 - 121.5ms/batch - loss: 0.52382 - diff: 8.38mlTrain batch 26/32 - 136.9ms/batch - loss: 0.53638 - diff: 8.58mlTrain batch 27/32 - 146.2ms/batch - loss: 0.55312 - diff: 8.85mlTrain batch 28/32 - 126.1ms/batch - loss: 0.56270 - diff: 9.00mlTrain batch 29/32 - 126.3ms/batch - loss: 0.56968 - diff: 9.11mlTrain batch 30/32 - 162.2ms/batch - loss: 0.56947 - diff: 9.11mlTrain batch 31/32 - 147.4ms/batch - loss: 0.57259 - diff: 9.16mlTrain batch 32/32 - 131.0ms/batch - loss: 0.58700 - diff: 9.16mlTrain batch 32/32 - 16.4s 131.0ms/batch - loss: 0.58700 - diff: 9.16ml
Test 1.1s: val_loss: 1.02013 - diff: 15.60ml

Epoch 115: current best loss = 0.89711, at epoch 110
Train batch 1/32 - 166.0ms/batch - loss: 0.47586 - diff: 7.61mlTrain batch 2/32 - 174.0ms/batch - loss: 0.44957 - diff: 7.19mlTrain batch 3/32 - 176.9ms/batch - loss: 0.51304 - diff: 8.21mlTrain batch 4/32 - 137.0ms/batch - loss: 0.47798 - diff: 7.65mlTrain batch 5/32 - 167.0ms/batch - loss: 0.49518 - diff: 7.92mlTrain batch 6/32 - 159.3ms/batch - loss: 0.48053 - diff: 7.69mlTrain batch 7/32 - 167.6ms/batch - loss: 0.50367 - diff: 8.06mlTrain batch 8/32 - 141.6ms/batch - loss: 0.47800 - diff: 7.65mlTrain batch 9/32 - 145.0ms/batch - loss: 0.50731 - diff: 8.12mlTrain batch 10/32 - 128.6ms/batch - loss: 0.50067 - diff: 8.01mlTrain batch 11/32 - 139.7ms/batch - loss: 0.53412 - diff: 8.55mlTrain batch 12/32 - 139.2ms/batch - loss: 0.55353 - diff: 8.86mlTrain batch 13/32 - 142.2ms/batch - loss: 0.55267 - diff: 8.84mlTrain batch 14/32 - 156.0ms/batch - loss: 0.53114 - diff: 8.50mlTrain batch 15/32 - 170.5ms/batch - loss: 0.52220 - diff: 8.36mlTrain batch 16/32 - 195.8ms/batch - loss: 0.51559 - diff: 8.25mlTrain batch 17/32 - 184.2ms/batch - loss: 0.53119 - diff: 8.50mlTrain batch 18/32 - 149.3ms/batch - loss: 0.51862 - diff: 8.30mlTrain batch 19/32 - 154.2ms/batch - loss: 0.50289 - diff: 8.05mlTrain batch 20/32 - 176.4ms/batch - loss: 0.50010 - diff: 8.00mlTrain batch 21/32 - 175.5ms/batch - loss: 0.50158 - diff: 8.03mlTrain batch 22/32 - 206.7ms/batch - loss: 0.52961 - diff: 8.47mlTrain batch 23/32 - 156.9ms/batch - loss: 0.55466 - diff: 8.87mlTrain batch 24/32 - 170.0ms/batch - loss: 0.56406 - diff: 9.02mlTrain batch 25/32 - 141.2ms/batch - loss: 0.56250 - diff: 9.00mlTrain batch 26/32 - 135.4ms/batch - loss: 0.55108 - diff: 8.82mlTrain batch 27/32 - 124.5ms/batch - loss: 0.54883 - diff: 8.78mlTrain batch 28/32 - 135.1ms/batch - loss: 0.54981 - diff: 8.80mlTrain batch 29/32 - 183.5ms/batch - loss: 0.55390 - diff: 8.86mlTrain batch 30/32 - 166.3ms/batch - loss: 0.55184 - diff: 8.83mlTrain batch 31/32 - 120.0ms/batch - loss: 0.55020 - diff: 8.80mlTrain batch 32/32 - 150.9ms/batch - loss: 0.56521 - diff: 8.81mlTrain batch 32/32 - 17.5s 150.9ms/batch - loss: 0.56521 - diff: 8.81ml
Test 0.9s: val_loss: 1.06050 - diff: 16.19ml

Epoch 116: current best loss = 0.89711, at epoch 110
Train batch 1/32 - 148.8ms/batch - loss: 0.46611 - diff: 7.46mlTrain batch 2/32 - 115.9ms/batch - loss: 0.51689 - diff: 8.27mlTrain batch 3/32 - 180.0ms/batch - loss: 0.49086 - diff: 7.85mlTrain batch 4/32 - 160.3ms/batch - loss: 0.50006 - diff: 8.00mlTrain batch 5/32 - 137.5ms/batch - loss: 0.53175 - diff: 8.51mlTrain batch 6/32 - 109.5ms/batch - loss: 0.50359 - diff: 8.06mlTrain batch 7/32 - 145.3ms/batch - loss: 0.49046 - diff: 7.85mlTrain batch 8/32 - 169.4ms/batch - loss: 0.48289 - diff: 7.73mlTrain batch 9/32 - 146.8ms/batch - loss: 0.47968 - diff: 7.67mlTrain batch 10/32 - 182.1ms/batch - loss: 0.48523 - diff: 7.76mlTrain batch 11/32 - 163.0ms/batch - loss: 0.48011 - diff: 7.68mlTrain batch 12/32 - 131.9ms/batch - loss: 0.53922 - diff: 8.63mlTrain batch 13/32 - 108.2ms/batch - loss: 0.58879 - diff: 9.42mlTrain batch 14/32 - 104.9ms/batch - loss: 0.57841 - diff: 9.25mlTrain batch 15/32 - 163.4ms/batch - loss: 0.56471 - diff: 9.04mlTrain batch 16/32 - 185.6ms/batch - loss: 0.56868 - diff: 9.10mlTrain batch 17/32 - 175.4ms/batch - loss: 0.56777 - diff: 9.08mlTrain batch 18/32 - 188.6ms/batch - loss: 0.57834 - diff: 9.25mlTrain batch 19/32 - 177.4ms/batch - loss: 0.57495 - diff: 9.20mlTrain batch 20/32 - 179.5ms/batch - loss: 0.57567 - diff: 9.21mlTrain batch 21/32 - 187.6ms/batch - loss: 0.56620 - diff: 9.06mlTrain batch 22/32 - 168.8ms/batch - loss: 0.57254 - diff: 9.16mlTrain batch 23/32 - 188.1ms/batch - loss: 0.56902 - diff: 9.10mlTrain batch 24/32 - 146.7ms/batch - loss: 0.56883 - diff: 9.10mlTrain batch 25/32 - 134.1ms/batch - loss: 0.56709 - diff: 9.07mlTrain batch 26/32 - 120.2ms/batch - loss: 0.58546 - diff: 9.37mlTrain batch 27/32 - 135.5ms/batch - loss: 0.58214 - diff: 9.31mlTrain batch 28/32 - 119.9ms/batch - loss: 0.58446 - diff: 9.35mlTrain batch 29/32 - 157.7ms/batch - loss: 0.58750 - diff: 9.40mlTrain batch 30/32 - 102.2ms/batch - loss: 0.58641 - diff: 9.38mlTrain batch 31/32 - 125.7ms/batch - loss: 0.58300 - diff: 9.33mlTrain batch 32/32 - 100.8ms/batch - loss: 0.59535 - diff: 9.32mlTrain batch 32/32 - 16.1s 100.8ms/batch - loss: 0.59535 - diff: 9.32ml
Test 1.0s: val_loss: 1.00939 - diff: 15.41ml

Epoch 117: current best loss = 0.89711, at epoch 110
Train batch 1/32 - 145.7ms/batch - loss: 0.89287 - diff: 14.29mlTrain batch 2/32 - 170.4ms/batch - loss: 0.68461 - diff: 10.95mlTrain batch 3/32 - 183.9ms/batch - loss: 0.57718 - diff: 9.23mlTrain batch 4/32 - 165.9ms/batch - loss: 0.57272 - diff: 9.16mlTrain batch 5/32 - 137.5ms/batch - loss: 0.58879 - diff: 9.42mlTrain batch 6/32 - 178.0ms/batch - loss: 0.58651 - diff: 9.38mlTrain batch 7/32 - 189.8ms/batch - loss: 0.58288 - diff: 9.33mlTrain batch 8/32 - 139.2ms/batch - loss: 0.57157 - diff: 9.15mlTrain batch 9/32 - 162.8ms/batch - loss: 0.57171 - diff: 9.15mlTrain batch 10/32 - 136.7ms/batch - loss: 0.58240 - diff: 9.32mlTrain batch 11/32 - 140.9ms/batch - loss: 0.58262 - diff: 9.32mlTrain batch 12/32 - 205.5ms/batch - loss: 0.56423 - diff: 9.03mlTrain batch 13/32 - 208.2ms/batch - loss: 0.55447 - diff: 8.87mlTrain batch 14/32 - 161.4ms/batch - loss: 0.55523 - diff: 8.88mlTrain batch 15/32 - 164.7ms/batch - loss: 0.54826 - diff: 8.77mlTrain batch 16/32 - 155.2ms/batch - loss: 0.54743 - diff: 8.76mlTrain batch 17/32 - 153.7ms/batch - loss: 0.54746 - diff: 8.76mlTrain batch 18/32 - 153.3ms/batch - loss: 0.54501 - diff: 8.72mlTrain batch 19/32 - 134.6ms/batch - loss: 0.54427 - diff: 8.71mlTrain batch 20/32 - 133.9ms/batch - loss: 0.54536 - diff: 8.73mlTrain batch 21/32 - 176.9ms/batch - loss: 0.54474 - diff: 8.72mlTrain batch 22/32 - 122.0ms/batch - loss: 0.54687 - diff: 8.75mlTrain batch 23/32 - 177.1ms/batch - loss: 0.54122 - diff: 8.66mlTrain batch 24/32 - 147.8ms/batch - loss: 0.54945 - diff: 8.79mlTrain batch 25/32 - 145.1ms/batch - loss: 0.54337 - diff: 8.69mlTrain batch 26/32 - 164.9ms/batch - loss: 0.54164 - diff: 8.67mlTrain batch 27/32 - 144.2ms/batch - loss: 0.55641 - diff: 8.90mlTrain batch 28/32 - 171.9ms/batch - loss: 0.55079 - diff: 8.81mlTrain batch 29/32 - 131.5ms/batch - loss: 0.54237 - diff: 8.68mlTrain batch 30/32 - 121.1ms/batch - loss: 0.53777 - diff: 8.60mlTrain batch 31/32 - 171.3ms/batch - loss: 0.53492 - diff: 8.56mlTrain batch 32/32 - 178.2ms/batch - loss: 0.56584 - diff: 8.63mlTrain batch 32/32 - 17.4s 178.2ms/batch - loss: 0.56584 - diff: 8.63ml
Test 1.1s: val_loss: 1.02254 - diff: 15.32ml

Epoch 118: current best loss = 0.89711, at epoch 110
Train batch 1/32 - 198.4ms/batch - loss: 0.32036 - diff: 5.13mlTrain batch 2/32 - 160.4ms/batch - loss: 0.36500 - diff: 5.84mlTrain batch 3/32 - 177.5ms/batch - loss: 0.36240 - diff: 5.80mlTrain batch 4/32 - 174.2ms/batch - loss: 0.40031 - diff: 6.41mlTrain batch 5/32 - 162.8ms/batch - loss: 0.43590 - diff: 6.97mlTrain batch 6/32 - 141.0ms/batch - loss: 0.44657 - diff: 7.15mlTrain batch 7/32 - 157.2ms/batch - loss: 0.47639 - diff: 7.62mlTrain batch 8/32 - 153.4ms/batch - loss: 0.48388 - diff: 7.74mlTrain batch 9/32 - 163.6ms/batch - loss: 0.51512 - diff: 8.24mlTrain batch 10/32 - 189.1ms/batch - loss: 0.53621 - diff: 8.58mlTrain batch 11/32 - 185.1ms/batch - loss: 0.53864 - diff: 8.62mlTrain batch 12/32 - 187.4ms/batch - loss: 0.52086 - diff: 8.33mlTrain batch 13/32 - 156.0ms/batch - loss: 0.50409 - diff: 8.07mlTrain batch 14/32 - 123.9ms/batch - loss: 0.50856 - diff: 8.14mlTrain batch 15/32 - 142.6ms/batch - loss: 0.51167 - diff: 8.19mlTrain batch 16/32 - 155.0ms/batch - loss: 0.50949 - diff: 8.15mlTrain batch 17/32 - 104.5ms/batch - loss: 0.51242 - diff: 8.20mlTrain batch 18/32 - 121.6ms/batch - loss: 0.51279 - diff: 8.20mlTrain batch 19/32 - 142.9ms/batch - loss: 0.52488 - diff: 8.40mlTrain batch 20/32 - 139.3ms/batch - loss: 0.54468 - diff: 8.71mlTrain batch 21/32 - 163.4ms/batch - loss: 0.54459 - diff: 8.71mlTrain batch 22/32 - 177.4ms/batch - loss: 0.54877 - diff: 8.78mlTrain batch 23/32 - 148.1ms/batch - loss: 0.53732 - diff: 8.60mlTrain batch 24/32 - 148.0ms/batch - loss: 0.54304 - diff: 8.69mlTrain batch 25/32 - 170.9ms/batch - loss: 0.54086 - diff: 8.65mlTrain batch 26/32 - 177.4ms/batch - loss: 0.53876 - diff: 8.62mlTrain batch 27/32 - 147.2ms/batch - loss: 0.53512 - diff: 8.56mlTrain batch 28/32 - 138.2ms/batch - loss: 0.53870 - diff: 8.62mlTrain batch 29/32 - 162.7ms/batch - loss: 0.53359 - diff: 8.54mlTrain batch 30/32 - 114.4ms/batch - loss: 0.53828 - diff: 8.61mlTrain batch 31/32 - 117.5ms/batch - loss: 0.54192 - diff: 8.67mlTrain batch 32/32 - 111.8ms/batch - loss: 0.55270 - diff: 8.66mlTrain batch 32/32 - 16.8s 111.8ms/batch - loss: 0.55270 - diff: 8.66ml
Test 1.2s: val_loss: 0.99857 - diff: 15.28ml

Epoch 119: current best loss = 0.89711, at epoch 110
Train batch 1/32 - 229.9ms/batch - loss: 0.66608 - diff: 10.66mlTrain batch 2/32 - 109.6ms/batch - loss: 0.54684 - diff: 8.75mlTrain batch 3/32 - 201.9ms/batch - loss: 0.60821 - diff: 9.73mlTrain batch 4/32 - 218.1ms/batch - loss: 0.55761 - diff: 8.92mlTrain batch 5/32 - 194.6ms/batch - loss: 0.52062 - diff: 8.33mlTrain batch 6/32 - 198.9ms/batch - loss: 0.52253 - diff: 8.36mlTrain batch 7/32 - 200.3ms/batch - loss: 0.59755 - diff: 9.56mlTrain batch 8/32 - 187.0ms/batch - loss: 0.57368 - diff: 9.18mlTrain batch 9/32 - 178.8ms/batch - loss: 0.53867 - diff: 8.62mlTrain batch 10/32 - 110.0ms/batch - loss: 0.53953 - diff: 8.63mlTrain batch 11/32 - 151.1ms/batch - loss: 0.53596 - diff: 8.58mlTrain batch 12/32 - 197.3ms/batch - loss: 0.51150 - diff: 8.18mlTrain batch 13/32 - 201.3ms/batch - loss: 0.52151 - diff: 8.34mlTrain batch 14/32 - 158.2ms/batch - loss: 0.53478 - diff: 8.56mlTrain batch 15/32 - 165.0ms/batch - loss: 0.57442 - diff: 9.19mlTrain batch 16/32 - 187.0ms/batch - loss: 0.56530 - diff: 9.04mlTrain batch 17/32 - 188.4ms/batch - loss: 0.57879 - diff: 9.26mlTrain batch 18/32 - 187.3ms/batch - loss: 0.57348 - diff: 9.18mlTrain batch 19/32 - 169.3ms/batch - loss: 0.56278 - diff: 9.00mlTrain batch 20/32 - 222.5ms/batch - loss: 0.54869 - diff: 8.78mlTrain batch 21/32 - 144.6ms/batch - loss: 0.54477 - diff: 8.72mlTrain batch 22/32 - 205.9ms/batch - loss: 0.53842 - diff: 8.61mlTrain batch 23/32 - 147.4ms/batch - loss: 0.52759 - diff: 8.44mlTrain batch 24/32 - 158.1ms/batch - loss: 0.53640 - diff: 8.58mlTrain batch 25/32 - 144.9ms/batch - loss: 0.52931 - diff: 8.47mlTrain batch 26/32 - 162.7ms/batch - loss: 0.53033 - diff: 8.49mlTrain batch 27/32 - 170.4ms/batch - loss: 0.52447 - diff: 8.39mlTrain batch 28/32 - 129.7ms/batch - loss: 0.52200 - diff: 8.35mlTrain batch 29/32 - 134.9ms/batch - loss: 0.52551 - diff: 8.41mlTrain batch 30/32 - 139.6ms/batch - loss: 0.52173 - diff: 8.35mlTrain batch 31/32 - 135.8ms/batch - loss: 0.52686 - diff: 8.43mlTrain batch 32/32 - 133.0ms/batch - loss: 0.54070 - diff: 8.43mlTrain batch 32/32 - 17.7s 133.0ms/batch - loss: 0.54070 - diff: 8.43ml
Test 1.0s: val_loss: 0.95026 - diff: 14.46ml

Epoch 120: current best loss = 0.89711, at epoch 110
Train batch 1/32 - 210.6ms/batch - loss: 0.69610 - diff: 11.14mlTrain batch 2/32 - 168.4ms/batch - loss: 0.64332 - diff: 10.29mlTrain batch 3/32 - 190.5ms/batch - loss: 0.76695 - diff: 12.27mlTrain batch 4/32 - 167.0ms/batch - loss: 0.66348 - diff: 10.62mlTrain batch 5/32 - 164.1ms/batch - loss: 0.63858 - diff: 10.22mlTrain batch 6/32 - 165.5ms/batch - loss: 0.63741 - diff: 10.20mlTrain batch 7/32 - 190.1ms/batch - loss: 0.65206 - diff: 10.43mlTrain batch 8/32 - 190.9ms/batch - loss: 0.67917 - diff: 10.87mlTrain batch 9/32 - 181.9ms/batch - loss: 0.65219 - diff: 10.44mlTrain batch 10/32 - 179.8ms/batch - loss: 0.62350 - diff: 9.98mlTrain batch 11/32 - 187.9ms/batch - loss: 0.61376 - diff: 9.82mlTrain batch 12/32 - 135.8ms/batch - loss: 0.60651 - diff: 9.70mlTrain batch 13/32 - 191.1ms/batch - loss: 0.62110 - diff: 9.94mlTrain batch 14/32 - 153.2ms/batch - loss: 0.61387 - diff: 9.82mlTrain batch 15/32 - 140.5ms/batch - loss: 0.59589 - diff: 9.53mlTrain batch 16/32 - 171.1ms/batch - loss: 0.59001 - diff: 9.44mlTrain batch 17/32 - 166.7ms/batch - loss: 0.57667 - diff: 9.23mlTrain batch 18/32 - 145.8ms/batch - loss: 0.56356 - diff: 9.02mlTrain batch 19/32 - 168.8ms/batch - loss: 0.55727 - diff: 8.92mlTrain batch 20/32 - 158.4ms/batch - loss: 0.55041 - diff: 8.81mlTrain batch 21/32 - 201.8ms/batch - loss: 0.55819 - diff: 8.93mlTrain batch 22/32 - 137.6ms/batch - loss: 0.56158 - diff: 8.99mlTrain batch 23/32 - 129.1ms/batch - loss: 0.56449 - diff: 9.03mlTrain batch 24/32 - 167.3ms/batch - loss: 0.55537 - diff: 8.89mlTrain batch 25/32 - 122.4ms/batch - loss: 0.55766 - diff: 8.92mlTrain batch 26/32 - 157.0ms/batch - loss: 0.55747 - diff: 8.92mlTrain batch 27/32 - 158.1ms/batch - loss: 0.55205 - diff: 8.83mlTrain batch 28/32 - 201.4ms/batch - loss: 0.55211 - diff: 8.83mlTrain batch 29/32 - 229.0ms/batch - loss: 0.55522 - diff: 8.88mlTrain batch 30/32 - 162.9ms/batch - loss: 0.55896 - diff: 8.94mlTrain batch 31/32 - 218.1ms/batch - loss: 0.55821 - diff: 8.93mlTrain batch 32/32 - 202.7ms/batch - loss: 0.56629 - diff: 8.91mlTrain batch 32/32 - 17.2s 202.7ms/batch - loss: 0.56629 - diff: 8.91ml
Test 1.1s: val_loss: 1.02799 - diff: 15.65ml

Epoch 121: current best loss = 0.89711, at epoch 110
Train batch 1/32 - 221.9ms/batch - loss: 0.45918 - diff: 7.35mlTrain batch 2/32 - 172.4ms/batch - loss: 0.48354 - diff: 7.74mlTrain batch 3/32 - 151.5ms/batch - loss: 0.44393 - diff: 7.10mlTrain batch 4/32 - 135.9ms/batch - loss: 0.42953 - diff: 6.87mlTrain batch 5/32 - 192.3ms/batch - loss: 0.45121 - diff: 7.22mlTrain batch 6/32 - 148.8ms/batch - loss: 0.43303 - diff: 6.93mlTrain batch 7/32 - 161.1ms/batch - loss: 0.44574 - diff: 7.13mlTrain batch 8/32 - 154.8ms/batch - loss: 0.43394 - diff: 6.94mlTrain batch 9/32 - 169.8ms/batch - loss: 0.44772 - diff: 7.16mlTrain batch 10/32 - 164.8ms/batch - loss: 0.43623 - diff: 6.98mlTrain batch 11/32 - 158.5ms/batch - loss: 0.42607 - diff: 6.82mlTrain batch 12/32 - 188.6ms/batch - loss: 0.43460 - diff: 6.95mlTrain batch 13/32 - 160.4ms/batch - loss: 0.42484 - diff: 6.80mlTrain batch 14/32 - 130.9ms/batch - loss: 0.41796 - diff: 6.69mlTrain batch 15/32 - 186.4ms/batch - loss: 0.46046 - diff: 7.37mlTrain batch 16/32 - 119.2ms/batch - loss: 0.46077 - diff: 7.37mlTrain batch 17/32 - 139.5ms/batch - loss: 0.47958 - diff: 7.67mlTrain batch 18/32 - 131.2ms/batch - loss: 0.50414 - diff: 8.07mlTrain batch 19/32 - 149.6ms/batch - loss: 0.51031 - diff: 8.16mlTrain batch 20/32 - 127.5ms/batch - loss: 0.50535 - diff: 8.09mlTrain batch 21/32 - 159.8ms/batch - loss: 0.50036 - diff: 8.01mlTrain batch 22/32 - 174.1ms/batch - loss: 0.50760 - diff: 8.12mlTrain batch 23/32 - 157.8ms/batch - loss: 0.50405 - diff: 8.06mlTrain batch 24/32 - 178.3ms/batch - loss: 0.50046 - diff: 8.01mlTrain batch 25/32 - 146.6ms/batch - loss: 0.50304 - diff: 8.05mlTrain batch 26/32 - 123.3ms/batch - loss: 0.49193 - diff: 7.87mlTrain batch 27/32 - 122.8ms/batch - loss: 0.49100 - diff: 7.86mlTrain batch 28/32 - 120.7ms/batch - loss: 0.49301 - diff: 7.89mlTrain batch 29/32 - 172.0ms/batch - loss: 0.48530 - diff: 7.76mlTrain batch 30/32 - 178.8ms/batch - loss: 0.48526 - diff: 7.76mlTrain batch 31/32 - 115.9ms/batch - loss: 0.49150 - diff: 7.86mlTrain batch 32/32 - 110.6ms/batch - loss: 0.54001 - diff: 8.01mlTrain batch 32/32 - 17.0s 110.6ms/batch - loss: 0.54001 - diff: 8.01ml
Test 1.0s: val_loss: 0.97779 - diff: 15.13ml
Epoch   122: reducing learning rate of group 0 to 6.2500e-05.

Epoch 122: current best loss = 0.89711, at epoch 110
Train batch 1/32 - 177.9ms/batch - loss: 0.95738 - diff: 15.32mlTrain batch 2/32 - 202.0ms/batch - loss: 0.70178 - diff: 11.23mlTrain batch 3/32 - 172.3ms/batch - loss: 0.63815 - diff: 10.21mlTrain batch 4/32 - 145.4ms/batch - loss: 0.59477 - diff: 9.52mlTrain batch 5/32 - 181.6ms/batch - loss: 0.57852 - diff: 9.26mlTrain batch 6/32 - 172.5ms/batch - loss: 0.60027 - diff: 9.60mlTrain batch 7/32 - 164.2ms/batch - loss: 0.59075 - diff: 9.45mlTrain batch 8/32 - 147.9ms/batch - loss: 0.56282 - diff: 9.01mlTrain batch 9/32 - 137.2ms/batch - loss: 0.54427 - diff: 8.71mlTrain batch 10/32 - 136.9ms/batch - loss: 0.55073 - diff: 8.81mlTrain batch 11/32 - 135.6ms/batch - loss: 0.55075 - diff: 8.81mlTrain batch 12/32 - 136.3ms/batch - loss: 0.54651 - diff: 8.74mlTrain batch 13/32 - 140.9ms/batch - loss: 0.54023 - diff: 8.64mlTrain batch 14/32 - 174.8ms/batch - loss: 0.52793 - diff: 8.45mlTrain batch 15/32 - 200.2ms/batch - loss: 0.54479 - diff: 8.72mlTrain batch 16/32 - 161.0ms/batch - loss: 0.53316 - diff: 8.53mlTrain batch 17/32 - 125.0ms/batch - loss: 0.52971 - diff: 8.48mlTrain batch 18/32 - 148.9ms/batch - loss: 0.51860 - diff: 8.30mlTrain batch 19/32 - 137.7ms/batch - loss: 0.52062 - diff: 8.33mlTrain batch 20/32 - 196.4ms/batch - loss: 0.51512 - diff: 8.24mlTrain batch 21/32 - 138.6ms/batch - loss: 0.50357 - diff: 8.06mlTrain batch 22/32 - 139.9ms/batch - loss: 0.49987 - diff: 8.00mlTrain batch 23/32 - 174.5ms/batch - loss: 0.49717 - diff: 7.95mlTrain batch 24/32 - 144.9ms/batch - loss: 0.50292 - diff: 8.05mlTrain batch 25/32 - 118.9ms/batch - loss: 0.50298 - diff: 8.05mlTrain batch 26/32 - 123.3ms/batch - loss: 0.51443 - diff: 8.23mlTrain batch 27/32 - 153.2ms/batch - loss: 0.50586 - diff: 8.09mlTrain batch 28/32 - 110.0ms/batch - loss: 0.50409 - diff: 8.07mlTrain batch 29/32 - 171.8ms/batch - loss: 0.50264 - diff: 8.04mlTrain batch 30/32 - 190.8ms/batch - loss: 0.50435 - diff: 8.07mlTrain batch 31/32 - 133.7ms/batch - loss: 0.50748 - diff: 8.12mlTrain batch 32/32 - 176.2ms/batch - loss: 0.51486 - diff: 8.10mlTrain batch 32/32 - 17.0s 176.2ms/batch - loss: 0.51486 - diff: 8.10ml
Test 1.0s: val_loss: 0.95033 - diff: 14.32ml

Epoch 123: current best loss = 0.89711, at epoch 110
Train batch 1/32 - 173.7ms/batch - loss: 0.42087 - diff: 6.73mlTrain batch 2/32 - 141.6ms/batch - loss: 0.48933 - diff: 7.83mlTrain batch 3/32 - 173.6ms/batch - loss: 0.52090 - diff: 8.33mlTrain batch 4/32 - 174.5ms/batch - loss: 0.56266 - diff: 9.00mlTrain batch 5/32 - 186.1ms/batch - loss: 0.55694 - diff: 8.91mlTrain batch 6/32 - 205.6ms/batch - loss: 0.63377 - diff: 10.14mlTrain batch 7/32 - 178.5ms/batch - loss: 0.59073 - diff: 9.45mlTrain batch 8/32 - 180.0ms/batch - loss: 0.59252 - diff: 9.48mlTrain batch 9/32 - 149.2ms/batch - loss: 0.63988 - diff: 10.24mlTrain batch 10/32 - 189.1ms/batch - loss: 0.68329 - diff: 10.93mlTrain batch 11/32 - 141.5ms/batch - loss: 0.65563 - diff: 10.49mlTrain batch 12/32 - 166.2ms/batch - loss: 0.64122 - diff: 10.26mlTrain batch 13/32 - 198.1ms/batch - loss: 0.62632 - diff: 10.02mlTrain batch 14/32 - 179.1ms/batch - loss: 0.61165 - diff: 9.79mlTrain batch 15/32 - 151.8ms/batch - loss: 0.59860 - diff: 9.58mlTrain batch 16/32 - 185.5ms/batch - loss: 0.59082 - diff: 9.45mlTrain batch 17/32 - 168.1ms/batch - loss: 0.58106 - diff: 9.30mlTrain batch 18/32 - 163.4ms/batch - loss: 0.59325 - diff: 9.49mlTrain batch 19/32 - 173.3ms/batch - loss: 0.59645 - diff: 9.54mlTrain batch 20/32 - 165.0ms/batch - loss: 0.58733 - diff: 9.40mlTrain batch 21/32 - 154.9ms/batch - loss: 0.58022 - diff: 9.28mlTrain batch 22/32 - 139.1ms/batch - loss: 0.56969 - diff: 9.12mlTrain batch 23/32 - 169.6ms/batch - loss: 0.56628 - diff: 9.06mlTrain batch 24/32 - 146.7ms/batch - loss: 0.58663 - diff: 9.39mlTrain batch 25/32 - 159.8ms/batch - loss: 0.58025 - diff: 9.28mlTrain batch 26/32 - 160.4ms/batch - loss: 0.57840 - diff: 9.25mlTrain batch 27/32 - 206.6ms/batch - loss: 0.57690 - diff: 9.23mlTrain batch 28/32 - 198.3ms/batch - loss: 0.57913 - diff: 9.27mlTrain batch 29/32 - 166.8ms/batch - loss: 0.57421 - diff: 9.19mlTrain batch 30/32 - 133.2ms/batch - loss: 0.57015 - diff: 9.12mlTrain batch 31/32 - 197.1ms/batch - loss: 0.56455 - diff: 9.03mlTrain batch 32/32 - 203.2ms/batch - loss: 0.57729 - diff: 9.03mlTrain batch 32/32 - 18.4s 203.2ms/batch - loss: 0.57729 - diff: 9.03ml
Test 1.2s: val_loss: 0.99962 - diff: 15.37ml

Epoch 124: current best loss = 0.89711, at epoch 110
Train batch 1/32 - 168.5ms/batch - loss: 0.45598 - diff: 7.30mlTrain batch 2/32 - 191.4ms/batch - loss: 0.59988 - diff: 9.60mlTrain batch 3/32 - 143.8ms/batch - loss: 0.61308 - diff: 9.81mlTrain batch 4/32 - 153.3ms/batch - loss: 0.62108 - diff: 9.94mlTrain batch 5/32 - 165.1ms/batch - loss: 0.59306 - diff: 9.49mlTrain batch 6/32 - 116.2ms/batch - loss: 0.60045 - diff: 9.61mlTrain batch 7/32 - 137.8ms/batch - loss: 0.56457 - diff: 9.03mlTrain batch 8/32 - 132.9ms/batch - loss: 0.55539 - diff: 8.89mlTrain batch 9/32 - 179.0ms/batch - loss: 0.53441 - diff: 8.55mlTrain batch 10/32 - 188.9ms/batch - loss: 0.51734 - diff: 8.28mlTrain batch 11/32 - 174.3ms/batch - loss: 0.52239 - diff: 8.36mlTrain batch 12/32 - 116.9ms/batch - loss: 0.50781 - diff: 8.13mlTrain batch 13/32 - 106.5ms/batch - loss: 0.51113 - diff: 8.18mlTrain batch 14/32 - 170.2ms/batch - loss: 0.49984 - diff: 8.00mlTrain batch 15/32 - 175.4ms/batch - loss: 0.50195 - diff: 8.03mlTrain batch 16/32 - 158.0ms/batch - loss: 0.49961 - diff: 7.99mlTrain batch 17/32 - 176.2ms/batch - loss: 0.49296 - diff: 7.89mlTrain batch 18/32 - 175.8ms/batch - loss: 0.48961 - diff: 7.83mlTrain batch 19/32 - 218.9ms/batch - loss: 0.49859 - diff: 7.98mlTrain batch 20/32 - 208.3ms/batch - loss: 0.50990 - diff: 8.16mlTrain batch 21/32 - 160.7ms/batch - loss: 0.50400 - diff: 8.06mlTrain batch 22/32 - 153.6ms/batch - loss: 0.50018 - diff: 8.00mlTrain batch 23/32 - 187.6ms/batch - loss: 0.50440 - diff: 8.07mlTrain batch 24/32 - 134.6ms/batch - loss: 0.50314 - diff: 8.05mlTrain batch 25/32 - 156.4ms/batch - loss: 0.49925 - diff: 7.99mlTrain batch 26/32 - 165.3ms/batch - loss: 0.49557 - diff: 7.93mlTrain batch 27/32 - 201.2ms/batch - loss: 0.50725 - diff: 8.12mlTrain batch 28/32 - 165.3ms/batch - loss: 0.51782 - diff: 8.29mlTrain batch 29/32 - 143.9ms/batch - loss: 0.51481 - diff: 8.24mlTrain batch 30/32 - 111.9ms/batch - loss: 0.51191 - diff: 8.19mlTrain batch 31/32 - 146.7ms/batch - loss: 0.51984 - diff: 8.32mlTrain batch 32/32 - 101.3ms/batch - loss: 0.52484 - diff: 8.29mlTrain batch 32/32 - 18.4s 101.3ms/batch - loss: 0.52484 - diff: 8.29ml
Test 1.2s: val_loss: 0.97861 - diff: 14.91ml

Epoch 125: current best loss = 0.89711, at epoch 110
Train batch 1/32 - 127.0ms/batch - loss: 0.48557 - diff: 7.77mlTrain batch 2/32 - 164.2ms/batch - loss: 0.37096 - diff: 5.94mlTrain batch 3/32 - 168.1ms/batch - loss: 0.38853 - diff: 6.22mlTrain batch 4/32 - 184.5ms/batch - loss: 0.39387 - diff: 6.30mlTrain batch 5/32 - 186.9ms/batch - loss: 0.40908 - diff: 6.55mlTrain batch 6/32 - 189.0ms/batch - loss: 0.41521 - diff: 6.64mlTrain batch 7/32 - 172.0ms/batch - loss: 0.41621 - diff: 6.66mlTrain batch 8/32 - 179.7ms/batch - loss: 0.40862 - diff: 6.54mlTrain batch 9/32 - 168.7ms/batch - loss: 0.40228 - diff: 6.44mlTrain batch 10/32 - 150.3ms/batch - loss: 0.40951 - diff: 6.55mlTrain batch 11/32 - 150.4ms/batch - loss: 0.39779 - diff: 6.36mlTrain batch 12/32 - 199.9ms/batch - loss: 0.39205 - diff: 6.27mlTrain batch 13/32 - 196.8ms/batch - loss: 0.44264 - diff: 7.08mlTrain batch 14/32 - 179.3ms/batch - loss: 0.44031 - diff: 7.04mlTrain batch 15/32 - 156.8ms/batch - loss: 0.44211 - diff: 7.07mlTrain batch 16/32 - 183.8ms/batch - loss: 0.43420 - diff: 6.95mlTrain batch 17/32 - 159.9ms/batch - loss: 0.43928 - diff: 7.03mlTrain batch 18/32 - 169.7ms/batch - loss: 0.43491 - diff: 6.96mlTrain batch 19/32 - 178.2ms/batch - loss: 0.43401 - diff: 6.94mlTrain batch 20/32 - 173.6ms/batch - loss: 0.43014 - diff: 6.88mlTrain batch 21/32 - 144.4ms/batch - loss: 0.43528 - diff: 6.96mlTrain batch 22/32 - 108.7ms/batch - loss: 0.44388 - diff: 7.10mlTrain batch 23/32 - 155.0ms/batch - loss: 0.45094 - diff: 7.22mlTrain batch 24/32 - 122.8ms/batch - loss: 0.44753 - diff: 7.16mlTrain batch 25/32 - 160.3ms/batch - loss: 0.44099 - diff: 7.06mlTrain batch 26/32 - 170.1ms/batch - loss: 0.43944 - diff: 7.03mlTrain batch 27/32 - 149.0ms/batch - loss: 0.43404 - diff: 6.94mlTrain batch 28/32 - 179.6ms/batch - loss: 0.44057 - diff: 7.05mlTrain batch 29/32 - 160.2ms/batch - loss: 0.44166 - diff: 7.07mlTrain batch 30/32 - 140.9ms/batch - loss: 0.44813 - diff: 7.17mlTrain batch 31/32 - 106.3ms/batch - loss: 0.46094 - diff: 7.38mlTrain batch 32/32 - 91.6ms/batch - loss: 0.46984 - diff: 7.37mlTrain batch 32/32 - 17.2s 91.6ms/batch - loss: 0.46984 - diff: 7.37ml
Test 0.9s: val_loss: 0.94863 - diff: 14.31ml

Epoch 126: current best loss = 0.89711, at epoch 110
Train batch 1/32 - 123.3ms/batch - loss: 0.56573 - diff: 9.05mlTrain batch 2/32 - 143.6ms/batch - loss: 0.47962 - diff: 7.67mlTrain batch 3/32 - 131.4ms/batch - loss: 0.46741 - diff: 7.48mlTrain batch 4/32 - 134.8ms/batch - loss: 0.48421 - diff: 7.75mlTrain batch 5/32 - 106.0ms/batch - loss: 0.48327 - diff: 7.73mlTrain batch 6/32 - 141.9ms/batch - loss: 0.47694 - diff: 7.63mlTrain batch 7/32 - 129.0ms/batch - loss: 0.47175 - diff: 7.55mlTrain batch 8/32 - 103.9ms/batch - loss: 0.45904 - diff: 7.34mlTrain batch 9/32 - 133.3ms/batch - loss: 0.46987 - diff: 7.52mlTrain batch 10/32 - 109.1ms/batch - loss: 0.48881 - diff: 7.82mlTrain batch 11/32 - 145.7ms/batch - loss: 0.48517 - diff: 7.76mlTrain batch 12/32 - 123.8ms/batch - loss: 0.47734 - diff: 7.64mlTrain batch 13/32 - 140.1ms/batch - loss: 0.47012 - diff: 7.52mlTrain batch 14/32 - 115.5ms/batch - loss: 0.49751 - diff: 7.96mlTrain batch 15/32 - 147.7ms/batch - loss: 0.49344 - diff: 7.89mlTrain batch 16/32 - 136.0ms/batch - loss: 0.49928 - diff: 7.99mlTrain batch 17/32 - 151.9ms/batch - loss: 0.48534 - diff: 7.77mlTrain batch 18/32 - 165.9ms/batch - loss: 0.47634 - diff: 7.62mlTrain batch 19/32 - 205.6ms/batch - loss: 0.48565 - diff: 7.77mlTrain batch 20/32 - 141.1ms/batch - loss: 0.47482 - diff: 7.60mlTrain batch 21/32 - 150.5ms/batch - loss: 0.47678 - diff: 7.63mlTrain batch 22/32 - 165.3ms/batch - loss: 0.47152 - diff: 7.54mlTrain batch 23/32 - 152.7ms/batch - loss: 0.49127 - diff: 7.86mlTrain batch 24/32 - 201.5ms/batch - loss: 0.48893 - diff: 7.82mlTrain batch 25/32 - 156.6ms/batch - loss: 0.48937 - diff: 7.83mlTrain batch 26/32 - 119.8ms/batch - loss: 0.49075 - diff: 7.85mlTrain batch 27/32 - 172.5ms/batch - loss: 0.48378 - diff: 7.74mlTrain batch 28/32 - 128.8ms/batch - loss: 0.48311 - diff: 7.73mlTrain batch 29/32 - 154.6ms/batch - loss: 0.49062 - diff: 7.85mlTrain batch 30/32 - 179.1ms/batch - loss: 0.48430 - diff: 7.75mlTrain batch 31/32 - 117.7ms/batch - loss: 0.48121 - diff: 7.70mlTrain batch 32/32 - 134.2ms/batch - loss: 0.49954 - diff: 7.73mlTrain batch 32/32 - 16.1s 134.2ms/batch - loss: 0.49954 - diff: 7.73ml
Test 1.2s: val_loss: 0.92603 - diff: 14.38ml

Epoch 127: current best loss = 0.89711, at epoch 110
Train batch 1/32 - 169.6ms/batch - loss: 0.54428 - diff: 8.71mlTrain batch 2/32 - 223.2ms/batch - loss: 0.48758 - diff: 7.80mlTrain batch 3/32 - 119.4ms/batch - loss: 0.46656 - diff: 7.46mlTrain batch 4/32 - 107.1ms/batch - loss: 0.45317 - diff: 7.25mlTrain batch 5/32 - 156.6ms/batch - loss: 0.45725 - diff: 7.32mlTrain batch 6/32 - 107.8ms/batch - loss: 0.43401 - diff: 6.94mlTrain batch 7/32 - 166.0ms/batch - loss: 0.44510 - diff: 7.12mlTrain batch 8/32 - 174.9ms/batch - loss: 0.44022 - diff: 7.04mlTrain batch 9/32 - 168.6ms/batch - loss: 0.44459 - diff: 7.11mlTrain batch 10/32 - 197.7ms/batch - loss: 0.43996 - diff: 7.04mlTrain batch 11/32 - 181.7ms/batch - loss: 0.45548 - diff: 7.29mlTrain batch 12/32 - 191.3ms/batch - loss: 0.43899 - diff: 7.02mlTrain batch 13/32 - 187.6ms/batch - loss: 0.46156 - diff: 7.38mlTrain batch 14/32 - 169.3ms/batch - loss: 0.46304 - diff: 7.41mlTrain batch 15/32 - 121.8ms/batch - loss: 0.45952 - diff: 7.35mlTrain batch 16/32 - 181.0ms/batch - loss: 0.47041 - diff: 7.53mlTrain batch 17/32 - 164.0ms/batch - loss: 0.48141 - diff: 7.70mlTrain batch 18/32 - 156.4ms/batch - loss: 0.47268 - diff: 7.56mlTrain batch 19/32 - 176.2ms/batch - loss: 0.46407 - diff: 7.43mlTrain batch 20/32 - 184.9ms/batch - loss: 0.47297 - diff: 7.57mlTrain batch 21/32 - 137.2ms/batch - loss: 0.47015 - diff: 7.52mlTrain batch 22/32 - 174.6ms/batch - loss: 0.46744 - diff: 7.48mlTrain batch 23/32 - 163.5ms/batch - loss: 0.46409 - diff: 7.43mlTrain batch 24/32 - 128.2ms/batch - loss: 0.46069 - diff: 7.37mlTrain batch 25/32 - 161.7ms/batch - loss: 0.45469 - diff: 7.28mlTrain batch 26/32 - 188.8ms/batch - loss: 0.46861 - diff: 7.50mlTrain batch 27/32 - 178.6ms/batch - loss: 0.46501 - diff: 7.44mlTrain batch 28/32 - 195.1ms/batch - loss: 0.45832 - diff: 7.33mlTrain batch 29/32 - 143.6ms/batch - loss: 0.45842 - diff: 7.33mlTrain batch 30/32 - 133.2ms/batch - loss: 0.45758 - diff: 7.32mlTrain batch 31/32 - 163.7ms/batch - loss: 0.46132 - diff: 7.38mlTrain batch 32/32 - 134.3ms/batch - loss: 0.51909 - diff: 7.57mlTrain batch 32/32 - 16.9s 134.3ms/batch - loss: 0.51909 - diff: 7.57ml
Test 1.0s: val_loss: 0.92230 - diff: 14.34ml

Epoch 128: current best loss = 0.89711, at epoch 110
Train batch 1/32 - 188.7ms/batch - loss: 0.38893 - diff: 6.22mlTrain batch 2/32 - 164.2ms/batch - loss: 0.34398 - diff: 5.50mlTrain batch 3/32 - 143.6ms/batch - loss: 0.42303 - diff: 6.77mlTrain batch 4/32 - 180.0ms/batch - loss: 0.40256 - diff: 6.44mlTrain batch 5/32 - 140.8ms/batch - loss: 0.43681 - diff: 6.99mlTrain batch 6/32 - 183.2ms/batch - loss: 0.43127 - diff: 6.90mlTrain batch 7/32 - 187.5ms/batch - loss: 0.43782 - diff: 7.01mlTrain batch 8/32 - 191.6ms/batch - loss: 0.43759 - diff: 7.00mlTrain batch 9/32 - 161.1ms/batch - loss: 0.43479 - diff: 6.96mlTrain batch 10/32 - 229.9ms/batch - loss: 0.44855 - diff: 7.18mlTrain batch 11/32 - 178.2ms/batch - loss: 0.45584 - diff: 7.29mlTrain batch 12/32 - 212.2ms/batch - loss: 0.45491 - diff: 7.28mlTrain batch 13/32 - 154.0ms/batch - loss: 0.44125 - diff: 7.06mlTrain batch 14/32 - 214.5ms/batch - loss: 0.43732 - diff: 7.00mlTrain batch 15/32 - 163.0ms/batch - loss: 0.47068 - diff: 7.53mlTrain batch 16/32 - 131.6ms/batch - loss: 0.46195 - diff: 7.39mlTrain batch 17/32 - 136.6ms/batch - loss: 0.45710 - diff: 7.31mlTrain batch 18/32 - 119.2ms/batch - loss: 0.45003 - diff: 7.20mlTrain batch 19/32 - 170.0ms/batch - loss: 0.44555 - diff: 7.13mlTrain batch 20/32 - 170.2ms/batch - loss: 0.44299 - diff: 7.09mlTrain batch 21/32 - 127.6ms/batch - loss: 0.43808 - diff: 7.01mlTrain batch 22/32 - 172.3ms/batch - loss: 0.43455 - diff: 6.95mlTrain batch 23/32 - 168.6ms/batch - loss: 0.45763 - diff: 7.32mlTrain batch 24/32 - 111.1ms/batch - loss: 0.47036 - diff: 7.53mlTrain batch 25/32 - 130.1ms/batch - loss: 0.47248 - diff: 7.56mlTrain batch 26/32 - 111.7ms/batch - loss: 0.46929 - diff: 7.51mlTrain batch 27/32 - 153.4ms/batch - loss: 0.46404 - diff: 7.42mlTrain batch 28/32 - 111.9ms/batch - loss: 0.46446 - diff: 7.43mlTrain batch 29/32 - 144.5ms/batch - loss: 0.47099 - diff: 7.54mlTrain batch 30/32 - 200.0ms/batch - loss: 0.46925 - diff: 7.51mlTrain batch 31/32 - 127.2ms/batch - loss: 0.46950 - diff: 7.51mlTrain batch 32/32 - 160.2ms/batch - loss: 0.47629 - diff: 7.49mlTrain batch 32/32 - 16.8s 160.2ms/batch - loss: 0.47629 - diff: 7.49ml
Test 1.1s: val_loss: 0.99809 - diff: 15.10ml

Epoch 129: current best loss = 0.89711, at epoch 110
Train batch 1/32 - 160.8ms/batch - loss: 1.41570 - diff: 22.65mlTrain batch 2/32 - 148.2ms/batch - loss: 0.93971 - diff: 15.04mlTrain batch 3/32 - 130.4ms/batch - loss: 0.81986 - diff: 13.12mlTrain batch 4/32 - 117.5ms/batch - loss: 0.70726 - diff: 11.32mlTrain batch 5/32 - 162.2ms/batch - loss: 0.65260 - diff: 10.44mlTrain batch 6/32 - 213.4ms/batch - loss: 0.62872 - diff: 10.06mlTrain batch 7/32 - 208.7ms/batch - loss: 0.61640 - diff: 9.86mlTrain batch 8/32 - 210.2ms/batch - loss: 0.58448 - diff: 9.35mlTrain batch 9/32 - 187.2ms/batch - loss: 0.58488 - diff: 9.36mlTrain batch 10/32 - 196.8ms/batch - loss: 0.55798 - diff: 8.93mlTrain batch 11/32 - 192.1ms/batch - loss: 0.55508 - diff: 8.88mlTrain batch 12/32 - 165.9ms/batch - loss: 0.57053 - diff: 9.13mlTrain batch 13/32 - 143.6ms/batch - loss: 0.55970 - diff: 8.96mlTrain batch 14/32 - 137.6ms/batch - loss: 0.54812 - diff: 8.77mlTrain batch 15/32 - 176.9ms/batch - loss: 0.54670 - diff: 8.75mlTrain batch 16/32 - 139.6ms/batch - loss: 0.53739 - diff: 8.60mlTrain batch 17/32 - 135.9ms/batch - loss: 0.52788 - diff: 8.45mlTrain batch 18/32 - 107.4ms/batch - loss: 0.52697 - diff: 8.43mlTrain batch 19/32 - 126.5ms/batch - loss: 0.52264 - diff: 8.36mlTrain batch 20/32 - 156.4ms/batch - loss: 0.51622 - diff: 8.26mlTrain batch 21/32 - 202.8ms/batch - loss: 0.52401 - diff: 8.38mlTrain batch 22/32 - 146.0ms/batch - loss: 0.51981 - diff: 8.32mlTrain batch 23/32 - 123.7ms/batch - loss: 0.52431 - diff: 8.39mlTrain batch 24/32 - 134.9ms/batch - loss: 0.51971 - diff: 8.32mlTrain batch 25/32 - 166.6ms/batch - loss: 0.52137 - diff: 8.34mlTrain batch 26/32 - 177.7ms/batch - loss: 0.51160 - diff: 8.19mlTrain batch 27/32 - 157.6ms/batch - loss: 0.50999 - diff: 8.16mlTrain batch 28/32 - 132.8ms/batch - loss: 0.50673 - diff: 8.11mlTrain batch 29/32 - 173.4ms/batch - loss: 0.50289 - diff: 8.05mlTrain batch 30/32 - 179.8ms/batch - loss: 0.49716 - diff: 7.95mlTrain batch 31/32 - 117.5ms/batch - loss: 0.49175 - diff: 7.87mlTrain batch 32/32 - 110.0ms/batch - loss: 0.50766 - diff: 7.88mlTrain batch 32/32 - 16.5s 110.0ms/batch - loss: 0.50766 - diff: 7.88ml
Test 1.1s: val_loss: 0.93435 - diff: 14.75ml

Epoch 130: current best loss = 0.89711, at epoch 110
Train batch 1/32 - 179.9ms/batch - loss: 0.75801 - diff: 12.13mlTrain batch 2/32 - 189.6ms/batch - loss: 0.58238 - diff: 9.32mlTrain batch 3/32 - 197.7ms/batch - loss: 0.53568 - diff: 8.57mlTrain batch 4/32 - 213.9ms/batch - loss: 0.49478 - diff: 7.92mlTrain batch 5/32 - 166.2ms/batch - loss: 0.46993 - diff: 7.52mlTrain batch 6/32 - 171.1ms/batch - loss: 0.47748 - diff: 7.64mlTrain batch 7/32 - 113.6ms/batch - loss: 0.46717 - diff: 7.47mlTrain batch 8/32 - 132.9ms/batch - loss: 0.44718 - diff: 7.15mlTrain batch 9/32 - 140.5ms/batch - loss: 0.44237 - diff: 7.08mlTrain batch 10/32 - 152.6ms/batch - loss: 0.47821 - diff: 7.65mlTrain batch 11/32 - 156.3ms/batch - loss: 0.48156 - diff: 7.70mlTrain batch 12/32 - 145.9ms/batch - loss: 0.49203 - diff: 7.87mlTrain batch 13/32 - 151.1ms/batch - loss: 0.50443 - diff: 8.07mlTrain batch 14/32 - 147.4ms/batch - loss: 0.50112 - diff: 8.02mlTrain batch 15/32 - 161.9ms/batch - loss: 0.49439 - diff: 7.91mlTrain batch 16/32 - 137.3ms/batch - loss: 0.48751 - diff: 7.80mlTrain batch 17/32 - 164.3ms/batch - loss: 0.48238 - diff: 7.72mlTrain batch 18/32 - 139.6ms/batch - loss: 0.47205 - diff: 7.55mlTrain batch 19/32 - 192.9ms/batch - loss: 0.47246 - diff: 7.56mlTrain batch 20/32 - 116.8ms/batch - loss: 0.47399 - diff: 7.58mlTrain batch 21/32 - 170.9ms/batch - loss: 0.46708 - diff: 7.47mlTrain batch 22/32 - 141.9ms/batch - loss: 0.46138 - diff: 7.38mlTrain batch 23/32 - 177.8ms/batch - loss: 0.47847 - diff: 7.66mlTrain batch 24/32 - 117.4ms/batch - loss: 0.46807 - diff: 7.49mlTrain batch 25/32 - 119.3ms/batch - loss: 0.47063 - diff: 7.53mlTrain batch 26/32 - 179.5ms/batch - loss: 0.46887 - diff: 7.50mlTrain batch 27/32 - 178.3ms/batch - loss: 0.46383 - diff: 7.42mlTrain batch 28/32 - 158.9ms/batch - loss: 0.46089 - diff: 7.37mlTrain batch 29/32 - 174.4ms/batch - loss: 0.45504 - diff: 7.28mlTrain batch 30/32 - 191.4ms/batch - loss: 0.45663 - diff: 7.31mlTrain batch 31/32 - 158.8ms/batch - loss: 0.45869 - diff: 7.34mlTrain batch 32/32 - 135.4ms/batch - loss: 0.47410 - diff: 7.36mlTrain batch 32/32 - 17.0s 135.4ms/batch - loss: 0.47410 - diff: 7.36ml
Test 1.1s: val_loss: 0.95134 - diff: 14.56ml

Epoch 131: current best loss = 0.89711, at epoch 110
Train batch 1/32 - 151.9ms/batch - loss: 0.82610 - diff: 13.22mlTrain batch 2/32 - 149.3ms/batch - loss: 0.66324 - diff: 10.61mlTrain batch 3/32 - 128.8ms/batch - loss: 0.58954 - diff: 9.43mlTrain batch 4/32 - 163.5ms/batch - loss: 0.52380 - diff: 8.38mlTrain batch 5/32 - 161.3ms/batch - loss: 0.51411 - diff: 8.23mlTrain batch 6/32 - 178.3ms/batch - loss: 0.51113 - diff: 8.18mlTrain batch 7/32 - 173.9ms/batch - loss: 0.50854 - diff: 8.14mlTrain batch 8/32 - 117.2ms/batch - loss: 0.50418 - diff: 8.07mlTrain batch 9/32 - 127.3ms/batch - loss: 0.49969 - diff: 8.00mlTrain batch 10/32 - 146.8ms/batch - loss: 0.48955 - diff: 7.83mlTrain batch 11/32 - 184.6ms/batch - loss: 0.47700 - diff: 7.63mlTrain batch 12/32 - 184.1ms/batch - loss: 0.46760 - diff: 7.48mlTrain batch 13/32 - 125.3ms/batch - loss: 0.45527 - diff: 7.28mlTrain batch 14/32 - 132.9ms/batch - loss: 0.45090 - diff: 7.21mlTrain batch 15/32 - 145.2ms/batch - loss: 0.56081 - diff: 8.97mlTrain batch 16/32 - 108.2ms/batch - loss: 0.57929 - diff: 9.27mlTrain batch 17/32 - 178.8ms/batch - loss: 0.59025 - diff: 9.44mlTrain batch 18/32 - 162.3ms/batch - loss: 0.59118 - diff: 9.46mlTrain batch 19/32 - 152.5ms/batch - loss: 0.58008 - diff: 9.28mlTrain batch 20/32 - 154.1ms/batch - loss: 0.56902 - diff: 9.10mlTrain batch 21/32 - 123.5ms/batch - loss: 0.56739 - diff: 9.08mlTrain batch 22/32 - 198.4ms/batch - loss: 0.56151 - diff: 8.98mlTrain batch 23/32 - 144.1ms/batch - loss: 0.56246 - diff: 9.00mlTrain batch 24/32 - 194.7ms/batch - loss: 0.57035 - diff: 9.13mlTrain batch 25/32 - 186.1ms/batch - loss: 0.56432 - diff: 9.03mlTrain batch 26/32 - 167.3ms/batch - loss: 0.55714 - diff: 8.91mlTrain batch 27/32 - 161.1ms/batch - loss: 0.54422 - diff: 8.71mlTrain batch 28/32 - 224.0ms/batch - loss: 0.54166 - diff: 8.67mlTrain batch 29/32 - 133.6ms/batch - loss: 0.54029 - diff: 8.64mlTrain batch 30/32 - 153.2ms/batch - loss: 0.53847 - diff: 8.62mlTrain batch 31/32 - 140.3ms/batch - loss: 0.53250 - diff: 8.52mlTrain batch 32/32 - 115.5ms/batch - loss: 0.55204 - diff: 8.55mlTrain batch 32/32 - 16.7s 115.5ms/batch - loss: 0.55204 - diff: 8.55ml
Test 1.1s: val_loss: 0.93333 - diff: 14.50ml

Epoch 132: current best loss = 0.89711, at epoch 110
Train batch 1/32 - 174.3ms/batch - loss: 0.30767 - diff: 4.92mlTrain batch 2/32 - 202.6ms/batch - loss: 0.34603 - diff: 5.54mlTrain batch 3/32 - 173.7ms/batch - loss: 0.37593 - diff: 6.01mlTrain batch 4/32 - 182.7ms/batch - loss: 0.35592 - diff: 5.69mlTrain batch 5/32 - 158.6ms/batch - loss: 0.37226 - diff: 5.96mlTrain batch 6/32 - 218.0ms/batch - loss: 0.38281 - diff: 6.12mlTrain batch 7/32 - 200.2ms/batch - loss: 0.37044 - diff: 5.93mlTrain batch 8/32 - 183.8ms/batch - loss: 0.36238 - diff: 5.80mlTrain batch 9/32 - 150.6ms/batch - loss: 0.39699 - diff: 6.35mlTrain batch 10/32 - 182.3ms/batch - loss: 0.38512 - diff: 6.16mlTrain batch 11/32 - 152.7ms/batch - loss: 0.42157 - diff: 6.75mlTrain batch 12/32 - 169.8ms/batch - loss: 0.41867 - diff: 6.70mlTrain batch 13/32 - 180.7ms/batch - loss: 0.41526 - diff: 6.64mlTrain batch 14/32 - 172.0ms/batch - loss: 0.41907 - diff: 6.71mlTrain batch 15/32 - 152.4ms/batch - loss: 0.43001 - diff: 6.88mlTrain batch 16/32 - 141.1ms/batch - loss: 0.42351 - diff: 6.78mlTrain batch 17/32 - 159.8ms/batch - loss: 0.42137 - diff: 6.74mlTrain batch 18/32 - 135.8ms/batch - loss: 0.42195 - diff: 6.75mlTrain batch 19/32 - 192.7ms/batch - loss: 0.42314 - diff: 6.77mlTrain batch 20/32 - 168.1ms/batch - loss: 0.44368 - diff: 7.10mlTrain batch 21/32 - 118.9ms/batch - loss: 0.45138 - diff: 7.22mlTrain batch 22/32 - 113.8ms/batch - loss: 0.46741 - diff: 7.48mlTrain batch 23/32 - 175.4ms/batch - loss: 0.46426 - diff: 7.43mlTrain batch 24/32 - 157.5ms/batch - loss: 0.46148 - diff: 7.38mlTrain batch 25/32 - 106.2ms/batch - loss: 0.46481 - diff: 7.44mlTrain batch 26/32 - 104.6ms/batch - loss: 0.45977 - diff: 7.36mlTrain batch 27/32 - 177.2ms/batch - loss: 0.46761 - diff: 7.48mlTrain batch 28/32 - 121.3ms/batch - loss: 0.47253 - diff: 7.56mlTrain batch 29/32 - 151.3ms/batch - loss: 0.48230 - diff: 7.72mlTrain batch 30/32 - 156.5ms/batch - loss: 0.47915 - diff: 7.67mlTrain batch 31/32 - 124.4ms/batch - loss: 0.48685 - diff: 7.79mlTrain batch 32/32 - 163.9ms/batch - loss: 0.50730 - diff: 7.82mlTrain batch 32/32 - 17.1s 163.9ms/batch - loss: 0.50730 - diff: 7.82ml
Test 1.0s: val_loss: 0.95318 - diff: 14.86ml
Epoch   133: reducing learning rate of group 0 to 3.1250e-05.

Epoch 133: current best loss = 0.89711, at epoch 110
Train batch 1/32 - 190.7ms/batch - loss: 0.39951 - diff: 6.39mlTrain batch 2/32 - 154.9ms/batch - loss: 0.39911 - diff: 6.39mlTrain batch 3/32 - 148.3ms/batch - loss: 0.40062 - diff: 6.41mlTrain batch 4/32 - 162.6ms/batch - loss: 0.61401 - diff: 9.82mlTrain batch 5/32 - 178.6ms/batch - loss: 0.54128 - diff: 8.66mlTrain batch 6/32 - 164.9ms/batch - loss: 0.52430 - diff: 8.39mlTrain batch 7/32 - 151.9ms/batch - loss: 0.48356 - diff: 7.74mlTrain batch 8/32 - 171.7ms/batch - loss: 0.45417 - diff: 7.27mlTrain batch 9/32 - 185.2ms/batch - loss: 0.47125 - diff: 7.54mlTrain batch 10/32 - 179.3ms/batch - loss: 0.47714 - diff: 7.63mlTrain batch 11/32 - 183.2ms/batch - loss: 0.48809 - diff: 7.81mlTrain batch 12/32 - 187.0ms/batch - loss: 0.49105 - diff: 7.86mlTrain batch 13/32 - 165.5ms/batch - loss: 0.49061 - diff: 7.85mlTrain batch 14/32 - 158.3ms/batch - loss: 0.49321 - diff: 7.89mlTrain batch 15/32 - 110.6ms/batch - loss: 0.49487 - diff: 7.92mlTrain batch 16/32 - 128.5ms/batch - loss: 0.49792 - diff: 7.97mlTrain batch 17/32 - 103.8ms/batch - loss: 0.49648 - diff: 7.94mlTrain batch 18/32 - 128.1ms/batch - loss: 0.49393 - diff: 7.90mlTrain batch 19/32 - 104.2ms/batch - loss: 0.49471 - diff: 7.92mlTrain batch 20/32 - 180.4ms/batch - loss: 0.49140 - diff: 7.86mlTrain batch 21/32 - 164.7ms/batch - loss: 0.48775 - diff: 7.80mlTrain batch 22/32 - 162.0ms/batch - loss: 0.48529 - diff: 7.76mlTrain batch 23/32 - 160.5ms/batch - loss: 0.48024 - diff: 7.68mlTrain batch 24/32 - 151.7ms/batch - loss: 0.47685 - diff: 7.63mlTrain batch 25/32 - 154.4ms/batch - loss: 0.47650 - diff: 7.62mlTrain batch 26/32 - 141.0ms/batch - loss: 0.46990 - diff: 7.52mlTrain batch 27/32 - 172.3ms/batch - loss: 0.48488 - diff: 7.76mlTrain batch 28/32 - 193.8ms/batch - loss: 0.48494 - diff: 7.76mlTrain batch 29/32 - 125.3ms/batch - loss: 0.47796 - diff: 7.65mlTrain batch 30/32 - 158.9ms/batch - loss: 0.47278 - diff: 7.56mlTrain batch 31/32 - 197.8ms/batch - loss: 0.47229 - diff: 7.56mlTrain batch 32/32 - 181.6ms/batch - loss: 0.49538 - diff: 7.60mlTrain batch 32/32 - 15.0s 181.6ms/batch - loss: 0.49538 - diff: 7.60ml
Test 1.1s: val_loss: 0.95437 - diff: 14.45ml

Epoch 134: current best loss = 0.89711, at epoch 110
Train batch 1/32 - 211.3ms/batch - loss: 0.38343 - diff: 6.13mlTrain batch 2/32 - 168.0ms/batch - loss: 0.45026 - diff: 7.20mlTrain batch 3/32 - 128.1ms/batch - loss: 0.41226 - diff: 6.60mlTrain batch 4/32 - 245.6ms/batch - loss: 0.37856 - diff: 6.06mlTrain batch 5/32 - 195.5ms/batch - loss: 0.41704 - diff: 6.67mlTrain batch 6/32 - 209.3ms/batch - loss: 0.43915 - diff: 7.03mlTrain batch 7/32 - 133.5ms/batch - loss: 0.43049 - diff: 6.89mlTrain batch 8/32 - 143.9ms/batch - loss: 0.41446 - diff: 6.63mlTrain batch 9/32 - 142.9ms/batch - loss: 0.42997 - diff: 6.88mlTrain batch 10/32 - 160.0ms/batch - loss: 0.42017 - diff: 6.72mlTrain batch 11/32 - 112.1ms/batch - loss: 0.39676 - diff: 6.35mlTrain batch 12/32 - 166.2ms/batch - loss: 0.42012 - diff: 6.72mlTrain batch 13/32 - 172.2ms/batch - loss: 0.43045 - diff: 6.89mlTrain batch 14/32 - 136.2ms/batch - loss: 0.43989 - diff: 7.04mlTrain batch 15/32 - 153.7ms/batch - loss: 0.45738 - diff: 7.32mlTrain batch 16/32 - 188.4ms/batch - loss: 0.45261 - diff: 7.24mlTrain batch 17/32 - 153.8ms/batch - loss: 0.46480 - diff: 7.44mlTrain batch 18/32 - 139.8ms/batch - loss: 0.46452 - diff: 7.43mlTrain batch 19/32 - 147.2ms/batch - loss: 0.47173 - diff: 7.55mlTrain batch 20/32 - 156.0ms/batch - loss: 0.46796 - diff: 7.49mlTrain batch 21/32 - 160.9ms/batch - loss: 0.46986 - diff: 7.52mlTrain batch 22/32 - 163.9ms/batch - loss: 0.47845 - diff: 7.66mlTrain batch 23/32 - 163.4ms/batch - loss: 0.47359 - diff: 7.58mlTrain batch 24/32 - 152.9ms/batch - loss: 0.47018 - diff: 7.52mlTrain batch 25/32 - 159.9ms/batch - loss: 0.46947 - diff: 7.51mlTrain batch 26/32 - 193.6ms/batch - loss: 0.47603 - diff: 7.62mlTrain batch 27/32 - 149.2ms/batch - loss: 0.47764 - diff: 7.64mlTrain batch 28/32 - 207.6ms/batch - loss: 0.47838 - diff: 7.65mlTrain batch 29/32 - 146.9ms/batch - loss: 0.48242 - diff: 7.72mlTrain batch 30/32 - 113.2ms/batch - loss: 0.48076 - diff: 7.69mlTrain batch 31/32 - 135.5ms/batch - loss: 0.47473 - diff: 7.60mlTrain batch 32/32 - 158.9ms/batch - loss: 0.49993 - diff: 7.65mlTrain batch 32/32 - 17.2s 158.9ms/batch - loss: 0.49993 - diff: 7.65ml
Test 1.1s: val_loss: 0.89760 - diff: 14.14ml

Epoch 135: current best loss = 0.89711, at epoch 110
Train batch 1/32 - 126.3ms/batch - loss: 0.29204 - diff: 4.67mlTrain batch 2/32 - 112.1ms/batch - loss: 0.35630 - diff: 5.70mlTrain batch 3/32 - 156.3ms/batch - loss: 0.43373 - diff: 6.94mlTrain batch 4/32 - 177.4ms/batch - loss: 0.38729 - diff: 6.20mlTrain batch 5/32 - 190.7ms/batch - loss: 0.46341 - diff: 7.41mlTrain batch 6/32 - 132.7ms/batch - loss: 0.46085 - diff: 7.37mlTrain batch 7/32 - 134.8ms/batch - loss: 0.44221 - diff: 7.08mlTrain batch 8/32 - 185.8ms/batch - loss: 0.45647 - diff: 7.30mlTrain batch 9/32 - 172.5ms/batch - loss: 0.45653 - diff: 7.30mlTrain batch 10/32 - 185.6ms/batch - loss: 0.45060 - diff: 7.21mlTrain batch 11/32 - 118.8ms/batch - loss: 0.43618 - diff: 6.98mlTrain batch 12/32 - 127.2ms/batch - loss: 0.45676 - diff: 7.31mlTrain batch 13/32 - 157.9ms/batch - loss: 0.45723 - diff: 7.32mlTrain batch 14/32 - 180.3ms/batch - loss: 0.45186 - diff: 7.23mlTrain batch 15/32 - 152.8ms/batch - loss: 0.45065 - diff: 7.21mlTrain batch 16/32 - 216.2ms/batch - loss: 0.46384 - diff: 7.42mlTrain batch 17/32 - 173.3ms/batch - loss: 0.47134 - diff: 7.54mlTrain batch 18/32 - 185.0ms/batch - loss: 0.48339 - diff: 7.73mlTrain batch 19/32 - 216.2ms/batch - loss: 0.47578 - diff: 7.61mlTrain batch 20/32 - 142.3ms/batch - loss: 0.47010 - diff: 7.52mlTrain batch 21/32 - 168.2ms/batch - loss: 0.46094 - diff: 7.38mlTrain batch 22/32 - 161.5ms/batch - loss: 0.46059 - diff: 7.37mlTrain batch 23/32 - 203.3ms/batch - loss: 0.45809 - diff: 7.33mlTrain batch 24/32 - 132.1ms/batch - loss: 0.45652 - diff: 7.30mlTrain batch 25/32 - 145.6ms/batch - loss: 0.46311 - diff: 7.41mlTrain batch 26/32 - 148.2ms/batch - loss: 0.48978 - diff: 7.84mlTrain batch 27/32 - 172.8ms/batch - loss: 0.49221 - diff: 7.88mlTrain batch 28/32 - 170.3ms/batch - loss: 0.49399 - diff: 7.90mlTrain batch 29/32 - 173.0ms/batch - loss: 0.49522 - diff: 7.92mlTrain batch 30/32 - 177.6ms/batch - loss: 0.49523 - diff: 7.92mlTrain batch 31/32 - 124.8ms/batch - loss: 0.48956 - diff: 7.83mlTrain batch 32/32 - 170.6ms/batch - loss: 0.49808 - diff: 7.82mlTrain batch 32/32 - 17.3s 170.6ms/batch - loss: 0.49808 - diff: 7.82ml
Test 1.2s: val_loss: 0.92828 - diff: 14.48ml

Epoch 136: current best loss = 0.89711, at epoch 110
Train batch 1/32 - 174.5ms/batch - loss: 0.81562 - diff: 13.05mlTrain batch 2/32 - 199.8ms/batch - loss: 0.59998 - diff: 9.60mlTrain batch 3/32 - 177.2ms/batch - loss: 0.52979 - diff: 8.48mlTrain batch 4/32 - 193.8ms/batch - loss: 0.51815 - diff: 8.29mlTrain batch 5/32 - 180.6ms/batch - loss: 0.52459 - diff: 8.39mlTrain batch 6/32 - 183.4ms/batch - loss: 0.51242 - diff: 8.20mlTrain batch 7/32 - 194.6ms/batch - loss: 0.48132 - diff: 7.70mlTrain batch 8/32 - 169.2ms/batch - loss: 0.47437 - diff: 7.59mlTrain batch 9/32 - 163.7ms/batch - loss: 0.45858 - diff: 7.34mlTrain batch 10/32 - 196.2ms/batch - loss: 0.43789 - diff: 7.01mlTrain batch 11/32 - 118.9ms/batch - loss: 0.43415 - diff: 6.95mlTrain batch 12/32 - 135.1ms/batch - loss: 0.43261 - diff: 6.92mlTrain batch 13/32 - 172.7ms/batch - loss: 0.42111 - diff: 6.74mlTrain batch 14/32 - 167.1ms/batch - loss: 0.43937 - diff: 7.03mlTrain batch 15/32 - 148.7ms/batch - loss: 0.43057 - diff: 6.89mlTrain batch 16/32 - 168.0ms/batch - loss: 0.42533 - diff: 6.81mlTrain batch 17/32 - 173.0ms/batch - loss: 0.43818 - diff: 7.01mlTrain batch 18/32 - 168.6ms/batch - loss: 0.43059 - diff: 6.89mlTrain batch 19/32 - 161.5ms/batch - loss: 0.43082 - diff: 6.89mlTrain batch 20/32 - 162.7ms/batch - loss: 0.42580 - diff: 6.81mlTrain batch 21/32 - 150.8ms/batch - loss: 0.42203 - diff: 6.75mlTrain batch 22/32 - 184.3ms/batch - loss: 0.42547 - diff: 6.81mlTrain batch 23/32 - 145.6ms/batch - loss: 0.41990 - diff: 6.72mlTrain batch 24/32 - 160.3ms/batch - loss: 0.42934 - diff: 6.87mlTrain batch 25/32 - 174.9ms/batch - loss: 0.42943 - diff: 6.87mlTrain batch 26/32 - 111.2ms/batch - loss: 0.42534 - diff: 6.81mlTrain batch 27/32 - 192.8ms/batch - loss: 0.42259 - diff: 6.76mlTrain batch 28/32 - 168.8ms/batch - loss: 0.42578 - diff: 6.81mlTrain batch 29/32 - 149.9ms/batch - loss: 0.42101 - diff: 6.74mlTrain batch 30/32 - 187.4ms/batch - loss: 0.42344 - diff: 6.78mlTrain batch 31/32 - 165.6ms/batch - loss: 0.41993 - diff: 6.72mlTrain batch 32/32 - 178.6ms/batch - loss: 0.43265 - diff: 6.73mlTrain batch 32/32 - 14.9s 178.6ms/batch - loss: 0.43265 - diff: 6.73ml
Test 1.1s: val_loss: 0.92440 - diff: 14.24ml

Epoch 137: current best loss = 0.89711, at epoch 110
Train batch 1/32 - 198.9ms/batch - loss: 0.35877 - diff: 5.74mlTrain batch 2/32 - 141.4ms/batch - loss: 0.53528 - diff: 8.56mlTrain batch 3/32 - 168.2ms/batch - loss: 0.48228 - diff: 7.72mlTrain batch 4/32 - 140.2ms/batch - loss: 0.45040 - diff: 7.21mlTrain batch 5/32 - 173.9ms/batch - loss: 0.45556 - diff: 7.29mlTrain batch 6/32 - 164.5ms/batch - loss: 0.44225 - diff: 7.08mlTrain batch 7/32 - 181.6ms/batch - loss: 0.43660 - diff: 6.99mlTrain batch 8/32 - 194.4ms/batch - loss: 0.45230 - diff: 7.24mlTrain batch 9/32 - 161.7ms/batch - loss: 0.45870 - diff: 7.34mlTrain batch 10/32 - 165.2ms/batch - loss: 0.44902 - diff: 7.18mlTrain batch 11/32 - 182.0ms/batch - loss: 0.43851 - diff: 7.02mlTrain batch 12/32 - 191.7ms/batch - loss: 0.42352 - diff: 6.78mlTrain batch 13/32 - 191.6ms/batch - loss: 0.42138 - diff: 6.74mlTrain batch 14/32 - 161.7ms/batch - loss: 0.41171 - diff: 6.59mlTrain batch 15/32 - 172.4ms/batch - loss: 0.42771 - diff: 6.84mlTrain batch 16/32 - 105.0ms/batch - loss: 0.42625 - diff: 6.82mlTrain batch 17/32 - 139.0ms/batch - loss: 0.42267 - diff: 6.76mlTrain batch 18/32 - 147.1ms/batch - loss: 0.42435 - diff: 6.79mlTrain batch 19/32 - 104.3ms/batch - loss: 0.42135 - diff: 6.74mlTrain batch 20/32 - 112.0ms/batch - loss: 0.41732 - diff: 6.68mlTrain batch 21/32 - 125.1ms/batch - loss: 0.41176 - diff: 6.59mlTrain batch 22/32 - 159.6ms/batch - loss: 0.40687 - diff: 6.51mlTrain batch 23/32 - 153.0ms/batch - loss: 0.40975 - diff: 6.56mlTrain batch 24/32 - 197.4ms/batch - loss: 0.41237 - diff: 6.60mlTrain batch 25/32 - 178.6ms/batch - loss: 0.41828 - diff: 6.69mlTrain batch 26/32 - 168.2ms/batch - loss: 0.41340 - diff: 6.61mlTrain batch 27/32 - 148.8ms/batch - loss: 0.42546 - diff: 6.81mlTrain batch 28/32 - 153.1ms/batch - loss: 0.42243 - diff: 6.76mlTrain batch 29/32 - 201.0ms/batch - loss: 0.42322 - diff: 6.77mlTrain batch 30/32 - 114.1ms/batch - loss: 0.42512 - diff: 6.80mlTrain batch 31/32 - 113.5ms/batch - loss: 0.42788 - diff: 6.85mlTrain batch 32/32 - 102.6ms/batch - loss: 0.46188 - diff: 6.94mlTrain batch 32/32 - 16.7s 102.6ms/batch - loss: 0.46188 - diff: 6.94ml
Test 1.1s: val_loss: 0.92978 - diff: 14.24ml

Epoch 138: current best loss = 0.89711, at epoch 110
Train batch 1/32 - 199.6ms/batch - loss: 0.34436 - diff: 5.51mlTrain batch 2/32 - 180.7ms/batch - loss: 0.36382 - diff: 5.82mlTrain batch 3/32 - 159.7ms/batch - loss: 0.34796 - diff: 5.57mlTrain batch 4/32 - 159.8ms/batch - loss: 0.37713 - diff: 6.03mlTrain batch 5/32 - 135.6ms/batch - loss: 0.36870 - diff: 5.90mlTrain batch 6/32 - 171.4ms/batch - loss: 0.35981 - diff: 5.76mlTrain batch 7/32 - 181.4ms/batch - loss: 0.38794 - diff: 6.21mlTrain batch 8/32 - 149.5ms/batch - loss: 0.37995 - diff: 6.08mlTrain batch 9/32 - 169.0ms/batch - loss: 0.38329 - diff: 6.13mlTrain batch 10/32 - 156.0ms/batch - loss: 0.42638 - diff: 6.82mlTrain batch 11/32 - 157.6ms/batch - loss: 0.42630 - diff: 6.82mlTrain batch 12/32 - 127.2ms/batch - loss: 0.41501 - diff: 6.64mlTrain batch 13/32 - 169.7ms/batch - loss: 0.40132 - diff: 6.42mlTrain batch 14/32 - 169.2ms/batch - loss: 0.39950 - diff: 6.39mlTrain batch 15/32 - 141.8ms/batch - loss: 0.39901 - diff: 6.38mlTrain batch 16/32 - 133.8ms/batch - loss: 0.38561 - diff: 6.17mlTrain batch 17/32 - 159.5ms/batch - loss: 0.39112 - diff: 6.26mlTrain batch 18/32 - 158.6ms/batch - loss: 0.38988 - diff: 6.24mlTrain batch 19/32 - 131.2ms/batch - loss: 0.39347 - diff: 6.30mlTrain batch 20/32 - 171.6ms/batch - loss: 0.38832 - diff: 6.21mlTrain batch 21/32 - 175.7ms/batch - loss: 0.38719 - diff: 6.20mlTrain batch 22/32 - 193.4ms/batch - loss: 0.37916 - diff: 6.07mlTrain batch 23/32 - 130.5ms/batch - loss: 0.37453 - diff: 5.99mlTrain batch 24/32 - 165.8ms/batch - loss: 0.37877 - diff: 6.06mlTrain batch 25/32 - 121.7ms/batch - loss: 0.37469 - diff: 6.00mlTrain batch 26/32 - 182.6ms/batch - loss: 0.36993 - diff: 5.92mlTrain batch 27/32 - 142.9ms/batch - loss: 0.37548 - diff: 6.01mlTrain batch 28/32 - 170.6ms/batch - loss: 0.37125 - diff: 5.94mlTrain batch 29/32 - 156.3ms/batch - loss: 0.36852 - diff: 5.90mlTrain batch 30/32 - 148.4ms/batch - loss: 0.37504 - diff: 6.00mlTrain batch 31/32 - 116.5ms/batch - loss: 0.37485 - diff: 6.00mlTrain batch 32/32 - 125.1ms/batch - loss: 0.38033 - diff: 5.98mlTrain batch 32/32 - 16.3s 125.1ms/batch - loss: 0.38033 - diff: 5.98ml
Test 1.0s: val_loss: 0.92305 - diff: 13.85ml

Epoch 139: current best loss = 0.89711, at epoch 110
Train batch 1/32 - 157.9ms/batch - loss: 0.43018 - diff: 6.88mlTrain batch 2/32 - 109.4ms/batch - loss: 0.43249 - diff: 6.92mlTrain batch 3/32 - 149.1ms/batch - loss: 0.38730 - diff: 6.20mlTrain batch 4/32 - 182.0ms/batch - loss: 0.47301 - diff: 7.57mlTrain batch 5/32 - 178.2ms/batch - loss: 0.47379 - diff: 7.58mlTrain batch 6/32 - 141.9ms/batch - loss: 0.48175 - diff: 7.71mlTrain batch 7/32 - 164.5ms/batch - loss: 0.48764 - diff: 7.80mlTrain batch 8/32 - 189.2ms/batch - loss: 0.47175 - diff: 7.55mlTrain batch 9/32 - 179.6ms/batch - loss: 0.47567 - diff: 7.61mlTrain batch 10/32 - 175.8ms/batch - loss: 0.46328 - diff: 7.41mlTrain batch 11/32 - 147.5ms/batch - loss: 0.47938 - diff: 7.67mlTrain batch 12/32 - 203.6ms/batch - loss: 0.46736 - diff: 7.48mlTrain batch 13/32 - 165.6ms/batch - loss: 0.46225 - diff: 7.40mlTrain batch 14/32 - 185.3ms/batch - loss: 0.46195 - diff: 7.39mlTrain batch 15/32 - 186.5ms/batch - loss: 0.47112 - diff: 7.54mlTrain batch 16/32 - 130.4ms/batch - loss: 0.46920 - diff: 7.51mlTrain batch 17/32 - 129.7ms/batch - loss: 0.46288 - diff: 7.41mlTrain batch 18/32 - 129.8ms/batch - loss: 0.48930 - diff: 7.83mlTrain batch 19/32 - 150.9ms/batch - loss: 0.49836 - diff: 7.97mlTrain batch 20/32 - 171.6ms/batch - loss: 0.49484 - diff: 7.92mlTrain batch 21/32 - 172.3ms/batch - loss: 0.48823 - diff: 7.81mlTrain batch 22/32 - 199.4ms/batch - loss: 0.48109 - diff: 7.70mlTrain batch 23/32 - 103.2ms/batch - loss: 0.47296 - diff: 7.57mlTrain batch 24/32 - 105.5ms/batch - loss: 0.46715 - diff: 7.47mlTrain batch 25/32 - 162.6ms/batch - loss: 0.46575 - diff: 7.45mlTrain batch 26/32 - 181.1ms/batch - loss: 0.46117 - diff: 7.38mlTrain batch 27/32 - 128.4ms/batch - loss: 0.45308 - diff: 7.25mlTrain batch 28/32 - 112.5ms/batch - loss: 0.45287 - diff: 7.25mlTrain batch 29/32 - 166.0ms/batch - loss: 0.45032 - diff: 7.21mlTrain batch 30/32 - 198.6ms/batch - loss: 0.44924 - diff: 7.19mlTrain batch 31/32 - 147.6ms/batch - loss: 0.44527 - diff: 7.12mlTrain batch 32/32 - 154.8ms/batch - loss: 0.47366 - diff: 7.20mlTrain batch 32/32 - 16.2s 154.8ms/batch - loss: 0.47366 - diff: 7.20ml
Test 1.1s: val_loss: 0.90129 - diff: 14.10ml

Epoch 140: current best loss = 0.89711, at epoch 110
Train batch 1/32 - 211.6ms/batch - loss: 0.38414 - diff: 6.15mlTrain batch 2/32 - 172.4ms/batch - loss: 0.31849 - diff: 5.10mlTrain batch 3/32 - 182.1ms/batch - loss: 0.34149 - diff: 5.46mlTrain batch 4/32 - 145.0ms/batch - loss: 0.35926 - diff: 5.75mlTrain batch 5/32 - 192.7ms/batch - loss: 0.35637 - diff: 5.70mlTrain batch 6/32 - 143.4ms/batch - loss: 0.33709 - diff: 5.39mlTrain batch 7/32 - 164.3ms/batch - loss: 0.35424 - diff: 5.67mlTrain batch 8/32 - 194.3ms/batch - loss: 0.40842 - diff: 6.53mlTrain batch 9/32 - 173.2ms/batch - loss: 0.42494 - diff: 6.80mlTrain batch 10/32 - 126.3ms/batch - loss: 0.43028 - diff: 6.88mlTrain batch 11/32 - 128.4ms/batch - loss: 0.42262 - diff: 6.76mlTrain batch 12/32 - 140.3ms/batch - loss: 0.46229 - diff: 7.40mlTrain batch 13/32 - 136.1ms/batch - loss: 0.44665 - diff: 7.15mlTrain batch 14/32 - 161.2ms/batch - loss: 0.43726 - diff: 7.00mlTrain batch 15/32 - 140.3ms/batch - loss: 0.43222 - diff: 6.92mlTrain batch 16/32 - 198.6ms/batch - loss: 0.43434 - diff: 6.95mlTrain batch 17/32 - 133.4ms/batch - loss: 0.42983 - diff: 6.88mlTrain batch 18/32 - 200.5ms/batch - loss: 0.42392 - diff: 6.78mlTrain batch 19/32 - 164.0ms/batch - loss: 0.44226 - diff: 7.08mlTrain batch 20/32 - 129.8ms/batch - loss: 0.44380 - diff: 7.10mlTrain batch 21/32 - 125.1ms/batch - loss: 0.44720 - diff: 7.16mlTrain batch 22/32 - 183.3ms/batch - loss: 0.44103 - diff: 7.06mlTrain batch 23/32 - 155.1ms/batch - loss: 0.44510 - diff: 7.12mlTrain batch 24/32 - 169.1ms/batch - loss: 0.43961 - diff: 7.03mlTrain batch 25/32 - 154.4ms/batch - loss: 0.43216 - diff: 6.91mlTrain batch 26/32 - 179.3ms/batch - loss: 0.42647 - diff: 6.82mlTrain batch 27/32 - 164.4ms/batch - loss: 0.43117 - diff: 6.90mlTrain batch 28/32 - 163.5ms/batch - loss: 0.43054 - diff: 6.89mlTrain batch 29/32 - 205.3ms/batch - loss: 0.43211 - diff: 6.91mlTrain batch 30/32 - 164.7ms/batch - loss: 0.43358 - diff: 6.94mlTrain batch 31/32 - 121.9ms/batch - loss: 0.42827 - diff: 6.85mlTrain batch 32/32 - 126.5ms/batch - loss: 0.48185 - diff: 7.03mlTrain batch 32/32 - 16.2s 126.5ms/batch - loss: 0.48185 - diff: 7.03ml
Test 1.2s: val_loss: 0.92095 - diff: 14.24ml

Epoch 141: current best loss = 0.89711, at epoch 110
Train batch 1/32 - 197.2ms/batch - loss: 0.22950 - diff: 3.67mlTrain batch 2/32 - 141.9ms/batch - loss: 0.34638 - diff: 5.54mlTrain batch 3/32 - 146.2ms/batch - loss: 0.32321 - diff: 5.17mlTrain batch 4/32 - 159.2ms/batch - loss: 0.34284 - diff: 5.49mlTrain batch 5/32 - 174.3ms/batch - loss: 0.35447 - diff: 5.67mlTrain batch 6/32 - 124.2ms/batch - loss: 0.36770 - diff: 5.88mlTrain batch 7/32 - 174.1ms/batch - loss: 0.37267 - diff: 5.96mlTrain batch 8/32 - 153.6ms/batch - loss: 0.38795 - diff: 6.21mlTrain batch 9/32 - 123.6ms/batch - loss: 0.39449 - diff: 6.31mlTrain batch 10/32 - 130.1ms/batch - loss: 0.40969 - diff: 6.56mlTrain batch 11/32 - 141.0ms/batch - loss: 0.41213 - diff: 6.59mlTrain batch 12/32 - 158.2ms/batch - loss: 0.42089 - diff: 6.73mlTrain batch 13/32 - 175.5ms/batch - loss: 0.41694 - diff: 6.67mlTrain batch 14/32 - 158.6ms/batch - loss: 0.41531 - diff: 6.64mlTrain batch 15/32 - 157.6ms/batch - loss: 0.43176 - diff: 6.91mlTrain batch 16/32 - 111.2ms/batch - loss: 0.42788 - diff: 6.85mlTrain batch 17/32 - 151.1ms/batch - loss: 0.44665 - diff: 7.15mlTrain batch 18/32 - 136.6ms/batch - loss: 0.44857 - diff: 7.18mlTrain batch 19/32 - 194.7ms/batch - loss: 0.44451 - diff: 7.11mlTrain batch 20/32 - 167.6ms/batch - loss: 0.45076 - diff: 7.21mlTrain batch 21/32 - 182.9ms/batch - loss: 0.44293 - diff: 7.09mlTrain batch 22/32 - 121.9ms/batch - loss: 0.43907 - diff: 7.03mlTrain batch 23/32 - 171.1ms/batch - loss: 0.43973 - diff: 7.04mlTrain batch 24/32 - 157.5ms/batch - loss: 0.45784 - diff: 7.33mlTrain batch 25/32 - 143.6ms/batch - loss: 0.45333 - diff: 7.25mlTrain batch 26/32 - 158.4ms/batch - loss: 0.44953 - diff: 7.19mlTrain batch 27/32 - 178.6ms/batch - loss: 0.46440 - diff: 7.43mlTrain batch 28/32 - 155.0ms/batch - loss: 0.45861 - diff: 7.34mlTrain batch 29/32 - 172.5ms/batch - loss: 0.45500 - diff: 7.28mlTrain batch 30/32 - 206.5ms/batch - loss: 0.45711 - diff: 7.31mlTrain batch 31/32 - 109.4ms/batch - loss: 0.45416 - diff: 7.27mlTrain batch 32/32 - 117.0ms/batch - loss: 0.46039 - diff: 7.25mlTrain batch 32/32 - 16.5s 117.0ms/batch - loss: 0.46039 - diff: 7.25ml
Test 1.2s: val_loss: 0.93032 - diff: 13.89ml

Epoch 142: current best loss = 0.89711, at epoch 110
Train batch 1/32 - 184.2ms/batch - loss: 0.25370 - diff: 4.06mlTrain batch 2/32 - 199.0ms/batch - loss: 0.31734 - diff: 5.08mlTrain batch 3/32 - 162.3ms/batch - loss: 0.30089 - diff: 4.81mlTrain batch 4/32 - 187.4ms/batch - loss: 0.30274 - diff: 4.84mlTrain batch 5/32 - 164.4ms/batch - loss: 0.31460 - diff: 5.03mlTrain batch 6/32 - 167.8ms/batch - loss: 0.32021 - diff: 5.12mlTrain batch 7/32 - 191.1ms/batch - loss: 0.33902 - diff: 5.42mlTrain batch 8/32 - 180.2ms/batch - loss: 0.33787 - diff: 5.41mlTrain batch 9/32 - 135.5ms/batch - loss: 0.33242 - diff: 5.32mlTrain batch 10/32 - 170.5ms/batch - loss: 0.33321 - diff: 5.33mlTrain batch 11/32 - 143.9ms/batch - loss: 0.32855 - diff: 5.26mlTrain batch 12/32 - 195.6ms/batch - loss: 0.32570 - diff: 5.21mlTrain batch 13/32 - 156.8ms/batch - loss: 0.31811 - diff: 5.09mlTrain batch 14/32 - 179.7ms/batch - loss: 0.33163 - diff: 5.31mlTrain batch 15/32 - 147.3ms/batch - loss: 0.35271 - diff: 5.64mlTrain batch 16/32 - 168.8ms/batch - loss: 0.35128 - diff: 5.62mlTrain batch 17/32 - 174.4ms/batch - loss: 0.36290 - diff: 5.81mlTrain batch 18/32 - 191.1ms/batch - loss: 0.37319 - diff: 5.97mlTrain batch 19/32 - 147.1ms/batch - loss: 0.36484 - diff: 5.84mlTrain batch 20/32 - 149.4ms/batch - loss: 0.36644 - diff: 5.86mlTrain batch 21/32 - 138.4ms/batch - loss: 0.36632 - diff: 5.86mlTrain batch 22/32 - 118.5ms/batch - loss: 0.36435 - diff: 5.83mlTrain batch 23/32 - 142.5ms/batch - loss: 0.36861 - diff: 5.90mlTrain batch 24/32 - 144.5ms/batch - loss: 0.37248 - diff: 5.96mlTrain batch 25/32 - 139.5ms/batch - loss: 0.37450 - diff: 5.99mlTrain batch 26/32 - 167.7ms/batch - loss: 0.37002 - diff: 5.92mlTrain batch 27/32 - 157.9ms/batch - loss: 0.36659 - diff: 5.87mlTrain batch 28/32 - 158.6ms/batch - loss: 0.36514 - diff: 5.84mlTrain batch 29/32 - 182.1ms/batch - loss: 0.36467 - diff: 5.83mlTrain batch 30/32 - 181.5ms/batch - loss: 0.36902 - diff: 5.90mlTrain batch 31/32 - 138.9ms/batch - loss: 0.37146 - diff: 5.94mlTrain batch 32/32 - 122.4ms/batch - loss: 0.39509 - diff: 6.00mlTrain batch 32/32 - 16.3s 122.4ms/batch - loss: 0.39509 - diff: 6.00ml
Test 1.2s: val_loss: 0.92555 - diff: 14.08ml

Epoch 143: current best loss = 0.89711, at epoch 110
Train batch 1/32 - 185.4ms/batch - loss: 0.26129 - diff: 4.18mlTrain batch 2/32 - 152.0ms/batch - loss: 0.30960 - diff: 4.95mlTrain batch 3/32 - 170.1ms/batch - loss: 0.27833 - diff: 4.45mlTrain batch 4/32 - 178.8ms/batch - loss: 0.33364 - diff: 5.34mlTrain batch 5/32 - 175.8ms/batch - loss: 0.32683 - diff: 5.23mlTrain batch 6/32 - 163.3ms/batch - loss: 0.32375 - diff: 5.18mlTrain batch 7/32 - 198.9ms/batch - loss: 0.32609 - diff: 5.22mlTrain batch 8/32 - 206.8ms/batch - loss: 0.33456 - diff: 5.35mlTrain batch 9/32 - 199.6ms/batch - loss: 0.33370 - diff: 5.34mlTrain batch 10/32 - 160.6ms/batch - loss: 0.33569 - diff: 5.37mlTrain batch 11/32 - 166.7ms/batch - loss: 0.33001 - diff: 5.28mlTrain batch 12/32 - 137.4ms/batch - loss: 0.33938 - diff: 5.43mlTrain batch 13/32 - 202.4ms/batch - loss: 0.34537 - diff: 5.53mlTrain batch 14/32 - 150.5ms/batch - loss: 0.34848 - diff: 5.58mlTrain batch 15/32 - 178.7ms/batch - loss: 0.34620 - diff: 5.54mlTrain batch 16/32 - 237.0ms/batch - loss: 0.35214 - diff: 5.63mlTrain batch 17/32 - 133.2ms/batch - loss: 0.35211 - diff: 5.63mlTrain batch 18/32 - 119.8ms/batch - loss: 0.35722 - diff: 5.72mlTrain batch 19/32 - 179.9ms/batch - loss: 0.35489 - diff: 5.68mlTrain batch 20/32 - 151.3ms/batch - loss: 0.36456 - diff: 5.83mlTrain batch 21/32 - 145.9ms/batch - loss: 0.37413 - diff: 5.99mlTrain batch 22/32 - 154.4ms/batch - loss: 0.37434 - diff: 5.99mlTrain batch 23/32 - 168.2ms/batch - loss: 0.38534 - diff: 6.17mlTrain batch 24/32 - 171.7ms/batch - loss: 0.38812 - diff: 6.21mlTrain batch 25/32 - 168.4ms/batch - loss: 0.38794 - diff: 6.21mlTrain batch 26/32 - 174.6ms/batch - loss: 0.38316 - diff: 6.13mlTrain batch 27/32 - 112.3ms/batch - loss: 0.39024 - diff: 6.24mlTrain batch 28/32 - 109.2ms/batch - loss: 0.38947 - diff: 6.23mlTrain batch 29/32 - 114.1ms/batch - loss: 0.38914 - diff: 6.23mlTrain batch 30/32 - 146.3ms/batch - loss: 0.39238 - diff: 6.28mlTrain batch 31/32 - 166.9ms/batch - loss: 0.39268 - diff: 6.28mlTrain batch 32/32 - 166.0ms/batch - loss: 0.41248 - diff: 6.32mlTrain batch 32/32 - 18.6s 166.0ms/batch - loss: 0.41248 - diff: 6.32ml
Test 1.1s: val_loss: 0.91447 - diff: 14.31ml
Epoch   144: reducing learning rate of group 0 to 1.5625e-05.

Epoch 144: current best loss = 0.89711, at epoch 110
Train batch 1/32 - 171.0ms/batch - loss: 0.50930 - diff: 8.15mlTrain batch 2/32 - 194.2ms/batch - loss: 0.47559 - diff: 7.61mlTrain batch 3/32 - 161.2ms/batch - loss: 0.52476 - diff: 8.40mlTrain batch 4/32 - 185.6ms/batch - loss: 0.75000 - diff: 12.00mlTrain batch 5/32 - 147.7ms/batch - loss: 0.67993 - diff: 10.88mlTrain batch 6/32 - 185.4ms/batch - loss: 0.61507 - diff: 9.84mlTrain batch 7/32 - 165.3ms/batch - loss: 0.60847 - diff: 9.74mlTrain batch 8/32 - 133.9ms/batch - loss: 0.58182 - diff: 9.31mlTrain batch 9/32 - 174.5ms/batch - loss: 0.55333 - diff: 8.85mlTrain batch 10/32 - 128.8ms/batch - loss: 0.54572 - diff: 8.73mlTrain batch 11/32 - 169.1ms/batch - loss: 0.53302 - diff: 8.53mlTrain batch 12/32 - 193.9ms/batch - loss: 0.52412 - diff: 8.39mlTrain batch 13/32 - 205.1ms/batch - loss: 0.50858 - diff: 8.14mlTrain batch 14/32 - 227.4ms/batch - loss: 0.49163 - diff: 7.87mlTrain batch 15/32 - 133.6ms/batch - loss: 0.47942 - diff: 7.67mlTrain batch 16/32 - 180.5ms/batch - loss: 0.47870 - diff: 7.66mlTrain batch 17/32 - 156.9ms/batch - loss: 0.47304 - diff: 7.57mlTrain batch 18/32 - 138.1ms/batch - loss: 0.49616 - diff: 7.94mlTrain batch 19/32 - 158.0ms/batch - loss: 0.49450 - diff: 7.91mlTrain batch 20/32 - 186.9ms/batch - loss: 0.49492 - diff: 7.92mlTrain batch 21/32 - 149.2ms/batch - loss: 0.48444 - diff: 7.75mlTrain batch 22/32 - 181.5ms/batch - loss: 0.47406 - diff: 7.58mlTrain batch 23/32 - 142.3ms/batch - loss: 0.46754 - diff: 7.48mlTrain batch 24/32 - 122.4ms/batch - loss: 0.47023 - diff: 7.52mlTrain batch 25/32 - 142.3ms/batch - loss: 0.46733 - diff: 7.48mlTrain batch 26/32 - 145.1ms/batch - loss: 0.47093 - diff: 7.53mlTrain batch 27/32 - 127.3ms/batch - loss: 0.46641 - diff: 7.46mlTrain batch 28/32 - 117.3ms/batch - loss: 0.46311 - diff: 7.41mlTrain batch 29/32 - 145.5ms/batch - loss: 0.45868 - diff: 7.34mlTrain batch 30/32 - 168.1ms/batch - loss: 0.45622 - diff: 7.30mlTrain batch 31/32 - 182.5ms/batch - loss: 0.44888 - diff: 7.18mlTrain batch 32/32 - 193.0ms/batch - loss: 0.46954 - diff: 7.22mlTrain batch 32/32 - 17.2s 193.0ms/batch - loss: 0.46954 - diff: 7.22ml
Test 1.2s: val_loss: 0.94243 - diff: 14.07ml

Epoch 145: current best loss = 0.89711, at epoch 110
Train batch 1/32 - 196.6ms/batch - loss: 0.34513 - diff: 5.52mlTrain batch 2/32 - 156.7ms/batch - loss: 0.48895 - diff: 7.82mlTrain batch 3/32 - 132.4ms/batch - loss: 0.49110 - diff: 7.86mlTrain batch 4/32 - 150.7ms/batch - loss: 0.57345 - diff: 9.18mlTrain batch 5/32 - 167.2ms/batch - loss: 0.51386 - diff: 8.22mlTrain batch 6/32 - 121.9ms/batch - loss: 0.51146 - diff: 8.18mlTrain batch 7/32 - 123.3ms/batch - loss: 0.48574 - diff: 7.77mlTrain batch 8/32 - 161.1ms/batch - loss: 0.49099 - diff: 7.86mlTrain batch 9/32 - 127.8ms/batch - loss: 0.48106 - diff: 7.70mlTrain batch 10/32 - 156.4ms/batch - loss: 0.49080 - diff: 7.85mlTrain batch 11/32 - 167.4ms/batch - loss: 0.56494 - diff: 9.04mlTrain batch 12/32 - 166.7ms/batch - loss: 0.55353 - diff: 8.86mlTrain batch 13/32 - 176.8ms/batch - loss: 0.53592 - diff: 8.57mlTrain batch 14/32 - 177.6ms/batch - loss: 0.52836 - diff: 8.45mlTrain batch 15/32 - 183.4ms/batch - loss: 0.51692 - diff: 8.27mlTrain batch 16/32 - 168.4ms/batch - loss: 0.50360 - diff: 8.06mlTrain batch 17/32 - 221.9ms/batch - loss: 0.49510 - diff: 7.92mlTrain batch 18/32 - 184.7ms/batch - loss: 0.50299 - diff: 8.05mlTrain batch 19/32 - 169.5ms/batch - loss: 0.48897 - diff: 7.82mlTrain batch 20/32 - 175.8ms/batch - loss: 0.48311 - diff: 7.73mlTrain batch 21/32 - 161.3ms/batch - loss: 0.47153 - diff: 7.54mlTrain batch 22/32 - 133.5ms/batch - loss: 0.47746 - diff: 7.64mlTrain batch 23/32 - 131.4ms/batch - loss: 0.47728 - diff: 7.64mlTrain batch 24/32 - 123.2ms/batch - loss: 0.47114 - diff: 7.54mlTrain batch 25/32 - 155.5ms/batch - loss: 0.46528 - diff: 7.44mlTrain batch 26/32 - 141.0ms/batch - loss: 0.46488 - diff: 7.44mlTrain batch 27/32 - 207.2ms/batch - loss: 0.46006 - diff: 7.36mlTrain batch 28/32 - 161.5ms/batch - loss: 0.45445 - diff: 7.27mlTrain batch 29/32 - 111.6ms/batch - loss: 0.44951 - diff: 7.19mlTrain batch 30/32 - 136.7ms/batch - loss: 0.44662 - diff: 7.15mlTrain batch 31/32 - 128.8ms/batch - loss: 0.44840 - diff: 7.17mlTrain batch 32/32 - 149.1ms/batch - loss: 0.46303 - diff: 7.19mlTrain batch 32/32 - 16.4s 149.1ms/batch - loss: 0.46303 - diff: 7.19ml
Test 1.1s: val_loss: 0.92332 - diff: 14.24ml

Epoch 146: current best loss = 0.89711, at epoch 110
Train batch 1/32 - 218.4ms/batch - loss: 0.63878 - diff: 10.22mlTrain batch 2/32 - 166.0ms/batch - loss: 0.47357 - diff: 7.58mlTrain batch 3/32 - 166.4ms/batch - loss: 0.45769 - diff: 7.32mlTrain batch 4/32 - 161.2ms/batch - loss: 0.43638 - diff: 6.98mlTrain batch 5/32 - 171.5ms/batch - loss: 0.40669 - diff: 6.51mlTrain batch 6/32 - 199.7ms/batch - loss: 0.37909 - diff: 6.07mlTrain batch 7/32 - 167.5ms/batch - loss: 0.37923 - diff: 6.07mlTrain batch 8/32 - 194.2ms/batch - loss: 0.38320 - diff: 6.13mlTrain batch 9/32 - 148.4ms/batch - loss: 0.37982 - diff: 6.08mlTrain batch 10/32 - 186.1ms/batch - loss: 0.39187 - diff: 6.27mlTrain batch 11/32 - 177.0ms/batch - loss: 0.39466 - diff: 6.31mlTrain batch 12/32 - 209.1ms/batch - loss: 0.38907 - diff: 6.23mlTrain batch 13/32 - 154.4ms/batch - loss: 0.37918 - diff: 6.07mlTrain batch 14/32 - 170.3ms/batch - loss: 0.37019 - diff: 5.92mlTrain batch 15/32 - 174.6ms/batch - loss: 0.36781 - diff: 5.88mlTrain batch 16/32 - 215.4ms/batch - loss: 0.36473 - diff: 5.84mlTrain batch 17/32 - 206.1ms/batch - loss: 0.36264 - diff: 5.80mlTrain batch 18/32 - 154.9ms/batch - loss: 0.36612 - diff: 5.86mlTrain batch 19/32 - 168.8ms/batch - loss: 0.36798 - diff: 5.89mlTrain batch 20/32 - 193.7ms/batch - loss: 0.36300 - diff: 5.81mlTrain batch 21/32 - 192.2ms/batch - loss: 0.37905 - diff: 6.06mlTrain batch 22/32 - 151.4ms/batch - loss: 0.37830 - diff: 6.05mlTrain batch 23/32 - 135.5ms/batch - loss: 0.37572 - diff: 6.01mlTrain batch 24/32 - 174.0ms/batch - loss: 0.37731 - diff: 6.04mlTrain batch 25/32 - 150.9ms/batch - loss: 0.37205 - diff: 5.95mlTrain batch 26/32 - 157.6ms/batch - loss: 0.37224 - diff: 5.96mlTrain batch 27/32 - 177.1ms/batch - loss: 0.37098 - diff: 5.94mlTrain batch 28/32 - 127.5ms/batch - loss: 0.36944 - diff: 5.91mlTrain batch 29/32 - 163.2ms/batch - loss: 0.36749 - diff: 5.88mlTrain batch 30/32 - 163.0ms/batch - loss: 0.38158 - diff: 6.11mlTrain batch 31/32 - 123.5ms/batch - loss: 0.37937 - diff: 6.07mlTrain batch 32/32 - 100.8ms/batch - loss: 0.41418 - diff: 6.17mlTrain batch 32/32 - 17.4s 100.8ms/batch - loss: 0.41418 - diff: 6.17ml
Test 1.1s: val_loss: 0.92211 - diff: 13.94ml

Epoch 147: current best loss = 0.89711, at epoch 110
Train batch 1/32 - 171.1ms/batch - loss: 0.32120 - diff: 5.14mlTrain batch 2/32 - 160.2ms/batch - loss: 0.42754 - diff: 6.84mlTrain batch 3/32 - 154.7ms/batch - loss: 0.42769 - diff: 6.84mlTrain batch 4/32 - 154.7ms/batch - loss: 0.43027 - diff: 6.88mlTrain batch 5/32 - 172.5ms/batch - loss: 0.41566 - diff: 6.65mlTrain batch 6/32 - 179.0ms/batch - loss: 0.39590 - diff: 6.33mlTrain batch 7/32 - 194.6ms/batch - loss: 0.40144 - diff: 6.42mlTrain batch 8/32 - 175.7ms/batch - loss: 0.40787 - diff: 6.53mlTrain batch 9/32 - 174.0ms/batch - loss: 0.39464 - diff: 6.31mlTrain batch 10/32 - 156.5ms/batch - loss: 0.39237 - diff: 6.28mlTrain batch 11/32 - 162.9ms/batch - loss: 0.38316 - diff: 6.13mlTrain batch 12/32 - 203.7ms/batch - loss: 0.39695 - diff: 6.35mlTrain batch 13/32 - 158.0ms/batch - loss: 0.39869 - diff: 6.38mlTrain batch 14/32 - 143.1ms/batch - loss: 0.39180 - diff: 6.27mlTrain batch 15/32 - 186.4ms/batch - loss: 0.39594 - diff: 6.34mlTrain batch 16/32 - 204.8ms/batch - loss: 0.39069 - diff: 6.25mlTrain batch 17/32 - 182.8ms/batch - loss: 0.38200 - diff: 6.11mlTrain batch 18/32 - 144.9ms/batch - loss: 0.38618 - diff: 6.18mlTrain batch 19/32 - 192.3ms/batch - loss: 0.39177 - diff: 6.27mlTrain batch 20/32 - 170.5ms/batch - loss: 0.38512 - diff: 6.16mlTrain batch 21/32 - 185.6ms/batch - loss: 0.38584 - diff: 6.17mlTrain batch 22/32 - 144.6ms/batch - loss: 0.38381 - diff: 6.14mlTrain batch 23/32 - 166.9ms/batch - loss: 0.38244 - diff: 6.12mlTrain batch 24/32 - 152.0ms/batch - loss: 0.38078 - diff: 6.09mlTrain batch 25/32 - 159.1ms/batch - loss: 0.37737 - diff: 6.04mlTrain batch 26/32 - 168.2ms/batch - loss: 0.37562 - diff: 6.01mlTrain batch 27/32 - 195.4ms/batch - loss: 0.38272 - diff: 6.12mlTrain batch 28/32 - 138.6ms/batch - loss: 0.38574 - diff: 6.17mlTrain batch 29/32 - 158.4ms/batch - loss: 0.40132 - diff: 6.42mlTrain batch 30/32 - 146.1ms/batch - loss: 0.40055 - diff: 6.41mlTrain batch 31/32 - 152.7ms/batch - loss: 0.39692 - diff: 6.35mlTrain batch 32/32 - 134.4ms/batch - loss: 0.41292 - diff: 6.38mlTrain batch 32/32 - 17.6s 134.4ms/batch - loss: 0.41292 - diff: 6.38ml
Test 1.2s: val_loss: 0.90957 - diff: 14.07ml

Epoch 148: current best loss = 0.89711, at epoch 110
Train batch 1/32 - 199.4ms/batch - loss: 0.35778 - diff: 5.72mlTrain batch 2/32 - 147.4ms/batch - loss: 0.44193 - diff: 7.07mlTrain batch 3/32 - 181.1ms/batch - loss: 0.38825 - diff: 6.21mlTrain batch 4/32 - 162.5ms/batch - loss: 0.39759 - diff: 6.36mlTrain batch 5/32 - 173.7ms/batch - loss: 0.37412 - diff: 5.99mlTrain batch 6/32 - 210.1ms/batch - loss: 0.39086 - diff: 6.25mlTrain batch 7/32 - 157.3ms/batch - loss: 0.37333 - diff: 5.97mlTrain batch 8/32 - 130.6ms/batch - loss: 0.35951 - diff: 5.75mlTrain batch 9/32 - 167.0ms/batch - loss: 0.35783 - diff: 5.73mlTrain batch 10/32 - 162.3ms/batch - loss: 0.35596 - diff: 5.70mlTrain batch 11/32 - 169.5ms/batch - loss: 0.36776 - diff: 5.88mlTrain batch 12/32 - 155.0ms/batch - loss: 0.35782 - diff: 5.73mlTrain batch 13/32 - 155.8ms/batch - loss: 0.35619 - diff: 5.70mlTrain batch 14/32 - 159.4ms/batch - loss: 0.39153 - diff: 6.26mlTrain batch 15/32 - 115.1ms/batch - loss: 0.38815 - diff: 6.21mlTrain batch 16/32 - 181.6ms/batch - loss: 0.38911 - diff: 6.23mlTrain batch 17/32 - 178.8ms/batch - loss: 0.37956 - diff: 6.07mlTrain batch 18/32 - 213.2ms/batch - loss: 0.38179 - diff: 6.11mlTrain batch 19/32 - 163.3ms/batch - loss: 0.38113 - diff: 6.10mlTrain batch 20/32 - 158.6ms/batch - loss: 0.37227 - diff: 5.96mlTrain batch 21/32 - 133.0ms/batch - loss: 0.40929 - diff: 6.55mlTrain batch 22/32 - 153.8ms/batch - loss: 0.40575 - diff: 6.49mlTrain batch 23/32 - 150.2ms/batch - loss: 0.40918 - diff: 6.55mlTrain batch 24/32 - 154.0ms/batch - loss: 0.40972 - diff: 6.56mlTrain batch 25/32 - 154.2ms/batch - loss: 0.41075 - diff: 6.57mlTrain batch 26/32 - 160.3ms/batch - loss: 0.41181 - diff: 6.59mlTrain batch 27/32 - 162.5ms/batch - loss: 0.40915 - diff: 6.55mlTrain batch 28/32 - 141.1ms/batch - loss: 0.40442 - diff: 6.47mlTrain batch 29/32 - 189.5ms/batch - loss: 0.40143 - diff: 6.42mlTrain batch 30/32 - 165.0ms/batch - loss: 0.40304 - diff: 6.45mlTrain batch 31/32 - 185.4ms/batch - loss: 0.40714 - diff: 6.51mlTrain batch 32/32 - 151.4ms/batch - loss: 0.45838 - diff: 6.68mlTrain batch 32/32 - 17.8s 151.4ms/batch - loss: 0.45838 - diff: 6.68ml
Test 1.1s: val_loss: 0.91525 - diff: 14.10ml

Epoch 149: current best loss = 0.89711, at epoch 110
Train batch 1/32 - 159.2ms/batch - loss: 0.54012 - diff: 8.64mlTrain batch 2/32 - 168.0ms/batch - loss: 0.50493 - diff: 8.08mlTrain batch 3/32 - 217.3ms/batch - loss: 0.45505 - diff: 7.28mlTrain batch 4/32 - 158.4ms/batch - loss: 0.49816 - diff: 7.97mlTrain batch 5/32 - 142.0ms/batch - loss: 0.45778 - diff: 7.32mlTrain batch 6/32 - 154.4ms/batch - loss: 0.45381 - diff: 7.26mlTrain batch 7/32 - 114.8ms/batch - loss: 0.44066 - diff: 7.05mlTrain batch 8/32 - 127.9ms/batch - loss: 0.42410 - diff: 6.79mlTrain batch 9/32 - 216.5ms/batch - loss: 0.43157 - diff: 6.91mlTrain batch 10/32 - 237.7ms/batch - loss: 0.42743 - diff: 6.84mlTrain batch 11/32 - 153.4ms/batch - loss: 0.41703 - diff: 6.67mlTrain batch 12/32 - 168.6ms/batch - loss: 0.40442 - diff: 6.47mlTrain batch 13/32 - 171.4ms/batch - loss: 0.38861 - diff: 6.22mlTrain batch 14/32 - 148.3ms/batch - loss: 0.38218 - diff: 6.11mlTrain batch 15/32 - 193.0ms/batch - loss: 0.37930 - diff: 6.07mlTrain batch 16/32 - 124.2ms/batch - loss: 0.38144 - diff: 6.10mlTrain batch 17/32 - 146.2ms/batch - loss: 0.37236 - diff: 5.96mlTrain batch 18/32 - 189.3ms/batch - loss: 0.37308 - diff: 5.97mlTrain batch 19/32 - 159.7ms/batch - loss: 0.37322 - diff: 5.97mlTrain batch 20/32 - 170.1ms/batch - loss: 0.37179 - diff: 5.95mlTrain batch 21/32 - 159.8ms/batch - loss: 0.36987 - diff: 5.92mlTrain batch 22/32 - 216.0ms/batch - loss: 0.36715 - diff: 5.87mlTrain batch 23/32 - 144.9ms/batch - loss: 0.36379 - diff: 5.82mlTrain batch 24/32 - 111.7ms/batch - loss: 0.36267 - diff: 5.80mlTrain batch 25/32 - 154.5ms/batch - loss: 0.37198 - diff: 5.95mlTrain batch 26/32 - 172.3ms/batch - loss: 0.37053 - diff: 5.93mlTrain batch 27/32 - 199.8ms/batch - loss: 0.37283 - diff: 5.97mlTrain batch 28/32 - 153.9ms/batch - loss: 0.37078 - diff: 5.93mlTrain batch 29/32 - 161.0ms/batch - loss: 0.37336 - diff: 5.97mlTrain batch 30/32 - 184.0ms/batch - loss: 0.37710 - diff: 6.03mlTrain batch 31/32 - 111.5ms/batch - loss: 0.37396 - diff: 5.98mlTrain batch 32/32 - 118.9ms/batch - loss: 0.38621 - diff: 6.00mlTrain batch 32/32 - 17.5s 118.9ms/batch - loss: 0.38621 - diff: 6.00ml
Test 1.3s: val_loss: 0.91129 - diff: 14.24ml

