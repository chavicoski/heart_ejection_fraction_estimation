nohup: ignoring input
Running experiment 2CH_preproc1_150x150_bySlices_dataset_allViews_Systole_TimeAsDepth_1_Adam-0.001_MSE_DA3
Going to train with the GPU in the slot 0 -> device model: GeForce RTX 2080
Model architecture:
 TimeAsDepth_1(
  (conv_block): Sequential(
    (0): Conv2d(30, 64, kernel_size=(3, 3), stride=(2, 2))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))
    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU()
    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (7): Dropout(p=0.4, inplace=False)
    (8): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))
    (9): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): ReLU()
    (11): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))
    (12): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (13): ReLU()
    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (15): Dropout(p=0.4, inplace=False)
    (16): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))
    (17): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): ReLU()
    (19): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))
    (20): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (21): ReLU()
    (22): Dropout(p=0.4, inplace=False)
    (23): AdaptiveAvgPool2d(output_size=(1, 1))
  )
  (flatten): Flatten()
  (dense_block): Sequential(
    (0): Linear(in_features=256, out_features=1024, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.4, inplace=False)
    (3): Linear(in_features=1024, out_features=1, bias=True)
  )
) 


############################
# TRAIN PHASE:  100 epochs #
############################

Epoch 0: 
Train batch 1/4 - 150.2ms/batch - loss: 59.62889 - diff: 71.64mlTrain batch 2/4 - 151.9ms/batch - loss: 62.74127 - diff: 74.68mlTrain batch 3/4 - 149.8ms/batch - loss: 53.60476 - diff: 70.12mlTrain batch 4/4 - 132.8ms/batch - loss: 54.97930 - diff: 70.72mlTrain batch 4/4 - 23.2s 132.8ms/batch - loss: 54.97930 - diff: 70.72ml
Test 2.7s: val_loss: 58.03046 - diff: 66.59ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Systole_TimeAsDepth_1_Adam-0.001_MSE_DA3_best

Epoch 1: current best loss = 58.03046, at epoch 0
Train batch 1/4 - 152.1ms/batch - loss: 55.81251 - diff: 68.84mlTrain batch 2/4 - 148.6ms/batch - loss: 50.67611 - diff: 67.06mlTrain batch 3/4 - 150.6ms/batch - loss: 48.44963 - diff: 66.19mlTrain batch 4/4 - 133.0ms/batch - loss: 50.26047 - diff: 66.60mlTrain batch 4/4 - 10.9s 133.0ms/batch - loss: 50.26047 - diff: 66.60ml
Test 1.0s: val_loss: 38.89761 - diff: 48.68ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Systole_TimeAsDepth_1_Adam-0.001_MSE_DA3_best

Epoch 2: current best loss = 38.89761, at epoch 1
Train batch 1/4 - 149.0ms/batch - loss: 40.86556 - diff: 60.22mlTrain batch 2/4 - 144.1ms/batch - loss: 40.86889 - diff: 60.68mlTrain batch 3/4 - 150.6ms/batch - loss: 44.91960 - diff: 61.83mlTrain batch 4/4 - 133.0ms/batch - loss: 43.44108 - diff: 60.49mlTrain batch 4/4 - 10.5s 133.0ms/batch - loss: 43.44108 - diff: 60.49ml
Test 0.6s: val_loss: 31.73032 - diff: 44.78ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Systole_TimeAsDepth_1_Adam-0.001_MSE_DA3_best

Epoch 3: current best loss = 31.73032, at epoch 2
Train batch 1/4 - 150.6ms/batch - loss: 28.10297 - diff: 50.38mlTrain batch 2/4 - 144.1ms/batch - loss: 32.33640 - diff: 52.82mlTrain batch 3/4 - 150.9ms/batch - loss: 35.11519 - diff: 52.77mlTrain batch 4/4 - 138.0ms/batch - loss: 35.12342 - diff: 52.34mlTrain batch 4/4 - 10.7s 138.0ms/batch - loss: 35.12342 - diff: 52.34ml
Test 0.6s: val_loss: 34.62957 - diff: 44.52ml

Epoch 4: current best loss = 31.73032, at epoch 2
Train batch 1/4 - 147.6ms/batch - loss: 23.57502 - diff: 44.23mlTrain batch 2/4 - 146.1ms/batch - loss: 26.31838 - diff: 45.99mlTrain batch 3/4 - 148.8ms/batch - loss: 28.24684 - diff: 43.71mlTrain batch 4/4 - 133.3ms/batch - loss: 26.71447 - diff: 42.23mlTrain batch 4/4 - 10.7s 133.3ms/batch - loss: 26.71447 - diff: 42.23ml
Test 0.6s: val_loss: 11.57472 - diff: 24.13ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Systole_TimeAsDepth_1_Adam-0.001_MSE_DA3_best

Epoch 5: current best loss = 11.57472, at epoch 4
Train batch 1/4 - 152.1ms/batch - loss: 24.00770 - diff: 39.25mlTrain batch 2/4 - 147.5ms/batch - loss: 23.73401 - diff: 37.78mlTrain batch 3/4 - 150.7ms/batch - loss: 21.06477 - diff: 36.09mlTrain batch 4/4 - 134.5ms/batch - loss: 18.92032 - diff: 34.26mlTrain batch 4/4 - 10.7s 134.5ms/batch - loss: 18.92032 - diff: 34.26ml
Test 0.6s: val_loss: 14.03460 - diff: 25.24ml

Epoch 6: current best loss = 11.57472, at epoch 4
Train batch 1/4 - 151.9ms/batch - loss: 13.74925 - diff: 28.26mlTrain batch 2/4 - 144.4ms/batch - loss: 10.95214 - diff: 25.92mlTrain batch 3/4 - 147.2ms/batch - loss: 13.64916 - diff: 26.59mlTrain batch 4/4 - 133.3ms/batch - loss: 12.89120 - diff: 26.11mlTrain batch 4/4 - 10.7s 133.3ms/batch - loss: 12.89120 - diff: 26.11ml
Test 0.6s: val_loss: 49.35533 - diff: 66.04ml

Epoch 7: current best loss = 11.57472, at epoch 4
Train batch 1/4 - 150.4ms/batch - loss: 17.11366 - diff: 28.03mlTrain batch 2/4 - 144.2ms/batch - loss: 11.49215 - diff: 24.48mlTrain batch 3/4 - 150.5ms/batch - loss: 11.21286 - diff: 24.56mlTrain batch 4/4 - 133.8ms/batch - loss: 11.18463 - diff: 25.28mlTrain batch 4/4 - 10.7s 133.8ms/batch - loss: 11.18463 - diff: 25.28ml
Test 0.6s: val_loss: 31.44201 - diff: 48.94ml

Epoch 8: current best loss = 11.57472, at epoch 4
Train batch 1/4 - 151.9ms/batch - loss: 12.37297 - diff: 27.20mlTrain batch 2/4 - 144.5ms/batch - loss: 12.05429 - diff: 26.56mlTrain batch 3/4 - 146.9ms/batch - loss: 10.51500 - diff: 26.03mlTrain batch 4/4 - 133.1ms/batch - loss: 10.05962 - diff: 25.98mlTrain batch 4/4 - 10.7s 133.1ms/batch - loss: 10.05962 - diff: 25.98ml
Test 0.6s: val_loss: 143.22181 - diff: 107.38ml

Epoch 9: current best loss = 11.57472, at epoch 4
Train batch 1/4 - 152.2ms/batch - loss: 16.36772 - diff: 28.54mlTrain batch 2/4 - 147.0ms/batch - loss: 12.48020 - diff: 26.89mlTrain batch 3/4 - 150.6ms/batch - loss: 11.36342 - diff: 26.91mlTrain batch 4/4 - 134.5ms/batch - loss: 11.16162 - diff: 26.89mlTrain batch 4/4 - 10.7s 134.5ms/batch - loss: 11.16162 - diff: 26.89ml
Test 0.6s: val_loss: 13.99977 - diff: 24.93ml

Epoch 10: current best loss = 11.57472, at epoch 4
Train batch 1/4 - 152.2ms/batch - loss: 10.98604 - diff: 25.94mlTrain batch 2/4 - 144.5ms/batch - loss: 12.43436 - diff: 26.53mlTrain batch 3/4 - 150.8ms/batch - loss: 10.31155 - diff: 25.22mlTrain batch 4/4 - 139.0ms/batch - loss: 9.54628 - diff: 24.81mlTrain batch 4/4 - 10.8s 139.0ms/batch - loss: 9.54628 - diff: 24.81ml
Test 0.6s: val_loss: 38.64742 - diff: 50.22ml

Epoch 11: current best loss = 11.57472, at epoch 4
Train batch 1/4 - 152.0ms/batch - loss: 14.50349 - diff: 26.74mlTrain batch 2/4 - 144.4ms/batch - loss: 9.95413 - diff: 23.55mlTrain batch 3/4 - 149.4ms/batch - loss: 9.01098 - diff: 23.33mlTrain batch 4/4 - 133.2ms/batch - loss: 8.44451 - diff: 22.82mlTrain batch 4/4 - 10.7s 133.2ms/batch - loss: 8.44451 - diff: 22.82ml
Test 0.6s: val_loss: 20.13262 - diff: 31.00ml

Epoch 12: current best loss = 11.57472, at epoch 4
Train batch 1/4 - 152.1ms/batch - loss: 7.24085 - diff: 23.53mlTrain batch 2/4 - 144.4ms/batch - loss: 6.59635 - diff: 21.67mlTrain batch 3/4 - 150.0ms/batch - loss: 7.26676 - diff: 21.45mlTrain batch 4/4 - 139.2ms/batch - loss: 8.41395 - diff: 21.20mlTrain batch 4/4 - 10.7s 139.2ms/batch - loss: 8.41395 - diff: 21.20ml
Test 0.6s: val_loss: 29.82651 - diff: 41.19ml

Epoch 13: current best loss = 11.57472, at epoch 4
Train batch 1/4 - 152.1ms/batch - loss: 6.04755 - diff: 20.91mlTrain batch 2/4 - 149.4ms/batch - loss: 7.76385 - diff: 21.10mlTrain batch 3/4 - 150.9ms/batch - loss: 8.28297 - diff: 21.18mlTrain batch 4/4 - 133.4ms/batch - loss: 7.56920 - diff: 20.43mlTrain batch 4/4 - 10.7s 133.4ms/batch - loss: 7.56920 - diff: 20.43ml
Test 0.6s: val_loss: 38.72057 - diff: 51.54ml

Epoch 14: current best loss = 11.57472, at epoch 4
Train batch 1/4 - 152.1ms/batch - loss: 6.44747 - diff: 21.19mlTrain batch 2/4 - 144.5ms/batch - loss: 8.84503 - diff: 22.27mlTrain batch 3/4 - 147.4ms/batch - loss: 7.52406 - diff: 21.16mlTrain batch 4/4 - 136.0ms/batch - loss: 7.64238 - diff: 21.27mlTrain batch 4/4 - 10.7s 136.0ms/batch - loss: 7.64238 - diff: 21.27ml
Test 0.6s: val_loss: 19.06294 - diff: 31.78ml

Epoch 15: current best loss = 11.57472, at epoch 4
Train batch 1/4 - 152.0ms/batch - loss: 4.18177 - diff: 17.76mlTrain batch 2/4 - 146.3ms/batch - loss: 5.10592 - diff: 18.92mlTrain batch 3/4 - 150.8ms/batch - loss: 5.44781 - diff: 19.44mlTrain batch 4/4 - 133.2ms/batch - loss: 7.89446 - diff: 20.46mlTrain batch 4/4 - 10.7s 133.2ms/batch - loss: 7.89446 - diff: 20.46ml
Test 0.6s: val_loss: 34.40615 - diff: 48.87ml
Epoch    16: reducing learning rate of group 0 to 5.0000e-04.

Epoch 16: current best loss = 11.57472, at epoch 4
Train batch 1/4 - 147.9ms/batch - loss: 8.62250 - diff: 22.53mlTrain batch 2/4 - 145.9ms/batch - loss: 9.23802 - diff: 21.82mlTrain batch 3/4 - 150.6ms/batch - loss: 9.77519 - diff: 22.96mlTrain batch 4/4 - 138.0ms/batch - loss: 8.84054 - diff: 22.28mlTrain batch 4/4 - 10.7s 138.0ms/batch - loss: 8.84054 - diff: 22.28ml
Test 0.6s: val_loss: 17.46882 - diff: 33.33ml

Epoch 17: current best loss = 11.57472, at epoch 4
Train batch 1/4 - 152.2ms/batch - loss: 9.68806 - diff: 23.60mlTrain batch 2/4 - 144.5ms/batch - loss: 8.37746 - diff: 22.28mlTrain batch 3/4 - 149.2ms/batch - loss: 8.65769 - diff: 21.97mlTrain batch 4/4 - 133.3ms/batch - loss: 7.96219 - diff: 21.28mlTrain batch 4/4 - 10.7s 133.3ms/batch - loss: 7.96219 - diff: 21.28ml
Test 0.6s: val_loss: 9.62065 - diff: 22.67ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Systole_TimeAsDepth_1_Adam-0.001_MSE_DA3_best

Epoch 18: current best loss = 9.62065, at epoch 17
Train batch 1/4 - 152.1ms/batch - loss: 10.29863 - diff: 22.48mlTrain batch 2/4 - 145.4ms/batch - loss: 8.34088 - diff: 20.43mlTrain batch 3/4 - 150.8ms/batch - loss: 7.39297 - diff: 20.30mlTrain batch 4/4 - 133.4ms/batch - loss: 7.37917 - diff: 20.46mlTrain batch 4/4 - 10.7s 133.4ms/batch - loss: 7.37917 - diff: 20.46ml
Test 0.6s: val_loss: 10.19036 - diff: 19.45ml

Epoch 19: current best loss = 9.62065, at epoch 17
Train batch 1/4 - 152.2ms/batch - loss: 7.60573 - diff: 20.99mlTrain batch 2/4 - 144.4ms/batch - loss: 7.83825 - diff: 21.05mlTrain batch 3/4 - 147.0ms/batch - loss: 6.97256 - diff: 20.63mlTrain batch 4/4 - 133.3ms/batch - loss: 7.50913 - diff: 20.79mlTrain batch 4/4 - 10.6s 133.3ms/batch - loss: 7.50913 - diff: 20.79ml
Test 0.6s: val_loss: 10.69845 - diff: 21.29ml

Epoch 20: current best loss = 9.62065, at epoch 17
Train batch 1/4 - 148.6ms/batch - loss: 7.90236 - diff: 24.30mlTrain batch 2/4 - 144.3ms/batch - loss: 6.24039 - diff: 21.35mlTrain batch 3/4 - 150.8ms/batch - loss: 7.97847 - diff: 21.62mlTrain batch 4/4 - 134.4ms/batch - loss: 7.20865 - diff: 20.77mlTrain batch 4/4 - 10.7s 134.4ms/batch - loss: 7.20865 - diff: 20.77ml
Test 0.6s: val_loss: 9.57120 - diff: 19.78ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Systole_TimeAsDepth_1_Adam-0.001_MSE_DA3_best

Epoch 21: current best loss = 9.57120, at epoch 20
Train batch 1/4 - 151.9ms/batch - loss: 7.27162 - diff: 20.61mlTrain batch 2/4 - 145.6ms/batch - loss: 8.41864 - diff: 20.73mlTrain batch 3/4 - 147.6ms/batch - loss: 7.75007 - diff: 20.85mlTrain batch 4/4 - 133.2ms/batch - loss: 7.09864 - diff: 20.07mlTrain batch 4/4 - 10.7s 133.2ms/batch - loss: 7.09864 - diff: 20.07ml
Test 0.6s: val_loss: 8.77465 - diff: 19.95ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Systole_TimeAsDepth_1_Adam-0.001_MSE_DA3_best

Epoch 22: current best loss = 8.77465, at epoch 21
Train batch 1/4 - 148.0ms/batch - loss: 5.21929 - diff: 18.97mlTrain batch 2/4 - 144.3ms/batch - loss: 5.25443 - diff: 19.55mlTrain batch 3/4 - 150.5ms/batch - loss: 5.28447 - diff: 19.50mlTrain batch 4/4 - 133.9ms/batch - loss: 7.15028 - diff: 19.93mlTrain batch 4/4 - 10.7s 133.9ms/batch - loss: 7.15028 - diff: 19.93ml
Test 0.6s: val_loss: 13.07933 - diff: 22.25ml

Epoch 23: current best loss = 8.77465, at epoch 21
Train batch 1/4 - 151.5ms/batch - loss: 5.52877 - diff: 19.80mlTrain batch 2/4 - 144.5ms/batch - loss: 6.39817 - diff: 20.47mlTrain batch 3/4 - 147.1ms/batch - loss: 5.64327 - diff: 19.46mlTrain batch 4/4 - 135.7ms/batch - loss: 5.95692 - diff: 19.17mlTrain batch 4/4 - 10.7s 135.7ms/batch - loss: 5.95692 - diff: 19.17ml
Test 0.6s: val_loss: 12.62973 - diff: 23.00ml

Epoch 24: current best loss = 8.77465, at epoch 21
Train batch 1/4 - 151.5ms/batch - loss: 4.53889 - diff: 18.45mlTrain batch 2/4 - 149.4ms/batch - loss: 4.69898 - diff: 18.47mlTrain batch 3/4 - 150.8ms/batch - loss: 6.64648 - diff: 19.54mlTrain batch 4/4 - 133.3ms/batch - loss: 6.50757 - diff: 19.69mlTrain batch 4/4 - 10.7s 133.3ms/batch - loss: 6.50757 - diff: 19.69ml
Test 0.6s: val_loss: 14.14258 - diff: 22.24ml

Epoch 25: current best loss = 8.77465, at epoch 21
Train batch 1/4 - 148.2ms/batch - loss: 7.74012 - diff: 20.61mlTrain batch 2/4 - 144.5ms/batch - loss: 7.44138 - diff: 20.45mlTrain batch 3/4 - 150.8ms/batch - loss: 6.42714 - diff: 19.83mlTrain batch 4/4 - 139.1ms/batch - loss: 6.46742 - diff: 20.19mlTrain batch 4/4 - 10.7s 139.1ms/batch - loss: 6.46742 - diff: 20.19ml
Test 0.6s: val_loss: 10.36801 - diff: 20.92ml

Epoch 26: current best loss = 8.77465, at epoch 21
Train batch 1/4 - 148.9ms/batch - loss: 4.87620 - diff: 19.10mlTrain batch 2/4 - 147.7ms/batch - loss: 4.33788 - diff: 17.70mlTrain batch 3/4 - 150.5ms/batch - loss: 5.90200 - diff: 18.41mlTrain batch 4/4 - 133.3ms/batch - loss: 5.62174 - diff: 18.35mlTrain batch 4/4 - 10.7s 133.3ms/batch - loss: 5.62174 - diff: 18.35ml
Test 0.6s: val_loss: 8.55465 - diff: 19.28ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Systole_TimeAsDepth_1_Adam-0.001_MSE_DA3_best

Epoch 27: current best loss = 8.55465, at epoch 26
Train batch 1/4 - 147.4ms/batch - loss: 11.03819 - diff: 20.05mlTrain batch 2/4 - 145.4ms/batch - loss: 8.15414 - diff: 19.95mlTrain batch 3/4 - 146.8ms/batch - loss: 6.98586 - diff: 19.03mlTrain batch 4/4 - 135.6ms/batch - loss: 6.82276 - diff: 19.23mlTrain batch 4/4 - 10.7s 135.6ms/batch - loss: 6.82276 - diff: 19.23ml
Test 0.6s: val_loss: 8.35255 - diff: 18.98ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Systole_TimeAsDepth_1_Adam-0.001_MSE_DA3_best

Epoch 28: current best loss = 8.35255, at epoch 27
Train batch 1/4 - 148.4ms/batch - loss: 9.95711 - diff: 22.05mlTrain batch 2/4 - 144.3ms/batch - loss: 7.07150 - diff: 19.90mlTrain batch 3/4 - 150.6ms/batch - loss: 6.21034 - diff: 19.39mlTrain batch 4/4 - 135.3ms/batch - loss: 6.13595 - diff: 19.23mlTrain batch 4/4 - 10.6s 135.3ms/batch - loss: 6.13595 - diff: 19.23ml
Test 0.6s: val_loss: 15.35999 - diff: 30.47ml

Epoch 29: current best loss = 8.35255, at epoch 27
Train batch 1/4 - 152.2ms/batch - loss: 4.15898 - diff: 17.81mlTrain batch 2/4 - 147.2ms/batch - loss: 4.31769 - diff: 17.91mlTrain batch 3/4 - 148.5ms/batch - loss: 5.20094 - diff: 18.55mlTrain batch 4/4 - 133.2ms/batch - loss: 6.56657 - diff: 19.14mlTrain batch 4/4 - 10.7s 133.2ms/batch - loss: 6.56657 - diff: 19.14ml
Test 0.6s: val_loss: 10.14469 - diff: 19.24ml

Epoch 30: current best loss = 8.35255, at epoch 27
Train batch 1/4 - 152.2ms/batch - loss: 4.25615 - diff: 18.24mlTrain batch 2/4 - 144.5ms/batch - loss: 4.47327 - diff: 18.65mlTrain batch 3/4 - 150.7ms/batch - loss: 4.47952 - diff: 18.47mlTrain batch 4/4 - 138.6ms/batch - loss: 7.00875 - diff: 20.27mlTrain batch 4/4 - 10.7s 138.6ms/batch - loss: 7.00875 - diff: 20.27ml
Test 0.6s: val_loss: 11.10970 - diff: 22.40ml

Epoch 31: current best loss = 8.35255, at epoch 27
Train batch 1/4 - 152.0ms/batch - loss: 7.96717 - diff: 19.89mlTrain batch 2/4 - 144.5ms/batch - loss: 6.77003 - diff: 19.81mlTrain batch 3/4 - 151.0ms/batch - loss: 5.84551 - diff: 18.83mlTrain batch 4/4 - 133.4ms/batch - loss: 5.44344 - diff: 18.31mlTrain batch 4/4 - 10.7s 133.4ms/batch - loss: 5.44344 - diff: 18.31ml
Test 0.6s: val_loss: 11.08540 - diff: 25.37ml

Epoch 32: current best loss = 8.35255, at epoch 27
Train batch 1/4 - 152.1ms/batch - loss: 4.13941 - diff: 17.54mlTrain batch 2/4 - 144.5ms/batch - loss: 4.20305 - diff: 17.48mlTrain batch 3/4 - 146.1ms/batch - loss: 6.32245 - diff: 19.22mlTrain batch 4/4 - 133.2ms/batch - loss: 6.09867 - diff: 19.14mlTrain batch 4/4 - 10.7s 133.2ms/batch - loss: 6.09867 - diff: 19.14ml
Test 0.6s: val_loss: 10.61441 - diff: 24.54ml

Epoch 33: current best loss = 8.35255, at epoch 27
Train batch 1/4 - 152.3ms/batch - loss: 9.77050 - diff: 21.85mlTrain batch 2/4 - 147.4ms/batch - loss: 7.24338 - diff: 20.23mlTrain batch 3/4 - 150.9ms/batch - loss: 6.05122 - diff: 19.28mlTrain batch 4/4 - 133.4ms/batch - loss: 6.14118 - diff: 19.69mlTrain batch 4/4 - 10.7s 133.4ms/batch - loss: 6.14118 - diff: 19.69ml
Test 0.6s: val_loss: 11.33398 - diff: 23.90ml

Epoch 34: current best loss = 8.35255, at epoch 27
Train batch 1/4 - 151.9ms/batch - loss: 5.80871 - diff: 19.46mlTrain batch 2/4 - 144.3ms/batch - loss: 5.62005 - diff: 19.73mlTrain batch 3/4 - 150.9ms/batch - loss: 5.12833 - diff: 18.72mlTrain batch 4/4 - 139.3ms/batch - loss: 6.87254 - diff: 19.37mlTrain batch 4/4 - 10.7s 139.3ms/batch - loss: 6.87254 - diff: 19.37ml
Test 0.6s: val_loss: 23.73563 - diff: 39.67ml

Epoch 35: current best loss = 8.35255, at epoch 27
Train batch 1/4 - 151.7ms/batch - loss: 4.04545 - diff: 17.50mlTrain batch 2/4 - 144.4ms/batch - loss: 5.22799 - diff: 18.01mlTrain batch 3/4 - 150.7ms/batch - loss: 4.77251 - diff: 17.52mlTrain batch 4/4 - 133.2ms/batch - loss: 5.81705 - diff: 18.39mlTrain batch 4/4 - 10.7s 133.2ms/batch - loss: 5.81705 - diff: 18.39ml
Test 0.6s: val_loss: 25.99937 - diff: 42.90ml

Epoch 36: current best loss = 8.35255, at epoch 27
Train batch 1/4 - 148.8ms/batch - loss: 5.11245 - diff: 19.44mlTrain batch 2/4 - 144.4ms/batch - loss: 8.08642 - diff: 20.17mlTrain batch 3/4 - 148.4ms/batch - loss: 6.87706 - diff: 19.69mlTrain batch 4/4 - 137.7ms/batch - loss: 6.32475 - diff: 19.14mlTrain batch 4/4 - 10.7s 137.7ms/batch - loss: 6.32475 - diff: 19.14ml
Test 0.6s: val_loss: 11.11328 - diff: 20.79ml

Epoch 37: current best loss = 8.35255, at epoch 27
Train batch 1/4 - 150.2ms/batch - loss: 5.05162 - diff: 18.43mlTrain batch 2/4 - 149.0ms/batch - loss: 4.75013 - diff: 18.45mlTrain batch 3/4 - 150.8ms/batch - loss: 5.56822 - diff: 19.26mlTrain batch 4/4 - 133.3ms/batch - loss: 6.09908 - diff: 19.23mlTrain batch 4/4 - 10.7s 133.3ms/batch - loss: 6.09908 - diff: 19.23ml
Test 0.6s: val_loss: 7.32436 - diff: 18.42ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Systole_TimeAsDepth_1_Adam-0.001_MSE_DA3_best

Epoch 38: current best loss = 7.32436, at epoch 37
Train batch 1/4 - 152.0ms/batch - loss: 6.13062 - diff: 19.82mlTrain batch 2/4 - 144.5ms/batch - loss: 5.66171 - diff: 19.25mlTrain batch 3/4 - 150.9ms/batch - loss: 6.49949 - diff: 19.17mlTrain batch 4/4 - 139.1ms/batch - loss: 5.85433 - diff: 18.45mlTrain batch 4/4 - 10.7s 139.1ms/batch - loss: 5.85433 - diff: 18.45ml
Test 0.7s: val_loss: 9.18656 - diff: 21.10ml

Epoch 39: current best loss = 7.32436, at epoch 37
Train batch 1/4 - 151.9ms/batch - loss: 3.83716 - diff: 16.74mlTrain batch 2/4 - 145.8ms/batch - loss: 3.70186 - diff: 16.51mlTrain batch 3/4 - 148.4ms/batch - loss: 5.36083 - diff: 17.89mlTrain batch 4/4 - 133.2ms/batch - loss: 5.28994 - diff: 18.00mlTrain batch 4/4 - 10.7s 133.2ms/batch - loss: 5.28994 - diff: 18.00ml
Test 0.6s: val_loss: 8.43642 - diff: 18.53ml

Epoch 40: current best loss = 7.32436, at epoch 37
Train batch 1/4 - 150.4ms/batch - loss: 5.18978 - diff: 17.90mlTrain batch 2/4 - 144.4ms/batch - loss: 5.29227 - diff: 18.78mlTrain batch 3/4 - 150.7ms/batch - loss: 5.18795 - diff: 19.28mlTrain batch 4/4 - 137.6ms/batch - loss: 4.98001 - diff: 18.75mlTrain batch 4/4 - 10.7s 137.6ms/batch - loss: 4.98001 - diff: 18.75ml
Test 0.6s: val_loss: 17.38967 - diff: 30.98ml

Epoch 41: current best loss = 7.32436, at epoch 37
Train batch 1/4 - 151.9ms/batch - loss: 6.00472 - diff: 18.71mlTrain batch 2/4 - 144.5ms/batch - loss: 5.67226 - diff: 19.55mlTrain batch 3/4 - 150.9ms/batch - loss: 6.00649 - diff: 19.50mlTrain batch 4/4 - 133.3ms/batch - loss: 5.92228 - diff: 19.36mlTrain batch 4/4 - 10.7s 133.3ms/batch - loss: 5.92228 - diff: 19.36ml
Test 0.6s: val_loss: 12.55898 - diff: 25.90ml

Epoch 42: current best loss = 7.32436, at epoch 37
Train batch 1/4 - 152.3ms/batch - loss: 7.00444 - diff: 19.26mlTrain batch 2/4 - 144.5ms/batch - loss: 5.59242 - diff: 18.30mlTrain batch 3/4 - 146.0ms/batch - loss: 6.26418 - diff: 19.16mlTrain batch 4/4 - 133.9ms/batch - loss: 5.83889 - diff: 18.76mlTrain batch 4/4 - 10.6s 133.9ms/batch - loss: 5.83889 - diff: 18.76ml
Test 0.6s: val_loss: 9.44106 - diff: 18.85ml

Epoch 43: current best loss = 7.32436, at epoch 37
Train batch 1/4 - 149.0ms/batch - loss: 5.29174 - diff: 19.34mlTrain batch 2/4 - 144.4ms/batch - loss: 5.89702 - diff: 19.41mlTrain batch 3/4 - 150.7ms/batch - loss: 6.04902 - diff: 19.39mlTrain batch 4/4 - 134.5ms/batch - loss: 5.62758 - diff: 18.73mlTrain batch 4/4 - 10.7s 134.5ms/batch - loss: 5.62758 - diff: 18.73ml
Test 0.6s: val_loss: 8.22415 - diff: 20.29ml

Epoch 44: current best loss = 7.32436, at epoch 37
Train batch 1/4 - 152.3ms/batch - loss: 3.99059 - diff: 16.65mlTrain batch 2/4 - 144.5ms/batch - loss: 4.72578 - diff: 18.28mlTrain batch 3/4 - 150.8ms/batch - loss: 4.64170 - diff: 18.21mlTrain batch 4/4 - 133.3ms/batch - loss: 6.51871 - diff: 18.80mlTrain batch 4/4 - 10.7s 133.3ms/batch - loss: 6.51871 - diff: 18.80ml
Test 0.6s: val_loss: 19.25503 - diff: 33.27ml

Epoch 45: current best loss = 7.32436, at epoch 37
Train batch 1/4 - 152.2ms/batch - loss: 3.96073 - diff: 16.77mlTrain batch 2/4 - 149.5ms/batch - loss: 6.73537 - diff: 18.51mlTrain batch 3/4 - 150.7ms/batch - loss: 5.79791 - diff: 18.02mlTrain batch 4/4 - 136.4ms/batch - loss: 5.85744 - diff: 18.28mlTrain batch 4/4 - 10.7s 136.4ms/batch - loss: 5.85744 - diff: 18.28ml
Test 0.6s: val_loss: 8.08290 - diff: 19.76ml

Epoch 46: current best loss = 7.32436, at epoch 37
Train batch 1/4 - 151.8ms/batch - loss: 3.45356 - diff: 16.46mlTrain batch 2/4 - 148.5ms/batch - loss: 4.77934 - diff: 17.50mlTrain batch 3/4 - 150.8ms/batch - loss: 4.95067 - diff: 18.07mlTrain batch 4/4 - 133.3ms/batch - loss: 5.27466 - diff: 18.21mlTrain batch 4/4 - 10.7s 133.3ms/batch - loss: 5.27466 - diff: 18.21ml
Test 0.6s: val_loss: 10.78495 - diff: 24.00ml

Epoch 47: current best loss = 7.32436, at epoch 37
Train batch 1/4 - 151.8ms/batch - loss: 4.10405 - diff: 17.61mlTrain batch 2/4 - 149.5ms/batch - loss: 4.42819 - diff: 17.58mlTrain batch 3/4 - 150.8ms/batch - loss: 4.87238 - diff: 18.34mlTrain batch 4/4 - 134.8ms/batch - loss: 5.76539 - diff: 18.82mlTrain batch 4/4 - 10.7s 134.8ms/batch - loss: 5.76539 - diff: 18.82ml
Test 0.6s: val_loss: 8.01518 - diff: 17.34ml

Epoch 48: current best loss = 7.32436, at epoch 37
Train batch 1/4 - 152.0ms/batch - loss: 5.70655 - diff: 16.69mlTrain batch 2/4 - 144.3ms/batch - loss: 4.52955 - diff: 16.32mlTrain batch 3/4 - 149.6ms/batch - loss: 4.30123 - diff: 16.62mlTrain batch 4/4 - 139.0ms/batch - loss: 5.73209 - diff: 17.91mlTrain batch 4/4 - 10.7s 139.0ms/batch - loss: 5.73209 - diff: 17.91ml
Test 0.6s: val_loss: 8.59154 - diff: 19.49ml
Epoch    49: reducing learning rate of group 0 to 2.5000e-04.

Epoch 49: current best loss = 7.32436, at epoch 37
Train batch 1/4 - 147.7ms/batch - loss: 4.66498 - diff: 17.66mlTrain batch 2/4 - 145.3ms/batch - loss: 4.05142 - diff: 16.90mlTrain batch 3/4 - 150.6ms/batch - loss: 5.37243 - diff: 17.69mlTrain batch 4/4 - 135.7ms/batch - loss: 5.54934 - diff: 18.24mlTrain batch 4/4 - 10.6s 135.7ms/batch - loss: 5.54934 - diff: 18.24ml
Test 0.6s: val_loss: 7.99986 - diff: 17.98ml

Epoch 50: current best loss = 7.32436, at epoch 37
Train batch 1/4 - 152.0ms/batch - loss: 5.50210 - diff: 17.98mlTrain batch 2/4 - 144.5ms/batch - loss: 4.98566 - diff: 17.76mlTrain batch 3/4 - 150.7ms/batch - loss: 5.50625 - diff: 18.38mlTrain batch 4/4 - 133.4ms/batch - loss: 5.23374 - diff: 18.03mlTrain batch 4/4 - 10.7s 133.4ms/batch - loss: 5.23374 - diff: 18.03ml
Test 0.6s: val_loss: 6.92316 - diff: 17.61ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Systole_TimeAsDepth_1_Adam-0.001_MSE_DA3_best

Epoch 51: current best loss = 6.92316, at epoch 50
Train batch 1/4 - 152.5ms/batch - loss: 5.90608 - diff: 19.13mlTrain batch 2/4 - 148.6ms/batch - loss: 4.65063 - diff: 17.99mlTrain batch 3/4 - 150.9ms/batch - loss: 5.02253 - diff: 18.09mlTrain batch 4/4 - 137.7ms/batch - loss: 4.89370 - diff: 17.69mlTrain batch 4/4 - 10.7s 137.7ms/batch - loss: 4.89370 - diff: 17.69ml
Test 0.6s: val_loss: 6.64594 - diff: 18.53ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Systole_TimeAsDepth_1_Adam-0.001_MSE_DA3_best

Epoch 52: current best loss = 6.64594, at epoch 51
Train batch 1/4 - 152.4ms/batch - loss: 4.44523 - diff: 16.91mlTrain batch 2/4 - 149.6ms/batch - loss: 5.22306 - diff: 17.39mlTrain batch 3/4 - 150.6ms/batch - loss: 4.81730 - diff: 17.16mlTrain batch 4/4 - 134.7ms/batch - loss: 4.85529 - diff: 17.46mlTrain batch 4/4 - 10.6s 134.7ms/batch - loss: 4.85529 - diff: 17.46ml
Test 0.6s: val_loss: 6.85328 - diff: 16.99ml

Epoch 53: current best loss = 6.64594, at epoch 51
Train batch 1/4 - 152.1ms/batch - loss: 7.74110 - diff: 20.49mlTrain batch 2/4 - 145.7ms/batch - loss: 5.77403 - diff: 18.80mlTrain batch 3/4 - 148.0ms/batch - loss: 5.09963 - diff: 18.00mlTrain batch 4/4 - 133.1ms/batch - loss: 4.88187 - diff: 17.45mlTrain batch 4/4 - 10.7s 133.1ms/batch - loss: 4.88187 - diff: 17.45ml
Test 0.6s: val_loss: 5.98800 - diff: 16.48ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Systole_TimeAsDepth_1_Adam-0.001_MSE_DA3_best

Epoch 54: current best loss = 5.98800, at epoch 53
Train batch 1/4 - 152.3ms/batch - loss: 5.21852 - diff: 18.33mlTrain batch 2/4 - 146.7ms/batch - loss: 4.69902 - diff: 17.36mlTrain batch 3/4 - 150.8ms/batch - loss: 4.53086 - diff: 17.71mlTrain batch 4/4 - 137.2ms/batch - loss: 5.25949 - diff: 18.01mlTrain batch 4/4 - 10.6s 137.2ms/batch - loss: 5.25949 - diff: 18.01ml
Test 0.6s: val_loss: 8.40653 - diff: 20.57ml

Epoch 55: current best loss = 5.98800, at epoch 53
Train batch 1/4 - 152.1ms/batch - loss: 4.90945 - diff: 18.40mlTrain batch 2/4 - 147.5ms/batch - loss: 4.56802 - diff: 18.32mlTrain batch 3/4 - 150.8ms/batch - loss: 4.56045 - diff: 17.67mlTrain batch 4/4 - 133.2ms/batch - loss: 5.10216 - diff: 17.48mlTrain batch 4/4 - 10.7s 133.2ms/batch - loss: 5.10216 - diff: 17.48ml
Test 0.6s: val_loss: 9.32081 - diff: 21.26ml

Epoch 56: current best loss = 5.98800, at epoch 53
Train batch 1/4 - 152.2ms/batch - loss: 4.85705 - diff: 18.12mlTrain batch 2/4 - 144.5ms/batch - loss: 5.02610 - diff: 18.51mlTrain batch 3/4 - 150.7ms/batch - loss: 4.78530 - diff: 18.23mlTrain batch 4/4 - 138.5ms/batch - loss: 5.09735 - diff: 17.91mlTrain batch 4/4 - 10.7s 138.5ms/batch - loss: 5.09735 - diff: 17.91ml
Test 0.7s: val_loss: 9.13223 - diff: 21.08ml

Epoch 57: current best loss = 5.98800, at epoch 53
Train batch 1/4 - 151.8ms/batch - loss: 3.83040 - diff: 17.43mlTrain batch 2/4 - 144.6ms/batch - loss: 3.98085 - diff: 17.30mlTrain batch 3/4 - 148.0ms/batch - loss: 4.13182 - diff: 17.08mlTrain batch 4/4 - 133.1ms/batch - loss: 4.80938 - diff: 17.65mlTrain batch 4/4 - 10.7s 133.1ms/batch - loss: 4.80938 - diff: 17.65ml
Test 0.7s: val_loss: 9.38523 - diff: 20.55ml

Epoch 58: current best loss = 5.98800, at epoch 53
Train batch 1/4 - 152.3ms/batch - loss: 4.82751 - diff: 18.98mlTrain batch 2/4 - 145.5ms/batch - loss: 5.21236 - diff: 18.50mlTrain batch 3/4 - 150.5ms/batch - loss: 4.58543 - diff: 17.42mlTrain batch 4/4 - 133.9ms/batch - loss: 4.83411 - diff: 17.56mlTrain batch 4/4 - 10.7s 133.9ms/batch - loss: 4.83411 - diff: 17.56ml
Test 0.6s: val_loss: 10.01452 - diff: 21.37ml

Epoch 59: current best loss = 5.98800, at epoch 53
Train batch 1/4 - 152.3ms/batch - loss: 4.81454 - diff: 17.66mlTrain batch 2/4 - 144.9ms/batch - loss: 4.56554 - diff: 17.58mlTrain batch 3/4 - 149.2ms/batch - loss: 4.63797 - diff: 17.39mlTrain batch 4/4 - 133.2ms/batch - loss: 4.68234 - diff: 17.24mlTrain batch 4/4 - 10.7s 133.2ms/batch - loss: 4.68234 - diff: 17.24ml
Test 0.7s: val_loss: 9.85420 - diff: 23.74ml

Epoch 60: current best loss = 5.98800, at epoch 53
Train batch 1/4 - 148.4ms/batch - loss: 7.57479 - diff: 19.93mlTrain batch 2/4 - 144.4ms/batch - loss: 5.55787 - diff: 17.61mlTrain batch 3/4 - 150.6ms/batch - loss: 5.34435 - diff: 17.81mlTrain batch 4/4 - 134.9ms/batch - loss: 4.98838 - diff: 17.43mlTrain batch 4/4 - 10.7s 134.9ms/batch - loss: 4.98838 - diff: 17.43ml
Test 0.6s: val_loss: 12.42881 - diff: 26.22ml

Epoch 61: current best loss = 5.98800, at epoch 53
Train batch 1/4 - 151.9ms/batch - loss: 3.99661 - diff: 17.57mlTrain batch 2/4 - 145.2ms/batch - loss: 4.03289 - diff: 16.86mlTrain batch 3/4 - 150.2ms/batch - loss: 3.90894 - diff: 16.64mlTrain batch 4/4 - 133.1ms/batch - loss: 4.37311 - diff: 16.32mlTrain batch 4/4 - 10.7s 133.1ms/batch - loss: 4.37311 - diff: 16.32ml
Test 0.6s: val_loss: 10.37118 - diff: 24.00ml

Epoch 62: current best loss = 5.98800, at epoch 53
Train batch 1/4 - 152.4ms/batch - loss: 3.58243 - diff: 15.64mlTrain batch 2/4 - 145.8ms/batch - loss: 3.50469 - diff: 15.66mlTrain batch 3/4 - 150.6ms/batch - loss: 3.90505 - diff: 16.00mlTrain batch 4/4 - 136.4ms/batch - loss: 4.48826 - diff: 16.45mlTrain batch 4/4 - 10.7s 136.4ms/batch - loss: 4.48826 - diff: 16.45ml
Test 0.6s: val_loss: 7.46519 - diff: 19.05ml

Epoch 63: current best loss = 5.98800, at epoch 53
Train batch 1/4 - 152.3ms/batch - loss: 5.20302 - diff: 20.34mlTrain batch 2/4 - 144.5ms/batch - loss: 4.09632 - diff: 17.42mlTrain batch 3/4 - 150.5ms/batch - loss: 4.39360 - diff: 17.13mlTrain batch 4/4 - 133.3ms/batch - loss: 4.16336 - diff: 16.74mlTrain batch 4/4 - 10.6s 133.3ms/batch - loss: 4.16336 - diff: 16.74ml
Test 0.6s: val_loss: 9.26330 - diff: 20.86ml

Epoch 64: current best loss = 5.98800, at epoch 53
Train batch 1/4 - 151.8ms/batch - loss: 3.84809 - diff: 16.72mlTrain batch 2/4 - 144.5ms/batch - loss: 4.15038 - diff: 16.94mlTrain batch 3/4 - 150.6ms/batch - loss: 3.98762 - diff: 16.78mlTrain batch 4/4 - 133.4ms/batch - loss: 4.62051 - diff: 17.36mlTrain batch 4/4 - 10.6s 133.4ms/batch - loss: 4.62051 - diff: 17.36ml
Test 0.6s: val_loss: 16.31737 - diff: 34.03ml
Epoch    65: reducing learning rate of group 0 to 1.2500e-04.

Epoch 65: current best loss = 5.98800, at epoch 53
Train batch 1/4 - 152.4ms/batch - loss: 3.61127 - diff: 16.72mlTrain batch 2/4 - 147.9ms/batch - loss: 4.76709 - diff: 16.79mlTrain batch 3/4 - 150.6ms/batch - loss: 4.23858 - diff: 16.33mlTrain batch 4/4 - 137.2ms/batch - loss: 4.58640 - diff: 16.66mlTrain batch 4/4 - 10.7s 137.2ms/batch - loss: 4.58640 - diff: 16.66ml
Test 0.6s: val_loss: 11.43927 - diff: 26.87ml

Epoch 66: current best loss = 5.98800, at epoch 53
Train batch 1/4 - 152.4ms/batch - loss: 3.46780 - diff: 15.89mlTrain batch 2/4 - 144.5ms/batch - loss: 3.62587 - diff: 16.96mlTrain batch 3/4 - 148.5ms/batch - loss: 4.61568 - diff: 17.19mlTrain batch 4/4 - 133.2ms/batch - loss: 4.64315 - diff: 17.09mlTrain batch 4/4 - 10.7s 133.2ms/batch - loss: 4.64315 - diff: 17.09ml
Test 0.6s: val_loss: 6.63683 - diff: 19.20ml

Epoch 67: current best loss = 5.98800, at epoch 53
Train batch 1/4 - 152.2ms/batch - loss: 3.56650 - diff: 15.58mlTrain batch 2/4 - 144.6ms/batch - loss: 3.78658 - diff: 16.26mlTrain batch 3/4 - 150.0ms/batch - loss: 3.89542 - diff: 16.73mlTrain batch 4/4 - 139.0ms/batch - loss: 4.88686 - diff: 17.32mlTrain batch 4/4 - 10.7s 139.0ms/batch - loss: 4.88686 - diff: 17.32ml
Test 0.6s: val_loss: 6.90546 - diff: 19.18ml

Epoch 68: current best loss = 5.98800, at epoch 53
Train batch 1/4 - 152.4ms/batch - loss: 5.21289 - diff: 17.73mlTrain batch 2/4 - 148.6ms/batch - loss: 5.36779 - diff: 17.88mlTrain batch 3/4 - 150.5ms/batch - loss: 4.67516 - diff: 17.19mlTrain batch 4/4 - 133.3ms/batch - loss: 4.30432 - diff: 16.43mlTrain batch 4/4 - 10.7s 133.3ms/batch - loss: 4.30432 - diff: 16.43ml
Test 0.6s: val_loss: 7.63029 - diff: 20.02ml

Epoch 69: current best loss = 5.98800, at epoch 53
Train batch 1/4 - 151.8ms/batch - loss: 3.80008 - diff: 16.51mlTrain batch 2/4 - 144.4ms/batch - loss: 3.97335 - diff: 16.72mlTrain batch 3/4 - 146.0ms/batch - loss: 3.74397 - diff: 15.99mlTrain batch 4/4 - 133.1ms/batch - loss: 4.00611 - diff: 16.17mlTrain batch 4/4 - 10.7s 133.1ms/batch - loss: 4.00611 - diff: 16.17ml
Test 0.6s: val_loss: 7.82479 - diff: 20.69ml

Epoch 70: current best loss = 5.98800, at epoch 53
Train batch 1/4 - 152.1ms/batch - loss: 3.39453 - diff: 16.22mlTrain batch 2/4 - 147.1ms/batch - loss: 4.21059 - diff: 16.56mlTrain batch 3/4 - 150.6ms/batch - loss: 4.50426 - diff: 16.64mlTrain batch 4/4 - 134.5ms/batch - loss: 4.43509 - diff: 16.46mlTrain batch 4/4 - 10.7s 134.5ms/batch - loss: 4.43509 - diff: 16.46ml
Test 0.6s: val_loss: 8.35446 - diff: 21.47ml

Epoch 71: current best loss = 5.98800, at epoch 53
Train batch 1/4 - 148.0ms/batch - loss: 3.81514 - diff: 17.98mlTrain batch 2/4 - 144.2ms/batch - loss: 4.56053 - diff: 17.40mlTrain batch 3/4 - 147.0ms/batch - loss: 3.97770 - diff: 16.45mlTrain batch 4/4 - 135.9ms/batch - loss: 4.66114 - diff: 16.92mlTrain batch 4/4 - 10.7s 135.9ms/batch - loss: 4.66114 - diff: 16.92ml
Test 0.6s: val_loss: 10.67915 - diff: 23.60ml

Epoch 72: current best loss = 5.98800, at epoch 53
Train batch 1/4 - 148.3ms/batch - loss: 5.27176 - diff: 18.49mlTrain batch 2/4 - 146.7ms/batch - loss: 4.95368 - diff: 17.65mlTrain batch 3/4 - 150.6ms/batch - loss: 4.35837 - diff: 16.93mlTrain batch 4/4 - 133.2ms/batch - loss: 4.24641 - diff: 16.63mlTrain batch 4/4 - 10.7s 133.2ms/batch - loss: 4.24641 - diff: 16.63ml
Test 0.6s: val_loss: 10.68450 - diff: 25.01ml

Epoch 73: current best loss = 5.98800, at epoch 53
Train batch 1/4 - 148.6ms/batch - loss: 3.54454 - diff: 15.15mlTrain batch 2/4 - 144.3ms/batch - loss: 4.16256 - diff: 15.86mlTrain batch 3/4 - 145.7ms/batch - loss: 4.35400 - diff: 16.49mlTrain batch 4/4 - 133.3ms/batch - loss: 4.28727 - diff: 16.33mlTrain batch 4/4 - 10.7s 133.3ms/batch - loss: 4.28727 - diff: 16.33ml
Test 0.6s: val_loss: 12.07948 - diff: 26.40ml

Epoch 74: current best loss = 5.98800, at epoch 53
Train batch 1/4 - 149.6ms/batch - loss: 4.22795 - diff: 17.72mlTrain batch 2/4 - 148.0ms/batch - loss: 3.60845 - diff: 16.22mlTrain batch 3/4 - 150.7ms/batch - loss: 4.09570 - diff: 16.59mlTrain batch 4/4 - 133.3ms/batch - loss: 4.37644 - diff: 16.61mlTrain batch 4/4 - 10.7s 133.3ms/batch - loss: 4.37644 - diff: 16.61ml
Test 0.6s: val_loss: 10.78206 - diff: 23.23ml

Epoch 75: current best loss = 5.98800, at epoch 53
Train batch 1/4 - 148.6ms/batch - loss: 3.81808 - diff: 16.34mlTrain batch 2/4 - 147.1ms/batch - loss: 3.90683 - diff: 16.98mlTrain batch 3/4 - 150.7ms/batch - loss: 4.71062 - diff: 17.44mlTrain batch 4/4 - 137.1ms/batch - loss: 4.42171 - diff: 17.14mlTrain batch 4/4 - 10.7s 137.1ms/batch - loss: 4.42171 - diff: 17.14ml
Test 0.6s: val_loss: 10.07496 - diff: 21.97ml
Epoch    76: reducing learning rate of group 0 to 6.2500e-05.

Epoch 76: current best loss = 5.98800, at epoch 53
Train batch 1/4 - 152.0ms/batch - loss: 4.07491 - diff: 15.91mlTrain batch 2/4 - 146.8ms/batch - loss: 3.38028 - diff: 15.06mlTrain batch 3/4 - 150.3ms/batch - loss: 3.56651 - diff: 15.50mlTrain batch 4/4 - 133.4ms/batch - loss: 3.71878 - diff: 15.66mlTrain batch 4/4 - 10.7s 133.4ms/batch - loss: 3.71878 - diff: 15.66ml
Test 0.6s: val_loss: 7.81797 - diff: 19.07ml

Epoch 77: current best loss = 5.98800, at epoch 53
Train batch 1/4 - 151.3ms/batch - loss: 4.59645 - diff: 16.91mlTrain batch 2/4 - 144.4ms/batch - loss: 4.54461 - diff: 17.26mlTrain batch 3/4 - 150.8ms/batch - loss: 4.12231 - diff: 16.71mlTrain batch 4/4 - 136.3ms/batch - loss: 4.20547 - diff: 16.63mlTrain batch 4/4 - 10.7s 136.3ms/batch - loss: 4.20547 - diff: 16.63ml
Test 0.6s: val_loss: 6.97688 - diff: 18.08ml

Epoch 78: current best loss = 5.98800, at epoch 53
Train batch 1/4 - 151.3ms/batch - loss: 3.98146 - diff: 15.27mlTrain batch 2/4 - 144.5ms/batch - loss: 3.44927 - diff: 14.85mlTrain batch 3/4 - 146.0ms/batch - loss: 3.69100 - diff: 15.35mlTrain batch 4/4 - 133.3ms/batch - loss: 3.83966 - diff: 15.70mlTrain batch 4/4 - 10.7s 133.3ms/batch - loss: 3.83966 - diff: 15.70ml
Test 0.6s: val_loss: 7.40748 - diff: 17.79ml

Epoch 79: current best loss = 5.98800, at epoch 53
Train batch 1/4 - 151.8ms/batch - loss: 3.67738 - diff: 15.65mlTrain batch 2/4 - 144.5ms/batch - loss: 5.22200 - diff: 17.16mlTrain batch 3/4 - 150.5ms/batch - loss: 4.60017 - diff: 16.65mlTrain batch 4/4 - 133.4ms/batch - loss: 4.44860 - diff: 16.32mlTrain batch 4/4 - 10.6s 133.4ms/batch - loss: 4.44860 - diff: 16.32ml
Test 0.6s: val_loss: 7.98695 - diff: 19.04ml

Epoch 80: current best loss = 5.98800, at epoch 53
Train batch 1/4 - 152.2ms/batch - loss: 3.09981 - diff: 15.18mlTrain batch 2/4 - 147.1ms/batch - loss: 3.29974 - diff: 15.51mlTrain batch 3/4 - 150.7ms/batch - loss: 3.19579 - diff: 15.28mlTrain batch 4/4 - 134.4ms/batch - loss: 3.81157 - diff: 15.85mlTrain batch 4/4 - 10.7s 134.4ms/batch - loss: 3.81157 - diff: 15.85ml
Test 0.6s: val_loss: 8.85390 - diff: 21.36ml

Epoch 81: current best loss = 5.98800, at epoch 53
Train batch 1/4 - 151.7ms/batch - loss: 2.80259 - diff: 14.42mlTrain batch 2/4 - 145.6ms/batch - loss: 3.38344 - diff: 15.64mlTrain batch 3/4 - 150.1ms/batch - loss: 3.73192 - diff: 16.08mlTrain batch 4/4 - 133.2ms/batch - loss: 3.76342 - diff: 15.82mlTrain batch 4/4 - 10.7s 133.2ms/batch - loss: 3.76342 - diff: 15.82ml
Test 0.6s: val_loss: 8.30310 - diff: 20.63ml

Epoch 82: current best loss = 5.98800, at epoch 53
Train batch 1/4 - 152.3ms/batch - loss: 4.69196 - diff: 18.65mlTrain batch 2/4 - 144.5ms/batch - loss: 4.06348 - diff: 16.54mlTrain batch 3/4 - 145.9ms/batch - loss: 3.80596 - diff: 16.16mlTrain batch 4/4 - 133.2ms/batch - loss: 4.04320 - diff: 16.43mlTrain batch 4/4 - 10.6s 133.2ms/batch - loss: 4.04320 - diff: 16.43ml
Test 0.6s: val_loss: 8.25635 - diff: 19.44ml

Epoch 83: current best loss = 5.98800, at epoch 53
Train batch 1/4 - 151.0ms/batch - loss: 3.75729 - diff: 16.68mlTrain batch 2/4 - 144.4ms/batch - loss: 3.35750 - diff: 15.82mlTrain batch 3/4 - 150.3ms/batch - loss: 3.62657 - diff: 15.86mlTrain batch 4/4 - 133.3ms/batch - loss: 4.02180 - diff: 16.11mlTrain batch 4/4 - 10.6s 133.3ms/batch - loss: 4.02180 - diff: 16.11ml
Test 0.6s: val_loss: 8.07956 - diff: 19.96ml

Epoch 84: current best loss = 5.98800, at epoch 53
Train batch 1/4 - 152.1ms/batch - loss: 4.97147 - diff: 17.12mlTrain batch 2/4 - 146.5ms/batch - loss: 4.39601 - diff: 16.83mlTrain batch 3/4 - 150.7ms/batch - loss: 4.07381 - diff: 16.68mlTrain batch 4/4 - 135.7ms/batch - loss: 3.95533 - diff: 16.18mlTrain batch 4/4 - 10.7s 135.7ms/batch - loss: 3.95533 - diff: 16.18ml
Test 0.6s: val_loss: 8.77499 - diff: 19.70ml

Epoch 85: current best loss = 5.98800, at epoch 53
Train batch 1/4 - 148.4ms/batch - loss: 4.02495 - diff: 17.40mlTrain batch 2/4 - 144.3ms/batch - loss: 4.06011 - diff: 16.72mlTrain batch 3/4 - 150.6ms/batch - loss: 3.77908 - diff: 16.02mlTrain batch 4/4 - 133.4ms/batch - loss: 3.62879 - diff: 15.59mlTrain batch 4/4 - 10.7s 133.4ms/batch - loss: 3.62879 - diff: 15.59ml
Test 0.6s: val_loss: 8.98236 - diff: 20.74ml

Epoch 86: current best loss = 5.98800, at epoch 53
Train batch 1/4 - 150.7ms/batch - loss: 5.63755 - diff: 18.36mlTrain batch 2/4 - 144.3ms/batch - loss: 4.48134 - diff: 17.03mlTrain batch 3/4 - 150.7ms/batch - loss: 4.63653 - diff: 17.36mlTrain batch 4/4 - 135.3ms/batch - loss: 4.19242 - diff: 16.55mlTrain batch 4/4 - 10.7s 135.3ms/batch - loss: 4.19242 - diff: 16.55ml
Test 0.6s: val_loss: 8.05773 - diff: 20.53ml
Epoch    87: reducing learning rate of group 0 to 3.1250e-05.

Epoch 87: current best loss = 5.98800, at epoch 53
Train batch 1/4 - 152.1ms/batch - loss: 2.36634 - diff: 13.01mlTrain batch 2/4 - 145.8ms/batch - loss: 4.36280 - diff: 15.50mlTrain batch 3/4 - 150.6ms/batch - loss: 4.13061 - diff: 15.78mlTrain batch 4/4 - 133.4ms/batch - loss: 4.05908 - diff: 15.87mlTrain batch 4/4 - 10.6s 133.4ms/batch - loss: 4.05908 - diff: 15.87ml
Test 0.6s: val_loss: 8.49672 - diff: 21.39ml

Epoch 88: current best loss = 5.98800, at epoch 53
Train batch 1/4 - 149.2ms/batch - loss: 2.94247 - diff: 15.19mlTrain batch 2/4 - 144.2ms/batch - loss: 3.32574 - diff: 15.40mlTrain batch 3/4 - 150.8ms/batch - loss: 3.47532 - diff: 15.62mlTrain batch 4/4 - 133.1ms/batch - loss: 3.75559 - diff: 15.93mlTrain batch 4/4 - 10.6s 133.1ms/batch - loss: 3.75559 - diff: 15.93ml
Test 0.6s: val_loss: 8.75083 - diff: 21.19ml

Epoch 89: current best loss = 5.98800, at epoch 53
Train batch 1/4 - 150.0ms/batch - loss: 3.02840 - diff: 15.11mlTrain batch 2/4 - 148.1ms/batch - loss: 3.57235 - diff: 16.27mlTrain batch 3/4 - 146.9ms/batch - loss: 3.97586 - diff: 15.89mlTrain batch 4/4 - 135.4ms/batch - loss: 4.02665 - diff: 16.12mlTrain batch 4/4 - 10.7s 135.4ms/batch - loss: 4.02665 - diff: 16.12ml
Test 0.6s: val_loss: 8.29320 - diff: 20.77ml

Epoch 90: current best loss = 5.98800, at epoch 53
Train batch 1/4 - 152.2ms/batch - loss: 2.98534 - diff: 14.80mlTrain batch 2/4 - 144.4ms/batch - loss: 3.85454 - diff: 16.36mlTrain batch 3/4 - 150.6ms/batch - loss: 3.77213 - diff: 16.51mlTrain batch 4/4 - 133.3ms/batch - loss: 3.96443 - diff: 16.69mlTrain batch 4/4 - 10.7s 133.3ms/batch - loss: 3.96443 - diff: 16.69ml
Test 0.6s: val_loss: 8.35696 - diff: 20.87ml

Epoch 91: current best loss = 5.98800, at epoch 53
Train batch 1/4 - 147.6ms/batch - loss: 4.62564 - diff: 16.65mlTrain batch 2/4 - 144.3ms/batch - loss: 3.87951 - diff: 16.05mlTrain batch 3/4 - 147.3ms/batch - loss: 3.70170 - diff: 16.14mlTrain batch 4/4 - 133.1ms/batch - loss: 4.38658 - diff: 16.47mlTrain batch 4/4 - 10.6s 133.1ms/batch - loss: 4.38658 - diff: 16.47ml
Test 0.6s: val_loss: 8.84825 - diff: 20.92ml

Epoch 92: current best loss = 5.98800, at epoch 53
Train batch 1/4 - 152.0ms/batch - loss: 3.53837 - diff: 15.55mlTrain batch 2/4 - 144.6ms/batch - loss: 2.84706 - diff: 13.91mlTrain batch 3/4 - 150.8ms/batch - loss: 3.76596 - diff: 15.20mlTrain batch 4/4 - 133.4ms/batch - loss: 3.97982 - diff: 15.59mlTrain batch 4/4 - 10.6s 133.4ms/batch - loss: 3.97982 - diff: 15.59ml
Test 0.6s: val_loss: 8.84009 - diff: 20.28ml

Epoch 93: current best loss = 5.98800, at epoch 53
Train batch 1/4 - 151.7ms/batch - loss: 4.00258 - diff: 16.63mlTrain batch 2/4 - 144.5ms/batch - loss: 3.50658 - diff: 15.67mlTrain batch 3/4 - 150.4ms/batch - loss: 3.85150 - diff: 16.22mlTrain batch 4/4 - 133.4ms/batch - loss: 3.82463 - diff: 16.17mlTrain batch 4/4 - 10.6s 133.4ms/batch - loss: 3.82463 - diff: 16.17ml
Test 0.6s: val_loss: 9.50911 - diff: 20.63ml

Epoch 94: current best loss = 5.98800, at epoch 53
Train batch 1/4 - 152.1ms/batch - loss: 3.48120 - diff: 15.75mlTrain batch 2/4 - 144.6ms/batch - loss: 3.96587 - diff: 16.16mlTrain batch 3/4 - 150.8ms/batch - loss: 3.99705 - diff: 16.66mlTrain batch 4/4 - 137.3ms/batch - loss: 4.29622 - diff: 16.44mlTrain batch 4/4 - 10.8s 137.3ms/batch - loss: 4.29622 - diff: 16.44ml
Test 0.6s: val_loss: 8.48314 - diff: 20.91ml

Epoch 95: current best loss = 5.98800, at epoch 53
Train batch 1/4 - 152.3ms/batch - loss: 4.17911 - diff: 16.55mlTrain batch 2/4 - 147.1ms/batch - loss: 3.65508 - diff: 16.20mlTrain batch 3/4 - 150.3ms/batch - loss: 3.60354 - diff: 16.18mlTrain batch 4/4 - 133.4ms/batch - loss: 4.02390 - diff: 16.54mlTrain batch 4/4 - 10.6s 133.4ms/batch - loss: 4.02390 - diff: 16.54ml
Test 0.6s: val_loss: 9.39257 - diff: 20.86ml

Epoch 96: current best loss = 5.98800, at epoch 53
Train batch 1/4 - 151.7ms/batch - loss: 4.07986 - diff: 17.04mlTrain batch 2/4 - 144.5ms/batch - loss: 3.80044 - diff: 16.25mlTrain batch 3/4 - 150.6ms/batch - loss: 4.24322 - diff: 16.68mlTrain batch 4/4 - 133.5ms/batch - loss: 4.17978 - diff: 16.55mlTrain batch 4/4 - 10.6s 133.5ms/batch - loss: 4.17978 - diff: 16.55ml
Test 0.6s: val_loss: 8.69311 - diff: 20.19ml

Epoch 97: current best loss = 5.98800, at epoch 53
Train batch 1/4 - 152.2ms/batch - loss: 4.38306 - diff: 17.05mlTrain batch 2/4 - 144.4ms/batch - loss: 3.63798 - diff: 15.44mlTrain batch 3/4 - 150.7ms/batch - loss: 3.36729 - diff: 15.43mlTrain batch 4/4 - 137.5ms/batch - loss: 3.88676 - diff: 15.96mlTrain batch 4/4 - 10.7s 137.5ms/batch - loss: 3.88676 - diff: 15.96ml
Test 0.6s: val_loss: 8.95677 - diff: 20.90ml
Epoch    98: reducing learning rate of group 0 to 1.5625e-05.

Epoch 98: current best loss = 5.98800, at epoch 53
Train batch 1/4 - 152.0ms/batch - loss: 3.76453 - diff: 15.90mlTrain batch 2/4 - 144.6ms/batch - loss: 3.60888 - diff: 15.70mlTrain batch 3/4 - 150.2ms/batch - loss: 3.55816 - diff: 15.89mlTrain batch 4/4 - 133.3ms/batch - loss: 3.69097 - diff: 16.01mlTrain batch 4/4 - 10.7s 133.3ms/batch - loss: 3.69097 - diff: 16.01ml
Test 0.6s: val_loss: 9.04743 - diff: 21.10ml

Epoch 99: current best loss = 5.98800, at epoch 53
Train batch 1/4 - 150.4ms/batch - loss: 3.05742 - diff: 15.09mlTrain batch 2/4 - 144.6ms/batch - loss: 3.42442 - diff: 15.35mlTrain batch 3/4 - 150.3ms/batch - loss: 3.93538 - diff: 15.74mlTrain batch 4/4 - 133.4ms/batch - loss: 3.93840 - diff: 15.49mlTrain batch 4/4 - 10.6s 133.4ms/batch - loss: 3.93840 - diff: 15.49ml
Test 0.6s: val_loss: 9.29016 - diff: 20.41ml

