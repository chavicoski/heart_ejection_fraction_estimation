nohup: ignoring input
Running experiment 4CH_preproc1_150x150_bySlices_dataset_allViews_Systole_DenseNet121_0_Adam-0.001_MSE_DA3
Going to train with the GPU in the slot 0 -> device model: GeForce GTX 1080
Model architecture:
 DenseNet121_0(
  (first_conv): Sequential(
    (0): Conv2d(30, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (pretrained_block): Sequential(
    (0): _DenseBlock(
      (denselayer1): _DenseLayer(
        (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer2): _DenseLayer(
        (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer3): _DenseLayer(
        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer4): _DenseLayer(
        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer5): _DenseLayer(
        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer6): _DenseLayer(
        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
    (1): _Transition(
      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)
    )
    (2): _DenseBlock(
      (denselayer1): _DenseLayer(
        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer2): _DenseLayer(
        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer3): _DenseLayer(
        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer4): _DenseLayer(
        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer5): _DenseLayer(
        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer6): _DenseLayer(
        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer7): _DenseLayer(
        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer8): _DenseLayer(
        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer9): _DenseLayer(
        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer10): _DenseLayer(
        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer11): _DenseLayer(
        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer12): _DenseLayer(
        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
    (3): _Transition(
      (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)
    )
    (4): _DenseBlock(
      (denselayer1): _DenseLayer(
        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer2): _DenseLayer(
        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer3): _DenseLayer(
        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer4): _DenseLayer(
        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer5): _DenseLayer(
        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer6): _DenseLayer(
        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer7): _DenseLayer(
        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer8): _DenseLayer(
        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer9): _DenseLayer(
        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer10): _DenseLayer(
        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer11): _DenseLayer(
        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer12): _DenseLayer(
        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer13): _DenseLayer(
        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer14): _DenseLayer(
        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer15): _DenseLayer(
        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer16): _DenseLayer(
        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer17): _DenseLayer(
        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer18): _DenseLayer(
        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer19): _DenseLayer(
        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer20): _DenseLayer(
        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer21): _DenseLayer(
        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer22): _DenseLayer(
        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer23): _DenseLayer(
        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer24): _DenseLayer(
        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
    (5): _Transition(
      (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)
    )
    (6): _DenseBlock(
      (denselayer1): _DenseLayer(
        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer2): _DenseLayer(
        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer3): _DenseLayer(
        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer4): _DenseLayer(
        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer5): _DenseLayer(
        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer6): _DenseLayer(
        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer7): _DenseLayer(
        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer8): _DenseLayer(
        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer9): _DenseLayer(
        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer10): _DenseLayer(
        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer11): _DenseLayer(
        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer12): _DenseLayer(
        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer13): _DenseLayer(
        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer14): _DenseLayer(
        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer15): _DenseLayer(
        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer16): _DenseLayer(
        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
    (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (reduction_block): Sequential(
    (0): AdaptiveAvgPool2d(output_size=(1, 1))
    (1): Flatten()
  )
  (dense_block): Sequential(
    (0): Linear(in_features=1024, out_features=512, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.4, inplace=False)
    (3): Linear(in_features=512, out_features=1, bias=True)
  )
) 


############################
# TRAIN PHASE:  150 epochs #
############################

Epoch 0: 
Train batch 1/31 - 77.9ms/batch - loss: 321.88120 - diff: 65.70mlTrain batch 2/31 - 66.8ms/batch - loss: 365.14122 - diff: 67.50mlTrain batch 3/31 - 68.7ms/batch - loss: 398.90923 - diff: 70.51mlTrain batch 4/31 - 64.7ms/batch - loss: 421.64516 - diff: 72.77mlTrain batch 5/31 - 62.2ms/batch - loss: 396.40444 - diff: 71.09mlTrain batch 6/31 - 62.7ms/batch - loss: 419.20855 - diff: 71.47mlTrain batch 7/31 - 62.4ms/batch - loss: 423.66078 - diff: 71.44mlTrain batch 8/31 - 63.3ms/batch - loss: 458.07970 - diff: 72.04mlTrain batch 9/31 - 62.1ms/batch - loss: 430.01102 - diff: 69.60mlTrain batch 10/31 - 62.1ms/batch - loss: 405.63305 - diff: 67.72mlTrain batch 11/31 - 73.1ms/batch - loss: 395.06027 - diff: 66.99mlTrain batch 12/31 - 62.5ms/batch - loss: 394.29032 - diff: 66.17mlTrain batch 13/31 - 64.9ms/batch - loss: 377.44167 - diff: 64.56mlTrain batch 14/31 - 62.1ms/batch - loss: 378.51010 - diff: 64.68mlTrain batch 15/31 - 69.1ms/batch - loss: 364.42936 - diff: 63.06mlTrain batch 16/31 - 62.7ms/batch - loss: 353.21978 - diff: 61.66mlTrain batch 17/31 - 72.7ms/batch - loss: 360.31708 - diff: 61.97mlTrain batch 18/31 - 62.2ms/batch - loss: 346.84926 - diff: 60.42mlTrain batch 19/31 - 72.1ms/batch - loss: 337.00131 - diff: 59.36mlTrain batch 20/31 - 62.3ms/batch - loss: 330.27843 - diff: 58.59mlTrain batch 21/31 - 64.1ms/batch - loss: 322.65733 - diff: 57.37mlTrain batch 22/31 - 62.4ms/batch - loss: 313.76127 - diff: 56.39mlTrain batch 23/31 - 63.0ms/batch - loss: 303.57419 - diff: 55.08mlTrain batch 24/31 - 62.9ms/batch - loss: 292.74750 - diff: 53.61mlTrain batch 25/31 - 63.9ms/batch - loss: 314.29393 - diff: 53.38mlTrain batch 26/31 - 62.4ms/batch - loss: 306.88404 - diff: 52.48mlTrain batch 27/31 - 63.7ms/batch - loss: 297.31974 - diff: 51.34mlTrain batch 28/31 - 62.4ms/batch - loss: 290.16504 - diff: 50.65mlTrain batch 29/31 - 62.6ms/batch - loss: 281.74811 - diff: 49.70mlTrain batch 30/31 - 62.4ms/batch - loss: 276.77626 - diff: 49.32mlTrain batch 31/31 - 41.6ms/batch - loss: 274.84451 - diff: 49.00mlTrain batch 31/31 - 9.7s 41.6ms/batch - loss: 274.84451 - diff: 49.00ml
Test 0.6s: val_loss: 129.46899 - diff: 31.07ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Systole_DenseNet121_0_Adam-0.001_MSE_DA3_best

Epoch 1: current best loss = 129.46899, at epoch 0
Train batch 1/31 - 71.0ms/batch - loss: 113.18628 - diff: 33.03mlTrain batch 2/31 - 64.7ms/batch - loss: 254.30200 - diff: 42.01mlTrain batch 3/31 - 64.3ms/batch - loss: 191.34352 - diff: 36.70mlTrain batch 4/31 - 62.4ms/batch - loss: 155.77016 - diff: 33.54mlTrain batch 5/31 - 64.2ms/batch - loss: 132.89940 - diff: 31.23mlTrain batch 6/31 - 63.6ms/batch - loss: 121.13093 - diff: 30.19mlTrain batch 7/31 - 64.2ms/batch - loss: 118.45915 - diff: 29.98mlTrain batch 8/31 - 62.5ms/batch - loss: 112.70769 - diff: 29.91mlTrain batch 9/31 - 64.1ms/batch - loss: 108.66662 - diff: 30.04mlTrain batch 10/31 - 62.8ms/batch - loss: 111.02660 - diff: 30.37mlTrain batch 11/31 - 74.0ms/batch - loss: 113.72092 - diff: 31.35mlTrain batch 12/31 - 66.3ms/batch - loss: 110.77146 - diff: 31.06mlTrain batch 13/31 - 82.4ms/batch - loss: 107.82361 - diff: 30.85mlTrain batch 14/31 - 62.7ms/batch - loss: 108.14410 - diff: 31.14mlTrain batch 15/31 - 64.2ms/batch - loss: 105.70848 - diff: 30.92mlTrain batch 16/31 - 63.8ms/batch - loss: 111.35889 - diff: 31.22mlTrain batch 17/31 - 63.5ms/batch - loss: 109.35843 - diff: 31.23mlTrain batch 18/31 - 63.1ms/batch - loss: 112.79280 - diff: 31.88mlTrain batch 19/31 - 63.4ms/batch - loss: 111.89810 - diff: 31.87mlTrain batch 20/31 - 62.9ms/batch - loss: 109.42724 - diff: 31.57mlTrain batch 21/31 - 64.5ms/batch - loss: 112.83583 - diff: 31.94mlTrain batch 22/31 - 62.4ms/batch - loss: 115.82714 - diff: 32.23mlTrain batch 23/31 - 64.2ms/batch - loss: 113.15974 - diff: 31.97mlTrain batch 24/31 - 62.5ms/batch - loss: 143.40252 - diff: 33.31mlTrain batch 25/31 - 64.2ms/batch - loss: 145.43634 - diff: 33.43mlTrain batch 26/31 - 62.4ms/batch - loss: 145.74226 - diff: 33.40mlTrain batch 27/31 - 64.5ms/batch - loss: 146.27384 - diff: 33.64mlTrain batch 28/31 - 63.6ms/batch - loss: 144.24615 - diff: 33.57mlTrain batch 29/31 - 63.3ms/batch - loss: 143.21917 - diff: 33.48mlTrain batch 30/31 - 62.4ms/batch - loss: 139.53560 - diff: 32.94mlTrain batch 31/31 - 41.4ms/batch - loss: 138.33205 - diff: 32.70mlTrain batch 31/31 - 9.7s 41.4ms/batch - loss: 138.33205 - diff: 32.70ml
Test 0.6s: val_loss: 105.16462 - diff: 28.74ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Systole_DenseNet121_0_Adam-0.001_MSE_DA3_best

Epoch 2: current best loss = 105.16462, at epoch 1
Train batch 1/31 - 72.5ms/batch - loss: 81.03452 - diff: 29.71mlTrain batch 2/31 - 63.3ms/batch - loss: 129.89833 - diff: 35.97mlTrain batch 3/31 - 80.6ms/batch - loss: 203.41481 - diff: 39.18mlTrain batch 4/31 - 62.5ms/batch - loss: 164.62136 - diff: 35.22mlTrain batch 5/31 - 68.6ms/batch - loss: 152.76334 - diff: 34.61mlTrain batch 6/31 - 62.7ms/batch - loss: 133.47424 - diff: 32.26mlTrain batch 7/31 - 67.4ms/batch - loss: 125.06236 - diff: 31.40mlTrain batch 8/31 - 62.6ms/batch - loss: 119.37991 - diff: 31.25mlTrain batch 9/31 - 63.1ms/batch - loss: 113.49990 - diff: 30.80mlTrain batch 10/31 - 62.3ms/batch - loss: 115.21829 - diff: 31.06mlTrain batch 11/31 - 62.5ms/batch - loss: 110.64096 - diff: 30.63mlTrain batch 12/31 - 62.5ms/batch - loss: 105.28558 - diff: 29.73mlTrain batch 13/31 - 67.9ms/batch - loss: 156.60294 - diff: 31.06mlTrain batch 14/31 - 65.4ms/batch - loss: 148.93249 - diff: 30.25mlTrain batch 15/31 - 63.3ms/batch - loss: 151.95270 - diff: 30.50mlTrain batch 16/31 - 62.6ms/batch - loss: 152.63343 - diff: 30.89mlTrain batch 17/31 - 72.9ms/batch - loss: 147.12761 - diff: 30.48mlTrain batch 18/31 - 70.9ms/batch - loss: 143.72381 - diff: 30.46mlTrain batch 19/31 - 63.0ms/batch - loss: 138.13124 - diff: 29.88mlTrain batch 20/31 - 64.5ms/batch - loss: 135.54503 - diff: 29.77mlTrain batch 21/31 - 63.0ms/batch - loss: 131.99332 - diff: 29.55mlTrain batch 22/31 - 79.9ms/batch - loss: 132.36078 - diff: 29.48mlTrain batch 23/31 - 64.8ms/batch - loss: 128.17272 - diff: 29.05mlTrain batch 24/31 - 66.3ms/batch - loss: 125.95822 - diff: 28.87mlTrain batch 25/31 - 63.1ms/batch - loss: 126.01963 - diff: 28.85mlTrain batch 26/31 - 66.7ms/batch - loss: 123.82101 - diff: 28.83mlTrain batch 27/31 - 63.5ms/batch - loss: 127.60856 - diff: 29.41mlTrain batch 28/31 - 66.0ms/batch - loss: 128.34609 - diff: 29.55mlTrain batch 29/31 - 63.0ms/batch - loss: 126.37555 - diff: 29.39mlTrain batch 30/31 - 63.6ms/batch - loss: 123.08616 - diff: 28.97mlTrain batch 31/31 - 40.6ms/batch - loss: 124.59622 - diff: 29.04mlTrain batch 31/31 - 9.7s 40.6ms/batch - loss: 124.59622 - diff: 29.04ml
Test 0.6s: val_loss: 96.46046 - diff: 26.64ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Systole_DenseNet121_0_Adam-0.001_MSE_DA3_best

Epoch 3: current best loss = 96.46046, at epoch 2
Train batch 1/31 - 62.6ms/batch - loss: 117.51817 - diff: 38.81mlTrain batch 2/31 - 62.3ms/batch - loss: 92.88274 - diff: 33.47mlTrain batch 3/31 - 62.7ms/batch - loss: 93.91070 - diff: 32.92mlTrain batch 4/31 - 63.1ms/batch - loss: 96.47824 - diff: 31.44mlTrain batch 5/31 - 62.3ms/batch - loss: 87.01118 - diff: 29.61mlTrain batch 6/31 - 62.4ms/batch - loss: 83.93803 - diff: 29.43mlTrain batch 7/31 - 64.4ms/batch - loss: 84.65172 - diff: 29.05mlTrain batch 8/31 - 62.3ms/batch - loss: 83.60696 - diff: 29.33mlTrain batch 9/31 - 63.9ms/batch - loss: 80.86196 - diff: 29.14mlTrain batch 10/31 - 63.8ms/batch - loss: 77.88628 - diff: 28.61mlTrain batch 11/31 - 64.1ms/batch - loss: 83.37393 - diff: 29.12mlTrain batch 12/31 - 62.5ms/batch - loss: 94.20428 - diff: 30.33mlTrain batch 13/31 - 97.2ms/batch - loss: 90.52902 - diff: 29.70mlTrain batch 14/31 - 66.6ms/batch - loss: 86.89575 - diff: 29.15mlTrain batch 15/31 - 63.2ms/batch - loss: 91.94109 - diff: 29.72mlTrain batch 16/31 - 62.9ms/batch - loss: 92.28585 - diff: 29.70mlTrain batch 17/31 - 62.5ms/batch - loss: 88.67954 - diff: 28.97mlTrain batch 18/31 - 63.6ms/batch - loss: 95.80001 - diff: 29.23mlTrain batch 19/31 - 63.9ms/batch - loss: 93.31368 - diff: 28.83mlTrain batch 20/31 - 63.1ms/batch - loss: 98.81091 - diff: 29.41mlTrain batch 21/31 - 62.5ms/batch - loss: 98.58980 - diff: 29.54mlTrain batch 22/31 - 71.8ms/batch - loss: 95.93737 - diff: 29.19mlTrain batch 23/31 - 64.6ms/batch - loss: 96.29905 - diff: 29.02mlTrain batch 24/31 - 62.6ms/batch - loss: 93.28691 - diff: 28.54mlTrain batch 25/31 - 63.5ms/batch - loss: 94.19750 - diff: 28.62mlTrain batch 26/31 - 62.8ms/batch - loss: 94.30210 - diff: 28.48mlTrain batch 27/31 - 63.3ms/batch - loss: 93.90624 - diff: 28.37mlTrain batch 28/31 - 71.0ms/batch - loss: 91.79191 - diff: 27.96mlTrain batch 29/31 - 63.3ms/batch - loss: 93.58889 - diff: 28.15mlTrain batch 30/31 - 63.4ms/batch - loss: 100.31485 - diff: 28.47mlTrain batch 31/31 - 40.9ms/batch - loss: 138.78134 - diff: 29.12mlTrain batch 31/31 - 9.7s 40.9ms/batch - loss: 138.78134 - diff: 29.12ml
Test 0.6s: val_loss: 86.87346 - diff: 24.26ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Systole_DenseNet121_0_Adam-0.001_MSE_DA3_best

Epoch 4: current best loss = 86.87346, at epoch 3
Train batch 1/31 - 62.6ms/batch - loss: 45.64590 - diff: 21.08mlTrain batch 2/31 - 62.3ms/batch - loss: 65.52792 - diff: 22.80mlTrain batch 3/31 - 63.1ms/batch - loss: 58.72786 - diff: 22.49mlTrain batch 4/31 - 62.4ms/batch - loss: 54.42773 - diff: 21.66mlTrain batch 5/31 - 64.4ms/batch - loss: 56.40585 - diff: 22.65mlTrain batch 6/31 - 62.3ms/batch - loss: 58.13250 - diff: 23.02mlTrain batch 7/31 - 64.0ms/batch - loss: 68.36213 - diff: 25.12mlTrain batch 8/31 - 63.4ms/batch - loss: 70.64654 - diff: 25.57mlTrain batch 9/31 - 64.2ms/batch - loss: 73.85241 - diff: 25.55mlTrain batch 10/31 - 62.3ms/batch - loss: 84.08240 - diff: 26.60mlTrain batch 11/31 - 63.9ms/batch - loss: 84.44109 - diff: 26.44mlTrain batch 12/31 - 62.6ms/batch - loss: 82.01182 - diff: 26.12mlTrain batch 13/31 - 65.2ms/batch - loss: 85.54045 - diff: 27.14mlTrain batch 14/31 - 65.7ms/batch - loss: 82.45978 - diff: 26.75mlTrain batch 15/31 - 65.7ms/batch - loss: 81.57922 - diff: 26.88mlTrain batch 16/31 - 63.9ms/batch - loss: 85.23418 - diff: 27.19mlTrain batch 17/31 - 63.9ms/batch - loss: 84.60273 - diff: 27.28mlTrain batch 18/31 - 62.4ms/batch - loss: 86.63551 - diff: 27.48mlTrain batch 19/31 - 63.2ms/batch - loss: 88.78483 - diff: 27.77mlTrain batch 20/31 - 62.5ms/batch - loss: 92.26621 - diff: 27.95mlTrain batch 21/31 - 63.1ms/batch - loss: 119.12736 - diff: 29.01mlTrain batch 22/31 - 62.4ms/batch - loss: 122.99822 - diff: 29.69mlTrain batch 23/31 - 64.1ms/batch - loss: 120.30842 - diff: 29.48mlTrain batch 24/31 - 62.3ms/batch - loss: 117.60187 - diff: 29.09mlTrain batch 25/31 - 63.2ms/batch - loss: 114.02432 - diff: 28.61mlTrain batch 26/31 - 62.4ms/batch - loss: 111.64780 - diff: 28.41mlTrain batch 27/31 - 63.8ms/batch - loss: 108.66167 - diff: 28.01mlTrain batch 28/31 - 62.8ms/batch - loss: 105.90471 - diff: 27.61mlTrain batch 29/31 - 64.2ms/batch - loss: 112.77034 - diff: 28.10mlTrain batch 30/31 - 62.3ms/batch - loss: 111.69693 - diff: 28.21mlTrain batch 31/31 - 42.1ms/batch - loss: 111.87256 - diff: 28.19mlTrain batch 31/31 - 9.6s 42.1ms/batch - loss: 111.87256 - diff: 28.19ml
Test 0.6s: val_loss: 75.78117 - diff: 25.95ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Systole_DenseNet121_0_Adam-0.001_MSE_DA3_best

Epoch 5: current best loss = 75.78117, at epoch 4
Train batch 1/31 - 72.2ms/batch - loss: 38.20174 - diff: 19.44mlTrain batch 2/31 - 62.5ms/batch - loss: 46.68222 - diff: 21.67mlTrain batch 3/31 - 65.0ms/batch - loss: 82.57486 - diff: 26.42mlTrain batch 4/31 - 62.4ms/batch - loss: 70.06700 - diff: 24.32mlTrain batch 5/31 - 64.8ms/batch - loss: 67.79817 - diff: 24.45mlTrain batch 6/31 - 62.8ms/batch - loss: 74.37254 - diff: 26.11mlTrain batch 7/31 - 64.3ms/batch - loss: 93.71151 - diff: 27.46mlTrain batch 8/31 - 63.4ms/batch - loss: 92.95687 - diff: 27.32mlTrain batch 9/31 - 62.6ms/batch - loss: 97.28057 - diff: 27.38mlTrain batch 10/31 - 63.1ms/batch - loss: 95.11161 - diff: 27.23mlTrain batch 11/31 - 62.3ms/batch - loss: 92.40451 - diff: 27.01mlTrain batch 12/31 - 62.6ms/batch - loss: 87.40624 - diff: 26.23mlTrain batch 13/31 - 64.2ms/batch - loss: 84.10189 - diff: 25.66mlTrain batch 14/31 - 63.2ms/batch - loss: 88.05988 - diff: 25.92mlTrain batch 15/31 - 62.3ms/batch - loss: 85.39660 - diff: 25.64mlTrain batch 16/31 - 62.2ms/batch - loss: 85.44418 - diff: 25.75mlTrain batch 17/31 - 62.8ms/batch - loss: 82.62262 - diff: 25.35mlTrain batch 18/31 - 62.6ms/batch - loss: 79.99096 - diff: 25.01mlTrain batch 19/31 - 62.9ms/batch - loss: 78.15472 - diff: 24.83mlTrain batch 20/31 - 62.3ms/batch - loss: 106.06838 - diff: 26.13mlTrain batch 21/31 - 62.8ms/batch - loss: 104.91225 - diff: 26.36mlTrain batch 22/31 - 62.2ms/batch - loss: 102.98709 - diff: 26.38mlTrain batch 23/31 - 62.4ms/batch - loss: 100.35360 - diff: 26.15mlTrain batch 24/31 - 62.2ms/batch - loss: 105.78259 - diff: 26.84mlTrain batch 25/31 - 62.4ms/batch - loss: 102.73825 - diff: 26.46mlTrain batch 26/31 - 62.9ms/batch - loss: 112.65850 - diff: 27.27mlTrain batch 27/31 - 63.6ms/batch - loss: 112.64646 - diff: 27.45mlTrain batch 28/31 - 62.8ms/batch - loss: 111.06070 - diff: 27.41mlTrain batch 29/31 - 62.7ms/batch - loss: 109.38137 - diff: 27.37mlTrain batch 30/31 - 63.0ms/batch - loss: 109.97088 - diff: 27.64mlTrain batch 31/31 - 42.4ms/batch - loss: 109.11665 - diff: 27.49mlTrain batch 31/31 - 9.7s 42.4ms/batch - loss: 109.11665 - diff: 27.49ml
Test 0.6s: val_loss: 74.72995 - diff: 23.87ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Systole_DenseNet121_0_Adam-0.001_MSE_DA3_best

Epoch 6: current best loss = 74.72995, at epoch 5
Train batch 1/31 - 62.5ms/batch - loss: 75.21597 - diff: 28.85mlTrain batch 2/31 - 63.5ms/batch - loss: 67.91178 - diff: 26.80mlTrain batch 3/31 - 64.4ms/batch - loss: 69.96936 - diff: 25.12mlTrain batch 4/31 - 62.4ms/batch - loss: 70.78926 - diff: 25.50mlTrain batch 5/31 - 64.7ms/batch - loss: 68.75198 - diff: 25.42mlTrain batch 6/31 - 63.8ms/batch - loss: 69.98924 - diff: 25.21mlTrain batch 7/31 - 62.3ms/batch - loss: 64.71694 - diff: 24.30mlTrain batch 8/31 - 63.5ms/batch - loss: 67.33927 - diff: 24.99mlTrain batch 9/31 - 64.5ms/batch - loss: 70.33643 - diff: 25.60mlTrain batch 10/31 - 63.2ms/batch - loss: 73.03467 - diff: 25.42mlTrain batch 11/31 - 64.2ms/batch - loss: 69.07497 - diff: 24.71mlTrain batch 12/31 - 62.3ms/batch - loss: 70.37892 - diff: 24.71mlTrain batch 13/31 - 65.1ms/batch - loss: 67.07506 - diff: 24.11mlTrain batch 14/31 - 63.1ms/batch - loss: 75.28415 - diff: 25.09mlTrain batch 15/31 - 63.1ms/batch - loss: 75.05327 - diff: 25.14mlTrain batch 16/31 - 62.4ms/batch - loss: 73.76558 - diff: 25.03mlTrain batch 17/31 - 63.3ms/batch - loss: 76.08397 - diff: 25.42mlTrain batch 18/31 - 62.5ms/batch - loss: 73.77738 - diff: 25.15mlTrain batch 19/31 - 63.3ms/batch - loss: 75.03773 - diff: 25.13mlTrain batch 20/31 - 62.3ms/batch - loss: 72.74087 - diff: 24.81mlTrain batch 21/31 - 70.5ms/batch - loss: 72.32715 - diff: 24.81mlTrain batch 22/31 - 62.3ms/batch - loss: 96.53131 - diff: 25.67mlTrain batch 23/31 - 71.8ms/batch - loss: 94.23475 - diff: 25.51mlTrain batch 24/31 - 63.3ms/batch - loss: 94.73270 - diff: 25.65mlTrain batch 25/31 - 63.3ms/batch - loss: 92.55838 - diff: 25.55mlTrain batch 26/31 - 62.9ms/batch - loss: 93.69260 - diff: 25.85mlTrain batch 27/31 - 69.4ms/batch - loss: 94.38919 - diff: 26.00mlTrain batch 28/31 - 62.3ms/batch - loss: 98.67812 - diff: 26.14mlTrain batch 29/31 - 63.5ms/batch - loss: 98.10262 - diff: 26.15mlTrain batch 30/31 - 62.3ms/batch - loss: 96.08543 - diff: 25.96mlTrain batch 31/31 - 40.8ms/batch - loss: 99.63067 - diff: 26.15mlTrain batch 31/31 - 9.7s 40.8ms/batch - loss: 99.63067 - diff: 26.15ml
Test 0.6s: val_loss: 77.61108 - diff: 25.15ml

Epoch 7: current best loss = 74.72995, at epoch 5
Train batch 1/31 - 71.0ms/batch - loss: 39.25378 - diff: 20.14mlTrain batch 2/31 - 62.4ms/batch - loss: 64.83204 - diff: 23.71mlTrain batch 3/31 - 63.9ms/batch - loss: 48.75337 - diff: 20.14mlTrain batch 4/31 - 63.5ms/batch - loss: 74.93926 - diff: 23.57mlTrain batch 5/31 - 67.4ms/batch - loss: 68.69734 - diff: 23.41mlTrain batch 6/31 - 62.4ms/batch - loss: 63.98148 - diff: 23.00mlTrain batch 7/31 - 63.1ms/batch - loss: 58.60501 - diff: 22.10mlTrain batch 8/31 - 64.3ms/batch - loss: 61.14467 - diff: 22.23mlTrain batch 9/31 - 62.4ms/batch - loss: 73.67143 - diff: 23.88mlTrain batch 10/31 - 62.3ms/batch - loss: 126.60701 - diff: 26.05mlTrain batch 11/31 - 63.1ms/batch - loss: 117.19792 - diff: 25.09mlTrain batch 12/31 - 62.3ms/batch - loss: 121.48737 - diff: 25.55mlTrain batch 13/31 - 64.3ms/batch - loss: 121.72129 - diff: 26.07mlTrain batch 14/31 - 63.6ms/batch - loss: 117.55425 - diff: 26.10mlTrain batch 15/31 - 67.5ms/batch - loss: 128.46866 - diff: 27.20mlTrain batch 16/31 - 68.7ms/batch - loss: 123.33609 - diff: 26.74mlTrain batch 17/31 - 62.4ms/batch - loss: 117.90737 - diff: 26.27mlTrain batch 18/31 - 64.3ms/batch - loss: 114.48874 - diff: 26.17mlTrain batch 19/31 - 62.4ms/batch - loss: 111.27723 - diff: 26.04mlTrain batch 20/31 - 62.9ms/batch - loss: 107.68022 - diff: 25.67mlTrain batch 21/31 - 66.3ms/batch - loss: 105.52971 - diff: 25.56mlTrain batch 22/31 - 62.9ms/batch - loss: 104.34412 - diff: 25.68mlTrain batch 23/31 - 62.4ms/batch - loss: 102.79312 - diff: 25.46mlTrain batch 24/31 - 64.5ms/batch - loss: 100.34041 - diff: 25.23mlTrain batch 25/31 - 62.4ms/batch - loss: 99.78091 - diff: 25.44mlTrain batch 26/31 - 62.4ms/batch - loss: 100.14488 - diff: 25.67mlTrain batch 27/31 - 62.3ms/batch - loss: 98.02812 - diff: 25.48mlTrain batch 28/31 - 62.3ms/batch - loss: 96.75256 - diff: 25.46mlTrain batch 29/31 - 62.5ms/batch - loss: 95.02253 - diff: 25.24mlTrain batch 30/31 - 63.1ms/batch - loss: 94.43957 - diff: 25.18mlTrain batch 31/31 - 41.9ms/batch - loss: 102.34478 - diff: 25.35mlTrain batch 31/31 - 9.6s 41.9ms/batch - loss: 102.34478 - diff: 25.35ml
Test 0.6s: val_loss: 78.47266 - diff: 24.58ml

Epoch 8: current best loss = 74.72995, at epoch 5
Train batch 1/31 - 65.1ms/batch - loss: 48.63602 - diff: 23.36mlTrain batch 2/31 - 62.4ms/batch - loss: 44.23753 - diff: 22.12mlTrain batch 3/31 - 63.4ms/batch - loss: 47.37336 - diff: 22.91mlTrain batch 4/31 - 62.4ms/batch - loss: 51.21330 - diff: 23.51mlTrain batch 5/31 - 62.3ms/batch - loss: 56.97721 - diff: 24.33mlTrain batch 6/31 - 62.5ms/batch - loss: 59.89615 - diff: 25.13mlTrain batch 7/31 - 64.4ms/batch - loss: 58.23604 - diff: 24.51mlTrain batch 8/31 - 63.7ms/batch - loss: 58.02492 - diff: 24.45mlTrain batch 9/31 - 62.5ms/batch - loss: 57.19632 - diff: 24.58mlTrain batch 10/31 - 62.3ms/batch - loss: 66.12456 - diff: 25.02mlTrain batch 11/31 - 63.7ms/batch - loss: 66.91096 - diff: 25.50mlTrain batch 12/31 - 63.1ms/batch - loss: 66.78502 - diff: 24.88mlTrain batch 13/31 - 63.2ms/batch - loss: 64.12489 - diff: 24.31mlTrain batch 14/31 - 63.0ms/batch - loss: 64.81455 - diff: 24.51mlTrain batch 15/31 - 63.9ms/batch - loss: 66.43248 - diff: 24.79mlTrain batch 16/31 - 62.6ms/batch - loss: 78.20428 - diff: 25.53mlTrain batch 17/31 - 66.5ms/batch - loss: 108.21445 - diff: 26.64mlTrain batch 18/31 - 67.6ms/batch - loss: 104.85012 - diff: 26.34mlTrain batch 19/31 - 62.4ms/batch - loss: 107.87151 - diff: 26.81mlTrain batch 20/31 - 62.3ms/batch - loss: 106.40353 - diff: 26.78mlTrain batch 21/31 - 62.8ms/batch - loss: 104.44303 - diff: 26.70mlTrain batch 22/31 - 62.8ms/batch - loss: 102.37529 - diff: 26.64mlTrain batch 23/31 - 64.9ms/batch - loss: 103.58217 - diff: 26.82mlTrain batch 24/31 - 63.8ms/batch - loss: 102.71702 - diff: 26.76mlTrain batch 25/31 - 63.7ms/batch - loss: 100.61513 - diff: 26.67mlTrain batch 26/31 - 63.0ms/batch - loss: 100.63714 - diff: 26.66mlTrain batch 27/31 - 62.9ms/batch - loss: 99.46416 - diff: 26.61mlTrain batch 28/31 - 64.7ms/batch - loss: 97.42428 - diff: 26.39mlTrain batch 29/31 - 62.3ms/batch - loss: 98.76097 - diff: 26.65mlTrain batch 30/31 - 62.5ms/batch - loss: 97.27841 - diff: 26.50mlTrain batch 31/31 - 40.7ms/batch - loss: 99.65092 - diff: 26.67mlTrain batch 31/31 - 9.7s 40.7ms/batch - loss: 99.65092 - diff: 26.67ml
Test 0.6s: val_loss: 81.09410 - diff: 25.55ml

Epoch 9: current best loss = 74.72995, at epoch 5
Train batch 1/31 - 63.6ms/batch - loss: 111.17826 - diff: 31.65mlTrain batch 2/31 - 62.5ms/batch - loss: 139.53652 - diff: 33.65mlTrain batch 3/31 - 62.4ms/batch - loss: 105.28533 - diff: 28.20mlTrain batch 4/31 - 62.4ms/batch - loss: 253.06109 - diff: 35.41mlTrain batch 5/31 - 62.4ms/batch - loss: 217.63637 - diff: 33.74mlTrain batch 6/31 - 62.4ms/batch - loss: 197.18273 - diff: 32.61mlTrain batch 7/31 - 62.3ms/batch - loss: 173.69452 - diff: 30.54mlTrain batch 8/31 - 62.8ms/batch - loss: 161.76885 - diff: 30.52mlTrain batch 9/31 - 64.5ms/batch - loss: 148.22813 - diff: 29.39mlTrain batch 10/31 - 62.5ms/batch - loss: 144.03320 - diff: 29.44mlTrain batch 11/31 - 62.5ms/batch - loss: 138.66126 - diff: 29.35mlTrain batch 12/31 - 63.1ms/batch - loss: 130.56080 - diff: 28.70mlTrain batch 13/31 - 62.4ms/batch - loss: 125.96970 - diff: 28.42mlTrain batch 14/31 - 62.4ms/batch - loss: 118.78632 - diff: 27.52mlTrain batch 15/31 - 62.5ms/batch - loss: 115.32002 - diff: 27.39mlTrain batch 16/31 - 63.5ms/batch - loss: 112.87576 - diff: 27.36mlTrain batch 17/31 - 65.1ms/batch - loss: 114.79944 - diff: 27.45mlTrain batch 18/31 - 65.2ms/batch - loss: 128.54360 - diff: 28.67mlTrain batch 19/31 - 65.0ms/batch - loss: 123.79953 - diff: 28.33mlTrain batch 20/31 - 62.5ms/batch - loss: 118.56617 - diff: 27.60mlTrain batch 21/31 - 63.6ms/batch - loss: 113.84620 - diff: 26.97mlTrain batch 22/31 - 62.4ms/batch - loss: 112.98206 - diff: 27.06mlTrain batch 23/31 - 63.4ms/batch - loss: 109.10073 - diff: 26.53mlTrain batch 24/31 - 62.5ms/batch - loss: 106.64820 - diff: 26.43mlTrain batch 25/31 - 63.2ms/batch - loss: 103.92242 - diff: 26.10mlTrain batch 26/31 - 62.4ms/batch - loss: 101.36452 - diff: 25.86mlTrain batch 27/31 - 63.8ms/batch - loss: 100.02725 - diff: 25.87mlTrain batch 28/31 - 62.6ms/batch - loss: 97.24212 - diff: 25.49mlTrain batch 29/31 - 63.2ms/batch - loss: 94.58822 - diff: 25.07mlTrain batch 30/31 - 63.3ms/batch - loss: 95.42718 - diff: 25.32mlTrain batch 31/31 - 42.2ms/batch - loss: 95.88109 - diff: 25.30mlTrain batch 31/31 - 9.7s 42.2ms/batch - loss: 95.88109 - diff: 25.30ml
Test 0.6s: val_loss: 101.28896 - diff: 24.89ml

Epoch 10: current best loss = 74.72995, at epoch 5
Train batch 1/31 - 64.6ms/batch - loss: 133.83986 - diff: 28.28mlTrain batch 2/31 - 62.5ms/batch - loss: 94.28015 - diff: 24.97mlTrain batch 3/31 - 75.6ms/batch - loss: 89.06981 - diff: 26.47mlTrain batch 4/31 - 63.1ms/batch - loss: 88.96542 - diff: 26.99mlTrain batch 5/31 - 72.5ms/batch - loss: 85.68845 - diff: 26.90mlTrain batch 6/31 - 62.4ms/batch - loss: 76.09663 - diff: 25.24mlTrain batch 7/31 - 69.5ms/batch - loss: 71.72605 - diff: 24.95mlTrain batch 8/31 - 63.9ms/batch - loss: 80.08305 - diff: 25.79mlTrain batch 9/31 - 72.4ms/batch - loss: 77.73124 - diff: 25.41mlTrain batch 10/31 - 62.4ms/batch - loss: 83.13949 - diff: 25.56mlTrain batch 11/31 - 62.6ms/batch - loss: 133.00207 - diff: 27.14mlTrain batch 12/31 - 62.4ms/batch - loss: 133.40158 - diff: 27.65mlTrain batch 13/31 - 62.4ms/batch - loss: 125.80733 - diff: 26.92mlTrain batch 14/31 - 64.8ms/batch - loss: 121.37076 - diff: 26.73mlTrain batch 15/31 - 64.0ms/batch - loss: 118.30231 - diff: 26.65mlTrain batch 16/31 - 62.4ms/batch - loss: 115.43932 - diff: 26.50mlTrain batch 17/31 - 63.5ms/batch - loss: 110.72485 - diff: 26.10mlTrain batch 18/31 - 62.6ms/batch - loss: 108.09271 - diff: 26.20mlTrain batch 19/31 - 64.0ms/batch - loss: 108.58703 - diff: 26.47mlTrain batch 20/31 - 63.1ms/batch - loss: 105.84541 - diff: 26.35mlTrain batch 21/31 - 62.4ms/batch - loss: 108.96659 - diff: 26.71mlTrain batch 22/31 - 62.4ms/batch - loss: 106.06150 - diff: 26.42mlTrain batch 23/31 - 62.4ms/batch - loss: 111.50532 - diff: 26.71mlTrain batch 24/31 - 62.4ms/batch - loss: 112.10318 - diff: 27.09mlTrain batch 25/31 - 62.8ms/batch - loss: 110.48289 - diff: 27.02mlTrain batch 26/31 - 62.7ms/batch - loss: 108.62190 - diff: 26.88mlTrain batch 27/31 - 62.3ms/batch - loss: 107.14804 - diff: 26.99mlTrain batch 28/31 - 62.4ms/batch - loss: 105.03678 - diff: 26.84mlTrain batch 29/31 - 62.5ms/batch - loss: 103.49367 - diff: 26.71mlTrain batch 30/31 - 62.3ms/batch - loss: 102.62063 - diff: 26.78mlTrain batch 31/31 - 40.6ms/batch - loss: 102.04133 - diff: 26.62mlTrain batch 31/31 - 9.7s 40.6ms/batch - loss: 102.04133 - diff: 26.62ml
Test 0.6s: val_loss: 81.42131 - diff: 23.65ml

Epoch 11: current best loss = 74.72995, at epoch 5
Train batch 1/31 - 65.1ms/batch - loss: 52.15987 - diff: 22.09mlTrain batch 2/31 - 64.3ms/batch - loss: 66.40983 - diff: 24.69mlTrain batch 3/31 - 64.5ms/batch - loss: 62.18746 - diff: 24.60mlTrain batch 4/31 - 78.4ms/batch - loss: 66.24471 - diff: 25.11mlTrain batch 5/31 - 64.3ms/batch - loss: 63.09278 - diff: 24.80mlTrain batch 6/31 - 68.9ms/batch - loss: 60.61654 - diff: 24.04mlTrain batch 7/31 - 64.5ms/batch - loss: 57.04658 - diff: 23.25mlTrain batch 8/31 - 71.5ms/batch - loss: 53.97021 - diff: 22.61mlTrain batch 9/31 - 63.4ms/batch - loss: 53.77859 - diff: 22.88mlTrain batch 10/31 - 63.0ms/batch - loss: 57.05382 - diff: 23.76mlTrain batch 11/31 - 64.4ms/batch - loss: 58.62297 - diff: 23.70mlTrain batch 12/31 - 74.6ms/batch - loss: 63.96027 - diff: 24.17mlTrain batch 13/31 - 65.0ms/batch - loss: 61.64843 - diff: 23.77mlTrain batch 14/31 - 63.1ms/batch - loss: 79.64384 - diff: 24.93mlTrain batch 15/31 - 63.2ms/batch - loss: 76.56165 - diff: 24.54mlTrain batch 16/31 - 62.5ms/batch - loss: 75.81615 - diff: 24.59mlTrain batch 17/31 - 63.7ms/batch - loss: 115.75833 - diff: 26.28mlTrain batch 18/31 - 62.6ms/batch - loss: 113.48502 - diff: 25.97mlTrain batch 19/31 - 85.0ms/batch - loss: 109.09218 - diff: 25.50mlTrain batch 20/31 - 65.5ms/batch - loss: 105.61012 - diff: 25.19mlTrain batch 21/31 - 68.8ms/batch - loss: 104.16129 - diff: 25.22mlTrain batch 22/31 - 62.8ms/batch - loss: 104.29956 - diff: 25.34mlTrain batch 23/31 - 63.5ms/batch - loss: 104.14512 - diff: 25.24mlTrain batch 24/31 - 63.2ms/batch - loss: 101.41484 - diff: 25.07mlTrain batch 25/31 - 63.4ms/batch - loss: 98.85758 - diff: 24.90mlTrain batch 26/31 - 64.5ms/batch - loss: 97.86944 - diff: 25.00mlTrain batch 27/31 - 63.6ms/batch - loss: 95.67333 - diff: 24.83mlTrain batch 28/31 - 62.3ms/batch - loss: 94.22797 - diff: 24.79mlTrain batch 29/31 - 62.5ms/batch - loss: 94.92501 - diff: 25.09mlTrain batch 30/31 - 62.8ms/batch - loss: 93.69832 - diff: 25.01mlTrain batch 31/31 - 41.5ms/batch - loss: 93.77489 - diff: 25.00mlTrain batch 31/31 - 9.6s 41.5ms/batch - loss: 93.77489 - diff: 25.00ml
Test 0.6s: val_loss: 81.79526 - diff: 25.52ml

Epoch 12: current best loss = 74.72995, at epoch 5
Train batch 1/31 - 64.7ms/batch - loss: 43.91394 - diff: 25.25mlTrain batch 2/31 - 72.1ms/batch - loss: 59.90336 - diff: 24.50mlTrain batch 3/31 - 62.6ms/batch - loss: 83.16964 - diff: 26.17mlTrain batch 4/31 - 64.6ms/batch - loss: 72.28040 - diff: 24.82mlTrain batch 5/31 - 64.2ms/batch - loss: 67.49710 - diff: 24.11mlTrain batch 6/31 - 67.8ms/batch - loss: 158.73650 - diff: 27.24mlTrain batch 7/31 - 70.0ms/batch - loss: 142.77774 - diff: 26.89mlTrain batch 8/31 - 64.4ms/batch - loss: 137.39369 - diff: 26.78mlTrain batch 9/31 - 63.0ms/batch - loss: 125.52723 - diff: 25.74mlTrain batch 10/31 - 62.9ms/batch - loss: 116.64754 - diff: 25.08mlTrain batch 11/31 - 63.6ms/batch - loss: 108.80543 - diff: 24.41mlTrain batch 12/31 - 63.2ms/batch - loss: 111.43001 - diff: 25.07mlTrain batch 13/31 - 63.4ms/batch - loss: 106.80561 - diff: 25.01mlTrain batch 14/31 - 63.3ms/batch - loss: 102.25554 - diff: 24.85mlTrain batch 15/31 - 63.8ms/batch - loss: 101.71519 - diff: 25.09mlTrain batch 16/31 - 68.0ms/batch - loss: 98.39538 - diff: 24.94mlTrain batch 17/31 - 63.6ms/batch - loss: 95.32383 - diff: 24.83mlTrain batch 18/31 - 64.9ms/batch - loss: 95.31711 - diff: 25.23mlTrain batch 19/31 - 63.7ms/batch - loss: 98.58491 - diff: 25.54mlTrain batch 20/31 - 64.9ms/batch - loss: 96.93043 - diff: 25.48mlTrain batch 21/31 - 65.6ms/batch - loss: 96.67683 - diff: 25.32mlTrain batch 22/31 - 63.8ms/batch - loss: 94.89036 - diff: 25.23mlTrain batch 23/31 - 62.4ms/batch - loss: 95.22527 - diff: 25.47mlTrain batch 24/31 - 62.4ms/batch - loss: 93.10437 - diff: 25.20mlTrain batch 25/31 - 64.6ms/batch - loss: 95.27224 - diff: 25.46mlTrain batch 26/31 - 62.6ms/batch - loss: 95.91025 - diff: 25.82mlTrain batch 27/31 - 64.0ms/batch - loss: 98.84321 - diff: 26.39mlTrain batch 28/31 - 64.9ms/batch - loss: 96.40009 - diff: 26.10mlTrain batch 29/31 - 63.6ms/batch - loss: 100.49112 - diff: 26.49mlTrain batch 30/31 - 64.7ms/batch - loss: 98.15296 - diff: 26.17mlTrain batch 31/31 - 41.1ms/batch - loss: 100.19880 - diff: 26.36mlTrain batch 31/31 - 9.7s 41.1ms/batch - loss: 100.19880 - diff: 26.36ml
Test 0.6s: val_loss: 69.57762 - diff: 22.85ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Systole_DenseNet121_0_Adam-0.001_MSE_DA3_best

Epoch 13: current best loss = 69.57762, at epoch 12
Train batch 1/31 - 64.3ms/batch - loss: 68.08395 - diff: 24.45mlTrain batch 2/31 - 62.5ms/batch - loss: 63.14837 - diff: 24.52mlTrain batch 3/31 - 62.5ms/batch - loss: 74.07795 - diff: 25.70mlTrain batch 4/31 - 62.4ms/batch - loss: 67.95355 - diff: 24.98mlTrain batch 5/31 - 63.5ms/batch - loss: 61.21539 - diff: 23.94mlTrain batch 6/31 - 62.6ms/batch - loss: 56.55665 - diff: 23.28mlTrain batch 7/31 - 62.5ms/batch - loss: 75.92641 - diff: 24.70mlTrain batch 8/31 - 62.5ms/batch - loss: 76.95824 - diff: 25.25mlTrain batch 9/31 - 63.6ms/batch - loss: 120.33210 - diff: 27.57mlTrain batch 10/31 - 62.5ms/batch - loss: 111.82605 - diff: 26.84mlTrain batch 11/31 - 63.4ms/batch - loss: 109.81712 - diff: 27.23mlTrain batch 12/31 - 62.5ms/batch - loss: 109.38612 - diff: 27.33mlTrain batch 13/31 - 63.0ms/batch - loss: 105.63181 - diff: 27.19mlTrain batch 14/31 - 63.2ms/batch - loss: 101.35444 - diff: 26.72mlTrain batch 15/31 - 63.5ms/batch - loss: 100.71884 - diff: 27.12mlTrain batch 16/31 - 62.5ms/batch - loss: 98.63915 - diff: 27.05mlTrain batch 17/31 - 63.8ms/batch - loss: 98.72876 - diff: 27.26mlTrain batch 18/31 - 62.4ms/batch - loss: 95.87273 - diff: 26.81mlTrain batch 19/31 - 62.6ms/batch - loss: 92.23303 - diff: 26.35mlTrain batch 20/31 - 62.5ms/batch - loss: 91.27984 - diff: 26.38mlTrain batch 21/31 - 63.9ms/batch - loss: 90.62901 - diff: 26.31mlTrain batch 22/31 - 68.4ms/batch - loss: 88.87899 - diff: 26.19mlTrain batch 23/31 - 64.5ms/batch - loss: 89.18245 - diff: 26.15mlTrain batch 24/31 - 63.3ms/batch - loss: 87.06056 - diff: 25.78mlTrain batch 25/31 - 62.4ms/batch - loss: 85.19848 - diff: 25.59mlTrain batch 26/31 - 64.3ms/batch - loss: 87.74733 - diff: 25.98mlTrain batch 27/31 - 62.6ms/batch - loss: 85.95882 - diff: 25.73mlTrain batch 28/31 - 71.3ms/batch - loss: 90.81985 - diff: 26.09mlTrain batch 29/31 - 62.5ms/batch - loss: 89.49743 - diff: 25.82mlTrain batch 30/31 - 63.3ms/batch - loss: 88.28831 - diff: 25.72mlTrain batch 31/31 - 41.0ms/batch - loss: 87.35138 - diff: 25.49mlTrain batch 31/31 - 9.7s 41.0ms/batch - loss: 87.35138 - diff: 25.49ml
Test 0.6s: val_loss: 73.01226 - diff: 24.84ml

Epoch 14: current best loss = 69.57762, at epoch 12
Train batch 1/31 - 77.8ms/batch - loss: 36.91508 - diff: 18.64mlTrain batch 2/31 - 62.5ms/batch - loss: 209.24402 - diff: 26.85mlTrain batch 3/31 - 62.9ms/batch - loss: 147.82801 - diff: 23.00mlTrain batch 4/31 - 62.5ms/batch - loss: 154.61771 - diff: 27.16mlTrain batch 5/31 - 62.8ms/batch - loss: 126.86555 - diff: 24.36mlTrain batch 6/31 - 62.8ms/batch - loss: 111.75186 - diff: 23.74mlTrain batch 7/31 - 62.4ms/batch - loss: 116.03042 - diff: 25.26mlTrain batch 8/31 - 62.9ms/batch - loss: 108.70427 - diff: 25.08mlTrain batch 9/31 - 64.4ms/batch - loss: 107.27633 - diff: 25.23mlTrain batch 10/31 - 62.5ms/batch - loss: 104.74472 - diff: 25.34mlTrain batch 11/31 - 62.5ms/batch - loss: 103.24088 - diff: 25.77mlTrain batch 12/31 - 64.4ms/batch - loss: 105.45364 - diff: 26.01mlTrain batch 13/31 - 62.3ms/batch - loss: 101.05208 - diff: 25.66mlTrain batch 14/31 - 63.1ms/batch - loss: 105.89334 - diff: 26.00mlTrain batch 15/31 - 62.7ms/batch - loss: 101.15828 - diff: 25.50mlTrain batch 16/31 - 62.9ms/batch - loss: 100.20359 - diff: 25.74mlTrain batch 17/31 - 62.9ms/batch - loss: 96.18838 - diff: 25.38mlTrain batch 18/31 - 62.7ms/batch - loss: 93.82480 - diff: 25.24mlTrain batch 19/31 - 62.4ms/batch - loss: 91.34720 - diff: 24.91mlTrain batch 20/31 - 62.5ms/batch - loss: 92.59525 - diff: 24.98mlTrain batch 21/31 - 63.0ms/batch - loss: 93.49190 - diff: 25.22mlTrain batch 22/31 - 63.1ms/batch - loss: 92.32449 - diff: 25.39mlTrain batch 23/31 - 62.2ms/batch - loss: 90.44604 - diff: 25.36mlTrain batch 24/31 - 62.5ms/batch - loss: 89.65509 - diff: 25.28mlTrain batch 25/31 - 62.5ms/batch - loss: 89.67832 - diff: 25.40mlTrain batch 26/31 - 62.6ms/batch - loss: 88.62232 - diff: 25.41mlTrain batch 27/31 - 62.6ms/batch - loss: 86.60595 - diff: 25.18mlTrain batch 28/31 - 62.3ms/batch - loss: 86.27442 - diff: 25.25mlTrain batch 29/31 - 63.4ms/batch - loss: 84.04377 - diff: 24.94mlTrain batch 30/31 - 63.0ms/batch - loss: 88.51246 - diff: 25.21mlTrain batch 31/31 - 43.3ms/batch - loss: 89.28707 - diff: 25.24mlTrain batch 31/31 - 9.7s 43.3ms/batch - loss: 89.28707 - diff: 25.24ml
Test 0.6s: val_loss: 90.89950 - diff: 30.24ml

Epoch 15: current best loss = 69.57762, at epoch 12
Train batch 1/31 - 89.1ms/batch - loss: 97.47887 - diff: 28.66mlTrain batch 2/31 - 62.4ms/batch - loss: 88.15933 - diff: 28.06mlTrain batch 3/31 - 76.9ms/batch - loss: 72.30812 - diff: 25.72mlTrain batch 4/31 - 62.6ms/batch - loss: 182.39675 - diff: 29.33mlTrain batch 5/31 - 73.6ms/batch - loss: 156.95408 - diff: 28.17mlTrain batch 6/31 - 62.3ms/batch - loss: 143.26350 - diff: 27.42mlTrain batch 7/31 - 74.4ms/batch - loss: 131.05659 - diff: 26.65mlTrain batch 8/31 - 63.1ms/batch - loss: 121.33270 - diff: 26.09mlTrain batch 9/31 - 73.8ms/batch - loss: 114.72878 - diff: 25.95mlTrain batch 10/31 - 62.8ms/batch - loss: 109.37418 - diff: 26.16mlTrain batch 11/31 - 70.1ms/batch - loss: 103.41367 - diff: 25.98mlTrain batch 12/31 - 63.2ms/batch - loss: 102.31297 - diff: 26.09mlTrain batch 13/31 - 62.5ms/batch - loss: 96.44645 - diff: 25.28mlTrain batch 14/31 - 63.4ms/batch - loss: 95.66693 - diff: 25.18mlTrain batch 15/31 - 79.6ms/batch - loss: 93.79562 - diff: 25.29mlTrain batch 16/31 - 62.3ms/batch - loss: 89.56603 - diff: 24.87mlTrain batch 17/31 - 79.9ms/batch - loss: 89.37235 - diff: 24.98mlTrain batch 18/31 - 64.5ms/batch - loss: 95.70029 - diff: 25.76mlTrain batch 19/31 - 71.5ms/batch - loss: 92.97218 - diff: 25.49mlTrain batch 20/31 - 62.4ms/batch - loss: 96.84387 - diff: 25.87mlTrain batch 21/31 - 63.0ms/batch - loss: 95.32225 - diff: 25.97mlTrain batch 22/31 - 62.4ms/batch - loss: 97.05745 - diff: 26.14mlTrain batch 23/31 - 63.9ms/batch - loss: 93.95140 - diff: 25.68mlTrain batch 24/31 - 63.6ms/batch - loss: 92.79755 - diff: 25.84mlTrain batch 25/31 - 62.4ms/batch - loss: 93.86717 - diff: 25.95mlTrain batch 26/31 - 62.3ms/batch - loss: 94.26271 - diff: 25.91mlTrain batch 27/31 - 62.6ms/batch - loss: 92.02385 - diff: 25.66mlTrain batch 28/31 - 62.4ms/batch - loss: 96.41795 - diff: 26.22mlTrain batch 29/31 - 63.8ms/batch - loss: 94.00225 - diff: 25.88mlTrain batch 30/31 - 63.5ms/batch - loss: 92.54817 - diff: 25.77mlTrain batch 31/31 - 40.9ms/batch - loss: 93.16617 - diff: 25.78mlTrain batch 31/31 - 9.6s 40.9ms/batch - loss: 93.16617 - diff: 25.78ml
Test 0.6s: val_loss: 92.08429 - diff: 26.55ml

Epoch 16: current best loss = 69.57762, at epoch 12
Train batch 1/31 - 71.5ms/batch - loss: 77.32121 - diff: 28.25mlTrain batch 2/31 - 63.4ms/batch - loss: 72.00900 - diff: 25.33mlTrain batch 3/31 - 64.1ms/batch - loss: 125.68638 - diff: 27.10mlTrain batch 4/31 - 62.3ms/batch - loss: 101.77038 - diff: 25.06mlTrain batch 5/31 - 64.8ms/batch - loss: 95.40397 - diff: 24.87mlTrain batch 6/31 - 62.5ms/batch - loss: 86.19256 - diff: 24.21mlTrain batch 7/31 - 63.3ms/batch - loss: 80.61923 - diff: 23.68mlTrain batch 8/31 - 62.7ms/batch - loss: 75.14139 - diff: 23.33mlTrain batch 9/31 - 65.5ms/batch - loss: 72.91357 - diff: 23.47mlTrain batch 10/31 - 62.4ms/batch - loss: 73.34383 - diff: 23.69mlTrain batch 11/31 - 66.5ms/batch - loss: 73.41163 - diff: 23.72mlTrain batch 12/31 - 62.4ms/batch - loss: 69.08760 - diff: 23.04mlTrain batch 13/31 - 64.2ms/batch - loss: 69.49663 - diff: 23.22mlTrain batch 14/31 - 62.3ms/batch - loss: 70.43308 - diff: 23.49mlTrain batch 15/31 - 62.4ms/batch - loss: 69.03823 - diff: 23.47mlTrain batch 16/31 - 63.4ms/batch - loss: 68.59559 - diff: 23.50mlTrain batch 17/31 - 63.0ms/batch - loss: 68.33658 - diff: 23.50mlTrain batch 18/31 - 63.6ms/batch - loss: 67.31026 - diff: 23.48mlTrain batch 19/31 - 67.0ms/batch - loss: 68.77473 - diff: 23.45mlTrain batch 20/31 - 62.9ms/batch - loss: 67.34427 - diff: 23.25mlTrain batch 21/31 - 63.4ms/batch - loss: 69.30268 - diff: 23.54mlTrain batch 22/31 - 63.3ms/batch - loss: 67.71763 - diff: 23.33mlTrain batch 23/31 - 76.7ms/batch - loss: 75.85933 - diff: 24.23mlTrain batch 24/31 - 65.5ms/batch - loss: 73.85986 - diff: 23.96mlTrain batch 25/31 - 64.6ms/batch - loss: 76.56607 - diff: 24.36mlTrain batch 26/31 - 62.9ms/batch - loss: 77.57036 - diff: 24.28mlTrain batch 27/31 - 73.0ms/batch - loss: 78.22165 - diff: 24.48mlTrain batch 28/31 - 63.8ms/batch - loss: 96.80787 - diff: 25.27mlTrain batch 29/31 - 64.3ms/batch - loss: 95.14600 - diff: 25.19mlTrain batch 30/31 - 63.2ms/batch - loss: 93.97319 - diff: 25.21mlTrain batch 31/31 - 40.4ms/batch - loss: 94.21457 - diff: 25.19mlTrain batch 31/31 - 9.7s 40.4ms/batch - loss: 94.21457 - diff: 25.19ml
Test 0.6s: val_loss: 71.45153 - diff: 23.82ml

Epoch 17: current best loss = 69.57762, at epoch 12
Train batch 1/31 - 64.5ms/batch - loss: 26.16328 - diff: 15.35mlTrain batch 2/31 - 62.3ms/batch - loss: 33.40285 - diff: 17.69mlTrain batch 3/31 - 62.8ms/batch - loss: 46.41876 - diff: 19.38mlTrain batch 4/31 - 64.0ms/batch - loss: 54.11728 - diff: 20.71mlTrain batch 5/31 - 62.9ms/batch - loss: 48.91029 - diff: 20.17mlTrain batch 6/31 - 63.5ms/batch - loss: 45.80216 - diff: 19.74mlTrain batch 7/31 - 62.3ms/batch - loss: 69.38247 - diff: 22.23mlTrain batch 8/31 - 62.3ms/batch - loss: 130.09478 - diff: 25.39mlTrain batch 9/31 - 62.7ms/batch - loss: 122.73807 - diff: 25.47mlTrain batch 10/31 - 64.8ms/batch - loss: 114.54195 - diff: 25.05mlTrain batch 11/31 - 62.5ms/batch - loss: 113.31805 - diff: 25.18mlTrain batch 12/31 - 62.9ms/batch - loss: 108.91638 - diff: 25.17mlTrain batch 13/31 - 63.0ms/batch - loss: 102.95528 - diff: 24.55mlTrain batch 14/31 - 63.9ms/batch - loss: 99.64668 - diff: 24.46mlTrain batch 15/31 - 62.5ms/batch - loss: 97.38996 - diff: 24.49mlTrain batch 16/31 - 62.4ms/batch - loss: 95.34775 - diff: 24.85mlTrain batch 17/31 - 62.5ms/batch - loss: 94.96801 - diff: 25.16mlTrain batch 18/31 - 62.3ms/batch - loss: 100.91175 - diff: 26.23mlTrain batch 19/31 - 62.6ms/batch - loss: 98.26130 - diff: 26.05mlTrain batch 20/31 - 62.8ms/batch - loss: 95.96551 - diff: 25.99mlTrain batch 21/31 - 62.7ms/batch - loss: 96.64080 - diff: 26.40mlTrain batch 22/31 - 63.3ms/batch - loss: 95.83259 - diff: 26.40mlTrain batch 23/31 - 62.4ms/batch - loss: 93.56657 - diff: 26.13mlTrain batch 24/31 - 62.4ms/batch - loss: 92.47339 - diff: 26.14mlTrain batch 25/31 - 66.4ms/batch - loss: 91.25626 - diff: 26.18mlTrain batch 26/31 - 62.4ms/batch - loss: 90.51741 - diff: 26.26mlTrain batch 27/31 - 62.3ms/batch - loss: 89.28995 - diff: 26.16mlTrain batch 28/31 - 63.6ms/batch - loss: 87.49369 - diff: 25.91mlTrain batch 29/31 - 62.5ms/batch - loss: 87.99130 - diff: 25.92mlTrain batch 30/31 - 62.9ms/batch - loss: 86.32187 - diff: 25.76mlTrain batch 31/31 - 41.0ms/batch - loss: 86.22933 - diff: 25.67mlTrain batch 31/31 - 9.6s 41.0ms/batch - loss: 86.22933 - diff: 25.67ml
Test 0.6s: val_loss: 71.55963 - diff: 24.87ml

Epoch 18: current best loss = 69.57762, at epoch 12
Train batch 1/31 - 72.6ms/batch - loss: 543.45483 - diff: 44.95mlTrain batch 2/31 - 63.0ms/batch - loss: 278.29041 - diff: 27.86mlTrain batch 3/31 - 65.8ms/batch - loss: 208.96316 - diff: 25.84mlTrain batch 4/31 - 64.8ms/batch - loss: 169.07204 - diff: 25.26mlTrain batch 5/31 - 78.8ms/batch - loss: 153.33954 - diff: 25.59mlTrain batch 6/31 - 67.2ms/batch - loss: 141.02755 - diff: 25.83mlTrain batch 7/31 - 62.9ms/batch - loss: 150.64428 - diff: 26.75mlTrain batch 8/31 - 63.0ms/batch - loss: 142.89686 - diff: 27.29mlTrain batch 9/31 - 64.1ms/batch - loss: 132.93284 - diff: 26.90mlTrain batch 10/31 - 63.8ms/batch - loss: 129.62110 - diff: 26.98mlTrain batch 11/31 - 64.0ms/batch - loss: 121.28101 - diff: 26.38mlTrain batch 12/31 - 64.1ms/batch - loss: 114.03833 - diff: 25.85mlTrain batch 13/31 - 64.9ms/batch - loss: 107.00084 - diff: 25.10mlTrain batch 14/31 - 64.1ms/batch - loss: 111.32989 - diff: 25.94mlTrain batch 15/31 - 63.4ms/batch - loss: 108.49140 - diff: 25.81mlTrain batch 16/31 - 65.4ms/batch - loss: 112.20084 - diff: 26.61mlTrain batch 17/31 - 64.9ms/batch - loss: 108.22739 - diff: 26.35mlTrain batch 18/31 - 65.5ms/batch - loss: 109.81197 - diff: 26.98mlTrain batch 19/31 - 67.1ms/batch - loss: 106.36672 - diff: 26.69mlTrain batch 20/31 - 66.8ms/batch - loss: 106.06950 - diff: 26.73mlTrain batch 21/31 - 64.8ms/batch - loss: 104.77495 - diff: 26.79mlTrain batch 22/31 - 66.1ms/batch - loss: 101.61834 - diff: 26.45mlTrain batch 23/31 - 65.7ms/batch - loss: 99.92051 - diff: 26.29mlTrain batch 24/31 - 65.8ms/batch - loss: 97.62844 - diff: 26.11mlTrain batch 25/31 - 87.4ms/batch - loss: 95.59356 - diff: 25.98mlTrain batch 26/31 - 67.7ms/batch - loss: 93.44686 - diff: 25.68mlTrain batch 27/31 - 62.8ms/batch - loss: 91.09261 - diff: 25.39mlTrain batch 28/31 - 62.4ms/batch - loss: 89.31991 - diff: 25.24mlTrain batch 29/31 - 76.0ms/batch - loss: 88.06753 - diff: 25.06mlTrain batch 30/31 - 62.3ms/batch - loss: 87.27611 - diff: 25.16mlTrain batch 31/31 - 40.7ms/batch - loss: 88.65345 - diff: 25.21mlTrain batch 31/31 - 9.7s 40.7ms/batch - loss: 88.65345 - diff: 25.21ml
Test 0.6s: val_loss: 63.16275 - diff: 23.44ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Systole_DenseNet121_0_Adam-0.001_MSE_DA3_best

Epoch 19: current best loss = 63.16275, at epoch 18
Train batch 1/31 - 64.5ms/batch - loss: 41.46630 - diff: 17.87mlTrain batch 2/31 - 64.5ms/batch - loss: 49.73138 - diff: 20.42mlTrain batch 3/31 - 64.5ms/batch - loss: 62.04388 - diff: 21.23mlTrain batch 4/31 - 65.5ms/batch - loss: 54.38153 - diff: 20.78mlTrain batch 5/31 - 64.3ms/batch - loss: 48.45154 - diff: 20.07mlTrain batch 6/31 - 69.7ms/batch - loss: 46.74230 - diff: 19.94mlTrain batch 7/31 - 62.9ms/batch - loss: 60.76915 - diff: 22.43mlTrain batch 8/31 - 63.3ms/batch - loss: 58.50925 - diff: 22.00mlTrain batch 9/31 - 62.5ms/batch - loss: 59.31180 - diff: 22.33mlTrain batch 10/31 - 72.0ms/batch - loss: 55.56346 - diff: 21.77mlTrain batch 11/31 - 63.6ms/batch - loss: 62.08477 - diff: 22.59mlTrain batch 12/31 - 73.2ms/batch - loss: 66.79465 - diff: 23.54mlTrain batch 13/31 - 62.5ms/batch - loss: 72.25238 - diff: 24.71mlTrain batch 14/31 - 73.2ms/batch - loss: 71.99045 - diff: 24.76mlTrain batch 15/31 - 62.5ms/batch - loss: 71.10550 - diff: 24.90mlTrain batch 16/31 - 69.1ms/batch - loss: 68.53325 - diff: 24.50mlTrain batch 17/31 - 62.5ms/batch - loss: 101.73094 - diff: 25.92mlTrain batch 18/31 - 62.9ms/batch - loss: 98.04357 - diff: 25.55mlTrain batch 19/31 - 63.1ms/batch - loss: 99.27300 - diff: 25.65mlTrain batch 20/31 - 63.3ms/batch - loss: 96.33727 - diff: 25.55mlTrain batch 21/31 - 62.6ms/batch - loss: 98.35138 - diff: 25.84mlTrain batch 22/31 - 71.8ms/batch - loss: 95.38564 - diff: 25.57mlTrain batch 23/31 - 62.6ms/batch - loss: 94.98040 - diff: 25.45mlTrain batch 24/31 - 63.3ms/batch - loss: 93.79982 - diff: 25.59mlTrain batch 25/31 - 64.8ms/batch - loss: 91.55164 - diff: 25.36mlTrain batch 26/31 - 66.5ms/batch - loss: 89.33204 - diff: 25.10mlTrain batch 27/31 - 62.9ms/batch - loss: 87.85694 - diff: 24.96mlTrain batch 28/31 - 62.3ms/batch - loss: 85.67096 - diff: 24.71mlTrain batch 29/31 - 62.5ms/batch - loss: 89.09013 - diff: 25.12mlTrain batch 30/31 - 62.8ms/batch - loss: 90.18620 - diff: 25.22mlTrain batch 31/31 - 45.9ms/batch - loss: 90.67041 - diff: 25.21mlTrain batch 31/31 - 9.7s 45.9ms/batch - loss: 90.67041 - diff: 25.21ml
Test 0.6s: val_loss: 87.23033 - diff: 25.59ml

Epoch 20: current best loss = 63.16275, at epoch 18
Train batch 1/31 - 68.7ms/batch - loss: 54.06535 - diff: 22.38mlTrain batch 2/31 - 63.0ms/batch - loss: 67.89935 - diff: 23.64mlTrain batch 3/31 - 62.7ms/batch - loss: 69.01361 - diff: 25.01mlTrain batch 4/31 - 65.6ms/batch - loss: 64.94228 - diff: 23.91mlTrain batch 5/31 - 76.5ms/batch - loss: 176.71934 - diff: 28.08mlTrain batch 6/31 - 62.7ms/batch - loss: 162.07094 - diff: 27.73mlTrain batch 7/31 - 82.0ms/batch - loss: 143.54791 - diff: 26.44mlTrain batch 8/31 - 62.5ms/batch - loss: 128.45628 - diff: 25.06mlTrain batch 9/31 - 70.4ms/batch - loss: 119.75858 - diff: 24.76mlTrain batch 10/31 - 63.0ms/batch - loss: 110.38762 - diff: 24.01mlTrain batch 11/31 - 63.6ms/batch - loss: 112.28691 - diff: 24.69mlTrain batch 12/31 - 62.6ms/batch - loss: 109.22336 - diff: 24.96mlTrain batch 13/31 - 72.0ms/batch - loss: 105.45552 - diff: 25.03mlTrain batch 14/31 - 62.8ms/batch - loss: 103.51884 - diff: 25.12mlTrain batch 15/31 - 69.1ms/batch - loss: 99.22957 - diff: 24.86mlTrain batch 16/31 - 62.5ms/batch - loss: 96.41548 - diff: 24.72mlTrain batch 17/31 - 81.7ms/batch - loss: 98.83354 - diff: 25.37mlTrain batch 18/31 - 62.7ms/batch - loss: 98.50368 - diff: 25.47mlTrain batch 19/31 - 70.3ms/batch - loss: 95.97123 - diff: 25.35mlTrain batch 20/31 - 63.6ms/batch - loss: 92.44632 - diff: 24.95mlTrain batch 21/31 - 73.2ms/batch - loss: 89.87767 - diff: 24.76mlTrain batch 22/31 - 62.4ms/batch - loss: 90.85351 - diff: 24.76mlTrain batch 23/31 - 70.7ms/batch - loss: 91.67631 - diff: 24.83mlTrain batch 24/31 - 62.3ms/batch - loss: 89.80411 - diff: 24.75mlTrain batch 25/31 - 63.3ms/batch - loss: 89.71241 - diff: 24.98mlTrain batch 26/31 - 63.1ms/batch - loss: 89.48091 - diff: 25.09mlTrain batch 27/31 - 64.6ms/batch - loss: 89.49235 - diff: 25.33mlTrain batch 28/31 - 64.7ms/batch - loss: 87.55838 - diff: 25.10mlTrain batch 29/31 - 63.8ms/batch - loss: 85.30566 - diff: 24.79mlTrain batch 30/31 - 62.4ms/batch - loss: 87.38302 - diff: 25.08mlTrain batch 31/31 - 40.7ms/batch - loss: 91.46688 - diff: 25.31mlTrain batch 31/31 - 9.7s 40.7ms/batch - loss: 91.46688 - diff: 25.31ml
Test 0.7s: val_loss: 96.30639 - diff: 25.37ml

Epoch 21: current best loss = 63.16275, at epoch 18
Train batch 1/31 - 66.4ms/batch - loss: 67.02789 - diff: 27.06mlTrain batch 2/31 - 70.8ms/batch - loss: 119.54397 - diff: 33.18mlTrain batch 3/31 - 63.1ms/batch - loss: 95.79902 - diff: 29.31mlTrain batch 4/31 - 77.0ms/batch - loss: 87.04009 - diff: 28.44mlTrain batch 5/31 - 63.6ms/batch - loss: 97.61442 - diff: 28.97mlTrain batch 6/31 - 76.5ms/batch - loss: 86.01412 - diff: 26.70mlTrain batch 7/31 - 62.5ms/batch - loss: 78.36740 - diff: 25.49mlTrain batch 8/31 - 65.5ms/batch - loss: 73.64967 - diff: 24.78mlTrain batch 9/31 - 63.9ms/batch - loss: 74.69334 - diff: 25.11mlTrain batch 10/31 - 63.5ms/batch - loss: 73.14480 - diff: 25.25mlTrain batch 11/31 - 63.8ms/batch - loss: 72.66233 - diff: 25.20mlTrain batch 12/31 - 63.6ms/batch - loss: 69.68200 - diff: 24.90mlTrain batch 13/31 - 64.5ms/batch - loss: 98.11803 - diff: 25.49mlTrain batch 14/31 - 62.6ms/batch - loss: 93.90912 - diff: 25.16mlTrain batch 15/31 - 62.6ms/batch - loss: 92.87899 - diff: 25.06mlTrain batch 16/31 - 62.4ms/batch - loss: 89.62704 - diff: 24.80mlTrain batch 17/31 - 64.4ms/batch - loss: 86.63611 - diff: 24.51mlTrain batch 18/31 - 62.8ms/batch - loss: 83.99964 - diff: 24.13mlTrain batch 19/31 - 65.9ms/batch - loss: 82.19683 - diff: 24.11mlTrain batch 20/31 - 63.1ms/batch - loss: 81.25941 - diff: 23.90mlTrain batch 21/31 - 63.6ms/batch - loss: 81.74340 - diff: 23.82mlTrain batch 22/31 - 62.7ms/batch - loss: 81.31409 - diff: 23.87mlTrain batch 23/31 - 64.0ms/batch - loss: 79.38457 - diff: 23.77mlTrain batch 24/31 - 62.6ms/batch - loss: 78.08605 - diff: 23.61mlTrain batch 25/31 - 64.4ms/batch - loss: 77.54141 - diff: 23.66mlTrain batch 26/31 - 62.5ms/batch - loss: 76.87418 - diff: 23.59mlTrain batch 27/31 - 92.4ms/batch - loss: 75.95247 - diff: 23.57mlTrain batch 28/31 - 65.7ms/batch - loss: 79.71801 - diff: 24.09mlTrain batch 29/31 - 62.3ms/batch - loss: 78.18760 - diff: 23.96mlTrain batch 30/31 - 63.5ms/batch - loss: 78.04606 - diff: 24.01mlTrain batch 31/31 - 42.6ms/batch - loss: 80.91859 - diff: 24.14mlTrain batch 31/31 - 9.7s 42.6ms/batch - loss: 80.91859 - diff: 24.14ml
Test 0.6s: val_loss: 70.15405 - diff: 24.07ml

Epoch 22: current best loss = 63.16275, at epoch 18
Train batch 1/31 - 64.6ms/batch - loss: 48.69894 - diff: 20.22mlTrain batch 2/31 - 63.1ms/batch - loss: 54.97100 - diff: 22.56mlTrain batch 3/31 - 64.5ms/batch - loss: 86.09497 - diff: 24.73mlTrain batch 4/31 - 62.5ms/batch - loss: 80.96488 - diff: 25.28mlTrain batch 5/31 - 65.0ms/batch - loss: 75.43240 - diff: 24.16mlTrain batch 6/31 - 63.6ms/batch - loss: 73.96081 - diff: 24.22mlTrain batch 7/31 - 64.1ms/batch - loss: 68.07484 - diff: 23.60mlTrain batch 8/31 - 63.4ms/batch - loss: 64.13697 - diff: 22.81mlTrain batch 9/31 - 62.5ms/batch - loss: 62.74364 - diff: 22.92mlTrain batch 10/31 - 63.4ms/batch - loss: 82.34143 - diff: 25.58mlTrain batch 11/31 - 62.6ms/batch - loss: 80.93988 - diff: 25.59mlTrain batch 12/31 - 62.6ms/batch - loss: 78.55901 - diff: 25.34mlTrain batch 13/31 - 63.3ms/batch - loss: 77.65895 - diff: 25.29mlTrain batch 14/31 - 62.9ms/batch - loss: 73.40776 - diff: 24.45mlTrain batch 15/31 - 62.6ms/batch - loss: 75.64109 - diff: 25.00mlTrain batch 16/31 - 63.3ms/batch - loss: 73.02119 - diff: 24.44mlTrain batch 17/31 - 64.4ms/batch - loss: 78.30682 - diff: 24.90mlTrain batch 18/31 - 62.6ms/batch - loss: 76.79222 - diff: 24.79mlTrain batch 19/31 - 64.4ms/batch - loss: 76.87161 - diff: 24.96mlTrain batch 20/31 - 63.7ms/batch - loss: 75.98105 - diff: 24.86mlTrain batch 21/31 - 64.5ms/batch - loss: 75.20377 - diff: 24.76mlTrain batch 22/31 - 63.0ms/batch - loss: 72.77539 - diff: 24.29mlTrain batch 23/31 - 63.2ms/batch - loss: 72.54568 - diff: 24.41mlTrain batch 24/31 - 62.5ms/batch - loss: 70.95683 - diff: 24.20mlTrain batch 25/31 - 63.9ms/batch - loss: 69.38535 - diff: 24.03mlTrain batch 26/31 - 62.6ms/batch - loss: 69.77651 - diff: 24.08mlTrain batch 27/31 - 65.1ms/batch - loss: 67.97807 - diff: 23.79mlTrain batch 28/31 - 64.0ms/batch - loss: 70.76620 - diff: 24.02mlTrain batch 29/31 - 64.0ms/batch - loss: 69.67821 - diff: 23.79mlTrain batch 30/31 - 62.9ms/batch - loss: 70.45789 - diff: 24.01mlTrain batch 31/31 - 39.6ms/batch - loss: 106.07027 - diff: 24.65mlTrain batch 31/31 - 9.7s 39.6ms/batch - loss: 106.07027 - diff: 24.65ml
Test 0.6s: val_loss: 68.79732 - diff: 23.20ml

Epoch 23: current best loss = 63.16275, at epoch 18
Train batch 1/31 - 70.5ms/batch - loss: 103.99277 - diff: 27.61mlTrain batch 2/31 - 64.1ms/batch - loss: 128.92908 - diff: 31.74mlTrain batch 3/31 - 64.6ms/batch - loss: 114.85194 - diff: 29.78mlTrain batch 4/31 - 62.5ms/batch - loss: 111.22808 - diff: 31.29mlTrain batch 5/31 - 63.7ms/batch - loss: 103.35296 - diff: 29.68mlTrain batch 6/31 - 62.6ms/batch - loss: 115.45268 - diff: 31.30mlTrain batch 7/31 - 63.6ms/batch - loss: 106.11063 - diff: 30.06mlTrain batch 8/31 - 62.4ms/batch - loss: 99.27991 - diff: 28.92mlTrain batch 9/31 - 66.5ms/batch - loss: 99.35741 - diff: 28.93mlTrain batch 10/31 - 63.2ms/batch - loss: 98.67754 - diff: 29.07mlTrain batch 11/31 - 66.5ms/batch - loss: 95.36696 - diff: 29.17mlTrain batch 12/31 - 63.7ms/batch - loss: 90.75794 - diff: 28.46mlTrain batch 13/31 - 62.6ms/batch - loss: 111.83389 - diff: 29.99mlTrain batch 14/31 - 63.5ms/batch - loss: 106.77658 - diff: 29.37mlTrain batch 15/31 - 63.0ms/batch - loss: 104.78483 - diff: 29.43mlTrain batch 16/31 - 62.6ms/batch - loss: 102.69564 - diff: 29.40mlTrain batch 17/31 - 62.8ms/batch - loss: 101.65554 - diff: 29.59mlTrain batch 18/31 - 62.8ms/batch - loss: 100.73530 - diff: 29.48mlTrain batch 19/31 - 63.1ms/batch - loss: 98.74566 - diff: 29.19mlTrain batch 20/31 - 63.3ms/batch - loss: 96.80741 - diff: 28.99mlTrain batch 21/31 - 63.4ms/batch - loss: 94.87135 - diff: 28.84mlTrain batch 22/31 - 62.5ms/batch - loss: 94.66860 - diff: 28.96mlTrain batch 23/31 - 62.7ms/batch - loss: 92.37929 - diff: 28.60mlTrain batch 24/31 - 62.7ms/batch - loss: 89.90694 - diff: 28.17mlTrain batch 25/31 - 62.7ms/batch - loss: 87.72499 - diff: 27.87mlTrain batch 26/31 - 62.6ms/batch - loss: 85.37317 - diff: 27.32mlTrain batch 27/31 - 62.6ms/batch - loss: 83.67145 - diff: 27.02mlTrain batch 28/31 - 63.0ms/batch - loss: 81.83262 - diff: 26.67mlTrain batch 29/31 - 63.7ms/batch - loss: 80.75127 - diff: 26.54mlTrain batch 30/31 - 64.4ms/batch - loss: 84.75915 - diff: 26.79mlTrain batch 31/31 - 45.3ms/batch - loss: 86.90910 - diff: 26.91mlTrain batch 31/31 - 9.6s 45.3ms/batch - loss: 86.90910 - diff: 26.91ml
Test 0.7s: val_loss: 74.12802 - diff: 24.71ml

Epoch 24: current best loss = 63.16275, at epoch 18
Train batch 1/31 - 66.3ms/batch - loss: 41.88401 - diff: 15.80mlTrain batch 2/31 - 64.0ms/batch - loss: 41.79714 - diff: 17.60mlTrain batch 3/31 - 66.7ms/batch - loss: 93.53501 - diff: 23.70mlTrain batch 4/31 - 63.9ms/batch - loss: 96.82142 - diff: 25.09mlTrain batch 5/31 - 63.0ms/batch - loss: 88.64638 - diff: 25.08mlTrain batch 6/31 - 65.5ms/batch - loss: 89.75649 - diff: 25.76mlTrain batch 7/31 - 63.3ms/batch - loss: 103.32862 - diff: 27.48mlTrain batch 8/31 - 64.7ms/batch - loss: 95.37231 - diff: 26.71mlTrain batch 9/31 - 64.3ms/batch - loss: 92.40176 - diff: 26.77mlTrain batch 10/31 - 63.3ms/batch - loss: 97.45073 - diff: 27.43mlTrain batch 11/31 - 65.6ms/batch - loss: 93.90989 - diff: 27.36mlTrain batch 12/31 - 63.8ms/batch - loss: 90.65095 - diff: 26.84mlTrain batch 13/31 - 64.3ms/batch - loss: 86.21624 - diff: 26.27mlTrain batch 14/31 - 77.0ms/batch - loss: 83.82803 - diff: 26.00mlTrain batch 15/31 - 64.3ms/batch - loss: 82.06645 - diff: 25.81mlTrain batch 16/31 - 65.7ms/batch - loss: 110.64337 - diff: 26.47mlTrain batch 17/31 - 71.5ms/batch - loss: 108.75827 - diff: 26.48mlTrain batch 18/31 - 63.7ms/batch - loss: 106.14955 - diff: 26.33mlTrain batch 19/31 - 70.5ms/batch - loss: 104.96248 - diff: 26.29mlTrain batch 20/31 - 64.3ms/batch - loss: 102.73002 - diff: 26.20mlTrain batch 21/31 - 70.3ms/batch - loss: 100.07997 - diff: 25.99mlTrain batch 22/31 - 70.4ms/batch - loss: 98.72222 - diff: 25.93mlTrain batch 23/31 - 62.7ms/batch - loss: 95.25576 - diff: 25.41mlTrain batch 24/31 - 64.9ms/batch - loss: 93.25197 - diff: 25.24mlTrain batch 25/31 - 63.5ms/batch - loss: 90.81619 - diff: 25.00mlTrain batch 26/31 - 76.0ms/batch - loss: 89.66902 - diff: 24.90mlTrain batch 27/31 - 63.5ms/batch - loss: 87.28622 - diff: 24.58mlTrain batch 28/31 - 66.1ms/batch - loss: 85.66973 - diff: 24.50mlTrain batch 29/31 - 63.4ms/batch - loss: 86.42467 - diff: 24.77mlTrain batch 30/31 - 63.4ms/batch - loss: 86.50555 - diff: 24.78mlTrain batch 31/31 - 40.3ms/batch - loss: 86.58098 - diff: 24.68mlTrain batch 31/31 - 9.6s 40.3ms/batch - loss: 86.58098 - diff: 24.68ml
Test 0.7s: val_loss: 78.56744 - diff: 23.38ml

Epoch 25: current best loss = 63.16275, at epoch 18
Train batch 1/31 - 64.2ms/batch - loss: 90.83656 - diff: 27.59mlTrain batch 2/31 - 62.6ms/batch - loss: 77.00657 - diff: 27.79mlTrain batch 3/31 - 63.4ms/batch - loss: 100.50396 - diff: 29.50mlTrain batch 4/31 - 62.6ms/batch - loss: 85.37791 - diff: 26.26mlTrain batch 5/31 - 63.3ms/batch - loss: 77.77448 - diff: 25.32mlTrain batch 6/31 - 63.0ms/batch - loss: 69.04345 - diff: 23.72mlTrain batch 7/31 - 62.6ms/batch - loss: 65.91353 - diff: 23.38mlTrain batch 8/31 - 63.0ms/batch - loss: 67.70369 - diff: 23.59mlTrain batch 9/31 - 62.6ms/batch - loss: 65.34254 - diff: 23.25mlTrain batch 10/31 - 63.1ms/batch - loss: 68.86108 - diff: 23.37mlTrain batch 11/31 - 63.7ms/batch - loss: 66.79366 - diff: 23.31mlTrain batch 12/31 - 62.6ms/batch - loss: 66.30382 - diff: 23.11mlTrain batch 13/31 - 63.3ms/batch - loss: 62.48474 - diff: 22.39mlTrain batch 14/31 - 62.5ms/batch - loss: 62.85414 - diff: 22.66mlTrain batch 15/31 - 63.0ms/batch - loss: 61.02268 - diff: 22.47mlTrain batch 16/31 - 63.8ms/batch - loss: 63.76927 - diff: 23.18mlTrain batch 17/31 - 62.6ms/batch - loss: 61.59123 - diff: 22.72mlTrain batch 18/31 - 63.1ms/batch - loss: 61.34017 - diff: 22.64mlTrain batch 19/31 - 62.6ms/batch - loss: 59.53793 - diff: 22.36mlTrain batch 20/31 - 62.6ms/batch - loss: 62.35786 - diff: 22.86mlTrain batch 21/31 - 62.6ms/batch - loss: 60.52998 - diff: 22.55mlTrain batch 22/31 - 62.7ms/batch - loss: 62.87786 - diff: 22.89mlTrain batch 23/31 - 62.6ms/batch - loss: 63.25100 - diff: 23.10mlTrain batch 24/31 - 62.5ms/batch - loss: 69.10635 - diff: 23.53mlTrain batch 25/31 - 62.6ms/batch - loss: 67.60941 - diff: 23.28mlTrain batch 26/31 - 62.6ms/batch - loss: 85.42572 - diff: 24.30mlTrain batch 27/31 - 63.0ms/batch - loss: 84.79815 - diff: 24.32mlTrain batch 28/31 - 63.3ms/batch - loss: 87.83499 - diff: 24.81mlTrain batch 29/31 - 62.6ms/batch - loss: 86.24051 - diff: 24.65mlTrain batch 30/31 - 62.6ms/batch - loss: 84.45942 - diff: 24.48mlTrain batch 31/31 - 42.7ms/batch - loss: 84.94386 - diff: 24.52mlTrain batch 31/31 - 9.6s 42.7ms/batch - loss: 84.94386 - diff: 24.52ml
Test 0.7s: val_loss: 69.12208 - diff: 24.07ml

Epoch 26: current best loss = 63.16275, at epoch 18
Train batch 1/31 - 64.0ms/batch - loss: 72.94447 - diff: 21.90mlTrain batch 2/31 - 62.6ms/batch - loss: 123.09917 - diff: 26.68mlTrain batch 3/31 - 73.4ms/batch - loss: 103.67690 - diff: 26.00mlTrain batch 4/31 - 62.6ms/batch - loss: 92.30589 - diff: 24.69mlTrain batch 5/31 - 70.4ms/batch - loss: 82.64040 - diff: 23.75mlTrain batch 6/31 - 63.9ms/batch - loss: 80.05023 - diff: 24.20mlTrain batch 7/31 - 73.4ms/batch - loss: 76.35363 - diff: 24.25mlTrain batch 8/31 - 62.8ms/batch - loss: 72.94127 - diff: 23.98mlTrain batch 9/31 - 75.2ms/batch - loss: 80.01184 - diff: 24.86mlTrain batch 10/31 - 62.7ms/batch - loss: 104.13344 - diff: 25.40mlTrain batch 11/31 - 78.8ms/batch - loss: 97.18589 - diff: 24.56mlTrain batch 12/31 - 62.7ms/batch - loss: 92.40762 - diff: 23.99mlTrain batch 13/31 - 68.9ms/batch - loss: 89.13299 - diff: 23.93mlTrain batch 14/31 - 62.9ms/batch - loss: 85.99724 - diff: 23.59mlTrain batch 15/31 - 71.9ms/batch - loss: 83.43374 - diff: 23.57mlTrain batch 16/31 - 63.5ms/batch - loss: 83.25416 - diff: 24.01mlTrain batch 17/31 - 65.2ms/batch - loss: 81.80530 - diff: 23.79mlTrain batch 18/31 - 63.5ms/batch - loss: 81.55821 - diff: 23.97mlTrain batch 19/31 - 77.3ms/batch - loss: 79.59816 - diff: 23.67mlTrain batch 20/31 - 62.6ms/batch - loss: 78.02167 - diff: 23.63mlTrain batch 21/31 - 75.2ms/batch - loss: 77.10562 - diff: 23.49mlTrain batch 22/31 - 63.8ms/batch - loss: 76.22929 - diff: 23.58mlTrain batch 23/31 - 75.3ms/batch - loss: 76.51850 - diff: 23.62mlTrain batch 24/31 - 62.6ms/batch - loss: 75.37359 - diff: 23.58mlTrain batch 25/31 - 70.2ms/batch - loss: 75.71078 - diff: 23.60mlTrain batch 26/31 - 62.7ms/batch - loss: 76.38592 - diff: 23.85mlTrain batch 27/31 - 78.6ms/batch - loss: 76.29030 - diff: 24.04mlTrain batch 28/31 - 62.6ms/batch - loss: 74.67400 - diff: 23.86mlTrain batch 29/31 - 70.3ms/batch - loss: 74.81305 - diff: 24.02mlTrain batch 30/31 - 62.6ms/batch - loss: 73.64833 - diff: 23.92mlTrain batch 31/31 - 41.0ms/batch - loss: 74.42681 - diff: 23.96mlTrain batch 31/31 - 9.6s 41.0ms/batch - loss: 74.42681 - diff: 23.96ml
Test 0.6s: val_loss: 71.61781 - diff: 23.95ml

Epoch 27: current best loss = 63.16275, at epoch 18
Train batch 1/31 - 64.8ms/batch - loss: 78.65523 - diff: 25.56mlTrain batch 2/31 - 63.5ms/batch - loss: 59.26680 - diff: 21.82mlTrain batch 3/31 - 63.9ms/batch - loss: 73.30924 - diff: 25.89mlTrain batch 4/31 - 62.9ms/batch - loss: 66.53378 - diff: 24.82mlTrain batch 5/31 - 64.8ms/batch - loss: 61.14747 - diff: 23.69mlTrain batch 6/31 - 63.6ms/batch - loss: 123.37111 - diff: 25.38mlTrain batch 7/31 - 64.7ms/batch - loss: 110.95626 - diff: 24.31mlTrain batch 8/31 - 62.8ms/batch - loss: 103.88148 - diff: 24.49mlTrain batch 9/31 - 65.1ms/batch - loss: 103.10410 - diff: 24.61mlTrain batch 10/31 - 62.7ms/batch - loss: 97.09242 - diff: 24.19mlTrain batch 11/31 - 63.5ms/batch - loss: 94.96818 - diff: 24.34mlTrain batch 12/31 - 63.0ms/batch - loss: 101.60336 - diff: 25.59mlTrain batch 13/31 - 63.4ms/batch - loss: 97.07736 - diff: 25.18mlTrain batch 14/31 - 63.7ms/batch - loss: 92.11912 - diff: 24.52mlTrain batch 15/31 - 64.6ms/batch - loss: 88.84343 - diff: 24.26mlTrain batch 16/31 - 62.6ms/batch - loss: 85.15803 - diff: 23.85mlTrain batch 17/31 - 63.6ms/batch - loss: 84.01899 - diff: 23.75mlTrain batch 18/31 - 63.0ms/batch - loss: 84.10212 - diff: 23.98mlTrain batch 19/31 - 68.7ms/batch - loss: 81.37976 - diff: 23.63mlTrain batch 20/31 - 62.6ms/batch - loss: 85.56032 - diff: 24.26mlTrain batch 21/31 - 62.7ms/batch - loss: 83.36564 - diff: 24.12mlTrain batch 22/31 - 63.9ms/batch - loss: 82.28884 - diff: 24.26mlTrain batch 23/31 - 62.8ms/batch - loss: 82.16386 - diff: 24.21mlTrain batch 24/31 - 63.4ms/batch - loss: 80.16099 - diff: 24.02mlTrain batch 25/31 - 62.9ms/batch - loss: 78.72358 - diff: 23.89mlTrain batch 26/31 - 62.8ms/batch - loss: 79.80439 - diff: 24.10mlTrain batch 27/31 - 62.8ms/batch - loss: 78.38576 - diff: 23.95mlTrain batch 28/31 - 63.0ms/batch - loss: 78.95533 - diff: 24.09mlTrain batch 29/31 - 63.4ms/batch - loss: 78.39627 - diff: 24.11mlTrain batch 30/31 - 62.6ms/batch - loss: 77.23043 - diff: 24.07mlTrain batch 31/31 - 42.4ms/batch - loss: 77.48755 - diff: 23.99mlTrain batch 31/31 - 9.7s 42.4ms/batch - loss: 77.48755 - diff: 23.99ml
Test 0.6s: val_loss: 62.20281 - diff: 23.61ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Systole_DenseNet121_0_Adam-0.001_MSE_DA3_best

Epoch 28: current best loss = 62.20281, at epoch 27
Train batch 1/31 - 65.6ms/batch - loss: 48.66015 - diff: 22.48mlTrain batch 2/31 - 62.5ms/batch - loss: 41.46362 - diff: 20.91mlTrain batch 3/31 - 62.7ms/batch - loss: 37.57358 - diff: 19.91mlTrain batch 4/31 - 63.7ms/batch - loss: 37.30578 - diff: 19.56mlTrain batch 5/31 - 74.0ms/batch - loss: 43.85123 - diff: 21.32mlTrain batch 6/31 - 63.3ms/batch - loss: 42.43502 - diff: 21.08mlTrain batch 7/31 - 63.5ms/batch - loss: 48.54598 - diff: 21.84mlTrain batch 8/31 - 63.2ms/batch - loss: 56.61511 - diff: 23.02mlTrain batch 9/31 - 62.8ms/batch - loss: 55.48506 - diff: 23.00mlTrain batch 10/31 - 70.0ms/batch - loss: 53.64316 - diff: 22.83mlTrain batch 11/31 - 63.0ms/batch - loss: 65.18925 - diff: 23.55mlTrain batch 12/31 - 63.7ms/batch - loss: 65.53634 - diff: 23.58mlTrain batch 13/31 - 63.2ms/batch - loss: 66.57658 - diff: 23.62mlTrain batch 14/31 - 67.7ms/batch - loss: 64.02640 - diff: 23.33mlTrain batch 15/31 - 63.0ms/batch - loss: 64.22679 - diff: 23.47mlTrain batch 16/31 - 64.7ms/batch - loss: 63.75351 - diff: 23.48mlTrain batch 17/31 - 63.4ms/batch - loss: 62.75240 - diff: 23.36mlTrain batch 18/31 - 65.2ms/batch - loss: 65.86695 - diff: 23.58mlTrain batch 19/31 - 63.9ms/batch - loss: 64.61479 - diff: 23.32mlTrain batch 20/31 - 64.1ms/batch - loss: 63.04953 - diff: 23.13mlTrain batch 21/31 - 64.3ms/batch - loss: 62.50862 - diff: 23.23mlTrain batch 22/31 - 66.0ms/batch - loss: 62.29492 - diff: 23.29mlTrain batch 23/31 - 64.0ms/batch - loss: 62.91427 - diff: 23.53mlTrain batch 24/31 - 66.1ms/batch - loss: 62.29886 - diff: 23.61mlTrain batch 25/31 - 64.5ms/batch - loss: 63.12899 - diff: 23.71mlTrain batch 26/31 - 63.4ms/batch - loss: 75.31858 - diff: 24.13mlTrain batch 27/31 - 63.9ms/batch - loss: 77.44464 - diff: 24.51mlTrain batch 28/31 - 63.8ms/batch - loss: 80.92847 - diff: 24.97mlTrain batch 29/31 - 64.4ms/batch - loss: 80.31472 - diff: 24.96mlTrain batch 30/31 - 64.7ms/batch - loss: 79.05847 - diff: 24.82mlTrain batch 31/31 - 40.8ms/batch - loss: 83.75306 - diff: 25.08mlTrain batch 31/31 - 9.7s 40.8ms/batch - loss: 83.75306 - diff: 25.08ml
Test 0.6s: val_loss: 72.23861 - diff: 23.59ml

Epoch 29: current best loss = 62.20281, at epoch 27
Train batch 1/31 - 82.4ms/batch - loss: 71.60776 - diff: 20.53mlTrain batch 2/31 - 62.6ms/batch - loss: 225.38275 - diff: 24.93mlTrain batch 3/31 - 72.8ms/batch - loss: 167.26158 - diff: 24.30mlTrain batch 4/31 - 62.7ms/batch - loss: 137.61532 - diff: 24.27mlTrain batch 5/31 - 63.5ms/batch - loss: 123.76523 - diff: 23.94mlTrain batch 6/31 - 62.6ms/batch - loss: 112.07308 - diff: 24.34mlTrain batch 7/31 - 64.1ms/batch - loss: 103.02954 - diff: 24.16mlTrain batch 8/31 - 62.7ms/batch - loss: 95.70847 - diff: 23.97mlTrain batch 9/31 - 72.3ms/batch - loss: 89.41390 - diff: 23.61mlTrain batch 10/31 - 63.0ms/batch - loss: 83.49553 - diff: 23.10mlTrain batch 11/31 - 70.6ms/batch - loss: 80.66829 - diff: 23.01mlTrain batch 12/31 - 64.4ms/batch - loss: 78.19359 - diff: 23.00mlTrain batch 13/31 - 65.8ms/batch - loss: 76.75931 - diff: 22.77mlTrain batch 14/31 - 62.6ms/batch - loss: 73.36724 - diff: 22.42mlTrain batch 15/31 - 62.7ms/batch - loss: 70.23484 - diff: 22.08mlTrain batch 16/31 - 62.8ms/batch - loss: 70.52932 - diff: 22.48mlTrain batch 17/31 - 62.7ms/batch - loss: 68.66920 - diff: 22.39mlTrain batch 18/31 - 62.9ms/batch - loss: 66.23455 - diff: 22.08mlTrain batch 19/31 - 62.9ms/batch - loss: 67.47710 - diff: 22.42mlTrain batch 20/31 - 63.3ms/batch - loss: 67.92491 - diff: 22.56mlTrain batch 21/31 - 67.1ms/batch - loss: 66.80444 - diff: 22.43mlTrain batch 22/31 - 63.8ms/batch - loss: 69.41533 - diff: 22.90mlTrain batch 23/31 - 63.3ms/batch - loss: 70.62655 - diff: 23.03mlTrain batch 24/31 - 62.8ms/batch - loss: 71.16557 - diff: 23.16mlTrain batch 25/31 - 62.6ms/batch - loss: 69.10852 - diff: 22.81mlTrain batch 26/31 - 62.7ms/batch - loss: 68.72790 - diff: 23.01mlTrain batch 27/31 - 64.2ms/batch - loss: 71.10897 - diff: 23.35mlTrain batch 28/31 - 64.4ms/batch - loss: 69.90606 - diff: 23.21mlTrain batch 29/31 - 62.5ms/batch - loss: 69.62924 - diff: 23.26mlTrain batch 30/31 - 62.5ms/batch - loss: 68.59115 - diff: 23.19mlTrain batch 31/31 - 40.9ms/batch - loss: 69.60968 - diff: 23.26mlTrain batch 31/31 - 9.7s 40.9ms/batch - loss: 69.60968 - diff: 23.26ml
Test 0.6s: val_loss: 71.60765 - diff: 23.24ml

Epoch 30: current best loss = 62.20281, at epoch 27
Train batch 1/31 - 74.6ms/batch - loss: 78.80872 - diff: 27.29mlTrain batch 2/31 - 66.7ms/batch - loss: 56.36478 - diff: 22.48mlTrain batch 3/31 - 62.6ms/batch - loss: 67.20862 - diff: 24.10mlTrain batch 4/31 - 63.5ms/batch - loss: 78.05602 - diff: 23.64mlTrain batch 5/31 - 62.9ms/batch - loss: 185.68757 - diff: 28.77mlTrain batch 6/31 - 62.8ms/batch - loss: 162.84800 - diff: 27.82mlTrain batch 7/31 - 62.6ms/batch - loss: 150.51445 - diff: 27.63mlTrain batch 8/31 - 62.8ms/batch - loss: 142.12681 - diff: 27.35mlTrain batch 9/31 - 63.0ms/batch - loss: 129.97915 - diff: 26.52mlTrain batch 10/31 - 62.6ms/batch - loss: 124.27686 - diff: 26.42mlTrain batch 11/31 - 63.1ms/batch - loss: 118.60685 - diff: 26.25mlTrain batch 12/31 - 62.8ms/batch - loss: 111.69994 - diff: 25.57mlTrain batch 13/31 - 62.8ms/batch - loss: 107.25670 - diff: 25.48mlTrain batch 14/31 - 62.6ms/batch - loss: 110.80378 - diff: 26.40mlTrain batch 15/31 - 62.8ms/batch - loss: 107.58072 - diff: 26.41mlTrain batch 16/31 - 62.7ms/batch - loss: 102.90611 - diff: 25.85mlTrain batch 17/31 - 62.8ms/batch - loss: 98.77808 - diff: 25.50mlTrain batch 18/31 - 62.6ms/batch - loss: 95.38109 - diff: 25.20mlTrain batch 19/31 - 62.7ms/batch - loss: 94.12878 - diff: 25.18mlTrain batch 20/31 - 62.7ms/batch - loss: 92.63408 - diff: 25.05mlTrain batch 21/31 - 62.6ms/batch - loss: 91.75766 - diff: 25.15mlTrain batch 22/31 - 62.6ms/batch - loss: 91.22443 - diff: 25.41mlTrain batch 23/31 - 63.1ms/batch - loss: 90.25907 - diff: 25.40mlTrain batch 24/31 - 62.8ms/batch - loss: 89.27517 - diff: 25.17mlTrain batch 25/31 - 63.9ms/batch - loss: 86.52187 - diff: 24.68mlTrain batch 26/31 - 62.8ms/batch - loss: 84.66908 - diff: 24.42mlTrain batch 27/31 - 63.8ms/batch - loss: 85.92573 - diff: 24.47mlTrain batch 28/31 - 62.6ms/batch - loss: 84.10130 - diff: 24.26mlTrain batch 29/31 - 62.7ms/batch - loss: 82.54839 - diff: 24.19mlTrain batch 30/31 - 62.7ms/batch - loss: 81.15982 - diff: 24.06mlTrain batch 31/31 - 41.8ms/batch - loss: 81.05624 - diff: 23.98mlTrain batch 31/31 - 9.7s 41.8ms/batch - loss: 81.05624 - diff: 23.98ml
Test 0.6s: val_loss: 71.78381 - diff: 22.97ml

Epoch 31: current best loss = 62.20281, at epoch 27
Train batch 1/31 - 70.9ms/batch - loss: 49.36050 - diff: 23.57mlTrain batch 2/31 - 62.9ms/batch - loss: 43.92853 - diff: 21.64mlTrain batch 3/31 - 79.3ms/batch - loss: 46.70160 - diff: 20.76mlTrain batch 4/31 - 62.9ms/batch - loss: 45.06872 - diff: 20.49mlTrain batch 5/31 - 64.5ms/batch - loss: 49.14130 - diff: 21.23mlTrain batch 6/31 - 63.9ms/batch - loss: 44.42617 - diff: 20.17mlTrain batch 7/31 - 64.5ms/batch - loss: 48.70469 - diff: 20.77mlTrain batch 8/31 - 62.6ms/batch - loss: 51.19454 - diff: 21.12mlTrain batch 9/31 - 64.4ms/batch - loss: 49.12922 - diff: 20.92mlTrain batch 10/31 - 62.7ms/batch - loss: 50.05382 - diff: 21.21mlTrain batch 11/31 - 63.4ms/batch - loss: 49.23136 - diff: 21.05mlTrain batch 12/31 - 64.0ms/batch - loss: 50.98692 - diff: 21.63mlTrain batch 13/31 - 63.8ms/batch - loss: 51.87375 - diff: 21.65mlTrain batch 14/31 - 62.9ms/batch - loss: 54.23925 - diff: 22.05mlTrain batch 15/31 - 66.7ms/batch - loss: 56.03347 - diff: 22.33mlTrain batch 16/31 - 62.7ms/batch - loss: 58.22747 - diff: 22.75mlTrain batch 17/31 - 67.5ms/batch - loss: 56.98311 - diff: 22.56mlTrain batch 18/31 - 62.6ms/batch - loss: 56.37263 - diff: 22.41mlTrain batch 19/31 - 63.6ms/batch - loss: 85.65159 - diff: 23.76mlTrain batch 20/31 - 63.8ms/batch - loss: 83.31500 - diff: 23.59mlTrain batch 21/31 - 62.9ms/batch - loss: 82.08965 - diff: 23.62mlTrain batch 22/31 - 63.8ms/batch - loss: 80.13516 - diff: 23.41mlTrain batch 23/31 - 62.7ms/batch - loss: 78.33304 - diff: 23.26mlTrain batch 24/31 - 62.6ms/batch - loss: 78.87365 - diff: 23.22mlTrain batch 25/31 - 62.6ms/batch - loss: 76.63524 - diff: 22.98mlTrain batch 26/31 - 62.5ms/batch - loss: 75.61316 - diff: 23.02mlTrain batch 27/31 - 62.6ms/batch - loss: 76.44623 - diff: 23.26mlTrain batch 28/31 - 62.6ms/batch - loss: 78.74870 - diff: 23.48mlTrain batch 29/31 - 63.6ms/batch - loss: 78.13215 - diff: 23.50mlTrain batch 30/31 - 62.6ms/batch - loss: 76.70697 - diff: 23.38mlTrain batch 31/31 - 40.5ms/batch - loss: 76.54633 - diff: 23.33mlTrain batch 31/31 - 9.7s 40.5ms/batch - loss: 76.54633 - diff: 23.33ml
Test 0.6s: val_loss: 62.51639 - diff: 21.96ml

Epoch 32: current best loss = 62.20281, at epoch 27
Train batch 1/31 - 66.8ms/batch - loss: 82.95813 - diff: 23.87mlTrain batch 2/31 - 62.6ms/batch - loss: 59.98213 - diff: 22.19mlTrain batch 3/31 - 68.6ms/batch - loss: 45.31910 - diff: 18.80mlTrain batch 4/31 - 68.0ms/batch - loss: 41.00885 - diff: 18.56mlTrain batch 5/31 - 63.1ms/batch - loss: 47.10059 - diff: 19.48mlTrain batch 6/31 - 62.7ms/batch - loss: 45.26106 - diff: 19.40mlTrain batch 7/31 - 80.4ms/batch - loss: 41.51623 - diff: 18.55mlTrain batch 8/31 - 62.6ms/batch - loss: 45.11464 - diff: 19.49mlTrain batch 9/31 - 63.6ms/batch - loss: 46.41742 - diff: 19.39mlTrain batch 10/31 - 62.8ms/batch - loss: 46.48093 - diff: 19.46mlTrain batch 11/31 - 73.2ms/batch - loss: 45.86920 - diff: 19.65mlTrain batch 12/31 - 64.6ms/batch - loss: 45.88957 - diff: 19.68mlTrain batch 13/31 - 76.8ms/batch - loss: 49.86189 - diff: 20.47mlTrain batch 14/31 - 65.1ms/batch - loss: 51.26230 - diff: 20.77mlTrain batch 15/31 - 72.1ms/batch - loss: 50.73550 - diff: 20.76mlTrain batch 16/31 - 63.0ms/batch - loss: 56.65382 - diff: 21.57mlTrain batch 17/31 - 62.7ms/batch - loss: 56.90611 - diff: 21.68mlTrain batch 18/31 - 62.7ms/batch - loss: 57.39567 - diff: 21.86mlTrain batch 19/31 - 77.6ms/batch - loss: 55.51159 - diff: 21.52mlTrain batch 20/31 - 63.4ms/batch - loss: 57.50786 - diff: 21.79mlTrain batch 21/31 - 66.0ms/batch - loss: 57.81370 - diff: 21.92mlTrain batch 22/31 - 62.9ms/batch - loss: 60.49766 - diff: 22.23mlTrain batch 23/31 - 67.3ms/batch - loss: 82.55577 - diff: 23.19mlTrain batch 24/31 - 62.5ms/batch - loss: 80.28925 - diff: 22.96mlTrain batch 25/31 - 66.9ms/batch - loss: 78.77804 - diff: 22.87mlTrain batch 26/31 - 62.5ms/batch - loss: 77.52679 - diff: 22.76mlTrain batch 27/31 - 67.8ms/batch - loss: 75.87333 - diff: 22.46mlTrain batch 28/31 - 63.7ms/batch - loss: 77.84091 - diff: 22.85mlTrain batch 29/31 - 62.7ms/batch - loss: 78.27303 - diff: 23.01mlTrain batch 30/31 - 62.6ms/batch - loss: 80.27239 - diff: 23.22mlTrain batch 31/31 - 41.3ms/batch - loss: 81.48184 - diff: 23.21mlTrain batch 31/31 - 9.8s 41.3ms/batch - loss: 81.48184 - diff: 23.21ml
Test 0.6s: val_loss: 110.20960 - diff: 29.62ml

Epoch 33: current best loss = 62.20281, at epoch 27
Train batch 1/31 - 64.8ms/batch - loss: 29.15561 - diff: 16.86mlTrain batch 2/31 - 62.6ms/batch - loss: 46.17890 - diff: 22.41mlTrain batch 3/31 - 67.2ms/batch - loss: 50.10918 - diff: 22.39mlTrain batch 4/31 - 72.5ms/batch - loss: 49.01800 - diff: 22.55mlTrain batch 5/31 - 65.4ms/batch - loss: 50.75154 - diff: 22.75mlTrain batch 6/31 - 63.4ms/batch - loss: 51.20841 - diff: 23.32mlTrain batch 7/31 - 62.8ms/batch - loss: 49.97535 - diff: 23.08mlTrain batch 8/31 - 62.6ms/batch - loss: 49.05502 - diff: 22.77mlTrain batch 9/31 - 62.6ms/batch - loss: 51.28602 - diff: 23.39mlTrain batch 10/31 - 62.7ms/batch - loss: 53.67316 - diff: 23.70mlTrain batch 11/31 - 63.8ms/batch - loss: 54.71919 - diff: 23.45mlTrain batch 12/31 - 62.6ms/batch - loss: 59.04119 - diff: 23.98mlTrain batch 13/31 - 63.0ms/batch - loss: 59.73141 - diff: 24.09mlTrain batch 14/31 - 62.9ms/batch - loss: 57.95367 - diff: 23.79mlTrain batch 15/31 - 63.2ms/batch - loss: 58.63593 - diff: 23.80mlTrain batch 16/31 - 62.6ms/batch - loss: 56.83877 - diff: 23.40mlTrain batch 17/31 - 62.7ms/batch - loss: 57.95637 - diff: 23.58mlTrain batch 18/31 - 62.9ms/batch - loss: 57.58822 - diff: 23.46mlTrain batch 19/31 - 62.6ms/batch - loss: 64.33613 - diff: 23.98mlTrain batch 20/31 - 62.6ms/batch - loss: 63.35285 - diff: 23.66mlTrain batch 21/31 - 62.6ms/batch - loss: 62.00660 - diff: 23.33mlTrain batch 22/31 - 62.8ms/batch - loss: 83.84062 - diff: 24.78mlTrain batch 23/31 - 62.8ms/batch - loss: 82.85042 - diff: 24.73mlTrain batch 24/31 - 63.0ms/batch - loss: 83.08148 - diff: 24.78mlTrain batch 25/31 - 62.9ms/batch - loss: 81.13685 - diff: 24.67mlTrain batch 26/31 - 62.6ms/batch - loss: 82.89418 - diff: 24.88mlTrain batch 27/31 - 63.1ms/batch - loss: 82.70384 - diff: 24.98mlTrain batch 28/31 - 62.8ms/batch - loss: 82.02381 - diff: 24.84mlTrain batch 29/31 - 62.6ms/batch - loss: 80.98474 - diff: 24.78mlTrain batch 30/31 - 62.8ms/batch - loss: 79.05593 - diff: 24.45mlTrain batch 31/31 - 44.2ms/batch - loss: 78.65864 - diff: 24.33mlTrain batch 31/31 - 9.7s 44.2ms/batch - loss: 78.65864 - diff: 24.33ml
Test 0.6s: val_loss: 64.20804 - diff: 24.07ml

Epoch 34: current best loss = 62.20281, at epoch 27
Train batch 1/31 - 80.3ms/batch - loss: 32.39319 - diff: 15.42mlTrain batch 2/31 - 63.0ms/batch - loss: 34.73116 - diff: 17.75mlTrain batch 3/31 - 70.5ms/batch - loss: 32.56421 - diff: 17.20mlTrain batch 4/31 - 62.8ms/batch - loss: 35.30074 - diff: 16.99mlTrain batch 5/31 - 76.4ms/batch - loss: 48.05760 - diff: 18.42mlTrain batch 6/31 - 63.8ms/batch - loss: 57.87724 - diff: 20.47mlTrain batch 7/31 - 63.1ms/batch - loss: 55.15129 - diff: 20.19mlTrain batch 8/31 - 63.2ms/batch - loss: 53.65632 - diff: 20.18mlTrain batch 9/31 - 65.9ms/batch - loss: 54.65275 - diff: 20.04mlTrain batch 10/31 - 62.9ms/batch - loss: 57.04019 - diff: 20.81mlTrain batch 11/31 - 70.5ms/batch - loss: 59.30597 - diff: 21.63mlTrain batch 12/31 - 62.5ms/batch - loss: 58.20346 - diff: 21.54mlTrain batch 13/31 - 71.2ms/batch - loss: 56.11258 - diff: 21.39mlTrain batch 14/31 - 63.0ms/batch - loss: 90.38417 - diff: 22.80mlTrain batch 15/31 - 79.0ms/batch - loss: 87.26749 - diff: 22.67mlTrain batch 16/31 - 63.5ms/batch - loss: 86.20336 - diff: 22.97mlTrain batch 17/31 - 78.0ms/batch - loss: 87.20233 - diff: 23.50mlTrain batch 18/31 - 63.0ms/batch - loss: 89.33531 - diff: 23.82mlTrain batch 19/31 - 72.2ms/batch - loss: 87.25136 - diff: 23.56mlTrain batch 20/31 - 62.6ms/batch - loss: 90.43637 - diff: 24.05mlTrain batch 21/31 - 89.3ms/batch - loss: 88.00435 - diff: 23.93mlTrain batch 22/31 - 62.8ms/batch - loss: 85.74410 - diff: 23.66mlTrain batch 23/31 - 67.5ms/batch - loss: 84.80708 - diff: 23.58mlTrain batch 24/31 - 64.2ms/batch - loss: 84.16808 - diff: 23.66mlTrain batch 25/31 - 77.8ms/batch - loss: 83.74445 - diff: 23.64mlTrain batch 26/31 - 62.5ms/batch - loss: 81.75871 - diff: 23.45mlTrain batch 27/31 - 65.4ms/batch - loss: 79.51908 - diff: 23.10mlTrain batch 28/31 - 62.6ms/batch - loss: 78.23599 - diff: 23.10mlTrain batch 29/31 - 62.8ms/batch - loss: 77.69964 - diff: 23.08mlTrain batch 30/31 - 62.8ms/batch - loss: 75.92353 - diff: 22.86mlTrain batch 31/31 - 41.1ms/batch - loss: 75.55269 - diff: 22.75mlTrain batch 31/31 - 9.7s 41.1ms/batch - loss: 75.55269 - diff: 22.75ml
Test 0.6s: val_loss: 78.91205 - diff: 25.20ml

Epoch 35: current best loss = 62.20281, at epoch 27
Train batch 1/31 - 73.5ms/batch - loss: 401.56683 - diff: 32.52mlTrain batch 2/31 - 63.3ms/batch - loss: 246.66647 - diff: 30.84mlTrain batch 3/31 - 65.5ms/batch - loss: 191.19060 - diff: 29.81mlTrain batch 4/31 - 62.5ms/batch - loss: 174.02932 - diff: 30.33mlTrain batch 5/31 - 70.6ms/batch - loss: 145.12686 - diff: 27.74mlTrain batch 6/31 - 71.8ms/batch - loss: 134.87289 - diff: 27.80mlTrain batch 7/31 - 73.6ms/batch - loss: 123.38610 - diff: 26.86mlTrain batch 8/31 - 63.3ms/batch - loss: 112.09887 - diff: 25.66mlTrain batch 9/31 - 64.9ms/batch - loss: 105.67054 - diff: 25.38mlTrain batch 10/31 - 63.5ms/batch - loss: 106.80160 - diff: 25.74mlTrain batch 11/31 - 64.5ms/batch - loss: 103.40237 - diff: 25.81mlTrain batch 12/31 - 62.9ms/batch - loss: 102.75278 - diff: 25.92mlTrain batch 13/31 - 64.5ms/batch - loss: 107.44457 - diff: 26.58mlTrain batch 14/31 - 62.7ms/batch - loss: 105.44526 - diff: 26.38mlTrain batch 15/31 - 63.7ms/batch - loss: 101.24157 - diff: 26.04mlTrain batch 16/31 - 62.8ms/batch - loss: 97.00796 - diff: 25.64mlTrain batch 17/31 - 63.6ms/batch - loss: 95.67994 - diff: 25.63mlTrain batch 18/31 - 64.1ms/batch - loss: 93.75212 - diff: 25.66mlTrain batch 19/31 - 63.5ms/batch - loss: 90.94004 - diff: 25.43mlTrain batch 20/31 - 63.2ms/batch - loss: 88.04979 - diff: 25.13mlTrain batch 21/31 - 64.3ms/batch - loss: 86.53178 - diff: 24.98mlTrain batch 22/31 - 63.0ms/batch - loss: 84.81788 - diff: 24.75mlTrain batch 23/31 - 68.7ms/batch - loss: 83.27985 - diff: 24.44mlTrain batch 24/31 - 62.6ms/batch - loss: 80.43287 - diff: 23.97mlTrain batch 25/31 - 67.5ms/batch - loss: 78.60833 - diff: 23.73mlTrain batch 26/31 - 62.7ms/batch - loss: 76.91560 - diff: 23.57mlTrain batch 27/31 - 62.9ms/batch - loss: 76.69241 - diff: 23.67mlTrain batch 28/31 - 62.8ms/batch - loss: 75.38695 - diff: 23.55mlTrain batch 29/31 - 63.5ms/batch - loss: 73.94108 - diff: 23.37mlTrain batch 30/31 - 63.4ms/batch - loss: 72.82435 - diff: 23.24mlTrain batch 31/31 - 42.5ms/batch - loss: 77.43150 - diff: 23.47mlTrain batch 31/31 - 9.7s 42.5ms/batch - loss: 77.43150 - diff: 23.47ml
Test 0.6s: val_loss: 63.93967 - diff: 22.78ml

Epoch 36: current best loss = 62.20281, at epoch 27
Train batch 1/31 - 65.1ms/batch - loss: 53.63752 - diff: 25.56mlTrain batch 2/31 - 62.6ms/batch - loss: 37.04636 - diff: 20.38mlTrain batch 3/31 - 72.2ms/batch - loss: 38.16658 - diff: 19.79mlTrain batch 4/31 - 62.6ms/batch - loss: 50.36226 - diff: 20.67mlTrain batch 5/31 - 64.1ms/batch - loss: 45.96534 - diff: 19.88mlTrain batch 6/31 - 62.8ms/batch - loss: 47.10963 - diff: 20.48mlTrain batch 7/31 - 69.1ms/batch - loss: 56.64364 - diff: 22.12mlTrain batch 8/31 - 63.2ms/batch - loss: 54.76209 - diff: 22.08mlTrain batch 9/31 - 63.4ms/batch - loss: 53.86755 - diff: 22.00mlTrain batch 10/31 - 62.7ms/batch - loss: 52.74436 - diff: 21.82mlTrain batch 11/31 - 63.4ms/batch - loss: 57.31261 - diff: 22.26mlTrain batch 12/31 - 62.9ms/batch - loss: 56.70163 - diff: 22.02mlTrain batch 13/31 - 63.6ms/batch - loss: 54.96724 - diff: 21.89mlTrain batch 14/31 - 62.9ms/batch - loss: 59.04523 - diff: 22.39mlTrain batch 15/31 - 65.2ms/batch - loss: 65.57064 - diff: 22.95mlTrain batch 16/31 - 63.3ms/batch - loss: 63.82534 - diff: 22.73mlTrain batch 17/31 - 64.3ms/batch - loss: 66.11920 - diff: 23.21mlTrain batch 18/31 - 62.5ms/batch - loss: 86.85287 - diff: 23.97mlTrain batch 19/31 - 64.4ms/batch - loss: 83.98162 - diff: 23.64mlTrain batch 20/31 - 63.3ms/batch - loss: 82.34609 - diff: 23.70mlTrain batch 21/31 - 64.2ms/batch - loss: 81.26865 - diff: 23.77mlTrain batch 22/31 - 62.6ms/batch - loss: 83.40515 - diff: 24.08mlTrain batch 23/31 - 63.9ms/batch - loss: 81.40671 - diff: 23.98mlTrain batch 24/31 - 62.6ms/batch - loss: 80.15788 - diff: 23.93mlTrain batch 25/31 - 64.2ms/batch - loss: 79.17292 - diff: 23.92mlTrain batch 26/31 - 62.6ms/batch - loss: 77.98906 - diff: 23.84mlTrain batch 27/31 - 64.5ms/batch - loss: 77.58960 - diff: 23.89mlTrain batch 28/31 - 62.6ms/batch - loss: 76.01797 - diff: 23.73mlTrain batch 29/31 - 63.9ms/batch - loss: 75.34595 - diff: 23.78mlTrain batch 30/31 - 62.6ms/batch - loss: 74.56999 - diff: 23.73mlTrain batch 31/31 - 42.1ms/batch - loss: 74.47043 - diff: 23.64mlTrain batch 31/31 - 9.7s 42.1ms/batch - loss: 74.47043 - diff: 23.64ml
Test 0.6s: val_loss: 75.16143 - diff: 25.54ml

Epoch 37: current best loss = 62.20281, at epoch 27
Train batch 1/31 - 80.8ms/batch - loss: 17.77710 - diff: 13.96mlTrain batch 2/31 - 63.1ms/batch - loss: 48.35606 - diff: 20.30mlTrain batch 3/31 - 70.8ms/batch - loss: 37.68451 - diff: 17.57mlTrain batch 4/31 - 69.1ms/batch - loss: 36.73369 - diff: 17.54mlTrain batch 5/31 - 68.6ms/batch - loss: 37.28359 - diff: 17.91mlTrain batch 6/31 - 62.7ms/batch - loss: 40.35603 - diff: 19.28mlTrain batch 7/31 - 69.0ms/batch - loss: 49.64848 - diff: 21.02mlTrain batch 8/31 - 66.5ms/batch - loss: 57.24246 - diff: 21.91mlTrain batch 9/31 - 63.5ms/batch - loss: 65.46843 - diff: 23.24mlTrain batch 10/31 - 62.6ms/batch - loss: 62.64287 - diff: 23.07mlTrain batch 11/31 - 71.7ms/batch - loss: 102.66123 - diff: 24.58mlTrain batch 12/31 - 62.8ms/batch - loss: 96.02040 - diff: 23.90mlTrain batch 13/31 - 71.2ms/batch - loss: 93.69305 - diff: 24.05mlTrain batch 14/31 - 63.7ms/batch - loss: 89.90195 - diff: 23.84mlTrain batch 15/31 - 67.8ms/batch - loss: 86.48161 - diff: 23.46mlTrain batch 16/31 - 63.8ms/batch - loss: 88.59651 - diff: 24.00mlTrain batch 17/31 - 77.4ms/batch - loss: 85.82463 - diff: 23.77mlTrain batch 18/31 - 62.7ms/batch - loss: 83.00447 - diff: 23.43mlTrain batch 19/31 - 78.0ms/batch - loss: 85.05484 - diff: 23.98mlTrain batch 20/31 - 62.6ms/batch - loss: 82.89175 - diff: 23.77mlTrain batch 21/31 - 81.8ms/batch - loss: 82.02559 - diff: 24.03mlTrain batch 22/31 - 62.7ms/batch - loss: 83.26581 - diff: 24.43mlTrain batch 23/31 - 92.7ms/batch - loss: 84.04290 - diff: 24.79mlTrain batch 24/31 - 65.8ms/batch - loss: 84.50160 - diff: 24.89mlTrain batch 25/31 - 70.1ms/batch - loss: 82.40834 - diff: 24.66mlTrain batch 26/31 - 63.7ms/batch - loss: 81.85455 - diff: 24.69mlTrain batch 27/31 - 84.8ms/batch - loss: 80.19620 - diff: 24.55mlTrain batch 28/31 - 64.7ms/batch - loss: 80.09978 - diff: 24.58mlTrain batch 29/31 - 63.6ms/batch - loss: 78.43896 - diff: 24.37mlTrain batch 30/31 - 62.6ms/batch - loss: 76.44416 - diff: 24.02mlTrain batch 31/31 - 41.6ms/batch - loss: 76.11805 - diff: 23.93mlTrain batch 31/31 - 9.7s 41.6ms/batch - loss: 76.11805 - diff: 23.93ml
Test 0.6s: val_loss: 82.67108 - diff: 25.55ml

Epoch 38: current best loss = 62.20281, at epoch 27
Train batch 1/31 - 72.6ms/batch - loss: 29.63535 - diff: 18.43mlTrain batch 2/31 - 62.6ms/batch - loss: 68.55442 - diff: 23.06mlTrain batch 3/31 - 64.2ms/batch - loss: 72.37367 - diff: 24.24mlTrain batch 4/31 - 64.6ms/batch - loss: 90.53095 - diff: 26.20mlTrain batch 5/31 - 64.4ms/batch - loss: 83.33288 - diff: 25.54mlTrain batch 6/31 - 65.6ms/batch - loss: 78.73185 - diff: 24.45mlTrain batch 7/31 - 64.7ms/batch - loss: 90.83065 - diff: 25.88mlTrain batch 8/31 - 63.1ms/batch - loss: 84.33604 - diff: 25.03mlTrain batch 9/31 - 63.9ms/batch - loss: 78.12776 - diff: 24.10mlTrain batch 10/31 - 64.2ms/batch - loss: 76.49998 - diff: 24.10mlTrain batch 11/31 - 63.9ms/batch - loss: 73.87791 - diff: 23.96mlTrain batch 12/31 - 62.6ms/batch - loss: 71.93381 - diff: 23.78mlTrain batch 13/31 - 65.2ms/batch - loss: 72.47478 - diff: 23.85mlTrain batch 14/31 - 62.6ms/batch - loss: 69.10395 - diff: 23.30mlTrain batch 15/31 - 65.1ms/batch - loss: 69.24498 - diff: 23.38mlTrain batch 16/31 - 62.6ms/batch - loss: 75.60305 - diff: 24.35mlTrain batch 17/31 - 65.2ms/batch - loss: 72.64742 - diff: 23.93mlTrain batch 18/31 - 62.6ms/batch - loss: 69.70296 - diff: 23.43mlTrain batch 19/31 - 65.0ms/batch - loss: 67.73786 - diff: 23.20mlTrain batch 20/31 - 62.6ms/batch - loss: 72.76086 - diff: 23.80mlTrain batch 21/31 - 68.0ms/batch - loss: 70.33515 - diff: 23.34mlTrain batch 22/31 - 62.6ms/batch - loss: 69.33996 - diff: 23.33mlTrain batch 23/31 - 62.7ms/batch - loss: 68.83949 - diff: 23.43mlTrain batch 24/31 - 62.8ms/batch - loss: 70.45047 - diff: 23.46mlTrain batch 25/31 - 62.7ms/batch - loss: 83.39990 - diff: 24.07mlTrain batch 26/31 - 64.5ms/batch - loss: 84.27277 - diff: 24.24mlTrain batch 27/31 - 62.7ms/batch - loss: 83.44826 - diff: 24.19mlTrain batch 28/31 - 62.6ms/batch - loss: 82.37827 - diff: 24.20mlTrain batch 29/31 - 63.8ms/batch - loss: 81.65235 - diff: 24.30mlTrain batch 30/31 - 62.6ms/batch - loss: 80.39645 - diff: 24.19mlTrain batch 31/31 - 41.4ms/batch - loss: 80.26586 - diff: 24.08mlTrain batch 31/31 - 9.6s 41.4ms/batch - loss: 80.26586 - diff: 24.08ml
Test 0.6s: val_loss: 80.65710 - diff: 25.83ml
Epoch    39: reducing learning rate of group 0 to 5.0000e-04.

Epoch 39: current best loss = 62.20281, at epoch 27
Train batch 1/31 - 88.8ms/batch - loss: 78.07546 - diff: 26.05mlTrain batch 2/31 - 63.8ms/batch - loss: 80.29420 - diff: 25.57mlTrain batch 3/31 - 69.7ms/batch - loss: 88.18164 - diff: 27.95mlTrain batch 4/31 - 63.2ms/batch - loss: 75.86316 - diff: 25.59mlTrain batch 5/31 - 85.7ms/batch - loss: 75.16558 - diff: 25.86mlTrain batch 6/31 - 63.0ms/batch - loss: 68.12956 - diff: 24.78mlTrain batch 7/31 - 67.4ms/batch - loss: 65.86250 - diff: 24.48mlTrain batch 8/31 - 62.7ms/batch - loss: 62.92277 - diff: 23.58mlTrain batch 9/31 - 89.0ms/batch - loss: 62.01930 - diff: 23.42mlTrain batch 10/31 - 66.5ms/batch - loss: 59.22187 - diff: 22.96mlTrain batch 11/31 - 63.5ms/batch - loss: 60.69119 - diff: 23.21mlTrain batch 12/31 - 62.7ms/batch - loss: 67.55455 - diff: 24.03mlTrain batch 13/31 - 78.7ms/batch - loss: 66.46069 - diff: 23.79mlTrain batch 14/31 - 62.7ms/batch - loss: 72.44823 - diff: 24.30mlTrain batch 15/31 - 83.9ms/batch - loss: 70.48340 - diff: 23.90mlTrain batch 16/31 - 62.6ms/batch - loss: 68.44264 - diff: 23.43mlTrain batch 17/31 - 81.0ms/batch - loss: 68.53090 - diff: 23.29mlTrain batch 18/31 - 62.8ms/batch - loss: 67.21816 - diff: 23.20mlTrain batch 19/31 - 73.7ms/batch - loss: 65.23760 - diff: 22.83mlTrain batch 20/31 - 62.8ms/batch - loss: 65.18104 - diff: 22.87mlTrain batch 21/31 - 78.3ms/batch - loss: 65.65243 - diff: 23.20mlTrain batch 22/31 - 63.3ms/batch - loss: 64.31443 - diff: 23.00mlTrain batch 23/31 - 68.0ms/batch - loss: 66.35473 - diff: 23.09mlTrain batch 24/31 - 77.6ms/batch - loss: 65.12094 - diff: 22.97mlTrain batch 25/31 - 84.7ms/batch - loss: 63.95624 - diff: 22.83mlTrain batch 26/31 - 63.9ms/batch - loss: 62.33715 - diff: 22.49mlTrain batch 27/31 - 69.5ms/batch - loss: 61.08877 - diff: 22.31mlTrain batch 28/31 - 62.6ms/batch - loss: 61.45234 - diff: 22.47mlTrain batch 29/31 - 70.3ms/batch - loss: 79.67632 - diff: 23.56mlTrain batch 30/31 - 62.9ms/batch - loss: 77.92619 - diff: 23.39mlTrain batch 31/31 - 41.2ms/batch - loss: 77.63536 - diff: 23.30mlTrain batch 31/31 - 9.7s 41.2ms/batch - loss: 77.63536 - diff: 23.30ml
Test 0.6s: val_loss: 65.68811 - diff: 24.44ml

Epoch 40: current best loss = 62.20281, at epoch 27
Train batch 1/31 - 73.1ms/batch - loss: 64.40530 - diff: 24.24mlTrain batch 2/31 - 62.6ms/batch - loss: 63.76355 - diff: 24.70mlTrain batch 3/31 - 62.7ms/batch - loss: 50.26806 - diff: 21.42mlTrain batch 4/31 - 63.7ms/batch - loss: 47.13900 - diff: 20.82mlTrain batch 5/31 - 64.7ms/batch - loss: 53.37249 - diff: 22.38mlTrain batch 6/31 - 64.5ms/batch - loss: 65.94705 - diff: 23.74mlTrain batch 7/31 - 64.8ms/batch - loss: 68.97287 - diff: 24.15mlTrain batch 8/31 - 63.2ms/batch - loss: 67.92836 - diff: 24.15mlTrain batch 9/31 - 74.3ms/batch - loss: 63.96377 - diff: 23.36mlTrain batch 10/31 - 63.7ms/batch - loss: 62.43861 - diff: 22.89mlTrain batch 11/31 - 63.9ms/batch - loss: 63.90094 - diff: 22.99mlTrain batch 12/31 - 62.6ms/batch - loss: 63.75968 - diff: 22.97mlTrain batch 13/31 - 68.0ms/batch - loss: 68.21722 - diff: 23.98mlTrain batch 14/31 - 62.8ms/batch - loss: 68.72084 - diff: 24.07mlTrain batch 15/31 - 68.2ms/batch - loss: 70.55568 - diff: 24.55mlTrain batch 16/31 - 62.5ms/batch - loss: 68.50178 - diff: 24.31mlTrain batch 17/31 - 67.7ms/batch - loss: 68.38419 - diff: 24.10mlTrain batch 18/31 - 62.9ms/batch - loss: 66.25439 - diff: 23.81mlTrain batch 19/31 - 64.2ms/batch - loss: 77.64085 - diff: 24.56mlTrain batch 20/31 - 62.6ms/batch - loss: 77.63935 - diff: 24.59mlTrain batch 21/31 - 64.1ms/batch - loss: 74.95491 - diff: 24.07mlTrain batch 22/31 - 62.6ms/batch - loss: 74.58507 - diff: 24.03mlTrain batch 23/31 - 63.5ms/batch - loss: 73.75657 - diff: 24.04mlTrain batch 24/31 - 62.7ms/batch - loss: 72.09516 - diff: 23.86mlTrain batch 25/31 - 63.4ms/batch - loss: 73.59652 - diff: 24.18mlTrain batch 26/31 - 62.6ms/batch - loss: 72.50975 - diff: 24.08mlTrain batch 27/31 - 68.3ms/batch - loss: 76.59406 - diff: 24.57mlTrain batch 28/31 - 63.2ms/batch - loss: 75.56852 - diff: 24.46mlTrain batch 29/31 - 65.0ms/batch - loss: 74.23099 - diff: 24.31mlTrain batch 30/31 - 62.7ms/batch - loss: 72.86844 - diff: 24.16mlTrain batch 31/31 - 45.4ms/batch - loss: 72.14045 - diff: 23.93mlTrain batch 31/31 - 9.7s 45.4ms/batch - loss: 72.14045 - diff: 23.93ml
Test 0.6s: val_loss: 70.55713 - diff: 24.97ml

Epoch 41: current best loss = 62.20281, at epoch 27
Train batch 1/31 - 64.6ms/batch - loss: 43.01174 - diff: 22.45mlTrain batch 2/31 - 63.8ms/batch - loss: 39.74002 - diff: 20.48mlTrain batch 3/31 - 66.6ms/batch - loss: 36.75559 - diff: 19.95mlTrain batch 4/31 - 63.1ms/batch - loss: 51.21587 - diff: 21.66mlTrain batch 5/31 - 65.2ms/batch - loss: 50.94902 - diff: 21.88mlTrain batch 6/31 - 62.6ms/batch - loss: 55.22516 - diff: 22.12mlTrain batch 7/31 - 65.0ms/batch - loss: 53.15992 - diff: 22.00mlTrain batch 8/31 - 63.6ms/batch - loss: 51.82030 - diff: 21.86mlTrain batch 9/31 - 64.7ms/batch - loss: 50.11500 - diff: 21.43mlTrain batch 10/31 - 62.5ms/batch - loss: 55.40597 - diff: 21.84mlTrain batch 11/31 - 67.0ms/batch - loss: 100.92910 - diff: 23.31mlTrain batch 12/31 - 65.9ms/batch - loss: 95.69719 - diff: 22.91mlTrain batch 13/31 - 62.7ms/batch - loss: 93.02593 - diff: 23.11mlTrain batch 14/31 - 65.2ms/batch - loss: 88.46256 - diff: 22.64mlTrain batch 15/31 - 62.5ms/batch - loss: 90.73787 - diff: 23.40mlTrain batch 16/31 - 62.6ms/batch - loss: 89.08038 - diff: 23.50mlTrain batch 17/31 - 62.6ms/batch - loss: 86.69545 - diff: 23.43mlTrain batch 18/31 - 62.7ms/batch - loss: 85.49075 - diff: 23.36mlTrain batch 19/31 - 62.5ms/batch - loss: 82.90394 - diff: 23.10mlTrain batch 20/31 - 62.9ms/batch - loss: 86.81762 - diff: 23.63mlTrain batch 21/31 - 62.6ms/batch - loss: 84.74136 - diff: 23.48mlTrain batch 22/31 - 62.6ms/batch - loss: 83.58979 - diff: 23.45mlTrain batch 23/31 - 63.2ms/batch - loss: 82.20726 - diff: 23.44mlTrain batch 24/31 - 62.5ms/batch - loss: 81.21028 - diff: 23.31mlTrain batch 25/31 - 62.7ms/batch - loss: 80.85085 - diff: 23.43mlTrain batch 26/31 - 62.6ms/batch - loss: 79.01795 - diff: 23.20mlTrain batch 27/31 - 62.7ms/batch - loss: 77.22399 - diff: 23.05mlTrain batch 28/31 - 62.8ms/batch - loss: 77.88152 - diff: 23.16mlTrain batch 29/31 - 62.5ms/batch - loss: 77.11124 - diff: 23.26mlTrain batch 30/31 - 62.4ms/batch - loss: 76.78815 - diff: 23.43mlTrain batch 31/31 - 41.2ms/batch - loss: 78.39791 - diff: 23.47mlTrain batch 31/31 - 9.7s 41.2ms/batch - loss: 78.39791 - diff: 23.47ml
Test 0.6s: val_loss: 76.36724 - diff: 26.03ml

Epoch 42: current best loss = 62.20281, at epoch 27
Train batch 1/31 - 72.3ms/batch - loss: 117.96983 - diff: 29.55mlTrain batch 2/31 - 62.9ms/batch - loss: 92.31062 - diff: 27.84mlTrain batch 3/31 - 64.7ms/batch - loss: 80.16706 - diff: 26.70mlTrain batch 4/31 - 66.0ms/batch - loss: 173.77034 - diff: 31.29mlTrain batch 5/31 - 63.3ms/batch - loss: 146.86261 - diff: 29.55mlTrain batch 6/31 - 65.7ms/batch - loss: 133.82393 - diff: 28.08mlTrain batch 7/31 - 64.8ms/batch - loss: 122.15466 - diff: 26.59mlTrain batch 8/31 - 64.8ms/batch - loss: 112.93166 - diff: 25.79mlTrain batch 9/31 - 63.9ms/batch - loss: 107.75071 - diff: 25.69mlTrain batch 10/31 - 64.8ms/batch - loss: 101.23841 - diff: 25.21mlTrain batch 11/31 - 70.8ms/batch - loss: 99.81362 - diff: 25.44mlTrain batch 12/31 - 63.7ms/batch - loss: 94.52141 - diff: 24.99mlTrain batch 13/31 - 69.0ms/batch - loss: 93.97495 - diff: 25.07mlTrain batch 14/31 - 62.7ms/batch - loss: 89.35086 - diff: 24.45mlTrain batch 15/31 - 64.5ms/batch - loss: 87.66304 - diff: 24.59mlTrain batch 16/31 - 63.4ms/batch - loss: 84.29933 - diff: 24.32mlTrain batch 17/31 - 62.6ms/batch - loss: 81.07747 - diff: 23.92mlTrain batch 18/31 - 64.4ms/batch - loss: 85.85872 - diff: 24.68mlTrain batch 19/31 - 62.7ms/batch - loss: 82.64408 - diff: 24.18mlTrain batch 20/31 - 62.9ms/batch - loss: 81.14067 - diff: 23.96mlTrain batch 21/31 - 63.0ms/batch - loss: 78.45821 - diff: 23.55mlTrain batch 22/31 - 62.6ms/batch - loss: 79.24805 - diff: 23.88mlTrain batch 23/31 - 62.6ms/batch - loss: 77.30617 - diff: 23.68mlTrain batch 24/31 - 62.6ms/batch - loss: 76.95620 - diff: 23.78mlTrain batch 25/31 - 62.7ms/batch - loss: 75.28627 - diff: 23.51mlTrain batch 26/31 - 63.1ms/batch - loss: 72.98239 - diff: 23.10mlTrain batch 27/31 - 62.6ms/batch - loss: 71.13457 - diff: 22.80mlTrain batch 28/31 - 63.8ms/batch - loss: 70.00934 - diff: 22.56mlTrain batch 29/31 - 62.7ms/batch - loss: 71.71460 - diff: 22.74mlTrain batch 30/31 - 62.6ms/batch - loss: 70.78330 - diff: 22.65mlTrain batch 31/31 - 43.4ms/batch - loss: 71.33879 - diff: 22.63mlTrain batch 31/31 - 9.7s 43.4ms/batch - loss: 71.33879 - diff: 22.63ml
Test 0.6s: val_loss: 73.05767 - diff: 25.20ml

Epoch 43: current best loss = 62.20281, at epoch 27
Train batch 1/31 - 65.6ms/batch - loss: 375.58368 - diff: 39.38mlTrain batch 2/31 - 63.3ms/batch - loss: 215.48494 - diff: 30.28mlTrain batch 3/31 - 75.8ms/batch - loss: 172.02432 - diff: 28.75mlTrain batch 4/31 - 63.7ms/batch - loss: 153.87476 - diff: 28.74mlTrain batch 5/31 - 67.1ms/batch - loss: 132.41710 - diff: 27.39mlTrain batch 6/31 - 62.5ms/batch - loss: 113.71230 - diff: 25.38mlTrain batch 7/31 - 63.2ms/batch - loss: 106.91871 - diff: 25.12mlTrain batch 8/31 - 62.7ms/batch - loss: 103.91415 - diff: 25.34mlTrain batch 9/31 - 69.5ms/batch - loss: 98.85815 - diff: 25.28mlTrain batch 10/31 - 63.1ms/batch - loss: 96.47670 - diff: 25.13mlTrain batch 11/31 - 63.4ms/batch - loss: 91.23228 - diff: 24.62mlTrain batch 12/31 - 62.6ms/batch - loss: 87.30662 - diff: 24.29mlTrain batch 13/31 - 63.5ms/batch - loss: 85.16098 - diff: 24.20mlTrain batch 14/31 - 64.7ms/batch - loss: 92.33482 - diff: 24.96mlTrain batch 15/31 - 64.4ms/batch - loss: 88.56474 - diff: 24.47mlTrain batch 16/31 - 62.6ms/batch - loss: 88.19347 - diff: 24.73mlTrain batch 17/31 - 62.8ms/batch - loss: 86.54408 - diff: 24.60mlTrain batch 18/31 - 62.7ms/batch - loss: 85.94965 - diff: 24.58mlTrain batch 19/31 - 62.6ms/batch - loss: 83.12998 - diff: 24.21mlTrain batch 20/31 - 62.6ms/batch - loss: 81.46868 - diff: 24.03mlTrain batch 21/31 - 62.7ms/batch - loss: 79.86922 - diff: 23.99mlTrain batch 22/31 - 62.7ms/batch - loss: 78.32989 - diff: 23.96mlTrain batch 23/31 - 62.7ms/batch - loss: 75.95489 - diff: 23.63mlTrain batch 24/31 - 62.5ms/batch - loss: 76.87028 - diff: 23.83mlTrain batch 25/31 - 62.7ms/batch - loss: 75.50782 - diff: 23.77mlTrain batch 26/31 - 62.6ms/batch - loss: 75.05429 - diff: 23.85mlTrain batch 27/31 - 62.7ms/batch - loss: 73.67352 - diff: 23.66mlTrain batch 28/31 - 62.6ms/batch - loss: 72.11423 - diff: 23.49mlTrain batch 29/31 - 62.6ms/batch - loss: 71.36423 - diff: 23.46mlTrain batch 30/31 - 62.6ms/batch - loss: 71.62435 - diff: 23.63mlTrain batch 31/31 - 41.1ms/batch - loss: 71.53384 - diff: 23.55mlTrain batch 31/31 - 9.8s 41.1ms/batch - loss: 71.53384 - diff: 23.55ml
Test 0.7s: val_loss: 76.55117 - diff: 26.44ml

Epoch 44: current best loss = 62.20281, at epoch 27
Train batch 1/31 - 85.7ms/batch - loss: 99.06309 - diff: 28.64mlTrain batch 2/31 - 62.7ms/batch - loss: 90.21580 - diff: 28.07mlTrain batch 3/31 - 95.9ms/batch - loss: 72.76222 - diff: 25.13mlTrain batch 4/31 - 64.0ms/batch - loss: 125.97454 - diff: 27.38mlTrain batch 5/31 - 81.1ms/batch - loss: 108.66885 - diff: 26.06mlTrain batch 6/31 - 66.4ms/batch - loss: 98.94845 - diff: 24.86mlTrain batch 7/31 - 91.0ms/batch - loss: 96.71227 - diff: 24.94mlTrain batch 8/31 - 62.6ms/batch - loss: 88.85540 - diff: 23.88mlTrain batch 9/31 - 77.6ms/batch - loss: 84.08070 - diff: 23.73mlTrain batch 10/31 - 63.1ms/batch - loss: 79.84406 - diff: 23.58mlTrain batch 11/31 - 65.9ms/batch - loss: 76.66464 - diff: 23.34mlTrain batch 12/31 - 64.8ms/batch - loss: 73.29937 - diff: 22.98mlTrain batch 13/31 - 81.8ms/batch - loss: 71.10407 - diff: 22.85mlTrain batch 14/31 - 66.1ms/batch - loss: 72.03301 - diff: 23.43mlTrain batch 15/31 - 63.6ms/batch - loss: 69.08967 - diff: 22.95mlTrain batch 16/31 - 63.5ms/batch - loss: 65.96473 - diff: 22.46mlTrain batch 17/31 - 83.1ms/batch - loss: 64.23451 - diff: 22.12mlTrain batch 18/31 - 62.7ms/batch - loss: 65.48910 - diff: 22.41mlTrain batch 19/31 - 76.8ms/batch - loss: 65.20680 - diff: 22.26mlTrain batch 20/31 - 64.7ms/batch - loss: 63.40380 - diff: 21.84mlTrain batch 21/31 - 76.4ms/batch - loss: 62.48663 - diff: 21.88mlTrain batch 22/31 - 66.7ms/batch - loss: 67.47681 - diff: 22.45mlTrain batch 23/31 - 69.7ms/batch - loss: 66.04088 - diff: 22.32mlTrain batch 24/31 - 66.0ms/batch - loss: 67.28300 - diff: 22.71mlTrain batch 25/31 - 78.4ms/batch - loss: 66.90831 - diff: 22.52mlTrain batch 26/31 - 64.4ms/batch - loss: 67.00881 - diff: 22.55mlTrain batch 27/31 - 65.0ms/batch - loss: 66.43766 - diff: 22.55mlTrain batch 28/31 - 64.6ms/batch - loss: 65.30437 - diff: 22.47mlTrain batch 29/31 - 63.9ms/batch - loss: 65.03391 - diff: 22.46mlTrain batch 30/31 - 63.5ms/batch - loss: 64.45831 - diff: 22.49mlTrain batch 31/31 - 41.2ms/batch - loss: 64.50118 - diff: 22.41mlTrain batch 31/31 - 9.7s 41.2ms/batch - loss: 64.50118 - diff: 22.41ml
Test 0.6s: val_loss: 77.59386 - diff: 25.66ml

Epoch 45: current best loss = 62.20281, at epoch 27
Going to unfreeze the pretrained weights
Train batch 1/31 - 116.1ms/batch - loss: 34.73644 - diff: 18.88mlTrain batch 2/31 - 100.3ms/batch - loss: 203.70242 - diff: 30.57mlTrain batch 3/31 - 97.4ms/batch - loss: 168.26562 - diff: 31.12mlTrain batch 4/31 - 93.5ms/batch - loss: 148.18549 - diff: 30.30mlTrain batch 5/31 - 98.9ms/batch - loss: 141.70741 - diff: 30.62mlTrain batch 6/31 - 94.1ms/batch - loss: 149.75230 - diff: 32.96mlTrain batch 7/31 - 97.7ms/batch - loss: 167.65565 - diff: 34.09mlTrain batch 8/31 - 94.0ms/batch - loss: 163.39401 - diff: 34.04mlTrain batch 9/31 - 98.5ms/batch - loss: 155.81203 - diff: 33.72mlTrain batch 10/31 - 93.9ms/batch - loss: 149.09388 - diff: 33.11mlTrain batch 11/31 - 96.5ms/batch - loss: 155.31774 - diff: 34.46mlTrain batch 12/31 - 95.7ms/batch - loss: 157.27062 - diff: 34.65mlTrain batch 13/31 - 94.9ms/batch - loss: 156.68237 - diff: 34.64mlTrain batch 14/31 - 96.0ms/batch - loss: 152.59344 - diff: 34.52mlTrain batch 15/31 - 97.8ms/batch - loss: 146.47580 - diff: 33.99mlTrain batch 16/31 - 95.0ms/batch - loss: 139.73784 - diff: 33.18mlTrain batch 17/31 - 93.9ms/batch - loss: 139.34101 - diff: 33.51mlTrain batch 18/31 - 94.4ms/batch - loss: 140.27764 - diff: 33.53mlTrain batch 19/31 - 94.7ms/batch - loss: 141.01007 - diff: 33.96mlTrain batch 20/31 - 96.6ms/batch - loss: 136.51830 - diff: 33.36mlTrain batch 21/31 - 106.5ms/batch - loss: 133.57102 - diff: 33.15mlTrain batch 22/31 - 95.9ms/batch - loss: 129.62997 - diff: 32.62mlTrain batch 23/31 - 106.1ms/batch - loss: 126.25947 - diff: 32.17mlTrain batch 24/31 - 96.7ms/batch - loss: 135.00861 - diff: 32.75mlTrain batch 25/31 - 98.4ms/batch - loss: 132.28976 - diff: 32.48mlTrain batch 26/31 - 94.3ms/batch - loss: 133.16010 - diff: 32.65mlTrain batch 27/31 - 94.9ms/batch - loss: 131.82053 - diff: 32.65mlTrain batch 28/31 - 94.3ms/batch - loss: 128.28152 - diff: 32.11mlTrain batch 29/31 - 95.6ms/batch - loss: 127.10412 - diff: 32.01mlTrain batch 30/31 - 93.2ms/batch - loss: 128.01967 - diff: 32.21mlTrain batch 31/31 - 66.8ms/batch - loss: 126.77788 - diff: 31.96mlTrain batch 31/31 - 9.7s 66.8ms/batch - loss: 126.77788 - diff: 31.96ml
Test 0.6s: val_loss: 131.36162 - diff: 34.78ml

Epoch 46: current best loss = 62.20281, at epoch 27
Train batch 1/31 - 98.4ms/batch - loss: 45.68967 - diff: 22.02mlTrain batch 2/31 - 94.5ms/batch - loss: 44.91163 - diff: 22.57mlTrain batch 3/31 - 93.8ms/batch - loss: 46.47034 - diff: 23.41mlTrain batch 4/31 - 94.8ms/batch - loss: 55.08996 - diff: 25.03mlTrain batch 5/31 - 94.8ms/batch - loss: 64.11982 - diff: 25.73mlTrain batch 6/31 - 94.5ms/batch - loss: 66.59333 - diff: 26.31mlTrain batch 7/31 - 94.5ms/batch - loss: 88.64345 - diff: 27.81mlTrain batch 8/31 - 95.1ms/batch - loss: 89.37484 - diff: 27.93mlTrain batch 9/31 - 94.5ms/batch - loss: 94.62875 - diff: 28.40mlTrain batch 10/31 - 95.3ms/batch - loss: 93.42039 - diff: 28.47mlTrain batch 11/31 - 93.6ms/batch - loss: 90.34355 - diff: 28.12mlTrain batch 12/31 - 95.7ms/batch - loss: 91.17453 - diff: 28.20mlTrain batch 13/31 - 93.6ms/batch - loss: 88.03005 - diff: 27.73mlTrain batch 14/31 - 94.8ms/batch - loss: 85.26134 - diff: 27.47mlTrain batch 15/31 - 95.3ms/batch - loss: 84.69915 - diff: 27.31mlTrain batch 16/31 - 100.2ms/batch - loss: 84.19491 - diff: 27.59mlTrain batch 17/31 - 93.9ms/batch - loss: 83.41956 - diff: 27.52mlTrain batch 18/31 - 96.3ms/batch - loss: 81.97327 - diff: 27.35mlTrain batch 19/31 - 95.1ms/batch - loss: 81.72695 - diff: 27.27mlTrain batch 20/31 - 94.5ms/batch - loss: 78.26279 - diff: 26.44mlTrain batch 21/31 - 94.2ms/batch - loss: 79.11329 - diff: 26.68mlTrain batch 22/31 - 95.2ms/batch - loss: 105.13249 - diff: 27.72mlTrain batch 23/31 - 94.8ms/batch - loss: 101.84630 - diff: 27.31mlTrain batch 24/31 - 94.0ms/batch - loss: 99.72369 - diff: 26.94mlTrain batch 25/31 - 94.3ms/batch - loss: 99.24832 - diff: 26.95mlTrain batch 26/31 - 94.3ms/batch - loss: 100.45790 - diff: 27.36mlTrain batch 27/31 - 95.6ms/batch - loss: 98.09764 - diff: 27.09mlTrain batch 28/31 - 94.3ms/batch - loss: 95.73024 - diff: 26.70mlTrain batch 29/31 - 93.5ms/batch - loss: 94.25457 - diff: 26.57mlTrain batch 30/31 - 95.2ms/batch - loss: 92.67381 - diff: 26.45mlTrain batch 31/31 - 69.3ms/batch - loss: 95.99404 - diff: 26.58mlTrain batch 31/31 - 9.7s 69.3ms/batch - loss: 95.99404 - diff: 26.58ml
Test 0.6s: val_loss: 67.29635 - diff: 22.92ml

Epoch 47: current best loss = 62.20281, at epoch 27
Train batch 1/31 - 99.7ms/batch - loss: 54.04617 - diff: 21.27mlTrain batch 2/31 - 95.2ms/batch - loss: 52.26828 - diff: 21.08mlTrain batch 3/31 - 103.7ms/batch - loss: 62.02273 - diff: 22.86mlTrain batch 4/31 - 94.4ms/batch - loss: 61.78704 - diff: 22.35mlTrain batch 5/31 - 102.8ms/batch - loss: 59.06251 - diff: 21.78mlTrain batch 6/31 - 94.0ms/batch - loss: 57.46098 - diff: 22.22mlTrain batch 7/31 - 110.2ms/batch - loss: 57.83955 - diff: 22.74mlTrain batch 8/31 - 94.2ms/batch - loss: 56.89627 - diff: 22.44mlTrain batch 9/31 - 108.9ms/batch - loss: 56.39272 - diff: 22.09mlTrain batch 10/31 - 94.0ms/batch - loss: 61.42794 - diff: 23.00mlTrain batch 11/31 - 108.9ms/batch - loss: 65.40279 - diff: 23.77mlTrain batch 12/31 - 94.3ms/batch - loss: 62.48015 - diff: 23.23mlTrain batch 13/31 - 106.7ms/batch - loss: 61.74313 - diff: 23.35mlTrain batch 14/31 - 93.7ms/batch - loss: 60.92126 - diff: 23.43mlTrain batch 15/31 - 98.4ms/batch - loss: 59.78828 - diff: 23.11mlTrain batch 16/31 - 95.2ms/batch - loss: 58.68947 - diff: 22.94mlTrain batch 17/31 - 101.1ms/batch - loss: 56.44380 - diff: 22.46mlTrain batch 18/31 - 99.5ms/batch - loss: 55.20820 - diff: 22.32mlTrain batch 19/31 - 97.8ms/batch - loss: 55.22797 - diff: 22.22mlTrain batch 20/31 - 94.2ms/batch - loss: 55.00803 - diff: 22.12mlTrain batch 21/31 - 105.3ms/batch - loss: 58.44806 - diff: 22.18mlTrain batch 22/31 - 94.8ms/batch - loss: 59.15080 - diff: 22.33mlTrain batch 23/31 - 109.1ms/batch - loss: 60.81515 - diff: 22.62mlTrain batch 24/31 - 93.7ms/batch - loss: 59.55318 - diff: 22.40mlTrain batch 25/31 - 105.8ms/batch - loss: 59.01689 - diff: 22.32mlTrain batch 26/31 - 95.2ms/batch - loss: 57.94630 - diff: 22.16mlTrain batch 27/31 - 114.7ms/batch - loss: 69.97172 - diff: 22.79mlTrain batch 28/31 - 94.7ms/batch - loss: 69.19444 - diff: 22.87mlTrain batch 29/31 - 95.9ms/batch - loss: 68.02070 - diff: 22.73mlTrain batch 30/31 - 94.3ms/batch - loss: 67.93774 - diff: 22.88mlTrain batch 31/31 - 68.5ms/batch - loss: 68.92625 - diff: 22.98mlTrain batch 31/31 - 9.8s 68.5ms/batch - loss: 68.92625 - diff: 22.98ml
Test 0.6s: val_loss: 76.93035 - diff: 27.81ml

Epoch 48: current best loss = 62.20281, at epoch 27
Train batch 1/31 - 97.7ms/batch - loss: 79.51281 - diff: 27.41mlTrain batch 2/31 - 93.3ms/batch - loss: 78.29913 - diff: 28.76mlTrain batch 3/31 - 95.0ms/batch - loss: 78.38903 - diff: 27.39mlTrain batch 4/31 - 93.9ms/batch - loss: 76.14443 - diff: 26.86mlTrain batch 5/31 - 95.2ms/batch - loss: 64.28574 - diff: 23.96mlTrain batch 6/31 - 94.9ms/batch - loss: 61.70613 - diff: 23.86mlTrain batch 7/31 - 95.6ms/batch - loss: 62.71935 - diff: 24.35mlTrain batch 8/31 - 93.9ms/batch - loss: 65.96070 - diff: 25.22mlTrain batch 9/31 - 95.5ms/batch - loss: 63.53067 - diff: 24.51mlTrain batch 10/31 - 94.6ms/batch - loss: 60.69042 - diff: 23.94mlTrain batch 11/31 - 94.0ms/batch - loss: 56.88015 - diff: 23.09mlTrain batch 12/31 - 95.3ms/batch - loss: 56.76293 - diff: 23.24mlTrain batch 13/31 - 95.2ms/batch - loss: 55.17270 - diff: 23.06mlTrain batch 14/31 - 94.8ms/batch - loss: 57.07151 - diff: 23.48mlTrain batch 15/31 - 94.1ms/batch - loss: 62.55374 - diff: 23.99mlTrain batch 16/31 - 96.5ms/batch - loss: 62.61709 - diff: 23.94mlTrain batch 17/31 - 95.5ms/batch - loss: 62.68831 - diff: 23.83mlTrain batch 18/31 - 99.1ms/batch - loss: 64.27567 - diff: 24.16mlTrain batch 19/31 - 94.0ms/batch - loss: 62.88157 - diff: 23.99mlTrain batch 20/31 - 95.0ms/batch - loss: 61.08934 - diff: 23.67mlTrain batch 21/31 - 93.9ms/batch - loss: 59.88648 - diff: 23.51mlTrain batch 22/31 - 94.6ms/batch - loss: 58.76758 - diff: 23.24mlTrain batch 23/31 - 94.0ms/batch - loss: 57.02746 - diff: 22.87mlTrain batch 24/31 - 94.4ms/batch - loss: 56.16698 - diff: 22.78mlTrain batch 25/31 - 94.0ms/batch - loss: 56.42859 - diff: 22.95mlTrain batch 26/31 - 95.7ms/batch - loss: 55.74388 - diff: 22.84mlTrain batch 27/31 - 95.7ms/batch - loss: 56.30053 - diff: 22.96mlTrain batch 28/31 - 93.7ms/batch - loss: 55.23027 - diff: 22.78mlTrain batch 29/31 - 94.4ms/batch - loss: 55.07371 - diff: 22.78mlTrain batch 30/31 - 93.6ms/batch - loss: 55.41286 - diff: 22.62mlTrain batch 31/31 - 66.8ms/batch - loss: 55.74998 - diff: 22.58mlTrain batch 31/31 - 9.7s 66.8ms/batch - loss: 55.74998 - diff: 22.58ml
Test 0.7s: val_loss: 52.79746 - diff: 20.10ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Systole_DenseNet121_0_Adam-0.001_MSE_DA3_best

Epoch 49: current best loss = 52.79746, at epoch 48
Train batch 1/31 - 98.8ms/batch - loss: 46.42003 - diff: 21.05mlTrain batch 2/31 - 95.3ms/batch - loss: 42.00611 - diff: 20.52mlTrain batch 3/31 - 95.6ms/batch - loss: 44.19192 - diff: 20.76mlTrain batch 4/31 - 94.2ms/batch - loss: 38.26730 - diff: 19.15mlTrain batch 5/31 - 95.8ms/batch - loss: 36.21334 - diff: 18.87mlTrain batch 6/31 - 95.3ms/batch - loss: 44.56706 - diff: 20.33mlTrain batch 7/31 - 110.6ms/batch - loss: 60.21081 - diff: 22.06mlTrain batch 8/31 - 93.7ms/batch - loss: 118.70830 - diff: 24.82mlTrain batch 9/31 - 94.7ms/batch - loss: 110.29630 - diff: 24.29mlTrain batch 10/31 - 94.2ms/batch - loss: 101.21903 - diff: 23.31mlTrain batch 11/31 - 101.2ms/batch - loss: 93.75866 - diff: 22.48mlTrain batch 12/31 - 94.4ms/batch - loss: 88.77369 - diff: 22.12mlTrain batch 13/31 - 94.7ms/batch - loss: 85.38952 - diff: 21.77mlTrain batch 14/31 - 95.7ms/batch - loss: 86.15107 - diff: 22.22mlTrain batch 15/31 - 108.1ms/batch - loss: 85.51768 - diff: 22.47mlTrain batch 16/31 - 95.2ms/batch - loss: 82.72413 - diff: 22.38mlTrain batch 17/31 - 94.7ms/batch - loss: 81.30631 - diff: 22.43mlTrain batch 18/31 - 93.9ms/batch - loss: 79.89239 - diff: 22.41mlTrain batch 19/31 - 97.6ms/batch - loss: 76.98151 - diff: 22.11mlTrain batch 20/31 - 94.0ms/batch - loss: 76.92945 - diff: 22.29mlTrain batch 21/31 - 94.8ms/batch - loss: 74.20350 - diff: 21.93mlTrain batch 22/31 - 94.7ms/batch - loss: 73.18172 - diff: 21.99mlTrain batch 23/31 - 94.8ms/batch - loss: 73.63791 - diff: 22.35mlTrain batch 24/31 - 95.4ms/batch - loss: 72.82675 - diff: 22.45mlTrain batch 25/31 - 93.5ms/batch - loss: 72.15364 - diff: 22.56mlTrain batch 26/31 - 95.1ms/batch - loss: 73.52506 - diff: 22.85mlTrain batch 27/31 - 94.8ms/batch - loss: 71.78244 - diff: 22.66mlTrain batch 28/31 - 95.1ms/batch - loss: 70.25076 - diff: 22.44mlTrain batch 29/31 - 93.7ms/batch - loss: 69.56536 - diff: 22.46mlTrain batch 30/31 - 94.1ms/batch - loss: 68.30616 - diff: 22.26mlTrain batch 31/31 - 68.4ms/batch - loss: 69.53370 - diff: 22.27mlTrain batch 31/31 - 9.8s 68.4ms/batch - loss: 69.53370 - diff: 22.27ml
Test 0.6s: val_loss: 38.41701 - diff: 18.32ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Systole_DenseNet121_0_Adam-0.001_MSE_DA3_best

Epoch 50: current best loss = 38.41701, at epoch 49
Train batch 1/31 - 97.5ms/batch - loss: 28.18114 - diff: 15.98mlTrain batch 2/31 - 94.3ms/batch - loss: 30.39953 - diff: 17.29mlTrain batch 3/31 - 96.7ms/batch - loss: 31.69101 - diff: 17.79mlTrain batch 4/31 - 94.2ms/batch - loss: 27.78852 - diff: 16.92mlTrain batch 5/31 - 94.9ms/batch - loss: 31.89481 - diff: 17.32mlTrain batch 6/31 - 94.8ms/batch - loss: 43.90117 - diff: 19.25mlTrain batch 7/31 - 95.8ms/batch - loss: 47.31238 - diff: 19.94mlTrain batch 8/31 - 93.6ms/batch - loss: 52.69236 - diff: 20.83mlTrain batch 9/31 - 97.0ms/batch - loss: 49.64035 - diff: 20.49mlTrain batch 10/31 - 93.7ms/batch - loss: 51.46862 - diff: 21.06mlTrain batch 11/31 - 94.8ms/batch - loss: 51.19104 - diff: 21.09mlTrain batch 12/31 - 94.2ms/batch - loss: 49.98306 - diff: 20.83mlTrain batch 13/31 - 96.2ms/batch - loss: 58.34960 - diff: 21.17mlTrain batch 14/31 - 94.6ms/batch - loss: 56.43303 - diff: 20.92mlTrain batch 15/31 - 97.1ms/batch - loss: 54.12023 - diff: 20.59mlTrain batch 16/31 - 94.7ms/batch - loss: 56.26126 - diff: 20.72mlTrain batch 17/31 - 96.4ms/batch - loss: 56.17048 - diff: 20.64mlTrain batch 18/31 - 93.5ms/batch - loss: 55.24021 - diff: 20.49mlTrain batch 19/31 - 116.0ms/batch - loss: 54.05413 - diff: 20.38mlTrain batch 20/31 - 93.1ms/batch - loss: 52.39463 - diff: 20.10mlTrain batch 21/31 - 94.3ms/batch - loss: 51.09055 - diff: 19.87mlTrain batch 22/31 - 93.9ms/batch - loss: 50.35748 - diff: 19.77mlTrain batch 23/31 - 93.9ms/batch - loss: 49.81479 - diff: 19.74mlTrain batch 24/31 - 95.1ms/batch - loss: 49.95897 - diff: 19.99mlTrain batch 25/31 - 95.2ms/batch - loss: 48.95449 - diff: 19.85mlTrain batch 26/31 - 94.9ms/batch - loss: 49.04346 - diff: 20.00mlTrain batch 27/31 - 94.1ms/batch - loss: 49.19829 - diff: 20.03mlTrain batch 28/31 - 95.3ms/batch - loss: 48.56156 - diff: 19.94mlTrain batch 29/31 - 93.6ms/batch - loss: 48.10312 - diff: 19.90mlTrain batch 30/31 - 94.4ms/batch - loss: 47.57337 - diff: 19.78mlTrain batch 31/31 - 67.8ms/batch - loss: 47.88161 - diff: 19.77mlTrain batch 31/31 - 9.7s 67.8ms/batch - loss: 47.88161 - diff: 19.77ml
Test 0.6s: val_loss: 31.07445 - diff: 16.08ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Systole_DenseNet121_0_Adam-0.001_MSE_DA3_best

Epoch 51: current best loss = 31.07445, at epoch 50
Train batch 1/31 - 99.2ms/batch - loss: 47.06971 - diff: 21.97mlTrain batch 2/31 - 93.7ms/batch - loss: 33.42075 - diff: 18.90mlTrain batch 3/31 - 95.5ms/batch - loss: 28.54340 - diff: 17.42mlTrain batch 4/31 - 93.8ms/batch - loss: 38.92747 - diff: 19.84mlTrain batch 5/31 - 94.3ms/batch - loss: 35.91187 - diff: 19.03mlTrain batch 6/31 - 93.9ms/batch - loss: 32.30875 - diff: 18.06mlTrain batch 7/31 - 94.1ms/batch - loss: 30.31830 - diff: 17.65mlTrain batch 8/31 - 94.2ms/batch - loss: 28.12653 - diff: 17.04mlTrain batch 9/31 - 94.0ms/batch - loss: 30.85329 - diff: 17.31mlTrain batch 10/31 - 95.2ms/batch - loss: 31.04137 - diff: 17.22mlTrain batch 11/31 - 94.4ms/batch - loss: 31.51622 - diff: 17.53mlTrain batch 12/31 - 95.3ms/batch - loss: 30.73623 - diff: 17.19mlTrain batch 13/31 - 94.2ms/batch - loss: 32.59416 - diff: 17.54mlTrain batch 14/31 - 95.0ms/batch - loss: 32.46911 - diff: 17.56mlTrain batch 15/31 - 94.5ms/batch - loss: 31.31339 - diff: 17.20mlTrain batch 16/31 - 94.9ms/batch - loss: 30.62400 - diff: 17.06mlTrain batch 17/31 - 96.7ms/batch - loss: 30.45301 - diff: 16.97mlTrain batch 18/31 - 95.6ms/batch - loss: 29.90734 - diff: 16.80mlTrain batch 19/31 - 94.1ms/batch - loss: 29.51662 - diff: 16.68mlTrain batch 20/31 - 95.1ms/batch - loss: 29.12890 - diff: 16.62mlTrain batch 21/31 - 94.6ms/batch - loss: 37.39277 - diff: 17.22mlTrain batch 22/31 - 94.1ms/batch - loss: 37.62855 - diff: 17.35mlTrain batch 23/31 - 94.0ms/batch - loss: 37.10954 - diff: 17.34mlTrain batch 24/31 - 93.8ms/batch - loss: 37.32629 - diff: 17.32mlTrain batch 25/31 - 93.8ms/batch - loss: 37.16197 - diff: 17.36mlTrain batch 26/31 - 96.6ms/batch - loss: 36.80144 - diff: 17.32mlTrain batch 27/31 - 94.0ms/batch - loss: 35.91583 - diff: 17.12mlTrain batch 28/31 - 95.6ms/batch - loss: 35.91812 - diff: 17.26mlTrain batch 29/31 - 94.0ms/batch - loss: 36.01411 - diff: 17.34mlTrain batch 30/31 - 94.2ms/batch - loss: 35.98931 - diff: 17.41mlTrain batch 31/31 - 70.0ms/batch - loss: 35.93889 - diff: 17.35mlTrain batch 31/31 - 9.8s 70.0ms/batch - loss: 35.93889 - diff: 17.35ml
Test 0.6s: val_loss: 46.59058 - diff: 19.65ml

Epoch 52: current best loss = 31.07445, at epoch 50
Train batch 1/31 - 100.3ms/batch - loss: 42.57287 - diff: 20.20mlTrain batch 2/31 - 94.5ms/batch - loss: 40.04945 - diff: 19.66mlTrain batch 3/31 - 93.8ms/batch - loss: 33.26908 - diff: 17.94mlTrain batch 4/31 - 93.7ms/batch - loss: 33.11958 - diff: 18.29mlTrain batch 5/31 - 95.4ms/batch - loss: 31.85505 - diff: 17.71mlTrain batch 6/31 - 93.9ms/batch - loss: 33.57126 - diff: 17.79mlTrain batch 7/31 - 106.7ms/batch - loss: 34.24512 - diff: 17.57mlTrain batch 8/31 - 93.9ms/batch - loss: 32.33386 - diff: 17.30mlTrain batch 9/31 - 108.8ms/batch - loss: 30.73500 - diff: 16.83mlTrain batch 10/31 - 93.8ms/batch - loss: 33.62188 - diff: 17.34mlTrain batch 11/31 - 105.9ms/batch - loss: 32.38088 - diff: 17.05mlTrain batch 12/31 - 93.5ms/batch - loss: 32.04995 - diff: 17.14mlTrain batch 13/31 - 96.4ms/batch - loss: 31.73512 - diff: 17.03mlTrain batch 14/31 - 93.8ms/batch - loss: 34.80714 - diff: 17.53mlTrain batch 15/31 - 102.1ms/batch - loss: 34.16959 - diff: 17.39mlTrain batch 16/31 - 93.9ms/batch - loss: 34.83795 - diff: 17.65mlTrain batch 17/31 - 95.5ms/batch - loss: 35.72856 - diff: 17.88mlTrain batch 18/31 - 96.2ms/batch - loss: 44.01475 - diff: 18.40mlTrain batch 19/31 - 99.2ms/batch - loss: 42.98175 - diff: 18.27mlTrain batch 20/31 - 93.6ms/batch - loss: 41.98830 - diff: 18.14mlTrain batch 21/31 - 93.6ms/batch - loss: 41.55047 - diff: 18.21mlTrain batch 22/31 - 95.9ms/batch - loss: 43.24670 - diff: 18.36mlTrain batch 23/31 - 94.1ms/batch - loss: 43.14287 - diff: 18.41mlTrain batch 24/31 - 96.6ms/batch - loss: 43.77766 - diff: 18.56mlTrain batch 25/31 - 94.4ms/batch - loss: 44.24620 - diff: 18.60mlTrain batch 26/31 - 96.0ms/batch - loss: 43.43295 - diff: 18.40mlTrain batch 27/31 - 95.1ms/batch - loss: 42.79016 - diff: 18.38mlTrain batch 28/31 - 94.4ms/batch - loss: 41.73370 - diff: 18.15mlTrain batch 29/31 - 93.5ms/batch - loss: 40.83454 - diff: 17.95mlTrain batch 30/31 - 94.0ms/batch - loss: 40.32433 - diff: 17.88mlTrain batch 31/31 - 67.9ms/batch - loss: 40.87565 - diff: 17.92mlTrain batch 31/31 - 9.8s 67.9ms/batch - loss: 40.87565 - diff: 17.92ml
Test 0.6s: val_loss: 46.71689 - diff: 20.01ml

Epoch 53: current best loss = 31.07445, at epoch 50
Train batch 1/31 - 108.4ms/batch - loss: 49.59426 - diff: 23.90mlTrain batch 2/31 - 94.1ms/batch - loss: 66.12294 - diff: 26.06mlTrain batch 3/31 - 99.0ms/batch - loss: 82.12066 - diff: 28.04mlTrain batch 4/31 - 94.2ms/batch - loss: 73.21867 - diff: 26.48mlTrain batch 5/31 - 97.1ms/batch - loss: 60.41170 - diff: 23.03mlTrain batch 6/31 - 94.4ms/batch - loss: 56.95447 - diff: 22.05mlTrain batch 7/31 - 103.5ms/batch - loss: 52.32497 - diff: 21.25mlTrain batch 8/31 - 94.9ms/batch - loss: 50.95905 - diff: 20.44mlTrain batch 9/31 - 94.8ms/batch - loss: 53.71916 - diff: 20.97mlTrain batch 10/31 - 94.0ms/batch - loss: 58.06946 - diff: 21.54mlTrain batch 11/31 - 107.3ms/batch - loss: 54.03189 - diff: 20.74mlTrain batch 12/31 - 95.9ms/batch - loss: 51.39455 - diff: 20.25mlTrain batch 13/31 - 97.5ms/batch - loss: 48.96010 - diff: 19.77mlTrain batch 14/31 - 94.6ms/batch - loss: 46.09862 - diff: 19.09mlTrain batch 15/31 - 97.0ms/batch - loss: 45.38649 - diff: 18.91mlTrain batch 16/31 - 98.6ms/batch - loss: 45.26868 - diff: 18.82mlTrain batch 17/31 - 95.5ms/batch - loss: 43.42353 - diff: 18.42mlTrain batch 18/31 - 94.9ms/batch - loss: 41.93977 - diff: 18.06mlTrain batch 19/31 - 102.0ms/batch - loss: 40.65833 - diff: 17.80mlTrain batch 20/31 - 100.5ms/batch - loss: 39.80703 - diff: 17.77mlTrain batch 21/31 - 93.9ms/batch - loss: 38.36573 - diff: 17.43mlTrain batch 22/31 - 94.6ms/batch - loss: 38.79875 - diff: 17.43mlTrain batch 23/31 - 106.5ms/batch - loss: 37.75249 - diff: 17.26mlTrain batch 24/31 - 94.1ms/batch - loss: 36.67617 - diff: 16.97mlTrain batch 25/31 - 98.5ms/batch - loss: 36.58177 - diff: 17.02mlTrain batch 26/31 - 97.0ms/batch - loss: 36.50427 - diff: 17.08mlTrain batch 27/31 - 98.5ms/batch - loss: 36.40562 - diff: 17.14mlTrain batch 28/31 - 96.9ms/batch - loss: 35.81973 - diff: 17.07mlTrain batch 29/31 - 95.0ms/batch - loss: 35.72088 - diff: 17.12mlTrain batch 30/31 - 94.3ms/batch - loss: 38.81854 - diff: 17.52mlTrain batch 31/31 - 67.3ms/batch - loss: 38.75902 - diff: 17.45mlTrain batch 31/31 - 9.8s 67.3ms/batch - loss: 38.75902 - diff: 17.45ml
Test 0.6s: val_loss: 38.13295 - diff: 18.63ml

Epoch 54: current best loss = 31.07445, at epoch 50
Train batch 1/31 - 105.9ms/batch - loss: 29.33690 - diff: 17.36mlTrain batch 2/31 - 93.4ms/batch - loss: 40.95896 - diff: 19.23mlTrain batch 3/31 - 96.0ms/batch - loss: 31.59329 - diff: 16.79mlTrain batch 4/31 - 94.1ms/batch - loss: 32.60107 - diff: 16.95mlTrain batch 5/31 - 99.4ms/batch - loss: 31.85072 - diff: 16.53mlTrain batch 6/31 - 94.7ms/batch - loss: 32.73604 - diff: 17.03mlTrain batch 7/31 - 98.2ms/batch - loss: 33.76410 - diff: 16.82mlTrain batch 8/31 - 93.6ms/batch - loss: 31.95882 - diff: 16.32mlTrain batch 9/31 - 98.6ms/batch - loss: 30.28212 - diff: 16.12mlTrain batch 10/31 - 95.2ms/batch - loss: 29.49302 - diff: 16.20mlTrain batch 11/31 - 98.8ms/batch - loss: 28.98668 - diff: 16.14mlTrain batch 12/31 - 94.6ms/batch - loss: 29.10417 - diff: 16.16mlTrain batch 13/31 - 94.4ms/batch - loss: 28.46175 - diff: 15.99mlTrain batch 14/31 - 96.1ms/batch - loss: 27.89128 - diff: 15.80mlTrain batch 15/31 - 95.6ms/batch - loss: 30.39448 - diff: 16.25mlTrain batch 16/31 - 94.7ms/batch - loss: 30.59141 - diff: 16.29mlTrain batch 17/31 - 95.8ms/batch - loss: 29.84640 - diff: 16.08mlTrain batch 18/31 - 96.5ms/batch - loss: 29.37231 - diff: 16.08mlTrain batch 19/31 - 94.2ms/batch - loss: 28.57280 - diff: 15.86mlTrain batch 20/31 - 96.8ms/batch - loss: 28.95810 - diff: 16.03mlTrain batch 21/31 - 100.7ms/batch - loss: 27.92642 - diff: 15.73mlTrain batch 22/31 - 93.8ms/batch - loss: 27.13894 - diff: 15.51mlTrain batch 23/31 - 94.0ms/batch - loss: 28.14564 - diff: 15.65mlTrain batch 24/31 - 96.7ms/batch - loss: 27.49471 - diff: 15.49mlTrain batch 25/31 - 94.1ms/batch - loss: 41.32665 - diff: 16.57mlTrain batch 26/31 - 95.6ms/batch - loss: 40.74579 - diff: 16.60mlTrain batch 27/31 - 94.6ms/batch - loss: 40.46044 - diff: 16.67mlTrain batch 28/31 - 96.0ms/batch - loss: 40.42136 - diff: 16.69mlTrain batch 29/31 - 94.7ms/batch - loss: 40.26605 - diff: 16.73mlTrain batch 30/31 - 94.5ms/batch - loss: 39.72136 - diff: 16.68mlTrain batch 31/31 - 75.2ms/batch - loss: 39.56892 - diff: 16.58mlTrain batch 31/31 - 9.8s 75.2ms/batch - loss: 39.56892 - diff: 16.58ml
Test 0.6s: val_loss: 47.32441 - diff: 19.09ml

Epoch 55: current best loss = 31.07445, at epoch 50
Train batch 1/31 - 116.1ms/batch - loss: 32.71302 - diff: 17.87mlTrain batch 2/31 - 94.7ms/batch - loss: 28.77945 - diff: 16.58mlTrain batch 3/31 - 113.4ms/batch - loss: 27.94800 - diff: 16.36mlTrain batch 4/31 - 94.1ms/batch - loss: 26.87362 - diff: 16.08mlTrain batch 5/31 - 116.6ms/batch - loss: 25.81597 - diff: 16.19mlTrain batch 6/31 - 94.6ms/batch - loss: 24.41438 - diff: 15.70mlTrain batch 7/31 - 120.7ms/batch - loss: 24.11036 - diff: 15.69mlTrain batch 8/31 - 95.1ms/batch - loss: 23.71434 - diff: 15.70mlTrain batch 9/31 - 117.8ms/batch - loss: 23.60617 - diff: 15.61mlTrain batch 10/31 - 94.5ms/batch - loss: 24.33538 - diff: 15.92mlTrain batch 11/31 - 118.3ms/batch - loss: 24.79930 - diff: 16.05mlTrain batch 12/31 - 93.9ms/batch - loss: 25.15746 - diff: 16.21mlTrain batch 13/31 - 108.3ms/batch - loss: 25.23453 - diff: 16.13mlTrain batch 14/31 - 94.0ms/batch - loss: 26.18923 - diff: 16.30mlTrain batch 15/31 - 120.0ms/batch - loss: 25.21901 - diff: 16.03mlTrain batch 16/31 - 93.7ms/batch - loss: 26.49738 - diff: 16.19mlTrain batch 17/31 - 117.3ms/batch - loss: 26.95580 - diff: 16.25mlTrain batch 18/31 - 94.1ms/batch - loss: 27.14333 - diff: 16.43mlTrain batch 19/31 - 95.8ms/batch - loss: 28.36087 - diff: 16.66mlTrain batch 20/31 - 95.4ms/batch - loss: 27.88627 - diff: 16.51mlTrain batch 21/31 - 107.7ms/batch - loss: 28.30693 - diff: 16.70mlTrain batch 22/31 - 98.7ms/batch - loss: 29.51652 - diff: 16.88mlTrain batch 23/31 - 94.5ms/batch - loss: 28.78369 - diff: 16.64mlTrain batch 24/31 - 95.1ms/batch - loss: 30.97613 - diff: 16.67mlTrain batch 25/31 - 107.8ms/batch - loss: 30.66135 - diff: 16.70mlTrain batch 26/31 - 94.6ms/batch - loss: 29.87199 - diff: 16.48mlTrain batch 27/31 - 107.5ms/batch - loss: 30.13676 - diff: 16.60mlTrain batch 28/31 - 94.0ms/batch - loss: 30.89468 - diff: 16.77mlTrain batch 29/31 - 103.4ms/batch - loss: 30.98618 - diff: 16.84mlTrain batch 30/31 - 93.5ms/batch - loss: 32.55468 - diff: 17.17mlTrain batch 31/31 - 67.4ms/batch - loss: 32.56499 - diff: 17.12mlTrain batch 31/31 - 9.8s 67.4ms/batch - loss: 32.56499 - diff: 17.12ml
Test 0.7s: val_loss: 41.60799 - diff: 19.42ml

Epoch 56: current best loss = 31.07445, at epoch 50
Train batch 1/31 - 102.1ms/batch - loss: 25.88151 - diff: 15.78mlTrain batch 2/31 - 94.2ms/batch - loss: 33.15182 - diff: 18.31mlTrain batch 3/31 - 95.5ms/batch - loss: 27.80328 - diff: 17.03mlTrain batch 4/31 - 96.8ms/batch - loss: 27.94717 - diff: 16.70mlTrain batch 5/31 - 96.3ms/batch - loss: 29.60102 - diff: 17.04mlTrain batch 6/31 - 94.5ms/batch - loss: 28.71090 - diff: 16.64mlTrain batch 7/31 - 102.7ms/batch - loss: 41.04089 - diff: 18.41mlTrain batch 8/31 - 94.5ms/batch - loss: 43.15008 - diff: 19.29mlTrain batch 9/31 - 97.3ms/batch - loss: 41.05331 - diff: 18.87mlTrain batch 10/31 - 94.3ms/batch - loss: 38.55998 - diff: 18.27mlTrain batch 11/31 - 103.1ms/batch - loss: 50.97903 - diff: 20.37mlTrain batch 12/31 - 93.9ms/batch - loss: 48.35610 - diff: 19.85mlTrain batch 13/31 - 107.4ms/batch - loss: 46.56891 - diff: 19.41mlTrain batch 14/31 - 93.9ms/batch - loss: 45.77079 - diff: 19.45mlTrain batch 15/31 - 94.9ms/batch - loss: 44.41272 - diff: 19.17mlTrain batch 16/31 - 96.1ms/batch - loss: 46.76685 - diff: 19.54mlTrain batch 17/31 - 96.9ms/batch - loss: 44.67266 - diff: 18.99mlTrain batch 18/31 - 93.8ms/batch - loss: 43.24942 - diff: 18.59mlTrain batch 19/31 - 95.1ms/batch - loss: 55.52960 - diff: 19.21mlTrain batch 20/31 - 95.6ms/batch - loss: 54.25620 - diff: 19.13mlTrain batch 21/31 - 102.6ms/batch - loss: 53.32167 - diff: 18.95mlTrain batch 22/31 - 96.9ms/batch - loss: 52.06482 - diff: 18.83mlTrain batch 23/31 - 93.5ms/batch - loss: 52.39709 - diff: 18.96mlTrain batch 24/31 - 93.4ms/batch - loss: 50.90369 - diff: 18.72mlTrain batch 25/31 - 94.6ms/batch - loss: 50.20969 - diff: 18.66mlTrain batch 26/31 - 94.2ms/batch - loss: 48.65839 - diff: 18.32mlTrain batch 27/31 - 93.8ms/batch - loss: 47.41424 - diff: 18.07mlTrain batch 28/31 - 94.7ms/batch - loss: 46.62365 - diff: 18.00mlTrain batch 29/31 - 93.2ms/batch - loss: 46.80771 - diff: 18.01mlTrain batch 30/31 - 93.4ms/batch - loss: 46.04218 - diff: 17.92mlTrain batch 31/31 - 72.6ms/batch - loss: 46.62344 - diff: 17.94mlTrain batch 31/31 - 9.8s 72.6ms/batch - loss: 46.62344 - diff: 17.94ml
Test 0.6s: val_loss: 46.31086 - diff: 17.91ml

Epoch 57: current best loss = 31.07445, at epoch 50
Train batch 1/31 - 100.1ms/batch - loss: 26.43320 - diff: 16.30mlTrain batch 2/31 - 93.7ms/batch - loss: 24.21023 - diff: 15.34mlTrain batch 3/31 - 94.7ms/batch - loss: 25.73857 - diff: 16.81mlTrain batch 4/31 - 95.2ms/batch - loss: 23.05411 - diff: 15.61mlTrain batch 5/31 - 95.0ms/batch - loss: 21.60977 - diff: 15.28mlTrain batch 6/31 - 95.1ms/batch - loss: 24.43409 - diff: 15.56mlTrain batch 7/31 - 96.2ms/batch - loss: 23.06150 - diff: 15.14mlTrain batch 8/31 - 94.6ms/batch - loss: 27.33303 - diff: 16.13mlTrain batch 9/31 - 109.0ms/batch - loss: 27.46819 - diff: 16.14mlTrain batch 10/31 - 93.7ms/batch - loss: 30.14279 - diff: 16.73mlTrain batch 11/31 - 94.1ms/batch - loss: 29.74907 - diff: 16.64mlTrain batch 12/31 - 93.8ms/batch - loss: 30.70048 - diff: 16.97mlTrain batch 13/31 - 112.1ms/batch - loss: 30.02975 - diff: 16.88mlTrain batch 14/31 - 94.1ms/batch - loss: 29.20342 - diff: 16.70mlTrain batch 15/31 - 93.9ms/batch - loss: 27.90964 - diff: 16.27mlTrain batch 16/31 - 93.7ms/batch - loss: 34.04734 - diff: 17.17mlTrain batch 17/31 - 95.0ms/batch - loss: 34.11470 - diff: 17.21mlTrain batch 18/31 - 93.9ms/batch - loss: 33.00475 - diff: 16.98mlTrain batch 19/31 - 98.4ms/batch - loss: 32.45135 - diff: 16.94mlTrain batch 20/31 - 96.5ms/batch - loss: 32.39525 - diff: 16.89mlTrain batch 21/31 - 93.8ms/batch - loss: 35.86288 - diff: 17.43mlTrain batch 22/31 - 93.3ms/batch - loss: 36.19603 - diff: 17.59mlTrain batch 23/31 - 97.7ms/batch - loss: 40.38782 - diff: 18.08mlTrain batch 24/31 - 95.0ms/batch - loss: 39.80346 - diff: 17.89mlTrain batch 25/31 - 95.5ms/batch - loss: 39.00218 - diff: 17.75mlTrain batch 26/31 - 94.1ms/batch - loss: 38.08351 - diff: 17.58mlTrain batch 27/31 - 93.6ms/batch - loss: 37.62730 - diff: 17.50mlTrain batch 28/31 - 96.2ms/batch - loss: 37.32482 - diff: 17.52mlTrain batch 29/31 - 93.1ms/batch - loss: 36.66730 - diff: 17.39mlTrain batch 30/31 - 95.0ms/batch - loss: 36.45635 - diff: 17.41mlTrain batch 31/31 - 66.8ms/batch - loss: 37.04478 - diff: 17.37mlTrain batch 31/31 - 9.8s 66.8ms/batch - loss: 37.04478 - diff: 17.37ml
Test 0.6s: val_loss: 40.09576 - diff: 17.57ml

Epoch 58: current best loss = 31.07445, at epoch 50
Train batch 1/31 - 108.3ms/batch - loss: 11.34129 - diff: 11.33mlTrain batch 2/31 - 95.5ms/batch - loss: 11.67537 - diff: 10.99mlTrain batch 3/31 - 104.4ms/batch - loss: 13.90265 - diff: 11.83mlTrain batch 4/31 - 99.1ms/batch - loss: 14.95349 - diff: 12.51mlTrain batch 5/31 - 96.4ms/batch - loss: 13.76405 - diff: 11.80mlTrain batch 6/31 - 95.2ms/batch - loss: 13.91328 - diff: 12.10mlTrain batch 7/31 - 104.0ms/batch - loss: 14.59100 - diff: 12.13mlTrain batch 8/31 - 94.2ms/batch - loss: 19.19644 - diff: 13.52mlTrain batch 9/31 - 95.2ms/batch - loss: 18.22641 - diff: 13.14mlTrain batch 10/31 - 97.2ms/batch - loss: 17.56409 - diff: 12.98mlTrain batch 11/31 - 111.0ms/batch - loss: 18.70009 - diff: 13.48mlTrain batch 12/31 - 95.9ms/batch - loss: 18.03418 - diff: 13.23mlTrain batch 13/31 - 95.5ms/batch - loss: 18.16713 - diff: 13.39mlTrain batch 14/31 - 106.2ms/batch - loss: 22.25421 - diff: 13.93mlTrain batch 15/31 - 94.3ms/batch - loss: 22.12129 - diff: 13.98mlTrain batch 16/31 - 97.1ms/batch - loss: 22.13157 - diff: 14.06mlTrain batch 17/31 - 94.3ms/batch - loss: 22.97103 - diff: 14.21mlTrain batch 18/31 - 95.3ms/batch - loss: 22.61172 - diff: 14.11mlTrain batch 19/31 - 94.1ms/batch - loss: 22.38914 - diff: 14.04mlTrain batch 20/31 - 98.8ms/batch - loss: 23.89485 - diff: 14.34mlTrain batch 21/31 - 94.1ms/batch - loss: 24.02993 - diff: 14.51mlTrain batch 22/31 - 94.6ms/batch - loss: 23.77141 - diff: 14.45mlTrain batch 23/31 - 100.6ms/batch - loss: 23.88410 - diff: 14.54mlTrain batch 24/31 - 100.6ms/batch - loss: 24.68480 - diff: 14.89mlTrain batch 25/31 - 95.1ms/batch - loss: 24.42406 - diff: 14.84mlTrain batch 26/31 - 94.0ms/batch - loss: 24.00410 - diff: 14.74mlTrain batch 27/31 - 100.3ms/batch - loss: 23.76464 - diff: 14.69mlTrain batch 28/31 - 96.1ms/batch - loss: 23.37557 - diff: 14.59mlTrain batch 29/31 - 94.3ms/batch - loss: 23.03881 - diff: 14.49mlTrain batch 30/31 - 94.9ms/batch - loss: 22.90238 - diff: 14.49mlTrain batch 31/31 - 67.6ms/batch - loss: 27.90367 - diff: 14.92mlTrain batch 31/31 - 9.8s 67.6ms/batch - loss: 27.90367 - diff: 14.92ml
Test 0.6s: val_loss: 31.19457 - diff: 15.02ml

Epoch 59: current best loss = 31.07445, at epoch 50
Train batch 1/31 - 106.0ms/batch - loss: 15.75601 - diff: 9.67mlTrain batch 2/31 - 93.3ms/batch - loss: 18.60695 - diff: 12.70mlTrain batch 3/31 - 102.4ms/batch - loss: 22.29827 - diff: 14.68mlTrain batch 4/31 - 94.3ms/batch - loss: 20.15450 - diff: 14.16mlTrain batch 5/31 - 97.0ms/batch - loss: 24.53971 - diff: 14.37mlTrain batch 6/31 - 94.8ms/batch - loss: 22.30698 - diff: 13.60mlTrain batch 7/31 - 98.0ms/batch - loss: 23.60907 - diff: 14.09mlTrain batch 8/31 - 94.6ms/batch - loss: 26.35138 - diff: 14.68mlTrain batch 9/31 - 97.9ms/batch - loss: 25.27705 - diff: 14.60mlTrain batch 10/31 - 94.0ms/batch - loss: 24.13133 - diff: 14.15mlTrain batch 11/31 - 97.9ms/batch - loss: 22.69208 - diff: 13.59mlTrain batch 12/31 - 94.1ms/batch - loss: 22.36006 - diff: 13.54mlTrain batch 13/31 - 97.6ms/batch - loss: 21.82448 - diff: 13.49mlTrain batch 14/31 - 95.2ms/batch - loss: 23.11057 - diff: 13.82mlTrain batch 15/31 - 99.1ms/batch - loss: 22.29274 - diff: 13.64mlTrain batch 16/31 - 95.1ms/batch - loss: 23.95714 - diff: 14.25mlTrain batch 17/31 - 98.5ms/batch - loss: 23.80779 - diff: 14.30mlTrain batch 18/31 - 94.2ms/batch - loss: 23.33738 - diff: 14.18mlTrain batch 19/31 - 95.3ms/batch - loss: 22.42384 - diff: 13.86mlTrain batch 20/31 - 95.0ms/batch - loss: 23.33405 - diff: 14.16mlTrain batch 21/31 - 94.7ms/batch - loss: 23.77061 - diff: 14.36mlTrain batch 22/31 - 94.7ms/batch - loss: 23.57373 - diff: 14.39mlTrain batch 23/31 - 94.7ms/batch - loss: 22.87441 - diff: 14.15mlTrain batch 24/31 - 96.3ms/batch - loss: 22.61492 - diff: 14.08mlTrain batch 25/31 - 94.1ms/batch - loss: 22.86167 - diff: 14.24mlTrain batch 26/31 - 93.9ms/batch - loss: 23.71918 - diff: 14.41mlTrain batch 27/31 - 94.5ms/batch - loss: 23.61072 - diff: 14.43mlTrain batch 28/31 - 94.0ms/batch - loss: 23.09898 - diff: 14.25mlTrain batch 29/31 - 94.9ms/batch - loss: 23.12576 - diff: 14.34mlTrain batch 30/31 - 94.6ms/batch - loss: 23.35718 - diff: 14.37mlTrain batch 31/31 - 67.7ms/batch - loss: 23.07361 - diff: 14.22mlTrain batch 31/31 - 9.8s 67.7ms/batch - loss: 23.07361 - diff: 14.22ml
Test 0.7s: val_loss: 38.17651 - diff: 17.61ml

Epoch 60: current best loss = 31.07445, at epoch 50
Train batch 1/31 - 107.1ms/batch - loss: 24.28334 - diff: 15.11mlTrain batch 2/31 - 100.2ms/batch - loss: 20.49909 - diff: 14.35mlTrain batch 3/31 - 94.5ms/batch - loss: 22.76074 - diff: 15.07mlTrain batch 4/31 - 96.2ms/batch - loss: 22.10812 - diff: 15.05mlTrain batch 5/31 - 95.4ms/batch - loss: 20.26481 - diff: 14.16mlTrain batch 6/31 - 95.7ms/batch - loss: 21.01458 - diff: 14.24mlTrain batch 7/31 - 95.4ms/batch - loss: 19.88289 - diff: 13.74mlTrain batch 8/31 - 103.3ms/batch - loss: 19.39493 - diff: 13.75mlTrain batch 9/31 - 97.1ms/batch - loss: 20.59700 - diff: 14.10mlTrain batch 10/31 - 96.9ms/batch - loss: 21.56683 - diff: 14.09mlTrain batch 11/31 - 94.4ms/batch - loss: 22.21649 - diff: 14.31mlTrain batch 12/31 - 97.8ms/batch - loss: 21.86586 - diff: 14.17mlTrain batch 13/31 - 95.1ms/batch - loss: 22.66047 - diff: 14.30mlTrain batch 14/31 - 93.5ms/batch - loss: 24.26069 - diff: 14.68mlTrain batch 15/31 - 95.2ms/batch - loss: 23.10669 - diff: 14.34mlTrain batch 16/31 - 94.8ms/batch - loss: 24.42807 - diff: 14.63mlTrain batch 17/31 - 95.9ms/batch - loss: 23.55391 - diff: 14.36mlTrain batch 18/31 - 99.2ms/batch - loss: 23.63136 - diff: 14.36mlTrain batch 19/31 - 95.6ms/batch - loss: 23.19275 - diff: 14.22mlTrain batch 20/31 - 96.6ms/batch - loss: 22.81188 - diff: 14.17mlTrain batch 21/31 - 94.8ms/batch - loss: 23.89898 - diff: 14.48mlTrain batch 22/31 - 98.2ms/batch - loss: 23.65668 - diff: 14.45mlTrain batch 23/31 - 97.7ms/batch - loss: 24.26414 - diff: 14.61mlTrain batch 24/31 - 98.1ms/batch - loss: 23.73275 - diff: 14.49mlTrain batch 25/31 - 100.7ms/batch - loss: 23.52305 - diff: 14.47mlTrain batch 26/31 - 100.7ms/batch - loss: 23.24354 - diff: 14.48mlTrain batch 27/31 - 96.8ms/batch - loss: 24.20643 - diff: 14.75mlTrain batch 28/31 - 94.8ms/batch - loss: 23.86127 - diff: 14.66mlTrain batch 29/31 - 94.4ms/batch - loss: 23.64061 - diff: 14.63mlTrain batch 30/31 - 93.7ms/batch - loss: 23.77096 - diff: 14.65mlTrain batch 31/31 - 68.0ms/batch - loss: 26.30699 - diff: 14.77mlTrain batch 31/31 - 9.8s 68.0ms/batch - loss: 26.30699 - diff: 14.77ml
Test 0.6s: val_loss: 26.04351 - diff: 15.32ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Systole_DenseNet121_0_Adam-0.001_MSE_DA3_best

Epoch 61: current best loss = 26.04351, at epoch 60
Train batch 1/31 - 99.4ms/batch - loss: 18.65590 - diff: 14.12mlTrain batch 2/31 - 94.3ms/batch - loss: 16.17032 - diff: 12.94mlTrain batch 3/31 - 96.0ms/batch - loss: 20.02921 - diff: 14.32mlTrain batch 4/31 - 106.9ms/batch - loss: 16.67855 - diff: 12.86mlTrain batch 5/31 - 96.7ms/batch - loss: 16.50185 - diff: 12.77mlTrain batch 6/31 - 94.8ms/batch - loss: 16.99861 - diff: 13.10mlTrain batch 7/31 - 95.3ms/batch - loss: 16.44881 - diff: 12.81mlTrain batch 8/31 - 97.3ms/batch - loss: 17.95316 - diff: 13.31mlTrain batch 9/31 - 95.4ms/batch - loss: 17.74485 - diff: 13.14mlTrain batch 10/31 - 96.7ms/batch - loss: 19.35989 - diff: 13.64mlTrain batch 11/31 - 94.7ms/batch - loss: 19.53039 - diff: 13.70mlTrain batch 12/31 - 97.0ms/batch - loss: 19.25615 - diff: 13.82mlTrain batch 13/31 - 95.3ms/batch - loss: 19.32457 - diff: 13.89mlTrain batch 14/31 - 95.2ms/batch - loss: 19.84111 - diff: 14.20mlTrain batch 15/31 - 96.4ms/batch - loss: 19.58887 - diff: 14.01mlTrain batch 16/31 - 94.8ms/batch - loss: 18.95738 - diff: 13.69mlTrain batch 17/31 - 96.2ms/batch - loss: 19.11024 - diff: 13.77mlTrain batch 18/31 - 94.8ms/batch - loss: 20.91749 - diff: 14.30mlTrain batch 19/31 - 95.1ms/batch - loss: 20.59004 - diff: 14.21mlTrain batch 20/31 - 96.8ms/batch - loss: 21.04559 - diff: 14.25mlTrain batch 21/31 - 94.8ms/batch - loss: 21.95743 - diff: 14.51mlTrain batch 22/31 - 96.5ms/batch - loss: 22.38869 - diff: 14.55mlTrain batch 23/31 - 95.2ms/batch - loss: 22.06759 - diff: 14.47mlTrain batch 24/31 - 94.8ms/batch - loss: 21.90833 - diff: 14.48mlTrain batch 25/31 - 120.1ms/batch - loss: 21.87958 - diff: 14.43mlTrain batch 26/31 - 98.2ms/batch - loss: 22.29993 - diff: 14.55mlTrain batch 27/31 - 95.4ms/batch - loss: 22.42226 - diff: 14.64mlTrain batch 28/31 - 95.3ms/batch - loss: 22.20837 - diff: 14.59mlTrain batch 29/31 - 94.1ms/batch - loss: 22.55410 - diff: 14.63mlTrain batch 30/31 - 93.6ms/batch - loss: 22.07248 - diff: 14.42mlTrain batch 31/31 - 69.1ms/batch - loss: 22.68089 - diff: 14.46mlTrain batch 31/31 - 9.8s 69.1ms/batch - loss: 22.68089 - diff: 14.46ml
Test 0.6s: val_loss: 25.27084 - diff: 15.30ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Systole_DenseNet121_0_Adam-0.001_MSE_DA3_best

Epoch 62: current best loss = 25.27084, at epoch 61
Train batch 1/31 - 101.1ms/batch - loss: 24.20729 - diff: 11.86mlTrain batch 2/31 - 95.9ms/batch - loss: 23.59733 - diff: 13.02mlTrain batch 3/31 - 99.0ms/batch - loss: 24.26066 - diff: 14.36mlTrain batch 4/31 - 96.6ms/batch - loss: 22.72882 - diff: 14.03mlTrain batch 5/31 - 119.4ms/batch - loss: 20.79923 - diff: 13.41mlTrain batch 6/31 - 94.0ms/batch - loss: 24.61861 - diff: 14.77mlTrain batch 7/31 - 112.9ms/batch - loss: 44.54691 - diff: 16.72mlTrain batch 8/31 - 95.1ms/batch - loss: 41.39753 - diff: 16.40mlTrain batch 9/31 - 108.1ms/batch - loss: 42.92642 - diff: 16.62mlTrain batch 10/31 - 95.2ms/batch - loss: 40.23937 - diff: 16.41mlTrain batch 11/31 - 97.5ms/batch - loss: 40.37271 - diff: 16.73mlTrain batch 12/31 - 101.8ms/batch - loss: 39.70949 - diff: 16.82mlTrain batch 13/31 - 96.2ms/batch - loss: 39.72367 - diff: 16.93mlTrain batch 14/31 - 94.3ms/batch - loss: 37.94988 - diff: 16.66mlTrain batch 15/31 - 99.5ms/batch - loss: 36.35132 - diff: 16.43mlTrain batch 16/31 - 95.2ms/batch - loss: 37.12940 - diff: 16.64mlTrain batch 17/31 - 96.8ms/batch - loss: 38.94283 - diff: 17.13mlTrain batch 18/31 - 104.8ms/batch - loss: 37.43047 - diff: 16.79mlTrain batch 19/31 - 103.9ms/batch - loss: 38.66371 - diff: 17.15mlTrain batch 20/31 - 103.1ms/batch - loss: 37.73252 - diff: 17.02mlTrain batch 21/31 - 96.4ms/batch - loss: 37.13517 - diff: 16.94mlTrain batch 22/31 - 94.3ms/batch - loss: 36.07101 - diff: 16.69mlTrain batch 23/31 - 102.5ms/batch - loss: 34.90825 - diff: 16.41mlTrain batch 24/31 - 96.4ms/batch - loss: 34.05421 - diff: 16.27mlTrain batch 25/31 - 113.7ms/batch - loss: 34.70669 - diff: 16.30mlTrain batch 26/31 - 97.6ms/batch - loss: 34.32703 - diff: 16.25mlTrain batch 27/31 - 95.9ms/batch - loss: 33.84012 - diff: 16.21mlTrain batch 28/31 - 94.0ms/batch - loss: 33.25208 - diff: 16.07mlTrain batch 29/31 - 95.8ms/batch - loss: 32.41058 - diff: 15.88mlTrain batch 30/31 - 95.0ms/batch - loss: 31.92209 - diff: 15.79mlTrain batch 31/31 - 67.5ms/batch - loss: 31.62753 - diff: 15.68mlTrain batch 31/31 - 9.8s 67.5ms/batch - loss: 31.62753 - diff: 15.68ml
Test 0.7s: val_loss: 28.80511 - diff: 15.60ml

Epoch 63: current best loss = 25.27084, at epoch 61
Train batch 1/31 - 107.2ms/batch - loss: 17.75025 - diff: 12.21mlTrain batch 2/31 - 93.3ms/batch - loss: 12.27255 - diff: 10.01mlTrain batch 3/31 - 97.4ms/batch - loss: 14.03367 - diff: 10.98mlTrain batch 4/31 - 94.9ms/batch - loss: 15.39199 - diff: 11.95mlTrain batch 5/31 - 94.1ms/batch - loss: 13.98683 - diff: 11.34mlTrain batch 6/31 - 94.8ms/batch - loss: 14.13597 - diff: 11.46mlTrain batch 7/31 - 94.2ms/batch - loss: 15.65976 - diff: 11.61mlTrain batch 8/31 - 94.2ms/batch - loss: 16.52559 - diff: 12.09mlTrain batch 9/31 - 99.5ms/batch - loss: 16.65145 - diff: 12.24mlTrain batch 10/31 - 94.1ms/batch - loss: 15.81062 - diff: 11.96mlTrain batch 11/31 - 98.4ms/batch - loss: 24.40064 - diff: 13.47mlTrain batch 12/31 - 93.8ms/batch - loss: 26.61683 - diff: 14.19mlTrain batch 13/31 - 96.7ms/batch - loss: 25.74457 - diff: 14.08mlTrain batch 14/31 - 96.2ms/batch - loss: 26.48706 - diff: 14.31mlTrain batch 15/31 - 98.3ms/batch - loss: 27.23931 - diff: 14.54mlTrain batch 16/31 - 93.4ms/batch - loss: 27.07529 - diff: 14.65mlTrain batch 17/31 - 97.7ms/batch - loss: 27.15021 - diff: 14.73mlTrain batch 18/31 - 93.9ms/batch - loss: 27.20029 - diff: 14.71mlTrain batch 19/31 - 94.4ms/batch - loss: 26.32606 - diff: 14.48mlTrain batch 20/31 - 95.0ms/batch - loss: 27.26092 - diff: 14.84mlTrain batch 21/31 - 97.4ms/batch - loss: 27.09140 - diff: 14.85mlTrain batch 22/31 - 94.8ms/batch - loss: 28.53877 - diff: 15.11mlTrain batch 23/31 - 97.4ms/batch - loss: 28.19729 - diff: 15.11mlTrain batch 24/31 - 94.7ms/batch - loss: 27.66942 - diff: 14.99mlTrain batch 25/31 - 122.9ms/batch - loss: 27.47683 - diff: 14.95mlTrain batch 26/31 - 97.2ms/batch - loss: 26.97972 - diff: 14.87mlTrain batch 27/31 - 94.0ms/batch - loss: 26.87227 - diff: 14.90mlTrain batch 28/31 - 93.8ms/batch - loss: 28.17121 - diff: 15.15mlTrain batch 29/31 - 95.0ms/batch - loss: 28.00614 - diff: 15.10mlTrain batch 30/31 - 93.8ms/batch - loss: 27.61982 - diff: 15.05mlTrain batch 31/31 - 74.0ms/batch - loss: 27.45705 - diff: 14.96mlTrain batch 31/31 - 9.8s 74.0ms/batch - loss: 27.45705 - diff: 14.96ml
Test 0.6s: val_loss: 46.19880 - diff: 16.95ml

Epoch 64: current best loss = 25.27084, at epoch 61
Train batch 1/31 - 111.2ms/batch - loss: 50.69916 - diff: 19.47mlTrain batch 2/31 - 95.9ms/batch - loss: 41.86640 - diff: 18.52mlTrain batch 3/31 - 96.8ms/batch - loss: 31.01965 - diff: 15.25mlTrain batch 4/31 - 94.1ms/batch - loss: 26.52141 - diff: 14.32mlTrain batch 5/31 - 95.2ms/batch - loss: 25.71136 - diff: 14.39mlTrain batch 6/31 - 93.7ms/batch - loss: 26.51972 - diff: 15.01mlTrain batch 7/31 - 95.8ms/batch - loss: 25.40331 - diff: 14.75mlTrain batch 8/31 - 93.9ms/batch - loss: 23.79870 - diff: 14.38mlTrain batch 9/31 - 94.2ms/batch - loss: 22.03196 - diff: 13.88mlTrain batch 10/31 - 93.9ms/batch - loss: 27.25721 - diff: 14.41mlTrain batch 11/31 - 94.5ms/batch - loss: 25.78420 - diff: 13.99mlTrain batch 12/31 - 94.2ms/batch - loss: 25.14448 - diff: 13.92mlTrain batch 13/31 - 97.0ms/batch - loss: 25.54585 - diff: 14.15mlTrain batch 14/31 - 94.6ms/batch - loss: 29.01932 - diff: 14.62mlTrain batch 15/31 - 94.3ms/batch - loss: 29.31657 - diff: 14.80mlTrain batch 16/31 - 94.1ms/batch - loss: 28.50113 - diff: 14.63mlTrain batch 17/31 - 95.1ms/batch - loss: 28.59413 - diff: 14.63mlTrain batch 18/31 - 95.0ms/batch - loss: 27.97960 - diff: 14.49mlTrain batch 19/31 - 110.4ms/batch - loss: 26.97032 - diff: 14.24mlTrain batch 20/31 - 93.8ms/batch - loss: 26.04061 - diff: 13.99mlTrain batch 21/31 - 109.9ms/batch - loss: 25.81588 - diff: 13.94mlTrain batch 22/31 - 93.8ms/batch - loss: 25.37696 - diff: 13.84mlTrain batch 23/31 - 94.7ms/batch - loss: 25.29951 - diff: 13.91mlTrain batch 24/31 - 93.6ms/batch - loss: 25.51812 - diff: 14.09mlTrain batch 25/31 - 93.6ms/batch - loss: 25.98087 - diff: 14.33mlTrain batch 26/31 - 94.4ms/batch - loss: 26.53385 - diff: 14.48mlTrain batch 27/31 - 98.1ms/batch - loss: 26.28723 - diff: 14.48mlTrain batch 28/31 - 94.5ms/batch - loss: 26.15633 - diff: 14.55mlTrain batch 29/31 - 93.5ms/batch - loss: 25.95405 - diff: 14.49mlTrain batch 30/31 - 93.8ms/batch - loss: 26.93168 - diff: 14.68mlTrain batch 31/31 - 68.2ms/batch - loss: 28.06471 - diff: 14.83mlTrain batch 31/31 - 9.8s 68.2ms/batch - loss: 28.06471 - diff: 14.83ml
Test 0.7s: val_loss: 34.22798 - diff: 16.49ml

Epoch 65: current best loss = 25.27084, at epoch 61
Train batch 1/31 - 113.6ms/batch - loss: 10.87552 - diff: 11.45mlTrain batch 2/31 - 97.5ms/batch - loss: 18.64502 - diff: 13.45mlTrain batch 3/31 - 99.1ms/batch - loss: 21.33714 - diff: 14.31mlTrain batch 4/31 - 105.9ms/batch - loss: 24.37989 - diff: 15.49mlTrain batch 5/31 - 98.9ms/batch - loss: 20.75266 - diff: 14.10mlTrain batch 6/31 - 100.1ms/batch - loss: 20.06285 - diff: 13.90mlTrain batch 7/31 - 99.0ms/batch - loss: 18.29850 - diff: 13.21mlTrain batch 8/31 - 105.5ms/batch - loss: 18.24661 - diff: 13.40mlTrain batch 9/31 - 99.4ms/batch - loss: 17.80342 - diff: 13.07mlTrain batch 10/31 - 96.9ms/batch - loss: 18.45235 - diff: 13.25mlTrain batch 11/31 - 99.4ms/batch - loss: 18.23927 - diff: 13.15mlTrain batch 12/31 - 95.3ms/batch - loss: 19.41065 - diff: 13.60mlTrain batch 13/31 - 96.7ms/batch - loss: 22.30229 - diff: 13.82mlTrain batch 14/31 - 95.9ms/batch - loss: 23.09669 - diff: 14.31mlTrain batch 15/31 - 98.6ms/batch - loss: 22.37827 - diff: 14.04mlTrain batch 16/31 - 98.5ms/batch - loss: 21.98288 - diff: 13.99mlTrain batch 17/31 - 102.8ms/batch - loss: 23.08720 - diff: 14.42mlTrain batch 18/31 - 96.6ms/batch - loss: 22.70913 - diff: 14.30mlTrain batch 19/31 - 100.2ms/batch - loss: 22.42617 - diff: 14.25mlTrain batch 20/31 - 95.5ms/batch - loss: 22.64769 - diff: 14.30mlTrain batch 21/31 - 98.0ms/batch - loss: 22.25064 - diff: 14.19mlTrain batch 22/31 - 99.6ms/batch - loss: 23.74581 - diff: 14.40mlTrain batch 23/31 - 94.7ms/batch - loss: 23.99688 - diff: 14.52mlTrain batch 24/31 - 104.0ms/batch - loss: 23.34617 - diff: 14.32mlTrain batch 25/31 - 95.6ms/batch - loss: 23.22261 - diff: 14.20mlTrain batch 26/31 - 95.2ms/batch - loss: 22.72706 - diff: 13.96mlTrain batch 27/31 - 125.0ms/batch - loss: 22.97732 - diff: 14.10mlTrain batch 28/31 - 101.2ms/batch - loss: 23.40446 - diff: 14.05mlTrain batch 29/31 - 94.2ms/batch - loss: 23.69533 - diff: 14.18mlTrain batch 30/31 - 94.2ms/batch - loss: 23.91915 - diff: 14.37mlTrain batch 31/31 - 68.3ms/batch - loss: 23.83570 - diff: 14.27mlTrain batch 31/31 - 9.8s 68.3ms/batch - loss: 23.83570 - diff: 14.27ml
Test 0.6s: val_loss: 27.89822 - diff: 15.11ml

Epoch 66: current best loss = 25.27084, at epoch 61
Train batch 1/31 - 98.2ms/batch - loss: 12.83572 - diff: 11.64mlTrain batch 2/31 - 94.9ms/batch - loss: 19.30937 - diff: 14.07mlTrain batch 3/31 - 96.3ms/batch - loss: 19.27950 - diff: 14.22mlTrain batch 4/31 - 94.1ms/batch - loss: 18.26050 - diff: 13.66mlTrain batch 5/31 - 97.2ms/batch - loss: 32.02118 - diff: 16.26mlTrain batch 6/31 - 94.0ms/batch - loss: 28.71894 - diff: 15.20mlTrain batch 7/31 - 95.3ms/batch - loss: 29.11252 - diff: 15.73mlTrain batch 8/31 - 93.8ms/batch - loss: 29.62478 - diff: 16.06mlTrain batch 9/31 - 108.9ms/batch - loss: 27.90615 - diff: 15.52mlTrain batch 10/31 - 93.9ms/batch - loss: 26.90441 - diff: 15.42mlTrain batch 11/31 - 102.7ms/batch - loss: 26.13410 - diff: 15.24mlTrain batch 12/31 - 94.1ms/batch - loss: 24.32657 - diff: 14.52mlTrain batch 13/31 - 112.2ms/batch - loss: 23.66101 - diff: 14.34mlTrain batch 14/31 - 93.8ms/batch - loss: 22.53049 - diff: 14.03mlTrain batch 15/31 - 105.3ms/batch - loss: 22.65495 - diff: 14.12mlTrain batch 16/31 - 93.9ms/batch - loss: 26.61383 - diff: 14.64mlTrain batch 17/31 - 104.4ms/batch - loss: 26.21066 - diff: 14.70mlTrain batch 18/31 - 95.1ms/batch - loss: 25.14856 - diff: 14.37mlTrain batch 19/31 - 102.8ms/batch - loss: 31.99968 - diff: 15.46mlTrain batch 20/31 - 94.1ms/batch - loss: 31.52571 - diff: 15.47mlTrain batch 21/31 - 100.6ms/batch - loss: 30.66045 - diff: 15.27mlTrain batch 22/31 - 94.2ms/batch - loss: 29.93252 - diff: 15.11mlTrain batch 23/31 - 93.9ms/batch - loss: 29.46301 - diff: 14.96mlTrain batch 24/31 - 94.7ms/batch - loss: 28.88882 - diff: 14.90mlTrain batch 25/31 - 93.9ms/batch - loss: 28.49757 - diff: 14.89mlTrain batch 26/31 - 94.6ms/batch - loss: 28.74062 - diff: 14.92mlTrain batch 27/31 - 94.4ms/batch - loss: 28.14691 - diff: 14.82mlTrain batch 28/31 - 95.1ms/batch - loss: 28.18919 - diff: 14.88mlTrain batch 29/31 - 96.7ms/batch - loss: 27.82853 - diff: 14.82mlTrain batch 30/31 - 93.5ms/batch - loss: 27.53759 - diff: 14.73mlTrain batch 31/31 - 70.8ms/batch - loss: 28.18627 - diff: 14.78mlTrain batch 31/31 - 9.7s 70.8ms/batch - loss: 28.18627 - diff: 14.78ml
Test 0.6s: val_loss: 34.70370 - diff: 16.59ml

Epoch 67: current best loss = 25.27084, at epoch 61
Train batch 1/31 - 108.9ms/batch - loss: 18.27032 - diff: 14.02mlTrain batch 2/31 - 98.2ms/batch - loss: 26.12539 - diff: 17.42mlTrain batch 3/31 - 96.2ms/batch - loss: 23.25924 - diff: 16.21mlTrain batch 4/31 - 94.1ms/batch - loss: 23.80380 - diff: 16.07mlTrain batch 5/31 - 99.4ms/batch - loss: 25.34613 - diff: 16.34mlTrain batch 6/31 - 95.3ms/batch - loss: 30.33789 - diff: 17.10mlTrain batch 7/31 - 98.5ms/batch - loss: 29.17068 - diff: 16.66mlTrain batch 8/31 - 97.4ms/batch - loss: 28.95001 - diff: 16.70mlTrain batch 9/31 - 97.4ms/batch - loss: 27.68461 - diff: 16.38mlTrain batch 10/31 - 94.6ms/batch - loss: 26.72437 - diff: 15.95mlTrain batch 11/31 - 101.0ms/batch - loss: 26.14640 - diff: 15.88mlTrain batch 12/31 - 96.7ms/batch - loss: 24.80390 - diff: 15.26mlTrain batch 13/31 - 94.7ms/batch - loss: 25.16145 - diff: 15.43mlTrain batch 14/31 - 94.5ms/batch - loss: 26.80566 - diff: 15.74mlTrain batch 15/31 - 107.2ms/batch - loss: 25.76707 - diff: 15.41mlTrain batch 16/31 - 96.4ms/batch - loss: 24.97131 - diff: 15.12mlTrain batch 17/31 - 109.8ms/batch - loss: 30.45296 - diff: 15.41mlTrain batch 18/31 - 94.4ms/batch - loss: 43.96504 - diff: 16.04mlTrain batch 19/31 - 98.1ms/batch - loss: 42.79683 - diff: 15.95mlTrain batch 20/31 - 98.9ms/batch - loss: 41.68090 - diff: 15.84mlTrain batch 21/31 - 94.5ms/batch - loss: 40.70292 - diff: 15.72mlTrain batch 22/31 - 99.1ms/batch - loss: 39.48468 - diff: 15.54mlTrain batch 23/31 - 95.6ms/batch - loss: 38.82953 - diff: 15.51mlTrain batch 24/31 - 103.2ms/batch - loss: 38.31949 - diff: 15.40mlTrain batch 25/31 - 94.3ms/batch - loss: 37.42656 - diff: 15.26mlTrain batch 26/31 - 107.3ms/batch - loss: 36.59248 - diff: 15.13mlTrain batch 27/31 - 94.1ms/batch - loss: 37.65597 - diff: 15.26mlTrain batch 28/31 - 104.9ms/batch - loss: 37.26222 - diff: 15.28mlTrain batch 29/31 - 109.2ms/batch - loss: 36.60671 - diff: 15.20mlTrain batch 30/31 - 95.0ms/batch - loss: 36.44757 - diff: 15.30mlTrain batch 31/31 - 74.4ms/batch - loss: 36.32175 - diff: 15.24mlTrain batch 31/31 - 9.7s 74.4ms/batch - loss: 36.32175 - diff: 15.24ml
Test 0.6s: val_loss: 74.67479 - diff: 27.31ml

Epoch 68: current best loss = 25.27084, at epoch 61
Train batch 1/31 - 107.5ms/batch - loss: 10.32530 - diff: 10.44mlTrain batch 2/31 - 93.4ms/batch - loss: 13.45350 - diff: 11.01mlTrain batch 3/31 - 97.3ms/batch - loss: 17.90325 - diff: 12.86mlTrain batch 4/31 - 93.8ms/batch - loss: 16.63806 - diff: 12.51mlTrain batch 5/31 - 97.2ms/batch - loss: 16.74708 - diff: 12.85mlTrain batch 6/31 - 94.5ms/batch - loss: 19.72975 - diff: 13.62mlTrain batch 7/31 - 97.4ms/batch - loss: 20.06240 - diff: 13.55mlTrain batch 8/31 - 96.2ms/batch - loss: 19.37577 - diff: 13.41mlTrain batch 9/31 - 94.0ms/batch - loss: 20.44499 - diff: 13.67mlTrain batch 10/31 - 93.8ms/batch - loss: 19.45975 - diff: 13.41mlTrain batch 11/31 - 93.9ms/batch - loss: 19.94108 - diff: 13.59mlTrain batch 12/31 - 94.4ms/batch - loss: 20.07187 - diff: 13.47mlTrain batch 13/31 - 97.9ms/batch - loss: 19.33642 - diff: 13.24mlTrain batch 14/31 - 94.2ms/batch - loss: 20.98647 - diff: 13.80mlTrain batch 15/31 - 97.9ms/batch - loss: 20.93659 - diff: 13.95mlTrain batch 16/31 - 93.6ms/batch - loss: 20.88481 - diff: 13.97mlTrain batch 17/31 - 102.7ms/batch - loss: 20.93929 - diff: 14.01mlTrain batch 18/31 - 93.6ms/batch - loss: 20.95708 - diff: 14.06mlTrain batch 19/31 - 94.2ms/batch - loss: 20.89830 - diff: 14.07mlTrain batch 20/31 - 94.7ms/batch - loss: 20.54264 - diff: 13.99mlTrain batch 21/31 - 106.3ms/batch - loss: 20.01998 - diff: 13.81mlTrain batch 22/31 - 93.9ms/batch - loss: 20.68513 - diff: 14.13mlTrain batch 23/31 - 94.4ms/batch - loss: 20.37254 - diff: 14.05mlTrain batch 24/31 - 95.1ms/batch - loss: 19.74501 - diff: 13.79mlTrain batch 25/31 - 94.0ms/batch - loss: 19.50419 - diff: 13.70mlTrain batch 26/31 - 94.6ms/batch - loss: 19.40817 - diff: 13.62mlTrain batch 27/31 - 103.6ms/batch - loss: 20.10302 - diff: 13.76mlTrain batch 28/31 - 93.6ms/batch - loss: 19.84649 - diff: 13.71mlTrain batch 29/31 - 93.3ms/batch - loss: 19.44829 - diff: 13.56mlTrain batch 30/31 - 93.9ms/batch - loss: 19.53533 - diff: 13.65mlTrain batch 31/31 - 80.5ms/batch - loss: 19.91219 - diff: 13.67mlTrain batch 31/31 - 9.7s 80.5ms/batch - loss: 19.91219 - diff: 13.67ml
Test 0.7s: val_loss: 27.48088 - diff: 15.03ml

Epoch 69: current best loss = 25.27084, at epoch 61
Train batch 1/31 - 119.6ms/batch - loss: 11.19824 - diff: 10.82mlTrain batch 2/31 - 94.2ms/batch - loss: 14.01550 - diff: 11.67mlTrain batch 3/31 - 102.8ms/batch - loss: 18.09667 - diff: 13.56mlTrain batch 4/31 - 94.7ms/batch - loss: 17.57699 - diff: 13.34mlTrain batch 5/31 - 104.7ms/batch - loss: 22.10063 - diff: 15.15mlTrain batch 6/31 - 94.6ms/batch - loss: 20.44399 - diff: 14.71mlTrain batch 7/31 - 103.3ms/batch - loss: 19.70969 - diff: 14.39mlTrain batch 8/31 - 95.6ms/batch - loss: 18.43538 - diff: 13.74mlTrain batch 9/31 - 111.6ms/batch - loss: 18.72744 - diff: 13.57mlTrain batch 10/31 - 94.7ms/batch - loss: 18.52889 - diff: 13.51mlTrain batch 11/31 - 113.3ms/batch - loss: 20.76193 - diff: 14.26mlTrain batch 12/31 - 94.0ms/batch - loss: 21.98285 - diff: 14.34mlTrain batch 13/31 - 109.8ms/batch - loss: 23.56974 - diff: 14.85mlTrain batch 14/31 - 94.1ms/batch - loss: 22.96691 - diff: 14.48mlTrain batch 15/31 - 116.7ms/batch - loss: 22.70757 - diff: 14.48mlTrain batch 16/31 - 94.0ms/batch - loss: 22.46914 - diff: 14.36mlTrain batch 17/31 - 119.6ms/batch - loss: 22.06847 - diff: 14.29mlTrain batch 18/31 - 93.9ms/batch - loss: 21.35690 - diff: 14.08mlTrain batch 19/31 - 106.8ms/batch - loss: 21.73415 - diff: 14.14mlTrain batch 20/31 - 93.9ms/batch - loss: 21.69486 - diff: 14.17mlTrain batch 21/31 - 94.3ms/batch - loss: 21.57704 - diff: 14.10mlTrain batch 22/31 - 97.4ms/batch - loss: 21.38388 - diff: 14.11mlTrain batch 23/31 - 97.2ms/batch - loss: 21.55776 - diff: 14.19mlTrain batch 24/31 - 96.0ms/batch - loss: 22.00858 - diff: 14.37mlTrain batch 25/31 - 118.2ms/batch - loss: 21.49717 - diff: 14.19mlTrain batch 26/31 - 93.9ms/batch - loss: 21.73411 - diff: 14.24mlTrain batch 27/31 - 106.1ms/batch - loss: 21.65843 - diff: 14.28mlTrain batch 28/31 - 95.6ms/batch - loss: 21.27579 - diff: 14.15mlTrain batch 29/31 - 93.5ms/batch - loss: 20.76133 - diff: 13.94mlTrain batch 30/31 - 94.4ms/batch - loss: 25.44652 - diff: 14.16mlTrain batch 31/31 - 70.4ms/batch - loss: 25.37667 - diff: 14.10mlTrain batch 31/31 - 9.7s 70.4ms/batch - loss: 25.37667 - diff: 14.10ml
Test 0.8s: val_loss: 31.41921 - diff: 16.57ml

Epoch 70: current best loss = 25.27084, at epoch 61
Train batch 1/31 - 105.9ms/batch - loss: 25.41451 - diff: 16.39mlTrain batch 2/31 - 94.4ms/batch - loss: 20.89758 - diff: 14.42mlTrain batch 3/31 - 96.7ms/batch - loss: 17.54988 - diff: 13.33mlTrain batch 4/31 - 95.3ms/batch - loss: 15.99160 - diff: 12.50mlTrain batch 5/31 - 95.0ms/batch - loss: 16.71657 - diff: 12.72mlTrain batch 6/31 - 94.2ms/batch - loss: 16.32389 - diff: 12.46mlTrain batch 7/31 - 96.5ms/batch - loss: 17.48591 - diff: 12.59mlTrain batch 8/31 - 94.2ms/batch - loss: 20.57391 - diff: 12.86mlTrain batch 9/31 - 94.2ms/batch - loss: 19.26003 - diff: 12.63mlTrain batch 10/31 - 96.7ms/batch - loss: 20.93229 - diff: 13.11mlTrain batch 11/31 - 94.2ms/batch - loss: 20.37044 - diff: 13.07mlTrain batch 12/31 - 97.2ms/batch - loss: 20.53077 - diff: 13.25mlTrain batch 13/31 - 95.8ms/batch - loss: 21.23637 - diff: 13.24mlTrain batch 14/31 - 94.0ms/batch - loss: 20.60040 - diff: 13.16mlTrain batch 15/31 - 103.1ms/batch - loss: 20.13277 - diff: 12.92mlTrain batch 16/31 - 94.4ms/batch - loss: 19.64081 - diff: 12.82mlTrain batch 17/31 - 94.6ms/batch - loss: 19.45672 - diff: 12.80mlTrain batch 18/31 - 105.7ms/batch - loss: 19.18137 - diff: 12.61mlTrain batch 19/31 - 111.3ms/batch - loss: 18.51956 - diff: 12.39mlTrain batch 20/31 - 94.3ms/batch - loss: 19.31821 - diff: 12.61mlTrain batch 21/31 - 103.4ms/batch - loss: 18.79893 - diff: 12.43mlTrain batch 22/31 - 100.2ms/batch - loss: 18.54863 - diff: 12.36mlTrain batch 23/31 - 94.8ms/batch - loss: 18.48337 - diff: 12.40mlTrain batch 24/31 - 96.0ms/batch - loss: 18.79379 - diff: 12.57mlTrain batch 25/31 - 97.8ms/batch - loss: 20.42575 - diff: 12.72mlTrain batch 26/31 - 95.8ms/batch - loss: 20.56950 - diff: 12.75mlTrain batch 27/31 - 109.1ms/batch - loss: 21.33159 - diff: 12.91mlTrain batch 28/31 - 96.0ms/batch - loss: 21.07977 - diff: 12.93mlTrain batch 29/31 - 93.4ms/batch - loss: 21.08579 - diff: 13.00mlTrain batch 30/31 - 93.4ms/batch - loss: 20.80410 - diff: 12.90mlTrain batch 31/31 - 66.7ms/batch - loss: 21.52796 - diff: 12.96mlTrain batch 31/31 - 9.8s 66.7ms/batch - loss: 21.52796 - diff: 12.96ml
Test 0.8s: val_loss: 46.24345 - diff: 17.79ml

Epoch 71: current best loss = 25.27084, at epoch 61
Train batch 1/31 - 106.7ms/batch - loss: 17.96309 - diff: 11.20mlTrain batch 2/31 - 94.3ms/batch - loss: 17.58327 - diff: 12.53mlTrain batch 3/31 - 97.5ms/batch - loss: 21.54412 - diff: 13.86mlTrain batch 4/31 - 95.3ms/batch - loss: 19.57918 - diff: 13.20mlTrain batch 5/31 - 98.0ms/batch - loss: 17.37304 - diff: 12.20mlTrain batch 6/31 - 94.8ms/batch - loss: 17.36578 - diff: 12.37mlTrain batch 7/31 - 97.0ms/batch - loss: 18.97575 - diff: 12.63mlTrain batch 8/31 - 96.3ms/batch - loss: 18.50546 - diff: 12.74mlTrain batch 9/31 - 94.0ms/batch - loss: 18.31390 - diff: 12.76mlTrain batch 10/31 - 94.8ms/batch - loss: 17.31118 - diff: 12.34mlTrain batch 11/31 - 94.1ms/batch - loss: 17.19557 - diff: 12.23mlTrain batch 12/31 - 95.7ms/batch - loss: 17.63700 - diff: 12.32mlTrain batch 13/31 - 97.6ms/batch - loss: 18.16679 - diff: 12.58mlTrain batch 14/31 - 97.0ms/batch - loss: 17.79737 - diff: 12.56mlTrain batch 15/31 - 94.1ms/batch - loss: 18.16213 - diff: 12.55mlTrain batch 16/31 - 95.2ms/batch - loss: 18.31148 - diff: 12.71mlTrain batch 17/31 - 97.9ms/batch - loss: 18.64704 - diff: 12.88mlTrain batch 18/31 - 94.9ms/batch - loss: 18.63464 - diff: 12.96mlTrain batch 19/31 - 97.1ms/batch - loss: 18.28806 - diff: 12.84mlTrain batch 20/31 - 96.2ms/batch - loss: 18.26438 - diff: 12.87mlTrain batch 21/31 - 98.2ms/batch - loss: 17.89548 - diff: 12.80mlTrain batch 22/31 - 95.4ms/batch - loss: 18.50689 - diff: 13.00mlTrain batch 23/31 - 97.8ms/batch - loss: 18.31991 - diff: 12.94mlTrain batch 24/31 - 96.9ms/batch - loss: 18.22924 - diff: 12.92mlTrain batch 25/31 - 94.6ms/batch - loss: 18.33100 - diff: 13.00mlTrain batch 26/31 - 105.6ms/batch - loss: 17.97930 - diff: 12.86mlTrain batch 27/31 - 96.9ms/batch - loss: 22.33182 - diff: 13.36mlTrain batch 28/31 - 116.2ms/batch - loss: 22.16179 - diff: 13.30mlTrain batch 29/31 - 93.8ms/batch - loss: 22.01818 - diff: 13.33mlTrain batch 30/31 - 95.2ms/batch - loss: 21.85959 - diff: 13.36mlTrain batch 31/31 - 66.6ms/batch - loss: 22.14077 - diff: 13.39mlTrain batch 31/31 - 9.8s 66.6ms/batch - loss: 22.14077 - diff: 13.39ml
Test 0.7s: val_loss: 38.57266 - diff: 18.02ml

Epoch 72: current best loss = 25.27084, at epoch 61
Train batch 1/31 - 106.5ms/batch - loss: 21.18555 - diff: 15.20mlTrain batch 2/31 - 95.5ms/batch - loss: 22.41246 - diff: 15.83mlTrain batch 3/31 - 97.7ms/batch - loss: 20.61278 - diff: 15.19mlTrain batch 4/31 - 94.4ms/batch - loss: 18.38215 - diff: 13.55mlTrain batch 5/31 - 98.4ms/batch - loss: 17.55127 - diff: 13.21mlTrain batch 6/31 - 94.2ms/batch - loss: 18.51381 - diff: 13.31mlTrain batch 7/31 - 97.7ms/batch - loss: 17.60778 - diff: 13.05mlTrain batch 8/31 - 95.5ms/batch - loss: 17.58350 - diff: 13.29mlTrain batch 9/31 - 97.8ms/batch - loss: 17.53249 - diff: 13.29mlTrain batch 10/31 - 98.2ms/batch - loss: 20.22013 - diff: 13.78mlTrain batch 11/31 - 97.1ms/batch - loss: 21.58776 - diff: 14.13mlTrain batch 12/31 - 94.1ms/batch - loss: 22.50481 - diff: 14.36mlTrain batch 13/31 - 97.2ms/batch - loss: 27.25653 - diff: 15.06mlTrain batch 14/31 - 94.4ms/batch - loss: 26.15175 - diff: 14.81mlTrain batch 15/31 - 96.6ms/batch - loss: 25.76058 - diff: 14.85mlTrain batch 16/31 - 95.8ms/batch - loss: 26.41654 - diff: 14.98mlTrain batch 17/31 - 95.2ms/batch - loss: 25.93333 - diff: 14.84mlTrain batch 18/31 - 95.7ms/batch - loss: 25.02949 - diff: 14.62mlTrain batch 19/31 - 97.5ms/batch - loss: 24.77289 - diff: 14.58mlTrain batch 20/31 - 94.5ms/batch - loss: 24.51028 - diff: 14.57mlTrain batch 21/31 - 101.8ms/batch - loss: 23.82546 - diff: 14.26mlTrain batch 22/31 - 95.0ms/batch - loss: 24.29226 - diff: 14.52mlTrain batch 23/31 - 93.9ms/batch - loss: 24.06238 - diff: 14.50mlTrain batch 24/31 - 96.0ms/batch - loss: 23.85570 - diff: 14.53mlTrain batch 25/31 - 98.4ms/batch - loss: 23.31358 - diff: 14.38mlTrain batch 26/31 - 95.4ms/batch - loss: 22.81302 - diff: 14.20mlTrain batch 27/31 - 96.7ms/batch - loss: 22.50984 - diff: 14.08mlTrain batch 28/31 - 107.2ms/batch - loss: 21.93831 - diff: 13.89mlTrain batch 29/31 - 96.7ms/batch - loss: 21.55627 - diff: 13.76mlTrain batch 30/31 - 94.5ms/batch - loss: 21.13362 - diff: 13.62mlTrain batch 31/31 - 68.8ms/batch - loss: 22.04833 - diff: 13.70mlTrain batch 31/31 - 9.7s 68.8ms/batch - loss: 22.04833 - diff: 13.70ml
Test 0.6s: val_loss: 29.75064 - diff: 15.73ml
Epoch    73: reducing learning rate of group 0 to 2.5000e-04.

Epoch 73: current best loss = 25.27084, at epoch 61
Train batch 1/31 - 106.2ms/batch - loss: 18.15692 - diff: 13.25mlTrain batch 2/31 - 93.2ms/batch - loss: 24.81401 - diff: 15.74mlTrain batch 3/31 - 95.6ms/batch - loss: 24.66312 - diff: 15.96mlTrain batch 4/31 - 93.5ms/batch - loss: 21.85536 - diff: 15.12mlTrain batch 5/31 - 120.0ms/batch - loss: 19.68756 - diff: 14.11mlTrain batch 6/31 - 105.1ms/batch - loss: 21.00174 - diff: 14.59mlTrain batch 7/31 - 95.8ms/batch - loss: 18.93078 - diff: 13.80mlTrain batch 8/31 - 94.9ms/batch - loss: 18.92667 - diff: 13.48mlTrain batch 9/31 - 118.0ms/batch - loss: 19.42404 - diff: 13.66mlTrain batch 10/31 - 100.0ms/batch - loss: 18.57183 - diff: 13.35mlTrain batch 11/31 - 108.0ms/batch - loss: 18.50747 - diff: 13.43mlTrain batch 12/31 - 95.1ms/batch - loss: 18.48091 - diff: 13.45mlTrain batch 13/31 - 106.3ms/batch - loss: 18.61374 - diff: 13.51mlTrain batch 14/31 - 94.3ms/batch - loss: 21.02408 - diff: 13.93mlTrain batch 15/31 - 97.1ms/batch - loss: 20.64795 - diff: 13.71mlTrain batch 16/31 - 94.2ms/batch - loss: 20.41277 - diff: 13.69mlTrain batch 17/31 - 113.0ms/batch - loss: 19.70178 - diff: 13.33mlTrain batch 18/31 - 94.1ms/batch - loss: 19.11105 - diff: 13.18mlTrain batch 19/31 - 99.0ms/batch - loss: 18.41645 - diff: 12.93mlTrain batch 20/31 - 96.1ms/batch - loss: 18.45802 - diff: 12.77mlTrain batch 21/31 - 96.3ms/batch - loss: 18.61120 - diff: 12.91mlTrain batch 22/31 - 94.9ms/batch - loss: 18.76176 - diff: 13.03mlTrain batch 23/31 - 105.1ms/batch - loss: 19.45977 - diff: 13.27mlTrain batch 24/31 - 93.8ms/batch - loss: 19.13576 - diff: 13.14mlTrain batch 25/31 - 98.9ms/batch - loss: 18.61965 - diff: 12.98mlTrain batch 26/31 - 94.2ms/batch - loss: 18.94977 - diff: 13.01mlTrain batch 27/31 - 120.2ms/batch - loss: 18.70209 - diff: 12.91mlTrain batch 28/31 - 94.8ms/batch - loss: 18.48623 - diff: 12.90mlTrain batch 29/31 - 96.4ms/batch - loss: 18.31066 - diff: 12.87mlTrain batch 30/31 - 93.7ms/batch - loss: 18.28682 - diff: 12.87mlTrain batch 31/31 - 68.5ms/batch - loss: 18.27466 - diff: 12.81mlTrain batch 31/31 - 9.8s 68.5ms/batch - loss: 18.27466 - diff: 12.81ml
Test 0.7s: val_loss: 23.66627 - diff: 14.08ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Systole_DenseNet121_0_Adam-0.001_MSE_DA3_best

Epoch 74: current best loss = 23.66627, at epoch 73
Train batch 1/31 - 113.2ms/batch - loss: 6.96938 - diff: 9.06mlTrain batch 2/31 - 101.8ms/batch - loss: 12.85704 - diff: 11.79mlTrain batch 3/31 - 95.2ms/batch - loss: 13.51004 - diff: 11.98mlTrain batch 4/31 - 93.4ms/batch - loss: 16.04213 - diff: 12.56mlTrain batch 5/31 - 94.7ms/batch - loss: 15.68407 - diff: 12.13mlTrain batch 6/31 - 93.5ms/batch - loss: 17.31593 - diff: 12.59mlTrain batch 7/31 - 94.9ms/batch - loss: 16.91067 - diff: 12.33mlTrain batch 8/31 - 93.9ms/batch - loss: 18.17757 - diff: 13.02mlTrain batch 9/31 - 93.6ms/batch - loss: 16.92961 - diff: 12.62mlTrain batch 10/31 - 94.4ms/batch - loss: 17.68578 - diff: 12.86mlTrain batch 11/31 - 93.6ms/batch - loss: 17.20462 - diff: 12.68mlTrain batch 12/31 - 94.3ms/batch - loss: 17.30634 - diff: 12.83mlTrain batch 13/31 - 93.5ms/batch - loss: 16.99185 - diff: 12.70mlTrain batch 14/31 - 95.1ms/batch - loss: 16.36368 - diff: 12.41mlTrain batch 15/31 - 93.6ms/batch - loss: 16.11640 - diff: 12.35mlTrain batch 16/31 - 94.9ms/batch - loss: 16.39404 - diff: 12.49mlTrain batch 17/31 - 93.6ms/batch - loss: 16.54073 - diff: 12.53mlTrain batch 18/31 - 96.3ms/batch - loss: 16.71449 - diff: 12.69mlTrain batch 19/31 - 93.8ms/batch - loss: 16.44032 - diff: 12.57mlTrain batch 20/31 - 93.8ms/batch - loss: 16.31382 - diff: 12.55mlTrain batch 21/31 - 93.5ms/batch - loss: 17.67598 - diff: 12.76mlTrain batch 22/31 - 93.7ms/batch - loss: 17.39869 - diff: 12.74mlTrain batch 23/31 - 93.6ms/batch - loss: 17.01400 - diff: 12.57mlTrain batch 24/31 - 94.6ms/batch - loss: 16.78335 - diff: 12.50mlTrain batch 25/31 - 94.6ms/batch - loss: 17.60020 - diff: 12.66mlTrain batch 26/31 - 94.6ms/batch - loss: 17.61942 - diff: 12.75mlTrain batch 27/31 - 93.8ms/batch - loss: 17.36450 - diff: 12.64mlTrain batch 28/31 - 93.6ms/batch - loss: 17.51504 - diff: 12.61mlTrain batch 29/31 - 93.3ms/batch - loss: 17.03503 - diff: 12.41mlTrain batch 30/31 - 93.3ms/batch - loss: 16.64984 - diff: 12.22mlTrain batch 31/31 - 75.6ms/batch - loss: 16.96110 - diff: 12.26mlTrain batch 31/31 - 9.8s 75.6ms/batch - loss: 16.96110 - diff: 12.26ml
Test 0.6s: val_loss: 23.01901 - diff: 14.20ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Systole_DenseNet121_0_Adam-0.001_MSE_DA3_best

Epoch 75: current best loss = 23.01901, at epoch 74
Train batch 1/31 - 98.2ms/batch - loss: 18.49401 - diff: 13.15mlTrain batch 2/31 - 96.0ms/batch - loss: 14.63128 - diff: 12.47mlTrain batch 3/31 - 99.0ms/batch - loss: 15.90850 - diff: 12.91mlTrain batch 4/31 - 93.9ms/batch - loss: 16.08996 - diff: 13.08mlTrain batch 5/31 - 94.3ms/batch - loss: 14.28686 - diff: 12.18mlTrain batch 6/31 - 94.0ms/batch - loss: 13.80656 - diff: 11.84mlTrain batch 7/31 - 107.3ms/batch - loss: 13.44037 - diff: 11.62mlTrain batch 8/31 - 93.7ms/batch - loss: 12.37243 - diff: 11.06mlTrain batch 9/31 - 94.2ms/batch - loss: 12.66669 - diff: 10.84mlTrain batch 10/31 - 94.6ms/batch - loss: 11.98329 - diff: 10.58mlTrain batch 11/31 - 93.9ms/batch - loss: 12.02715 - diff: 10.54mlTrain batch 12/31 - 94.1ms/batch - loss: 11.95723 - diff: 10.57mlTrain batch 13/31 - 94.5ms/batch - loss: 11.64503 - diff: 10.42mlTrain batch 14/31 - 94.0ms/batch - loss: 11.36985 - diff: 10.40mlTrain batch 15/31 - 93.8ms/batch - loss: 11.21482 - diff: 10.40mlTrain batch 16/31 - 94.0ms/batch - loss: 11.47401 - diff: 10.46mlTrain batch 17/31 - 93.7ms/batch - loss: 12.06237 - diff: 10.82mlTrain batch 18/31 - 94.2ms/batch - loss: 12.06290 - diff: 10.88mlTrain batch 19/31 - 94.9ms/batch - loss: 12.00779 - diff: 10.90mlTrain batch 20/31 - 94.4ms/batch - loss: 12.69723 - diff: 11.14mlTrain batch 21/31 - 102.2ms/batch - loss: 12.50667 - diff: 11.02mlTrain batch 22/31 - 94.7ms/batch - loss: 12.38349 - diff: 11.00mlTrain batch 23/31 - 94.0ms/batch - loss: 13.14757 - diff: 11.21mlTrain batch 24/31 - 94.7ms/batch - loss: 12.75140 - diff: 11.03mlTrain batch 25/31 - 94.1ms/batch - loss: 12.57656 - diff: 10.95mlTrain batch 26/31 - 94.2ms/batch - loss: 12.95868 - diff: 11.13mlTrain batch 27/31 - 93.9ms/batch - loss: 13.00844 - diff: 11.13mlTrain batch 28/31 - 95.6ms/batch - loss: 12.80980 - diff: 11.05mlTrain batch 29/31 - 94.0ms/batch - loss: 12.89322 - diff: 11.07mlTrain batch 30/31 - 96.2ms/batch - loss: 12.91163 - diff: 11.06mlTrain batch 31/31 - 68.1ms/batch - loss: 13.24988 - diff: 11.10mlTrain batch 31/31 - 9.8s 68.1ms/batch - loss: 13.24988 - diff: 11.10ml
Test 0.7s: val_loss: 21.92357 - diff: 13.34ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Systole_DenseNet121_0_Adam-0.001_MSE_DA3_best

Epoch 76: current best loss = 21.92357, at epoch 75
Train batch 1/31 - 106.7ms/batch - loss: 15.68795 - diff: 13.07mlTrain batch 2/31 - 93.9ms/batch - loss: 11.70835 - diff: 10.88mlTrain batch 3/31 - 117.1ms/batch - loss: 9.49506 - diff: 9.84mlTrain batch 4/31 - 100.7ms/batch - loss: 8.89056 - diff: 9.52mlTrain batch 5/31 - 98.1ms/batch - loss: 11.23934 - diff: 10.54mlTrain batch 6/31 - 93.5ms/batch - loss: 12.81918 - diff: 11.10mlTrain batch 7/31 - 99.8ms/batch - loss: 12.55047 - diff: 10.96mlTrain batch 8/31 - 97.7ms/batch - loss: 14.03580 - diff: 11.64mlTrain batch 9/31 - 101.3ms/batch - loss: 13.90604 - diff: 11.56mlTrain batch 10/31 - 96.5ms/batch - loss: 13.20840 - diff: 11.24mlTrain batch 11/31 - 100.6ms/batch - loss: 13.23627 - diff: 11.28mlTrain batch 12/31 - 103.6ms/batch - loss: 12.76872 - diff: 11.13mlTrain batch 13/31 - 95.6ms/batch - loss: 13.64427 - diff: 11.15mlTrain batch 14/31 - 110.1ms/batch - loss: 13.39631 - diff: 11.08mlTrain batch 15/31 - 99.4ms/batch - loss: 13.15398 - diff: 11.00mlTrain batch 16/31 - 100.1ms/batch - loss: 12.79060 - diff: 10.82mlTrain batch 17/31 - 96.7ms/batch - loss: 12.85662 - diff: 10.80mlTrain batch 18/31 - 109.6ms/batch - loss: 12.50219 - diff: 10.71mlTrain batch 19/31 - 95.3ms/batch - loss: 12.69001 - diff: 10.74mlTrain batch 20/31 - 95.2ms/batch - loss: 12.44349 - diff: 10.59mlTrain batch 21/31 - 96.4ms/batch - loss: 12.06441 - diff: 10.37mlTrain batch 22/31 - 96.2ms/batch - loss: 12.17865 - diff: 10.48mlTrain batch 23/31 - 95.0ms/batch - loss: 12.09629 - diff: 10.48mlTrain batch 24/31 - 100.0ms/batch - loss: 13.10662 - diff: 10.84mlTrain batch 25/31 - 94.9ms/batch - loss: 12.98095 - diff: 10.79mlTrain batch 26/31 - 99.5ms/batch - loss: 12.73609 - diff: 10.68mlTrain batch 27/31 - 94.6ms/batch - loss: 12.61414 - diff: 10.65mlTrain batch 28/31 - 94.4ms/batch - loss: 12.67620 - diff: 10.70mlTrain batch 29/31 - 94.6ms/batch - loss: 12.50801 - diff: 10.66mlTrain batch 30/31 - 94.9ms/batch - loss: 12.39718 - diff: 10.60mlTrain batch 31/31 - 68.6ms/batch - loss: 12.66443 - diff: 10.62mlTrain batch 31/31 - 9.8s 68.6ms/batch - loss: 12.66443 - diff: 10.62ml
Test 0.7s: val_loss: 20.47853 - diff: 13.43ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Systole_DenseNet121_0_Adam-0.001_MSE_DA3_best

Epoch 77: current best loss = 20.47853, at epoch 76
Train batch 1/31 - 99.0ms/batch - loss: 12.16906 - diff: 11.74mlTrain batch 2/31 - 94.5ms/batch - loss: 23.81543 - diff: 14.72mlTrain batch 3/31 - 106.2ms/batch - loss: 17.92668 - diff: 12.24mlTrain batch 4/31 - 111.1ms/batch - loss: 14.85717 - diff: 11.04mlTrain batch 5/31 - 96.2ms/batch - loss: 14.08466 - diff: 10.83mlTrain batch 6/31 - 94.7ms/batch - loss: 13.17679 - diff: 10.79mlTrain batch 7/31 - 95.8ms/batch - loss: 13.17905 - diff: 10.99mlTrain batch 8/31 - 96.5ms/batch - loss: 13.21263 - diff: 10.86mlTrain batch 9/31 - 95.2ms/batch - loss: 13.20802 - diff: 10.78mlTrain batch 10/31 - 98.2ms/batch - loss: 13.03889 - diff: 10.78mlTrain batch 11/31 - 95.3ms/batch - loss: 15.92713 - diff: 11.89mlTrain batch 12/31 - 94.8ms/batch - loss: 17.10271 - diff: 12.25mlTrain batch 13/31 - 95.4ms/batch - loss: 16.80025 - diff: 12.18mlTrain batch 14/31 - 96.5ms/batch - loss: 16.32995 - diff: 12.06mlTrain batch 15/31 - 94.8ms/batch - loss: 15.76132 - diff: 11.93mlTrain batch 16/31 - 96.5ms/batch - loss: 15.22587 - diff: 11.73mlTrain batch 17/31 - 94.3ms/batch - loss: 15.24345 - diff: 11.74mlTrain batch 18/31 - 97.8ms/batch - loss: 14.82082 - diff: 11.57mlTrain batch 19/31 - 95.0ms/batch - loss: 14.68153 - diff: 11.39mlTrain batch 20/31 - 100.5ms/batch - loss: 14.38705 - diff: 11.24mlTrain batch 21/31 - 94.8ms/batch - loss: 14.14183 - diff: 11.21mlTrain batch 22/31 - 97.6ms/batch - loss: 14.07468 - diff: 11.25mlTrain batch 23/31 - 95.0ms/batch - loss: 14.40300 - diff: 11.48mlTrain batch 24/31 - 95.4ms/batch - loss: 14.21882 - diff: 11.39mlTrain batch 25/31 - 94.9ms/batch - loss: 14.23667 - diff: 11.37mlTrain batch 26/31 - 99.4ms/batch - loss: 14.20968 - diff: 11.36mlTrain batch 27/31 - 94.8ms/batch - loss: 13.92905 - diff: 11.24mlTrain batch 28/31 - 95.9ms/batch - loss: 13.66979 - diff: 11.14mlTrain batch 29/31 - 94.6ms/batch - loss: 13.31795 - diff: 10.95mlTrain batch 30/31 - 93.9ms/batch - loss: 13.69484 - diff: 11.13mlTrain batch 31/31 - 69.4ms/batch - loss: 13.62005 - diff: 11.07mlTrain batch 31/31 - 9.8s 69.4ms/batch - loss: 13.62005 - diff: 11.07ml
Test 0.7s: val_loss: 21.91563 - diff: 13.23ml

Epoch 78: current best loss = 20.47853, at epoch 76
Train batch 1/31 - 98.1ms/batch - loss: 4.00821 - diff: 6.32mlTrain batch 2/31 - 93.8ms/batch - loss: 6.86915 - diff: 8.46mlTrain batch 3/31 - 95.8ms/batch - loss: 7.33858 - diff: 8.75mlTrain batch 4/31 - 94.9ms/batch - loss: 6.85603 - diff: 8.41mlTrain batch 5/31 - 95.9ms/batch - loss: 8.31171 - diff: 9.05mlTrain batch 6/31 - 93.3ms/batch - loss: 12.48175 - diff: 10.68mlTrain batch 7/31 - 93.3ms/batch - loss: 11.52533 - diff: 10.26mlTrain batch 8/31 - 94.5ms/batch - loss: 10.84527 - diff: 10.00mlTrain batch 9/31 - 93.6ms/batch - loss: 12.13471 - diff: 10.13mlTrain batch 10/31 - 93.9ms/batch - loss: 11.32275 - diff: 9.74mlTrain batch 11/31 - 94.4ms/batch - loss: 11.37808 - diff: 9.92mlTrain batch 12/31 - 94.5ms/batch - loss: 10.72633 - diff: 9.59mlTrain batch 13/31 - 93.8ms/batch - loss: 10.59201 - diff: 9.58mlTrain batch 14/31 - 94.8ms/batch - loss: 10.60066 - diff: 9.70mlTrain batch 15/31 - 93.8ms/batch - loss: 10.33715 - diff: 9.54mlTrain batch 16/31 - 94.9ms/batch - loss: 10.12123 - diff: 9.46mlTrain batch 17/31 - 93.8ms/batch - loss: 13.97145 - diff: 10.06mlTrain batch 18/31 - 94.7ms/batch - loss: 13.67035 - diff: 10.05mlTrain batch 19/31 - 93.8ms/batch - loss: 13.31576 - diff: 10.00mlTrain batch 20/31 - 94.5ms/batch - loss: 13.31054 - diff: 10.09mlTrain batch 21/31 - 95.3ms/batch - loss: 13.63635 - diff: 10.25mlTrain batch 22/31 - 94.0ms/batch - loss: 13.65618 - diff: 10.34mlTrain batch 23/31 - 94.8ms/batch - loss: 13.40665 - diff: 10.30mlTrain batch 24/31 - 94.5ms/batch - loss: 13.39530 - diff: 10.35mlTrain batch 25/31 - 95.0ms/batch - loss: 13.36277 - diff: 10.33mlTrain batch 26/31 - 94.1ms/batch - loss: 13.26516 - diff: 10.35mlTrain batch 27/31 - 95.0ms/batch - loss: 13.28647 - diff: 10.42mlTrain batch 28/31 - 93.7ms/batch - loss: 13.10420 - diff: 10.40mlTrain batch 29/31 - 93.8ms/batch - loss: 13.20367 - diff: 10.49mlTrain batch 30/31 - 93.6ms/batch - loss: 13.34111 - diff: 10.51mlTrain batch 31/31 - 72.1ms/batch - loss: 13.50366 - diff: 10.49mlTrain batch 31/31 - 9.8s 72.1ms/batch - loss: 13.50366 - diff: 10.49ml
Test 0.6s: val_loss: 27.87109 - diff: 14.04ml

Epoch 79: current best loss = 20.47853, at epoch 76
Train batch 1/31 - 101.3ms/batch - loss: 11.97347 - diff: 11.10mlTrain batch 2/31 - 94.2ms/batch - loss: 12.18447 - diff: 11.04mlTrain batch 3/31 - 94.7ms/batch - loss: 12.29855 - diff: 11.83mlTrain batch 4/31 - 93.7ms/batch - loss: 11.81037 - diff: 11.36mlTrain batch 5/31 - 131.5ms/batch - loss: 10.19978 - diff: 10.25mlTrain batch 6/31 - 95.3ms/batch - loss: 9.51196 - diff: 9.67mlTrain batch 7/31 - 106.1ms/batch - loss: 9.35298 - diff: 9.50mlTrain batch 8/31 - 93.7ms/batch - loss: 8.93179 - diff: 9.31mlTrain batch 9/31 - 96.5ms/batch - loss: 10.28432 - diff: 9.56mlTrain batch 10/31 - 94.3ms/batch - loss: 10.25663 - diff: 9.51mlTrain batch 11/31 - 96.0ms/batch - loss: 11.63696 - diff: 10.01mlTrain batch 12/31 - 94.4ms/batch - loss: 11.37922 - diff: 9.86mlTrain batch 13/31 - 99.4ms/batch - loss: 11.00866 - diff: 9.79mlTrain batch 14/31 - 94.6ms/batch - loss: 10.61231 - diff: 9.59mlTrain batch 15/31 - 112.1ms/batch - loss: 10.39267 - diff: 9.54mlTrain batch 16/31 - 97.1ms/batch - loss: 10.25021 - diff: 9.49mlTrain batch 17/31 - 100.6ms/batch - loss: 10.08154 - diff: 9.51mlTrain batch 18/31 - 96.5ms/batch - loss: 11.21800 - diff: 9.83mlTrain batch 19/31 - 100.8ms/batch - loss: 10.99352 - diff: 9.73mlTrain batch 20/31 - 97.4ms/batch - loss: 11.90275 - diff: 10.11mlTrain batch 21/31 - 112.9ms/batch - loss: 13.07380 - diff: 10.59mlTrain batch 22/31 - 95.9ms/batch - loss: 12.81335 - diff: 10.51mlTrain batch 23/31 - 113.0ms/batch - loss: 12.78838 - diff: 10.56mlTrain batch 24/31 - 99.5ms/batch - loss: 12.54680 - diff: 10.49mlTrain batch 25/31 - 107.5ms/batch - loss: 12.39854 - diff: 10.48mlTrain batch 26/31 - 99.3ms/batch - loss: 12.31987 - diff: 10.44mlTrain batch 27/31 - 116.6ms/batch - loss: 12.24649 - diff: 10.44mlTrain batch 28/31 - 96.3ms/batch - loss: 12.41873 - diff: 10.54mlTrain batch 29/31 - 103.3ms/batch - loss: 12.22902 - diff: 10.48mlTrain batch 30/31 - 95.4ms/batch - loss: 12.10708 - diff: 10.44mlTrain batch 31/31 - 68.7ms/batch - loss: 12.02915 - diff: 10.38mlTrain batch 31/31 - 9.8s 68.7ms/batch - loss: 12.02915 - diff: 10.38ml
Test 0.6s: val_loss: 23.95639 - diff: 14.43ml

Epoch 80: current best loss = 20.47853, at epoch 76
Train batch 1/31 - 99.6ms/batch - loss: 6.85281 - diff: 8.96mlTrain batch 2/31 - 93.8ms/batch - loss: 13.05502 - diff: 11.47mlTrain batch 3/31 - 94.6ms/batch - loss: 12.35088 - diff: 11.11mlTrain batch 4/31 - 93.5ms/batch - loss: 13.79376 - diff: 11.70mlTrain batch 5/31 - 96.3ms/batch - loss: 17.24703 - diff: 12.59mlTrain batch 6/31 - 101.0ms/batch - loss: 18.72343 - diff: 13.50mlTrain batch 7/31 - 94.1ms/batch - loss: 17.35009 - diff: 12.89mlTrain batch 8/31 - 94.7ms/batch - loss: 16.24415 - diff: 12.49mlTrain batch 9/31 - 99.3ms/batch - loss: 15.75271 - diff: 12.27mlTrain batch 10/31 - 94.6ms/batch - loss: 15.07941 - diff: 11.91mlTrain batch 11/31 - 98.2ms/batch - loss: 15.03700 - diff: 11.82mlTrain batch 12/31 - 93.4ms/batch - loss: 14.85200 - diff: 11.70mlTrain batch 13/31 - 96.7ms/batch - loss: 15.04264 - diff: 11.66mlTrain batch 14/31 - 94.2ms/batch - loss: 14.89910 - diff: 11.72mlTrain batch 15/31 - 97.3ms/batch - loss: 14.14675 - diff: 11.35mlTrain batch 16/31 - 95.3ms/batch - loss: 13.93264 - diff: 11.22mlTrain batch 17/31 - 95.1ms/batch - loss: 13.52608 - diff: 11.10mlTrain batch 18/31 - 94.9ms/batch - loss: 13.50874 - diff: 11.23mlTrain batch 19/31 - 98.6ms/batch - loss: 13.25565 - diff: 11.16mlTrain batch 20/31 - 94.0ms/batch - loss: 12.80087 - diff: 10.95mlTrain batch 21/31 - 94.2ms/batch - loss: 13.17148 - diff: 11.16mlTrain batch 22/31 - 93.8ms/batch - loss: 12.99335 - diff: 11.06mlTrain batch 23/31 - 94.3ms/batch - loss: 13.02204 - diff: 11.13mlTrain batch 24/31 - 94.7ms/batch - loss: 12.81807 - diff: 11.03mlTrain batch 25/31 - 94.3ms/batch - loss: 12.90342 - diff: 11.11mlTrain batch 26/31 - 93.9ms/batch - loss: 12.68841 - diff: 11.00mlTrain batch 27/31 - 95.4ms/batch - loss: 12.39841 - diff: 10.88mlTrain batch 28/31 - 93.9ms/batch - loss: 12.19048 - diff: 10.79mlTrain batch 29/31 - 95.9ms/batch - loss: 12.25370 - diff: 10.83mlTrain batch 30/31 - 96.8ms/batch - loss: 12.00435 - diff: 10.69mlTrain batch 31/31 - 69.2ms/batch - loss: 12.27490 - diff: 10.73mlTrain batch 31/31 - 9.8s 69.2ms/batch - loss: 12.27490 - diff: 10.73ml
Test 0.6s: val_loss: 25.07468 - diff: 14.17ml

Epoch 81: current best loss = 20.47853, at epoch 76
Train batch 1/31 - 99.4ms/batch - loss: 11.57251 - diff: 11.72mlTrain batch 2/31 - 94.7ms/batch - loss: 8.19052 - diff: 9.58mlTrain batch 3/31 - 94.6ms/batch - loss: 9.17299 - diff: 9.72mlTrain batch 4/31 - 93.8ms/batch - loss: 17.90096 - diff: 11.88mlTrain batch 5/31 - 94.0ms/batch - loss: 15.24257 - diff: 10.86mlTrain batch 6/31 - 94.4ms/batch - loss: 13.40344 - diff: 10.22mlTrain batch 7/31 - 96.8ms/batch - loss: 12.28505 - diff: 9.76mlTrain batch 8/31 - 93.5ms/batch - loss: 11.33055 - diff: 9.44mlTrain batch 9/31 - 94.9ms/batch - loss: 11.20337 - diff: 9.45mlTrain batch 10/31 - 93.8ms/batch - loss: 10.60425 - diff: 9.15mlTrain batch 11/31 - 94.6ms/batch - loss: 10.62607 - diff: 9.23mlTrain batch 12/31 - 95.9ms/batch - loss: 10.32869 - diff: 9.16mlTrain batch 13/31 - 94.4ms/batch - loss: 10.79048 - diff: 9.25mlTrain batch 14/31 - 94.0ms/batch - loss: 11.06124 - diff: 9.46mlTrain batch 15/31 - 93.8ms/batch - loss: 11.14108 - diff: 9.64mlTrain batch 16/31 - 93.7ms/batch - loss: 12.36784 - diff: 10.25mlTrain batch 17/31 - 93.9ms/batch - loss: 12.37620 - diff: 10.33mlTrain batch 18/31 - 93.7ms/batch - loss: 12.25817 - diff: 10.26mlTrain batch 19/31 - 93.7ms/batch - loss: 11.94075 - diff: 10.10mlTrain batch 20/31 - 93.8ms/batch - loss: 11.55222 - diff: 9.96mlTrain batch 21/31 - 94.4ms/batch - loss: 11.33137 - diff: 9.85mlTrain batch 22/31 - 94.4ms/batch - loss: 11.11650 - diff: 9.81mlTrain batch 23/31 - 93.8ms/batch - loss: 10.75497 - diff: 9.60mlTrain batch 24/31 - 94.4ms/batch - loss: 10.66870 - diff: 9.61mlTrain batch 25/31 - 96.6ms/batch - loss: 10.47680 - diff: 9.53mlTrain batch 26/31 - 93.4ms/batch - loss: 10.42010 - diff: 9.56mlTrain batch 27/31 - 98.9ms/batch - loss: 10.64232 - diff: 9.71mlTrain batch 28/31 - 93.6ms/batch - loss: 10.56307 - diff: 9.70mlTrain batch 29/31 - 93.3ms/batch - loss: 10.53697 - diff: 9.69mlTrain batch 30/31 - 94.0ms/batch - loss: 10.84687 - diff: 9.81mlTrain batch 31/31 - 67.1ms/batch - loss: 12.86697 - diff: 10.02mlTrain batch 31/31 - 9.8s 67.1ms/batch - loss: 12.86697 - diff: 10.02ml
Test 0.6s: val_loss: 22.27415 - diff: 13.61ml

Epoch 82: current best loss = 20.47853, at epoch 76
Train batch 1/31 - 114.2ms/batch - loss: 18.42680 - diff: 12.09mlTrain batch 2/31 - 95.4ms/batch - loss: 13.11831 - diff: 10.70mlTrain batch 3/31 - 97.6ms/batch - loss: 10.30993 - diff: 9.37mlTrain batch 4/31 - 97.9ms/batch - loss: 10.38116 - diff: 9.87mlTrain batch 5/31 - 95.8ms/batch - loss: 11.57732 - diff: 9.94mlTrain batch 6/31 - 95.1ms/batch - loss: 10.66560 - diff: 9.59mlTrain batch 7/31 - 100.2ms/batch - loss: 10.37740 - diff: 9.35mlTrain batch 8/31 - 101.4ms/batch - loss: 9.46285 - diff: 8.88mlTrain batch 9/31 - 94.7ms/batch - loss: 9.08650 - diff: 8.79mlTrain batch 10/31 - 95.5ms/batch - loss: 9.09848 - diff: 8.91mlTrain batch 11/31 - 95.8ms/batch - loss: 9.07592 - diff: 8.90mlTrain batch 12/31 - 95.0ms/batch - loss: 9.37955 - diff: 9.05mlTrain batch 13/31 - 103.4ms/batch - loss: 9.22806 - diff: 8.99mlTrain batch 14/31 - 97.6ms/batch - loss: 10.06867 - diff: 9.53mlTrain batch 15/31 - 97.0ms/batch - loss: 10.82487 - diff: 9.83mlTrain batch 16/31 - 100.1ms/batch - loss: 10.59972 - diff: 9.78mlTrain batch 17/31 - 99.1ms/batch - loss: 11.11082 - diff: 9.85mlTrain batch 18/31 - 96.8ms/batch - loss: 10.98175 - diff: 9.87mlTrain batch 19/31 - 97.9ms/batch - loss: 11.38123 - diff: 10.13mlTrain batch 20/31 - 98.1ms/batch - loss: 11.64871 - diff: 10.26mlTrain batch 21/31 - 95.3ms/batch - loss: 11.57859 - diff: 10.25mlTrain batch 22/31 - 102.9ms/batch - loss: 11.53658 - diff: 10.25mlTrain batch 23/31 - 94.9ms/batch - loss: 11.43774 - diff: 10.18mlTrain batch 24/31 - 94.8ms/batch - loss: 11.42324 - diff: 10.23mlTrain batch 25/31 - 97.2ms/batch - loss: 11.15366 - diff: 10.09mlTrain batch 26/31 - 94.9ms/batch - loss: 10.99395 - diff: 10.05mlTrain batch 27/31 - 109.4ms/batch - loss: 11.20479 - diff: 10.09mlTrain batch 28/31 - 96.9ms/batch - loss: 11.15872 - diff: 10.14mlTrain batch 29/31 - 94.7ms/batch - loss: 11.43816 - diff: 10.26mlTrain batch 30/31 - 95.5ms/batch - loss: 11.83022 - diff: 10.39mlTrain batch 31/31 - 68.2ms/batch - loss: 12.50829 - diff: 10.45mlTrain batch 31/31 - 9.8s 68.2ms/batch - loss: 12.50829 - diff: 10.45ml
Test 0.7s: val_loss: 19.29070 - diff: 13.41ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Systole_DenseNet121_0_Adam-0.001_MSE_DA3_best

Epoch 83: current best loss = 19.29070, at epoch 82
Train batch 1/31 - 112.8ms/batch - loss: 5.72297 - diff: 7.44mlTrain batch 2/31 - 97.1ms/batch - loss: 6.48132 - diff: 8.48mlTrain batch 3/31 - 96.9ms/batch - loss: 8.76231 - diff: 9.92mlTrain batch 4/31 - 95.1ms/batch - loss: 11.07592 - diff: 10.99mlTrain batch 5/31 - 94.7ms/batch - loss: 10.22394 - diff: 10.09mlTrain batch 6/31 - 95.0ms/batch - loss: 9.81344 - diff: 9.88mlTrain batch 7/31 - 102.6ms/batch - loss: 12.55859 - diff: 10.59mlTrain batch 8/31 - 98.4ms/batch - loss: 12.06493 - diff: 10.38mlTrain batch 9/31 - 93.5ms/batch - loss: 11.63024 - diff: 10.24mlTrain batch 10/31 - 95.1ms/batch - loss: 10.86449 - diff: 9.77mlTrain batch 11/31 - 96.6ms/batch - loss: 10.25655 - diff: 9.48mlTrain batch 12/31 - 94.6ms/batch - loss: 11.43723 - diff: 9.92mlTrain batch 13/31 - 94.6ms/batch - loss: 11.38014 - diff: 10.04mlTrain batch 14/31 - 94.6ms/batch - loss: 11.04205 - diff: 9.89mlTrain batch 15/31 - 94.5ms/batch - loss: 11.30278 - diff: 9.84mlTrain batch 16/31 - 95.2ms/batch - loss: 10.95843 - diff: 9.70mlTrain batch 17/31 - 97.7ms/batch - loss: 10.87239 - diff: 9.73mlTrain batch 18/31 - 93.9ms/batch - loss: 11.25744 - diff: 9.98mlTrain batch 19/31 - 104.5ms/batch - loss: 11.04487 - diff: 9.89mlTrain batch 20/31 - 94.2ms/batch - loss: 11.32405 - diff: 10.00mlTrain batch 21/31 - 96.9ms/batch - loss: 10.93679 - diff: 9.79mlTrain batch 22/31 - 97.7ms/batch - loss: 10.81574 - diff: 9.77mlTrain batch 23/31 - 100.0ms/batch - loss: 10.60673 - diff: 9.68mlTrain batch 24/31 - 96.3ms/batch - loss: 10.41549 - diff: 9.58mlTrain batch 25/31 - 95.7ms/batch - loss: 10.44332 - diff: 9.64mlTrain batch 26/31 - 95.1ms/batch - loss: 11.38470 - diff: 9.73mlTrain batch 27/31 - 95.3ms/batch - loss: 11.46530 - diff: 9.79mlTrain batch 28/31 - 97.9ms/batch - loss: 11.36458 - diff: 9.69mlTrain batch 29/31 - 93.6ms/batch - loss: 11.23288 - diff: 9.69mlTrain batch 30/31 - 94.1ms/batch - loss: 11.16759 - diff: 9.69mlTrain batch 31/31 - 67.6ms/batch - loss: 11.38734 - diff: 9.68mlTrain batch 31/31 - 9.8s 67.6ms/batch - loss: 11.38734 - diff: 9.68ml
Test 0.7s: val_loss: 20.45928 - diff: 13.29ml

Epoch 84: current best loss = 19.29070, at epoch 82
Train batch 1/31 - 108.3ms/batch - loss: 20.24924 - diff: 14.50mlTrain batch 2/31 - 95.2ms/batch - loss: 13.84541 - diff: 12.17mlTrain batch 3/31 - 99.5ms/batch - loss: 10.79257 - diff: 10.51mlTrain batch 4/31 - 94.2ms/batch - loss: 10.57503 - diff: 10.51mlTrain batch 5/31 - 98.4ms/batch - loss: 9.72030 - diff: 10.13mlTrain batch 6/31 - 93.7ms/batch - loss: 9.87702 - diff: 10.14mlTrain batch 7/31 - 101.8ms/batch - loss: 10.76459 - diff: 10.46mlTrain batch 8/31 - 99.0ms/batch - loss: 10.42621 - diff: 10.28mlTrain batch 9/31 - 97.0ms/batch - loss: 10.88642 - diff: 10.46mlTrain batch 10/31 - 94.4ms/batch - loss: 10.71754 - diff: 10.40mlTrain batch 11/31 - 98.1ms/batch - loss: 10.19769 - diff: 10.13mlTrain batch 12/31 - 94.3ms/batch - loss: 9.68891 - diff: 9.78mlTrain batch 13/31 - 94.9ms/batch - loss: 10.92514 - diff: 10.25mlTrain batch 14/31 - 96.2ms/batch - loss: 10.83079 - diff: 10.22mlTrain batch 15/31 - 98.8ms/batch - loss: 11.54031 - diff: 10.67mlTrain batch 16/31 - 94.6ms/batch - loss: 11.10764 - diff: 10.44mlTrain batch 17/31 - 94.9ms/batch - loss: 11.58586 - diff: 10.56mlTrain batch 18/31 - 97.5ms/batch - loss: 11.69552 - diff: 10.61mlTrain batch 19/31 - 97.8ms/batch - loss: 11.54449 - diff: 10.58mlTrain batch 20/31 - 94.1ms/batch - loss: 11.69649 - diff: 10.70mlTrain batch 21/31 - 97.4ms/batch - loss: 11.79425 - diff: 10.72mlTrain batch 22/31 - 95.6ms/batch - loss: 11.99522 - diff: 10.87mlTrain batch 23/31 - 96.0ms/batch - loss: 11.92305 - diff: 10.86mlTrain batch 24/31 - 94.9ms/batch - loss: 11.65481 - diff: 10.70mlTrain batch 25/31 - 98.4ms/batch - loss: 12.41413 - diff: 11.01mlTrain batch 26/31 - 93.9ms/batch - loss: 12.17978 - diff: 10.92mlTrain batch 27/31 - 97.9ms/batch - loss: 11.97403 - diff: 10.78mlTrain batch 28/31 - 94.2ms/batch - loss: 12.19314 - diff: 10.91mlTrain batch 29/31 - 95.9ms/batch - loss: 12.05534 - diff: 10.86mlTrain batch 30/31 - 93.2ms/batch - loss: 11.94861 - diff: 10.83mlTrain batch 31/31 - 73.4ms/batch - loss: 12.32778 - diff: 10.88mlTrain batch 31/31 - 9.7s 73.4ms/batch - loss: 12.32778 - diff: 10.88ml
Test 0.6s: val_loss: 19.45788 - diff: 13.23ml

Epoch 85: current best loss = 19.29070, at epoch 82
Train batch 1/31 - 119.3ms/batch - loss: 4.53709 - diff: 7.45mlTrain batch 2/31 - 93.7ms/batch - loss: 7.27603 - diff: 8.25mlTrain batch 3/31 - 107.5ms/batch - loss: 16.44821 - diff: 12.05mlTrain batch 4/31 - 94.7ms/batch - loss: 13.45229 - diff: 10.92mlTrain batch 5/31 - 107.0ms/batch - loss: 13.60485 - diff: 11.06mlTrain batch 6/31 - 94.1ms/batch - loss: 12.58546 - diff: 10.62mlTrain batch 7/31 - 96.8ms/batch - loss: 12.04425 - diff: 10.30mlTrain batch 8/31 - 94.6ms/batch - loss: 11.31418 - diff: 9.95mlTrain batch 9/31 - 114.2ms/batch - loss: 11.15193 - diff: 9.88mlTrain batch 10/31 - 97.6ms/batch - loss: 11.72417 - diff: 10.25mlTrain batch 11/31 - 99.5ms/batch - loss: 11.03272 - diff: 9.88mlTrain batch 12/31 - 94.2ms/batch - loss: 10.58571 - diff: 9.71mlTrain batch 13/31 - 106.3ms/batch - loss: 10.16201 - diff: 9.61mlTrain batch 14/31 - 93.4ms/batch - loss: 11.59531 - diff: 10.12mlTrain batch 15/31 - 94.6ms/batch - loss: 11.47478 - diff: 10.10mlTrain batch 16/31 - 93.8ms/batch - loss: 10.98574 - diff: 9.85mlTrain batch 17/31 - 94.7ms/batch - loss: 10.98784 - diff: 9.84mlTrain batch 18/31 - 93.7ms/batch - loss: 11.36864 - diff: 9.98mlTrain batch 19/31 - 93.9ms/batch - loss: 11.60873 - diff: 10.16mlTrain batch 20/31 - 94.0ms/batch - loss: 11.57084 - diff: 10.21mlTrain batch 21/31 - 95.5ms/batch - loss: 11.55106 - diff: 10.25mlTrain batch 22/31 - 94.5ms/batch - loss: 11.50788 - diff: 10.27mlTrain batch 23/31 - 96.6ms/batch - loss: 11.44532 - diff: 10.28mlTrain batch 24/31 - 95.5ms/batch - loss: 11.56134 - diff: 10.36mlTrain batch 25/31 - 93.9ms/batch - loss: 11.31860 - diff: 10.23mlTrain batch 26/31 - 95.6ms/batch - loss: 11.33438 - diff: 10.24mlTrain batch 27/31 - 94.0ms/batch - loss: 11.28076 - diff: 10.26mlTrain batch 28/31 - 96.0ms/batch - loss: 11.08090 - diff: 10.17mlTrain batch 29/31 - 94.7ms/batch - loss: 10.90278 - diff: 10.11mlTrain batch 30/31 - 94.7ms/batch - loss: 10.65522 - diff: 9.97mlTrain batch 31/31 - 67.8ms/batch - loss: 10.98240 - diff: 10.01mlTrain batch 31/31 - 9.8s 67.8ms/batch - loss: 10.98240 - diff: 10.01ml
Test 0.7s: val_loss: 23.36206 - diff: 13.94ml

Epoch 86: current best loss = 19.29070, at epoch 82
Train batch 1/31 - 103.8ms/batch - loss: 12.62782 - diff: 10.04mlTrain batch 2/31 - 94.5ms/batch - loss: 12.22559 - diff: 10.75mlTrain batch 3/31 - 99.1ms/batch - loss: 9.83179 - diff: 9.32mlTrain batch 4/31 - 96.4ms/batch - loss: 10.88039 - diff: 9.99mlTrain batch 5/31 - 98.7ms/batch - loss: 11.65381 - diff: 10.68mlTrain batch 6/31 - 97.1ms/batch - loss: 11.75268 - diff: 10.88mlTrain batch 7/31 - 99.4ms/batch - loss: 10.85106 - diff: 10.37mlTrain batch 8/31 - 95.2ms/batch - loss: 9.91353 - diff: 9.87mlTrain batch 9/31 - 124.0ms/batch - loss: 9.41558 - diff: 9.61mlTrain batch 10/31 - 98.0ms/batch - loss: 9.90913 - diff: 9.98mlTrain batch 11/31 - 95.0ms/batch - loss: 9.46885 - diff: 9.77mlTrain batch 12/31 - 94.0ms/batch - loss: 9.30824 - diff: 9.64mlTrain batch 13/31 - 95.3ms/batch - loss: 8.82402 - diff: 9.33mlTrain batch 14/31 - 110.5ms/batch - loss: 13.17421 - diff: 9.97mlTrain batch 15/31 - 96.5ms/batch - loss: 12.63217 - diff: 9.79mlTrain batch 16/31 - 97.6ms/batch - loss: 12.41548 - diff: 9.73mlTrain batch 17/31 - 94.2ms/batch - loss: 13.30590 - diff: 10.31mlTrain batch 18/31 - 97.8ms/batch - loss: 12.77399 - diff: 10.11mlTrain batch 19/31 - 94.0ms/batch - loss: 12.56627 - diff: 10.11mlTrain batch 20/31 - 96.5ms/batch - loss: 12.26238 - diff: 9.97mlTrain batch 21/31 - 94.5ms/batch - loss: 12.01699 - diff: 9.83mlTrain batch 22/31 - 117.0ms/batch - loss: 11.95629 - diff: 9.84mlTrain batch 23/31 - 102.7ms/batch - loss: 12.14270 - diff: 9.98mlTrain batch 24/31 - 97.0ms/batch - loss: 12.42970 - diff: 10.20mlTrain batch 25/31 - 96.8ms/batch - loss: 12.30099 - diff: 10.19mlTrain batch 26/31 - 100.7ms/batch - loss: 12.03119 - diff: 10.05mlTrain batch 27/31 - 101.0ms/batch - loss: 12.27073 - diff: 10.15mlTrain batch 28/31 - 97.1ms/batch - loss: 12.08175 - diff: 10.08mlTrain batch 29/31 - 95.9ms/batch - loss: 13.33776 - diff: 10.43mlTrain batch 30/31 - 95.3ms/batch - loss: 13.20189 - diff: 10.44mlTrain batch 31/31 - 69.2ms/batch - loss: 14.19273 - diff: 10.55mlTrain batch 31/31 - 9.8s 69.2ms/batch - loss: 14.19273 - diff: 10.55ml
Test 0.6s: val_loss: 24.20548 - diff: 13.90ml

Epoch 87: current best loss = 19.29070, at epoch 82
Train batch 1/31 - 100.3ms/batch - loss: 9.33612 - diff: 9.89mlTrain batch 2/31 - 93.9ms/batch - loss: 9.93503 - diff: 10.11mlTrain batch 3/31 - 97.2ms/batch - loss: 10.32769 - diff: 10.05mlTrain batch 4/31 - 94.2ms/batch - loss: 10.02333 - diff: 10.20mlTrain batch 5/31 - 97.9ms/batch - loss: 9.32073 - diff: 9.80mlTrain batch 6/31 - 93.8ms/batch - loss: 8.81691 - diff: 9.54mlTrain batch 7/31 - 97.5ms/batch - loss: 8.17029 - diff: 9.12mlTrain batch 8/31 - 94.3ms/batch - loss: 7.77863 - diff: 8.95mlTrain batch 9/31 - 94.1ms/batch - loss: 7.38774 - diff: 8.73mlTrain batch 10/31 - 96.3ms/batch - loss: 7.62547 - diff: 8.87mlTrain batch 11/31 - 97.5ms/batch - loss: 7.59122 - diff: 8.90mlTrain batch 12/31 - 96.2ms/batch - loss: 7.25608 - diff: 8.70mlTrain batch 13/31 - 93.5ms/batch - loss: 6.97245 - diff: 8.54mlTrain batch 14/31 - 93.9ms/batch - loss: 7.11667 - diff: 8.67mlTrain batch 15/31 - 94.8ms/batch - loss: 6.96829 - diff: 8.57mlTrain batch 16/31 - 93.6ms/batch - loss: 7.14011 - diff: 8.64mlTrain batch 17/31 - 94.2ms/batch - loss: 7.50129 - diff: 8.73mlTrain batch 18/31 - 93.7ms/batch - loss: 7.33352 - diff: 8.64mlTrain batch 19/31 - 94.4ms/batch - loss: 7.74749 - diff: 8.84mlTrain batch 20/31 - 93.9ms/batch - loss: 7.79082 - diff: 8.86mlTrain batch 21/31 - 95.0ms/batch - loss: 7.64045 - diff: 8.76mlTrain batch 22/31 - 94.5ms/batch - loss: 7.60670 - diff: 8.76mlTrain batch 23/31 - 94.2ms/batch - loss: 9.11132 - diff: 9.06mlTrain batch 24/31 - 94.6ms/batch - loss: 9.14817 - diff: 9.05mlTrain batch 25/31 - 93.9ms/batch - loss: 9.53350 - diff: 9.18mlTrain batch 26/31 - 95.3ms/batch - loss: 9.63321 - diff: 9.28mlTrain batch 27/31 - 93.6ms/batch - loss: 9.65192 - diff: 9.34mlTrain batch 28/31 - 95.2ms/batch - loss: 9.61835 - diff: 9.36mlTrain batch 29/31 - 94.2ms/batch - loss: 9.57726 - diff: 9.33mlTrain batch 30/31 - 93.6ms/batch - loss: 10.09518 - diff: 9.53mlTrain batch 31/31 - 72.8ms/batch - loss: 10.08275 - diff: 9.48mlTrain batch 31/31 - 9.8s 72.8ms/batch - loss: 10.08275 - diff: 9.48ml
Test 0.7s: val_loss: 27.33482 - diff: 14.44ml

Epoch 88: current best loss = 19.29070, at epoch 82
Train batch 1/31 - 98.7ms/batch - loss: 2.94329 - diff: 5.57mlTrain batch 2/31 - 93.7ms/batch - loss: 8.36098 - diff: 7.58mlTrain batch 3/31 - 93.5ms/batch - loss: 9.58271 - diff: 8.25mlTrain batch 4/31 - 94.4ms/batch - loss: 8.92547 - diff: 8.15mlTrain batch 5/31 - 93.6ms/batch - loss: 9.92175 - diff: 8.85mlTrain batch 6/31 - 94.8ms/batch - loss: 10.00561 - diff: 9.20mlTrain batch 7/31 - 93.7ms/batch - loss: 9.99535 - diff: 9.41mlTrain batch 8/31 - 94.8ms/batch - loss: 9.70113 - diff: 9.32mlTrain batch 9/31 - 93.9ms/batch - loss: 27.23607 - diff: 12.59mlTrain batch 10/31 - 95.5ms/batch - loss: 24.93214 - diff: 11.93mlTrain batch 11/31 - 101.5ms/batch - loss: 23.15647 - diff: 11.59mlTrain batch 12/31 - 97.0ms/batch - loss: 21.79097 - diff: 11.25mlTrain batch 13/31 - 94.4ms/batch - loss: 20.92050 - diff: 10.99mlTrain batch 14/31 - 94.3ms/batch - loss: 19.67866 - diff: 10.65mlTrain batch 15/31 - 93.9ms/batch - loss: 18.86150 - diff: 10.58mlTrain batch 16/31 - 94.9ms/batch - loss: 18.43419 - diff: 10.56mlTrain batch 17/31 - 93.7ms/batch - loss: 18.48970 - diff: 10.81mlTrain batch 18/31 - 95.5ms/batch - loss: 18.51286 - diff: 11.07mlTrain batch 19/31 - 94.2ms/batch - loss: 17.92514 - diff: 10.97mlTrain batch 20/31 - 95.7ms/batch - loss: 17.17824 - diff: 10.72mlTrain batch 21/31 - 94.1ms/batch - loss: 16.83960 - diff: 10.65mlTrain batch 22/31 - 95.4ms/batch - loss: 16.49458 - diff: 10.68mlTrain batch 23/31 - 93.7ms/batch - loss: 16.70419 - diff: 10.72mlTrain batch 24/31 - 95.2ms/batch - loss: 16.70024 - diff: 10.85mlTrain batch 25/31 - 94.6ms/batch - loss: 16.54365 - diff: 10.83mlTrain batch 26/31 - 94.7ms/batch - loss: 16.43894 - diff: 10.93mlTrain batch 27/31 - 94.0ms/batch - loss: 16.07348 - diff: 10.81mlTrain batch 28/31 - 94.5ms/batch - loss: 15.71040 - diff: 10.70mlTrain batch 29/31 - 94.4ms/batch - loss: 15.40074 - diff: 10.58mlTrain batch 30/31 - 95.8ms/batch - loss: 15.21188 - diff: 10.56mlTrain batch 31/31 - 67.8ms/batch - loss: 15.41673 - diff: 10.55mlTrain batch 31/31 - 9.8s 67.8ms/batch - loss: 15.41673 - diff: 10.55ml
Test 0.6s: val_loss: 26.39926 - diff: 14.03ml

Epoch 89: current best loss = 19.29070, at epoch 82
Train batch 1/31 - 117.1ms/batch - loss: 11.13310 - diff: 11.13mlTrain batch 2/31 - 93.1ms/batch - loss: 10.13844 - diff: 9.36mlTrain batch 3/31 - 108.1ms/batch - loss: 8.87203 - diff: 9.03mlTrain batch 4/31 - 93.5ms/batch - loss: 8.03767 - diff: 8.73mlTrain batch 5/31 - 106.5ms/batch - loss: 8.96769 - diff: 8.84mlTrain batch 6/31 - 95.0ms/batch - loss: 9.57857 - diff: 9.23mlTrain batch 7/31 - 103.2ms/batch - loss: 8.72644 - diff: 8.88mlTrain batch 8/31 - 93.8ms/batch - loss: 8.54892 - diff: 8.78mlTrain batch 9/31 - 94.4ms/batch - loss: 8.26971 - diff: 8.63mlTrain batch 10/31 - 93.9ms/batch - loss: 8.06025 - diff: 8.63mlTrain batch 11/31 - 101.4ms/batch - loss: 7.87434 - diff: 8.53mlTrain batch 12/31 - 100.6ms/batch - loss: 8.01524 - diff: 8.55mlTrain batch 13/31 - 93.7ms/batch - loss: 7.96879 - diff: 8.52mlTrain batch 14/31 - 94.5ms/batch - loss: 8.50512 - diff: 8.94mlTrain batch 15/31 - 106.6ms/batch - loss: 8.99724 - diff: 9.15mlTrain batch 16/31 - 94.0ms/batch - loss: 9.36319 - diff: 9.37mlTrain batch 17/31 - 113.7ms/batch - loss: 9.04796 - diff: 9.19mlTrain batch 18/31 - 93.6ms/batch - loss: 8.68462 - diff: 8.96mlTrain batch 19/31 - 99.6ms/batch - loss: 8.98366 - diff: 9.12mlTrain batch 20/31 - 94.9ms/batch - loss: 8.76191 - diff: 9.02mlTrain batch 21/31 - 97.7ms/batch - loss: 8.62289 - diff: 8.95mlTrain batch 22/31 - 93.7ms/batch - loss: 9.04232 - diff: 9.11mlTrain batch 23/31 - 95.8ms/batch - loss: 9.01384 - diff: 9.16mlTrain batch 24/31 - 95.8ms/batch - loss: 8.97042 - diff: 9.16mlTrain batch 25/31 - 97.8ms/batch - loss: 8.94523 - diff: 9.09mlTrain batch 26/31 - 95.0ms/batch - loss: 9.15995 - diff: 9.24mlTrain batch 27/31 - 105.8ms/batch - loss: 9.26514 - diff: 9.33mlTrain batch 28/31 - 94.0ms/batch - loss: 9.21392 - diff: 9.33mlTrain batch 29/31 - 96.4ms/batch - loss: 9.33752 - diff: 9.36mlTrain batch 30/31 - 93.7ms/batch - loss: 9.20641 - diff: 9.30mlTrain batch 31/31 - 68.5ms/batch - loss: 10.14623 - diff: 9.45mlTrain batch 31/31 - 9.8s 68.5ms/batch - loss: 10.14623 - diff: 9.45ml
Test 0.7s: val_loss: 22.62999 - diff: 13.62ml

Epoch 90: current best loss = 19.29070, at epoch 82
Train batch 1/31 - 100.9ms/batch - loss: 5.45985 - diff: 7.78mlTrain batch 2/31 - 95.0ms/batch - loss: 8.74792 - diff: 9.52mlTrain batch 3/31 - 94.0ms/batch - loss: 14.31244 - diff: 12.23mlTrain batch 4/31 - 95.6ms/batch - loss: 11.76714 - diff: 10.60mlTrain batch 5/31 - 98.7ms/batch - loss: 10.69195 - diff: 10.23mlTrain batch 6/31 - 94.9ms/batch - loss: 10.37342 - diff: 10.15mlTrain batch 7/31 - 97.5ms/batch - loss: 9.65164 - diff: 9.70mlTrain batch 8/31 - 94.8ms/batch - loss: 9.27033 - diff: 9.36mlTrain batch 9/31 - 98.2ms/batch - loss: 8.83029 - diff: 9.11mlTrain batch 10/31 - 95.3ms/batch - loss: 8.27382 - diff: 8.67mlTrain batch 11/31 - 107.5ms/batch - loss: 8.18073 - diff: 8.69mlTrain batch 12/31 - 105.9ms/batch - loss: 8.70897 - diff: 9.08mlTrain batch 13/31 - 95.3ms/batch - loss: 8.49695 - diff: 9.06mlTrain batch 14/31 - 96.3ms/batch - loss: 8.18621 - diff: 8.84mlTrain batch 15/31 - 98.6ms/batch - loss: 8.77178 - diff: 9.17mlTrain batch 16/31 - 95.1ms/batch - loss: 8.97385 - diff: 9.21mlTrain batch 17/31 - 94.4ms/batch - loss: 8.74598 - diff: 9.10mlTrain batch 18/31 - 95.5ms/batch - loss: 8.66535 - diff: 9.10mlTrain batch 19/31 - 94.7ms/batch - loss: 9.44532 - diff: 9.55mlTrain batch 20/31 - 94.5ms/batch - loss: 9.56115 - diff: 9.53mlTrain batch 21/31 - 94.8ms/batch - loss: 11.12665 - diff: 10.03mlTrain batch 22/31 - 95.4ms/batch - loss: 11.11391 - diff: 10.08mlTrain batch 23/31 - 95.2ms/batch - loss: 10.90367 - diff: 9.99mlTrain batch 24/31 - 94.7ms/batch - loss: 10.71554 - diff: 9.96mlTrain batch 25/31 - 94.3ms/batch - loss: 10.81133 - diff: 10.02mlTrain batch 26/31 - 96.2ms/batch - loss: 10.92080 - diff: 10.00mlTrain batch 27/31 - 97.1ms/batch - loss: 10.90387 - diff: 10.00mlTrain batch 28/31 - 97.7ms/batch - loss: 10.88591 - diff: 9.98mlTrain batch 29/31 - 94.0ms/batch - loss: 10.86827 - diff: 9.98mlTrain batch 30/31 - 95.3ms/batch - loss: 10.76419 - diff: 9.95mlTrain batch 31/31 - 69.3ms/batch - loss: 10.75627 - diff: 9.91mlTrain batch 31/31 - 9.8s 69.3ms/batch - loss: 10.75627 - diff: 9.91ml
Test 0.6s: val_loss: 23.30123 - diff: 14.61ml

Epoch 91: current best loss = 19.29070, at epoch 82
Train batch 1/31 - 116.0ms/batch - loss: 5.42603 - diff: 7.02mlTrain batch 2/31 - 94.2ms/batch - loss: 6.48849 - diff: 7.77mlTrain batch 3/31 - 106.3ms/batch - loss: 6.08531 - diff: 7.46mlTrain batch 4/31 - 94.8ms/batch - loss: 6.23718 - diff: 7.73mlTrain batch 5/31 - 107.2ms/batch - loss: 5.92335 - diff: 7.55mlTrain batch 6/31 - 94.3ms/batch - loss: 5.72659 - diff: 7.43mlTrain batch 7/31 - 94.3ms/batch - loss: 5.92912 - diff: 7.56mlTrain batch 8/31 - 94.6ms/batch - loss: 6.31182 - diff: 7.84mlTrain batch 9/31 - 94.7ms/batch - loss: 7.00828 - diff: 8.28mlTrain batch 10/31 - 94.0ms/batch - loss: 6.92634 - diff: 8.26mlTrain batch 11/31 - 93.9ms/batch - loss: 6.43635 - diff: 7.90mlTrain batch 12/31 - 93.9ms/batch - loss: 6.52132 - diff: 7.82mlTrain batch 13/31 - 99.0ms/batch - loss: 6.34922 - diff: 7.70mlTrain batch 14/31 - 93.4ms/batch - loss: 7.05726 - diff: 8.12mlTrain batch 15/31 - 94.8ms/batch - loss: 7.65700 - diff: 8.41mlTrain batch 16/31 - 95.9ms/batch - loss: 8.72837 - diff: 8.98mlTrain batch 17/31 - 95.9ms/batch - loss: 8.67286 - diff: 8.96mlTrain batch 18/31 - 94.1ms/batch - loss: 8.81013 - diff: 9.07mlTrain batch 19/31 - 94.1ms/batch - loss: 8.64429 - diff: 9.03mlTrain batch 20/31 - 95.2ms/batch - loss: 9.18500 - diff: 9.38mlTrain batch 21/31 - 94.2ms/batch - loss: 9.02858 - diff: 9.29mlTrain batch 22/31 - 95.1ms/batch - loss: 9.89679 - diff: 9.54mlTrain batch 23/31 - 94.2ms/batch - loss: 13.31259 - diff: 10.49mlTrain batch 24/31 - 94.1ms/batch - loss: 13.18335 - diff: 10.46mlTrain batch 25/31 - 94.0ms/batch - loss: 12.98137 - diff: 10.42mlTrain batch 26/31 - 94.8ms/batch - loss: 13.00112 - diff: 10.49mlTrain batch 27/31 - 93.6ms/batch - loss: 13.13276 - diff: 10.56mlTrain batch 28/31 - 94.4ms/batch - loss: 13.22345 - diff: 10.56mlTrain batch 29/31 - 93.3ms/batch - loss: 13.12695 - diff: 10.59mlTrain batch 30/31 - 94.0ms/batch - loss: 13.58521 - diff: 10.67mlTrain batch 31/31 - 67.0ms/batch - loss: 13.71800 - diff: 10.66mlTrain batch 31/31 - 9.8s 67.0ms/batch - loss: 13.71800 - diff: 10.66ml
Test 0.7s: val_loss: 21.94829 - diff: 13.37ml

Epoch 92: current best loss = 19.29070, at epoch 82
Train batch 1/31 - 104.6ms/batch - loss: 9.50443 - diff: 9.39mlTrain batch 2/31 - 93.9ms/batch - loss: 12.04417 - diff: 11.01mlTrain batch 3/31 - 106.4ms/batch - loss: 10.78720 - diff: 10.64mlTrain batch 4/31 - 95.6ms/batch - loss: 11.77922 - diff: 10.31mlTrain batch 5/31 - 95.0ms/batch - loss: 12.41163 - diff: 10.22mlTrain batch 6/31 - 94.3ms/batch - loss: 12.39362 - diff: 10.13mlTrain batch 7/31 - 108.5ms/batch - loss: 12.25750 - diff: 10.37mlTrain batch 8/31 - 93.8ms/batch - loss: 12.57236 - diff: 10.57mlTrain batch 9/31 - 94.1ms/batch - loss: 11.82199 - diff: 10.27mlTrain batch 10/31 - 94.6ms/batch - loss: 11.56065 - diff: 10.08mlTrain batch 11/31 - 94.8ms/batch - loss: 11.27911 - diff: 9.95mlTrain batch 12/31 - 94.2ms/batch - loss: 10.81445 - diff: 9.69mlTrain batch 13/31 - 99.8ms/batch - loss: 10.67928 - diff: 9.63mlTrain batch 14/31 - 100.9ms/batch - loss: 11.00999 - diff: 9.88mlTrain batch 15/31 - 95.5ms/batch - loss: 10.76921 - diff: 9.81mlTrain batch 16/31 - 94.4ms/batch - loss: 10.92937 - diff: 10.04mlTrain batch 17/31 - 96.2ms/batch - loss: 10.67341 - diff: 9.90mlTrain batch 18/31 - 94.5ms/batch - loss: 10.37761 - diff: 9.74mlTrain batch 19/31 - 99.4ms/batch - loss: 10.06068 - diff: 9.62mlTrain batch 20/31 - 96.5ms/batch - loss: 10.06044 - diff: 9.53mlTrain batch 21/31 - 96.3ms/batch - loss: 10.05430 - diff: 9.54mlTrain batch 22/31 - 95.2ms/batch - loss: 9.83805 - diff: 9.47mlTrain batch 23/31 - 95.2ms/batch - loss: 10.22023 - diff: 9.73mlTrain batch 24/31 - 94.4ms/batch - loss: 10.20043 - diff: 9.73mlTrain batch 25/31 - 102.9ms/batch - loss: 11.80576 - diff: 9.92mlTrain batch 26/31 - 96.2ms/batch - loss: 11.54871 - diff: 9.81mlTrain batch 27/31 - 96.1ms/batch - loss: 11.34911 - diff: 9.75mlTrain batch 28/31 - 95.4ms/batch - loss: 11.35605 - diff: 9.75mlTrain batch 29/31 - 95.4ms/batch - loss: 11.21684 - diff: 9.73mlTrain batch 30/31 - 94.1ms/batch - loss: 11.14243 - diff: 9.74mlTrain batch 31/31 - 68.7ms/batch - loss: 11.20973 - diff: 9.72mlTrain batch 31/31 - 9.8s 68.7ms/batch - loss: 11.20973 - diff: 9.72ml
Test 0.6s: val_loss: 27.45433 - diff: 15.04ml

Epoch 93: current best loss = 19.29070, at epoch 82
Train batch 1/31 - 98.3ms/batch - loss: 11.12482 - diff: 10.56mlTrain batch 2/31 - 94.0ms/batch - loss: 8.39975 - diff: 9.21mlTrain batch 3/31 - 94.6ms/batch - loss: 8.51243 - diff: 9.45mlTrain batch 4/31 - 94.6ms/batch - loss: 9.01523 - diff: 9.59mlTrain batch 5/31 - 94.5ms/batch - loss: 8.53193 - diff: 9.26mlTrain batch 6/31 - 93.9ms/batch - loss: 8.87213 - diff: 9.39mlTrain batch 7/31 - 94.3ms/batch - loss: 8.96758 - diff: 9.53mlTrain batch 8/31 - 94.4ms/batch - loss: 9.39617 - diff: 9.87mlTrain batch 9/31 - 93.8ms/batch - loss: 10.69262 - diff: 10.13mlTrain batch 10/31 - 94.8ms/batch - loss: 10.52433 - diff: 10.17mlTrain batch 11/31 - 93.7ms/batch - loss: 10.56052 - diff: 10.10mlTrain batch 12/31 - 94.8ms/batch - loss: 10.69134 - diff: 10.24mlTrain batch 13/31 - 95.9ms/batch - loss: 10.40342 - diff: 10.07mlTrain batch 14/31 - 97.2ms/batch - loss: 9.95766 - diff: 9.87mlTrain batch 15/31 - 93.9ms/batch - loss: 10.91940 - diff: 9.94mlTrain batch 16/31 - 93.8ms/batch - loss: 12.06282 - diff: 10.13mlTrain batch 17/31 - 94.8ms/batch - loss: 12.08877 - diff: 10.16mlTrain batch 18/31 - 94.1ms/batch - loss: 11.95500 - diff: 10.12mlTrain batch 19/31 - 95.1ms/batch - loss: 12.26732 - diff: 10.39mlTrain batch 20/31 - 94.1ms/batch - loss: 12.94443 - diff: 10.61mlTrain batch 21/31 - 94.8ms/batch - loss: 13.64435 - diff: 10.82mlTrain batch 22/31 - 94.1ms/batch - loss: 13.56562 - diff: 10.86mlTrain batch 23/31 - 94.6ms/batch - loss: 14.06027 - diff: 11.20mlTrain batch 24/31 - 93.6ms/batch - loss: 13.79456 - diff: 11.12mlTrain batch 25/31 - 93.9ms/batch - loss: 13.43990 - diff: 10.94mlTrain batch 26/31 - 94.2ms/batch - loss: 13.20220 - diff: 10.87mlTrain batch 27/31 - 94.6ms/batch - loss: 13.23269 - diff: 10.84mlTrain batch 28/31 - 94.5ms/batch - loss: 13.18368 - diff: 10.84mlTrain batch 29/31 - 93.9ms/batch - loss: 13.07509 - diff: 10.81mlTrain batch 30/31 - 93.8ms/batch - loss: 12.97191 - diff: 10.80mlTrain batch 31/31 - 70.7ms/batch - loss: 12.85104 - diff: 10.70mlTrain batch 31/31 - 9.8s 70.7ms/batch - loss: 12.85104 - diff: 10.70ml
Test 0.6s: val_loss: 27.26701 - diff: 14.44ml
Epoch    94: reducing learning rate of group 0 to 1.2500e-04.

Epoch 94: current best loss = 19.29070, at epoch 82
Train batch 1/31 - 99.1ms/batch - loss: 4.75582 - diff: 7.34mlTrain batch 2/31 - 94.0ms/batch - loss: 5.85976 - diff: 8.07mlTrain batch 3/31 - 93.6ms/batch - loss: 7.66555 - diff: 8.80mlTrain batch 4/31 - 94.9ms/batch - loss: 8.22311 - diff: 8.91mlTrain batch 5/31 - 93.8ms/batch - loss: 8.59696 - diff: 8.99mlTrain batch 6/31 - 95.0ms/batch - loss: 8.79913 - diff: 8.84mlTrain batch 7/31 - 94.2ms/batch - loss: 8.47622 - diff: 8.57mlTrain batch 8/31 - 94.2ms/batch - loss: 7.78151 - diff: 8.25mlTrain batch 9/31 - 96.4ms/batch - loss: 9.23822 - diff: 8.80mlTrain batch 10/31 - 93.8ms/batch - loss: 9.40270 - diff: 9.01mlTrain batch 11/31 - 101.5ms/batch - loss: 9.74345 - diff: 9.33mlTrain batch 12/31 - 94.1ms/batch - loss: 9.89762 - diff: 9.38mlTrain batch 13/31 - 94.9ms/batch - loss: 10.04951 - diff: 9.56mlTrain batch 14/31 - 95.2ms/batch - loss: 11.33797 - diff: 9.59mlTrain batch 15/31 - 100.9ms/batch - loss: 10.92099 - diff: 9.44mlTrain batch 16/31 - 94.2ms/batch - loss: 10.51869 - diff: 9.31mlTrain batch 17/31 - 95.3ms/batch - loss: 11.14132 - diff: 9.66mlTrain batch 18/31 - 94.6ms/batch - loss: 19.77066 - diff: 10.94mlTrain batch 19/31 - 96.5ms/batch - loss: 18.90908 - diff: 10.68mlTrain batch 20/31 - 94.4ms/batch - loss: 18.19443 - diff: 10.49mlTrain batch 21/31 - 95.6ms/batch - loss: 18.03554 - diff: 10.54mlTrain batch 22/31 - 93.8ms/batch - loss: 17.39245 - diff: 10.39mlTrain batch 23/31 - 96.4ms/batch - loss: 16.75554 - diff: 10.18mlTrain batch 24/31 - 94.5ms/batch - loss: 16.32720 - diff: 10.10mlTrain batch 25/31 - 113.3ms/batch - loss: 15.91846 - diff: 10.00mlTrain batch 26/31 - 94.8ms/batch - loss: 15.64294 - diff: 9.94mlTrain batch 27/31 - 109.6ms/batch - loss: 15.47974 - diff: 9.91mlTrain batch 28/31 - 93.8ms/batch - loss: 15.45818 - diff: 10.01mlTrain batch 29/31 - 93.8ms/batch - loss: 15.26286 - diff: 9.98mlTrain batch 30/31 - 93.9ms/batch - loss: 15.19934 - diff: 10.05mlTrain batch 31/31 - 67.3ms/batch - loss: 15.34882 - diff: 10.02mlTrain batch 31/31 - 9.7s 67.3ms/batch - loss: 15.34882 - diff: 10.02ml
Test 0.7s: val_loss: 30.76594 - diff: 15.94ml

Epoch 95: current best loss = 19.29070, at epoch 82
Train batch 1/31 - 100.5ms/batch - loss: 5.32053 - diff: 6.65mlTrain batch 2/31 - 99.1ms/batch - loss: 5.70969 - diff: 7.36mlTrain batch 3/31 - 98.2ms/batch - loss: 6.30530 - diff: 7.58mlTrain batch 4/31 - 97.6ms/batch - loss: 6.78962 - diff: 8.04mlTrain batch 5/31 - 97.1ms/batch - loss: 6.41665 - diff: 8.03mlTrain batch 6/31 - 99.5ms/batch - loss: 7.12356 - diff: 8.45mlTrain batch 7/31 - 98.0ms/batch - loss: 11.12639 - diff: 10.36mlTrain batch 8/31 - 114.2ms/batch - loss: 11.54882 - diff: 10.55mlTrain batch 9/31 - 98.1ms/batch - loss: 10.71112 - diff: 10.04mlTrain batch 10/31 - 96.1ms/batch - loss: 11.77588 - diff: 10.34mlTrain batch 11/31 - 101.3ms/batch - loss: 11.11713 - diff: 9.91mlTrain batch 12/31 - 94.6ms/batch - loss: 10.65680 - diff: 9.71mlTrain batch 13/31 - 99.6ms/batch - loss: 10.52840 - diff: 9.71mlTrain batch 14/31 - 94.4ms/batch - loss: 10.32324 - diff: 9.70mlTrain batch 15/31 - 102.3ms/batch - loss: 10.71138 - diff: 9.89mlTrain batch 16/31 - 102.2ms/batch - loss: 10.60654 - diff: 9.93mlTrain batch 17/31 - 94.5ms/batch - loss: 10.18948 - diff: 9.69mlTrain batch 18/31 - 95.8ms/batch - loss: 9.89860 - diff: 9.60mlTrain batch 19/31 - 93.8ms/batch - loss: 9.95436 - diff: 9.60mlTrain batch 20/31 - 96.3ms/batch - loss: 10.25904 - diff: 9.59mlTrain batch 21/31 - 93.6ms/batch - loss: 9.94146 - diff: 9.42mlTrain batch 22/31 - 94.8ms/batch - loss: 9.98760 - diff: 9.41mlTrain batch 23/31 - 93.5ms/batch - loss: 10.00496 - diff: 9.44mlTrain batch 24/31 - 94.4ms/batch - loss: 9.69158 - diff: 9.26mlTrain batch 25/31 - 94.9ms/batch - loss: 9.72661 - diff: 9.36mlTrain batch 26/31 - 95.3ms/batch - loss: 9.55294 - diff: 9.32mlTrain batch 27/31 - 94.2ms/batch - loss: 9.51451 - diff: 9.31mlTrain batch 28/31 - 95.3ms/batch - loss: 9.41305 - diff: 9.28mlTrain batch 29/31 - 93.5ms/batch - loss: 9.27560 - diff: 9.23mlTrain batch 30/31 - 93.7ms/batch - loss: 9.24791 - diff: 9.22mlTrain batch 31/31 - 68.7ms/batch - loss: 9.28622 - diff: 9.20mlTrain batch 31/31 - 9.7s 68.7ms/batch - loss: 9.28622 - diff: 9.20ml
Test 0.6s: val_loss: 27.27930 - diff: 14.13ml

Epoch 96: current best loss = 19.29070, at epoch 82
Train batch 1/31 - 116.0ms/batch - loss: 9.93534 - diff: 11.11mlTrain batch 2/31 - 94.8ms/batch - loss: 11.29990 - diff: 11.72mlTrain batch 3/31 - 107.6ms/batch - loss: 9.45319 - diff: 10.40mlTrain batch 4/31 - 93.4ms/batch - loss: 8.01557 - diff: 9.33mlTrain batch 5/31 - 95.7ms/batch - loss: 9.12328 - diff: 9.70mlTrain batch 6/31 - 93.7ms/batch - loss: 9.10997 - diff: 9.45mlTrain batch 7/31 - 104.0ms/batch - loss: 8.82744 - diff: 9.26mlTrain batch 8/31 - 93.7ms/batch - loss: 8.32089 - diff: 9.05mlTrain batch 9/31 - 101.3ms/batch - loss: 7.84412 - diff: 8.73mlTrain batch 10/31 - 93.7ms/batch - loss: 7.68934 - diff: 8.68mlTrain batch 11/31 - 100.6ms/batch - loss: 8.35043 - diff: 8.99mlTrain batch 12/31 - 94.2ms/batch - loss: 8.25074 - diff: 8.97mlTrain batch 13/31 - 96.6ms/batch - loss: 8.29243 - diff: 8.92mlTrain batch 14/31 - 94.3ms/batch - loss: 8.02221 - diff: 8.77mlTrain batch 15/31 - 97.1ms/batch - loss: 7.97430 - diff: 8.76mlTrain batch 16/31 - 93.6ms/batch - loss: 7.73208 - diff: 8.61mlTrain batch 17/31 - 100.1ms/batch - loss: 7.69316 - diff: 8.53mlTrain batch 18/31 - 93.2ms/batch - loss: 7.70086 - diff: 8.57mlTrain batch 19/31 - 94.4ms/batch - loss: 8.12705 - diff: 8.83mlTrain batch 20/31 - 94.6ms/batch - loss: 8.16839 - diff: 8.81mlTrain batch 21/31 - 93.5ms/batch - loss: 7.90496 - diff: 8.66mlTrain batch 22/31 - 94.0ms/batch - loss: 8.27382 - diff: 8.87mlTrain batch 23/31 - 97.6ms/batch - loss: 8.13413 - diff: 8.79mlTrain batch 24/31 - 93.9ms/batch - loss: 7.97731 - diff: 8.69mlTrain batch 25/31 - 108.6ms/batch - loss: 7.87635 - diff: 8.65mlTrain batch 26/31 - 95.5ms/batch - loss: 7.78035 - diff: 8.59mlTrain batch 27/31 - 94.1ms/batch - loss: 7.81027 - diff: 8.64mlTrain batch 28/31 - 94.1ms/batch - loss: 7.71682 - diff: 8.55mlTrain batch 29/31 - 94.1ms/batch - loss: 7.72530 - diff: 8.55mlTrain batch 30/31 - 93.8ms/batch - loss: 7.61818 - diff: 8.50mlTrain batch 31/31 - 67.5ms/batch - loss: 7.89237 - diff: 8.52mlTrain batch 31/31 - 9.7s 67.5ms/batch - loss: 7.89237 - diff: 8.52ml
Test 0.7s: val_loss: 24.63723 - diff: 14.39ml

Epoch 97: current best loss = 19.29070, at epoch 82
Train batch 1/31 - 117.4ms/batch - loss: 20.68220 - diff: 14.99mlTrain batch 2/31 - 98.4ms/batch - loss: 16.65085 - diff: 13.34mlTrain batch 3/31 - 109.7ms/batch - loss: 13.72034 - diff: 11.43mlTrain batch 4/31 - 96.3ms/batch - loss: 13.07798 - diff: 11.38mlTrain batch 5/31 - 96.8ms/batch - loss: 11.62858 - diff: 10.68mlTrain batch 6/31 - 93.9ms/batch - loss: 10.94056 - diff: 10.40mlTrain batch 7/31 - 94.8ms/batch - loss: 9.95552 - diff: 9.84mlTrain batch 8/31 - 95.0ms/batch - loss: 9.26985 - diff: 9.53mlTrain batch 9/31 - 99.6ms/batch - loss: 9.55076 - diff: 9.73mlTrain batch 10/31 - 95.6ms/batch - loss: 9.11909 - diff: 9.40mlTrain batch 11/31 - 95.8ms/batch - loss: 10.18534 - diff: 9.81mlTrain batch 12/31 - 96.2ms/batch - loss: 9.64937 - diff: 9.48mlTrain batch 13/31 - 98.3ms/batch - loss: 9.45778 - diff: 9.38mlTrain batch 14/31 - 98.1ms/batch - loss: 9.12328 - diff: 9.23mlTrain batch 15/31 - 94.2ms/batch - loss: 9.16925 - diff: 9.29mlTrain batch 16/31 - 93.9ms/batch - loss: 9.44968 - diff: 9.43mlTrain batch 17/31 - 98.7ms/batch - loss: 9.15708 - diff: 9.31mlTrain batch 18/31 - 97.4ms/batch - loss: 8.90028 - diff: 9.15mlTrain batch 19/31 - 94.3ms/batch - loss: 8.70585 - diff: 9.04mlTrain batch 20/31 - 93.5ms/batch - loss: 9.76327 - diff: 9.48mlTrain batch 21/31 - 94.7ms/batch - loss: 10.23423 - diff: 9.58mlTrain batch 22/31 - 102.0ms/batch - loss: 9.86716 - diff: 9.37mlTrain batch 23/31 - 94.0ms/batch - loss: 9.83722 - diff: 9.41mlTrain batch 24/31 - 95.7ms/batch - loss: 9.89715 - diff: 9.47mlTrain batch 25/31 - 94.5ms/batch - loss: 9.68082 - diff: 9.35mlTrain batch 26/31 - 95.2ms/batch - loss: 9.73424 - diff: 9.40mlTrain batch 27/31 - 94.7ms/batch - loss: 9.66428 - diff: 9.37mlTrain batch 28/31 - 96.5ms/batch - loss: 9.64465 - diff: 9.41mlTrain batch 29/31 - 94.1ms/batch - loss: 9.52886 - diff: 9.38mlTrain batch 30/31 - 96.6ms/batch - loss: 9.35181 - diff: 9.28mlTrain batch 31/31 - 68.2ms/batch - loss: 9.27206 - diff: 9.21mlTrain batch 31/31 - 9.8s 68.2ms/batch - loss: 9.27206 - diff: 9.21ml
Test 0.7s: val_loss: 23.85881 - diff: 14.39ml

Epoch 98: current best loss = 19.29070, at epoch 82
Train batch 1/31 - 99.7ms/batch - loss: 40.85156 - diff: 22.89mlTrain batch 2/31 - 93.9ms/batch - loss: 26.42936 - diff: 15.79mlTrain batch 3/31 - 95.1ms/batch - loss: 19.98406 - diff: 12.88mlTrain batch 4/31 - 94.0ms/batch - loss: 16.72405 - diff: 11.88mlTrain batch 5/31 - 94.7ms/batch - loss: 13.92244 - diff: 10.53mlTrain batch 6/31 - 94.1ms/batch - loss: 12.58380 - diff: 9.97mlTrain batch 7/31 - 94.5ms/batch - loss: 11.41572 - diff: 9.58mlTrain batch 8/31 - 94.1ms/batch - loss: 10.81285 - diff: 9.32mlTrain batch 9/31 - 94.1ms/batch - loss: 10.10526 - diff: 8.94mlTrain batch 10/31 - 93.9ms/batch - loss: 9.44098 - diff: 8.62mlTrain batch 11/31 - 94.9ms/batch - loss: 9.51810 - diff: 8.85mlTrain batch 12/31 - 95.5ms/batch - loss: 9.68118 - diff: 9.00mlTrain batch 13/31 - 94.1ms/batch - loss: 9.77873 - diff: 9.23mlTrain batch 14/31 - 94.7ms/batch - loss: 9.60577 - diff: 9.13mlTrain batch 15/31 - 94.8ms/batch - loss: 9.11080 - diff: 8.85mlTrain batch 16/31 - 94.2ms/batch - loss: 9.20097 - diff: 9.00mlTrain batch 17/31 - 94.4ms/batch - loss: 9.08981 - diff: 9.01mlTrain batch 18/31 - 96.7ms/batch - loss: 9.02744 - diff: 9.02mlTrain batch 19/31 - 93.3ms/batch - loss: 9.14040 - diff: 9.11mlTrain batch 20/31 - 94.1ms/batch - loss: 9.47130 - diff: 9.23mlTrain batch 21/31 - 93.7ms/batch - loss: 9.75474 - diff: 9.42mlTrain batch 22/31 - 94.4ms/batch - loss: 9.51252 - diff: 9.25mlTrain batch 23/31 - 94.0ms/batch - loss: 9.46795 - diff: 9.27mlTrain batch 24/31 - 94.4ms/batch - loss: 9.50162 - diff: 9.34mlTrain batch 25/31 - 94.1ms/batch - loss: 9.74198 - diff: 9.54mlTrain batch 26/31 - 94.3ms/batch - loss: 9.50663 - diff: 9.40mlTrain batch 27/31 - 93.8ms/batch - loss: 10.02916 - diff: 9.71mlTrain batch 28/31 - 95.1ms/batch - loss: 9.82617 - diff: 9.61mlTrain batch 29/31 - 93.5ms/batch - loss: 10.06796 - diff: 9.79mlTrain batch 30/31 - 94.8ms/batch - loss: 9.80172 - diff: 9.62mlTrain batch 31/31 - 70.0ms/batch - loss: 10.16640 - diff: 9.65mlTrain batch 31/31 - 9.8s 70.0ms/batch - loss: 10.16640 - diff: 9.65ml
Test 0.7s: val_loss: 25.21169 - diff: 14.22ml

Epoch 99: current best loss = 19.29070, at epoch 82
Train batch 1/31 - 100.0ms/batch - loss: 3.26039 - diff: 5.39mlTrain batch 2/31 - 93.8ms/batch - loss: 3.59086 - diff: 5.82mlTrain batch 3/31 - 104.3ms/batch - loss: 5.18610 - diff: 7.25mlTrain batch 4/31 - 93.3ms/batch - loss: 6.34534 - diff: 8.17mlTrain batch 5/31 - 101.1ms/batch - loss: 5.44563 - diff: 7.46mlTrain batch 6/31 - 94.1ms/batch - loss: 5.55827 - diff: 7.41mlTrain batch 7/31 - 103.2ms/batch - loss: 6.45017 - diff: 8.04mlTrain batch 8/31 - 94.2ms/batch - loss: 6.65082 - diff: 8.09mlTrain batch 9/31 - 101.9ms/batch - loss: 6.23116 - diff: 7.78mlTrain batch 10/31 - 93.9ms/batch - loss: 9.30590 - diff: 9.21mlTrain batch 11/31 - 109.1ms/batch - loss: 8.91908 - diff: 8.97mlTrain batch 12/31 - 93.7ms/batch - loss: 8.69376 - diff: 8.89mlTrain batch 13/31 - 94.9ms/batch - loss: 8.34550 - diff: 8.63mlTrain batch 14/31 - 95.8ms/batch - loss: 8.34157 - diff: 8.64mlTrain batch 15/31 - 111.1ms/batch - loss: 8.08422 - diff: 8.52mlTrain batch 16/31 - 93.9ms/batch - loss: 7.69805 - diff: 8.28mlTrain batch 17/31 - 94.6ms/batch - loss: 7.58007 - diff: 8.29mlTrain batch 18/31 - 96.3ms/batch - loss: 7.55620 - diff: 8.25mlTrain batch 19/31 - 102.7ms/batch - loss: 7.52792 - diff: 8.28mlTrain batch 20/31 - 99.6ms/batch - loss: 7.93915 - diff: 8.52mlTrain batch 21/31 - 93.8ms/batch - loss: 8.02688 - diff: 8.60mlTrain batch 22/31 - 93.5ms/batch - loss: 7.96246 - diff: 8.62mlTrain batch 23/31 - 97.7ms/batch - loss: 7.74281 - diff: 8.45mlTrain batch 24/31 - 96.2ms/batch - loss: 7.77840 - diff: 8.47mlTrain batch 25/31 - 106.7ms/batch - loss: 7.76281 - diff: 8.46mlTrain batch 26/31 - 94.6ms/batch - loss: 7.61950 - diff: 8.38mlTrain batch 27/31 - 102.6ms/batch - loss: 7.47080 - diff: 8.30mlTrain batch 28/31 - 93.5ms/batch - loss: 7.42088 - diff: 8.29mlTrain batch 29/31 - 95.1ms/batch - loss: 8.63385 - diff: 8.82mlTrain batch 30/31 - 94.1ms/batch - loss: 8.46101 - diff: 8.70mlTrain batch 31/31 - 68.4ms/batch - loss: 8.60599 - diff: 8.72mlTrain batch 31/31 - 9.8s 68.4ms/batch - loss: 8.60599 - diff: 8.72ml
Test 0.7s: val_loss: 23.32780 - diff: 13.98ml

Epoch 100: current best loss = 19.29070, at epoch 82
Train batch 1/31 - 130.1ms/batch - loss: 6.53238 - diff: 9.20mlTrain batch 2/31 - 95.5ms/batch - loss: 5.76516 - diff: 8.57mlTrain batch 3/31 - 116.4ms/batch - loss: 8.92445 - diff: 9.93mlTrain batch 4/31 - 94.0ms/batch - loss: 7.76166 - diff: 9.09mlTrain batch 5/31 - 98.0ms/batch - loss: 7.85608 - diff: 9.28mlTrain batch 6/31 - 96.4ms/batch - loss: 7.28373 - diff: 8.94mlTrain batch 7/31 - 98.2ms/batch - loss: 7.14470 - diff: 8.94mlTrain batch 8/31 - 96.1ms/batch - loss: 6.94821 - diff: 8.75mlTrain batch 9/31 - 97.8ms/batch - loss: 6.77385 - diff: 8.64mlTrain batch 10/31 - 108.1ms/batch - loss: 6.37940 - diff: 8.38mlTrain batch 11/31 - 99.2ms/batch - loss: 6.16386 - diff: 8.13mlTrain batch 12/31 - 96.6ms/batch - loss: 6.11736 - diff: 8.13mlTrain batch 13/31 - 98.6ms/batch - loss: 6.09485 - diff: 8.14mlTrain batch 14/31 - 96.3ms/batch - loss: 6.33479 - diff: 8.28mlTrain batch 15/31 - 99.1ms/batch - loss: 6.09523 - diff: 8.09mlTrain batch 16/31 - 101.3ms/batch - loss: 6.39352 - diff: 8.30mlTrain batch 17/31 - 99.9ms/batch - loss: 6.39284 - diff: 8.26mlTrain batch 18/31 - 97.2ms/batch - loss: 6.63441 - diff: 8.36mlTrain batch 19/31 - 115.5ms/batch - loss: 7.17801 - diff: 8.62mlTrain batch 20/31 - 98.4ms/batch - loss: 7.10063 - diff: 8.53mlTrain batch 21/31 - 97.5ms/batch - loss: 7.03175 - diff: 8.48mlTrain batch 22/31 - 97.7ms/batch - loss: 7.34782 - diff: 8.67mlTrain batch 23/31 - 101.5ms/batch - loss: 7.26908 - diff: 8.60mlTrain batch 24/31 - 99.8ms/batch - loss: 7.57963 - diff: 8.78mlTrain batch 25/31 - 96.4ms/batch - loss: 7.37111 - diff: 8.63mlTrain batch 26/31 - 103.3ms/batch - loss: 7.27785 - diff: 8.61mlTrain batch 27/31 - 95.4ms/batch - loss: 7.13288 - diff: 8.51mlTrain batch 28/31 - 114.6ms/batch - loss: 7.10835 - diff: 8.50mlTrain batch 29/31 - 96.8ms/batch - loss: 7.28840 - diff: 8.56mlTrain batch 30/31 - 95.4ms/batch - loss: 7.70953 - diff: 8.78mlTrain batch 31/31 - 69.5ms/batch - loss: 7.79646 - diff: 8.77mlTrain batch 31/31 - 9.8s 69.5ms/batch - loss: 7.79646 - diff: 8.77ml
Test 0.6s: val_loss: 23.64023 - diff: 13.97ml

Epoch 101: current best loss = 19.29070, at epoch 82
Train batch 1/31 - 108.7ms/batch - loss: 6.02652 - diff: 7.70mlTrain batch 2/31 - 93.8ms/batch - loss: 5.58863 - diff: 7.66mlTrain batch 3/31 - 94.9ms/batch - loss: 6.27346 - diff: 8.06mlTrain batch 4/31 - 93.5ms/batch - loss: 6.94913 - diff: 8.51mlTrain batch 5/31 - 93.7ms/batch - loss: 7.12180 - diff: 8.62mlTrain batch 6/31 - 94.0ms/batch - loss: 6.95979 - diff: 8.44mlTrain batch 7/31 - 94.7ms/batch - loss: 6.69196 - diff: 8.31mlTrain batch 8/31 - 93.5ms/batch - loss: 6.27853 - diff: 8.00mlTrain batch 9/31 - 97.3ms/batch - loss: 6.72783 - diff: 8.25mlTrain batch 10/31 - 95.1ms/batch - loss: 7.03153 - diff: 8.37mlTrain batch 11/31 - 99.3ms/batch - loss: 6.79748 - diff: 8.27mlTrain batch 12/31 - 94.2ms/batch - loss: 6.64866 - diff: 8.19mlTrain batch 13/31 - 98.4ms/batch - loss: 6.85370 - diff: 8.36mlTrain batch 14/31 - 94.1ms/batch - loss: 6.69294 - diff: 8.27mlTrain batch 15/31 - 98.0ms/batch - loss: 6.49053 - diff: 8.15mlTrain batch 16/31 - 93.9ms/batch - loss: 6.64651 - diff: 8.16mlTrain batch 17/31 - 97.0ms/batch - loss: 6.72548 - diff: 8.12mlTrain batch 18/31 - 97.4ms/batch - loss: 6.56768 - diff: 8.03mlTrain batch 19/31 - 94.7ms/batch - loss: 6.37360 - diff: 7.88mlTrain batch 20/31 - 95.7ms/batch - loss: 6.23956 - diff: 7.82mlTrain batch 21/31 - 109.9ms/batch - loss: 6.19412 - diff: 7.82mlTrain batch 22/31 - 94.3ms/batch - loss: 6.35836 - diff: 7.86mlTrain batch 23/31 - 96.2ms/batch - loss: 6.38758 - diff: 7.89mlTrain batch 24/31 - 95.3ms/batch - loss: 6.48308 - diff: 8.00mlTrain batch 25/31 - 95.2ms/batch - loss: 6.39902 - diff: 7.94mlTrain batch 26/31 - 95.1ms/batch - loss: 6.47987 - diff: 7.95mlTrain batch 27/31 - 95.2ms/batch - loss: 6.78933 - diff: 8.14mlTrain batch 28/31 - 95.1ms/batch - loss: 6.69286 - diff: 8.07mlTrain batch 29/31 - 99.6ms/batch - loss: 6.64337 - diff: 8.03mlTrain batch 30/31 - 93.6ms/batch - loss: 6.57850 - diff: 7.95mlTrain batch 31/31 - 69.3ms/batch - loss: 6.74493 - diff: 7.98mlTrain batch 31/31 - 9.8s 69.3ms/batch - loss: 6.74493 - diff: 7.98ml
Test 0.7s: val_loss: 24.28111 - diff: 14.69ml

Epoch 102: current best loss = 19.29070, at epoch 82
Train batch 1/31 - 119.9ms/batch - loss: 2.16540 - diff: 4.40mlTrain batch 2/31 - 93.6ms/batch - loss: 4.35152 - diff: 5.92mlTrain batch 3/31 - 101.5ms/batch - loss: 4.17669 - diff: 5.88mlTrain batch 4/31 - 95.9ms/batch - loss: 3.56484 - diff: 5.44mlTrain batch 5/31 - 102.0ms/batch - loss: 4.09437 - diff: 5.87mlTrain batch 6/31 - 96.0ms/batch - loss: 5.65593 - diff: 6.64mlTrain batch 7/31 - 110.9ms/batch - loss: 13.38142 - diff: 9.21mlTrain batch 8/31 - 94.3ms/batch - loss: 12.14198 - diff: 8.73mlTrain batch 9/31 - 107.5ms/batch - loss: 11.30331 - diff: 8.52mlTrain batch 10/31 - 94.2ms/batch - loss: 10.86022 - diff: 8.59mlTrain batch 11/31 - 111.2ms/batch - loss: 10.37432 - diff: 8.52mlTrain batch 12/31 - 94.3ms/batch - loss: 10.34442 - diff: 8.69mlTrain batch 13/31 - 111.4ms/batch - loss: 10.03647 - diff: 8.65mlTrain batch 14/31 - 95.9ms/batch - loss: 10.01703 - diff: 8.67mlTrain batch 15/31 - 108.0ms/batch - loss: 9.50217 - diff: 8.39mlTrain batch 16/31 - 94.8ms/batch - loss: 9.06081 - diff: 8.18mlTrain batch 17/31 - 104.4ms/batch - loss: 8.88405 - diff: 8.05mlTrain batch 18/31 - 94.5ms/batch - loss: 9.13756 - diff: 8.26mlTrain batch 19/31 - 98.1ms/batch - loss: 9.73391 - diff: 8.61mlTrain batch 20/31 - 94.8ms/batch - loss: 9.51340 - diff: 8.48mlTrain batch 21/31 - 106.7ms/batch - loss: 10.25110 - diff: 8.70mlTrain batch 22/31 - 99.7ms/batch - loss: 10.15218 - diff: 8.76mlTrain batch 23/31 - 94.7ms/batch - loss: 9.82366 - diff: 8.60mlTrain batch 24/31 - 96.3ms/batch - loss: 9.60516 - diff: 8.53mlTrain batch 25/31 - 125.7ms/batch - loss: 9.44023 - diff: 8.46mlTrain batch 26/31 - 95.0ms/batch - loss: 9.46571 - diff: 8.44mlTrain batch 27/31 - 106.9ms/batch - loss: 9.43891 - diff: 8.49mlTrain batch 28/31 - 94.3ms/batch - loss: 9.48411 - diff: 8.58mlTrain batch 29/31 - 94.8ms/batch - loss: 9.49967 - diff: 8.64mlTrain batch 30/31 - 94.8ms/batch - loss: 9.56128 - diff: 8.72mlTrain batch 31/31 - 68.0ms/batch - loss: 13.48472 - diff: 9.21mlTrain batch 31/31 - 9.8s 68.0ms/batch - loss: 13.48472 - diff: 9.21ml
Test 0.7s: val_loss: 25.34042 - diff: 14.65ml

Epoch 103: current best loss = 19.29070, at epoch 82
Train batch 1/31 - 107.0ms/batch - loss: 9.93255 - diff: 7.54mlTrain batch 2/31 - 94.3ms/batch - loss: 5.80155 - diff: 5.77mlTrain batch 3/31 - 97.4ms/batch - loss: 5.65100 - diff: 6.38mlTrain batch 4/31 - 93.6ms/batch - loss: 7.02025 - diff: 7.54mlTrain batch 5/31 - 97.8ms/batch - loss: 13.26536 - diff: 9.86mlTrain batch 6/31 - 93.7ms/batch - loss: 13.16917 - diff: 10.21mlTrain batch 7/31 - 97.4ms/batch - loss: 11.98084 - diff: 9.73mlTrain batch 8/31 - 93.9ms/batch - loss: 11.14120 - diff: 9.52mlTrain batch 9/31 - 96.6ms/batch - loss: 10.82454 - diff: 9.50mlTrain batch 10/31 - 94.6ms/batch - loss: 10.57323 - diff: 9.38mlTrain batch 11/31 - 98.6ms/batch - loss: 10.01032 - diff: 9.15mlTrain batch 12/31 - 93.8ms/batch - loss: 10.33513 - diff: 9.33mlTrain batch 13/31 - 104.5ms/batch - loss: 10.07189 - diff: 9.34mlTrain batch 14/31 - 93.6ms/batch - loss: 10.11856 - diff: 9.30mlTrain batch 15/31 - 97.9ms/batch - loss: 10.22686 - diff: 9.50mlTrain batch 16/31 - 93.7ms/batch - loss: 10.00147 - diff: 9.43mlTrain batch 17/31 - 97.2ms/batch - loss: 9.74432 - diff: 9.30mlTrain batch 18/31 - 94.4ms/batch - loss: 9.47383 - diff: 9.19mlTrain batch 19/31 - 95.9ms/batch - loss: 10.74419 - diff: 9.65mlTrain batch 20/31 - 94.5ms/batch - loss: 12.23591 - diff: 10.27mlTrain batch 21/31 - 98.5ms/batch - loss: 12.00546 - diff: 10.20mlTrain batch 22/31 - 97.0ms/batch - loss: 11.70872 - diff: 10.08mlTrain batch 23/31 - 97.4ms/batch - loss: 11.35623 - diff: 9.91mlTrain batch 24/31 - 94.2ms/batch - loss: 11.48183 - diff: 10.03mlTrain batch 25/31 - 97.1ms/batch - loss: 11.11213 - diff: 9.83mlTrain batch 26/31 - 94.3ms/batch - loss: 10.95616 - diff: 9.81mlTrain batch 27/31 - 98.1ms/batch - loss: 10.67476 - diff: 9.65mlTrain batch 28/31 - 93.5ms/batch - loss: 11.21682 - diff: 10.00mlTrain batch 29/31 - 96.0ms/batch - loss: 11.13396 - diff: 9.97mlTrain batch 30/31 - 93.4ms/batch - loss: 11.07149 - diff: 9.96mlTrain batch 31/31 - 67.8ms/batch - loss: 11.05047 - diff: 9.91mlTrain batch 31/31 - 9.8s 67.8ms/batch - loss: 11.05047 - diff: 9.91ml
Test 0.6s: val_loss: 25.17822 - diff: 14.45ml

Epoch 104: current best loss = 19.29070, at epoch 82
Train batch 1/31 - 119.4ms/batch - loss: 2.21319 - diff: 4.75mlTrain batch 2/31 - 93.8ms/batch - loss: 7.10122 - diff: 7.81mlTrain batch 3/31 - 112.7ms/batch - loss: 6.48824 - diff: 7.71mlTrain batch 4/31 - 93.2ms/batch - loss: 6.34077 - diff: 7.89mlTrain batch 5/31 - 107.3ms/batch - loss: 7.29421 - diff: 8.56mlTrain batch 6/31 - 94.8ms/batch - loss: 7.18754 - diff: 8.58mlTrain batch 7/31 - 108.0ms/batch - loss: 7.38317 - diff: 8.58mlTrain batch 8/31 - 93.5ms/batch - loss: 6.93381 - diff: 8.35mlTrain batch 9/31 - 97.7ms/batch - loss: 7.70766 - diff: 8.49mlTrain batch 10/31 - 94.7ms/batch - loss: 7.59853 - diff: 8.47mlTrain batch 11/31 - 95.2ms/batch - loss: 8.60900 - diff: 8.94mlTrain batch 12/31 - 94.1ms/batch - loss: 8.28791 - diff: 8.73mlTrain batch 13/31 - 97.2ms/batch - loss: 8.14060 - diff: 8.61mlTrain batch 14/31 - 95.8ms/batch - loss: 10.31173 - diff: 9.67mlTrain batch 15/31 - 95.1ms/batch - loss: 9.78814 - diff: 9.34mlTrain batch 16/31 - 95.3ms/batch - loss: 9.42516 - diff: 9.15mlTrain batch 17/31 - 95.1ms/batch - loss: 9.88416 - diff: 9.44mlTrain batch 18/31 - 95.1ms/batch - loss: 9.61942 - diff: 9.30mlTrain batch 19/31 - 94.3ms/batch - loss: 9.77674 - diff: 9.34mlTrain batch 20/31 - 94.2ms/batch - loss: 9.94863 - diff: 9.49mlTrain batch 21/31 - 93.1ms/batch - loss: 9.72555 - diff: 9.32mlTrain batch 22/31 - 93.9ms/batch - loss: 9.61385 - diff: 9.31mlTrain batch 23/31 - 100.2ms/batch - loss: 9.43221 - diff: 9.22mlTrain batch 24/31 - 95.0ms/batch - loss: 9.12359 - diff: 9.03mlTrain batch 25/31 - 95.1ms/batch - loss: 9.05210 - diff: 9.03mlTrain batch 26/31 - 94.8ms/batch - loss: 8.85686 - diff: 8.94mlTrain batch 27/31 - 94.4ms/batch - loss: 9.18873 - diff: 9.16mlTrain batch 28/31 - 93.9ms/batch - loss: 8.99900 - diff: 9.04mlTrain batch 29/31 - 93.1ms/batch - loss: 8.89810 - diff: 9.00mlTrain batch 30/31 - 94.3ms/batch - loss: 9.48683 - diff: 9.14mlTrain batch 31/31 - 67.5ms/batch - loss: 9.60153 - diff: 9.14mlTrain batch 31/31 - 9.9s 67.5ms/batch - loss: 9.60153 - diff: 9.14ml
Test 0.7s: val_loss: 23.33409 - diff: 14.02ml
Epoch   105: reducing learning rate of group 0 to 6.2500e-05.

Epoch 105: current best loss = 19.29070, at epoch 82
Train batch 1/31 - 117.7ms/batch - loss: 5.02357 - diff: 6.79mlTrain batch 2/31 - 95.5ms/batch - loss: 8.14969 - diff: 9.45mlTrain batch 3/31 - 102.9ms/batch - loss: 8.69549 - diff: 10.10mlTrain batch 4/31 - 94.3ms/batch - loss: 8.69235 - diff: 9.71mlTrain batch 5/31 - 95.2ms/batch - loss: 7.45385 - diff: 8.79mlTrain batch 6/31 - 94.4ms/batch - loss: 7.48734 - diff: 8.70mlTrain batch 7/31 - 96.1ms/batch - loss: 7.39048 - diff: 8.79mlTrain batch 8/31 - 94.7ms/batch - loss: 7.30947 - diff: 8.76mlTrain batch 9/31 - 101.9ms/batch - loss: 7.09820 - diff: 8.63mlTrain batch 10/31 - 98.0ms/batch - loss: 6.80927 - diff: 8.43mlTrain batch 11/31 - 105.1ms/batch - loss: 6.66135 - diff: 8.26mlTrain batch 12/31 - 94.7ms/batch - loss: 6.71459 - diff: 8.28mlTrain batch 13/31 - 94.5ms/batch - loss: 6.63953 - diff: 8.18mlTrain batch 14/31 - 94.6ms/batch - loss: 6.86134 - diff: 8.34mlTrain batch 15/31 - 102.7ms/batch - loss: 6.83593 - diff: 8.33mlTrain batch 16/31 - 97.8ms/batch - loss: 7.05534 - diff: 8.49mlTrain batch 17/31 - 94.5ms/batch - loss: 7.00429 - diff: 8.39mlTrain batch 18/31 - 96.9ms/batch - loss: 7.15093 - diff: 8.50mlTrain batch 19/31 - 106.3ms/batch - loss: 7.16997 - diff: 8.54mlTrain batch 20/31 - 97.4ms/batch - loss: 6.94700 - diff: 8.37mlTrain batch 21/31 - 95.3ms/batch - loss: 7.21932 - diff: 8.47mlTrain batch 22/31 - 94.1ms/batch - loss: 7.03430 - diff: 8.36mlTrain batch 23/31 - 99.6ms/batch - loss: 6.91156 - diff: 8.28mlTrain batch 24/31 - 99.2ms/batch - loss: 6.88028 - diff: 8.24mlTrain batch 25/31 - 94.5ms/batch - loss: 6.81906 - diff: 8.21mlTrain batch 26/31 - 96.2ms/batch - loss: 6.82517 - diff: 8.17mlTrain batch 27/31 - 96.1ms/batch - loss: 6.76496 - diff: 8.13mlTrain batch 28/31 - 94.3ms/batch - loss: 6.81025 - diff: 8.22mlTrain batch 29/31 - 94.1ms/batch - loss: 6.83934 - diff: 8.23mlTrain batch 30/31 - 94.0ms/batch - loss: 6.94007 - diff: 8.30mlTrain batch 31/31 - 68.6ms/batch - loss: 7.10276 - diff: 8.32mlTrain batch 31/31 - 9.8s 68.6ms/batch - loss: 7.10276 - diff: 8.32ml
Test 0.6s: val_loss: 23.51075 - diff: 13.97ml

Epoch 106: current best loss = 19.29070, at epoch 82
Train batch 1/31 - 108.6ms/batch - loss: 5.18670 - diff: 7.82mlTrain batch 2/31 - 95.1ms/batch - loss: 4.79071 - diff: 7.05mlTrain batch 3/31 - 98.8ms/batch - loss: 4.31932 - diff: 6.62mlTrain batch 4/31 - 94.4ms/batch - loss: 4.85959 - diff: 6.78mlTrain batch 5/31 - 98.1ms/batch - loss: 6.06499 - diff: 7.34mlTrain batch 6/31 - 95.8ms/batch - loss: 5.92038 - diff: 7.34mlTrain batch 7/31 - 94.6ms/batch - loss: 6.69986 - diff: 7.99mlTrain batch 8/31 - 93.7ms/batch - loss: 6.75041 - diff: 8.05mlTrain batch 9/31 - 95.3ms/batch - loss: 6.54247 - diff: 7.92mlTrain batch 10/31 - 93.9ms/batch - loss: 6.13401 - diff: 7.63mlTrain batch 11/31 - 94.7ms/batch - loss: 6.30591 - diff: 7.89mlTrain batch 12/31 - 93.9ms/batch - loss: 6.10383 - diff: 7.78mlTrain batch 13/31 - 94.6ms/batch - loss: 6.35227 - diff: 7.95mlTrain batch 14/31 - 96.3ms/batch - loss: 6.15949 - diff: 7.85mlTrain batch 15/31 - 95.2ms/batch - loss: 6.07130 - diff: 7.81mlTrain batch 16/31 - 95.1ms/batch - loss: 6.14989 - diff: 7.89mlTrain batch 17/31 - 94.2ms/batch - loss: 6.02590 - diff: 7.82mlTrain batch 18/31 - 96.0ms/batch - loss: 6.19124 - diff: 7.88mlTrain batch 19/31 - 95.1ms/batch - loss: 6.16755 - diff: 7.90mlTrain batch 20/31 - 94.8ms/batch - loss: 6.37887 - diff: 7.94mlTrain batch 21/31 - 95.3ms/batch - loss: 6.36054 - diff: 7.96mlTrain batch 22/31 - 95.1ms/batch - loss: 6.21049 - diff: 7.85mlTrain batch 23/31 - 95.0ms/batch - loss: 6.02709 - diff: 7.71mlTrain batch 24/31 - 98.3ms/batch - loss: 5.91122 - diff: 7.66mlTrain batch 25/31 - 93.3ms/batch - loss: 5.73960 - diff: 7.50mlTrain batch 26/31 - 94.4ms/batch - loss: 5.71183 - diff: 7.47mlTrain batch 27/31 - 94.2ms/batch - loss: 6.06852 - diff: 7.67mlTrain batch 28/31 - 94.0ms/batch - loss: 6.01088 - diff: 7.65mlTrain batch 29/31 - 93.8ms/batch - loss: 6.00732 - diff: 7.67mlTrain batch 30/31 - 93.5ms/batch - loss: 5.94571 - diff: 7.64mlTrain batch 31/31 - 73.9ms/batch - loss: 6.04843 - diff: 7.63mlTrain batch 31/31 - 9.8s 73.9ms/batch - loss: 6.04843 - diff: 7.63ml
Test 0.6s: val_loss: 22.99635 - diff: 14.22ml

Epoch 107: current best loss = 19.29070, at epoch 82
Train batch 1/31 - 118.5ms/batch - loss: 3.35756 - diff: 6.12mlTrain batch 2/31 - 93.6ms/batch - loss: 4.84713 - diff: 6.40mlTrain batch 3/31 - 113.7ms/batch - loss: 6.20138 - diff: 7.66mlTrain batch 4/31 - 94.3ms/batch - loss: 5.52538 - diff: 7.29mlTrain batch 5/31 - 109.6ms/batch - loss: 5.21841 - diff: 7.09mlTrain batch 6/31 - 94.0ms/batch - loss: 5.73946 - diff: 7.52mlTrain batch 7/31 - 113.1ms/batch - loss: 5.38445 - diff: 7.29mlTrain batch 8/31 - 93.8ms/batch - loss: 5.36873 - diff: 7.24mlTrain batch 9/31 - 95.9ms/batch - loss: 5.10394 - diff: 7.03mlTrain batch 10/31 - 94.5ms/batch - loss: 5.16279 - diff: 7.06mlTrain batch 11/31 - 105.7ms/batch - loss: 5.37685 - diff: 7.27mlTrain batch 12/31 - 93.7ms/batch - loss: 5.78478 - diff: 7.58mlTrain batch 13/31 - 95.9ms/batch - loss: 5.62619 - diff: 7.42mlTrain batch 14/31 - 94.3ms/batch - loss: 5.67862 - diff: 7.50mlTrain batch 15/31 - 110.8ms/batch - loss: 5.74664 - diff: 7.56mlTrain batch 16/31 - 93.9ms/batch - loss: 5.86061 - diff: 7.67mlTrain batch 17/31 - 93.4ms/batch - loss: 5.85637 - diff: 7.63mlTrain batch 18/31 - 94.5ms/batch - loss: 6.30082 - diff: 7.82mlTrain batch 19/31 - 100.9ms/batch - loss: 6.64743 - diff: 8.07mlTrain batch 20/31 - 94.1ms/batch - loss: 8.16424 - diff: 8.58mlTrain batch 21/31 - 93.6ms/batch - loss: 7.99446 - diff: 8.48mlTrain batch 22/31 - 93.7ms/batch - loss: 8.09983 - diff: 8.62mlTrain batch 23/31 - 93.3ms/batch - loss: 7.91451 - diff: 8.54mlTrain batch 24/31 - 94.1ms/batch - loss: 7.80886 - diff: 8.50mlTrain batch 25/31 - 101.1ms/batch - loss: 7.63202 - diff: 8.40mlTrain batch 26/31 - 97.5ms/batch - loss: 8.35101 - diff: 8.83mlTrain batch 27/31 - 93.5ms/batch - loss: 8.25192 - diff: 8.79mlTrain batch 28/31 - 93.7ms/batch - loss: 8.07751 - diff: 8.70mlTrain batch 29/31 - 93.9ms/batch - loss: 7.90651 - diff: 8.59mlTrain batch 30/31 - 94.2ms/batch - loss: 7.80053 - diff: 8.55mlTrain batch 31/31 - 69.1ms/batch - loss: 8.68677 - diff: 8.70mlTrain batch 31/31 - 9.8s 69.1ms/batch - loss: 8.68677 - diff: 8.70ml
Test 0.7s: val_loss: 22.94341 - diff: 14.25ml

Epoch 108: current best loss = 19.29070, at epoch 82
Train batch 1/31 - 123.8ms/batch - loss: 2.78096 - diff: 5.26mlTrain batch 2/31 - 94.6ms/batch - loss: 2.75024 - diff: 5.36mlTrain batch 3/31 - 96.2ms/batch - loss: 9.74938 - diff: 9.48mlTrain batch 4/31 - 94.4ms/batch - loss: 8.26033 - diff: 8.53mlTrain batch 5/31 - 94.1ms/batch - loss: 7.91918 - diff: 8.30mlTrain batch 6/31 - 96.2ms/batch - loss: 7.58947 - diff: 8.22mlTrain batch 7/31 - 94.4ms/batch - loss: 7.40284 - diff: 8.17mlTrain batch 8/31 - 94.3ms/batch - loss: 8.48808 - diff: 8.86mlTrain batch 9/31 - 94.2ms/batch - loss: 8.48492 - diff: 8.88mlTrain batch 10/31 - 94.2ms/batch - loss: 7.98662 - diff: 8.63mlTrain batch 11/31 - 94.0ms/batch - loss: 7.64288 - diff: 8.35mlTrain batch 12/31 - 94.0ms/batch - loss: 7.34414 - diff: 8.21mlTrain batch 13/31 - 104.8ms/batch - loss: 7.19855 - diff: 8.12mlTrain batch 14/31 - 96.6ms/batch - loss: 6.84067 - diff: 7.86mlTrain batch 15/31 - 93.7ms/batch - loss: 7.32465 - diff: 8.12mlTrain batch 16/31 - 95.6ms/batch - loss: 7.53816 - diff: 8.25mlTrain batch 17/31 - 94.2ms/batch - loss: 7.52255 - diff: 8.21mlTrain batch 18/31 - 94.0ms/batch - loss: 7.47525 - diff: 8.23mlTrain batch 19/31 - 97.8ms/batch - loss: 7.41869 - diff: 8.20mlTrain batch 20/31 - 94.7ms/batch - loss: 7.47573 - diff: 8.28mlTrain batch 21/31 - 94.1ms/batch - loss: 7.39586 - diff: 8.26mlTrain batch 22/31 - 94.0ms/batch - loss: 7.22409 - diff: 8.15mlTrain batch 23/31 - 93.5ms/batch - loss: 7.12831 - diff: 8.11mlTrain batch 24/31 - 95.4ms/batch - loss: 7.30111 - diff: 8.12mlTrain batch 25/31 - 101.4ms/batch - loss: 7.20874 - diff: 8.09mlTrain batch 26/31 - 97.7ms/batch - loss: 7.20478 - diff: 8.12mlTrain batch 27/31 - 94.1ms/batch - loss: 7.17314 - diff: 8.10mlTrain batch 28/31 - 94.7ms/batch - loss: 7.24460 - diff: 8.17mlTrain batch 29/31 - 94.0ms/batch - loss: 7.76927 - diff: 8.34mlTrain batch 30/31 - 95.5ms/batch - loss: 7.58253 - diff: 8.22mlTrain batch 31/31 - 67.9ms/batch - loss: 7.62322 - diff: 8.21mlTrain batch 31/31 - 9.9s 67.9ms/batch - loss: 7.62322 - diff: 8.21ml
Test 0.7s: val_loss: 26.69940 - diff: 14.33ml

Epoch 109: current best loss = 19.29070, at epoch 82
Train batch 1/31 - 109.4ms/batch - loss: 5.09296 - diff: 7.24mlTrain batch 2/31 - 94.6ms/batch - loss: 5.95760 - diff: 7.96mlTrain batch 3/31 - 94.3ms/batch - loss: 5.87096 - diff: 7.63mlTrain batch 4/31 - 116.1ms/batch - loss: 6.25399 - diff: 7.89mlTrain batch 5/31 - 93.9ms/batch - loss: 6.05049 - diff: 7.62mlTrain batch 6/31 - 112.8ms/batch - loss: 5.35357 - diff: 7.05mlTrain batch 7/31 - 93.9ms/batch - loss: 5.52848 - diff: 7.24mlTrain batch 8/31 - 95.2ms/batch - loss: 6.49140 - diff: 7.83mlTrain batch 9/31 - 95.0ms/batch - loss: 6.35961 - diff: 7.79mlTrain batch 10/31 - 95.8ms/batch - loss: 6.84825 - diff: 8.12mlTrain batch 11/31 - 94.5ms/batch - loss: 6.48221 - diff: 7.84mlTrain batch 12/31 - 96.1ms/batch - loss: 7.19465 - diff: 8.38mlTrain batch 13/31 - 93.8ms/batch - loss: 7.22800 - diff: 8.45mlTrain batch 14/31 - 96.3ms/batch - loss: 7.00274 - diff: 8.30mlTrain batch 15/31 - 94.6ms/batch - loss: 6.70433 - diff: 8.10mlTrain batch 16/31 - 96.9ms/batch - loss: 6.67412 - diff: 8.07mlTrain batch 17/31 - 93.8ms/batch - loss: 6.95422 - diff: 8.10mlTrain batch 18/31 - 96.5ms/batch - loss: 6.80939 - diff: 8.02mlTrain batch 19/31 - 94.0ms/batch - loss: 6.68768 - diff: 7.97mlTrain batch 20/31 - 95.8ms/batch - loss: 6.55064 - diff: 7.90mlTrain batch 21/31 - 94.0ms/batch - loss: 6.36276 - diff: 7.78mlTrain batch 22/31 - 95.8ms/batch - loss: 6.37146 - diff: 7.80mlTrain batch 23/31 - 93.8ms/batch - loss: 6.49913 - diff: 7.92mlTrain batch 24/31 - 94.0ms/batch - loss: 6.42399 - diff: 7.88mlTrain batch 25/31 - 96.8ms/batch - loss: 6.40308 - diff: 7.88mlTrain batch 26/31 - 125.5ms/batch - loss: 6.32421 - diff: 7.82mlTrain batch 27/31 - 94.5ms/batch - loss: 6.25274 - diff: 7.76mlTrain batch 28/31 - 94.2ms/batch - loss: 6.36081 - diff: 7.82mlTrain batch 29/31 - 93.8ms/batch - loss: 6.73986 - diff: 7.96mlTrain batch 30/31 - 95.3ms/batch - loss: 6.62039 - diff: 7.90mlTrain batch 31/31 - 69.8ms/batch - loss: 6.83872 - diff: 7.95mlTrain batch 31/31 - 9.9s 69.8ms/batch - loss: 6.83872 - diff: 7.95ml
Test 0.6s: val_loss: 25.04984 - diff: 14.21ml

Epoch 110: current best loss = 19.29070, at epoch 82
Train batch 1/31 - 106.9ms/batch - loss: 5.00716 - diff: 6.19mlTrain batch 2/31 - 93.6ms/batch - loss: 4.30234 - diff: 6.46mlTrain batch 3/31 - 97.3ms/batch - loss: 5.06846 - diff: 6.97mlTrain batch 4/31 - 94.4ms/batch - loss: 5.56731 - diff: 7.39mlTrain batch 5/31 - 93.7ms/batch - loss: 5.14927 - diff: 7.11mlTrain batch 6/31 - 94.8ms/batch - loss: 5.33282 - diff: 7.30mlTrain batch 7/31 - 104.6ms/batch - loss: 5.46082 - diff: 7.29mlTrain batch 8/31 - 95.1ms/batch - loss: 5.03831 - diff: 6.97mlTrain batch 9/31 - 94.7ms/batch - loss: 5.07460 - diff: 7.00mlTrain batch 10/31 - 93.5ms/batch - loss: 6.46585 - diff: 7.87mlTrain batch 11/31 - 100.1ms/batch - loss: 6.38481 - diff: 7.82mlTrain batch 12/31 - 94.4ms/batch - loss: 6.69539 - diff: 7.90mlTrain batch 13/31 - 97.3ms/batch - loss: 7.09078 - diff: 8.19mlTrain batch 14/31 - 93.6ms/batch - loss: 7.07298 - diff: 8.20mlTrain batch 15/31 - 95.1ms/batch - loss: 6.78227 - diff: 7.97mlTrain batch 16/31 - 93.3ms/batch - loss: 6.73572 - diff: 7.87mlTrain batch 17/31 - 95.2ms/batch - loss: 6.49774 - diff: 7.74mlTrain batch 18/31 - 94.3ms/batch - loss: 6.66073 - diff: 7.92mlTrain batch 19/31 - 95.0ms/batch - loss: 6.46856 - diff: 7.77mlTrain batch 20/31 - 95.0ms/batch - loss: 6.40655 - diff: 7.75mlTrain batch 21/31 - 94.3ms/batch - loss: 6.28239 - diff: 7.68mlTrain batch 22/31 - 94.2ms/batch - loss: 6.36899 - diff: 7.75mlTrain batch 23/31 - 95.8ms/batch - loss: 6.44531 - diff: 7.89mlTrain batch 24/31 - 94.0ms/batch - loss: 6.40216 - diff: 7.87mlTrain batch 25/31 - 93.7ms/batch - loss: 6.24689 - diff: 7.76mlTrain batch 26/31 - 94.4ms/batch - loss: 6.26302 - diff: 7.78mlTrain batch 27/31 - 100.9ms/batch - loss: 6.18040 - diff: 7.72mlTrain batch 28/31 - 93.6ms/batch - loss: 6.09476 - diff: 7.67mlTrain batch 29/31 - 94.1ms/batch - loss: 5.95858 - diff: 7.55mlTrain batch 30/31 - 93.5ms/batch - loss: 5.92349 - diff: 7.54mlTrain batch 31/31 - 68.3ms/batch - loss: 6.14456 - diff: 7.60mlTrain batch 31/31 - 9.8s 68.3ms/batch - loss: 6.14456 - diff: 7.60ml
Test 0.7s: val_loss: 25.11094 - diff: 14.69ml

Epoch 111: current best loss = 19.29070, at epoch 82
Train batch 1/31 - 104.6ms/batch - loss: 8.87123 - diff: 8.79mlTrain batch 2/31 - 94.6ms/batch - loss: 10.82941 - diff: 10.89mlTrain batch 3/31 - 95.9ms/batch - loss: 14.19688 - diff: 11.64mlTrain batch 4/31 - 94.5ms/batch - loss: 11.52995 - diff: 10.37mlTrain batch 5/31 - 93.7ms/batch - loss: 9.89015 - diff: 9.55mlTrain batch 6/31 - 94.3ms/batch - loss: 9.42246 - diff: 9.27mlTrain batch 7/31 - 99.9ms/batch - loss: 9.17750 - diff: 9.28mlTrain batch 8/31 - 94.7ms/batch - loss: 8.63224 - diff: 8.95mlTrain batch 9/31 - 108.6ms/batch - loss: 10.58389 - diff: 9.79mlTrain batch 10/31 - 93.6ms/batch - loss: 9.78594 - diff: 9.30mlTrain batch 11/31 - 97.6ms/batch - loss: 9.21094 - diff: 9.03mlTrain batch 12/31 - 94.6ms/batch - loss: 8.79193 - diff: 8.83mlTrain batch 13/31 - 95.6ms/batch - loss: 8.37628 - diff: 8.57mlTrain batch 14/31 - 96.0ms/batch - loss: 7.97544 - diff: 8.33mlTrain batch 15/31 - 94.6ms/batch - loss: 8.43132 - diff: 8.53mlTrain batch 16/31 - 94.7ms/batch - loss: 8.29016 - diff: 8.44mlTrain batch 17/31 - 106.0ms/batch - loss: 8.03587 - diff: 8.33mlTrain batch 18/31 - 94.0ms/batch - loss: 8.00841 - diff: 8.36mlTrain batch 19/31 - 107.0ms/batch - loss: 7.85959 - diff: 8.30mlTrain batch 20/31 - 95.0ms/batch - loss: 7.87707 - diff: 8.33mlTrain batch 21/31 - 95.7ms/batch - loss: 7.71791 - diff: 8.24mlTrain batch 22/31 - 95.0ms/batch - loss: 7.54381 - diff: 8.17mlTrain batch 23/31 - 103.2ms/batch - loss: 7.43944 - diff: 8.08mlTrain batch 24/31 - 94.2ms/batch - loss: 7.25285 - diff: 7.98mlTrain batch 25/31 - 96.9ms/batch - loss: 7.23134 - diff: 8.01mlTrain batch 26/31 - 94.0ms/batch - loss: 8.22767 - diff: 8.46mlTrain batch 27/31 - 105.6ms/batch - loss: 8.12844 - diff: 8.44mlTrain batch 28/31 - 98.5ms/batch - loss: 7.97182 - diff: 8.36mlTrain batch 29/31 - 96.6ms/batch - loss: 8.01984 - diff: 8.43mlTrain batch 30/31 - 93.6ms/batch - loss: 7.92938 - diff: 8.40mlTrain batch 31/31 - 68.1ms/batch - loss: 7.99878 - diff: 8.36mlTrain batch 31/31 - 9.9s 68.1ms/batch - loss: 7.99878 - diff: 8.36ml
Test 0.7s: val_loss: 25.08344 - diff: 14.11ml

Epoch 112: current best loss = 19.29070, at epoch 82
Train batch 1/31 - 99.0ms/batch - loss: 5.01712 - diff: 7.66mlTrain batch 2/31 - 94.7ms/batch - loss: 5.09190 - diff: 7.32mlTrain batch 3/31 - 94.8ms/batch - loss: 4.97062 - diff: 7.30mlTrain batch 4/31 - 117.4ms/batch - loss: 5.10269 - diff: 7.40mlTrain batch 5/31 - 94.8ms/batch - loss: 5.21476 - diff: 7.52mlTrain batch 6/31 - 107.8ms/batch - loss: 4.92222 - diff: 7.31mlTrain batch 7/31 - 94.5ms/batch - loss: 5.45159 - diff: 7.63mlTrain batch 8/31 - 111.5ms/batch - loss: 5.53790 - diff: 7.59mlTrain batch 9/31 - 96.6ms/batch - loss: 6.16041 - diff: 7.89mlTrain batch 10/31 - 101.7ms/batch - loss: 5.82722 - diff: 7.62mlTrain batch 11/31 - 95.3ms/batch - loss: 6.66580 - diff: 8.21mlTrain batch 12/31 - 96.9ms/batch - loss: 6.32061 - diff: 7.95mlTrain batch 13/31 - 94.2ms/batch - loss: 6.01009 - diff: 7.73mlTrain batch 14/31 - 99.1ms/batch - loss: 5.97243 - diff: 7.69mlTrain batch 15/31 - 94.9ms/batch - loss: 6.43288 - diff: 7.96mlTrain batch 16/31 - 96.1ms/batch - loss: 6.70406 - diff: 8.17mlTrain batch 17/31 - 93.8ms/batch - loss: 6.80915 - diff: 8.30mlTrain batch 18/31 - 95.9ms/batch - loss: 6.60554 - diff: 8.16mlTrain batch 19/31 - 95.0ms/batch - loss: 6.54266 - diff: 8.06mlTrain batch 20/31 - 94.7ms/batch - loss: 6.68547 - diff: 8.20mlTrain batch 21/31 - 93.9ms/batch - loss: 6.87050 - diff: 8.33mlTrain batch 22/31 - 100.2ms/batch - loss: 6.71751 - diff: 8.21mlTrain batch 23/31 - 93.8ms/batch - loss: 6.72886 - diff: 8.25mlTrain batch 24/31 - 95.7ms/batch - loss: 6.48107 - diff: 8.02mlTrain batch 25/31 - 95.4ms/batch - loss: 7.01416 - diff: 8.35mlTrain batch 26/31 - 95.5ms/batch - loss: 6.92247 - diff: 8.26mlTrain batch 27/31 - 97.3ms/batch - loss: 6.92736 - diff: 8.30mlTrain batch 28/31 - 100.2ms/batch - loss: 7.11367 - diff: 8.36mlTrain batch 29/31 - 93.9ms/batch - loss: 7.12586 - diff: 8.38mlTrain batch 30/31 - 95.1ms/batch - loss: 7.04969 - diff: 8.33mlTrain batch 31/31 - 69.0ms/batch - loss: 7.52146 - diff: 8.42mlTrain batch 31/31 - 9.8s 69.0ms/batch - loss: 7.52146 - diff: 8.42ml
Test 0.7s: val_loss: 23.43831 - diff: 14.19ml

Epoch 113: current best loss = 19.29070, at epoch 82
Train batch 1/31 - 100.1ms/batch - loss: 14.23774 - diff: 12.08mlTrain batch 2/31 - 93.5ms/batch - loss: 10.67861 - diff: 10.44mlTrain batch 3/31 - 96.6ms/batch - loss: 8.58133 - diff: 9.07mlTrain batch 4/31 - 95.9ms/batch - loss: 7.95626 - diff: 8.72mlTrain batch 5/31 - 97.8ms/batch - loss: 7.63856 - diff: 8.62mlTrain batch 6/31 - 94.2ms/batch - loss: 6.94992 - diff: 8.21mlTrain batch 7/31 - 94.7ms/batch - loss: 7.58843 - diff: 8.68mlTrain batch 8/31 - 93.3ms/batch - loss: 7.79463 - diff: 9.03mlTrain batch 9/31 - 95.1ms/batch - loss: 7.78040 - diff: 8.93mlTrain batch 10/31 - 93.5ms/batch - loss: 7.92767 - diff: 9.05mlTrain batch 11/31 - 94.7ms/batch - loss: 7.76251 - diff: 8.91mlTrain batch 12/31 - 93.7ms/batch - loss: 7.30560 - diff: 8.57mlTrain batch 13/31 - 94.0ms/batch - loss: 6.86890 - diff: 8.23mlTrain batch 14/31 - 93.8ms/batch - loss: 6.87485 - diff: 8.23mlTrain batch 15/31 - 93.4ms/batch - loss: 6.54797 - diff: 8.00mlTrain batch 16/31 - 96.0ms/batch - loss: 6.30913 - diff: 7.84mlTrain batch 17/31 - 93.7ms/batch - loss: 6.29917 - diff: 7.87mlTrain batch 18/31 - 94.9ms/batch - loss: 6.87042 - diff: 8.20mlTrain batch 19/31 - 93.9ms/batch - loss: 6.80645 - diff: 8.20mlTrain batch 20/31 - 94.2ms/batch - loss: 7.20103 - diff: 8.35mlTrain batch 21/31 - 94.0ms/batch - loss: 6.98837 - diff: 8.19mlTrain batch 22/31 - 94.8ms/batch - loss: 6.85664 - diff: 8.10mlTrain batch 23/31 - 93.7ms/batch - loss: 6.70664 - diff: 7.99mlTrain batch 24/31 - 93.9ms/batch - loss: 6.72927 - diff: 8.01mlTrain batch 25/31 - 94.0ms/batch - loss: 6.56530 - diff: 7.90mlTrain batch 26/31 - 94.4ms/batch - loss: 6.53329 - diff: 7.88mlTrain batch 27/31 - 95.4ms/batch - loss: 6.47985 - diff: 7.87mlTrain batch 28/31 - 94.4ms/batch - loss: 6.32433 - diff: 7.75mlTrain batch 29/31 - 96.0ms/batch - loss: 6.19656 - diff: 7.67mlTrain batch 30/31 - 93.4ms/batch - loss: 6.04047 - diff: 7.56mlTrain batch 31/31 - 71.6ms/batch - loss: 6.13581 - diff: 7.56mlTrain batch 31/31 - 9.9s 71.6ms/batch - loss: 6.13581 - diff: 7.56ml
Test 0.6s: val_loss: 25.23008 - diff: 14.24ml

Epoch 114: current best loss = 19.29070, at epoch 82
Train batch 1/31 - 102.7ms/batch - loss: 3.96683 - diff: 6.31mlTrain batch 2/31 - 94.2ms/batch - loss: 4.47346 - diff: 6.65mlTrain batch 3/31 - 99.9ms/batch - loss: 5.96072 - diff: 7.78mlTrain batch 4/31 - 94.0ms/batch - loss: 5.05541 - diff: 7.13mlTrain batch 5/31 - 101.4ms/batch - loss: 4.72722 - diff: 6.97mlTrain batch 6/31 - 95.9ms/batch - loss: 5.68469 - diff: 7.57mlTrain batch 7/31 - 96.4ms/batch - loss: 5.08462 - diff: 7.06mlTrain batch 8/31 - 94.6ms/batch - loss: 4.92250 - diff: 6.95mlTrain batch 9/31 - 99.9ms/batch - loss: 4.64252 - diff: 6.66mlTrain batch 10/31 - 95.3ms/batch - loss: 5.14183 - diff: 6.95mlTrain batch 11/31 - 97.2ms/batch - loss: 5.00679 - diff: 6.92mlTrain batch 12/31 - 94.4ms/batch - loss: 5.44479 - diff: 7.14mlTrain batch 13/31 - 106.4ms/batch - loss: 5.25194 - diff: 6.99mlTrain batch 14/31 - 94.2ms/batch - loss: 4.99421 - diff: 6.80mlTrain batch 15/31 - 96.1ms/batch - loss: 5.19719 - diff: 6.91mlTrain batch 16/31 - 94.6ms/batch - loss: 5.76171 - diff: 7.33mlTrain batch 17/31 - 98.0ms/batch - loss: 5.67265 - diff: 7.30mlTrain batch 18/31 - 96.5ms/batch - loss: 5.58566 - diff: 7.24mlTrain batch 19/31 - 96.0ms/batch - loss: 5.48496 - diff: 7.17mlTrain batch 20/31 - 94.8ms/batch - loss: 5.53914 - diff: 7.29mlTrain batch 21/31 - 94.2ms/batch - loss: 5.51985 - diff: 7.27mlTrain batch 22/31 - 94.9ms/batch - loss: 5.36487 - diff: 7.15mlTrain batch 23/31 - 94.4ms/batch - loss: 5.44114 - diff: 7.15mlTrain batch 24/31 - 94.2ms/batch - loss: 5.34097 - diff: 7.06mlTrain batch 25/31 - 94.6ms/batch - loss: 5.48240 - diff: 7.16mlTrain batch 26/31 - 94.9ms/batch - loss: 5.39832 - diff: 7.12mlTrain batch 27/31 - 94.3ms/batch - loss: 5.42262 - diff: 7.15mlTrain batch 28/31 - 93.9ms/batch - loss: 5.48064 - diff: 7.23mlTrain batch 29/31 - 102.0ms/batch - loss: 5.54807 - diff: 7.31mlTrain batch 30/31 - 94.6ms/batch - loss: 5.63603 - diff: 7.32mlTrain batch 31/31 - 76.3ms/batch - loss: 5.63698 - diff: 7.30mlTrain batch 31/31 - 9.8s 76.3ms/batch - loss: 5.63698 - diff: 7.30ml
Test 0.6s: val_loss: 23.73283 - diff: 14.29ml

Epoch 115: current best loss = 19.29070, at epoch 82
Train batch 1/31 - 99.0ms/batch - loss: 4.96361 - diff: 6.65mlTrain batch 2/31 - 93.8ms/batch - loss: 3.19999 - diff: 5.27mlTrain batch 3/31 - 93.8ms/batch - loss: 4.91515 - diff: 6.47mlTrain batch 4/31 - 95.3ms/batch - loss: 4.79615 - diff: 6.61mlTrain batch 5/31 - 93.8ms/batch - loss: 5.71593 - diff: 7.22mlTrain batch 6/31 - 96.4ms/batch - loss: 5.13083 - diff: 6.84mlTrain batch 7/31 - 93.8ms/batch - loss: 5.37096 - diff: 7.17mlTrain batch 8/31 - 94.3ms/batch - loss: 5.84505 - diff: 7.40mlTrain batch 9/31 - 96.4ms/batch - loss: 7.52481 - diff: 8.22mlTrain batch 10/31 - 94.2ms/batch - loss: 7.25807 - diff: 8.14mlTrain batch 11/31 - 94.9ms/batch - loss: 7.40055 - diff: 8.27mlTrain batch 12/31 - 94.1ms/batch - loss: 7.25952 - diff: 8.16mlTrain batch 13/31 - 94.9ms/batch - loss: 7.67131 - diff: 8.29mlTrain batch 14/31 - 94.8ms/batch - loss: 7.99058 - diff: 8.55mlTrain batch 15/31 - 94.3ms/batch - loss: 7.66877 - diff: 8.38mlTrain batch 16/31 - 96.1ms/batch - loss: 7.22605 - diff: 8.01mlTrain batch 17/31 - 94.2ms/batch - loss: 7.37964 - diff: 8.19mlTrain batch 18/31 - 95.9ms/batch - loss: 7.11767 - diff: 7.97mlTrain batch 19/31 - 94.1ms/batch - loss: 7.40847 - diff: 8.24mlTrain batch 20/31 - 96.8ms/batch - loss: 7.26421 - diff: 8.17mlTrain batch 21/31 - 94.2ms/batch - loss: 7.01888 - diff: 8.00mlTrain batch 22/31 - 95.4ms/batch - loss: 6.82704 - diff: 7.87mlTrain batch 23/31 - 94.9ms/batch - loss: 7.07760 - diff: 7.92mlTrain batch 24/31 - 95.5ms/batch - loss: 7.08223 - diff: 7.95mlTrain batch 25/31 - 94.1ms/batch - loss: 7.07108 - diff: 7.91mlTrain batch 26/31 - 96.2ms/batch - loss: 6.93833 - diff: 7.85mlTrain batch 27/31 - 94.2ms/batch - loss: 7.01661 - diff: 7.96mlTrain batch 28/31 - 95.9ms/batch - loss: 6.97136 - diff: 7.93mlTrain batch 29/31 - 94.1ms/batch - loss: 6.97046 - diff: 7.99mlTrain batch 30/31 - 95.0ms/batch - loss: 6.80812 - diff: 7.87mlTrain batch 31/31 - 83.5ms/batch - loss: 8.86869 - diff: 8.17mlTrain batch 31/31 - 9.8s 83.5ms/batch - loss: 8.86869 - diff: 8.17ml
Test 0.8s: val_loss: 23.72714 - diff: 14.13ml
Epoch   116: reducing learning rate of group 0 to 3.1250e-05.

Epoch 116: current best loss = 19.29070, at epoch 82
Train batch 1/31 - 119.9ms/batch - loss: 4.51655 - diff: 7.39mlTrain batch 2/31 - 93.6ms/batch - loss: 4.86636 - diff: 7.16mlTrain batch 3/31 - 94.7ms/batch - loss: 4.65564 - diff: 6.96mlTrain batch 4/31 - 94.0ms/batch - loss: 5.47225 - diff: 7.35mlTrain batch 5/31 - 95.9ms/batch - loss: 6.14036 - diff: 7.63mlTrain batch 6/31 - 94.2ms/batch - loss: 5.63180 - diff: 7.30mlTrain batch 7/31 - 96.0ms/batch - loss: 5.14028 - diff: 6.87mlTrain batch 8/31 - 94.2ms/batch - loss: 5.00990 - diff: 6.84mlTrain batch 9/31 - 96.6ms/batch - loss: 5.18058 - diff: 7.01mlTrain batch 10/31 - 93.7ms/batch - loss: 4.86892 - diff: 6.75mlTrain batch 11/31 - 95.4ms/batch - loss: 4.59775 - diff: 6.52mlTrain batch 12/31 - 94.4ms/batch - loss: 4.48518 - diff: 6.42mlTrain batch 13/31 - 102.7ms/batch - loss: 4.56748 - diff: 6.36mlTrain batch 14/31 - 94.3ms/batch - loss: 4.63482 - diff: 6.48mlTrain batch 15/31 - 111.0ms/batch - loss: 4.45709 - diff: 6.36mlTrain batch 16/31 - 93.7ms/batch - loss: 4.42815 - diff: 6.30mlTrain batch 17/31 - 114.1ms/batch - loss: 6.67526 - diff: 6.66mlTrain batch 18/31 - 93.5ms/batch - loss: 6.50456 - diff: 6.60mlTrain batch 19/31 - 109.8ms/batch - loss: 6.40410 - diff: 6.65mlTrain batch 20/31 - 94.4ms/batch - loss: 6.23977 - diff: 6.62mlTrain batch 21/31 - 108.6ms/batch - loss: 6.33005 - diff: 6.75mlTrain batch 22/31 - 94.1ms/batch - loss: 6.43909 - diff: 6.84mlTrain batch 23/31 - 104.9ms/batch - loss: 6.36868 - diff: 6.85mlTrain batch 24/31 - 94.0ms/batch - loss: 6.35733 - diff: 6.88mlTrain batch 25/31 - 96.2ms/batch - loss: 6.38313 - diff: 6.92mlTrain batch 26/31 - 94.8ms/batch - loss: 6.24486 - diff: 6.88mlTrain batch 27/31 - 102.3ms/batch - loss: 6.37820 - diff: 7.05mlTrain batch 28/31 - 93.8ms/batch - loss: 6.30949 - diff: 7.02mlTrain batch 29/31 - 93.7ms/batch - loss: 6.27719 - diff: 7.04mlTrain batch 30/31 - 93.9ms/batch - loss: 6.28299 - diff: 7.07mlTrain batch 31/31 - 72.5ms/batch - loss: 6.33263 - diff: 7.07mlTrain batch 31/31 - 9.7s 72.5ms/batch - loss: 6.33263 - diff: 7.07ml
Test 0.9s: val_loss: 23.71605 - diff: 14.03ml

Epoch 117: current best loss = 19.29070, at epoch 82
Train batch 1/31 - 118.7ms/batch - loss: 5.66393 - diff: 7.80mlTrain batch 2/31 - 94.7ms/batch - loss: 8.74242 - diff: 7.56mlTrain batch 3/31 - 97.0ms/batch - loss: 11.18006 - diff: 9.42mlTrain batch 4/31 - 94.2ms/batch - loss: 8.96010 - diff: 8.27mlTrain batch 5/31 - 99.7ms/batch - loss: 7.94578 - diff: 7.80mlTrain batch 6/31 - 95.3ms/batch - loss: 7.01714 - diff: 7.35mlTrain batch 7/31 - 115.6ms/batch - loss: 6.58530 - diff: 7.22mlTrain batch 8/31 - 96.5ms/batch - loss: 6.45564 - diff: 7.21mlTrain batch 9/31 - 98.2ms/batch - loss: 6.23060 - diff: 7.17mlTrain batch 10/31 - 97.6ms/batch - loss: 6.01067 - diff: 7.08mlTrain batch 11/31 - 99.5ms/batch - loss: 6.09551 - diff: 7.21mlTrain batch 12/31 - 95.8ms/batch - loss: 7.00046 - diff: 7.85mlTrain batch 13/31 - 100.7ms/batch - loss: 8.09195 - diff: 8.03mlTrain batch 14/31 - 101.4ms/batch - loss: 7.79408 - diff: 7.91mlTrain batch 15/31 - 95.8ms/batch - loss: 7.59516 - diff: 7.86mlTrain batch 16/31 - 97.5ms/batch - loss: 7.36473 - diff: 7.78mlTrain batch 17/31 - 120.4ms/batch - loss: 7.35963 - diff: 7.82mlTrain batch 18/31 - 94.1ms/batch - loss: 7.24881 - diff: 7.78mlTrain batch 19/31 - 97.1ms/batch - loss: 7.26411 - diff: 7.77mlTrain batch 20/31 - 95.5ms/batch - loss: 7.40804 - diff: 7.94mlTrain batch 21/31 - 97.9ms/batch - loss: 7.25905 - diff: 7.87mlTrain batch 22/31 - 97.3ms/batch - loss: 7.41786 - diff: 8.00mlTrain batch 23/31 - 99.6ms/batch - loss: 7.28820 - diff: 7.95mlTrain batch 24/31 - 103.5ms/batch - loss: 7.24842 - diff: 7.90mlTrain batch 25/31 - 95.9ms/batch - loss: 7.14429 - diff: 7.89mlTrain batch 26/31 - 96.8ms/batch - loss: 7.21501 - diff: 7.94mlTrain batch 27/31 - 95.3ms/batch - loss: 7.11800 - diff: 7.89mlTrain batch 28/31 - 96.7ms/batch - loss: 7.03030 - diff: 7.86mlTrain batch 29/31 - 95.2ms/batch - loss: 6.86521 - diff: 7.77mlTrain batch 30/31 - 99.1ms/batch - loss: 7.57238 - diff: 8.14mlTrain batch 31/31 - 68.1ms/batch - loss: 7.92557 - diff: 8.21mlTrain batch 31/31 - 9.7s 68.1ms/batch - loss: 7.92557 - diff: 8.21ml
Test 0.7s: val_loss: 22.52341 - diff: 14.04ml

Epoch 118: current best loss = 19.29070, at epoch 82
Train batch 1/31 - 109.8ms/batch - loss: 4.93045 - diff: 7.73mlTrain batch 2/31 - 93.8ms/batch - loss: 5.51473 - diff: 7.66mlTrain batch 3/31 - 96.2ms/batch - loss: 4.42770 - diff: 6.65mlTrain batch 4/31 - 93.9ms/batch - loss: 13.85413 - diff: 8.98mlTrain batch 5/31 - 97.0ms/batch - loss: 12.39291 - diff: 8.77mlTrain batch 6/31 - 93.9ms/batch - loss: 11.17795 - diff: 8.58mlTrain batch 7/31 - 99.2ms/batch - loss: 10.56334 - diff: 8.58mlTrain batch 8/31 - 93.8ms/batch - loss: 10.23191 - diff: 8.64mlTrain batch 9/31 - 105.3ms/batch - loss: 9.81565 - diff: 8.55mlTrain batch 10/31 - 94.0ms/batch - loss: 10.11414 - diff: 9.03mlTrain batch 11/31 - 97.6ms/batch - loss: 9.82328 - diff: 9.03mlTrain batch 12/31 - 93.8ms/batch - loss: 9.29543 - diff: 8.73mlTrain batch 13/31 - 94.5ms/batch - loss: 8.88145 - diff: 8.58mlTrain batch 14/31 - 95.8ms/batch - loss: 8.67668 - diff: 8.52mlTrain batch 15/31 - 94.8ms/batch - loss: 8.31038 - diff: 8.34mlTrain batch 16/31 - 94.8ms/batch - loss: 8.30935 - diff: 8.35mlTrain batch 17/31 - 98.4ms/batch - loss: 8.09618 - diff: 8.24mlTrain batch 18/31 - 93.7ms/batch - loss: 7.76449 - diff: 8.00mlTrain batch 19/31 - 95.0ms/batch - loss: 7.74105 - diff: 8.01mlTrain batch 20/31 - 96.2ms/batch - loss: 7.94678 - diff: 8.20mlTrain batch 21/31 - 95.5ms/batch - loss: 7.76320 - diff: 8.10mlTrain batch 22/31 - 94.5ms/batch - loss: 7.61051 - diff: 8.09mlTrain batch 23/31 - 94.9ms/batch - loss: 7.39103 - diff: 7.98mlTrain batch 24/31 - 95.8ms/batch - loss: 7.21432 - diff: 7.90mlTrain batch 25/31 - 94.1ms/batch - loss: 7.18898 - diff: 7.85mlTrain batch 26/31 - 94.8ms/batch - loss: 7.06720 - diff: 7.82mlTrain batch 27/31 - 94.8ms/batch - loss: 6.99480 - diff: 7.81mlTrain batch 28/31 - 95.0ms/batch - loss: 6.84265 - diff: 7.72mlTrain batch 29/31 - 93.8ms/batch - loss: 6.98008 - diff: 7.85mlTrain batch 30/31 - 94.4ms/batch - loss: 6.93566 - diff: 7.84mlTrain batch 31/31 - 68.8ms/batch - loss: 6.96863 - diff: 7.83mlTrain batch 31/31 - 9.8s 68.8ms/batch - loss: 6.96863 - diff: 7.83ml
Test 0.7s: val_loss: 22.26474 - diff: 13.88ml

Epoch 119: current best loss = 19.29070, at epoch 82
Train batch 1/31 - 99.6ms/batch - loss: 4.78934 - diff: 6.78mlTrain batch 2/31 - 93.6ms/batch - loss: 5.57842 - diff: 6.61mlTrain batch 3/31 - 110.9ms/batch - loss: 6.09107 - diff: 7.42mlTrain batch 4/31 - 97.3ms/batch - loss: 5.53154 - diff: 7.39mlTrain batch 5/31 - 101.6ms/batch - loss: 5.09132 - diff: 6.99mlTrain batch 6/31 - 95.5ms/batch - loss: 6.05167 - diff: 7.86mlTrain batch 7/31 - 108.0ms/batch - loss: 7.11117 - diff: 8.64mlTrain batch 8/31 - 95.3ms/batch - loss: 6.75450 - diff: 8.45mlTrain batch 9/31 - 107.3ms/batch - loss: 6.44642 - diff: 8.24mlTrain batch 10/31 - 94.4ms/batch - loss: 6.20402 - diff: 8.07mlTrain batch 11/31 - 114.9ms/batch - loss: 5.91005 - diff: 7.84mlTrain batch 12/31 - 94.4ms/batch - loss: 5.76969 - diff: 7.72mlTrain batch 13/31 - 100.2ms/batch - loss: 7.89949 - diff: 8.59mlTrain batch 14/31 - 94.3ms/batch - loss: 7.94988 - diff: 8.65mlTrain batch 15/31 - 107.1ms/batch - loss: 7.74170 - diff: 8.45mlTrain batch 16/31 - 94.9ms/batch - loss: 7.46509 - diff: 8.28mlTrain batch 17/31 - 97.7ms/batch - loss: 7.68098 - diff: 8.48mlTrain batch 18/31 - 97.0ms/batch - loss: 7.38960 - diff: 8.29mlTrain batch 19/31 - 99.8ms/batch - loss: 7.36708 - diff: 8.30mlTrain batch 20/31 - 106.5ms/batch - loss: 7.35251 - diff: 8.34mlTrain batch 21/31 - 100.8ms/batch - loss: 7.40454 - diff: 8.42mlTrain batch 22/31 - 96.6ms/batch - loss: 7.64464 - diff: 8.58mlTrain batch 23/31 - 95.9ms/batch - loss: 7.59388 - diff: 8.54mlTrain batch 24/31 - 95.9ms/batch - loss: 7.45864 - diff: 8.47mlTrain batch 25/31 - 99.6ms/batch - loss: 7.34735 - diff: 8.39mlTrain batch 26/31 - 97.6ms/batch - loss: 7.23868 - diff: 8.29mlTrain batch 27/31 - 96.5ms/batch - loss: 7.11329 - diff: 8.23mlTrain batch 28/31 - 101.6ms/batch - loss: 7.27648 - diff: 8.22mlTrain batch 29/31 - 97.4ms/batch - loss: 7.07933 - diff: 8.08mlTrain batch 30/31 - 94.5ms/batch - loss: 7.05739 - diff: 8.08mlTrain batch 31/31 - 70.1ms/batch - loss: 7.99089 - diff: 8.22mlTrain batch 31/31 - 9.8s 70.1ms/batch - loss: 7.99089 - diff: 8.22ml
Test 0.6s: val_loss: 23.76752 - diff: 14.27ml

Epoch 120: current best loss = 19.29070, at epoch 82
Train batch 1/31 - 101.5ms/batch - loss: 11.24568 - diff: 10.51mlTrain batch 2/31 - 94.6ms/batch - loss: 7.24128 - diff: 8.35mlTrain batch 3/31 - 94.4ms/batch - loss: 6.98377 - diff: 8.14mlTrain batch 4/31 - 94.4ms/batch - loss: 6.10716 - diff: 7.77mlTrain batch 5/31 - 94.3ms/batch - loss: 7.24647 - diff: 8.00mlTrain batch 6/31 - 94.6ms/batch - loss: 6.30580 - diff: 7.39mlTrain batch 7/31 - 94.2ms/batch - loss: 5.90944 - diff: 7.31mlTrain batch 8/31 - 95.0ms/batch - loss: 6.33121 - diff: 7.58mlTrain batch 9/31 - 94.1ms/batch - loss: 7.03725 - diff: 8.18mlTrain batch 10/31 - 95.2ms/batch - loss: 6.55520 - diff: 7.80mlTrain batch 11/31 - 94.5ms/batch - loss: 6.50661 - diff: 7.84mlTrain batch 12/31 - 94.1ms/batch - loss: 6.24285 - diff: 7.61mlTrain batch 13/31 - 94.1ms/batch - loss: 5.88105 - diff: 7.33mlTrain batch 14/31 - 94.1ms/batch - loss: 5.77409 - diff: 7.21mlTrain batch 15/31 - 95.0ms/batch - loss: 5.77539 - diff: 7.26mlTrain batch 16/31 - 95.4ms/batch - loss: 5.80550 - diff: 7.34mlTrain batch 17/31 - 93.6ms/batch - loss: 5.88293 - diff: 7.44mlTrain batch 18/31 - 93.6ms/batch - loss: 5.84478 - diff: 7.46mlTrain batch 19/31 - 94.0ms/batch - loss: 5.70616 - diff: 7.36mlTrain batch 20/31 - 94.2ms/batch - loss: 5.70120 - diff: 7.39mlTrain batch 21/31 - 94.1ms/batch - loss: 5.51771 - diff: 7.23mlTrain batch 22/31 - 96.4ms/batch - loss: 5.47884 - diff: 7.21mlTrain batch 23/31 - 94.3ms/batch - loss: 5.54632 - diff: 7.29mlTrain batch 24/31 - 94.9ms/batch - loss: 5.52525 - diff: 7.30mlTrain batch 25/31 - 95.1ms/batch - loss: 5.39922 - diff: 7.19mlTrain batch 26/31 - 94.9ms/batch - loss: 5.31631 - diff: 7.14mlTrain batch 27/31 - 95.0ms/batch - loss: 5.24741 - diff: 7.08mlTrain batch 28/31 - 94.8ms/batch - loss: 5.23860 - diff: 7.11mlTrain batch 29/31 - 93.6ms/batch - loss: 5.15687 - diff: 7.04mlTrain batch 30/31 - 94.2ms/batch - loss: 5.18584 - diff: 7.06mlTrain batch 31/31 - 72.1ms/batch - loss: 5.16785 - diff: 7.02mlTrain batch 31/31 - 9.8s 72.1ms/batch - loss: 5.16785 - diff: 7.02ml
Test 0.7s: val_loss: 23.91290 - diff: 14.12ml

Epoch 121: current best loss = 19.29070, at epoch 82
Train batch 1/31 - 111.7ms/batch - loss: 2.53339 - diff: 5.21mlTrain batch 2/31 - 100.5ms/batch - loss: 3.20784 - diff: 5.88mlTrain batch 3/31 - 95.1ms/batch - loss: 3.46444 - diff: 6.16mlTrain batch 4/31 - 94.8ms/batch - loss: 3.92266 - diff: 6.52mlTrain batch 5/31 - 94.5ms/batch - loss: 4.32361 - diff: 6.70mlTrain batch 6/31 - 95.0ms/batch - loss: 4.88657 - diff: 7.02mlTrain batch 7/31 - 95.5ms/batch - loss: 4.74920 - diff: 6.94mlTrain batch 8/31 - 96.5ms/batch - loss: 4.68511 - diff: 6.84mlTrain batch 9/31 - 94.4ms/batch - loss: 4.65448 - diff: 6.78mlTrain batch 10/31 - 94.8ms/batch - loss: 4.55989 - diff: 6.77mlTrain batch 11/31 - 96.7ms/batch - loss: 5.24188 - diff: 7.33mlTrain batch 12/31 - 94.0ms/batch - loss: 5.12256 - diff: 7.21mlTrain batch 13/31 - 110.0ms/batch - loss: 5.71571 - diff: 7.56mlTrain batch 14/31 - 94.8ms/batch - loss: 5.47499 - diff: 7.38mlTrain batch 15/31 - 97.3ms/batch - loss: 5.28423 - diff: 7.21mlTrain batch 16/31 - 95.3ms/batch - loss: 5.32632 - diff: 7.29mlTrain batch 17/31 - 96.9ms/batch - loss: 5.44464 - diff: 7.37mlTrain batch 18/31 - 95.4ms/batch - loss: 5.43021 - diff: 7.34mlTrain batch 19/31 - 108.9ms/batch - loss: 5.39674 - diff: 7.31mlTrain batch 20/31 - 94.0ms/batch - loss: 5.76136 - diff: 7.53mlTrain batch 21/31 - 96.3ms/batch - loss: 5.68973 - diff: 7.51mlTrain batch 22/31 - 95.5ms/batch - loss: 5.54562 - diff: 7.41mlTrain batch 23/31 - 94.1ms/batch - loss: 5.43957 - diff: 7.36mlTrain batch 24/31 - 95.7ms/batch - loss: 5.39057 - diff: 7.36mlTrain batch 25/31 - 94.4ms/batch - loss: 5.46720 - diff: 7.45mlTrain batch 26/31 - 94.7ms/batch - loss: 5.65467 - diff: 7.45mlTrain batch 27/31 - 95.0ms/batch - loss: 5.74931 - diff: 7.49mlTrain batch 28/31 - 94.2ms/batch - loss: 5.71113 - diff: 7.48mlTrain batch 29/31 - 94.0ms/batch - loss: 5.59932 - diff: 7.41mlTrain batch 30/31 - 94.5ms/batch - loss: 7.24185 - diff: 7.65mlTrain batch 31/31 - 68.4ms/batch - loss: 7.28228 - diff: 7.65mlTrain batch 31/31 - 9.8s 68.4ms/batch - loss: 7.28228 - diff: 7.65ml
Test 0.7s: val_loss: 26.82683 - diff: 14.29ml

Epoch 122: current best loss = 19.29070, at epoch 82
Train batch 1/31 - 111.0ms/batch - loss: 2.65492 - diff: 5.14mlTrain batch 2/31 - 98.7ms/batch - loss: 4.02565 - diff: 5.90mlTrain batch 3/31 - 95.1ms/batch - loss: 5.26450 - diff: 6.93mlTrain batch 4/31 - 94.1ms/batch - loss: 5.71443 - diff: 7.01mlTrain batch 5/31 - 96.3ms/batch - loss: 6.12084 - diff: 7.29mlTrain batch 6/31 - 94.8ms/batch - loss: 6.67461 - diff: 7.79mlTrain batch 7/31 - 95.5ms/batch - loss: 6.08250 - diff: 7.46mlTrain batch 8/31 - 105.3ms/batch - loss: 5.50701 - diff: 6.99mlTrain batch 9/31 - 95.5ms/batch - loss: 5.41528 - diff: 7.04mlTrain batch 10/31 - 100.5ms/batch - loss: 5.19838 - diff: 6.92mlTrain batch 11/31 - 95.1ms/batch - loss: 5.05761 - diff: 6.87mlTrain batch 12/31 - 98.4ms/batch - loss: 5.05485 - diff: 6.86mlTrain batch 13/31 - 94.9ms/batch - loss: 6.24297 - diff: 7.52mlTrain batch 14/31 - 96.4ms/batch - loss: 6.83434 - diff: 7.99mlTrain batch 15/31 - 95.5ms/batch - loss: 6.50443 - diff: 7.76mlTrain batch 16/31 - 98.9ms/batch - loss: 6.25696 - diff: 7.60mlTrain batch 17/31 - 96.4ms/batch - loss: 6.51377 - diff: 7.69mlTrain batch 18/31 - 97.8ms/batch - loss: 6.53524 - diff: 7.63mlTrain batch 19/31 - 94.7ms/batch - loss: 7.20623 - diff: 8.05mlTrain batch 20/31 - 101.7ms/batch - loss: 7.19069 - diff: 8.07mlTrain batch 21/31 - 94.3ms/batch - loss: 7.17608 - diff: 8.10mlTrain batch 22/31 - 97.9ms/batch - loss: 7.18534 - diff: 8.16mlTrain batch 23/31 - 94.2ms/batch - loss: 6.98672 - diff: 8.05mlTrain batch 24/31 - 100.4ms/batch - loss: 6.85229 - diff: 7.99mlTrain batch 25/31 - 95.2ms/batch - loss: 6.83116 - diff: 7.99mlTrain batch 26/31 - 97.6ms/batch - loss: 6.77244 - diff: 7.94mlTrain batch 27/31 - 94.7ms/batch - loss: 6.74719 - diff: 7.92mlTrain batch 28/31 - 100.2ms/batch - loss: 6.71527 - diff: 7.94mlTrain batch 29/31 - 93.6ms/batch - loss: 7.20051 - diff: 8.18mlTrain batch 30/31 - 101.9ms/batch - loss: 7.10013 - diff: 8.12mlTrain batch 31/31 - 68.0ms/batch - loss: 7.15389 - diff: 8.12mlTrain batch 31/31 - 9.8s 68.0ms/batch - loss: 7.15389 - diff: 8.12ml
Test 0.7s: val_loss: 25.41145 - diff: 14.11ml

Epoch 123: current best loss = 19.29070, at epoch 82
Train batch 1/31 - 120.6ms/batch - loss: 2.88365 - diff: 4.82mlTrain batch 2/31 - 95.1ms/batch - loss: 3.65538 - diff: 5.94mlTrain batch 3/31 - 94.3ms/batch - loss: 3.21880 - diff: 5.57mlTrain batch 4/31 - 94.4ms/batch - loss: 3.32683 - diff: 5.85mlTrain batch 5/31 - 94.8ms/batch - loss: 3.69070 - diff: 6.30mlTrain batch 6/31 - 94.3ms/batch - loss: 3.65659 - diff: 6.35mlTrain batch 7/31 - 94.3ms/batch - loss: 4.09800 - diff: 6.38mlTrain batch 8/31 - 95.1ms/batch - loss: 3.84792 - diff: 6.18mlTrain batch 9/31 - 94.0ms/batch - loss: 4.82645 - diff: 6.92mlTrain batch 10/31 - 95.2ms/batch - loss: 5.44340 - diff: 7.31mlTrain batch 11/31 - 93.5ms/batch - loss: 5.68914 - diff: 7.23mlTrain batch 12/31 - 95.2ms/batch - loss: 5.99839 - diff: 7.56mlTrain batch 13/31 - 94.1ms/batch - loss: 5.93708 - diff: 7.51mlTrain batch 14/31 - 93.8ms/batch - loss: 5.87717 - diff: 7.43mlTrain batch 15/31 - 95.2ms/batch - loss: 5.91580 - diff: 7.38mlTrain batch 16/31 - 95.1ms/batch - loss: 5.79205 - diff: 7.26mlTrain batch 17/31 - 94.6ms/batch - loss: 5.60693 - diff: 7.14mlTrain batch 18/31 - 94.6ms/batch - loss: 5.36601 - diff: 6.94mlTrain batch 19/31 - 94.2ms/batch - loss: 5.51540 - diff: 7.05mlTrain batch 20/31 - 93.6ms/batch - loss: 5.57964 - diff: 7.09mlTrain batch 21/31 - 95.1ms/batch - loss: 5.48252 - diff: 7.03mlTrain batch 22/31 - 93.9ms/batch - loss: 5.59013 - diff: 7.12mlTrain batch 23/31 - 96.5ms/batch - loss: 5.45594 - diff: 7.05mlTrain batch 24/31 - 95.4ms/batch - loss: 5.34608 - diff: 6.99mlTrain batch 25/31 - 94.9ms/batch - loss: 5.55055 - diff: 7.13mlTrain batch 26/31 - 95.4ms/batch - loss: 5.48709 - diff: 7.08mlTrain batch 27/31 - 94.3ms/batch - loss: 5.38770 - diff: 7.03mlTrain batch 28/31 - 96.2ms/batch - loss: 5.49850 - diff: 7.15mlTrain batch 29/31 - 94.0ms/batch - loss: 5.40640 - diff: 7.07mlTrain batch 30/31 - 93.7ms/batch - loss: 5.37457 - diff: 7.04mlTrain batch 31/31 - 73.3ms/batch - loss: 8.59320 - diff: 7.24mlTrain batch 31/31 - 9.8s 73.3ms/batch - loss: 8.59320 - diff: 7.24ml
Test 0.7s: val_loss: 26.00602 - diff: 14.04ml

Epoch 124: current best loss = 19.29070, at epoch 82
Train batch 1/31 - 108.1ms/batch - loss: 14.15111 - diff: 11.77mlTrain batch 2/31 - 94.2ms/batch - loss: 8.61110 - diff: 8.84mlTrain batch 3/31 - 100.8ms/batch - loss: 9.70717 - diff: 9.84mlTrain batch 4/31 - 96.5ms/batch - loss: 8.07603 - diff: 8.82mlTrain batch 5/31 - 94.7ms/batch - loss: 7.58742 - diff: 8.55mlTrain batch 6/31 - 94.1ms/batch - loss: 6.59525 - diff: 7.87mlTrain batch 7/31 - 97.2ms/batch - loss: 6.40141 - diff: 7.67mlTrain batch 8/31 - 93.7ms/batch - loss: 5.80960 - diff: 7.24mlTrain batch 9/31 - 97.3ms/batch - loss: 5.95167 - diff: 7.35mlTrain batch 10/31 - 94.3ms/batch - loss: 5.64808 - diff: 7.22mlTrain batch 11/31 - 96.8ms/batch - loss: 5.64918 - diff: 7.33mlTrain batch 12/31 - 95.5ms/batch - loss: 5.56896 - diff: 7.30mlTrain batch 13/31 - 98.2ms/batch - loss: 5.51086 - diff: 7.34mlTrain batch 14/31 - 94.2ms/batch - loss: 5.55533 - diff: 7.39mlTrain batch 15/31 - 108.5ms/batch - loss: 5.89824 - diff: 7.51mlTrain batch 16/31 - 94.1ms/batch - loss: 6.00207 - diff: 7.64mlTrain batch 17/31 - 103.6ms/batch - loss: 5.91354 - diff: 7.57mlTrain batch 18/31 - 94.2ms/batch - loss: 5.66845 - diff: 7.35mlTrain batch 19/31 - 93.8ms/batch - loss: 5.53356 - diff: 7.30mlTrain batch 20/31 - 94.6ms/batch - loss: 5.45555 - diff: 7.29mlTrain batch 21/31 - 109.3ms/batch - loss: 5.45919 - diff: 7.32mlTrain batch 22/31 - 94.4ms/batch - loss: 5.34086 - diff: 7.25mlTrain batch 23/31 - 101.7ms/batch - loss: 5.42993 - diff: 7.27mlTrain batch 24/31 - 94.6ms/batch - loss: 5.34592 - diff: 7.23mlTrain batch 25/31 - 106.3ms/batch - loss: 6.04973 - diff: 7.39mlTrain batch 26/31 - 95.1ms/batch - loss: 6.08238 - diff: 7.41mlTrain batch 27/31 - 96.4ms/batch - loss: 6.05289 - diff: 7.44mlTrain batch 28/31 - 94.2ms/batch - loss: 5.96479 - diff: 7.39mlTrain batch 29/31 - 94.0ms/batch - loss: 5.97474 - diff: 7.38mlTrain batch 30/31 - 93.6ms/batch - loss: 6.18593 - diff: 7.51mlTrain batch 31/31 - 69.0ms/batch - loss: 6.45777 - diff: 7.57mlTrain batch 31/31 - 9.8s 69.0ms/batch - loss: 6.45777 - diff: 7.57ml
Test 0.7s: val_loss: 22.35953 - diff: 13.85ml

Epoch 125: current best loss = 19.29070, at epoch 82
Train batch 1/31 - 112.6ms/batch - loss: 4.78726 - diff: 7.35mlTrain batch 2/31 - 94.6ms/batch - loss: 4.07344 - diff: 6.80mlTrain batch 3/31 - 99.1ms/batch - loss: 6.16982 - diff: 8.36mlTrain batch 4/31 - 99.8ms/batch - loss: 5.06831 - diff: 7.29mlTrain batch 5/31 - 95.7ms/batch - loss: 5.98722 - diff: 7.96mlTrain batch 6/31 - 93.8ms/batch - loss: 5.47603 - diff: 7.51mlTrain batch 7/31 - 113.0ms/batch - loss: 5.15593 - diff: 7.33mlTrain batch 8/31 - 96.6ms/batch - loss: 5.14965 - diff: 7.17mlTrain batch 9/31 - 95.6ms/batch - loss: 5.05165 - diff: 7.12mlTrain batch 10/31 - 99.1ms/batch - loss: 5.03510 - diff: 7.17mlTrain batch 11/31 - 134.6ms/batch - loss: 5.89530 - diff: 7.72mlTrain batch 12/31 - 94.3ms/batch - loss: 5.66947 - diff: 7.54mlTrain batch 13/31 - 110.1ms/batch - loss: 5.66208 - diff: 7.56mlTrain batch 14/31 - 106.3ms/batch - loss: 5.69029 - diff: 7.58mlTrain batch 15/31 - 95.3ms/batch - loss: 5.47591 - diff: 7.42mlTrain batch 16/31 - 94.3ms/batch - loss: 5.37168 - diff: 7.31mlTrain batch 17/31 - 105.1ms/batch - loss: 5.97924 - diff: 7.75mlTrain batch 18/31 - 96.8ms/batch - loss: 5.83679 - diff: 7.65mlTrain batch 19/31 - 112.9ms/batch - loss: 5.71658 - diff: 7.56mlTrain batch 20/31 - 95.1ms/batch - loss: 6.03935 - diff: 7.68mlTrain batch 21/31 - 94.7ms/batch - loss: 6.17376 - diff: 7.83mlTrain batch 22/31 - 94.7ms/batch - loss: 6.09470 - diff: 7.73mlTrain batch 23/31 - 96.4ms/batch - loss: 6.25002 - diff: 7.81mlTrain batch 24/31 - 95.6ms/batch - loss: 6.07115 - diff: 7.68mlTrain batch 25/31 - 96.0ms/batch - loss: 6.06946 - diff: 7.71mlTrain batch 26/31 - 93.7ms/batch - loss: 6.41596 - diff: 7.77mlTrain batch 27/31 - 105.1ms/batch - loss: 6.40915 - diff: 7.79mlTrain batch 28/31 - 94.5ms/batch - loss: 6.53547 - diff: 7.87mlTrain batch 29/31 - 97.0ms/batch - loss: 6.50779 - diff: 7.87mlTrain batch 30/31 - 93.8ms/batch - loss: 6.34868 - diff: 7.74mlTrain batch 31/31 - 68.0ms/batch - loss: 6.60016 - diff: 7.79mlTrain batch 31/31 - 9.9s 68.0ms/batch - loss: 6.60016 - diff: 7.79ml
Test 0.7s: val_loss: 24.74032 - diff: 14.00ml

Epoch 126: current best loss = 19.29070, at epoch 82
Train batch 1/31 - 109.9ms/batch - loss: 4.58293 - diff: 6.50mlTrain batch 2/31 - 94.8ms/batch - loss: 3.70838 - diff: 6.09mlTrain batch 3/31 - 104.9ms/batch - loss: 8.55413 - diff: 7.80mlTrain batch 4/31 - 98.8ms/batch - loss: 7.04547 - diff: 7.08mlTrain batch 5/31 - 115.1ms/batch - loss: 6.07896 - diff: 6.54mlTrain batch 6/31 - 96.0ms/batch - loss: 6.03162 - diff: 6.59mlTrain batch 7/31 - 95.6ms/batch - loss: 6.10021 - diff: 6.77mlTrain batch 8/31 - 94.7ms/batch - loss: 5.86552 - diff: 6.82mlTrain batch 9/31 - 97.5ms/batch - loss: 5.83870 - diff: 6.88mlTrain batch 10/31 - 95.9ms/batch - loss: 5.45719 - diff: 6.58mlTrain batch 11/31 - 98.5ms/batch - loss: 5.21148 - diff: 6.47mlTrain batch 12/31 - 94.7ms/batch - loss: 5.32239 - diff: 6.58mlTrain batch 13/31 - 99.8ms/batch - loss: 5.37266 - diff: 6.64mlTrain batch 14/31 - 94.2ms/batch - loss: 5.21903 - diff: 6.59mlTrain batch 15/31 - 95.5ms/batch - loss: 5.23105 - diff: 6.68mlTrain batch 16/31 - 95.1ms/batch - loss: 4.99832 - diff: 6.48mlTrain batch 17/31 - 98.5ms/batch - loss: 5.01670 - diff: 6.55mlTrain batch 18/31 - 94.5ms/batch - loss: 5.17917 - diff: 6.76mlTrain batch 19/31 - 97.8ms/batch - loss: 5.18004 - diff: 6.81mlTrain batch 20/31 - 93.7ms/batch - loss: 5.46987 - diff: 7.05mlTrain batch 21/31 - 95.7ms/batch - loss: 5.99692 - diff: 7.42mlTrain batch 22/31 - 93.4ms/batch - loss: 5.91740 - diff: 7.40mlTrain batch 23/31 - 97.5ms/batch - loss: 5.96694 - diff: 7.47mlTrain batch 24/31 - 94.4ms/batch - loss: 5.81831 - diff: 7.34mlTrain batch 25/31 - 94.0ms/batch - loss: 5.74805 - diff: 7.29mlTrain batch 26/31 - 95.5ms/batch - loss: 5.70040 - diff: 7.29mlTrain batch 27/31 - 94.2ms/batch - loss: 5.66034 - diff: 7.24mlTrain batch 28/31 - 95.3ms/batch - loss: 5.54240 - diff: 7.15mlTrain batch 29/31 - 94.0ms/batch - loss: 5.58367 - diff: 7.20mlTrain batch 30/31 - 94.0ms/batch - loss: 5.75130 - diff: 7.35mlTrain batch 31/31 - 73.0ms/batch - loss: 5.73052 - diff: 7.30mlTrain batch 31/31 - 9.8s 73.0ms/batch - loss: 5.73052 - diff: 7.30ml
Test 0.7s: val_loss: 23.30367 - diff: 14.07ml
Epoch   127: reducing learning rate of group 0 to 1.5625e-05.

Epoch 127: current best loss = 19.29070, at epoch 82
Train batch 1/31 - 114.7ms/batch - loss: 4.74277 - diff: 6.56mlTrain batch 2/31 - 93.9ms/batch - loss: 3.71363 - diff: 6.02mlTrain batch 3/31 - 97.7ms/batch - loss: 3.27823 - diff: 5.71mlTrain batch 4/31 - 95.4ms/batch - loss: 3.10999 - diff: 5.43mlTrain batch 5/31 - 97.2ms/batch - loss: 3.02051 - diff: 5.38mlTrain batch 6/31 - 94.3ms/batch - loss: 3.42949 - diff: 5.61mlTrain batch 7/31 - 93.9ms/batch - loss: 3.18348 - diff: 5.45mlTrain batch 8/31 - 95.6ms/batch - loss: 3.21560 - diff: 5.53mlTrain batch 9/31 - 94.7ms/batch - loss: 4.58645 - diff: 6.23mlTrain batch 10/31 - 94.0ms/batch - loss: 4.86964 - diff: 6.53mlTrain batch 11/31 - 99.7ms/batch - loss: 4.87858 - diff: 6.64mlTrain batch 12/31 - 94.1ms/batch - loss: 8.93758 - diff: 8.17mlTrain batch 13/31 - 93.8ms/batch - loss: 8.44236 - diff: 7.93mlTrain batch 14/31 - 93.7ms/batch - loss: 8.96476 - diff: 8.35mlTrain batch 15/31 - 96.9ms/batch - loss: 8.67282 - diff: 8.24mlTrain batch 16/31 - 95.0ms/batch - loss: 8.42218 - diff: 8.14mlTrain batch 17/31 - 94.7ms/batch - loss: 8.50929 - diff: 8.36mlTrain batch 18/31 - 95.9ms/batch - loss: 8.45592 - diff: 8.41mlTrain batch 19/31 - 94.4ms/batch - loss: 8.28541 - diff: 8.35mlTrain batch 20/31 - 93.7ms/batch - loss: 8.46689 - diff: 8.50mlTrain batch 21/31 - 94.9ms/batch - loss: 8.50407 - diff: 8.58mlTrain batch 22/31 - 94.5ms/batch - loss: 8.48746 - diff: 8.63mlTrain batch 23/31 - 93.7ms/batch - loss: 8.61016 - diff: 8.76mlTrain batch 24/31 - 95.3ms/batch - loss: 8.48101 - diff: 8.70mlTrain batch 25/31 - 94.0ms/batch - loss: 8.28382 - diff: 8.60mlTrain batch 26/31 - 94.9ms/batch - loss: 8.01804 - diff: 8.42mlTrain batch 27/31 - 93.6ms/batch - loss: 7.84322 - diff: 8.32mlTrain batch 28/31 - 95.9ms/batch - loss: 8.01075 - diff: 8.48mlTrain batch 29/31 - 93.3ms/batch - loss: 7.99590 - diff: 8.49mlTrain batch 30/31 - 93.9ms/batch - loss: 7.81023 - diff: 8.38mlTrain batch 31/31 - 67.8ms/batch - loss: 7.90041 - diff: 8.36mlTrain batch 31/31 - 9.8s 67.8ms/batch - loss: 7.90041 - diff: 8.36ml
Test 0.7s: val_loss: 24.71113 - diff: 14.31ml

Epoch 128: current best loss = 19.29070, at epoch 82
Train batch 1/31 - 117.3ms/batch - loss: 6.30976 - diff: 8.05mlTrain batch 2/31 - 93.9ms/batch - loss: 6.46479 - diff: 7.97mlTrain batch 3/31 - 98.4ms/batch - loss: 5.09109 - diff: 6.88mlTrain batch 4/31 - 94.3ms/batch - loss: 4.90020 - diff: 6.99mlTrain batch 5/31 - 103.7ms/batch - loss: 4.86085 - diff: 6.99mlTrain batch 6/31 - 99.5ms/batch - loss: 4.36024 - diff: 6.52mlTrain batch 7/31 - 99.7ms/batch - loss: 4.75072 - diff: 6.66mlTrain batch 8/31 - 94.2ms/batch - loss: 5.26261 - diff: 7.15mlTrain batch 9/31 - 103.8ms/batch - loss: 4.93021 - diff: 6.91mlTrain batch 10/31 - 97.9ms/batch - loss: 4.81381 - diff: 6.84mlTrain batch 11/31 - 106.1ms/batch - loss: 4.92573 - diff: 7.03mlTrain batch 12/31 - 96.5ms/batch - loss: 5.24418 - diff: 7.28mlTrain batch 13/31 - 106.6ms/batch - loss: 5.16656 - diff: 7.23mlTrain batch 14/31 - 96.1ms/batch - loss: 4.98717 - diff: 7.09mlTrain batch 15/31 - 103.6ms/batch - loss: 4.79686 - diff: 6.94mlTrain batch 16/31 - 95.7ms/batch - loss: 4.97551 - diff: 7.07mlTrain batch 17/31 - 100.2ms/batch - loss: 5.54595 - diff: 7.51mlTrain batch 18/31 - 95.5ms/batch - loss: 5.41915 - diff: 7.43mlTrain batch 19/31 - 108.4ms/batch - loss: 5.30473 - diff: 7.36mlTrain batch 20/31 - 94.3ms/batch - loss: 5.29011 - diff: 7.33mlTrain batch 21/31 - 108.8ms/batch - loss: 5.24269 - diff: 7.30mlTrain batch 22/31 - 95.0ms/batch - loss: 5.31097 - diff: 7.32mlTrain batch 23/31 - 109.8ms/batch - loss: 5.17341 - diff: 7.21mlTrain batch 24/31 - 94.6ms/batch - loss: 5.22498 - diff: 7.26mlTrain batch 25/31 - 94.4ms/batch - loss: 5.34251 - diff: 7.22mlTrain batch 26/31 - 96.3ms/batch - loss: 5.26237 - diff: 7.14mlTrain batch 27/31 - 96.7ms/batch - loss: 5.13660 - diff: 7.04mlTrain batch 28/31 - 95.9ms/batch - loss: 5.26391 - diff: 7.06mlTrain batch 29/31 - 94.1ms/batch - loss: 5.22915 - diff: 7.05mlTrain batch 30/31 - 95.2ms/batch - loss: 5.11100 - diff: 6.96mlTrain batch 31/31 - 68.7ms/batch - loss: 5.26340 - diff: 6.99mlTrain batch 31/31 - 9.8s 68.7ms/batch - loss: 5.26340 - diff: 6.99ml
Test 0.7s: val_loss: 23.68902 - diff: 14.19ml

Epoch 129: current best loss = 19.29070, at epoch 82
Train batch 1/31 - 99.3ms/batch - loss: 4.08790 - diff: 6.62mlTrain batch 2/31 - 100.3ms/batch - loss: 4.46322 - diff: 6.85mlTrain batch 3/31 - 94.2ms/batch - loss: 5.06021 - diff: 7.07mlTrain batch 4/31 - 94.3ms/batch - loss: 4.58182 - diff: 6.80mlTrain batch 5/31 - 96.0ms/batch - loss: 4.44551 - diff: 6.66mlTrain batch 6/31 - 97.8ms/batch - loss: 4.00601 - diff: 6.22mlTrain batch 7/31 - 95.4ms/batch - loss: 3.71856 - diff: 5.98mlTrain batch 8/31 - 94.1ms/batch - loss: 3.85580 - diff: 6.14mlTrain batch 9/31 - 94.5ms/batch - loss: 3.76742 - diff: 6.09mlTrain batch 10/31 - 94.0ms/batch - loss: 3.78178 - diff: 6.11mlTrain batch 11/31 - 94.7ms/batch - loss: 3.62268 - diff: 5.94mlTrain batch 12/31 - 93.6ms/batch - loss: 4.09193 - diff: 6.38mlTrain batch 13/31 - 106.6ms/batch - loss: 4.57463 - diff: 6.72mlTrain batch 14/31 - 94.1ms/batch - loss: 4.51538 - diff: 6.64mlTrain batch 15/31 - 96.2ms/batch - loss: 4.61064 - diff: 6.61mlTrain batch 16/31 - 93.6ms/batch - loss: 4.95150 - diff: 6.88mlTrain batch 17/31 - 94.7ms/batch - loss: 4.92564 - diff: 6.82mlTrain batch 18/31 - 93.9ms/batch - loss: 4.94082 - diff: 6.86mlTrain batch 19/31 - 95.8ms/batch - loss: 4.87863 - diff: 6.86mlTrain batch 20/31 - 93.8ms/batch - loss: 4.69144 - diff: 6.69mlTrain batch 21/31 - 96.0ms/batch - loss: 4.59881 - diff: 6.65mlTrain batch 22/31 - 93.7ms/batch - loss: 4.61194 - diff: 6.66mlTrain batch 23/31 - 93.9ms/batch - loss: 4.85916 - diff: 6.76mlTrain batch 24/31 - 94.1ms/batch - loss: 4.91736 - diff: 6.77mlTrain batch 25/31 - 94.2ms/batch - loss: 5.44037 - diff: 7.04mlTrain batch 26/31 - 94.1ms/batch - loss: 5.46896 - diff: 7.08mlTrain batch 27/31 - 94.2ms/batch - loss: 5.53554 - diff: 7.14mlTrain batch 28/31 - 94.5ms/batch - loss: 5.43873 - diff: 7.09mlTrain batch 29/31 - 93.7ms/batch - loss: 5.63792 - diff: 7.22mlTrain batch 30/31 - 93.8ms/batch - loss: 5.87573 - diff: 7.42mlTrain batch 31/31 - 72.8ms/batch - loss: 5.98696 - diff: 7.42mlTrain batch 31/31 - 9.8s 72.8ms/batch - loss: 5.98696 - diff: 7.42ml
Test 0.7s: val_loss: 23.39425 - diff: 14.20ml

Epoch 130: current best loss = 19.29070, at epoch 82
Train batch 1/31 - 120.8ms/batch - loss: 8.80306 - diff: 10.69mlTrain batch 2/31 - 94.4ms/batch - loss: 6.22010 - diff: 8.28mlTrain batch 3/31 - 109.1ms/batch - loss: 5.68743 - diff: 7.89mlTrain batch 4/31 - 93.4ms/batch - loss: 5.88771 - diff: 8.13mlTrain batch 5/31 - 97.6ms/batch - loss: 5.27801 - diff: 7.64mlTrain batch 6/31 - 94.4ms/batch - loss: 5.64872 - diff: 7.88mlTrain batch 7/31 - 125.7ms/batch - loss: 9.42567 - diff: 9.68mlTrain batch 8/31 - 94.5ms/batch - loss: 8.55341 - diff: 9.13mlTrain batch 9/31 - 98.0ms/batch - loss: 8.14026 - diff: 8.85mlTrain batch 10/31 - 96.7ms/batch - loss: 7.68244 - diff: 8.63mlTrain batch 11/31 - 105.2ms/batch - loss: 7.61411 - diff: 8.54mlTrain batch 12/31 - 93.8ms/batch - loss: 7.71688 - diff: 8.66mlTrain batch 13/31 - 105.6ms/batch - loss: 8.29823 - diff: 9.02mlTrain batch 14/31 - 94.0ms/batch - loss: 7.94969 - diff: 8.78mlTrain batch 15/31 - 102.2ms/batch - loss: 8.05619 - diff: 8.88mlTrain batch 16/31 - 93.9ms/batch - loss: 8.20659 - diff: 9.02mlTrain batch 17/31 - 97.5ms/batch - loss: 7.92153 - diff: 8.83mlTrain batch 18/31 - 93.9ms/batch - loss: 7.80630 - diff: 8.77mlTrain batch 19/31 - 106.8ms/batch - loss: 7.57590 - diff: 8.63mlTrain batch 20/31 - 94.7ms/batch - loss: 7.30715 - diff: 8.43mlTrain batch 21/31 - 98.9ms/batch - loss: 7.27138 - diff: 8.42mlTrain batch 22/31 - 93.9ms/batch - loss: 7.25885 - diff: 8.42mlTrain batch 23/31 - 109.5ms/batch - loss: 7.13929 - diff: 8.35mlTrain batch 24/31 - 94.8ms/batch - loss: 6.93492 - diff: 8.21mlTrain batch 25/31 - 109.5ms/batch - loss: 6.77837 - diff: 8.10mlTrain batch 26/31 - 94.7ms/batch - loss: 7.35658 - diff: 8.25mlTrain batch 27/31 - 100.1ms/batch - loss: 7.36400 - diff: 8.28mlTrain batch 28/31 - 93.8ms/batch - loss: 7.18818 - diff: 8.17mlTrain batch 29/31 - 99.9ms/batch - loss: 7.01212 - diff: 8.06mlTrain batch 30/31 - 93.5ms/batch - loss: 6.91057 - diff: 8.01mlTrain batch 31/31 - 68.3ms/batch - loss: 7.38707 - diff: 8.12mlTrain batch 31/31 - 9.8s 68.3ms/batch - loss: 7.38707 - diff: 8.12ml
Test 0.7s: val_loss: 25.33359 - diff: 13.99ml

Epoch 131: current best loss = 19.29070, at epoch 82
Train batch 1/31 - 105.8ms/batch - loss: 2.52300 - diff: 4.92mlTrain batch 2/31 - 96.8ms/batch - loss: 4.25498 - diff: 6.46mlTrain batch 3/31 - 98.1ms/batch - loss: 3.67368 - diff: 6.04mlTrain batch 4/31 - 106.1ms/batch - loss: 5.62876 - diff: 7.64mlTrain batch 5/31 - 98.2ms/batch - loss: 5.69124 - diff: 7.74mlTrain batch 6/31 - 95.9ms/batch - loss: 5.68295 - diff: 7.69mlTrain batch 7/31 - 107.3ms/batch - loss: 5.42465 - diff: 7.48mlTrain batch 8/31 - 97.9ms/batch - loss: 5.73773 - diff: 7.85mlTrain batch 9/31 - 97.9ms/batch - loss: 5.74341 - diff: 7.86mlTrain batch 10/31 - 94.1ms/batch - loss: 5.39013 - diff: 7.57mlTrain batch 11/31 - 105.2ms/batch - loss: 6.40539 - diff: 8.20mlTrain batch 12/31 - 95.7ms/batch - loss: 6.31923 - diff: 8.16mlTrain batch 13/31 - 99.2ms/batch - loss: 6.37754 - diff: 8.21mlTrain batch 14/31 - 96.1ms/batch - loss: 6.35095 - diff: 8.14mlTrain batch 15/31 - 98.0ms/batch - loss: 6.34822 - diff: 8.14mlTrain batch 16/31 - 94.2ms/batch - loss: 6.23054 - diff: 8.06mlTrain batch 17/31 - 105.0ms/batch - loss: 5.98150 - diff: 7.88mlTrain batch 18/31 - 102.9ms/batch - loss: 5.83397 - diff: 7.75mlTrain batch 19/31 - 102.5ms/batch - loss: 5.59759 - diff: 7.55mlTrain batch 20/31 - 96.0ms/batch - loss: 5.63806 - diff: 7.56mlTrain batch 21/31 - 122.1ms/batch - loss: 5.71027 - diff: 7.64mlTrain batch 22/31 - 93.8ms/batch - loss: 5.90309 - diff: 7.69mlTrain batch 23/31 - 109.9ms/batch - loss: 5.75363 - diff: 7.59mlTrain batch 24/31 - 94.4ms/batch - loss: 5.64511 - diff: 7.52mlTrain batch 25/31 - 102.6ms/batch - loss: 5.90664 - diff: 7.70mlTrain batch 26/31 - 95.2ms/batch - loss: 5.97300 - diff: 7.74mlTrain batch 27/31 - 115.7ms/batch - loss: 5.88928 - diff: 7.69mlTrain batch 28/31 - 94.3ms/batch - loss: 5.77998 - diff: 7.62mlTrain batch 29/31 - 99.2ms/batch - loss: 5.63485 - diff: 7.48mlTrain batch 30/31 - 94.1ms/batch - loss: 5.59280 - diff: 7.47mlTrain batch 31/31 - 69.3ms/batch - loss: 5.93870 - diff: 7.52mlTrain batch 31/31 - 9.9s 69.3ms/batch - loss: 5.93870 - diff: 7.52ml
Test 0.7s: val_loss: 25.69561 - diff: 14.11ml

Epoch 132: current best loss = 19.29070, at epoch 82
Train batch 1/31 - 99.7ms/batch - loss: 4.59402 - diff: 7.52mlTrain batch 2/31 - 94.9ms/batch - loss: 6.64537 - diff: 8.53mlTrain batch 3/31 - 95.2ms/batch - loss: 8.87637 - diff: 10.06mlTrain batch 4/31 - 94.8ms/batch - loss: 8.12683 - diff: 9.55mlTrain batch 5/31 - 94.3ms/batch - loss: 8.32762 - diff: 9.78mlTrain batch 6/31 - 94.3ms/batch - loss: 7.28743 - diff: 8.86mlTrain batch 7/31 - 95.7ms/batch - loss: 6.86698 - diff: 8.46mlTrain batch 8/31 - 97.1ms/batch - loss: 7.38537 - diff: 8.72mlTrain batch 9/31 - 95.4ms/batch - loss: 7.00138 - diff: 8.48mlTrain batch 10/31 - 98.3ms/batch - loss: 7.46959 - diff: 8.64mlTrain batch 11/31 - 93.9ms/batch - loss: 7.14502 - diff: 8.42mlTrain batch 12/31 - 94.1ms/batch - loss: 6.67897 - diff: 8.06mlTrain batch 13/31 - 93.9ms/batch - loss: 6.39285 - diff: 7.88mlTrain batch 14/31 - 94.1ms/batch - loss: 6.08505 - diff: 7.66mlTrain batch 15/31 - 94.1ms/batch - loss: 5.78396 - diff: 7.44mlTrain batch 16/31 - 95.3ms/batch - loss: 5.69318 - diff: 7.40mlTrain batch 17/31 - 94.0ms/batch - loss: 6.14016 - diff: 7.70mlTrain batch 18/31 - 94.8ms/batch - loss: 6.03381 - diff: 7.64mlTrain batch 19/31 - 94.3ms/batch - loss: 6.11067 - diff: 7.66mlTrain batch 20/31 - 95.4ms/batch - loss: 6.01445 - diff: 7.56mlTrain batch 21/31 - 94.0ms/batch - loss: 5.89282 - diff: 7.47mlTrain batch 22/31 - 96.7ms/batch - loss: 5.80960 - diff: 7.40mlTrain batch 23/31 - 94.0ms/batch - loss: 5.93387 - diff: 7.50mlTrain batch 24/31 - 94.5ms/batch - loss: 6.01462 - diff: 7.51mlTrain batch 25/31 - 94.6ms/batch - loss: 5.97757 - diff: 7.53mlTrain batch 26/31 - 95.2ms/batch - loss: 6.71670 - diff: 7.96mlTrain batch 27/31 - 93.8ms/batch - loss: 6.72044 - diff: 8.02mlTrain batch 28/31 - 95.7ms/batch - loss: 6.64859 - diff: 7.99mlTrain batch 29/31 - 93.8ms/batch - loss: 6.61947 - diff: 7.98mlTrain batch 30/31 - 94.3ms/batch - loss: 6.59164 - diff: 7.95mlTrain batch 31/31 - 70.1ms/batch - loss: 7.12355 - diff: 8.07mlTrain batch 31/31 - 9.8s 70.1ms/batch - loss: 7.12355 - diff: 8.07ml
Test 0.7s: val_loss: 22.38725 - diff: 14.03ml

Epoch 133: current best loss = 19.29070, at epoch 82
Train batch 1/31 - 108.9ms/batch - loss: 1.62791 - diff: 4.29mlTrain batch 2/31 - 94.1ms/batch - loss: 2.86146 - diff: 4.75mlTrain batch 3/31 - 96.6ms/batch - loss: 2.54842 - diff: 4.78mlTrain batch 4/31 - 94.8ms/batch - loss: 2.70262 - diff: 4.91mlTrain batch 5/31 - 96.0ms/batch - loss: 3.34801 - diff: 5.14mlTrain batch 6/31 - 93.9ms/batch - loss: 3.19377 - diff: 5.05mlTrain batch 7/31 - 95.3ms/batch - loss: 3.36835 - diff: 5.30mlTrain batch 8/31 - 94.1ms/batch - loss: 3.28374 - diff: 5.25mlTrain batch 9/31 - 104.6ms/batch - loss: 3.30501 - diff: 5.36mlTrain batch 10/31 - 93.8ms/batch - loss: 3.20890 - diff: 5.30mlTrain batch 11/31 - 97.8ms/batch - loss: 3.13189 - diff: 5.19mlTrain batch 12/31 - 94.9ms/batch - loss: 3.46906 - diff: 5.56mlTrain batch 13/31 - 95.0ms/batch - loss: 4.07613 - diff: 6.05mlTrain batch 14/31 - 94.3ms/batch - loss: 6.54444 - diff: 6.86mlTrain batch 15/31 - 94.2ms/batch - loss: 6.66494 - diff: 7.13mlTrain batch 16/31 - 94.2ms/batch - loss: 6.55572 - diff: 7.13mlTrain batch 17/31 - 96.1ms/batch - loss: 7.23973 - diff: 7.46mlTrain batch 18/31 - 93.8ms/batch - loss: 7.15523 - diff: 7.48mlTrain batch 19/31 - 95.0ms/batch - loss: 7.57756 - diff: 7.85mlTrain batch 20/31 - 95.1ms/batch - loss: 7.60446 - diff: 7.97mlTrain batch 21/31 - 94.2ms/batch - loss: 7.35107 - diff: 7.81mlTrain batch 22/31 - 94.3ms/batch - loss: 7.20700 - diff: 7.76mlTrain batch 23/31 - 94.1ms/batch - loss: 7.30935 - diff: 7.87mlTrain batch 24/31 - 96.6ms/batch - loss: 7.72494 - diff: 8.09mlTrain batch 25/31 - 94.2ms/batch - loss: 7.79851 - diff: 8.23mlTrain batch 26/31 - 94.1ms/batch - loss: 7.62071 - diff: 8.12mlTrain batch 27/31 - 94.7ms/batch - loss: 7.44581 - diff: 8.02mlTrain batch 28/31 - 94.0ms/batch - loss: 7.28235 - diff: 7.93mlTrain batch 29/31 - 93.5ms/batch - loss: 7.50956 - diff: 8.07mlTrain batch 30/31 - 94.5ms/batch - loss: 7.38430 - diff: 7.99mlTrain batch 31/31 - 69.1ms/batch - loss: 7.83967 - diff: 8.09mlTrain batch 31/31 - 9.8s 69.1ms/batch - loss: 7.83967 - diff: 8.09ml
Test 0.7s: val_loss: 22.85204 - diff: 14.20ml

Epoch 134: current best loss = 19.29070, at epoch 82
Train batch 1/31 - 121.3ms/batch - loss: 4.56339 - diff: 6.96mlTrain batch 2/31 - 94.9ms/batch - loss: 5.63407 - diff: 7.81mlTrain batch 3/31 - 101.9ms/batch - loss: 5.48395 - diff: 7.65mlTrain batch 4/31 - 95.0ms/batch - loss: 4.83538 - diff: 7.05mlTrain batch 5/31 - 107.2ms/batch - loss: 4.32522 - diff: 6.47mlTrain batch 6/31 - 95.6ms/batch - loss: 4.93931 - diff: 6.98mlTrain batch 7/31 - 98.5ms/batch - loss: 4.65663 - diff: 6.77mlTrain batch 8/31 - 94.8ms/batch - loss: 4.37675 - diff: 6.58mlTrain batch 9/31 - 100.0ms/batch - loss: 4.24339 - diff: 6.49mlTrain batch 10/31 - 100.9ms/batch - loss: 5.24835 - diff: 7.15mlTrain batch 11/31 - 99.1ms/batch - loss: 5.16644 - diff: 7.16mlTrain batch 12/31 - 94.3ms/batch - loss: 5.32714 - diff: 7.29mlTrain batch 13/31 - 109.2ms/batch - loss: 5.10008 - diff: 7.08mlTrain batch 14/31 - 95.0ms/batch - loss: 4.88232 - diff: 6.89mlTrain batch 15/31 - 106.0ms/batch - loss: 4.63359 - diff: 6.65mlTrain batch 16/31 - 93.8ms/batch - loss: 4.46598 - diff: 6.51mlTrain batch 17/31 - 93.9ms/batch - loss: 4.52181 - diff: 6.58mlTrain batch 18/31 - 93.7ms/batch - loss: 4.36851 - diff: 6.44mlTrain batch 19/31 - 97.3ms/batch - loss: 4.28605 - diff: 6.34mlTrain batch 20/31 - 95.6ms/batch - loss: 4.29584 - diff: 6.32mlTrain batch 21/31 - 99.0ms/batch - loss: 4.19786 - diff: 6.26mlTrain batch 22/31 - 93.7ms/batch - loss: 4.58662 - diff: 6.33mlTrain batch 23/31 - 110.0ms/batch - loss: 4.47496 - diff: 6.24mlTrain batch 24/31 - 93.9ms/batch - loss: 4.64993 - diff: 6.42mlTrain batch 25/31 - 96.1ms/batch - loss: 4.70664 - diff: 6.48mlTrain batch 26/31 - 94.5ms/batch - loss: 4.67978 - diff: 6.48mlTrain batch 27/31 - 102.4ms/batch - loss: 4.67861 - diff: 6.51mlTrain batch 28/31 - 93.6ms/batch - loss: 4.71691 - diff: 6.54mlTrain batch 29/31 - 101.7ms/batch - loss: 4.87265 - diff: 6.69mlTrain batch 30/31 - 93.9ms/batch - loss: 4.77252 - diff: 6.59mlTrain batch 31/31 - 69.8ms/batch - loss: 4.86983 - diff: 6.60mlTrain batch 31/31 - 9.9s 69.8ms/batch - loss: 4.86983 - diff: 6.60ml
Test 0.7s: val_loss: 22.42916 - diff: 14.15ml

Epoch 135: current best loss = 19.29070, at epoch 82
Train batch 1/31 - 105.6ms/batch - loss: 2.73879 - diff: 5.38mlTrain batch 2/31 - 94.6ms/batch - loss: 2.70654 - diff: 5.11mlTrain batch 3/31 - 96.4ms/batch - loss: 4.42363 - diff: 6.34mlTrain batch 4/31 - 93.8ms/batch - loss: 4.74993 - diff: 6.68mlTrain batch 5/31 - 96.9ms/batch - loss: 5.09207 - diff: 7.17mlTrain batch 6/31 - 94.9ms/batch - loss: 5.03028 - diff: 7.17mlTrain batch 7/31 - 96.2ms/batch - loss: 6.05211 - diff: 7.86mlTrain batch 8/31 - 93.9ms/batch - loss: 5.90796 - diff: 7.77mlTrain batch 9/31 - 97.8ms/batch - loss: 5.82249 - diff: 7.69mlTrain batch 10/31 - 106.4ms/batch - loss: 5.62019 - diff: 7.54mlTrain batch 11/31 - 94.4ms/batch - loss: 5.55866 - diff: 7.47mlTrain batch 12/31 - 94.0ms/batch - loss: 5.26305 - diff: 7.26mlTrain batch 13/31 - 96.2ms/batch - loss: 5.07846 - diff: 7.13mlTrain batch 14/31 - 94.1ms/batch - loss: 5.03628 - diff: 7.10mlTrain batch 15/31 - 113.0ms/batch - loss: 6.60257 - diff: 7.34mlTrain batch 16/31 - 94.1ms/batch - loss: 6.76997 - diff: 7.46mlTrain batch 17/31 - 99.7ms/batch - loss: 6.63516 - diff: 7.37mlTrain batch 18/31 - 95.4ms/batch - loss: 6.73452 - diff: 7.50mlTrain batch 19/31 - 96.7ms/batch - loss: 7.41190 - diff: 7.97mlTrain batch 20/31 - 94.2ms/batch - loss: 7.19321 - diff: 7.84mlTrain batch 21/31 - 96.9ms/batch - loss: 7.02448 - diff: 7.74mlTrain batch 22/31 - 96.7ms/batch - loss: 6.88271 - diff: 7.66mlTrain batch 23/31 - 96.6ms/batch - loss: 7.72775 - diff: 8.14mlTrain batch 24/31 - 101.6ms/batch - loss: 7.72450 - diff: 8.21mlTrain batch 25/31 - 98.6ms/batch - loss: 7.67800 - diff: 8.17mlTrain batch 26/31 - 95.7ms/batch - loss: 7.44773 - diff: 8.02mlTrain batch 27/31 - 104.1ms/batch - loss: 7.32510 - diff: 7.98mlTrain batch 28/31 - 100.7ms/batch - loss: 7.14795 - diff: 7.87mlTrain batch 29/31 - 110.8ms/batch - loss: 7.00425 - diff: 7.80mlTrain batch 30/31 - 95.9ms/batch - loss: 6.92160 - diff: 7.77mlTrain batch 31/31 - 69.1ms/batch - loss: 6.95608 - diff: 7.77mlTrain batch 31/31 - 9.9s 69.1ms/batch - loss: 6.95608 - diff: 7.77ml
Test 0.7s: val_loss: 22.84144 - diff: 14.27ml

Epoch 136: current best loss = 19.29070, at epoch 82
Train batch 1/31 - 108.6ms/batch - loss: 2.57351 - diff: 4.95mlTrain batch 2/31 - 94.2ms/batch - loss: 3.85220 - diff: 5.86mlTrain batch 3/31 - 95.1ms/batch - loss: 5.36046 - diff: 6.85mlTrain batch 4/31 - 94.6ms/batch - loss: 4.88163 - diff: 6.35mlTrain batch 5/31 - 94.8ms/batch - loss: 4.98571 - diff: 6.52mlTrain batch 6/31 - 94.3ms/batch - loss: 5.00083 - diff: 6.60mlTrain batch 7/31 - 95.2ms/batch - loss: 4.62649 - diff: 6.35mlTrain batch 8/31 - 94.3ms/batch - loss: 4.56085 - diff: 6.17mlTrain batch 9/31 - 93.9ms/batch - loss: 4.42759 - diff: 6.10mlTrain batch 10/31 - 95.2ms/batch - loss: 4.15895 - diff: 5.95mlTrain batch 11/31 - 94.0ms/batch - loss: 4.15829 - diff: 5.97mlTrain batch 12/31 - 95.1ms/batch - loss: 4.21936 - diff: 6.08mlTrain batch 13/31 - 94.0ms/batch - loss: 4.18289 - diff: 6.12mlTrain batch 14/31 - 95.4ms/batch - loss: 4.56360 - diff: 6.44mlTrain batch 15/31 - 94.3ms/batch - loss: 4.57191 - diff: 6.52mlTrain batch 16/31 - 96.2ms/batch - loss: 4.77584 - diff: 6.66mlTrain batch 17/31 - 94.2ms/batch - loss: 4.65609 - diff: 6.59mlTrain batch 18/31 - 95.4ms/batch - loss: 4.58379 - diff: 6.55mlTrain batch 19/31 - 94.6ms/batch - loss: 4.54278 - diff: 6.58mlTrain batch 20/31 - 95.4ms/batch - loss: 4.53355 - diff: 6.57mlTrain batch 21/31 - 94.9ms/batch - loss: 4.57469 - diff: 6.59mlTrain batch 22/31 - 94.1ms/batch - loss: 4.88372 - diff: 6.71mlTrain batch 23/31 - 94.0ms/batch - loss: 5.12195 - diff: 6.90mlTrain batch 24/31 - 96.4ms/batch - loss: 5.04120 - diff: 6.83mlTrain batch 25/31 - 94.2ms/batch - loss: 6.00699 - diff: 7.33mlTrain batch 26/31 - 94.4ms/batch - loss: 6.55005 - diff: 7.70mlTrain batch 27/31 - 93.9ms/batch - loss: 6.47117 - diff: 7.68mlTrain batch 28/31 - 95.0ms/batch - loss: 6.38596 - diff: 7.63mlTrain batch 29/31 - 93.7ms/batch - loss: 6.32825 - diff: 7.60mlTrain batch 30/31 - 94.8ms/batch - loss: 6.21466 - diff: 7.54mlTrain batch 31/31 - 72.4ms/batch - loss: 7.76014 - diff: 7.83mlTrain batch 31/31 - 9.8s 72.4ms/batch - loss: 7.76014 - diff: 7.83ml
Test 0.7s: val_loss: 23.07271 - diff: 14.27ml

Epoch 137: current best loss = 19.29070, at epoch 82
Train batch 1/31 - 117.4ms/batch - loss: 4.60798 - diff: 6.84mlTrain batch 2/31 - 93.9ms/batch - loss: 4.83865 - diff: 6.99mlTrain batch 3/31 - 109.5ms/batch - loss: 4.59864 - diff: 6.61mlTrain batch 4/31 - 93.8ms/batch - loss: 6.27232 - diff: 7.21mlTrain batch 5/31 - 106.5ms/batch - loss: 6.18501 - diff: 7.41mlTrain batch 6/31 - 93.6ms/batch - loss: 5.84470 - diff: 7.10mlTrain batch 7/31 - 98.8ms/batch - loss: 5.62736 - diff: 6.98mlTrain batch 8/31 - 94.1ms/batch - loss: 5.84710 - diff: 7.27mlTrain batch 9/31 - 97.2ms/batch - loss: 5.75013 - diff: 7.22mlTrain batch 10/31 - 94.2ms/batch - loss: 5.83447 - diff: 7.34mlTrain batch 11/31 - 105.0ms/batch - loss: 5.61869 - diff: 7.22mlTrain batch 12/31 - 100.4ms/batch - loss: 5.40821 - diff: 7.10mlTrain batch 13/31 - 94.4ms/batch - loss: 5.22355 - diff: 6.95mlTrain batch 14/31 - 95.5ms/batch - loss: 5.38585 - diff: 7.04mlTrain batch 15/31 - 109.7ms/batch - loss: 5.59566 - diff: 7.12mlTrain batch 16/31 - 94.3ms/batch - loss: 5.43798 - diff: 7.00mlTrain batch 17/31 - 101.8ms/batch - loss: 5.42475 - diff: 6.99mlTrain batch 18/31 - 93.7ms/batch - loss: 5.43870 - diff: 7.05mlTrain batch 19/31 - 94.5ms/batch - loss: 5.52615 - diff: 7.07mlTrain batch 20/31 - 94.0ms/batch - loss: 5.77753 - diff: 7.15mlTrain batch 21/31 - 95.9ms/batch - loss: 5.79550 - diff: 7.19mlTrain batch 22/31 - 95.2ms/batch - loss: 5.67330 - diff: 7.11mlTrain batch 23/31 - 107.1ms/batch - loss: 5.51580 - diff: 6.98mlTrain batch 24/31 - 94.7ms/batch - loss: 5.47996 - diff: 6.99mlTrain batch 25/31 - 94.4ms/batch - loss: 5.44239 - diff: 6.98mlTrain batch 26/31 - 93.9ms/batch - loss: 5.41800 - diff: 6.98mlTrain batch 27/31 - 93.7ms/batch - loss: 5.36915 - diff: 6.97mlTrain batch 28/31 - 93.7ms/batch - loss: 5.28047 - diff: 6.92mlTrain batch 29/31 - 106.5ms/batch - loss: 5.24329 - diff: 6.92mlTrain batch 30/31 - 93.0ms/batch - loss: 5.42457 - diff: 7.05mlTrain batch 31/31 - 68.0ms/batch - loss: 5.49317 - diff: 7.04mlTrain batch 31/31 - 9.8s 68.0ms/batch - loss: 5.49317 - diff: 7.04ml
Test 0.7s: val_loss: 23.22554 - diff: 14.16ml
Epoch   138: reducing learning rate of group 0 to 7.8125e-06.

Epoch 138: current best loss = 19.29070, at epoch 82
Train batch 1/31 - 115.0ms/batch - loss: 3.75122 - diff: 5.87mlTrain batch 2/31 - 95.8ms/batch - loss: 7.13172 - diff: 8.31mlTrain batch 3/31 - 95.1ms/batch - loss: 6.88619 - diff: 8.22mlTrain batch 4/31 - 94.1ms/batch - loss: 6.70497 - diff: 8.39mlTrain batch 5/31 - 107.7ms/batch - loss: 6.84237 - diff: 8.44mlTrain batch 6/31 - 95.6ms/batch - loss: 6.08158 - diff: 7.85mlTrain batch 7/31 - 100.6ms/batch - loss: 10.41403 - diff: 9.35mlTrain batch 8/31 - 95.3ms/batch - loss: 10.00332 - diff: 9.23mlTrain batch 9/31 - 94.1ms/batch - loss: 9.18716 - diff: 8.71mlTrain batch 10/31 - 94.6ms/batch - loss: 8.89128 - diff: 8.60mlTrain batch 11/31 - 100.1ms/batch - loss: 8.76406 - diff: 8.68mlTrain batch 12/31 - 96.9ms/batch - loss: 8.50093 - diff: 8.51mlTrain batch 13/31 - 94.2ms/batch - loss: 8.10949 - diff: 8.32mlTrain batch 14/31 - 93.6ms/batch - loss: 7.67007 - diff: 8.05mlTrain batch 15/31 - 95.3ms/batch - loss: 7.30949 - diff: 7.84mlTrain batch 16/31 - 96.4ms/batch - loss: 7.23906 - diff: 7.82mlTrain batch 17/31 - 94.4ms/batch - loss: 7.02683 - diff: 7.72mlTrain batch 18/31 - 95.5ms/batch - loss: 7.03014 - diff: 7.83mlTrain batch 19/31 - 94.6ms/batch - loss: 7.01548 - diff: 7.79mlTrain batch 20/31 - 94.8ms/batch - loss: 6.72412 - diff: 7.57mlTrain batch 21/31 - 94.9ms/batch - loss: 6.83587 - diff: 7.73mlTrain batch 22/31 - 95.4ms/batch - loss: 6.78182 - diff: 7.74mlTrain batch 23/31 - 94.9ms/batch - loss: 6.81466 - diff: 7.71mlTrain batch 24/31 - 94.8ms/batch - loss: 6.65658 - diff: 7.61mlTrain batch 25/31 - 94.7ms/batch - loss: 6.55228 - diff: 7.58mlTrain batch 26/31 - 94.5ms/batch - loss: 6.46014 - diff: 7.54mlTrain batch 27/31 - 94.5ms/batch - loss: 6.32862 - diff: 7.46mlTrain batch 28/31 - 96.1ms/batch - loss: 6.14904 - diff: 7.33mlTrain batch 29/31 - 95.0ms/batch - loss: 6.07516 - diff: 7.29mlTrain batch 30/31 - 96.8ms/batch - loss: 5.96822 - diff: 7.23mlTrain batch 31/31 - 69.7ms/batch - loss: 7.88514 - diff: 7.57mlTrain batch 31/31 - 9.9s 69.7ms/batch - loss: 7.88514 - diff: 7.57ml
Test 0.7s: val_loss: 25.81367 - diff: 14.18ml

Epoch 139: current best loss = 19.29070, at epoch 82
Train batch 1/31 - 109.0ms/batch - loss: 7.47677 - diff: 9.29mlTrain batch 2/31 - 93.8ms/batch - loss: 7.89634 - diff: 9.13mlTrain batch 3/31 - 98.7ms/batch - loss: 7.39085 - diff: 8.92mlTrain batch 4/31 - 94.2ms/batch - loss: 6.07051 - diff: 7.82mlTrain batch 5/31 - 95.6ms/batch - loss: 5.99233 - diff: 7.83mlTrain batch 6/31 - 95.6ms/batch - loss: 5.47778 - diff: 7.43mlTrain batch 7/31 - 103.2ms/batch - loss: 5.68218 - diff: 7.63mlTrain batch 8/31 - 93.6ms/batch - loss: 5.39506 - diff: 7.44mlTrain batch 9/31 - 94.1ms/batch - loss: 5.06641 - diff: 7.18mlTrain batch 10/31 - 94.6ms/batch - loss: 5.01046 - diff: 7.08mlTrain batch 11/31 - 95.6ms/batch - loss: 5.04796 - diff: 7.01mlTrain batch 12/31 - 96.2ms/batch - loss: 5.09113 - diff: 7.09mlTrain batch 13/31 - 93.2ms/batch - loss: 5.13072 - diff: 7.09mlTrain batch 14/31 - 94.5ms/batch - loss: 5.36302 - diff: 7.23mlTrain batch 15/31 - 93.8ms/batch - loss: 5.71263 - diff: 7.32mlTrain batch 16/31 - 94.9ms/batch - loss: 5.71129 - diff: 7.35mlTrain batch 17/31 - 94.3ms/batch - loss: 5.83720 - diff: 7.52mlTrain batch 18/31 - 94.5ms/batch - loss: 5.65834 - diff: 7.40mlTrain batch 19/31 - 94.1ms/batch - loss: 5.46627 - diff: 7.27mlTrain batch 20/31 - 95.9ms/batch - loss: 5.38369 - diff: 7.24mlTrain batch 21/31 - 94.2ms/batch - loss: 5.22615 - diff: 7.11mlTrain batch 22/31 - 94.3ms/batch - loss: 5.98281 - diff: 7.24mlTrain batch 23/31 - 94.0ms/batch - loss: 5.85391 - diff: 7.15mlTrain batch 24/31 - 95.5ms/batch - loss: 5.84790 - diff: 7.19mlTrain batch 25/31 - 95.1ms/batch - loss: 6.03335 - diff: 7.40mlTrain batch 26/31 - 96.4ms/batch - loss: 5.87973 - diff: 7.29mlTrain batch 27/31 - 98.1ms/batch - loss: 6.13641 - diff: 7.46mlTrain batch 28/31 - 94.7ms/batch - loss: 6.03413 - diff: 7.39mlTrain batch 29/31 - 98.2ms/batch - loss: 5.90783 - diff: 7.29mlTrain batch 30/31 - 93.6ms/batch - loss: 5.86063 - diff: 7.27mlTrain batch 31/31 - 72.1ms/batch - loss: 6.70132 - diff: 7.45mlTrain batch 31/31 - 9.8s 72.1ms/batch - loss: 6.70132 - diff: 7.45ml
Test 0.7s: val_loss: 22.93542 - diff: 14.14ml

Epoch 140: current best loss = 19.29070, at epoch 82
Train batch 1/31 - 119.2ms/batch - loss: 2.41711 - diff: 5.09mlTrain batch 2/31 - 95.1ms/batch - loss: 5.34501 - diff: 7.37mlTrain batch 3/31 - 114.3ms/batch - loss: 5.02049 - diff: 7.34mlTrain batch 4/31 - 94.3ms/batch - loss: 4.87956 - diff: 6.89mlTrain batch 5/31 - 108.7ms/batch - loss: 4.47940 - diff: 6.62mlTrain batch 6/31 - 94.0ms/batch - loss: 4.54596 - diff: 6.79mlTrain batch 7/31 - 112.7ms/batch - loss: 4.68659 - diff: 6.86mlTrain batch 8/31 - 94.3ms/batch - loss: 4.88170 - diff: 7.07mlTrain batch 9/31 - 104.5ms/batch - loss: 6.32904 - diff: 8.02mlTrain batch 10/31 - 94.1ms/batch - loss: 6.72349 - diff: 8.17mlTrain batch 11/31 - 94.2ms/batch - loss: 6.74515 - diff: 8.31mlTrain batch 12/31 - 95.0ms/batch - loss: 6.44928 - diff: 8.12mlTrain batch 13/31 - 125.9ms/batch - loss: 6.40200 - diff: 8.14mlTrain batch 14/31 - 95.6ms/batch - loss: 6.21115 - diff: 8.01mlTrain batch 15/31 - 94.0ms/batch - loss: 5.89581 - diff: 7.74mlTrain batch 16/31 - 95.0ms/batch - loss: 5.68110 - diff: 7.55mlTrain batch 17/31 - 95.0ms/batch - loss: 5.44941 - diff: 7.34mlTrain batch 18/31 - 96.3ms/batch - loss: 5.53676 - diff: 7.44mlTrain batch 19/31 - 98.6ms/batch - loss: 5.39356 - diff: 7.32mlTrain batch 20/31 - 95.1ms/batch - loss: 5.39299 - diff: 7.31mlTrain batch 21/31 - 100.5ms/batch - loss: 5.42477 - diff: 7.30mlTrain batch 22/31 - 94.7ms/batch - loss: 5.32945 - diff: 7.21mlTrain batch 23/31 - 100.4ms/batch - loss: 5.47841 - diff: 7.30mlTrain batch 24/31 - 94.2ms/batch - loss: 5.31851 - diff: 7.18mlTrain batch 25/31 - 97.6ms/batch - loss: 5.16752 - diff: 7.05mlTrain batch 26/31 - 95.3ms/batch - loss: 5.28493 - diff: 7.13mlTrain batch 27/31 - 104.8ms/batch - loss: 5.22282 - diff: 7.11mlTrain batch 28/31 - 94.9ms/batch - loss: 5.18310 - diff: 7.10mlTrain batch 29/31 - 103.5ms/batch - loss: 5.09403 - diff: 7.04mlTrain batch 30/31 - 95.1ms/batch - loss: 5.05546 - diff: 7.01mlTrain batch 31/31 - 68.6ms/batch - loss: 5.08336 - diff: 7.00mlTrain batch 31/31 - 9.8s 68.6ms/batch - loss: 5.08336 - diff: 7.00ml
Test 0.7s: val_loss: 22.55028 - diff: 14.09ml

Epoch 141: current best loss = 19.29070, at epoch 82
Train batch 1/31 - 103.7ms/batch - loss: 5.50631 - diff: 7.26mlTrain batch 2/31 - 95.0ms/batch - loss: 5.28688 - diff: 7.37mlTrain batch 3/31 - 115.9ms/batch - loss: 4.30317 - diff: 6.56mlTrain batch 4/31 - 93.9ms/batch - loss: 4.64677 - diff: 6.82mlTrain batch 5/31 - 95.0ms/batch - loss: 4.86916 - diff: 6.96mlTrain batch 6/31 - 93.7ms/batch - loss: 4.48096 - diff: 6.63mlTrain batch 7/31 - 106.1ms/batch - loss: 5.27801 - diff: 6.76mlTrain batch 8/31 - 106.7ms/batch - loss: 5.17754 - diff: 6.73mlTrain batch 9/31 - 110.6ms/batch - loss: 4.92455 - diff: 6.57mlTrain batch 10/31 - 93.9ms/batch - loss: 5.03978 - diff: 6.75mlTrain batch 11/31 - 104.4ms/batch - loss: 5.81027 - diff: 7.08mlTrain batch 12/31 - 93.8ms/batch - loss: 5.62879 - diff: 6.96mlTrain batch 13/31 - 98.4ms/batch - loss: 5.44089 - diff: 6.90mlTrain batch 14/31 - 97.0ms/batch - loss: 5.65805 - diff: 7.10mlTrain batch 15/31 - 94.3ms/batch - loss: 5.47127 - diff: 6.96mlTrain batch 16/31 - 94.0ms/batch - loss: 5.33963 - diff: 6.90mlTrain batch 17/31 - 95.1ms/batch - loss: 5.27179 - diff: 6.83mlTrain batch 18/31 - 96.5ms/batch - loss: 5.16587 - diff: 6.78mlTrain batch 19/31 - 94.4ms/batch - loss: 5.36627 - diff: 6.99mlTrain batch 20/31 - 97.9ms/batch - loss: 5.84194 - diff: 7.35mlTrain batch 21/31 - 114.6ms/batch - loss: 5.77760 - diff: 7.31mlTrain batch 22/31 - 94.2ms/batch - loss: 5.65345 - diff: 7.23mlTrain batch 23/31 - 94.7ms/batch - loss: 5.67266 - diff: 7.26mlTrain batch 24/31 - 98.3ms/batch - loss: 5.53099 - diff: 7.13mlTrain batch 25/31 - 94.7ms/batch - loss: 5.63632 - diff: 7.21mlTrain batch 26/31 - 97.1ms/batch - loss: 5.65147 - diff: 7.23mlTrain batch 27/31 - 95.5ms/batch - loss: 5.54880 - diff: 7.15mlTrain batch 28/31 - 95.2ms/batch - loss: 5.55623 - diff: 7.20mlTrain batch 29/31 - 95.5ms/batch - loss: 5.47869 - diff: 7.17mlTrain batch 30/31 - 94.3ms/batch - loss: 5.44635 - diff: 7.14mlTrain batch 31/31 - 68.6ms/batch - loss: 11.09019 - diff: 7.42mlTrain batch 31/31 - 9.8s 68.6ms/batch - loss: 11.09019 - diff: 7.42ml
Test 0.7s: val_loss: 25.44154 - diff: 14.10ml

Epoch 142: current best loss = 19.29070, at epoch 82
Train batch 1/31 - 109.9ms/batch - loss: 6.45061 - diff: 8.74mlTrain batch 2/31 - 94.8ms/batch - loss: 6.63278 - diff: 8.95mlTrain batch 3/31 - 98.4ms/batch - loss: 6.47883 - diff: 8.29mlTrain batch 4/31 - 94.2ms/batch - loss: 5.55362 - diff: 7.55mlTrain batch 5/31 - 97.7ms/batch - loss: 5.12125 - diff: 7.35mlTrain batch 6/31 - 95.1ms/batch - loss: 6.60841 - diff: 8.43mlTrain batch 7/31 - 96.7ms/batch - loss: 6.18934 - diff: 8.08mlTrain batch 8/31 - 94.1ms/batch - loss: 5.94906 - diff: 7.94mlTrain batch 9/31 - 96.4ms/batch - loss: 5.63333 - diff: 7.64mlTrain batch 10/31 - 94.9ms/batch - loss: 5.65100 - diff: 7.70mlTrain batch 11/31 - 95.9ms/batch - loss: 6.83866 - diff: 8.50mlTrain batch 12/31 - 94.8ms/batch - loss: 6.44866 - diff: 8.23mlTrain batch 13/31 - 96.8ms/batch - loss: 6.33130 - diff: 8.20mlTrain batch 14/31 - 98.2ms/batch - loss: 6.06666 - diff: 7.98mlTrain batch 15/31 - 94.1ms/batch - loss: 6.37098 - diff: 8.23mlTrain batch 16/31 - 95.7ms/batch - loss: 6.40910 - diff: 8.26mlTrain batch 17/31 - 94.2ms/batch - loss: 6.38329 - diff: 8.25mlTrain batch 18/31 - 95.2ms/batch - loss: 6.11264 - diff: 8.01mlTrain batch 19/31 - 94.7ms/batch - loss: 6.03532 - diff: 7.95mlTrain batch 20/31 - 95.4ms/batch - loss: 6.10268 - diff: 8.02mlTrain batch 21/31 - 95.0ms/batch - loss: 5.89220 - diff: 7.81mlTrain batch 22/31 - 96.1ms/batch - loss: 5.74428 - diff: 7.69mlTrain batch 23/31 - 95.1ms/batch - loss: 5.63645 - diff: 7.61mlTrain batch 24/31 - 95.0ms/batch - loss: 5.82690 - diff: 7.72mlTrain batch 25/31 - 94.3ms/batch - loss: 7.87658 - diff: 8.21mlTrain batch 26/31 - 95.6ms/batch - loss: 7.83706 - diff: 8.21mlTrain batch 27/31 - 94.5ms/batch - loss: 7.77204 - diff: 8.24mlTrain batch 28/31 - 95.2ms/batch - loss: 7.62520 - diff: 8.16mlTrain batch 29/31 - 93.9ms/batch - loss: 7.57991 - diff: 8.15mlTrain batch 30/31 - 95.5ms/batch - loss: 7.45792 - diff: 8.11mlTrain batch 31/31 - 74.4ms/batch - loss: 7.39361 - diff: 8.05mlTrain batch 31/31 - 9.8s 74.4ms/batch - loss: 7.39361 - diff: 8.05ml
Test 0.7s: val_loss: 22.56127 - diff: 13.99ml

Epoch 143: current best loss = 19.29070, at epoch 82
Train batch 1/31 - 116.2ms/batch - loss: 9.57456 - diff: 10.64mlTrain batch 2/31 - 94.3ms/batch - loss: 6.05996 - diff: 7.91mlTrain batch 3/31 - 96.3ms/batch - loss: 8.47567 - diff: 9.59mlTrain batch 4/31 - 94.2ms/batch - loss: 8.05812 - diff: 9.55mlTrain batch 5/31 - 94.2ms/batch - loss: 7.32101 - diff: 8.85mlTrain batch 6/31 - 94.5ms/batch - loss: 6.71741 - diff: 8.48mlTrain batch 7/31 - 93.9ms/batch - loss: 6.50205 - diff: 8.39mlTrain batch 8/31 - 95.0ms/batch - loss: 6.15159 - diff: 8.11mlTrain batch 9/31 - 94.0ms/batch - loss: 5.99519 - diff: 7.92mlTrain batch 10/31 - 94.9ms/batch - loss: 5.71004 - diff: 7.67mlTrain batch 11/31 - 94.0ms/batch - loss: 5.41339 - diff: 7.50mlTrain batch 12/31 - 96.3ms/batch - loss: 5.33950 - diff: 7.45mlTrain batch 13/31 - 95.2ms/batch - loss: 5.22059 - diff: 7.37mlTrain batch 14/31 - 94.9ms/batch - loss: 5.10450 - diff: 7.23mlTrain batch 15/31 - 114.6ms/batch - loss: 5.55261 - diff: 7.55mlTrain batch 16/31 - 98.6ms/batch - loss: 5.42328 - diff: 7.44mlTrain batch 17/31 - 93.9ms/batch - loss: 5.74569 - diff: 7.73mlTrain batch 18/31 - 95.0ms/batch - loss: 5.71936 - diff: 7.67mlTrain batch 19/31 - 109.5ms/batch - loss: 5.58633 - diff: 7.51mlTrain batch 20/31 - 94.2ms/batch - loss: 5.47603 - diff: 7.40mlTrain batch 21/31 - 101.6ms/batch - loss: 5.39433 - diff: 7.35mlTrain batch 22/31 - 93.6ms/batch - loss: 5.48528 - diff: 7.37mlTrain batch 23/31 - 106.7ms/batch - loss: 5.53954 - diff: 7.46mlTrain batch 24/31 - 93.8ms/batch - loss: 5.59359 - diff: 7.47mlTrain batch 25/31 - 101.3ms/batch - loss: 5.81108 - diff: 7.58mlTrain batch 26/31 - 94.7ms/batch - loss: 5.83066 - diff: 7.64mlTrain batch 27/31 - 124.0ms/batch - loss: 5.71176 - diff: 7.55mlTrain batch 28/31 - 93.7ms/batch - loss: 5.84352 - diff: 7.62mlTrain batch 29/31 - 108.3ms/batch - loss: 6.03414 - diff: 7.75mlTrain batch 30/31 - 93.9ms/batch - loss: 5.97051 - diff: 7.71mlTrain batch 31/31 - 69.6ms/batch - loss: 5.94067 - diff: 7.66mlTrain batch 31/31 - 9.8s 69.6ms/batch - loss: 5.94067 - diff: 7.66ml
Test 0.7s: val_loss: 26.95042 - diff: 14.19ml

Epoch 144: current best loss = 19.29070, at epoch 82
Train batch 1/31 - 113.7ms/batch - loss: 4.83062 - diff: 7.26mlTrain batch 2/31 - 98.0ms/batch - loss: 4.84408 - diff: 7.28mlTrain batch 3/31 - 100.8ms/batch - loss: 4.70292 - diff: 7.22mlTrain batch 4/31 - 95.9ms/batch - loss: 4.35418 - diff: 6.95mlTrain batch 5/31 - 97.1ms/batch - loss: 3.70570 - diff: 6.23mlTrain batch 6/31 - 100.4ms/batch - loss: 3.35509 - diff: 5.87mlTrain batch 7/31 - 106.2ms/batch - loss: 3.32482 - diff: 5.81mlTrain batch 8/31 - 94.8ms/batch - loss: 3.44741 - diff: 5.96mlTrain batch 9/31 - 99.6ms/batch - loss: 4.74581 - diff: 6.66mlTrain batch 10/31 - 94.1ms/batch - loss: 8.02927 - diff: 8.32mlTrain batch 11/31 - 105.3ms/batch - loss: 7.57431 - diff: 8.06mlTrain batch 12/31 - 94.5ms/batch - loss: 7.44432 - diff: 8.06mlTrain batch 13/31 - 95.2ms/batch - loss: 8.28647 - diff: 8.11mlTrain batch 14/31 - 95.2ms/batch - loss: 7.97060 - diff: 8.01mlTrain batch 15/31 - 118.5ms/batch - loss: 7.98849 - diff: 8.10mlTrain batch 16/31 - 99.1ms/batch - loss: 7.83465 - diff: 8.08mlTrain batch 17/31 - 97.1ms/batch - loss: 7.57125 - diff: 7.96mlTrain batch 18/31 - 94.6ms/batch - loss: 7.43041 - diff: 7.88mlTrain batch 19/31 - 98.6ms/batch - loss: 7.24754 - diff: 7.80mlTrain batch 20/31 - 95.3ms/batch - loss: 7.19253 - diff: 7.81mlTrain batch 21/31 - 98.8ms/batch - loss: 6.90962 - diff: 7.60mlTrain batch 22/31 - 94.7ms/batch - loss: 6.73249 - diff: 7.50mlTrain batch 23/31 - 97.2ms/batch - loss: 6.53514 - diff: 7.37mlTrain batch 24/31 - 95.3ms/batch - loss: 6.57607 - diff: 7.45mlTrain batch 25/31 - 98.8ms/batch - loss: 6.42691 - diff: 7.37mlTrain batch 26/31 - 97.3ms/batch - loss: 6.28258 - diff: 7.28mlTrain batch 27/31 - 93.8ms/batch - loss: 6.20058 - diff: 7.22mlTrain batch 28/31 - 95.2ms/batch - loss: 6.12095 - diff: 7.21mlTrain batch 29/31 - 93.8ms/batch - loss: 6.40850 - diff: 7.43mlTrain batch 30/31 - 95.6ms/batch - loss: 6.31946 - diff: 7.38mlTrain batch 31/31 - 69.5ms/batch - loss: 6.32590 - diff: 7.35mlTrain batch 31/31 - 9.8s 69.5ms/batch - loss: 6.32590 - diff: 7.35ml
Test 0.7s: val_loss: 23.14016 - diff: 14.16ml

Epoch 145: current best loss = 19.29070, at epoch 82
Train batch 1/31 - 98.3ms/batch - loss: 2.34229 - diff: 5.36mlTrain batch 2/31 - 93.7ms/batch - loss: 2.28166 - diff: 5.38mlTrain batch 3/31 - 93.8ms/batch - loss: 2.68562 - diff: 5.60mlTrain batch 4/31 - 94.1ms/batch - loss: 3.11284 - diff: 5.77mlTrain batch 5/31 - 94.1ms/batch - loss: 3.00378 - diff: 5.70mlTrain batch 6/31 - 93.6ms/batch - loss: 3.36859 - diff: 6.05mlTrain batch 7/31 - 94.2ms/batch - loss: 4.18181 - diff: 6.72mlTrain batch 8/31 - 93.4ms/batch - loss: 4.32141 - diff: 6.70mlTrain batch 9/31 - 96.7ms/batch - loss: 4.23773 - diff: 6.62mlTrain batch 10/31 - 94.8ms/batch - loss: 4.01725 - diff: 6.44mlTrain batch 11/31 - 97.4ms/batch - loss: 4.37504 - diff: 6.74mlTrain batch 12/31 - 94.6ms/batch - loss: 4.45271 - diff: 6.84mlTrain batch 13/31 - 94.6ms/batch - loss: 4.43995 - diff: 6.82mlTrain batch 14/31 - 93.8ms/batch - loss: 4.50990 - diff: 6.88mlTrain batch 15/31 - 94.6ms/batch - loss: 4.56818 - diff: 6.95mlTrain batch 16/31 - 94.5ms/batch - loss: 4.54813 - diff: 6.94mlTrain batch 17/31 - 98.9ms/batch - loss: 4.73699 - diff: 7.06mlTrain batch 18/31 - 95.4ms/batch - loss: 4.86704 - diff: 7.03mlTrain batch 19/31 - 94.3ms/batch - loss: 4.93471 - diff: 7.10mlTrain batch 20/31 - 94.8ms/batch - loss: 4.99389 - diff: 7.15mlTrain batch 21/31 - 95.0ms/batch - loss: 4.86509 - diff: 7.01mlTrain batch 22/31 - 94.5ms/batch - loss: 4.91528 - diff: 7.08mlTrain batch 23/31 - 94.6ms/batch - loss: 5.61333 - diff: 7.50mlTrain batch 24/31 - 96.6ms/batch - loss: 5.62281 - diff: 7.48mlTrain batch 25/31 - 93.9ms/batch - loss: 5.68359 - diff: 7.52mlTrain batch 26/31 - 96.6ms/batch - loss: 5.74639 - diff: 7.59mlTrain batch 27/31 - 94.0ms/batch - loss: 5.84570 - diff: 7.57mlTrain batch 28/31 - 95.9ms/batch - loss: 5.71135 - diff: 7.47mlTrain batch 29/31 - 93.6ms/batch - loss: 5.68363 - diff: 7.45mlTrain batch 30/31 - 94.2ms/batch - loss: 5.66487 - diff: 7.47mlTrain batch 31/31 - 68.2ms/batch - loss: 5.66215 - diff: 7.44mlTrain batch 31/31 - 9.9s 68.2ms/batch - loss: 5.66215 - diff: 7.44ml
Test 0.6s: val_loss: 24.61483 - diff: 14.27ml

Epoch 146: current best loss = 19.29070, at epoch 82
Train batch 1/31 - 117.1ms/batch - loss: 6.19007 - diff: 7.39mlTrain batch 2/31 - 94.5ms/batch - loss: 7.50560 - diff: 8.00mlTrain batch 3/31 - 107.0ms/batch - loss: 8.23370 - diff: 9.18mlTrain batch 4/31 - 96.3ms/batch - loss: 7.30886 - diff: 8.47mlTrain batch 5/31 - 108.6ms/batch - loss: 8.10660 - diff: 8.88mlTrain batch 6/31 - 95.2ms/batch - loss: 7.63812 - diff: 8.72mlTrain batch 7/31 - 104.7ms/batch - loss: 6.83213 - diff: 8.12mlTrain batch 8/31 - 95.4ms/batch - loss: 6.49520 - diff: 7.93mlTrain batch 9/31 - 107.9ms/batch - loss: 6.04134 - diff: 7.61mlTrain batch 10/31 - 94.6ms/batch - loss: 7.08855 - diff: 8.30mlTrain batch 11/31 - 108.0ms/batch - loss: 6.89452 - diff: 8.17mlTrain batch 12/31 - 93.6ms/batch - loss: 7.36416 - diff: 8.36mlTrain batch 13/31 - 106.1ms/batch - loss: 7.05143 - diff: 8.23mlTrain batch 14/31 - 93.8ms/batch - loss: 7.16005 - diff: 8.40mlTrain batch 15/31 - 96.8ms/batch - loss: 6.80086 - diff: 8.11mlTrain batch 16/31 - 93.0ms/batch - loss: 7.12076 - diff: 8.35mlTrain batch 17/31 - 116.1ms/batch - loss: 6.79064 - diff: 8.06mlTrain batch 18/31 - 100.6ms/batch - loss: 6.69937 - diff: 8.03mlTrain batch 19/31 - 94.9ms/batch - loss: 6.57500 - diff: 7.97mlTrain batch 20/31 - 95.4ms/batch - loss: 6.41752 - diff: 7.89mlTrain batch 21/31 - 123.9ms/batch - loss: 6.60599 - diff: 8.09mlTrain batch 22/31 - 94.6ms/batch - loss: 6.47125 - diff: 8.01mlTrain batch 23/31 - 110.6ms/batch - loss: 6.29223 - diff: 7.90mlTrain batch 24/31 - 95.2ms/batch - loss: 6.13836 - diff: 7.78mlTrain batch 25/31 - 106.7ms/batch - loss: 6.08782 - diff: 7.72mlTrain batch 26/31 - 94.4ms/batch - loss: 6.05999 - diff: 7.69mlTrain batch 27/31 - 107.6ms/batch - loss: 5.97655 - diff: 7.64mlTrain batch 28/31 - 93.4ms/batch - loss: 5.97013 - diff: 7.65mlTrain batch 29/31 - 99.6ms/batch - loss: 5.81777 - diff: 7.51mlTrain batch 30/31 - 93.4ms/batch - loss: 6.44066 - diff: 7.85mlTrain batch 31/31 - 68.1ms/batch - loss: 6.57577 - diff: 7.87mlTrain batch 31/31 - 9.9s 68.1ms/batch - loss: 6.57577 - diff: 7.87ml
Test 0.7s: val_loss: 23.12332 - diff: 14.26ml

Epoch 147: current best loss = 19.29070, at epoch 82
Train batch 1/31 - 109.7ms/batch - loss: 6.15829 - diff: 7.95mlTrain batch 2/31 - 96.1ms/batch - loss: 4.46320 - diff: 6.49mlTrain batch 3/31 - 99.3ms/batch - loss: 3.89325 - diff: 6.18mlTrain batch 4/31 - 97.8ms/batch - loss: 4.10085 - diff: 6.49mlTrain batch 5/31 - 107.2ms/batch - loss: 5.99453 - diff: 7.77mlTrain batch 6/31 - 94.3ms/batch - loss: 5.42757 - diff: 7.33mlTrain batch 7/31 - 97.3ms/batch - loss: 5.92323 - diff: 7.75mlTrain batch 8/31 - 95.0ms/batch - loss: 5.81471 - diff: 7.69mlTrain batch 9/31 - 99.1ms/batch - loss: 5.53336 - diff: 7.50mlTrain batch 10/31 - 95.2ms/batch - loss: 5.30350 - diff: 7.30mlTrain batch 11/31 - 99.1ms/batch - loss: 5.67188 - diff: 7.51mlTrain batch 12/31 - 98.1ms/batch - loss: 5.85684 - diff: 7.70mlTrain batch 13/31 - 109.2ms/batch - loss: 5.74498 - diff: 7.62mlTrain batch 14/31 - 96.2ms/batch - loss: 5.50000 - diff: 7.37mlTrain batch 15/31 - 96.3ms/batch - loss: 5.49057 - diff: 7.39mlTrain batch 16/31 - 98.4ms/batch - loss: 5.25075 - diff: 7.17mlTrain batch 17/31 - 136.2ms/batch - loss: 5.47345 - diff: 7.38mlTrain batch 18/31 - 99.9ms/batch - loss: 5.31949 - diff: 7.25mlTrain batch 19/31 - 101.4ms/batch - loss: 5.28604 - diff: 7.24mlTrain batch 20/31 - 93.7ms/batch - loss: 5.29899 - diff: 7.22mlTrain batch 21/31 - 98.6ms/batch - loss: 5.51597 - diff: 7.37mlTrain batch 22/31 - 100.0ms/batch - loss: 5.42534 - diff: 7.29mlTrain batch 23/31 - 101.6ms/batch - loss: 5.49900 - diff: 7.28mlTrain batch 24/31 - 95.1ms/batch - loss: 5.42953 - diff: 7.23mlTrain batch 25/31 - 98.4ms/batch - loss: 5.40234 - diff: 7.18mlTrain batch 26/31 - 97.6ms/batch - loss: 5.33482 - diff: 7.16mlTrain batch 27/31 - 98.1ms/batch - loss: 5.46089 - diff: 7.28mlTrain batch 28/31 - 96.2ms/batch - loss: 5.48332 - diff: 7.31mlTrain batch 29/31 - 97.6ms/batch - loss: 5.39957 - diff: 7.23mlTrain batch 30/31 - 96.0ms/batch - loss: 5.34928 - diff: 7.21mlTrain batch 31/31 - 70.0ms/batch - loss: 5.80947 - diff: 7.27mlTrain batch 31/31 - 9.9s 70.0ms/batch - loss: 5.80947 - diff: 7.27ml
Test 0.7s: val_loss: 25.12553 - diff: 14.16ml

Epoch 148: current best loss = 19.29070, at epoch 82
Train batch 1/31 - 110.5ms/batch - loss: 3.46326 - diff: 6.17mlTrain batch 2/31 - 94.1ms/batch - loss: 7.97313 - diff: 8.82mlTrain batch 3/31 - 94.6ms/batch - loss: 9.53918 - diff: 10.37mlTrain batch 4/31 - 94.3ms/batch - loss: 7.54875 - diff: 8.85mlTrain batch 5/31 - 94.6ms/batch - loss: 6.96565 - diff: 8.35mlTrain batch 6/31 - 93.9ms/batch - loss: 7.09039 - diff: 8.57mlTrain batch 7/31 - 97.8ms/batch - loss: 6.39081 - diff: 8.07mlTrain batch 8/31 - 93.5ms/batch - loss: 5.96632 - diff: 7.79mlTrain batch 9/31 - 99.4ms/batch - loss: 5.65769 - diff: 7.55mlTrain batch 10/31 - 96.0ms/batch - loss: 5.60757 - diff: 7.53mlTrain batch 11/31 - 95.5ms/batch - loss: 5.34248 - diff: 7.37mlTrain batch 12/31 - 94.4ms/batch - loss: 5.14388 - diff: 7.24mlTrain batch 13/31 - 94.8ms/batch - loss: 5.73131 - diff: 7.69mlTrain batch 14/31 - 95.9ms/batch - loss: 5.75465 - diff: 7.64mlTrain batch 15/31 - 94.2ms/batch - loss: 5.58981 - diff: 7.51mlTrain batch 16/31 - 95.0ms/batch - loss: 5.43204 - diff: 7.39mlTrain batch 17/31 - 98.2ms/batch - loss: 5.31152 - diff: 7.28mlTrain batch 18/31 - 96.6ms/batch - loss: 5.30231 - diff: 7.29mlTrain batch 19/31 - 97.0ms/batch - loss: 5.89030 - diff: 7.67mlTrain batch 20/31 - 94.1ms/batch - loss: 5.92468 - diff: 7.69mlTrain batch 21/31 - 99.7ms/batch - loss: 5.92368 - diff: 7.73mlTrain batch 22/31 - 94.1ms/batch - loss: 6.50289 - diff: 8.08mlTrain batch 23/31 - 98.1ms/batch - loss: 6.32453 - diff: 7.96mlTrain batch 24/31 - 93.5ms/batch - loss: 6.78381 - diff: 8.10mlTrain batch 25/31 - 93.5ms/batch - loss: 6.83004 - diff: 8.06mlTrain batch 26/31 - 94.7ms/batch - loss: 6.68753 - diff: 7.96mlTrain batch 27/31 - 98.1ms/batch - loss: 6.73267 - diff: 8.03mlTrain batch 28/31 - 93.5ms/batch - loss: 6.77557 - diff: 8.01mlTrain batch 29/31 - 96.2ms/batch - loss: 6.75951 - diff: 7.99mlTrain batch 30/31 - 93.3ms/batch - loss: 6.78690 - diff: 8.03mlTrain batch 31/31 - 69.3ms/batch - loss: 6.91978 - diff: 8.03mlTrain batch 31/31 - 9.8s 69.3ms/batch - loss: 6.91978 - diff: 8.03ml
Test 0.7s: val_loss: 25.65621 - diff: 14.03ml
Epoch   149: reducing learning rate of group 0 to 3.9063e-06.

Epoch 149: current best loss = 19.29070, at epoch 82
Train batch 1/31 - 99.0ms/batch - loss: 9.45144 - diff: 7.31mlTrain batch 2/31 - 94.5ms/batch - loss: 9.60799 - diff: 9.32mlTrain batch 3/31 - 98.0ms/batch - loss: 7.33485 - diff: 8.13mlTrain batch 4/31 - 93.6ms/batch - loss: 6.79892 - diff: 7.95mlTrain batch 5/31 - 98.6ms/batch - loss: 5.86197 - diff: 7.33mlTrain batch 6/31 - 94.0ms/batch - loss: 5.57501 - diff: 7.22mlTrain batch 7/31 - 98.6ms/batch - loss: 5.09261 - diff: 6.87mlTrain batch 8/31 - 94.1ms/batch - loss: 4.87632 - diff: 6.83mlTrain batch 9/31 - 96.5ms/batch - loss: 5.58746 - diff: 7.39mlTrain batch 10/31 - 94.1ms/batch - loss: 5.63446 - diff: 7.33mlTrain batch 11/31 - 97.8ms/batch - loss: 5.68354 - diff: 7.29mlTrain batch 12/31 - 94.4ms/batch - loss: 5.46778 - diff: 7.16mlTrain batch 13/31 - 111.9ms/batch - loss: 5.29359 - diff: 7.08mlTrain batch 14/31 - 94.1ms/batch - loss: 5.18049 - diff: 7.00mlTrain batch 15/31 - 112.0ms/batch - loss: 5.47116 - diff: 7.20mlTrain batch 16/31 - 94.7ms/batch - loss: 5.43914 - diff: 7.18mlTrain batch 17/31 - 94.5ms/batch - loss: 5.35785 - diff: 7.20mlTrain batch 18/31 - 93.9ms/batch - loss: 5.29458 - diff: 7.19mlTrain batch 19/31 - 101.6ms/batch - loss: 5.29408 - diff: 7.23mlTrain batch 20/31 - 100.0ms/batch - loss: 5.35325 - diff: 7.28mlTrain batch 21/31 - 93.6ms/batch - loss: 5.34496 - diff: 7.24mlTrain batch 22/31 - 94.6ms/batch - loss: 5.22976 - diff: 7.16mlTrain batch 23/31 - 95.2ms/batch - loss: 5.20401 - diff: 7.14mlTrain batch 24/31 - 94.3ms/batch - loss: 5.47672 - diff: 7.33mlTrain batch 25/31 - 95.9ms/batch - loss: 5.39638 - diff: 7.27mlTrain batch 26/31 - 94.4ms/batch - loss: 5.42901 - diff: 7.25mlTrain batch 27/31 - 94.0ms/batch - loss: 5.47095 - diff: 7.29mlTrain batch 28/31 - 97.1ms/batch - loss: 5.38830 - diff: 7.23mlTrain batch 29/31 - 94.0ms/batch - loss: 5.40567 - diff: 7.24mlTrain batch 30/31 - 94.4ms/batch - loss: 5.46746 - diff: 7.30mlTrain batch 31/31 - 69.5ms/batch - loss: 6.10883 - diff: 7.39mlTrain batch 31/31 - 9.8s 69.5ms/batch - loss: 6.10883 - diff: 7.39ml
Test 0.7s: val_loss: 24.00957 - diff: 14.03ml

Traceback (most recent call last):
  File "train.py", line 266, in <module>
    plot_results(train_losses, test_losses, title=f"Loss {target_label}", save_as=exp_name + "_loss")
  File "/home/allochi/tfm/workspace/lib/utils.py", line 393, in plot_results
    plt.plot(train_values, "r", label="train")
  File "/home/allochi/.conda/envs/DL_env/lib/python3.8/site-packages/matplotlib/pyplot.py", line 2761, in plot
    return gca().plot(
  File "/home/allochi/.conda/envs/DL_env/lib/python3.8/site-packages/matplotlib/pyplot.py", line 879, in gca
    return gcf().gca(**kwargs)
  File "/home/allochi/.conda/envs/DL_env/lib/python3.8/site-packages/matplotlib/pyplot.py", line 611, in gcf
    return figure()
  File "/home/allochi/.conda/envs/DL_env/lib/python3.8/site-packages/matplotlib/pyplot.py", line 540, in figure
    figManager = new_figure_manager(num, figsize=figsize,
  File "/home/allochi/.conda/envs/DL_env/lib/python3.8/site-packages/matplotlib/backend_bases.py", line 3358, in new_figure_manager
    return cls.new_figure_manager_given_figure(num, fig)
  File "/home/allochi/.conda/envs/DL_env/lib/python3.8/site-packages/matplotlib/backends/_backend_tk.py", line 888, in new_figure_manager_given_figure
    window = tk.Tk(className="matplotlib")
  File "/home/allochi/.conda/envs/DL_env/lib/python3.8/tkinter/__init__.py", line 2261, in __init__
    self.tk = _tkinter.create(screenName, baseName, className, interactive, wantobjects, useTk, sync, use)
_tkinter.TclError: couldn't connect to display "localhost:10.0"
