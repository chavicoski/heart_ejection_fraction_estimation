nohup: ignoring input
2020-08-30 23:19:22.491015: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/allochi/protobuf_install/lib:/home/allochi/protobuf_install/lib:/usr/local/cuda-10.1/lib64/:/usr/local/cudnn/cuda10.1/dnn7.6.5/lib64/:/usr/local/cuda-10.0/lib64/:/usr/local/cudnn/cuda10/dnn7.6.5/lib64/
2020-08-30 23:19:22.491196: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/allochi/protobuf_install/lib:/home/allochi/protobuf_install/lib:/usr/local/cuda-10.1/lib64/:/usr/local/cudnn/cuda10.1/dnn7.6.5/lib64/:/usr/local/cuda-10.0/lib64/:/usr/local/cudnn/cuda10/dnn7.6.5/lib64/
2020-08-30 23:19:22.491214: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
Running experiment 2CH_preproc1_150x150_bySlices_dataset_allViews_Systole_VGG19_Adam-0.001_MSE_DA3
Going to train with the GPU in the slot 0 -> device model: GeForce GTX 1080
Model architecture:
 VGG19(
  (first_conv): Sequential(
    (0): Conv2d(30, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU()
    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (pretrained_block): Sequential(
    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU(inplace=True)
    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): ReLU(inplace=True)
    (5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (6): ReLU(inplace=True)
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (9): ReLU(inplace=True)
    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): ReLU(inplace=True)
    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (13): ReLU(inplace=True)
    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (15): ReLU(inplace=True)
    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (18): ReLU(inplace=True)
    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (20): ReLU(inplace=True)
    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (22): ReLU(inplace=True)
    (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (24): ReLU(inplace=True)
    (25): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (27): ReLU(inplace=True)
    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (29): ReLU(inplace=True)
    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (31): ReLU(inplace=True)
    (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (33): ReLU(inplace=True)
    (34): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (reduction_block): Sequential(
    (0): AdaptiveAvgPool2d(output_size=(1, 1))
    (1): Flatten()
  )
  (dense_block): Sequential(
    (0): Linear(in_features=512, out_features=512, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.4, inplace=False)
    (3): Linear(in_features=512, out_features=1, bias=True)
  )
) 


############################
# TRAIN PHASE:  150 epochs #
############################

Epoch 0: 
Train batch 1/16 - 1354.4ms/batch - loss: 219.80046 - diff: 71.50mlTrain batch 2/16 - 195.6ms/batch - loss: 200.55331 - diff: 70.48mlTrain batch 3/16 - 196.4ms/batch - loss: 190.57965 - diff: 68.61mlTrain batch 4/16 - 196.2ms/batch - loss: 209.38751 - diff: 70.47mlTrain batch 5/16 - 196.5ms/batch - loss: 208.86299 - diff: 70.37mlTrain batch 6/16 - 197.0ms/batch - loss: 195.40985 - diff: 68.38mlTrain batch 7/16 - 196.6ms/batch - loss: 202.89052 - diff: 69.32mlTrain batch 8/16 - 197.3ms/batch - loss: 199.50650 - diff: 68.71mlTrain batch 9/16 - 196.3ms/batch - loss: 193.17604 - diff: 66.83mlTrain batch 10/16 - 196.3ms/batch - loss: 188.44243 - diff: 65.81mlTrain batch 11/16 - 195.7ms/batch - loss: 184.78774 - diff: 64.74mlTrain batch 12/16 - 196.4ms/batch - loss: 197.06300 - diff: 64.68mlTrain batch 13/16 - 195.8ms/batch - loss: 187.71432 - diff: 62.85mlTrain batch 14/16 - 196.4ms/batch - loss: 176.35017 - diff: 60.11mlTrain batch 15/16 - 197.9ms/batch - loss: 169.05893 - diff: 58.30mlTrain batch 16/16 - 131.6ms/batch - loss: 167.03232 - diff: 57.31mlTrain batch 16/16 - 22.0s 131.6ms/batch - loss: 167.03232 - diff: 57.31ml
Test 7.0s: val_loss: 170.36791 - diff: 61.01ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Systole_VGG19_Adam-0.001_MSE_DA3_best

Epoch 1: current best loss = 170.36791, at epoch 0
Train batch 1/16 - 197.0ms/batch - loss: 276.10645 - diff: 48.10mlTrain batch 2/16 - 198.1ms/batch - loss: 175.32435 - diff: 40.88mlTrain batch 3/16 - 196.7ms/batch - loss: 126.53620 - diff: 34.76mlTrain batch 4/16 - 196.5ms/batch - loss: 107.42141 - diff: 34.32mlTrain batch 5/16 - 196.4ms/batch - loss: 96.70445 - diff: 33.53mlTrain batch 6/16 - 196.9ms/batch - loss: 91.17285 - diff: 33.59mlTrain batch 7/16 - 197.8ms/batch - loss: 87.38008 - diff: 33.89mlTrain batch 8/16 - 197.1ms/batch - loss: 82.45677 - diff: 33.53mlTrain batch 9/16 - 197.3ms/batch - loss: 76.71136 - diff: 32.46mlTrain batch 10/16 - 196.8ms/batch - loss: 74.61521 - diff: 32.01mlTrain batch 11/16 - 196.6ms/batch - loss: 70.02866 - diff: 31.24mlTrain batch 12/16 - 196.7ms/batch - loss: 69.29722 - diff: 31.58mlTrain batch 13/16 - 197.3ms/batch - loss: 66.86752 - diff: 31.27mlTrain batch 14/16 - 196.2ms/batch - loss: 64.58780 - diff: 30.99mlTrain batch 15/16 - 196.7ms/batch - loss: 65.99813 - diff: 31.48mlTrain batch 16/16 - 129.9ms/batch - loss: 71.66832 - diff: 31.93mlTrain batch 16/16 - 9.8s 129.9ms/batch - loss: 71.66832 - diff: 31.93ml
Test 0.8s: val_loss: 128.36673 - diff: 42.74ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Systole_VGG19_Adam-0.001_MSE_DA3_best

Epoch 2: current best loss = 128.36673, at epoch 1
Train batch 1/16 - 196.8ms/batch - loss: 48.49650 - diff: 26.77mlTrain batch 2/16 - 198.4ms/batch - loss: 55.74867 - diff: 29.55mlTrain batch 3/16 - 196.0ms/batch - loss: 55.17532 - diff: 30.83mlTrain batch 4/16 - 200.3ms/batch - loss: 55.60754 - diff: 31.46mlTrain batch 5/16 - 199.5ms/batch - loss: 63.38790 - diff: 32.20mlTrain batch 6/16 - 199.5ms/batch - loss: 58.50175 - diff: 31.48mlTrain batch 7/16 - 199.6ms/batch - loss: 85.02392 - diff: 34.14mlTrain batch 8/16 - 199.1ms/batch - loss: 78.66615 - diff: 33.18mlTrain batch 9/16 - 197.4ms/batch - loss: 75.90221 - diff: 33.19mlTrain batch 10/16 - 200.2ms/batch - loss: 71.95828 - diff: 32.64mlTrain batch 11/16 - 196.9ms/batch - loss: 70.45482 - diff: 32.42mlTrain batch 12/16 - 205.2ms/batch - loss: 67.80048 - diff: 31.80mlTrain batch 13/16 - 209.6ms/batch - loss: 65.34899 - diff: 31.37mlTrain batch 14/16 - 213.8ms/batch - loss: 65.98106 - diff: 31.74mlTrain batch 15/16 - 203.1ms/batch - loss: 64.23589 - diff: 31.35mlTrain batch 16/16 - 131.4ms/batch - loss: 66.87619 - diff: 31.23mlTrain batch 16/16 - 10.6s 131.4ms/batch - loss: 66.87619 - diff: 31.23ml
Test 0.8s: val_loss: 76.93614 - diff: 32.29ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Systole_VGG19_Adam-0.001_MSE_DA3_best

Epoch 3: current best loss = 76.93614, at epoch 2
Train batch 1/16 - 203.2ms/batch - loss: 31.86915 - diff: 25.79mlTrain batch 2/16 - 197.7ms/batch - loss: 31.62239 - diff: 25.31mlTrain batch 3/16 - 197.7ms/batch - loss: 27.56255 - diff: 23.43mlTrain batch 4/16 - 199.8ms/batch - loss: 25.83870 - diff: 22.84mlTrain batch 5/16 - 197.5ms/batch - loss: 33.12733 - diff: 25.00mlTrain batch 6/16 - 197.2ms/batch - loss: 31.14398 - diff: 24.57mlTrain batch 7/16 - 201.9ms/batch - loss: 32.08581 - diff: 24.53mlTrain batch 8/16 - 199.5ms/batch - loss: 31.27578 - diff: 24.34mlTrain batch 9/16 - 202.4ms/batch - loss: 39.02000 - diff: 26.19mlTrain batch 10/16 - 197.7ms/batch - loss: 40.20462 - diff: 26.41mlTrain batch 11/16 - 201.0ms/batch - loss: 40.99161 - diff: 26.85mlTrain batch 12/16 - 197.7ms/batch - loss: 44.66946 - diff: 27.20mlTrain batch 13/16 - 201.6ms/batch - loss: 49.95409 - diff: 28.24mlTrain batch 14/16 - 198.5ms/batch - loss: 50.88376 - diff: 28.46mlTrain batch 15/16 - 198.0ms/batch - loss: 49.73590 - diff: 28.22mlTrain batch 16/16 - 131.6ms/batch - loss: 67.33865 - diff: 29.12mlTrain batch 16/16 - 10.3s 131.6ms/batch - loss: 67.33865 - diff: 29.12ml
Test 0.8s: val_loss: 63.07149 - diff: 27.35ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Systole_VGG19_Adam-0.001_MSE_DA3_best

Epoch 4: current best loss = 63.07149, at epoch 3
Train batch 1/16 - 202.0ms/batch - loss: 112.75397 - diff: 42.32mlTrain batch 2/16 - 199.7ms/batch - loss: 73.17073 - diff: 33.94mlTrain batch 3/16 - 201.1ms/batch - loss: 64.37347 - diff: 32.39mlTrain batch 4/16 - 199.8ms/batch - loss: 64.39532 - diff: 32.20mlTrain batch 5/16 - 198.7ms/batch - loss: 58.55982 - diff: 31.32mlTrain batch 6/16 - 199.5ms/batch - loss: 55.80099 - diff: 31.11mlTrain batch 7/16 - 200.5ms/batch - loss: 53.10575 - diff: 30.76mlTrain batch 8/16 - 197.8ms/batch - loss: 53.87887 - diff: 31.16mlTrain batch 9/16 - 198.2ms/batch - loss: 57.17611 - diff: 31.69mlTrain batch 10/16 - 197.5ms/batch - loss: 55.29545 - diff: 31.36mlTrain batch 11/16 - 199.5ms/batch - loss: 53.51182 - diff: 31.08mlTrain batch 12/16 - 197.3ms/batch - loss: 53.85772 - diff: 31.24mlTrain batch 13/16 - 200.7ms/batch - loss: 52.59689 - diff: 30.74mlTrain batch 14/16 - 197.3ms/batch - loss: 50.67648 - diff: 30.21mlTrain batch 15/16 - 197.8ms/batch - loss: 65.32359 - diff: 31.23mlTrain batch 16/16 - 130.7ms/batch - loss: 66.46460 - diff: 31.07mlTrain batch 16/16 - 10.3s 130.7ms/batch - loss: 66.46460 - diff: 31.07ml
Test 0.8s: val_loss: 75.30316 - diff: 32.42ml

Epoch 5: current best loss = 63.07149, at epoch 3
Train batch 1/16 - 199.3ms/batch - loss: 64.18559 - diff: 29.61mlTrain batch 2/16 - 199.6ms/batch - loss: 127.63715 - diff: 30.92mlTrain batch 3/16 - 197.9ms/batch - loss: 100.91308 - diff: 29.31mlTrain batch 4/16 - 196.9ms/batch - loss: 92.84613 - diff: 31.07mlTrain batch 5/16 - 197.9ms/batch - loss: 83.10436 - diff: 29.85mlTrain batch 6/16 - 198.4ms/batch - loss: 75.81435 - diff: 29.20mlTrain batch 7/16 - 200.5ms/batch - loss: 70.72906 - diff: 29.08mlTrain batch 8/16 - 203.9ms/batch - loss: 69.39877 - diff: 28.99mlTrain batch 9/16 - 197.1ms/batch - loss: 67.65512 - diff: 29.45mlTrain batch 10/16 - 197.6ms/batch - loss: 66.68572 - diff: 29.73mlTrain batch 11/16 - 197.5ms/batch - loss: 64.84573 - diff: 29.35mlTrain batch 12/16 - 197.5ms/batch - loss: 63.70379 - diff: 29.53mlTrain batch 13/16 - 199.0ms/batch - loss: 65.38060 - diff: 29.87mlTrain batch 14/16 - 198.9ms/batch - loss: 63.91339 - diff: 29.91mlTrain batch 15/16 - 197.3ms/batch - loss: 61.30745 - diff: 29.36mlTrain batch 16/16 - 133.2ms/batch - loss: 60.45933 - diff: 29.09mlTrain batch 16/16 - 10.4s 133.2ms/batch - loss: 60.45933 - diff: 29.09ml
Test 0.8s: val_loss: 52.69072 - diff: 27.54ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Systole_VGG19_Adam-0.001_MSE_DA3_best

Epoch 6: current best loss = 52.69072, at epoch 5
Train batch 1/16 - 201.1ms/batch - loss: 71.38554 - diff: 33.48mlTrain batch 2/16 - 199.6ms/batch - loss: 50.33083 - diff: 29.45mlTrain batch 3/16 - 198.1ms/batch - loss: 49.98433 - diff: 29.08mlTrain batch 4/16 - 198.7ms/batch - loss: 44.24274 - diff: 27.96mlTrain batch 5/16 - 211.9ms/batch - loss: 49.72405 - diff: 28.65mlTrain batch 6/16 - 199.4ms/batch - loss: 48.66437 - diff: 28.11mlTrain batch 7/16 - 202.2ms/batch - loss: 49.69632 - diff: 28.72mlTrain batch 8/16 - 198.5ms/batch - loss: 47.85259 - diff: 28.46mlTrain batch 9/16 - 201.6ms/batch - loss: 65.62427 - diff: 29.23mlTrain batch 10/16 - 197.5ms/batch - loss: 64.27495 - diff: 29.35mlTrain batch 11/16 - 203.6ms/batch - loss: 63.87204 - diff: 29.36mlTrain batch 12/16 - 198.5ms/batch - loss: 62.51097 - diff: 29.61mlTrain batch 13/16 - 200.0ms/batch - loss: 59.25882 - diff: 28.94mlTrain batch 14/16 - 197.5ms/batch - loss: 57.80257 - diff: 28.53mlTrain batch 15/16 - 196.6ms/batch - loss: 59.27057 - diff: 28.82mlTrain batch 16/16 - 131.8ms/batch - loss: 60.53316 - diff: 28.85mlTrain batch 16/16 - 10.3s 131.8ms/batch - loss: 60.53316 - diff: 28.85ml
Test 0.9s: val_loss: 51.93368 - diff: 26.21ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Systole_VGG19_Adam-0.001_MSE_DA3_best

Epoch 7: current best loss = 51.93368, at epoch 6
Train batch 1/16 - 202.3ms/batch - loss: 51.02024 - diff: 30.31mlTrain batch 2/16 - 199.5ms/batch - loss: 50.05132 - diff: 29.89mlTrain batch 3/16 - 221.1ms/batch - loss: 45.49295 - diff: 28.93mlTrain batch 4/16 - 201.4ms/batch - loss: 49.19229 - diff: 29.04mlTrain batch 5/16 - 213.0ms/batch - loss: 46.06023 - diff: 28.44mlTrain batch 6/16 - 199.4ms/batch - loss: 49.27955 - diff: 28.82mlTrain batch 7/16 - 198.9ms/batch - loss: 49.72903 - diff: 29.14mlTrain batch 8/16 - 197.2ms/batch - loss: 51.73997 - diff: 29.57mlTrain batch 9/16 - 201.6ms/batch - loss: 50.44129 - diff: 29.25mlTrain batch 10/16 - 197.6ms/batch - loss: 50.60014 - diff: 29.48mlTrain batch 11/16 - 201.3ms/batch - loss: 48.64389 - diff: 29.18mlTrain batch 12/16 - 196.9ms/batch - loss: 58.74002 - diff: 29.29mlTrain batch 13/16 - 199.2ms/batch - loss: 57.42077 - diff: 29.27mlTrain batch 14/16 - 197.9ms/batch - loss: 59.94814 - diff: 29.64mlTrain batch 15/16 - 197.1ms/batch - loss: 57.85145 - diff: 29.20mlTrain batch 16/16 - 132.8ms/batch - loss: 58.43998 - diff: 29.27mlTrain batch 16/16 - 10.3s 132.8ms/batch - loss: 58.43998 - diff: 29.27ml
Test 0.8s: val_loss: 59.28761 - diff: 25.55ml

Epoch 8: current best loss = 51.93368, at epoch 6
Train batch 1/16 - 200.7ms/batch - loss: 41.14032 - diff: 26.37mlTrain batch 2/16 - 200.9ms/batch - loss: 126.15018 - diff: 33.94mlTrain batch 3/16 - 201.9ms/batch - loss: 110.95085 - diff: 33.96mlTrain batch 4/16 - 198.8ms/batch - loss: 93.11060 - diff: 32.23mlTrain batch 5/16 - 200.0ms/batch - loss: 80.01137 - diff: 30.61mlTrain batch 6/16 - 200.2ms/batch - loss: 74.71134 - diff: 30.34mlTrain batch 7/16 - 198.7ms/batch - loss: 68.40061 - diff: 29.53mlTrain batch 8/16 - 198.8ms/batch - loss: 63.09717 - diff: 28.77mlTrain batch 9/16 - 198.6ms/batch - loss: 63.07113 - diff: 29.08mlTrain batch 10/16 - 197.2ms/batch - loss: 61.37475 - diff: 29.14mlTrain batch 11/16 - 200.0ms/batch - loss: 61.32359 - diff: 29.47mlTrain batch 12/16 - 197.4ms/batch - loss: 58.12867 - diff: 28.66mlTrain batch 13/16 - 199.1ms/batch - loss: 57.64256 - diff: 28.68mlTrain batch 14/16 - 198.2ms/batch - loss: 55.84506 - diff: 28.53mlTrain batch 15/16 - 197.5ms/batch - loss: 56.44569 - diff: 28.80mlTrain batch 16/16 - 132.0ms/batch - loss: 56.60203 - diff: 28.75mlTrain batch 16/16 - 10.3s 132.0ms/batch - loss: 56.60203 - diff: 28.75ml
Test 0.8s: val_loss: 49.70214 - diff: 26.25ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Systole_VGG19_Adam-0.001_MSE_DA3_best

Epoch 9: current best loss = 49.70214, at epoch 8
Train batch 1/16 - 198.7ms/batch - loss: 16.60397 - diff: 18.27mlTrain batch 2/16 - 199.4ms/batch - loss: 26.42597 - diff: 21.78mlTrain batch 3/16 - 198.8ms/batch - loss: 25.59144 - diff: 21.94mlTrain batch 4/16 - 199.5ms/batch - loss: 31.57337 - diff: 23.85mlTrain batch 5/16 - 197.5ms/batch - loss: 29.89828 - diff: 23.86mlTrain batch 6/16 - 199.5ms/batch - loss: 31.62405 - diff: 24.15mlTrain batch 7/16 - 199.1ms/batch - loss: 35.04754 - diff: 25.16mlTrain batch 8/16 - 198.6ms/batch - loss: 38.48830 - diff: 25.73mlTrain batch 9/16 - 201.2ms/batch - loss: 57.85462 - diff: 27.08mlTrain batch 10/16 - 198.4ms/batch - loss: 56.82299 - diff: 27.14mlTrain batch 11/16 - 202.6ms/batch - loss: 56.57009 - diff: 27.43mlTrain batch 12/16 - 198.1ms/batch - loss: 56.34166 - diff: 27.54mlTrain batch 13/16 - 201.5ms/batch - loss: 59.82732 - diff: 28.34mlTrain batch 14/16 - 198.8ms/batch - loss: 58.79799 - diff: 28.41mlTrain batch 15/16 - 197.5ms/batch - loss: 57.49958 - diff: 28.42mlTrain batch 16/16 - 133.1ms/batch - loss: 57.01868 - diff: 28.28mlTrain batch 16/16 - 10.3s 133.1ms/batch - loss: 57.01868 - diff: 28.28ml
Test 0.8s: val_loss: 55.10515 - diff: 26.20ml

Epoch 10: current best loss = 49.70214, at epoch 8
Train batch 1/16 - 199.4ms/batch - loss: 51.65312 - diff: 30.63mlTrain batch 2/16 - 198.2ms/batch - loss: 48.57666 - diff: 30.06mlTrain batch 3/16 - 199.2ms/batch - loss: 54.00166 - diff: 32.21mlTrain batch 4/16 - 198.2ms/batch - loss: 47.65662 - diff: 30.33mlTrain batch 5/16 - 198.1ms/batch - loss: 46.67082 - diff: 29.61mlTrain batch 6/16 - 198.5ms/batch - loss: 51.05995 - diff: 30.15mlTrain batch 7/16 - 199.0ms/batch - loss: 51.93934 - diff: 30.71mlTrain batch 8/16 - 198.7ms/batch - loss: 50.53298 - diff: 29.94mlTrain batch 9/16 - 203.6ms/batch - loss: 46.97678 - diff: 28.71mlTrain batch 10/16 - 199.2ms/batch - loss: 46.30583 - diff: 28.48mlTrain batch 11/16 - 201.5ms/batch - loss: 59.95034 - diff: 29.26mlTrain batch 12/16 - 197.6ms/batch - loss: 59.08239 - diff: 29.09mlTrain batch 13/16 - 200.2ms/batch - loss: 57.88495 - diff: 29.10mlTrain batch 14/16 - 198.6ms/batch - loss: 59.52455 - diff: 29.42mlTrain batch 15/16 - 196.8ms/batch - loss: 58.06411 - diff: 29.24mlTrain batch 16/16 - 133.9ms/batch - loss: 58.52223 - diff: 29.20mlTrain batch 16/16 - 10.4s 133.9ms/batch - loss: 58.52223 - diff: 29.20ml
Test 0.8s: val_loss: 55.28592 - diff: 25.97ml

Epoch 11: current best loss = 49.70214, at epoch 8
Train batch 1/16 - 198.5ms/batch - loss: 55.39831 - diff: 29.99mlTrain batch 2/16 - 198.4ms/batch - loss: 43.11896 - diff: 27.91mlTrain batch 3/16 - 198.1ms/batch - loss: 45.22385 - diff: 27.80mlTrain batch 4/16 - 198.5ms/batch - loss: 84.13895 - diff: 30.38mlTrain batch 5/16 - 197.9ms/batch - loss: 72.53249 - diff: 28.89mlTrain batch 6/16 - 197.4ms/batch - loss: 68.26660 - diff: 29.18mlTrain batch 7/16 - 197.1ms/batch - loss: 63.30659 - diff: 28.81mlTrain batch 8/16 - 199.2ms/batch - loss: 64.40896 - diff: 29.06mlTrain batch 9/16 - 199.6ms/batch - loss: 65.58298 - diff: 29.88mlTrain batch 10/16 - 203.3ms/batch - loss: 63.11271 - diff: 29.63mlTrain batch 11/16 - 203.3ms/batch - loss: 59.61097 - diff: 29.13mlTrain batch 12/16 - 197.4ms/batch - loss: 61.17528 - diff: 29.42mlTrain batch 13/16 - 214.6ms/batch - loss: 58.74323 - diff: 29.13mlTrain batch 14/16 - 198.0ms/batch - loss: 56.51220 - diff: 28.75mlTrain batch 15/16 - 197.4ms/batch - loss: 57.67889 - diff: 29.32mlTrain batch 16/16 - 132.3ms/batch - loss: 57.43899 - diff: 29.02mlTrain batch 16/16 - 10.2s 132.3ms/batch - loss: 57.43899 - diff: 29.02ml
Test 0.8s: val_loss: 72.96992 - diff: 26.70ml

Epoch 12: current best loss = 49.70214, at epoch 8
Train batch 1/16 - 199.3ms/batch - loss: 17.20992 - diff: 19.48mlTrain batch 2/16 - 198.5ms/batch - loss: 30.85286 - diff: 24.72mlTrain batch 3/16 - 197.9ms/batch - loss: 42.62048 - diff: 27.04mlTrain batch 4/16 - 198.3ms/batch - loss: 41.11197 - diff: 25.83mlTrain batch 5/16 - 198.9ms/batch - loss: 43.18764 - diff: 26.69mlTrain batch 6/16 - 200.4ms/batch - loss: 41.49733 - diff: 26.15mlTrain batch 7/16 - 199.9ms/batch - loss: 37.55095 - diff: 24.91mlTrain batch 8/16 - 198.8ms/batch - loss: 36.94505 - diff: 24.86mlTrain batch 9/16 - 197.6ms/batch - loss: 36.38945 - diff: 24.97mlTrain batch 10/16 - 197.0ms/batch - loss: 35.04005 - diff: 24.48mlTrain batch 11/16 - 200.8ms/batch - loss: 34.93622 - diff: 24.50mlTrain batch 12/16 - 198.5ms/batch - loss: 36.00058 - diff: 24.68mlTrain batch 13/16 - 198.4ms/batch - loss: 35.72835 - diff: 24.61mlTrain batch 14/16 - 197.2ms/batch - loss: 37.42411 - diff: 25.29mlTrain batch 15/16 - 197.1ms/batch - loss: 42.98307 - diff: 26.49mlTrain batch 16/16 - 131.1ms/batch - loss: 62.12515 - diff: 27.58mlTrain batch 16/16 - 10.3s 131.1ms/batch - loss: 62.12515 - diff: 27.58ml
Test 0.8s: val_loss: 52.50982 - diff: 28.88ml

Epoch 13: current best loss = 49.70214, at epoch 8
Train batch 1/16 - 197.3ms/batch - loss: 39.92812 - diff: 27.10mlTrain batch 2/16 - 198.3ms/batch - loss: 56.73705 - diff: 31.91mlTrain batch 3/16 - 197.6ms/batch - loss: 54.03880 - diff: 30.41mlTrain batch 4/16 - 199.4ms/batch - loss: 51.13676 - diff: 30.04mlTrain batch 5/16 - 200.6ms/batch - loss: 46.77935 - diff: 28.64mlTrain batch 6/16 - 198.1ms/batch - loss: 46.35268 - diff: 28.95mlTrain batch 7/16 - 203.2ms/batch - loss: 44.35039 - diff: 28.65mlTrain batch 8/16 - 197.6ms/batch - loss: 47.67178 - diff: 29.44mlTrain batch 9/16 - 201.7ms/batch - loss: 47.26995 - diff: 29.59mlTrain batch 10/16 - 201.7ms/batch - loss: 48.11912 - diff: 29.80mlTrain batch 11/16 - 207.4ms/batch - loss: 62.09836 - diff: 30.70mlTrain batch 12/16 - 199.9ms/batch - loss: 62.66287 - diff: 30.59mlTrain batch 13/16 - 197.2ms/batch - loss: 60.44357 - diff: 30.19mlTrain batch 14/16 - 201.3ms/batch - loss: 59.63044 - diff: 29.79mlTrain batch 15/16 - 197.0ms/batch - loss: 57.61912 - diff: 29.29mlTrain batch 16/16 - 131.1ms/batch - loss: 56.15055 - diff: 28.76mlTrain batch 16/16 - 10.3s 131.1ms/batch - loss: 56.15055 - diff: 28.76ml
Test 0.8s: val_loss: 74.26524 - diff: 25.95ml

Epoch 14: current best loss = 49.70214, at epoch 8
Train batch 1/16 - 201.8ms/batch - loss: 62.75035 - diff: 31.47mlTrain batch 2/16 - 200.9ms/batch - loss: 63.61817 - diff: 31.54mlTrain batch 3/16 - 198.4ms/batch - loss: 54.87612 - diff: 29.05mlTrain batch 4/16 - 201.4ms/batch - loss: 88.86082 - diff: 30.63mlTrain batch 5/16 - 198.9ms/batch - loss: 83.68970 - diff: 29.90mlTrain batch 6/16 - 203.2ms/batch - loss: 77.44620 - diff: 29.61mlTrain batch 7/16 - 198.1ms/batch - loss: 68.60042 - diff: 27.92mlTrain batch 8/16 - 201.4ms/batch - loss: 64.93641 - diff: 27.60mlTrain batch 9/16 - 198.3ms/batch - loss: 63.30694 - diff: 28.04mlTrain batch 10/16 - 201.4ms/batch - loss: 63.17925 - diff: 28.89mlTrain batch 11/16 - 197.1ms/batch - loss: 61.22856 - diff: 28.77mlTrain batch 12/16 - 198.1ms/batch - loss: 58.74491 - diff: 28.42mlTrain batch 13/16 - 198.0ms/batch - loss: 56.63683 - diff: 28.21mlTrain batch 14/16 - 198.5ms/batch - loss: 55.76528 - diff: 28.38mlTrain batch 15/16 - 197.2ms/batch - loss: 53.52450 - diff: 27.86mlTrain batch 16/16 - 135.5ms/batch - loss: 55.17927 - diff: 27.98mlTrain batch 16/16 - 10.3s 135.5ms/batch - loss: 55.17927 - diff: 27.98ml
Test 0.8s: val_loss: 46.41544 - diff: 25.61ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Systole_VGG19_Adam-0.001_MSE_DA3_best

Epoch 15: current best loss = 46.41544, at epoch 14
Train batch 1/16 - 199.6ms/batch - loss: 14.71404 - diff: 16.75mlTrain batch 2/16 - 201.3ms/batch - loss: 18.35873 - diff: 18.53mlTrain batch 3/16 - 199.5ms/batch - loss: 30.04215 - diff: 23.33mlTrain batch 4/16 - 199.2ms/batch - loss: 35.52450 - diff: 23.88mlTrain batch 5/16 - 198.6ms/batch - loss: 41.48615 - diff: 24.70mlTrain batch 6/16 - 197.6ms/batch - loss: 41.58554 - diff: 25.16mlTrain batch 7/16 - 199.3ms/batch - loss: 58.65988 - diff: 25.80mlTrain batch 8/16 - 197.0ms/batch - loss: 58.39958 - diff: 26.19mlTrain batch 9/16 - 198.2ms/batch - loss: 60.26768 - diff: 27.24mlTrain batch 10/16 - 198.7ms/batch - loss: 58.12101 - diff: 26.99mlTrain batch 11/16 - 198.7ms/batch - loss: 55.41936 - diff: 26.68mlTrain batch 12/16 - 198.7ms/batch - loss: 54.95368 - diff: 26.87mlTrain batch 13/16 - 200.1ms/batch - loss: 54.22049 - diff: 26.83mlTrain batch 14/16 - 198.2ms/batch - loss: 52.46146 - diff: 26.66mlTrain batch 15/16 - 197.8ms/batch - loss: 51.30191 - diff: 26.77mlTrain batch 16/16 - 131.3ms/batch - loss: 52.75650 - diff: 26.82mlTrain batch 16/16 - 10.4s 131.3ms/batch - loss: 52.75650 - diff: 26.82ml
Test 0.8s: val_loss: 48.89090 - diff: 26.44ml

Epoch 16: current best loss = 46.41544, at epoch 14
Train batch 1/16 - 200.2ms/batch - loss: 48.51349 - diff: 31.86mlTrain batch 2/16 - 197.6ms/batch - loss: 52.12765 - diff: 32.59mlTrain batch 3/16 - 201.2ms/batch - loss: 54.60295 - diff: 33.12mlTrain batch 4/16 - 197.4ms/batch - loss: 54.25439 - diff: 31.87mlTrain batch 5/16 - 200.2ms/batch - loss: 57.69090 - diff: 31.45mlTrain batch 6/16 - 197.3ms/batch - loss: 59.31106 - diff: 31.78mlTrain batch 7/16 - 201.7ms/batch - loss: 55.45505 - diff: 30.77mlTrain batch 8/16 - 197.5ms/batch - loss: 52.96363 - diff: 30.41mlTrain batch 9/16 - 202.3ms/batch - loss: 66.20483 - diff: 30.65mlTrain batch 10/16 - 197.7ms/batch - loss: 62.03580 - diff: 29.84mlTrain batch 11/16 - 200.3ms/batch - loss: 59.31308 - diff: 29.46mlTrain batch 12/16 - 202.2ms/batch - loss: 55.75244 - diff: 28.62mlTrain batch 13/16 - 206.1ms/batch - loss: 53.88236 - diff: 28.35mlTrain batch 14/16 - 200.1ms/batch - loss: 52.00814 - diff: 27.96mlTrain batch 15/16 - 198.7ms/batch - loss: 53.03747 - diff: 28.37mlTrain batch 16/16 - 133.3ms/batch - loss: 52.53561 - diff: 28.04mlTrain batch 16/16 - 10.3s 133.3ms/batch - loss: 52.53561 - diff: 28.04ml
Test 0.8s: val_loss: 50.51099 - diff: 25.69ml

Epoch 17: current best loss = 46.41544, at epoch 14
Train batch 1/16 - 199.6ms/batch - loss: 12.45171 - diff: 15.80mlTrain batch 2/16 - 198.4ms/batch - loss: 19.71423 - diff: 19.76mlTrain batch 3/16 - 201.5ms/batch - loss: 20.09267 - diff: 20.21mlTrain batch 4/16 - 197.9ms/batch - loss: 24.93114 - diff: 21.80mlTrain batch 5/16 - 198.9ms/batch - loss: 53.76346 - diff: 23.89mlTrain batch 6/16 - 198.0ms/batch - loss: 50.65038 - diff: 24.02mlTrain batch 7/16 - 198.9ms/batch - loss: 47.99387 - diff: 24.15mlTrain batch 8/16 - 197.5ms/batch - loss: 45.86905 - diff: 24.02mlTrain batch 9/16 - 197.8ms/batch - loss: 45.80475 - diff: 24.52mlTrain batch 10/16 - 199.2ms/batch - loss: 43.82405 - diff: 24.44mlTrain batch 11/16 - 200.0ms/batch - loss: 52.54917 - diff: 26.48mlTrain batch 12/16 - 198.7ms/batch - loss: 51.53795 - diff: 26.43mlTrain batch 13/16 - 197.5ms/batch - loss: 52.01008 - diff: 26.76mlTrain batch 14/16 - 203.7ms/batch - loss: 50.76794 - diff: 26.50mlTrain batch 15/16 - 197.3ms/batch - loss: 49.35858 - diff: 26.43mlTrain batch 16/16 - 131.0ms/batch - loss: 50.52127 - diff: 26.59mlTrain batch 16/16 - 10.3s 131.0ms/batch - loss: 50.52127 - diff: 26.59ml
Test 0.8s: val_loss: 47.17135 - diff: 25.08ml

Epoch 18: current best loss = 46.41544, at epoch 14
Train batch 1/16 - 200.1ms/batch - loss: 19.03810 - diff: 19.20mlTrain batch 2/16 - 198.7ms/batch - loss: 115.45168 - diff: 32.67mlTrain batch 3/16 - 197.9ms/batch - loss: 91.53819 - diff: 30.75mlTrain batch 4/16 - 199.7ms/batch - loss: 75.25969 - diff: 29.03mlTrain batch 5/16 - 197.2ms/batch - loss: 64.24363 - diff: 27.71mlTrain batch 6/16 - 199.5ms/batch - loss: 62.21702 - diff: 28.42mlTrain batch 7/16 - 198.7ms/batch - loss: 59.52358 - diff: 28.40mlTrain batch 8/16 - 198.9ms/batch - loss: 58.37033 - diff: 28.30mlTrain batch 9/16 - 199.2ms/batch - loss: 56.06342 - diff: 28.23mlTrain batch 10/16 - 199.2ms/batch - loss: 54.02348 - diff: 27.85mlTrain batch 11/16 - 200.8ms/batch - loss: 55.30422 - diff: 27.87mlTrain batch 12/16 - 197.5ms/batch - loss: 54.64417 - diff: 28.02mlTrain batch 13/16 - 197.1ms/batch - loss: 53.93976 - diff: 27.86mlTrain batch 14/16 - 198.6ms/batch - loss: 53.54574 - diff: 27.93mlTrain batch 15/16 - 199.8ms/batch - loss: 51.96662 - diff: 27.63mlTrain batch 16/16 - 132.2ms/batch - loss: 51.05910 - diff: 27.29mlTrain batch 16/16 - 10.3s 132.2ms/batch - loss: 51.05910 - diff: 27.29ml
Test 0.8s: val_loss: 47.98710 - diff: 25.43ml

Epoch 19: current best loss = 46.41544, at epoch 14
Train batch 1/16 - 200.3ms/batch - loss: 18.27450 - diff: 20.27mlTrain batch 2/16 - 199.3ms/batch - loss: 51.01051 - diff: 28.29mlTrain batch 3/16 - 197.1ms/batch - loss: 100.06144 - diff: 30.21mlTrain batch 4/16 - 197.1ms/batch - loss: 84.98514 - diff: 29.22mlTrain batch 5/16 - 200.0ms/batch - loss: 74.46286 - diff: 27.90mlTrain batch 6/16 - 199.5ms/batch - loss: 77.94811 - diff: 28.91mlTrain batch 7/16 - 198.9ms/batch - loss: 69.42735 - diff: 27.62mlTrain batch 8/16 - 198.9ms/batch - loss: 64.82863 - diff: 27.51mlTrain batch 9/16 - 198.2ms/batch - loss: 62.36979 - diff: 27.87mlTrain batch 10/16 - 197.9ms/batch - loss: 63.24162 - diff: 28.62mlTrain batch 11/16 - 199.1ms/batch - loss: 61.48544 - diff: 28.34mlTrain batch 12/16 - 199.3ms/batch - loss: 58.95797 - diff: 27.95mlTrain batch 13/16 - 197.0ms/batch - loss: 57.28342 - diff: 27.71mlTrain batch 14/16 - 198.2ms/batch - loss: 54.90098 - diff: 27.39mlTrain batch 15/16 - 202.4ms/batch - loss: 52.56297 - diff: 26.91mlTrain batch 16/16 - 135.8ms/batch - loss: 51.93802 - diff: 26.77mlTrain batch 16/16 - 10.4s 135.8ms/batch - loss: 51.93802 - diff: 26.77ml
Test 0.8s: val_loss: 46.12843 - diff: 25.90ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Systole_VGG19_Adam-0.001_MSE_DA3_best

Epoch 20: current best loss = 46.12843, at epoch 19
Train batch 1/16 - 197.9ms/batch - loss: 30.13739 - diff: 25.40mlTrain batch 2/16 - 202.5ms/batch - loss: 24.39294 - diff: 22.55mlTrain batch 3/16 - 198.0ms/batch - loss: 28.00521 - diff: 22.56mlTrain batch 4/16 - 200.6ms/batch - loss: 45.33945 - diff: 26.61mlTrain batch 5/16 - 198.8ms/batch - loss: 43.06125 - diff: 26.48mlTrain batch 6/16 - 201.3ms/batch - loss: 41.41982 - diff: 26.13mlTrain batch 7/16 - 198.0ms/batch - loss: 39.16077 - diff: 25.52mlTrain batch 8/16 - 198.6ms/batch - loss: 38.26288 - diff: 25.32mlTrain batch 9/16 - 198.8ms/batch - loss: 37.01063 - diff: 24.57mlTrain batch 10/16 - 200.8ms/batch - loss: 37.24439 - diff: 24.80mlTrain batch 11/16 - 200.2ms/batch - loss: 41.64864 - diff: 25.08mlTrain batch 12/16 - 200.1ms/batch - loss: 42.67268 - diff: 25.41mlTrain batch 13/16 - 197.2ms/batch - loss: 41.64960 - diff: 25.22mlTrain batch 14/16 - 197.7ms/batch - loss: 51.88080 - diff: 26.46mlTrain batch 15/16 - 197.0ms/batch - loss: 50.02912 - diff: 26.24mlTrain batch 16/16 - 133.0ms/batch - loss: 49.18589 - diff: 26.06mlTrain batch 16/16 - 10.4s 133.0ms/batch - loss: 49.18589 - diff: 26.06ml
Test 0.8s: val_loss: 54.18465 - diff: 25.39ml

Epoch 21: current best loss = 46.12843, at epoch 19
Train batch 1/16 - 199.7ms/batch - loss: 37.23461 - diff: 29.56mlTrain batch 2/16 - 201.6ms/batch - loss: 51.80134 - diff: 28.18mlTrain batch 3/16 - 201.3ms/batch - loss: 55.57577 - diff: 29.12mlTrain batch 4/16 - 202.6ms/batch - loss: 47.67902 - diff: 27.33mlTrain batch 5/16 - 197.6ms/batch - loss: 45.17236 - diff: 26.52mlTrain batch 6/16 - 199.6ms/batch - loss: 41.97449 - diff: 26.06mlTrain batch 7/16 - 198.5ms/batch - loss: 44.68791 - diff: 26.86mlTrain batch 8/16 - 198.6ms/batch - loss: 43.02963 - diff: 26.29mlTrain batch 9/16 - 198.6ms/batch - loss: 40.94716 - diff: 25.86mlTrain batch 10/16 - 198.1ms/batch - loss: 41.04882 - diff: 25.97mlTrain batch 11/16 - 197.4ms/batch - loss: 41.60578 - diff: 25.90mlTrain batch 12/16 - 199.7ms/batch - loss: 41.95731 - diff: 25.77mlTrain batch 13/16 - 197.9ms/batch - loss: 55.70084 - diff: 26.93mlTrain batch 14/16 - 198.0ms/batch - loss: 53.42425 - diff: 26.49mlTrain batch 15/16 - 197.5ms/batch - loss: 52.83705 - diff: 26.62mlTrain batch 16/16 - 131.9ms/batch - loss: 52.20305 - diff: 26.40mlTrain batch 16/16 - 10.2s 131.9ms/batch - loss: 52.20305 - diff: 26.40ml
Test 0.8s: val_loss: 47.57923 - diff: 25.14ml

Epoch 22: current best loss = 46.12843, at epoch 19
Train batch 1/16 - 199.3ms/batch - loss: 41.42055 - diff: 26.57mlTrain batch 2/16 - 198.3ms/batch - loss: 41.46731 - diff: 27.92mlTrain batch 3/16 - 197.7ms/batch - loss: 41.37579 - diff: 27.82mlTrain batch 4/16 - 197.1ms/batch - loss: 48.91113 - diff: 28.77mlTrain batch 5/16 - 198.8ms/batch - loss: 46.87378 - diff: 28.10mlTrain batch 6/16 - 198.3ms/batch - loss: 67.28066 - diff: 28.80mlTrain batch 7/16 - 197.3ms/batch - loss: 62.24422 - diff: 28.28mlTrain batch 8/16 - 200.5ms/batch - loss: 60.87632 - diff: 28.47mlTrain batch 9/16 - 197.9ms/batch - loss: 56.27701 - diff: 27.59mlTrain batch 10/16 - 199.9ms/batch - loss: 55.13767 - diff: 27.79mlTrain batch 11/16 - 198.5ms/batch - loss: 52.98158 - diff: 27.35mlTrain batch 12/16 - 198.3ms/batch - loss: 50.77746 - diff: 26.99mlTrain batch 13/16 - 199.1ms/batch - loss: 50.10894 - diff: 27.02mlTrain batch 14/16 - 199.5ms/batch - loss: 47.50978 - diff: 26.26mlTrain batch 15/16 - 201.9ms/batch - loss: 46.56086 - diff: 26.13mlTrain batch 16/16 - 135.0ms/batch - loss: 48.73084 - diff: 26.28mlTrain batch 16/16 - 10.3s 135.0ms/batch - loss: 48.73084 - diff: 26.28ml
Test 0.8s: val_loss: 55.86123 - diff: 25.68ml

Epoch 23: current best loss = 46.12843, at epoch 19
Train batch 1/16 - 202.8ms/batch - loss: 54.11757 - diff: 26.81mlTrain batch 2/16 - 199.1ms/batch - loss: 40.11630 - diff: 25.08mlTrain batch 3/16 - 204.6ms/batch - loss: 85.14067 - diff: 28.23mlTrain batch 4/16 - 199.6ms/batch - loss: 73.17890 - diff: 27.31mlTrain batch 5/16 - 202.9ms/batch - loss: 66.51931 - diff: 26.70mlTrain batch 6/16 - 200.5ms/batch - loss: 71.12386 - diff: 28.17mlTrain batch 7/16 - 204.5ms/batch - loss: 68.64751 - diff: 28.78mlTrain batch 8/16 - 198.2ms/batch - loss: 63.68269 - diff: 28.01mlTrain batch 9/16 - 202.2ms/batch - loss: 59.65786 - diff: 27.53mlTrain batch 10/16 - 199.9ms/batch - loss: 56.91874 - diff: 27.51mlTrain batch 11/16 - 202.8ms/batch - loss: 54.05078 - diff: 27.06mlTrain batch 12/16 - 200.3ms/batch - loss: 51.52429 - diff: 26.66mlTrain batch 13/16 - 198.6ms/batch - loss: 50.72618 - diff: 26.55mlTrain batch 14/16 - 199.0ms/batch - loss: 50.30486 - diff: 26.70mlTrain batch 15/16 - 198.1ms/batch - loss: 48.56631 - diff: 26.38mlTrain batch 16/16 - 132.4ms/batch - loss: 48.51944 - diff: 26.24mlTrain batch 16/16 - 10.2s 132.4ms/batch - loss: 48.51944 - diff: 26.24ml
Test 0.8s: val_loss: 58.18419 - diff: 25.58ml

Epoch 24: current best loss = 46.12843, at epoch 19
Train batch 1/16 - 199.1ms/batch - loss: 58.68237 - diff: 30.23mlTrain batch 2/16 - 199.5ms/batch - loss: 45.09859 - diff: 26.62mlTrain batch 3/16 - 199.3ms/batch - loss: 54.96105 - diff: 28.34mlTrain batch 4/16 - 197.9ms/batch - loss: 45.59763 - diff: 25.45mlTrain batch 5/16 - 199.3ms/batch - loss: 38.77245 - diff: 23.37mlTrain batch 6/16 - 198.8ms/batch - loss: 75.68313 - diff: 27.82mlTrain batch 7/16 - 198.0ms/batch - loss: 72.08479 - diff: 28.27mlTrain batch 8/16 - 199.0ms/batch - loss: 66.50512 - diff: 27.75mlTrain batch 9/16 - 199.1ms/batch - loss: 61.31270 - diff: 26.99mlTrain batch 10/16 - 201.5ms/batch - loss: 59.75045 - diff: 26.91mlTrain batch 11/16 - 197.7ms/batch - loss: 56.33798 - diff: 26.25mlTrain batch 12/16 - 201.3ms/batch - loss: 54.77187 - diff: 26.32mlTrain batch 13/16 - 197.4ms/batch - loss: 54.08252 - diff: 26.51mlTrain batch 14/16 - 197.9ms/batch - loss: 51.67467 - diff: 26.18mlTrain batch 15/16 - 199.0ms/batch - loss: 50.92944 - diff: 26.42mlTrain batch 16/16 - 131.2ms/batch - loss: 49.76341 - diff: 26.05mlTrain batch 16/16 - 10.3s 131.2ms/batch - loss: 49.76341 - diff: 26.05ml
Test 0.8s: val_loss: 47.45330 - diff: 25.72ml

Epoch 25: current best loss = 46.12843, at epoch 19
Train batch 1/16 - 197.3ms/batch - loss: 87.80132 - diff: 32.13mlTrain batch 2/16 - 198.0ms/batch - loss: 66.66461 - diff: 29.06mlTrain batch 3/16 - 197.2ms/batch - loss: 53.00591 - diff: 26.93mlTrain batch 4/16 - 197.7ms/batch - loss: 46.80893 - diff: 26.32mlTrain batch 5/16 - 199.1ms/batch - loss: 44.77638 - diff: 26.23mlTrain batch 6/16 - 200.9ms/batch - loss: 43.65333 - diff: 25.48mlTrain batch 7/16 - 198.8ms/batch - loss: 63.57370 - diff: 27.69mlTrain batch 8/16 - 198.2ms/batch - loss: 61.24295 - diff: 27.76mlTrain batch 9/16 - 197.2ms/batch - loss: 56.94189 - diff: 27.19mlTrain batch 10/16 - 199.4ms/batch - loss: 54.00427 - diff: 26.71mlTrain batch 11/16 - 198.3ms/batch - loss: 50.39922 - diff: 25.83mlTrain batch 12/16 - 199.2ms/batch - loss: 48.69989 - diff: 25.57mlTrain batch 13/16 - 199.0ms/batch - loss: 47.81548 - diff: 25.61mlTrain batch 14/16 - 198.4ms/batch - loss: 48.04357 - diff: 25.92mlTrain batch 15/16 - 197.9ms/batch - loss: 46.24603 - diff: 25.55mlTrain batch 16/16 - 131.8ms/batch - loss: 46.05508 - diff: 25.59mlTrain batch 16/16 - 10.3s 131.8ms/batch - loss: 46.05508 - diff: 25.59ml
Test 0.8s: val_loss: 49.35584 - diff: 27.34ml

Epoch 26: current best loss = 46.12843, at epoch 19
Train batch 1/16 - 202.4ms/batch - loss: 34.17647 - diff: 24.63mlTrain batch 2/16 - 198.5ms/batch - loss: 34.23294 - diff: 24.89mlTrain batch 3/16 - 197.6ms/batch - loss: 28.97752 - diff: 22.18mlTrain batch 4/16 - 198.8ms/batch - loss: 29.06815 - diff: 22.77mlTrain batch 5/16 - 199.0ms/batch - loss: 26.37804 - diff: 22.05mlTrain batch 6/16 - 198.1ms/batch - loss: 26.79196 - diff: 22.43mlTrain batch 7/16 - 199.3ms/batch - loss: 27.88837 - diff: 22.79mlTrain batch 8/16 - 197.6ms/batch - loss: 30.42535 - diff: 23.08mlTrain batch 9/16 - 200.2ms/batch - loss: 33.27777 - diff: 23.85mlTrain batch 10/16 - 201.3ms/batch - loss: 31.39874 - diff: 23.16mlTrain batch 11/16 - 197.9ms/batch - loss: 31.41384 - diff: 23.25mlTrain batch 12/16 - 197.8ms/batch - loss: 32.92409 - diff: 23.92mlTrain batch 13/16 - 199.8ms/batch - loss: 32.06236 - diff: 23.67mlTrain batch 14/16 - 197.4ms/batch - loss: 49.68413 - diff: 25.66mlTrain batch 15/16 - 200.5ms/batch - loss: 49.15976 - diff: 25.64mlTrain batch 16/16 - 132.0ms/batch - loss: 48.44998 - diff: 25.50mlTrain batch 16/16 - 10.3s 132.0ms/batch - loss: 48.44998 - diff: 25.50ml
Test 0.8s: val_loss: 71.75758 - diff: 25.40ml

Epoch 27: current best loss = 46.12843, at epoch 19
Train batch 1/16 - 198.4ms/batch - loss: 31.67113 - diff: 21.19mlTrain batch 2/16 - 200.5ms/batch - loss: 36.99881 - diff: 24.29mlTrain batch 3/16 - 211.2ms/batch - loss: 33.34163 - diff: 23.89mlTrain batch 4/16 - 198.0ms/batch - loss: 56.96020 - diff: 26.51mlTrain batch 5/16 - 198.4ms/batch - loss: 52.78629 - diff: 26.84mlTrain batch 6/16 - 198.2ms/batch - loss: 50.67838 - diff: 27.21mlTrain batch 7/16 - 198.4ms/batch - loss: 52.42289 - diff: 28.31mlTrain batch 8/16 - 201.3ms/batch - loss: 50.47918 - diff: 28.16mlTrain batch 9/16 - 198.3ms/batch - loss: 47.94499 - diff: 27.51mlTrain batch 10/16 - 197.3ms/batch - loss: 45.23134 - diff: 26.53mlTrain batch 11/16 - 198.6ms/batch - loss: 42.87896 - diff: 25.77mlTrain batch 12/16 - 198.3ms/batch - loss: 45.19849 - diff: 25.83mlTrain batch 13/16 - 199.0ms/batch - loss: 44.88512 - diff: 25.79mlTrain batch 14/16 - 198.7ms/batch - loss: 45.36510 - diff: 26.08mlTrain batch 15/16 - 199.2ms/batch - loss: 45.34139 - diff: 26.24mlTrain batch 16/16 - 132.9ms/batch - loss: 47.14229 - diff: 26.35mlTrain batch 16/16 - 10.3s 132.9ms/batch - loss: 47.14229 - diff: 26.35ml
Test 0.8s: val_loss: 52.03575 - diff: 25.37ml

Epoch 28: current best loss = 46.12843, at epoch 19
Train batch 1/16 - 202.4ms/batch - loss: 11.42070 - diff: 14.84mlTrain batch 2/16 - 198.9ms/batch - loss: 36.53311 - diff: 21.79mlTrain batch 3/16 - 202.7ms/batch - loss: 45.20767 - diff: 24.48mlTrain batch 4/16 - 204.7ms/batch - loss: 50.09412 - diff: 25.79mlTrain batch 5/16 - 199.9ms/batch - loss: 46.73899 - diff: 25.64mlTrain batch 6/16 - 198.5ms/batch - loss: 44.99293 - diff: 25.98mlTrain batch 7/16 - 201.3ms/batch - loss: 43.33809 - diff: 25.74mlTrain batch 8/16 - 199.3ms/batch - loss: 40.74411 - diff: 25.27mlTrain batch 9/16 - 199.2ms/batch - loss: 41.17443 - diff: 25.80mlTrain batch 10/16 - 200.3ms/batch - loss: 58.69460 - diff: 27.35mlTrain batch 11/16 - 199.8ms/batch - loss: 55.31263 - diff: 26.84mlTrain batch 12/16 - 198.5ms/batch - loss: 52.91678 - diff: 26.52mlTrain batch 13/16 - 199.3ms/batch - loss: 51.17563 - diff: 26.18mlTrain batch 14/16 - 198.4ms/batch - loss: 49.36947 - diff: 25.99mlTrain batch 15/16 - 197.9ms/batch - loss: 48.25567 - diff: 25.82mlTrain batch 16/16 - 134.4ms/batch - loss: 51.06467 - diff: 26.38mlTrain batch 16/16 - 10.2s 134.4ms/batch - loss: 51.06467 - diff: 26.38ml
Test 0.8s: val_loss: 52.47600 - diff: 27.87ml

Epoch 29: current best loss = 46.12843, at epoch 19
Train batch 1/16 - 198.0ms/batch - loss: 193.02243 - diff: 37.81mlTrain batch 2/16 - 199.7ms/batch - loss: 119.76793 - diff: 32.97mlTrain batch 3/16 - 202.8ms/batch - loss: 90.86398 - diff: 29.95mlTrain batch 4/16 - 200.4ms/batch - loss: 79.75732 - diff: 29.45mlTrain batch 5/16 - 201.7ms/batch - loss: 72.96436 - diff: 29.06mlTrain batch 6/16 - 199.7ms/batch - loss: 65.61778 - diff: 28.79mlTrain batch 7/16 - 201.6ms/batch - loss: 63.48388 - diff: 28.86mlTrain batch 8/16 - 198.0ms/batch - loss: 60.01892 - diff: 28.45mlTrain batch 9/16 - 197.4ms/batch - loss: 56.16992 - diff: 27.60mlTrain batch 10/16 - 200.3ms/batch - loss: 53.70015 - diff: 27.01mlTrain batch 11/16 - 201.5ms/batch - loss: 50.22679 - diff: 26.18mlTrain batch 12/16 - 200.3ms/batch - loss: 50.91229 - diff: 26.50mlTrain batch 13/16 - 197.6ms/batch - loss: 50.16844 - diff: 26.42mlTrain batch 14/16 - 198.2ms/batch - loss: 48.66825 - diff: 26.12mlTrain batch 15/16 - 198.7ms/batch - loss: 49.11886 - diff: 26.06mlTrain batch 16/16 - 132.2ms/batch - loss: 49.67924 - diff: 26.04mlTrain batch 16/16 - 10.3s 132.2ms/batch - loss: 49.67924 - diff: 26.04ml
Test 0.8s: val_loss: 50.23012 - diff: 28.35ml

Epoch 30: current best loss = 46.12843, at epoch 19
Train batch 1/16 - 203.8ms/batch - loss: 27.99451 - diff: 23.24mlTrain batch 2/16 - 197.8ms/batch - loss: 34.84277 - diff: 25.37mlTrain batch 3/16 - 199.3ms/batch - loss: 35.51226 - diff: 26.10mlTrain batch 4/16 - 197.8ms/batch - loss: 38.09314 - diff: 27.28mlTrain batch 5/16 - 198.5ms/batch - loss: 37.11951 - diff: 26.30mlTrain batch 6/16 - 200.0ms/batch - loss: 34.63603 - diff: 25.40mlTrain batch 7/16 - 199.9ms/batch - loss: 31.96642 - diff: 24.49mlTrain batch 8/16 - 200.8ms/batch - loss: 29.61411 - diff: 23.59mlTrain batch 9/16 - 197.9ms/batch - loss: 29.61113 - diff: 23.48mlTrain batch 10/16 - 200.0ms/batch - loss: 50.10566 - diff: 25.58mlTrain batch 11/16 - 197.5ms/batch - loss: 48.34279 - diff: 25.10mlTrain batch 12/16 - 199.0ms/batch - loss: 46.49152 - diff: 24.73mlTrain batch 13/16 - 197.8ms/batch - loss: 44.15576 - diff: 24.15mlTrain batch 14/16 - 198.7ms/batch - loss: 45.67428 - diff: 24.42mlTrain batch 15/16 - 198.3ms/batch - loss: 43.81845 - diff: 24.18mlTrain batch 16/16 - 132.5ms/batch - loss: 44.67816 - diff: 24.26mlTrain batch 16/16 - 10.3s 132.5ms/batch - loss: 44.67816 - diff: 24.26ml
Test 0.8s: val_loss: 48.07184 - diff: 25.02ml
Epoch    31: reducing learning rate of group 0 to 5.0000e-04.

Epoch 31: current best loss = 46.12843, at epoch 19
Train batch 1/16 - 202.8ms/batch - loss: 37.65516 - diff: 25.35mlTrain batch 2/16 - 198.9ms/batch - loss: 43.14057 - diff: 24.88mlTrain batch 3/16 - 198.8ms/batch - loss: 51.68650 - diff: 25.55mlTrain batch 4/16 - 198.8ms/batch - loss: 85.43273 - diff: 29.44mlTrain batch 5/16 - 202.5ms/batch - loss: 74.07496 - diff: 28.32mlTrain batch 6/16 - 200.9ms/batch - loss: 66.85545 - diff: 27.94mlTrain batch 7/16 - 202.7ms/batch - loss: 60.97359 - diff: 27.27mlTrain batch 8/16 - 199.4ms/batch - loss: 55.57128 - diff: 26.29mlTrain batch 9/16 - 201.5ms/batch - loss: 51.84216 - diff: 25.53mlTrain batch 10/16 - 198.3ms/batch - loss: 49.33201 - diff: 25.38mlTrain batch 11/16 - 202.4ms/batch - loss: 51.65814 - diff: 26.14mlTrain batch 12/16 - 197.7ms/batch - loss: 50.11925 - diff: 25.94mlTrain batch 13/16 - 202.6ms/batch - loss: 48.07073 - diff: 25.69mlTrain batch 14/16 - 199.1ms/batch - loss: 46.62929 - diff: 25.56mlTrain batch 15/16 - 198.0ms/batch - loss: 45.05203 - diff: 25.35mlTrain batch 16/16 - 134.3ms/batch - loss: 44.66895 - diff: 25.20mlTrain batch 16/16 - 10.2s 134.3ms/batch - loss: 44.66895 - diff: 25.20ml
Test 0.8s: val_loss: 43.64051 - diff: 25.11ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Systole_VGG19_Adam-0.001_MSE_DA3_best

Epoch 32: current best loss = 43.64051, at epoch 31
Train batch 1/16 - 200.6ms/batch - loss: 168.22446 - diff: 32.30mlTrain batch 2/16 - 204.9ms/batch - loss: 109.78122 - diff: 30.74mlTrain batch 3/16 - 197.5ms/batch - loss: 98.99145 - diff: 30.62mlTrain batch 4/16 - 200.4ms/batch - loss: 84.14070 - diff: 29.32mlTrain batch 5/16 - 202.9ms/batch - loss: 72.54671 - diff: 27.72mlTrain batch 6/16 - 198.1ms/batch - loss: 64.19723 - diff: 26.43mlTrain batch 7/16 - 198.9ms/batch - loss: 59.72353 - diff: 26.33mlTrain batch 8/16 - 198.1ms/batch - loss: 58.39811 - diff: 26.70mlTrain batch 9/16 - 197.6ms/batch - loss: 58.45376 - diff: 27.08mlTrain batch 10/16 - 197.9ms/batch - loss: 54.62417 - diff: 26.50mlTrain batch 11/16 - 200.8ms/batch - loss: 52.66164 - diff: 26.26mlTrain batch 12/16 - 197.7ms/batch - loss: 50.41453 - diff: 25.78mlTrain batch 13/16 - 199.2ms/batch - loss: 48.62366 - diff: 25.49mlTrain batch 14/16 - 197.1ms/batch - loss: 46.46273 - diff: 25.08mlTrain batch 15/16 - 199.3ms/batch - loss: 46.42292 - diff: 25.08mlTrain batch 16/16 - 132.2ms/batch - loss: 47.24326 - diff: 25.22mlTrain batch 16/16 - 10.3s 132.2ms/batch - loss: 47.24326 - diff: 25.22ml
Test 0.8s: val_loss: 61.72346 - diff: 26.28ml

Epoch 33: current best loss = 43.64051, at epoch 31
Train batch 1/16 - 197.7ms/batch - loss: 53.66647 - diff: 30.24mlTrain batch 2/16 - 201.2ms/batch - loss: 45.44018 - diff: 28.88mlTrain batch 3/16 - 199.4ms/batch - loss: 37.24806 - diff: 26.69mlTrain batch 4/16 - 197.9ms/batch - loss: 33.07331 - diff: 24.83mlTrain batch 5/16 - 199.7ms/batch - loss: 29.90069 - diff: 23.70mlTrain batch 6/16 - 197.5ms/batch - loss: 34.01477 - diff: 24.42mlTrain batch 7/16 - 205.0ms/batch - loss: 31.01952 - diff: 23.42mlTrain batch 8/16 - 201.2ms/batch - loss: 29.39681 - diff: 22.52mlTrain batch 9/16 - 202.7ms/batch - loss: 30.31128 - diff: 22.95mlTrain batch 10/16 - 200.4ms/batch - loss: 29.72745 - diff: 22.92mlTrain batch 11/16 - 201.5ms/batch - loss: 31.94773 - diff: 23.41mlTrain batch 12/16 - 198.6ms/batch - loss: 32.12019 - diff: 23.34mlTrain batch 13/16 - 203.4ms/batch - loss: 38.07681 - diff: 24.47mlTrain batch 14/16 - 198.0ms/batch - loss: 36.87881 - diff: 23.94mlTrain batch 15/16 - 201.3ms/batch - loss: 44.77018 - diff: 24.70mlTrain batch 16/16 - 132.8ms/batch - loss: 46.26014 - diff: 24.87mlTrain batch 16/16 - 10.3s 132.8ms/batch - loss: 46.26014 - diff: 24.87ml
Test 0.8s: val_loss: 52.91591 - diff: 26.86ml

Epoch 34: current best loss = 43.64051, at epoch 31
Train batch 1/16 - 205.4ms/batch - loss: 28.59650 - diff: 22.79mlTrain batch 2/16 - 199.5ms/batch - loss: 31.42187 - diff: 23.54mlTrain batch 3/16 - 198.2ms/batch - loss: 35.75533 - diff: 25.09mlTrain batch 4/16 - 197.5ms/batch - loss: 31.90820 - diff: 24.05mlTrain batch 5/16 - 198.4ms/batch - loss: 30.18323 - diff: 23.78mlTrain batch 6/16 - 204.2ms/batch - loss: 31.66147 - diff: 24.42mlTrain batch 7/16 - 203.2ms/batch - loss: 30.80623 - diff: 24.01mlTrain batch 8/16 - 200.3ms/batch - loss: 31.63017 - diff: 23.95mlTrain batch 9/16 - 202.6ms/batch - loss: 30.27861 - diff: 23.57mlTrain batch 10/16 - 199.6ms/batch - loss: 41.81660 - diff: 24.07mlTrain batch 11/16 - 202.8ms/batch - loss: 41.84839 - diff: 24.43mlTrain batch 12/16 - 199.0ms/batch - loss: 42.46980 - diff: 24.63mlTrain batch 13/16 - 203.9ms/batch - loss: 40.65985 - diff: 24.33mlTrain batch 14/16 - 198.3ms/batch - loss: 39.42192 - diff: 24.16mlTrain batch 15/16 - 198.3ms/batch - loss: 41.69221 - diff: 24.46mlTrain batch 16/16 - 132.0ms/batch - loss: 43.23835 - diff: 24.56mlTrain batch 16/16 - 10.3s 132.0ms/batch - loss: 43.23835 - diff: 24.56ml
Test 0.9s: val_loss: 58.15371 - diff: 25.58ml

Epoch 35: current best loss = 43.64051, at epoch 31
Train batch 1/16 - 197.8ms/batch - loss: 56.44427 - diff: 32.97mlTrain batch 2/16 - 198.1ms/batch - loss: 35.60564 - diff: 25.78mlTrain batch 3/16 - 201.4ms/batch - loss: 32.12347 - diff: 24.85mlTrain batch 4/16 - 198.4ms/batch - loss: 27.62048 - diff: 23.06mlTrain batch 5/16 - 203.2ms/batch - loss: 31.29729 - diff: 24.28mlTrain batch 6/16 - 199.8ms/batch - loss: 35.26371 - diff: 25.51mlTrain batch 7/16 - 203.2ms/batch - loss: 33.73132 - diff: 24.94mlTrain batch 8/16 - 198.8ms/batch - loss: 31.19341 - diff: 23.97mlTrain batch 9/16 - 201.3ms/batch - loss: 31.53330 - diff: 24.30mlTrain batch 10/16 - 203.3ms/batch - loss: 30.74294 - diff: 23.95mlTrain batch 11/16 - 203.1ms/batch - loss: 33.35860 - diff: 24.32mlTrain batch 12/16 - 197.8ms/batch - loss: 45.95491 - diff: 25.10mlTrain batch 13/16 - 202.3ms/batch - loss: 44.63480 - diff: 24.91mlTrain batch 14/16 - 202.3ms/batch - loss: 48.25868 - diff: 25.47mlTrain batch 15/16 - 197.8ms/batch - loss: 47.04763 - diff: 25.45mlTrain batch 16/16 - 134.0ms/batch - loss: 47.79733 - diff: 25.26mlTrain batch 16/16 - 10.3s 134.0ms/batch - loss: 47.79733 - diff: 25.26ml
Test 0.9s: val_loss: 49.63044 - diff: 25.48ml

Epoch 36: current best loss = 43.64051, at epoch 31
Train batch 1/16 - 203.0ms/batch - loss: 33.74043 - diff: 26.04mlTrain batch 2/16 - 198.6ms/batch - loss: 32.19376 - diff: 25.68mlTrain batch 3/16 - 203.8ms/batch - loss: 42.03011 - diff: 28.04mlTrain batch 4/16 - 197.9ms/batch - loss: 37.15284 - diff: 26.73mlTrain batch 5/16 - 203.9ms/batch - loss: 35.01729 - diff: 26.38mlTrain batch 6/16 - 199.5ms/batch - loss: 33.95327 - diff: 25.98mlTrain batch 7/16 - 198.1ms/batch - loss: 35.64009 - diff: 26.42mlTrain batch 8/16 - 197.3ms/batch - loss: 38.92083 - diff: 26.94mlTrain batch 9/16 - 197.5ms/batch - loss: 38.65014 - diff: 26.77mlTrain batch 10/16 - 197.8ms/batch - loss: 48.26228 - diff: 27.26mlTrain batch 11/16 - 200.5ms/batch - loss: 46.17026 - diff: 26.82mlTrain batch 12/16 - 200.1ms/batch - loss: 45.34208 - diff: 26.53mlTrain batch 13/16 - 198.5ms/batch - loss: 43.93170 - diff: 26.27mlTrain batch 14/16 - 198.1ms/batch - loss: 46.15736 - diff: 26.67mlTrain batch 15/16 - 197.7ms/batch - loss: 43.93430 - diff: 26.03mlTrain batch 16/16 - 131.4ms/batch - loss: 44.34207 - diff: 26.01mlTrain batch 16/16 - 10.3s 131.4ms/batch - loss: 44.34207 - diff: 26.01ml
Test 0.9s: val_loss: 44.47800 - diff: 25.54ml

Epoch 37: current best loss = 43.64051, at epoch 31
Train batch 1/16 - 198.6ms/batch - loss: 20.03200 - diff: 20.56mlTrain batch 2/16 - 198.4ms/batch - loss: 22.72270 - diff: 20.99mlTrain batch 3/16 - 197.6ms/batch - loss: 24.06824 - diff: 21.62mlTrain batch 4/16 - 204.7ms/batch - loss: 27.63765 - diff: 21.83mlTrain batch 5/16 - 197.8ms/batch - loss: 29.51616 - diff: 22.19mlTrain batch 6/16 - 198.2ms/batch - loss: 30.96476 - diff: 23.00mlTrain batch 7/16 - 199.3ms/batch - loss: 31.20530 - diff: 23.28mlTrain batch 8/16 - 199.1ms/batch - loss: 38.08616 - diff: 24.28mlTrain batch 9/16 - 200.3ms/batch - loss: 38.35098 - diff: 24.52mlTrain batch 10/16 - 198.4ms/batch - loss: 52.31057 - diff: 26.05mlTrain batch 11/16 - 198.3ms/batch - loss: 49.78495 - diff: 25.58mlTrain batch 12/16 - 197.9ms/batch - loss: 48.23829 - diff: 25.62mlTrain batch 13/16 - 201.5ms/batch - loss: 46.09005 - diff: 25.29mlTrain batch 14/16 - 199.1ms/batch - loss: 45.62586 - diff: 25.45mlTrain batch 15/16 - 198.0ms/batch - loss: 43.94333 - diff: 25.17mlTrain batch 16/16 - 134.2ms/batch - loss: 43.95876 - diff: 25.14mlTrain batch 16/16 - 10.3s 134.2ms/batch - loss: 43.95876 - diff: 25.14ml
Test 0.8s: val_loss: 49.78594 - diff: 26.30ml

Epoch 38: current best loss = 43.64051, at epoch 31
Train batch 1/16 - 200.2ms/batch - loss: 27.25559 - diff: 22.80mlTrain batch 2/16 - 200.0ms/batch - loss: 83.76627 - diff: 29.37mlTrain batch 3/16 - 197.2ms/batch - loss: 58.78632 - diff: 23.98mlTrain batch 4/16 - 197.7ms/batch - loss: 50.57974 - diff: 23.80mlTrain batch 5/16 - 199.5ms/batch - loss: 49.53106 - diff: 24.75mlTrain batch 6/16 - 198.7ms/batch - loss: 48.80504 - diff: 25.29mlTrain batch 7/16 - 200.3ms/batch - loss: 48.30976 - diff: 25.83mlTrain batch 8/16 - 198.5ms/batch - loss: 50.85343 - diff: 25.85mlTrain batch 9/16 - 199.5ms/batch - loss: 47.76977 - diff: 25.34mlTrain batch 10/16 - 199.7ms/batch - loss: 45.69090 - diff: 25.01mlTrain batch 11/16 - 201.7ms/batch - loss: 43.19625 - diff: 24.53mlTrain batch 12/16 - 198.0ms/batch - loss: 43.19047 - diff: 24.58mlTrain batch 13/16 - 199.5ms/batch - loss: 42.64420 - diff: 24.55mlTrain batch 14/16 - 199.0ms/batch - loss: 42.03341 - diff: 24.51mlTrain batch 15/16 - 201.0ms/batch - loss: 41.79974 - diff: 24.53mlTrain batch 16/16 - 135.9ms/batch - loss: 41.72016 - diff: 24.46mlTrain batch 16/16 - 10.4s 135.9ms/batch - loss: 41.72016 - diff: 24.46ml
Test 0.8s: val_loss: 49.34305 - diff: 28.30ml

Epoch 39: current best loss = 43.64051, at epoch 31
Train batch 1/16 - 200.2ms/batch - loss: 35.52525 - diff: 27.44mlTrain batch 2/16 - 199.7ms/batch - loss: 25.84654 - diff: 22.25mlTrain batch 3/16 - 198.5ms/batch - loss: 29.91736 - diff: 23.34mlTrain batch 4/16 - 197.8ms/batch - loss: 27.77140 - diff: 22.42mlTrain batch 5/16 - 198.8ms/batch - loss: 25.10379 - diff: 21.54mlTrain batch 6/16 - 199.3ms/batch - loss: 23.88390 - diff: 20.47mlTrain batch 7/16 - 201.9ms/batch - loss: 25.19411 - diff: 20.57mlTrain batch 8/16 - 197.8ms/batch - loss: 44.32499 - diff: 22.14mlTrain batch 9/16 - 200.1ms/batch - loss: 44.70338 - diff: 22.84mlTrain batch 10/16 - 197.8ms/batch - loss: 46.85167 - diff: 23.75mlTrain batch 11/16 - 198.2ms/batch - loss: 43.79024 - diff: 23.02mlTrain batch 12/16 - 198.2ms/batch - loss: 46.71338 - diff: 23.81mlTrain batch 13/16 - 200.7ms/batch - loss: 47.54234 - diff: 24.03mlTrain batch 14/16 - 199.2ms/batch - loss: 46.31244 - diff: 23.99mlTrain batch 15/16 - 197.1ms/batch - loss: 45.07856 - diff: 23.85mlTrain batch 16/16 - 132.1ms/batch - loss: 44.30596 - diff: 23.61mlTrain batch 16/16 - 10.5s 132.1ms/batch - loss: 44.30596 - diff: 23.61ml
Test 0.8s: val_loss: 57.54717 - diff: 29.39ml

Epoch 40: current best loss = 43.64051, at epoch 31
Train batch 1/16 - 199.5ms/batch - loss: 35.54272 - diff: 27.95mlTrain batch 2/16 - 199.6ms/batch - loss: 83.99347 - diff: 30.03mlTrain batch 3/16 - 197.2ms/batch - loss: 71.21651 - diff: 29.97mlTrain batch 4/16 - 199.0ms/batch - loss: 62.70162 - diff: 29.28mlTrain batch 5/16 - 200.2ms/batch - loss: 55.07621 - diff: 27.85mlTrain batch 6/16 - 197.7ms/batch - loss: 51.37833 - diff: 27.68mlTrain batch 7/16 - 199.2ms/batch - loss: 46.82109 - diff: 26.52mlTrain batch 8/16 - 196.9ms/batch - loss: 43.18348 - diff: 25.88mlTrain batch 9/16 - 198.7ms/batch - loss: 41.43956 - diff: 25.79mlTrain batch 10/16 - 197.7ms/batch - loss: 40.00639 - diff: 25.76mlTrain batch 11/16 - 199.0ms/batch - loss: 39.63391 - diff: 25.91mlTrain batch 12/16 - 201.1ms/batch - loss: 40.01364 - diff: 26.09mlTrain batch 13/16 - 200.0ms/batch - loss: 38.79474 - diff: 25.73mlTrain batch 14/16 - 200.9ms/batch - loss: 36.83466 - diff: 24.98mlTrain batch 15/16 - 198.4ms/batch - loss: 38.49703 - diff: 25.20mlTrain batch 16/16 - 132.0ms/batch - loss: 40.47636 - diff: 25.25mlTrain batch 16/16 - 10.3s 132.0ms/batch - loss: 40.47636 - diff: 25.25ml
Test 0.8s: val_loss: 44.73447 - diff: 24.41ml

Epoch 41: current best loss = 43.64051, at epoch 31
Train batch 1/16 - 201.2ms/batch - loss: 20.95155 - diff: 18.17mlTrain batch 2/16 - 201.7ms/batch - loss: 21.62405 - diff: 18.02mlTrain batch 3/16 - 201.4ms/batch - loss: 21.67341 - diff: 18.89mlTrain batch 4/16 - 197.6ms/batch - loss: 22.29883 - diff: 18.97mlTrain batch 5/16 - 201.6ms/batch - loss: 21.49794 - diff: 18.81mlTrain batch 6/16 - 199.4ms/batch - loss: 21.44477 - diff: 19.21mlTrain batch 7/16 - 199.1ms/batch - loss: 26.02942 - diff: 20.55mlTrain batch 8/16 - 199.9ms/batch - loss: 27.06195 - diff: 21.32mlTrain batch 9/16 - 197.6ms/batch - loss: 26.79898 - diff: 21.41mlTrain batch 10/16 - 201.9ms/batch - loss: 25.38274 - diff: 20.88mlTrain batch 11/16 - 198.9ms/batch - loss: 25.77691 - diff: 21.17mlTrain batch 12/16 - 197.6ms/batch - loss: 38.31238 - diff: 22.43mlTrain batch 13/16 - 197.4ms/batch - loss: 41.15266 - diff: 23.30mlTrain batch 14/16 - 197.5ms/batch - loss: 40.50545 - diff: 23.32mlTrain batch 15/16 - 199.0ms/batch - loss: 40.05859 - diff: 23.37mlTrain batch 16/16 - 131.6ms/batch - loss: 39.62143 - diff: 23.21mlTrain batch 16/16 - 10.3s 131.6ms/batch - loss: 39.62143 - diff: 23.21ml
Test 0.8s: val_loss: 50.15667 - diff: 25.92ml

Epoch 42: current best loss = 43.64051, at epoch 31
Train batch 1/16 - 198.9ms/batch - loss: 29.64645 - diff: 21.17mlTrain batch 2/16 - 198.7ms/batch - loss: 35.27599 - diff: 23.61mlTrain batch 3/16 - 199.6ms/batch - loss: 33.14708 - diff: 24.06mlTrain batch 4/16 - 198.5ms/batch - loss: 32.86083 - diff: 24.47mlTrain batch 5/16 - 198.7ms/batch - loss: 29.74146 - diff: 23.32mlTrain batch 6/16 - 197.6ms/batch - loss: 51.39476 - diff: 25.14mlTrain batch 7/16 - 197.7ms/batch - loss: 49.69294 - diff: 25.24mlTrain batch 8/16 - 197.6ms/batch - loss: 48.31188 - diff: 25.18mlTrain batch 9/16 - 200.9ms/batch - loss: 45.83005 - diff: 25.01mlTrain batch 10/16 - 199.6ms/batch - loss: 44.46382 - diff: 24.97mlTrain batch 11/16 - 198.6ms/batch - loss: 42.16478 - diff: 24.47mlTrain batch 12/16 - 197.8ms/batch - loss: 41.61453 - diff: 24.49mlTrain batch 13/16 - 198.8ms/batch - loss: 43.60662 - diff: 24.80mlTrain batch 14/16 - 200.2ms/batch - loss: 43.52532 - diff: 24.89mlTrain batch 15/16 - 197.1ms/batch - loss: 42.29713 - diff: 24.53mlTrain batch 16/16 - 132.3ms/batch - loss: 41.85976 - diff: 24.25mlTrain batch 16/16 - 10.3s 132.3ms/batch - loss: 41.85976 - diff: 24.25ml
Test 0.9s: val_loss: 42.86696 - diff: 24.25ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Systole_VGG19_Adam-0.001_MSE_DA3_best

Epoch 43: current best loss = 42.86696, at epoch 42
Train batch 1/16 - 203.2ms/batch - loss: 30.56323 - diff: 25.35mlTrain batch 2/16 - 197.9ms/batch - loss: 49.84745 - diff: 28.19mlTrain batch 3/16 - 201.2ms/batch - loss: 48.26613 - diff: 26.84mlTrain batch 4/16 - 198.1ms/batch - loss: 42.41417 - diff: 25.71mlTrain batch 5/16 - 203.6ms/batch - loss: 42.50611 - diff: 26.30mlTrain batch 6/16 - 201.1ms/batch - loss: 41.27508 - diff: 25.94mlTrain batch 7/16 - 202.1ms/batch - loss: 39.05999 - diff: 25.26mlTrain batch 8/16 - 199.3ms/batch - loss: 36.27712 - diff: 24.37mlTrain batch 9/16 - 197.2ms/batch - loss: 35.05017 - diff: 24.10mlTrain batch 10/16 - 203.6ms/batch - loss: 35.29397 - diff: 24.19mlTrain batch 11/16 - 197.8ms/batch - loss: 34.45583 - diff: 24.00mlTrain batch 12/16 - 202.0ms/batch - loss: 34.41821 - diff: 24.04mlTrain batch 13/16 - 199.5ms/batch - loss: 33.81488 - diff: 23.87mlTrain batch 14/16 - 200.8ms/batch - loss: 34.02641 - diff: 24.05mlTrain batch 15/16 - 198.4ms/batch - loss: 41.92560 - diff: 24.46mlTrain batch 16/16 - 134.1ms/batch - loss: 41.86921 - diff: 24.31mlTrain batch 16/16 - 10.3s 134.1ms/batch - loss: 41.86921 - diff: 24.31ml
Test 0.9s: val_loss: 69.81090 - diff: 28.28ml

Epoch 44: current best loss = 42.86696, at epoch 42
Train batch 1/16 - 199.1ms/batch - loss: 20.07156 - diff: 20.34mlTrain batch 2/16 - 200.6ms/batch - loss: 19.77542 - diff: 20.08mlTrain batch 3/16 - 202.3ms/batch - loss: 26.66849 - diff: 22.79mlTrain batch 4/16 - 198.1ms/batch - loss: 27.60143 - diff: 22.93mlTrain batch 5/16 - 202.3ms/batch - loss: 28.95603 - diff: 23.46mlTrain batch 6/16 - 198.1ms/batch - loss: 28.32219 - diff: 23.40mlTrain batch 7/16 - 202.1ms/batch - loss: 26.94420 - diff: 22.92mlTrain batch 8/16 - 197.6ms/batch - loss: 45.23074 - diff: 24.57mlTrain batch 9/16 - 200.3ms/batch - loss: 46.11339 - diff: 25.26mlTrain batch 10/16 - 199.6ms/batch - loss: 44.98260 - diff: 25.22mlTrain batch 11/16 - 199.3ms/batch - loss: 44.15886 - diff: 25.26mlTrain batch 12/16 - 199.8ms/batch - loss: 42.43582 - diff: 24.96mlTrain batch 13/16 - 200.2ms/batch - loss: 44.56704 - diff: 25.41mlTrain batch 14/16 - 198.1ms/batch - loss: 45.13108 - diff: 25.68mlTrain batch 15/16 - 198.2ms/batch - loss: 44.57197 - diff: 25.57mlTrain batch 16/16 - 131.7ms/batch - loss: 43.55694 - diff: 25.17mlTrain batch 16/16 - 10.2s 131.7ms/batch - loss: 43.55694 - diff: 25.17ml
Test 0.9s: val_loss: 51.38983 - diff: 28.21ml

Epoch 45: current best loss = 42.86696, at epoch 42
Going to unfreeze the pretrained weights
Train batch 1/16 - 263.1ms/batch - loss: 60.52113 - diff: 33.47mlTrain batch 2/16 - 259.8ms/batch - loss: 41907.87775 - diff: 827.12mlTrain batch 3/16 - 258.5ms/batch - loss: 28021.50489 - diff: 576.50mlTrain batch 4/16 - 260.6ms/batch - loss: 21049.19506 - diff: 446.80mlTrain batch 5/16 - 263.2ms/batch - loss: 16857.14227 - diff: 366.60mlTrain batch 6/16 - 258.9ms/batch - loss: 14058.35276 - diff: 311.54mlTrain batch 7/16 - 258.7ms/batch - loss: 12078.85820 - diff: 277.84mlTrain batch 8/16 - 259.1ms/batch - loss: 10579.46925 - diff: 247.90mlTrain batch 9/16 - 259.1ms/batch - loss: 9418.30017 - diff: 226.13mlTrain batch 10/16 - 261.0ms/batch - loss: 8503.57169 - diff: 208.63mlTrain batch 11/16 - 259.5ms/batch - loss: 7743.26356 - diff: 195.03mlTrain batch 12/16 - 259.6ms/batch - loss: 7101.93172 - diff: 181.30mlTrain batch 13/16 - 259.1ms/batch - loss: 6564.12914 - diff: 170.12mlTrain batch 14/16 - 259.1ms/batch - loss: 6100.26119 - diff: 160.51mlTrain batch 15/16 - 258.0ms/batch - loss: 5698.21092 - diff: 151.79mlTrain batch 16/16 - 172.8ms/batch - loss: 5473.27167 - diff: 146.99mlTrain batch 16/16 - 10.5s 172.8ms/batch - loss: 5473.27167 - diff: 146.99ml
Test 0.8s: val_loss: 149.57712 - diff: 56.99ml

Epoch 46: current best loss = 42.86696, at epoch 42
Train batch 1/16 - 261.2ms/batch - loss: 54.57189 - diff: 35.67mlTrain batch 2/16 - 258.6ms/batch - loss: 48.29570 - diff: 30.81mlTrain batch 3/16 - 259.0ms/batch - loss: 57.58317 - diff: 33.66mlTrain batch 4/16 - 259.9ms/batch - loss: 67.85582 - diff: 34.43mlTrain batch 5/16 - 262.4ms/batch - loss: 64.06513 - diff: 33.52mlTrain batch 6/16 - 265.1ms/batch - loss: 68.39752 - diff: 35.51mlTrain batch 7/16 - 262.6ms/batch - loss: 67.73726 - diff: 35.99mlTrain batch 8/16 - 258.1ms/batch - loss: 69.73083 - diff: 35.85mlTrain batch 9/16 - 262.6ms/batch - loss: 68.56412 - diff: 35.55mlTrain batch 10/16 - 259.3ms/batch - loss: 88.26807 - diff: 37.12mlTrain batch 11/16 - 261.0ms/batch - loss: 84.49412 - diff: 36.08mlTrain batch 12/16 - 260.1ms/batch - loss: 81.02421 - diff: 35.40mlTrain batch 13/16 - 261.1ms/batch - loss: 79.32891 - diff: 35.36mlTrain batch 14/16 - 260.5ms/batch - loss: 82.87905 - diff: 36.68mlTrain batch 15/16 - 258.7ms/batch - loss: 86.36501 - diff: 37.40mlTrain batch 16/16 - 174.0ms/batch - loss: 84.32246 - diff: 36.67mlTrain batch 16/16 - 10.4s 174.0ms/batch - loss: 84.32246 - diff: 36.67ml
Test 0.9s: val_loss: 61.01213 - diff: 27.53ml

Epoch 47: current best loss = 42.86696, at epoch 42
Train batch 1/16 - 262.0ms/batch - loss: 95.14752 - diff: 38.03mlTrain batch 2/16 - 260.0ms/batch - loss: 59.78300 - diff: 29.74mlTrain batch 3/16 - 262.3ms/batch - loss: 57.72039 - diff: 30.41mlTrain batch 4/16 - 258.4ms/batch - loss: 59.93292 - diff: 30.73mlTrain batch 5/16 - 263.9ms/batch - loss: 55.69863 - diff: 30.24mlTrain batch 6/16 - 258.9ms/batch - loss: 59.00588 - diff: 31.22mlTrain batch 7/16 - 264.3ms/batch - loss: 64.59842 - diff: 32.03mlTrain batch 8/16 - 259.5ms/batch - loss: 65.91106 - diff: 32.38mlTrain batch 9/16 - 263.2ms/batch - loss: 62.10162 - diff: 31.23mlTrain batch 10/16 - 258.2ms/batch - loss: 60.32840 - diff: 30.66mlTrain batch 11/16 - 264.2ms/batch - loss: 57.70541 - diff: 30.21mlTrain batch 12/16 - 260.0ms/batch - loss: 58.08440 - diff: 30.42mlTrain batch 13/16 - 263.0ms/batch - loss: 56.59032 - diff: 30.12mlTrain batch 14/16 - 259.8ms/batch - loss: 66.85672 - diff: 30.31mlTrain batch 15/16 - 258.3ms/batch - loss: 66.16619 - diff: 30.38mlTrain batch 16/16 - 172.9ms/batch - loss: 68.53545 - diff: 30.82mlTrain batch 16/16 - 10.4s 172.9ms/batch - loss: 68.53545 - diff: 30.82ml
Test 0.9s: val_loss: 54.84095 - diff: 28.88ml

Epoch 48: current best loss = 42.86696, at epoch 42
Train batch 1/16 - 259.7ms/batch - loss: 33.52200 - diff: 27.95mlTrain batch 2/16 - 259.0ms/batch - loss: 48.10637 - diff: 28.78mlTrain batch 3/16 - 258.7ms/batch - loss: 45.02412 - diff: 27.96mlTrain batch 4/16 - 258.3ms/batch - loss: 87.18805 - diff: 31.30mlTrain batch 5/16 - 257.7ms/batch - loss: 78.97932 - diff: 31.09mlTrain batch 6/16 - 259.6ms/batch - loss: 72.67496 - diff: 31.00mlTrain batch 7/16 - 263.0ms/batch - loss: 75.26719 - diff: 32.16mlTrain batch 8/16 - 258.5ms/batch - loss: 72.94510 - diff: 31.38mlTrain batch 9/16 - 257.8ms/batch - loss: 67.83723 - diff: 30.63mlTrain batch 10/16 - 258.6ms/batch - loss: 64.69922 - diff: 29.90mlTrain batch 11/16 - 258.7ms/batch - loss: 61.14662 - diff: 29.26mlTrain batch 12/16 - 260.3ms/batch - loss: 62.86683 - diff: 29.77mlTrain batch 13/16 - 260.0ms/batch - loss: 64.43220 - diff: 29.95mlTrain batch 14/16 - 259.8ms/batch - loss: 61.78755 - diff: 29.63mlTrain batch 15/16 - 258.1ms/batch - loss: 62.85065 - diff: 29.98mlTrain batch 16/16 - 172.2ms/batch - loss: 63.20557 - diff: 30.03mlTrain batch 16/16 - 10.5s 172.2ms/batch - loss: 63.20557 - diff: 30.03ml
Test 0.8s: val_loss: 54.18816 - diff: 26.45ml

Epoch 49: current best loss = 42.86696, at epoch 42
Train batch 1/16 - 260.1ms/batch - loss: 307.91953 - diff: 54.47mlTrain batch 2/16 - 259.5ms/batch - loss: 174.08422 - diff: 39.92mlTrain batch 3/16 - 259.9ms/batch - loss: 133.28166 - diff: 37.18mlTrain batch 4/16 - 261.7ms/batch - loss: 114.08300 - diff: 35.78mlTrain batch 5/16 - 257.6ms/batch - loss: 98.56090 - diff: 33.92mlTrain batch 6/16 - 259.1ms/batch - loss: 92.45445 - diff: 33.31mlTrain batch 7/16 - 260.7ms/batch - loss: 90.59844 - diff: 33.28mlTrain batch 8/16 - 258.7ms/batch - loss: 83.84322 - diff: 32.41mlTrain batch 9/16 - 258.8ms/batch - loss: 79.14940 - diff: 32.14mlTrain batch 10/16 - 259.1ms/batch - loss: 74.52043 - diff: 31.27mlTrain batch 11/16 - 260.6ms/batch - loss: 69.91543 - diff: 30.34mlTrain batch 12/16 - 260.8ms/batch - loss: 66.06719 - diff: 29.74mlTrain batch 13/16 - 259.1ms/batch - loss: 63.33228 - diff: 29.33mlTrain batch 14/16 - 258.6ms/batch - loss: 63.82794 - diff: 29.40mlTrain batch 15/16 - 258.6ms/batch - loss: 61.56607 - diff: 29.24mlTrain batch 16/16 - 173.0ms/batch - loss: 62.63127 - diff: 29.24mlTrain batch 16/16 - 10.4s 173.0ms/batch - loss: 62.63127 - diff: 29.24ml
Test 0.9s: val_loss: 49.53894 - diff: 25.99ml

Epoch 50: current best loss = 42.86696, at epoch 42
Train batch 1/16 - 258.6ms/batch - loss: 37.13074 - diff: 26.59mlTrain batch 2/16 - 259.1ms/batch - loss: 38.92676 - diff: 28.70mlTrain batch 3/16 - 259.4ms/batch - loss: 46.21814 - diff: 28.74mlTrain batch 4/16 - 260.3ms/batch - loss: 89.61091 - diff: 31.56mlTrain batch 5/16 - 261.0ms/batch - loss: 82.36748 - diff: 32.16mlTrain batch 6/16 - 261.5ms/batch - loss: 83.36105 - diff: 34.10mlTrain batch 7/16 - 265.6ms/batch - loss: 77.51743 - diff: 32.72mlTrain batch 8/16 - 268.9ms/batch - loss: 71.60015 - diff: 31.72mlTrain batch 9/16 - 258.7ms/batch - loss: 70.79569 - diff: 31.43mlTrain batch 10/16 - 260.4ms/batch - loss: 69.12140 - diff: 31.27mlTrain batch 11/16 - 260.3ms/batch - loss: 66.93183 - diff: 31.15mlTrain batch 12/16 - 260.0ms/batch - loss: 70.25058 - diff: 31.75mlTrain batch 13/16 - 259.4ms/batch - loss: 67.33791 - diff: 31.38mlTrain batch 14/16 - 258.9ms/batch - loss: 64.35793 - diff: 30.89mlTrain batch 15/16 - 258.8ms/batch - loss: 63.35860 - diff: 30.71mlTrain batch 16/16 - 171.8ms/batch - loss: 62.21306 - diff: 30.33mlTrain batch 16/16 - 10.5s 171.8ms/batch - loss: 62.21306 - diff: 30.33ml
Test 0.9s: val_loss: 75.62923 - diff: 28.81ml

Epoch 51: current best loss = 42.86696, at epoch 42
Train batch 1/16 - 263.0ms/batch - loss: 53.61170 - diff: 31.43mlTrain batch 2/16 - 257.6ms/batch - loss: 73.73212 - diff: 33.92mlTrain batch 3/16 - 260.2ms/batch - loss: 67.23624 - diff: 33.93mlTrain batch 4/16 - 259.8ms/batch - loss: 71.77151 - diff: 36.13mlTrain batch 5/16 - 261.8ms/batch - loss: 67.91551 - diff: 35.77mlTrain batch 6/16 - 258.8ms/batch - loss: 68.82998 - diff: 35.20mlTrain batch 7/16 - 269.0ms/batch - loss: 66.84179 - diff: 34.18mlTrain batch 8/16 - 266.9ms/batch - loss: 67.36036 - diff: 34.35mlTrain batch 9/16 - 260.8ms/batch - loss: 62.60270 - diff: 33.06mlTrain batch 10/16 - 259.1ms/batch - loss: 59.07411 - diff: 32.25mlTrain batch 11/16 - 283.9ms/batch - loss: 58.28807 - diff: 32.10mlTrain batch 12/16 - 258.8ms/batch - loss: 57.17701 - diff: 32.09mlTrain batch 13/16 - 268.4ms/batch - loss: 68.82171 - diff: 32.84mlTrain batch 14/16 - 259.7ms/batch - loss: 69.86710 - diff: 32.60mlTrain batch 15/16 - 257.8ms/batch - loss: 67.42285 - diff: 32.04mlTrain batch 16/16 - 172.4ms/batch - loss: 66.22767 - diff: 31.58mlTrain batch 16/16 - 10.4s 172.4ms/batch - loss: 66.22767 - diff: 31.58ml
Test 0.8s: val_loss: 50.03108 - diff: 24.96ml

Epoch 52: current best loss = 42.86696, at epoch 42
Train batch 1/16 - 263.5ms/batch - loss: 16.10585 - diff: 18.71mlTrain batch 2/16 - 258.1ms/batch - loss: 49.32094 - diff: 28.93mlTrain batch 3/16 - 265.0ms/batch - loss: 68.36696 - diff: 32.29mlTrain batch 4/16 - 258.2ms/batch - loss: 68.02785 - diff: 32.96mlTrain batch 5/16 - 263.1ms/batch - loss: 71.84221 - diff: 35.53mlTrain batch 6/16 - 260.8ms/batch - loss: 65.55201 - diff: 33.99mlTrain batch 7/16 - 258.8ms/batch - loss: 61.45386 - diff: 32.81mlTrain batch 8/16 - 262.7ms/batch - loss: 57.64007 - diff: 31.73mlTrain batch 9/16 - 260.5ms/batch - loss: 54.61515 - diff: 30.82mlTrain batch 10/16 - 258.2ms/batch - loss: 54.70036 - diff: 30.47mlTrain batch 11/16 - 272.2ms/batch - loss: 56.63005 - diff: 30.96mlTrain batch 12/16 - 260.4ms/batch - loss: 70.21205 - diff: 31.57mlTrain batch 13/16 - 271.3ms/batch - loss: 69.24147 - diff: 32.10mlTrain batch 14/16 - 263.3ms/batch - loss: 70.18165 - diff: 32.74mlTrain batch 15/16 - 264.2ms/batch - loss: 67.26108 - diff: 32.18mlTrain batch 16/16 - 173.8ms/batch - loss: 65.86863 - diff: 31.75mlTrain batch 16/16 - 10.4s 173.8ms/batch - loss: 65.86863 - diff: 31.75ml
Test 0.8s: val_loss: 75.98979 - diff: 32.85ml

Epoch 53: current best loss = 42.86696, at epoch 42
Train batch 1/16 - 260.1ms/batch - loss: 41.89136 - diff: 25.51mlTrain batch 2/16 - 258.5ms/batch - loss: 65.95751 - diff: 31.86mlTrain batch 3/16 - 273.9ms/batch - loss: 66.08978 - diff: 32.91mlTrain batch 4/16 - 258.3ms/batch - loss: 71.12677 - diff: 33.23mlTrain batch 5/16 - 259.4ms/batch - loss: 74.11788 - diff: 33.60mlTrain batch 6/16 - 259.6ms/batch - loss: 66.69872 - diff: 31.83mlTrain batch 7/16 - 258.4ms/batch - loss: 69.19210 - diff: 33.38mlTrain batch 8/16 - 260.3ms/batch - loss: 68.62646 - diff: 34.23mlTrain batch 9/16 - 260.4ms/batch - loss: 66.78672 - diff: 33.81mlTrain batch 10/16 - 259.0ms/batch - loss: 64.23643 - diff: 32.86mlTrain batch 11/16 - 260.4ms/batch - loss: 68.17408 - diff: 33.03mlTrain batch 12/16 - 258.6ms/batch - loss: 82.43308 - diff: 34.12mlTrain batch 13/16 - 258.8ms/batch - loss: 82.79611 - diff: 34.19mlTrain batch 14/16 - 258.1ms/batch - loss: 80.50054 - diff: 33.65mlTrain batch 15/16 - 259.8ms/batch - loss: 77.44779 - diff: 33.28mlTrain batch 16/16 - 173.1ms/batch - loss: 76.51601 - diff: 33.10mlTrain batch 16/16 - 10.4s 173.1ms/batch - loss: 76.51601 - diff: 33.10ml
Test 0.8s: val_loss: 54.09931 - diff: 30.11ml
Epoch    54: reducing learning rate of group 0 to 2.5000e-04.

Epoch 54: current best loss = 42.86696, at epoch 42
Train batch 1/16 - 266.2ms/batch - loss: 80.70286 - diff: 33.66mlTrain batch 2/16 - 259.4ms/batch - loss: 66.73771 - diff: 33.42mlTrain batch 3/16 - 266.7ms/batch - loss: 57.80443 - diff: 30.61mlTrain batch 4/16 - 259.1ms/batch - loss: 59.11291 - diff: 31.17mlTrain batch 5/16 - 263.7ms/batch - loss: 58.66914 - diff: 30.63mlTrain batch 6/16 - 260.0ms/batch - loss: 58.31833 - diff: 29.72mlTrain batch 7/16 - 264.6ms/batch - loss: 77.70421 - diff: 30.46mlTrain batch 8/16 - 259.9ms/batch - loss: 74.45934 - diff: 30.30mlTrain batch 9/16 - 258.3ms/batch - loss: 71.71194 - diff: 30.49mlTrain batch 10/16 - 259.0ms/batch - loss: 67.35874 - diff: 29.77mlTrain batch 11/16 - 262.4ms/batch - loss: 65.23580 - diff: 29.74mlTrain batch 12/16 - 261.6ms/batch - loss: 61.61628 - diff: 29.18mlTrain batch 13/16 - 257.8ms/batch - loss: 60.17168 - diff: 28.91mlTrain batch 14/16 - 262.1ms/batch - loss: 60.15987 - diff: 28.87mlTrain batch 15/16 - 258.3ms/batch - loss: 58.53129 - diff: 28.81mlTrain batch 16/16 - 176.7ms/batch - loss: 57.74664 - diff: 28.64mlTrain batch 16/16 - 10.5s 176.7ms/batch - loss: 57.74664 - diff: 28.64ml
Test 0.8s: val_loss: 73.76799 - diff: 24.73ml

Epoch 55: current best loss = 42.86696, at epoch 42
Train batch 1/16 - 263.9ms/batch - loss: 23.07951 - diff: 22.76mlTrain batch 2/16 - 258.8ms/batch - loss: 36.10778 - diff: 24.29mlTrain batch 3/16 - 263.0ms/batch - loss: 39.21491 - diff: 25.18mlTrain batch 4/16 - 259.7ms/batch - loss: 52.41384 - diff: 27.06mlTrain batch 5/16 - 261.8ms/batch - loss: 47.45485 - diff: 26.09mlTrain batch 6/16 - 258.7ms/batch - loss: 43.00210 - diff: 24.88mlTrain batch 7/16 - 259.6ms/batch - loss: 41.85566 - diff: 25.38mlTrain batch 8/16 - 259.4ms/batch - loss: 43.43290 - diff: 25.96mlTrain batch 9/16 - 260.3ms/batch - loss: 45.35862 - diff: 26.37mlTrain batch 10/16 - 258.3ms/batch - loss: 48.18558 - diff: 27.33mlTrain batch 11/16 - 260.5ms/batch - loss: 47.02755 - diff: 27.35mlTrain batch 12/16 - 261.0ms/batch - loss: 47.18615 - diff: 27.81mlTrain batch 13/16 - 262.8ms/batch - loss: 45.73600 - diff: 27.66mlTrain batch 14/16 - 258.0ms/batch - loss: 44.80442 - diff: 27.34mlTrain batch 15/16 - 258.1ms/batch - loss: 45.88913 - diff: 27.46mlTrain batch 16/16 - 172.2ms/batch - loss: 66.48368 - diff: 28.31mlTrain batch 16/16 - 10.4s 172.2ms/batch - loss: 66.48368 - diff: 28.31ml
Test 0.9s: val_loss: 51.19414 - diff: 24.69ml

Epoch 56: current best loss = 42.86696, at epoch 42
Train batch 1/16 - 258.5ms/batch - loss: 50.08313 - diff: 27.14mlTrain batch 2/16 - 261.0ms/batch - loss: 45.21062 - diff: 25.66mlTrain batch 3/16 - 260.0ms/batch - loss: 39.28190 - diff: 24.87mlTrain batch 4/16 - 261.6ms/batch - loss: 53.79009 - diff: 28.44mlTrain batch 5/16 - 258.5ms/batch - loss: 50.18064 - diff: 28.40mlTrain batch 6/16 - 260.2ms/batch - loss: 81.12885 - diff: 32.54mlTrain batch 7/16 - 262.5ms/batch - loss: 76.24275 - diff: 32.58mlTrain batch 8/16 - 260.1ms/batch - loss: 71.72462 - diff: 32.23mlTrain batch 9/16 - 262.8ms/batch - loss: 73.67527 - diff: 32.48mlTrain batch 10/16 - 258.7ms/batch - loss: 69.22239 - diff: 31.84mlTrain batch 11/16 - 263.2ms/batch - loss: 64.92534 - diff: 30.87mlTrain batch 12/16 - 259.3ms/batch - loss: 62.92002 - diff: 30.64mlTrain batch 13/16 - 258.5ms/batch - loss: 61.18896 - diff: 30.22mlTrain batch 14/16 - 259.8ms/batch - loss: 60.28390 - diff: 29.90mlTrain batch 15/16 - 259.1ms/batch - loss: 58.80480 - diff: 29.49mlTrain batch 16/16 - 172.1ms/batch - loss: 57.58198 - diff: 29.10mlTrain batch 16/16 - 10.5s 172.1ms/batch - loss: 57.58198 - diff: 29.10ml
Test 0.9s: val_loss: 46.14274 - diff: 26.95ml

Epoch 57: current best loss = 42.86696, at epoch 42
Train batch 1/16 - 259.6ms/batch - loss: 31.85753 - diff: 24.92mlTrain batch 2/16 - 260.2ms/batch - loss: 41.03818 - diff: 28.56mlTrain batch 3/16 - 258.0ms/batch - loss: 36.26747 - diff: 27.47mlTrain batch 4/16 - 258.4ms/batch - loss: 39.56625 - diff: 28.38mlTrain batch 5/16 - 258.7ms/batch - loss: 36.03463 - diff: 26.64mlTrain batch 6/16 - 258.1ms/batch - loss: 43.20495 - diff: 27.60mlTrain batch 7/16 - 262.9ms/batch - loss: 43.96185 - diff: 27.30mlTrain batch 8/16 - 261.4ms/batch - loss: 43.57341 - diff: 27.10mlTrain batch 9/16 - 263.7ms/batch - loss: 40.97748 - diff: 26.34mlTrain batch 10/16 - 258.7ms/batch - loss: 56.44104 - diff: 27.30mlTrain batch 11/16 - 263.2ms/batch - loss: 54.47049 - diff: 27.10mlTrain batch 12/16 - 259.7ms/batch - loss: 55.03526 - diff: 27.80mlTrain batch 13/16 - 263.8ms/batch - loss: 54.25311 - diff: 28.00mlTrain batch 14/16 - 259.0ms/batch - loss: 55.85414 - diff: 28.10mlTrain batch 15/16 - 258.2ms/batch - loss: 53.34906 - diff: 27.56mlTrain batch 16/16 - 172.8ms/batch - loss: 54.79943 - diff: 27.52mlTrain batch 16/16 - 10.5s 172.8ms/batch - loss: 54.79943 - diff: 27.52ml
Test 0.9s: val_loss: 42.06663 - diff: 22.87ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Systole_VGG19_Adam-0.001_MSE_DA3_best

Epoch 58: current best loss = 42.06663, at epoch 57
Train batch 1/16 - 263.4ms/batch - loss: 53.21787 - diff: 27.49mlTrain batch 2/16 - 259.4ms/batch - loss: 42.36588 - diff: 24.40mlTrain batch 3/16 - 272.1ms/batch - loss: 90.55109 - diff: 29.65mlTrain batch 4/16 - 262.3ms/batch - loss: 93.06663 - diff: 32.32mlTrain batch 5/16 - 272.6ms/batch - loss: 80.03857 - diff: 31.02mlTrain batch 6/16 - 262.5ms/batch - loss: 72.31647 - diff: 30.26mlTrain batch 7/16 - 261.7ms/batch - loss: 63.30555 - diff: 27.83mlTrain batch 8/16 - 259.3ms/batch - loss: 61.44838 - diff: 27.71mlTrain batch 9/16 - 259.5ms/batch - loss: 58.79759 - diff: 27.32mlTrain batch 10/16 - 259.3ms/batch - loss: 58.89130 - diff: 27.53mlTrain batch 11/16 - 259.4ms/batch - loss: 56.72493 - diff: 27.20mlTrain batch 12/16 - 263.4ms/batch - loss: 56.40891 - diff: 27.50mlTrain batch 13/16 - 259.2ms/batch - loss: 54.59412 - diff: 27.58mlTrain batch 14/16 - 260.7ms/batch - loss: 53.83131 - diff: 28.11mlTrain batch 15/16 - 259.0ms/batch - loss: 54.23087 - diff: 28.32mlTrain batch 16/16 - 172.8ms/batch - loss: 54.18616 - diff: 28.28mlTrain batch 16/16 - 10.4s 172.8ms/batch - loss: 54.18616 - diff: 28.28ml
Test 0.8s: val_loss: 44.14703 - diff: 23.56ml

Epoch 59: current best loss = 42.06663, at epoch 57
Train batch 1/16 - 263.8ms/batch - loss: 45.94474 - diff: 26.30mlTrain batch 2/16 - 262.3ms/batch - loss: 42.73450 - diff: 26.56mlTrain batch 3/16 - 261.0ms/batch - loss: 34.82452 - diff: 23.96mlTrain batch 4/16 - 260.3ms/batch - loss: 42.46001 - diff: 25.78mlTrain batch 5/16 - 262.3ms/batch - loss: 50.45362 - diff: 26.98mlTrain batch 6/16 - 262.0ms/batch - loss: 47.78218 - diff: 26.96mlTrain batch 7/16 - 262.3ms/batch - loss: 49.51219 - diff: 28.83mlTrain batch 8/16 - 258.3ms/batch - loss: 48.79977 - diff: 28.72mlTrain batch 9/16 - 260.4ms/batch - loss: 44.98479 - diff: 27.49mlTrain batch 10/16 - 259.4ms/batch - loss: 41.56782 - diff: 26.26mlTrain batch 11/16 - 261.9ms/batch - loss: 40.90602 - diff: 25.70mlTrain batch 12/16 - 259.8ms/batch - loss: 41.94075 - diff: 25.47mlTrain batch 13/16 - 262.0ms/batch - loss: 42.09365 - diff: 25.53mlTrain batch 14/16 - 261.5ms/batch - loss: 43.22547 - diff: 25.75mlTrain batch 15/16 - 258.3ms/batch - loss: 51.84840 - diff: 26.37mlTrain batch 16/16 - 172.6ms/batch - loss: 52.23582 - diff: 26.54mlTrain batch 16/16 - 10.4s 172.6ms/batch - loss: 52.23582 - diff: 26.54ml
Test 0.8s: val_loss: 59.23266 - diff: 35.90ml

Epoch 60: current best loss = 42.06663, at epoch 57
Train batch 1/16 - 258.8ms/batch - loss: 29.42208 - diff: 25.46mlTrain batch 2/16 - 258.8ms/batch - loss: 27.83818 - diff: 24.91mlTrain batch 3/16 - 259.0ms/batch - loss: 25.36432 - diff: 23.51mlTrain batch 4/16 - 258.6ms/batch - loss: 35.49883 - diff: 25.25mlTrain batch 5/16 - 258.7ms/batch - loss: 31.38703 - diff: 23.62mlTrain batch 6/16 - 258.8ms/batch - loss: 37.70730 - diff: 25.30mlTrain batch 7/16 - 259.6ms/batch - loss: 50.44813 - diff: 27.01mlTrain batch 8/16 - 260.8ms/batch - loss: 49.39177 - diff: 27.02mlTrain batch 9/16 - 263.9ms/batch - loss: 49.82414 - diff: 27.26mlTrain batch 10/16 - 258.6ms/batch - loss: 50.93948 - diff: 27.78mlTrain batch 11/16 - 258.2ms/batch - loss: 50.46736 - diff: 28.23mlTrain batch 12/16 - 258.9ms/batch - loss: 60.32404 - diff: 29.94mlTrain batch 13/16 - 260.5ms/batch - loss: 57.77988 - diff: 29.44mlTrain batch 14/16 - 258.8ms/batch - loss: 54.89466 - diff: 28.74mlTrain batch 15/16 - 258.7ms/batch - loss: 54.63093 - diff: 28.54mlTrain batch 16/16 - 172.5ms/batch - loss: 56.26642 - diff: 28.83mlTrain batch 16/16 - 10.5s 172.5ms/batch - loss: 56.26642 - diff: 28.83ml
Test 0.9s: val_loss: 51.77073 - diff: 25.77ml

Epoch 61: current best loss = 42.06663, at epoch 57
Train batch 1/16 - 262.5ms/batch - loss: 45.28625 - diff: 25.20mlTrain batch 2/16 - 260.7ms/batch - loss: 42.57499 - diff: 24.94mlTrain batch 3/16 - 259.4ms/batch - loss: 39.70677 - diff: 24.01mlTrain batch 4/16 - 259.3ms/batch - loss: 36.70342 - diff: 24.16mlTrain batch 5/16 - 263.4ms/batch - loss: 32.59510 - diff: 22.89mlTrain batch 6/16 - 259.4ms/batch - loss: 31.25740 - diff: 22.88mlTrain batch 7/16 - 263.3ms/batch - loss: 29.90962 - diff: 22.17mlTrain batch 8/16 - 260.0ms/batch - loss: 31.53356 - diff: 22.79mlTrain batch 9/16 - 262.9ms/batch - loss: 39.97820 - diff: 23.50mlTrain batch 10/16 - 261.3ms/batch - loss: 37.92268 - diff: 23.21mlTrain batch 11/16 - 263.6ms/batch - loss: 39.39075 - diff: 24.07mlTrain batch 12/16 - 259.0ms/batch - loss: 39.31461 - diff: 24.52mlTrain batch 13/16 - 262.2ms/batch - loss: 45.52410 - diff: 25.21mlTrain batch 14/16 - 262.9ms/batch - loss: 44.16708 - diff: 25.19mlTrain batch 15/16 - 259.1ms/batch - loss: 44.35849 - diff: 25.65mlTrain batch 16/16 - 172.8ms/batch - loss: 44.47146 - diff: 25.45mlTrain batch 16/16 - 10.4s 172.8ms/batch - loss: 44.47146 - diff: 25.45ml
Test 0.9s: val_loss: 42.40277 - diff: 21.91ml

Epoch 62: current best loss = 42.06663, at epoch 57
Train batch 1/16 - 260.7ms/batch - loss: 17.34389 - diff: 17.55mlTrain batch 2/16 - 259.6ms/batch - loss: 13.22694 - diff: 15.94mlTrain batch 3/16 - 258.8ms/batch - loss: 16.64105 - diff: 16.95mlTrain batch 4/16 - 259.1ms/batch - loss: 30.23305 - diff: 21.17mlTrain batch 5/16 - 264.1ms/batch - loss: 31.62500 - diff: 21.79mlTrain batch 6/16 - 258.1ms/batch - loss: 34.54904 - diff: 23.75mlTrain batch 7/16 - 259.5ms/batch - loss: 33.49620 - diff: 23.81mlTrain batch 8/16 - 260.9ms/batch - loss: 31.17453 - diff: 23.05mlTrain batch 9/16 - 264.4ms/batch - loss: 45.80869 - diff: 24.24mlTrain batch 10/16 - 263.8ms/batch - loss: 43.56282 - diff: 23.71mlTrain batch 11/16 - 260.6ms/batch - loss: 50.23047 - diff: 24.81mlTrain batch 12/16 - 260.1ms/batch - loss: 49.07108 - diff: 25.11mlTrain batch 13/16 - 272.6ms/batch - loss: 47.48368 - diff: 25.01mlTrain batch 14/16 - 257.9ms/batch - loss: 46.19977 - diff: 24.91mlTrain batch 15/16 - 258.4ms/batch - loss: 44.69559 - diff: 24.60mlTrain batch 16/16 - 172.0ms/batch - loss: 45.21006 - diff: 24.40mlTrain batch 16/16 - 10.4s 172.0ms/batch - loss: 45.21006 - diff: 24.40ml
Test 0.8s: val_loss: 43.79229 - diff: 23.17ml

Epoch 63: current best loss = 42.06663, at epoch 57
Train batch 1/16 - 261.4ms/batch - loss: 38.07598 - diff: 24.64mlTrain batch 2/16 - 260.3ms/batch - loss: 25.59829 - diff: 20.66mlTrain batch 3/16 - 259.8ms/batch - loss: 23.18015 - diff: 20.57mlTrain batch 4/16 - 260.4ms/batch - loss: 24.91275 - diff: 21.68mlTrain batch 5/16 - 260.1ms/batch - loss: 28.65617 - diff: 23.37mlTrain batch 6/16 - 260.3ms/batch - loss: 28.72578 - diff: 22.64mlTrain batch 7/16 - 261.1ms/batch - loss: 31.72486 - diff: 23.35mlTrain batch 8/16 - 258.2ms/batch - loss: 38.10855 - diff: 24.64mlTrain batch 9/16 - 261.8ms/batch - loss: 49.95588 - diff: 25.32mlTrain batch 10/16 - 262.0ms/batch - loss: 47.85908 - diff: 25.49mlTrain batch 11/16 - 261.2ms/batch - loss: 45.96729 - diff: 25.28mlTrain batch 12/16 - 258.0ms/batch - loss: 44.59373 - diff: 25.24mlTrain batch 13/16 - 274.0ms/batch - loss: 43.73595 - diff: 25.28mlTrain batch 14/16 - 260.8ms/batch - loss: 45.86768 - diff: 25.17mlTrain batch 15/16 - 261.8ms/batch - loss: 45.53028 - diff: 24.98mlTrain batch 16/16 - 172.6ms/batch - loss: 47.75842 - diff: 25.25mlTrain batch 16/16 - 10.5s 172.6ms/batch - loss: 47.75842 - diff: 25.25ml
Test 0.8s: val_loss: 39.96339 - diff: 22.98ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Systole_VGG19_Adam-0.001_MSE_DA3_best

Epoch 64: current best loss = 39.96339, at epoch 63
Train batch 1/16 - 261.7ms/batch - loss: 29.94368 - diff: 26.12mlTrain batch 2/16 - 259.9ms/batch - loss: 38.85974 - diff: 28.48mlTrain batch 3/16 - 259.1ms/batch - loss: 41.19099 - diff: 29.82mlTrain batch 4/16 - 259.1ms/batch - loss: 42.82993 - diff: 29.16mlTrain batch 5/16 - 262.3ms/batch - loss: 56.11482 - diff: 30.68mlTrain batch 6/16 - 258.7ms/batch - loss: 52.10425 - diff: 29.15mlTrain batch 7/16 - 258.3ms/batch - loss: 49.30709 - diff: 28.31mlTrain batch 8/16 - 258.8ms/batch - loss: 58.90372 - diff: 28.29mlTrain batch 9/16 - 265.9ms/batch - loss: 54.39275 - diff: 27.37mlTrain batch 10/16 - 257.9ms/batch - loss: 55.20060 - diff: 28.65mlTrain batch 11/16 - 259.6ms/batch - loss: 55.10490 - diff: 28.86mlTrain batch 12/16 - 259.6ms/batch - loss: 52.11238 - diff: 28.01mlTrain batch 13/16 - 260.9ms/batch - loss: 50.56166 - diff: 27.60mlTrain batch 14/16 - 259.0ms/batch - loss: 53.00539 - diff: 28.24mlTrain batch 15/16 - 257.7ms/batch - loss: 51.88496 - diff: 27.94mlTrain batch 16/16 - 172.7ms/batch - loss: 51.76257 - diff: 27.84mlTrain batch 16/16 - 10.5s 172.7ms/batch - loss: 51.76257 - diff: 27.84ml
Test 0.8s: val_loss: 35.69432 - diff: 23.54ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Systole_VGG19_Adam-0.001_MSE_DA3_best

Epoch 65: current best loss = 35.69432, at epoch 64
Train batch 1/16 - 259.1ms/batch - loss: 37.54035 - diff: 26.25mlTrain batch 2/16 - 261.1ms/batch - loss: 53.51052 - diff: 33.24mlTrain batch 3/16 - 260.9ms/batch - loss: 47.44895 - diff: 31.13mlTrain batch 4/16 - 258.3ms/batch - loss: 41.72935 - diff: 29.26mlTrain batch 5/16 - 263.5ms/batch - loss: 39.94200 - diff: 28.64mlTrain batch 6/16 - 259.9ms/batch - loss: 41.40609 - diff: 28.10mlTrain batch 7/16 - 262.9ms/batch - loss: 58.30420 - diff: 28.69mlTrain batch 8/16 - 258.1ms/batch - loss: 62.79446 - diff: 28.60mlTrain batch 9/16 - 260.8ms/batch - loss: 58.08306 - diff: 27.66mlTrain batch 10/16 - 258.1ms/batch - loss: 55.07943 - diff: 27.37mlTrain batch 11/16 - 262.2ms/batch - loss: 52.22391 - diff: 27.09mlTrain batch 12/16 - 260.8ms/batch - loss: 50.47194 - diff: 26.92mlTrain batch 13/16 - 261.2ms/batch - loss: 48.63831 - diff: 26.66mlTrain batch 14/16 - 258.6ms/batch - loss: 46.99343 - diff: 26.40mlTrain batch 15/16 - 259.3ms/batch - loss: 45.82614 - diff: 25.98mlTrain batch 16/16 - 173.4ms/batch - loss: 45.97104 - diff: 25.99mlTrain batch 16/16 - 10.5s 173.4ms/batch - loss: 45.97104 - diff: 25.99ml
Test 0.8s: val_loss: 33.13099 - diff: 21.64ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Systole_VGG19_Adam-0.001_MSE_DA3_best

Epoch 66: current best loss = 33.13099, at epoch 65
Train batch 1/16 - 261.6ms/batch - loss: 30.09162 - diff: 23.50mlTrain batch 2/16 - 258.3ms/batch - loss: 40.96590 - diff: 27.68mlTrain batch 3/16 - 261.8ms/batch - loss: 41.02430 - diff: 28.19mlTrain batch 4/16 - 261.0ms/batch - loss: 36.75072 - diff: 26.27mlTrain batch 5/16 - 259.8ms/batch - loss: 35.78043 - diff: 25.58mlTrain batch 6/16 - 258.3ms/batch - loss: 40.12473 - diff: 26.91mlTrain batch 7/16 - 260.3ms/batch - loss: 48.51719 - diff: 27.66mlTrain batch 8/16 - 262.2ms/batch - loss: 44.78202 - diff: 26.63mlTrain batch 9/16 - 259.8ms/batch - loss: 55.97652 - diff: 27.10mlTrain batch 10/16 - 259.6ms/batch - loss: 53.43668 - diff: 27.28mlTrain batch 11/16 - 263.6ms/batch - loss: 51.71965 - diff: 27.31mlTrain batch 12/16 - 258.9ms/batch - loss: 49.34775 - diff: 26.79mlTrain batch 13/16 - 259.6ms/batch - loss: 47.32488 - diff: 26.32mlTrain batch 14/16 - 258.4ms/batch - loss: 45.30138 - diff: 25.70mlTrain batch 15/16 - 258.4ms/batch - loss: 45.20130 - diff: 25.82mlTrain batch 16/16 - 173.5ms/batch - loss: 47.46051 - diff: 25.71mlTrain batch 16/16 - 10.6s 173.5ms/batch - loss: 47.46051 - diff: 25.71ml
Test 0.9s: val_loss: 33.45361 - diff: 20.78ml

Epoch 67: current best loss = 33.13099, at epoch 65
Train batch 1/16 - 260.9ms/batch - loss: 27.91393 - diff: 21.35mlTrain batch 2/16 - 259.5ms/batch - loss: 23.86243 - diff: 20.81mlTrain batch 3/16 - 260.6ms/batch - loss: 32.25348 - diff: 24.76mlTrain batch 4/16 - 259.7ms/batch - loss: 34.72454 - diff: 26.29mlTrain batch 5/16 - 260.7ms/batch - loss: 34.46335 - diff: 26.43mlTrain batch 6/16 - 258.6ms/batch - loss: 32.35999 - diff: 25.62mlTrain batch 7/16 - 258.7ms/batch - loss: 30.83904 - diff: 24.90mlTrain batch 8/16 - 260.9ms/batch - loss: 28.99587 - diff: 24.13mlTrain batch 9/16 - 259.3ms/batch - loss: 30.29674 - diff: 24.41mlTrain batch 10/16 - 259.6ms/batch - loss: 33.46774 - diff: 25.07mlTrain batch 11/16 - 261.7ms/batch - loss: 34.81411 - diff: 24.68mlTrain batch 12/16 - 258.9ms/batch - loss: 33.37863 - diff: 24.32mlTrain batch 13/16 - 260.0ms/batch - loss: 37.52145 - diff: 24.87mlTrain batch 14/16 - 259.8ms/batch - loss: 36.65308 - diff: 24.87mlTrain batch 15/16 - 259.5ms/batch - loss: 41.02170 - diff: 25.60mlTrain batch 16/16 - 173.2ms/batch - loss: 41.44052 - diff: 25.74mlTrain batch 16/16 - 10.5s 173.2ms/batch - loss: 41.44052 - diff: 25.74ml
Test 0.8s: val_loss: 34.85033 - diff: 21.55ml

Epoch 68: current best loss = 33.13099, at epoch 65
Train batch 1/16 - 262.8ms/batch - loss: 45.21545 - diff: 29.28mlTrain batch 2/16 - 258.3ms/batch - loss: 43.17709 - diff: 26.11mlTrain batch 3/16 - 258.6ms/batch - loss: 34.94832 - diff: 23.17mlTrain batch 4/16 - 258.4ms/batch - loss: 33.44530 - diff: 23.23mlTrain batch 5/16 - 260.4ms/batch - loss: 29.40405 - diff: 21.44mlTrain batch 6/16 - 258.6ms/batch - loss: 38.08950 - diff: 22.27mlTrain batch 7/16 - 264.4ms/batch - loss: 35.21869 - diff: 21.84mlTrain batch 8/16 - 258.3ms/batch - loss: 44.43321 - diff: 23.07mlTrain batch 9/16 - 262.8ms/batch - loss: 43.18905 - diff: 23.59mlTrain batch 10/16 - 262.9ms/batch - loss: 41.74222 - diff: 23.65mlTrain batch 11/16 - 264.1ms/batch - loss: 41.05149 - diff: 23.69mlTrain batch 12/16 - 258.7ms/batch - loss: 43.06470 - diff: 24.31mlTrain batch 13/16 - 263.9ms/batch - loss: 42.70627 - diff: 24.42mlTrain batch 14/16 - 258.2ms/batch - loss: 41.16159 - diff: 24.07mlTrain batch 15/16 - 258.4ms/batch - loss: 40.06509 - diff: 23.92mlTrain batch 16/16 - 172.1ms/batch - loss: 41.25838 - diff: 24.13mlTrain batch 16/16 - 10.5s 172.1ms/batch - loss: 41.25838 - diff: 24.13ml
Test 0.8s: val_loss: 100.13933 - diff: 46.76ml

Epoch 69: current best loss = 33.13099, at epoch 65
Train batch 1/16 - 264.8ms/batch - loss: 55.15800 - diff: 38.64mlTrain batch 2/16 - 259.3ms/batch - loss: 49.50102 - diff: 34.46mlTrain batch 3/16 - 260.7ms/batch - loss: 38.99253 - diff: 29.11mlTrain batch 4/16 - 258.3ms/batch - loss: 40.64894 - diff: 29.32mlTrain batch 5/16 - 260.5ms/batch - loss: 40.13302 - diff: 28.39mlTrain batch 6/16 - 259.1ms/batch - loss: 36.71042 - diff: 26.45mlTrain batch 7/16 - 258.9ms/batch - loss: 48.21869 - diff: 26.98mlTrain batch 8/16 - 259.8ms/batch - loss: 44.64994 - diff: 26.14mlTrain batch 9/16 - 258.5ms/batch - loss: 48.74554 - diff: 27.05mlTrain batch 10/16 - 259.9ms/batch - loss: 49.00222 - diff: 27.65mlTrain batch 11/16 - 259.9ms/batch - loss: 47.81593 - diff: 27.70mlTrain batch 12/16 - 258.7ms/batch - loss: 47.31328 - diff: 27.63mlTrain batch 13/16 - 260.3ms/batch - loss: 46.62774 - diff: 27.35mlTrain batch 14/16 - 259.7ms/batch - loss: 45.58765 - diff: 26.96mlTrain batch 15/16 - 258.3ms/batch - loss: 44.59271 - diff: 26.59mlTrain batch 16/16 - 172.7ms/batch - loss: 43.62422 - diff: 26.19mlTrain batch 16/16 - 10.5s 172.7ms/batch - loss: 43.62422 - diff: 26.19ml
Test 0.8s: val_loss: 32.77265 - diff: 21.82ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Systole_VGG19_Adam-0.001_MSE_DA3_best

Epoch 70: current best loss = 32.77265, at epoch 69
Train batch 1/16 - 260.1ms/batch - loss: 22.33193 - diff: 20.01mlTrain batch 2/16 - 259.6ms/batch - loss: 33.31013 - diff: 24.82mlTrain batch 3/16 - 262.4ms/batch - loss: 29.20947 - diff: 23.76mlTrain batch 4/16 - 259.4ms/batch - loss: 26.06837 - diff: 22.07mlTrain batch 5/16 - 271.9ms/batch - loss: 25.93680 - diff: 21.78mlTrain batch 6/16 - 260.7ms/batch - loss: 24.26391 - diff: 21.21mlTrain batch 7/16 - 262.6ms/batch - loss: 22.50382 - diff: 20.38mlTrain batch 8/16 - 258.8ms/batch - loss: 23.23989 - diff: 20.48mlTrain batch 9/16 - 262.6ms/batch - loss: 25.10432 - diff: 20.68mlTrain batch 10/16 - 259.6ms/batch - loss: 29.82958 - diff: 20.95mlTrain batch 11/16 - 263.7ms/batch - loss: 34.22022 - diff: 21.64mlTrain batch 12/16 - 260.1ms/batch - loss: 36.99932 - diff: 23.07mlTrain batch 13/16 - 263.8ms/batch - loss: 36.18867 - diff: 23.18mlTrain batch 14/16 - 259.9ms/batch - loss: 39.37417 - diff: 24.01mlTrain batch 15/16 - 258.8ms/batch - loss: 38.71292 - diff: 23.64mlTrain batch 16/16 - 172.7ms/batch - loss: 39.30650 - diff: 23.63mlTrain batch 16/16 - 10.4s 172.7ms/batch - loss: 39.30650 - diff: 23.63ml
Test 0.8s: val_loss: 35.14108 - diff: 20.75ml

Epoch 71: current best loss = 32.77265, at epoch 69
Train batch 1/16 - 262.3ms/batch - loss: 24.65796 - diff: 19.82mlTrain batch 2/16 - 259.5ms/batch - loss: 23.72174 - diff: 19.12mlTrain batch 3/16 - 262.4ms/batch - loss: 25.85429 - diff: 21.22mlTrain batch 4/16 - 259.6ms/batch - loss: 28.32274 - diff: 23.14mlTrain batch 5/16 - 281.1ms/batch - loss: 27.54976 - diff: 23.32mlTrain batch 6/16 - 258.2ms/batch - loss: 26.52885 - diff: 22.91mlTrain batch 7/16 - 260.8ms/batch - loss: 25.70376 - diff: 22.04mlTrain batch 8/16 - 259.5ms/batch - loss: 24.52582 - diff: 21.62mlTrain batch 9/16 - 260.1ms/batch - loss: 27.57005 - diff: 22.51mlTrain batch 10/16 - 260.2ms/batch - loss: 25.85088 - diff: 21.73mlTrain batch 11/16 - 258.1ms/batch - loss: 28.37390 - diff: 22.32mlTrain batch 12/16 - 259.1ms/batch - loss: 37.01675 - diff: 23.28mlTrain batch 13/16 - 259.8ms/batch - loss: 41.37693 - diff: 24.48mlTrain batch 14/16 - 258.6ms/batch - loss: 45.81482 - diff: 26.31mlTrain batch 15/16 - 259.8ms/batch - loss: 44.37415 - diff: 26.13mlTrain batch 16/16 - 172.5ms/batch - loss: 44.75664 - diff: 26.07mlTrain batch 16/16 - 10.4s 172.5ms/batch - loss: 44.75664 - diff: 26.07ml
Test 0.8s: val_loss: 63.97435 - diff: 30.66ml

Epoch 72: current best loss = 32.77265, at epoch 69
Train batch 1/16 - 263.2ms/batch - loss: 41.91423 - diff: 26.15mlTrain batch 2/16 - 261.0ms/batch - loss: 54.42100 - diff: 30.80mlTrain batch 3/16 - 263.3ms/batch - loss: 76.84659 - diff: 32.48mlTrain batch 4/16 - 260.8ms/batch - loss: 107.72674 - diff: 34.06mlTrain batch 5/16 - 263.1ms/batch - loss: 101.73212 - diff: 34.18mlTrain batch 6/16 - 263.1ms/batch - loss: 89.55068 - diff: 32.44mlTrain batch 7/16 - 258.4ms/batch - loss: 86.22900 - diff: 32.77mlTrain batch 8/16 - 262.9ms/batch - loss: 83.69103 - diff: 33.38mlTrain batch 9/16 - 258.2ms/batch - loss: 79.85195 - diff: 33.53mlTrain batch 10/16 - 258.2ms/batch - loss: 74.52882 - diff: 32.51mlTrain batch 11/16 - 258.2ms/batch - loss: 68.99115 - diff: 31.01mlTrain batch 12/16 - 258.4ms/batch - loss: 64.57976 - diff: 29.96mlTrain batch 13/16 - 258.4ms/batch - loss: 62.03023 - diff: 29.45mlTrain batch 14/16 - 258.5ms/batch - loss: 61.67121 - diff: 29.24mlTrain batch 15/16 - 258.1ms/batch - loss: 60.63921 - diff: 29.04mlTrain batch 16/16 - 173.3ms/batch - loss: 58.98080 - diff: 28.52mlTrain batch 16/16 - 10.4s 173.3ms/batch - loss: 58.98080 - diff: 28.52ml
Test 0.8s: val_loss: 32.96435 - diff: 23.99ml

Epoch 73: current best loss = 32.77265, at epoch 69
Train batch 1/16 - 261.0ms/batch - loss: 87.24815 - diff: 27.98mlTrain batch 2/16 - 258.8ms/batch - loss: 62.03941 - diff: 28.20mlTrain batch 3/16 - 261.1ms/batch - loss: 52.71884 - diff: 27.39mlTrain batch 4/16 - 260.3ms/batch - loss: 46.22217 - diff: 25.65mlTrain batch 5/16 - 258.5ms/batch - loss: 39.41274 - diff: 23.83mlTrain batch 6/16 - 259.3ms/batch - loss: 43.77212 - diff: 24.97mlTrain batch 7/16 - 259.4ms/batch - loss: 39.43482 - diff: 23.83mlTrain batch 8/16 - 258.7ms/batch - loss: 36.33813 - diff: 22.76mlTrain batch 9/16 - 260.3ms/batch - loss: 35.53093 - diff: 22.79mlTrain batch 10/16 - 258.8ms/batch - loss: 34.23514 - diff: 22.67mlTrain batch 11/16 - 260.9ms/batch - loss: 33.59276 - diff: 22.82mlTrain batch 12/16 - 259.5ms/batch - loss: 39.38370 - diff: 23.37mlTrain batch 13/16 - 259.3ms/batch - loss: 37.77428 - diff: 23.06mlTrain batch 14/16 - 259.4ms/batch - loss: 37.04409 - diff: 23.19mlTrain batch 15/16 - 257.7ms/batch - loss: 36.36013 - diff: 23.06mlTrain batch 16/16 - 172.7ms/batch - loss: 37.57456 - diff: 23.07mlTrain batch 16/16 - 10.5s 172.7ms/batch - loss: 37.57456 - diff: 23.07ml
Test 0.8s: val_loss: 30.56714 - diff: 20.98ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Systole_VGG19_Adam-0.001_MSE_DA3_best

Epoch 74: current best loss = 30.56714, at epoch 73
Train batch 1/16 - 262.3ms/batch - loss: 27.17699 - diff: 21.32mlTrain batch 2/16 - 259.8ms/batch - loss: 29.83903 - diff: 21.29mlTrain batch 3/16 - 263.8ms/batch - loss: 32.88688 - diff: 21.29mlTrain batch 4/16 - 258.7ms/batch - loss: 31.99716 - diff: 22.17mlTrain batch 5/16 - 262.6ms/batch - loss: 31.08923 - diff: 22.10mlTrain batch 6/16 - 258.3ms/batch - loss: 28.49394 - diff: 21.50mlTrain batch 7/16 - 263.8ms/batch - loss: 28.41822 - diff: 21.31mlTrain batch 8/16 - 259.9ms/batch - loss: 29.74939 - diff: 21.54mlTrain batch 9/16 - 265.2ms/batch - loss: 36.64923 - diff: 22.41mlTrain batch 10/16 - 258.0ms/batch - loss: 34.79529 - diff: 22.04mlTrain batch 11/16 - 261.2ms/batch - loss: 39.81450 - diff: 22.66mlTrain batch 12/16 - 258.3ms/batch - loss: 38.84665 - diff: 22.65mlTrain batch 13/16 - 261.2ms/batch - loss: 40.10041 - diff: 23.52mlTrain batch 14/16 - 259.3ms/batch - loss: 38.58759 - diff: 23.24mlTrain batch 15/16 - 258.3ms/batch - loss: 38.66524 - diff: 23.32mlTrain batch 16/16 - 173.8ms/batch - loss: 39.19182 - diff: 23.25mlTrain batch 16/16 - 10.5s 173.8ms/batch - loss: 39.19182 - diff: 23.25ml
Test 0.9s: val_loss: 47.06652 - diff: 25.23ml

Epoch 75: current best loss = 30.56714, at epoch 73
Train batch 1/16 - 262.7ms/batch - loss: 23.72848 - diff: 22.08mlTrain batch 2/16 - 260.2ms/batch - loss: 50.28388 - diff: 26.60mlTrain batch 3/16 - 259.8ms/batch - loss: 43.74493 - diff: 25.25mlTrain batch 4/16 - 259.0ms/batch - loss: 39.76134 - diff: 25.27mlTrain batch 5/16 - 259.4ms/batch - loss: 37.02353 - diff: 25.17mlTrain batch 6/16 - 258.1ms/batch - loss: 51.38233 - diff: 27.52mlTrain batch 7/16 - 258.7ms/batch - loss: 47.28989 - diff: 26.92mlTrain batch 8/16 - 258.1ms/batch - loss: 44.00546 - diff: 26.13mlTrain batch 9/16 - 259.0ms/batch - loss: 43.79241 - diff: 26.04mlTrain batch 10/16 - 259.4ms/batch - loss: 43.19232 - diff: 25.52mlTrain batch 11/16 - 261.1ms/batch - loss: 41.75783 - diff: 25.23mlTrain batch 12/16 - 259.6ms/batch - loss: 41.40572 - diff: 25.21mlTrain batch 13/16 - 259.0ms/batch - loss: 39.00297 - diff: 24.36mlTrain batch 14/16 - 258.7ms/batch - loss: 41.60528 - diff: 24.55mlTrain batch 15/16 - 258.3ms/batch - loss: 40.64237 - diff: 24.57mlTrain batch 16/16 - 173.5ms/batch - loss: 40.31644 - diff: 24.43mlTrain batch 16/16 - 10.5s 173.5ms/batch - loss: 40.31644 - diff: 24.43ml
Test 0.8s: val_loss: 29.42117 - diff: 20.96ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Systole_VGG19_Adam-0.001_MSE_DA3_best

Epoch 76: current best loss = 29.42117, at epoch 75
Train batch 1/16 - 258.6ms/batch - loss: 19.39694 - diff: 21.67mlTrain batch 2/16 - 260.9ms/batch - loss: 26.54589 - diff: 22.22mlTrain batch 3/16 - 259.3ms/batch - loss: 58.46504 - diff: 25.04mlTrain batch 4/16 - 258.3ms/batch - loss: 49.85165 - diff: 23.93mlTrain batch 5/16 - 259.8ms/batch - loss: 59.16302 - diff: 26.42mlTrain batch 6/16 - 258.9ms/batch - loss: 54.06533 - diff: 26.18mlTrain batch 7/16 - 258.8ms/batch - loss: 50.54912 - diff: 25.65mlTrain batch 8/16 - 259.3ms/batch - loss: 48.75947 - diff: 25.52mlTrain batch 9/16 - 264.9ms/batch - loss: 48.80761 - diff: 25.74mlTrain batch 10/16 - 259.2ms/batch - loss: 47.43864 - diff: 25.45mlTrain batch 11/16 - 264.2ms/batch - loss: 47.14714 - diff: 25.46mlTrain batch 12/16 - 258.5ms/batch - loss: 44.68068 - diff: 24.72mlTrain batch 13/16 - 261.3ms/batch - loss: 42.58150 - diff: 24.36mlTrain batch 14/16 - 260.0ms/batch - loss: 42.74660 - diff: 24.70mlTrain batch 15/16 - 258.9ms/batch - loss: 41.38696 - diff: 24.42mlTrain batch 16/16 - 173.4ms/batch - loss: 40.35529 - diff: 23.94mlTrain batch 16/16 - 10.4s 173.4ms/batch - loss: 40.35529 - diff: 23.94ml
Test 0.8s: val_loss: 36.72433 - diff: 20.83ml

Epoch 77: current best loss = 29.42117, at epoch 75
Train batch 1/16 - 263.8ms/batch - loss: 53.39062 - diff: 26.41mlTrain batch 2/16 - 258.0ms/batch - loss: 41.54522 - diff: 24.98mlTrain batch 3/16 - 259.9ms/batch - loss: 70.28375 - diff: 26.60mlTrain batch 4/16 - 259.4ms/batch - loss: 61.27443 - diff: 26.73mlTrain batch 5/16 - 260.0ms/batch - loss: 63.38760 - diff: 28.26mlTrain batch 6/16 - 259.3ms/batch - loss: 57.75232 - diff: 27.33mlTrain batch 7/16 - 260.5ms/batch - loss: 51.44442 - diff: 25.60mlTrain batch 8/16 - 259.1ms/batch - loss: 49.20079 - diff: 24.54mlTrain batch 9/16 - 259.8ms/batch - loss: 52.35382 - diff: 24.71mlTrain batch 10/16 - 261.7ms/batch - loss: 50.20748 - diff: 24.64mlTrain batch 11/16 - 259.1ms/batch - loss: 46.85827 - diff: 23.83mlTrain batch 12/16 - 260.3ms/batch - loss: 45.52187 - diff: 23.73mlTrain batch 13/16 - 262.0ms/batch - loss: 43.55299 - diff: 23.49mlTrain batch 14/16 - 260.3ms/batch - loss: 42.05172 - diff: 23.45mlTrain batch 15/16 - 257.7ms/batch - loss: 41.28695 - diff: 23.40mlTrain batch 16/16 - 172.2ms/batch - loss: 42.05346 - diff: 23.57mlTrain batch 16/16 - 10.5s 172.2ms/batch - loss: 42.05346 - diff: 23.57ml
Test 0.8s: val_loss: 35.34916 - diff: 24.74ml

Epoch 78: current best loss = 29.42117, at epoch 75
Train batch 1/16 - 260.5ms/batch - loss: 36.05051 - diff: 24.99mlTrain batch 2/16 - 260.1ms/batch - loss: 28.41812 - diff: 24.05mlTrain batch 3/16 - 262.6ms/batch - loss: 26.82051 - diff: 23.45mlTrain batch 4/16 - 263.7ms/batch - loss: 23.60734 - diff: 21.86mlTrain batch 5/16 - 261.6ms/batch - loss: 23.40183 - diff: 21.13mlTrain batch 6/16 - 258.0ms/batch - loss: 25.11060 - diff: 21.36mlTrain batch 7/16 - 261.3ms/batch - loss: 23.93141 - diff: 20.63mlTrain batch 8/16 - 258.7ms/batch - loss: 23.88399 - diff: 20.33mlTrain batch 9/16 - 260.5ms/batch - loss: 23.96868 - diff: 20.40mlTrain batch 10/16 - 258.5ms/batch - loss: 23.74658 - diff: 20.62mlTrain batch 11/16 - 260.8ms/batch - loss: 23.78935 - diff: 20.68mlTrain batch 12/16 - 258.3ms/batch - loss: 23.77783 - diff: 20.77mlTrain batch 13/16 - 260.2ms/batch - loss: 30.34950 - diff: 21.76mlTrain batch 14/16 - 258.7ms/batch - loss: 31.55048 - diff: 22.36mlTrain batch 15/16 - 258.1ms/batch - loss: 35.82482 - diff: 23.13mlTrain batch 16/16 - 173.3ms/batch - loss: 36.21740 - diff: 23.20mlTrain batch 16/16 - 10.4s 173.3ms/batch - loss: 36.21740 - diff: 23.20ml
Test 0.9s: val_loss: 26.34069 - diff: 20.03ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Systole_VGG19_Adam-0.001_MSE_DA3_best

Epoch 79: current best loss = 26.34069, at epoch 78
Train batch 1/16 - 265.0ms/batch - loss: 25.71749 - diff: 22.09mlTrain batch 2/16 - 258.6ms/batch - loss: 50.95148 - diff: 23.05mlTrain batch 3/16 - 269.4ms/batch - loss: 36.97743 - diff: 20.07mlTrain batch 4/16 - 259.3ms/batch - loss: 34.64454 - diff: 20.49mlTrain batch 5/16 - 263.4ms/batch - loss: 30.66891 - diff: 19.88mlTrain batch 6/16 - 260.5ms/batch - loss: 29.75355 - diff: 19.96mlTrain batch 7/16 - 262.3ms/batch - loss: 28.82972 - diff: 20.26mlTrain batch 8/16 - 263.9ms/batch - loss: 28.54170 - diff: 20.34mlTrain batch 9/16 - 262.4ms/batch - loss: 31.80010 - diff: 20.78mlTrain batch 10/16 - 258.6ms/batch - loss: 31.94738 - diff: 21.46mlTrain batch 11/16 - 270.4ms/batch - loss: 31.48946 - diff: 21.61mlTrain batch 12/16 - 259.6ms/batch - loss: 30.76001 - diff: 21.61mlTrain batch 13/16 - 260.5ms/batch - loss: 30.17913 - diff: 21.57mlTrain batch 14/16 - 258.4ms/batch - loss: 30.67387 - diff: 21.67mlTrain batch 15/16 - 258.3ms/batch - loss: 30.20018 - diff: 21.64mlTrain batch 16/16 - 172.2ms/batch - loss: 32.80568 - diff: 21.93mlTrain batch 16/16 - 10.5s 172.2ms/batch - loss: 32.80568 - diff: 21.93ml
Test 0.8s: val_loss: 36.93561 - diff: 26.41ml

Epoch 80: current best loss = 26.34069, at epoch 78
Train batch 1/16 - 259.0ms/batch - loss: 20.09029 - diff: 20.23mlTrain batch 2/16 - 259.3ms/batch - loss: 21.16343 - diff: 20.68mlTrain batch 3/16 - 258.3ms/batch - loss: 28.30342 - diff: 22.74mlTrain batch 4/16 - 260.1ms/batch - loss: 25.61192 - diff: 21.69mlTrain batch 5/16 - 259.5ms/batch - loss: 23.79163 - diff: 21.00mlTrain batch 6/16 - 259.7ms/batch - loss: 22.56271 - diff: 20.50mlTrain batch 7/16 - 262.3ms/batch - loss: 23.50205 - diff: 20.65mlTrain batch 8/16 - 258.9ms/batch - loss: 23.15264 - diff: 20.68mlTrain batch 9/16 - 261.3ms/batch - loss: 25.00266 - diff: 21.30mlTrain batch 10/16 - 258.6ms/batch - loss: 24.17238 - diff: 21.01mlTrain batch 11/16 - 263.1ms/batch - loss: 31.46195 - diff: 21.59mlTrain batch 12/16 - 258.7ms/batch - loss: 31.41951 - diff: 21.92mlTrain batch 13/16 - 262.8ms/batch - loss: 34.49886 - diff: 22.56mlTrain batch 14/16 - 258.3ms/batch - loss: 32.99395 - diff: 22.09mlTrain batch 15/16 - 258.3ms/batch - loss: 33.36464 - diff: 22.08mlTrain batch 16/16 - 173.4ms/batch - loss: 34.62136 - diff: 22.27mlTrain batch 16/16 - 10.4s 173.4ms/batch - loss: 34.62136 - diff: 22.27ml
Test 0.8s: val_loss: 35.62937 - diff: 19.32ml

Epoch 81: current best loss = 26.34069, at epoch 78
Train batch 1/16 - 260.3ms/batch - loss: 16.30099 - diff: 15.93mlTrain batch 2/16 - 258.6ms/batch - loss: 60.92167 - diff: 24.83mlTrain batch 3/16 - 259.4ms/batch - loss: 49.34134 - diff: 24.51mlTrain batch 4/16 - 258.3ms/batch - loss: 47.51616 - diff: 26.17mlTrain batch 5/16 - 258.8ms/batch - loss: 41.28257 - diff: 24.37mlTrain batch 6/16 - 261.0ms/batch - loss: 39.88850 - diff: 24.34mlTrain batch 7/16 - 258.1ms/batch - loss: 38.36748 - diff: 24.16mlTrain batch 8/16 - 258.3ms/batch - loss: 36.92471 - diff: 23.80mlTrain batch 9/16 - 258.9ms/batch - loss: 34.43443 - diff: 23.14mlTrain batch 10/16 - 262.0ms/batch - loss: 34.71068 - diff: 23.10mlTrain batch 11/16 - 260.2ms/batch - loss: 33.86151 - diff: 23.16mlTrain batch 12/16 - 258.7ms/batch - loss: 33.67852 - diff: 23.54mlTrain batch 13/16 - 260.5ms/batch - loss: 33.05182 - diff: 23.50mlTrain batch 14/16 - 259.6ms/batch - loss: 36.53373 - diff: 23.88mlTrain batch 15/16 - 258.5ms/batch - loss: 36.13692 - diff: 23.98mlTrain batch 16/16 - 173.4ms/batch - loss: 35.31999 - diff: 23.64mlTrain batch 16/16 - 10.5s 173.4ms/batch - loss: 35.31999 - diff: 23.64ml
Test 0.9s: val_loss: 27.34860 - diff: 19.98ml

Epoch 82: current best loss = 26.34069, at epoch 78
Train batch 1/16 - 260.1ms/batch - loss: 15.45153 - diff: 13.99mlTrain batch 2/16 - 258.2ms/batch - loss: 22.53038 - diff: 18.02mlTrain batch 3/16 - 260.0ms/batch - loss: 26.91178 - diff: 19.52mlTrain batch 4/16 - 259.9ms/batch - loss: 24.05789 - diff: 19.19mlTrain batch 5/16 - 258.7ms/batch - loss: 23.86985 - diff: 19.50mlTrain batch 6/16 - 260.4ms/batch - loss: 23.97335 - diff: 19.99mlTrain batch 7/16 - 259.0ms/batch - loss: 25.05081 - diff: 20.44mlTrain batch 8/16 - 260.2ms/batch - loss: 25.39224 - diff: 20.79mlTrain batch 9/16 - 259.0ms/batch - loss: 32.29155 - diff: 21.73mlTrain batch 10/16 - 258.9ms/batch - loss: 33.18067 - diff: 22.00mlTrain batch 11/16 - 258.9ms/batch - loss: 34.87043 - diff: 23.08mlTrain batch 12/16 - 259.5ms/batch - loss: 34.51595 - diff: 23.08mlTrain batch 13/16 - 259.3ms/batch - loss: 35.71781 - diff: 23.64mlTrain batch 14/16 - 258.6ms/batch - loss: 34.60685 - diff: 23.36mlTrain batch 15/16 - 258.7ms/batch - loss: 33.88688 - diff: 23.28mlTrain batch 16/16 - 173.2ms/batch - loss: 36.91580 - diff: 23.58mlTrain batch 16/16 - 10.5s 173.2ms/batch - loss: 36.91580 - diff: 23.58ml
Test 0.9s: val_loss: 44.04380 - diff: 24.72ml

Epoch 83: current best loss = 26.34069, at epoch 78
Train batch 1/16 - 262.8ms/batch - loss: 40.05107 - diff: 23.55mlTrain batch 2/16 - 260.8ms/batch - loss: 40.18825 - diff: 23.09mlTrain batch 3/16 - 263.6ms/batch - loss: 36.95125 - diff: 23.59mlTrain batch 4/16 - 264.0ms/batch - loss: 37.95812 - diff: 25.85mlTrain batch 5/16 - 262.5ms/batch - loss: 37.63354 - diff: 26.39mlTrain batch 6/16 - 261.7ms/batch - loss: 47.17109 - diff: 26.17mlTrain batch 7/16 - 258.6ms/batch - loss: 46.02665 - diff: 26.19mlTrain batch 8/16 - 259.7ms/batch - loss: 46.78149 - diff: 26.29mlTrain batch 9/16 - 260.0ms/batch - loss: 43.62004 - diff: 25.30mlTrain batch 10/16 - 261.1ms/batch - loss: 41.91603 - diff: 24.52mlTrain batch 11/16 - 260.8ms/batch - loss: 39.97757 - diff: 24.42mlTrain batch 12/16 - 259.3ms/batch - loss: 38.74441 - diff: 24.32mlTrain batch 13/16 - 261.4ms/batch - loss: 40.75656 - diff: 24.47mlTrain batch 14/16 - 258.9ms/batch - loss: 40.05326 - diff: 24.32mlTrain batch 15/16 - 258.4ms/batch - loss: 38.92014 - diff: 23.98mlTrain batch 16/16 - 173.8ms/batch - loss: 38.37736 - diff: 23.69mlTrain batch 16/16 - 10.5s 173.8ms/batch - loss: 38.37736 - diff: 23.69ml
Test 0.9s: val_loss: 26.66797 - diff: 19.28ml

Epoch 84: current best loss = 26.34069, at epoch 78
Train batch 1/16 - 262.7ms/batch - loss: 16.17873 - diff: 18.81mlTrain batch 2/16 - 259.8ms/batch - loss: 14.45172 - diff: 17.11mlTrain batch 3/16 - 263.7ms/batch - loss: 19.32072 - diff: 18.89mlTrain batch 4/16 - 260.7ms/batch - loss: 25.94857 - diff: 20.54mlTrain batch 5/16 - 263.2ms/batch - loss: 25.88892 - diff: 20.82mlTrain batch 6/16 - 258.7ms/batch - loss: 25.38378 - diff: 20.91mlTrain batch 7/16 - 263.0ms/batch - loss: 26.88267 - diff: 21.40mlTrain batch 8/16 - 260.5ms/batch - loss: 25.60500 - diff: 21.02mlTrain batch 9/16 - 261.9ms/batch - loss: 26.78031 - diff: 21.44mlTrain batch 10/16 - 258.8ms/batch - loss: 27.18691 - diff: 21.19mlTrain batch 11/16 - 263.3ms/batch - loss: 26.58775 - diff: 20.82mlTrain batch 12/16 - 262.0ms/batch - loss: 26.27803 - diff: 20.69mlTrain batch 13/16 - 261.0ms/batch - loss: 26.67688 - diff: 20.77mlTrain batch 14/16 - 258.7ms/batch - loss: 27.86795 - diff: 21.36mlTrain batch 15/16 - 258.5ms/batch - loss: 28.48951 - diff: 21.79mlTrain batch 16/16 - 172.9ms/batch - loss: 28.90465 - diff: 21.89mlTrain batch 16/16 - 10.5s 172.9ms/batch - loss: 28.90465 - diff: 21.89ml
Test 0.8s: val_loss: 25.51809 - diff: 18.44ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Systole_VGG19_Adam-0.001_MSE_DA3_best

Epoch 85: current best loss = 25.51809, at epoch 84
Train batch 1/16 - 261.0ms/batch - loss: 21.75972 - diff: 18.85mlTrain batch 2/16 - 259.8ms/batch - loss: 18.70110 - diff: 17.48mlTrain batch 3/16 - 260.9ms/batch - loss: 27.58986 - diff: 20.63mlTrain batch 4/16 - 260.0ms/batch - loss: 25.08067 - diff: 19.86mlTrain batch 5/16 - 259.2ms/batch - loss: 29.59152 - diff: 21.10mlTrain batch 6/16 - 260.5ms/batch - loss: 30.09281 - diff: 21.27mlTrain batch 7/16 - 258.4ms/batch - loss: 30.29476 - diff: 21.25mlTrain batch 8/16 - 258.7ms/batch - loss: 30.64914 - diff: 22.00mlTrain batch 9/16 - 258.7ms/batch - loss: 39.53813 - diff: 24.93mlTrain batch 10/16 - 259.6ms/batch - loss: 38.97720 - diff: 25.22mlTrain batch 11/16 - 257.7ms/batch - loss: 43.48832 - diff: 25.17mlTrain batch 12/16 - 263.5ms/batch - loss: 42.16744 - diff: 24.94mlTrain batch 13/16 - 261.7ms/batch - loss: 40.82355 - diff: 24.65mlTrain batch 14/16 - 260.4ms/batch - loss: 39.89435 - diff: 24.30mlTrain batch 15/16 - 258.2ms/batch - loss: 39.58474 - diff: 24.31mlTrain batch 16/16 - 172.6ms/batch - loss: 39.49879 - diff: 24.12mlTrain batch 16/16 - 10.5s 172.6ms/batch - loss: 39.49879 - diff: 24.12ml
Test 0.8s: val_loss: 27.45992 - diff: 19.02ml

Epoch 86: current best loss = 25.51809, at epoch 84
Train batch 1/16 - 260.7ms/batch - loss: 17.75460 - diff: 18.40mlTrain batch 2/16 - 259.3ms/batch - loss: 18.01031 - diff: 18.32mlTrain batch 3/16 - 263.7ms/batch - loss: 23.17825 - diff: 21.10mlTrain batch 4/16 - 258.3ms/batch - loss: 22.76813 - diff: 21.16mlTrain batch 5/16 - 258.5ms/batch - loss: 23.31372 - diff: 21.69mlTrain batch 6/16 - 258.7ms/batch - loss: 22.12827 - diff: 21.37mlTrain batch 7/16 - 258.2ms/batch - loss: 22.72269 - diff: 21.13mlTrain batch 8/16 - 259.2ms/batch - loss: 31.83726 - diff: 22.52mlTrain batch 9/16 - 259.4ms/batch - loss: 31.36889 - diff: 22.04mlTrain batch 10/16 - 259.8ms/batch - loss: 30.46229 - diff: 21.96mlTrain batch 11/16 - 260.9ms/batch - loss: 30.66051 - diff: 22.31mlTrain batch 12/16 - 259.1ms/batch - loss: 29.71838 - diff: 22.15mlTrain batch 13/16 - 259.2ms/batch - loss: 28.55151 - diff: 21.80mlTrain batch 14/16 - 259.0ms/batch - loss: 28.13904 - diff: 21.71mlTrain batch 15/16 - 260.6ms/batch - loss: 27.28231 - diff: 21.42mlTrain batch 16/16 - 172.3ms/batch - loss: 29.79376 - diff: 21.55mlTrain batch 16/16 - 10.5s 172.3ms/batch - loss: 29.79376 - diff: 21.55ml
Test 0.8s: val_loss: 28.88863 - diff: 19.85ml

Epoch 87: current best loss = 25.51809, at epoch 84
Train batch 1/16 - 262.1ms/batch - loss: 18.08445 - diff: 18.34mlTrain batch 2/16 - 263.5ms/batch - loss: 21.02247 - diff: 20.12mlTrain batch 3/16 - 264.1ms/batch - loss: 20.68003 - diff: 19.73mlTrain batch 4/16 - 264.1ms/batch - loss: 23.31063 - diff: 21.19mlTrain batch 5/16 - 261.9ms/batch - loss: 24.44210 - diff: 21.74mlTrain batch 6/16 - 263.8ms/batch - loss: 23.02462 - diff: 21.07mlTrain batch 7/16 - 259.7ms/batch - loss: 22.13366 - diff: 20.57mlTrain batch 8/16 - 261.5ms/batch - loss: 21.55396 - diff: 20.28mlTrain batch 9/16 - 268.9ms/batch - loss: 21.70686 - diff: 20.28mlTrain batch 10/16 - 258.7ms/batch - loss: 20.64545 - diff: 19.73mlTrain batch 11/16 - 263.1ms/batch - loss: 21.84021 - diff: 20.06mlTrain batch 12/16 - 257.6ms/batch - loss: 23.90371 - diff: 20.11mlTrain batch 13/16 - 259.3ms/batch - loss: 23.93141 - diff: 20.42mlTrain batch 14/16 - 259.0ms/batch - loss: 25.58216 - diff: 20.84mlTrain batch 15/16 - 258.5ms/batch - loss: 25.72732 - diff: 21.05mlTrain batch 16/16 - 173.0ms/batch - loss: 27.42983 - diff: 21.36mlTrain batch 16/16 - 10.4s 173.0ms/batch - loss: 27.42983 - diff: 21.36ml
Test 0.8s: val_loss: 24.52967 - diff: 18.57ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Systole_VGG19_Adam-0.001_MSE_DA3_best

Epoch 88: current best loss = 24.52967, at epoch 87
Train batch 1/16 - 265.1ms/batch - loss: 10.58600 - diff: 13.55mlTrain batch 2/16 - 259.3ms/batch - loss: 12.51283 - diff: 14.74mlTrain batch 3/16 - 261.6ms/batch - loss: 34.88214 - diff: 18.25mlTrain batch 4/16 - 259.4ms/batch - loss: 31.38683 - diff: 18.04mlTrain batch 5/16 - 258.7ms/batch - loss: 28.01769 - diff: 18.02mlTrain batch 6/16 - 258.8ms/batch - loss: 29.72072 - diff: 18.64mlTrain batch 7/16 - 258.2ms/batch - loss: 28.01991 - diff: 18.81mlTrain batch 8/16 - 259.5ms/batch - loss: 31.62404 - diff: 20.51mlTrain batch 9/16 - 258.6ms/batch - loss: 30.80000 - diff: 20.37mlTrain batch 10/16 - 258.7ms/batch - loss: 29.37653 - diff: 20.08mlTrain batch 11/16 - 259.9ms/batch - loss: 30.04057 - diff: 20.60mlTrain batch 12/16 - 265.5ms/batch - loss: 31.03170 - diff: 20.75mlTrain batch 13/16 - 260.5ms/batch - loss: 30.51580 - diff: 20.77mlTrain batch 14/16 - 261.3ms/batch - loss: 30.47802 - diff: 20.74mlTrain batch 15/16 - 258.3ms/batch - loss: 29.45865 - diff: 20.60mlTrain batch 16/16 - 174.2ms/batch - loss: 30.47045 - diff: 20.84mlTrain batch 16/16 - 10.5s 174.2ms/batch - loss: 30.47045 - diff: 20.84ml
Test 0.8s: val_loss: 41.15790 - diff: 28.79ml

Epoch 89: current best loss = 24.52967, at epoch 87
Train batch 1/16 - 262.7ms/batch - loss: 45.42155 - diff: 34.67mlTrain batch 2/16 - 258.0ms/batch - loss: 39.05328 - diff: 31.05mlTrain batch 3/16 - 262.2ms/batch - loss: 32.12821 - diff: 27.57mlTrain batch 4/16 - 261.9ms/batch - loss: 35.28847 - diff: 26.66mlTrain batch 5/16 - 261.2ms/batch - loss: 35.44071 - diff: 26.00mlTrain batch 6/16 - 259.1ms/batch - loss: 41.33826 - diff: 26.74mlTrain batch 7/16 - 260.9ms/batch - loss: 41.60107 - diff: 26.71mlTrain batch 8/16 - 258.9ms/batch - loss: 41.63786 - diff: 27.33mlTrain batch 9/16 - 260.2ms/batch - loss: 41.36812 - diff: 27.67mlTrain batch 10/16 - 258.2ms/batch - loss: 39.15437 - diff: 26.88mlTrain batch 11/16 - 262.7ms/batch - loss: 39.84819 - diff: 27.01mlTrain batch 12/16 - 260.4ms/batch - loss: 40.89403 - diff: 27.26mlTrain batch 13/16 - 262.9ms/batch - loss: 41.40535 - diff: 27.59mlTrain batch 14/16 - 259.2ms/batch - loss: 40.13021 - diff: 27.16mlTrain batch 15/16 - 258.9ms/batch - loss: 39.83029 - diff: 26.88mlTrain batch 16/16 - 173.1ms/batch - loss: 39.81505 - diff: 26.58mlTrain batch 16/16 - 10.5s 173.1ms/batch - loss: 39.81505 - diff: 26.58ml
Test 0.8s: val_loss: 25.43124 - diff: 19.67ml

Epoch 90: current best loss = 24.52967, at epoch 87
Train batch 1/16 - 259.2ms/batch - loss: 34.58508 - diff: 24.18mlTrain batch 2/16 - 258.8ms/batch - loss: 39.24313 - diff: 27.63mlTrain batch 3/16 - 259.4ms/batch - loss: 31.14378 - diff: 23.43mlTrain batch 4/16 - 258.2ms/batch - loss: 32.08605 - diff: 23.82mlTrain batch 5/16 - 258.8ms/batch - loss: 28.00519 - diff: 21.80mlTrain batch 6/16 - 258.6ms/batch - loss: 26.82435 - diff: 21.15mlTrain batch 7/16 - 258.9ms/batch - loss: 28.15401 - diff: 21.76mlTrain batch 8/16 - 259.9ms/batch - loss: 28.79451 - diff: 21.99mlTrain batch 9/16 - 261.1ms/batch - loss: 27.24473 - diff: 21.67mlTrain batch 10/16 - 258.1ms/batch - loss: 28.89331 - diff: 22.34mlTrain batch 11/16 - 259.5ms/batch - loss: 28.21182 - diff: 22.39mlTrain batch 12/16 - 258.6ms/batch - loss: 28.28805 - diff: 22.46mlTrain batch 13/16 - 258.8ms/batch - loss: 27.80219 - diff: 22.44mlTrain batch 14/16 - 259.0ms/batch - loss: 30.68973 - diff: 22.60mlTrain batch 15/16 - 260.4ms/batch - loss: 32.25865 - diff: 22.94mlTrain batch 16/16 - 173.2ms/batch - loss: 31.74818 - diff: 22.70mlTrain batch 16/16 - 10.5s 173.2ms/batch - loss: 31.74818 - diff: 22.70ml
Test 0.9s: val_loss: 36.23237 - diff: 24.27ml

Epoch 91: current best loss = 24.52967, at epoch 87
Train batch 1/16 - 264.9ms/batch - loss: 29.32554 - diff: 24.34mlTrain batch 2/16 - 259.8ms/batch - loss: 27.09885 - diff: 24.16mlTrain batch 3/16 - 262.2ms/batch - loss: 23.57381 - diff: 22.21mlTrain batch 4/16 - 260.1ms/batch - loss: 22.41573 - diff: 21.47mlTrain batch 5/16 - 263.3ms/batch - loss: 25.45059 - diff: 21.91mlTrain batch 6/16 - 261.4ms/batch - loss: 25.96214 - diff: 22.10mlTrain batch 7/16 - 263.2ms/batch - loss: 23.99466 - diff: 21.29mlTrain batch 8/16 - 259.6ms/batch - loss: 22.30137 - diff: 20.25mlTrain batch 9/16 - 264.6ms/batch - loss: 23.10736 - diff: 20.61mlTrain batch 10/16 - 258.8ms/batch - loss: 23.74538 - diff: 21.08mlTrain batch 11/16 - 263.3ms/batch - loss: 25.67989 - diff: 21.68mlTrain batch 12/16 - 259.3ms/batch - loss: 25.93158 - diff: 21.82mlTrain batch 13/16 - 258.0ms/batch - loss: 27.23046 - diff: 22.09mlTrain batch 14/16 - 259.5ms/batch - loss: 27.37703 - diff: 22.17mlTrain batch 15/16 - 258.1ms/batch - loss: 27.99046 - diff: 22.13mlTrain batch 16/16 - 172.4ms/batch - loss: 27.22864 - diff: 21.66mlTrain batch 16/16 - 10.5s 172.4ms/batch - loss: 27.22864 - diff: 21.66ml
Test 0.8s: val_loss: 23.78501 - diff: 19.30ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Systole_VGG19_Adam-0.001_MSE_DA3_best

Epoch 92: current best loss = 23.78501, at epoch 91
Train batch 1/16 - 258.8ms/batch - loss: 18.52613 - diff: 17.91mlTrain batch 2/16 - 260.4ms/batch - loss: 19.93649 - diff: 19.01mlTrain batch 3/16 - 257.9ms/batch - loss: 17.60790 - diff: 17.99mlTrain batch 4/16 - 260.3ms/batch - loss: 18.82253 - diff: 17.84mlTrain batch 5/16 - 259.2ms/batch - loss: 17.43605 - diff: 17.06mlTrain batch 6/16 - 260.8ms/batch - loss: 18.48862 - diff: 17.39mlTrain batch 7/16 - 258.6ms/batch - loss: 19.63511 - diff: 17.96mlTrain batch 8/16 - 261.5ms/batch - loss: 21.40615 - diff: 18.65mlTrain batch 9/16 - 258.9ms/batch - loss: 21.66288 - diff: 19.20mlTrain batch 10/16 - 258.3ms/batch - loss: 21.51084 - diff: 19.13mlTrain batch 11/16 - 259.1ms/batch - loss: 22.23101 - diff: 19.52mlTrain batch 12/16 - 259.6ms/batch - loss: 22.96239 - diff: 19.93mlTrain batch 13/16 - 258.8ms/batch - loss: 22.59696 - diff: 19.86mlTrain batch 14/16 - 261.2ms/batch - loss: 24.27644 - diff: 20.03mlTrain batch 15/16 - 258.9ms/batch - loss: 24.08250 - diff: 20.04mlTrain batch 16/16 - 172.6ms/batch - loss: 27.08153 - diff: 20.42mlTrain batch 16/16 - 10.5s 172.6ms/batch - loss: 27.08153 - diff: 20.42ml
Test 0.9s: val_loss: 25.79676 - diff: 20.97ml

Epoch 93: current best loss = 23.78501, at epoch 91
Train batch 1/16 - 260.4ms/batch - loss: 37.20419 - diff: 28.61mlTrain batch 2/16 - 259.0ms/batch - loss: 28.08733 - diff: 24.61mlTrain batch 3/16 - 263.7ms/batch - loss: 26.56404 - diff: 22.85mlTrain batch 4/16 - 260.0ms/batch - loss: 22.81045 - diff: 20.90mlTrain batch 5/16 - 262.8ms/batch - loss: 24.97678 - diff: 20.81mlTrain batch 6/16 - 258.1ms/batch - loss: 23.91177 - diff: 20.17mlTrain batch 7/16 - 263.1ms/batch - loss: 24.70141 - diff: 20.52mlTrain batch 8/16 - 258.6ms/batch - loss: 23.72697 - diff: 20.29mlTrain batch 9/16 - 265.5ms/batch - loss: 22.82245 - diff: 19.57mlTrain batch 10/16 - 258.0ms/batch - loss: 22.02357 - diff: 19.35mlTrain batch 11/16 - 258.7ms/batch - loss: 20.99378 - diff: 18.97mlTrain batch 12/16 - 259.7ms/batch - loss: 23.52225 - diff: 19.58mlTrain batch 13/16 - 260.8ms/batch - loss: 24.14365 - diff: 19.85mlTrain batch 14/16 - 258.7ms/batch - loss: 24.18623 - diff: 20.07mlTrain batch 15/16 - 258.3ms/batch - loss: 28.01337 - diff: 20.78mlTrain batch 16/16 - 173.3ms/batch - loss: 28.03000 - diff: 20.71mlTrain batch 16/16 - 10.5s 173.3ms/batch - loss: 28.03000 - diff: 20.71ml
Test 0.8s: val_loss: 42.35490 - diff: 22.91ml

Epoch 94: current best loss = 23.78501, at epoch 91
Train batch 1/16 - 261.2ms/batch - loss: 18.52481 - diff: 18.18mlTrain batch 2/16 - 259.8ms/batch - loss: 26.39482 - diff: 22.17mlTrain batch 3/16 - 260.6ms/batch - loss: 36.38824 - diff: 24.77mlTrain batch 4/16 - 258.8ms/batch - loss: 46.00149 - diff: 27.57mlTrain batch 5/16 - 259.0ms/batch - loss: 39.26982 - diff: 24.91mlTrain batch 6/16 - 258.9ms/batch - loss: 37.19791 - diff: 24.66mlTrain batch 7/16 - 258.3ms/batch - loss: 35.96422 - diff: 24.84mlTrain batch 8/16 - 258.1ms/batch - loss: 35.32953 - diff: 24.99mlTrain batch 9/16 - 264.7ms/batch - loss: 47.39268 - diff: 26.88mlTrain batch 10/16 - 261.9ms/batch - loss: 45.84075 - diff: 26.81mlTrain batch 11/16 - 262.2ms/batch - loss: 45.10321 - diff: 26.87mlTrain batch 12/16 - 262.3ms/batch - loss: 44.20982 - diff: 26.84mlTrain batch 13/16 - 273.3ms/batch - loss: 42.62983 - diff: 26.34mlTrain batch 14/16 - 258.5ms/batch - loss: 40.97275 - diff: 25.76mlTrain batch 15/16 - 259.7ms/batch - loss: 41.48875 - diff: 25.77mlTrain batch 16/16 - 172.4ms/batch - loss: 46.51996 - diff: 25.86mlTrain batch 16/16 - 10.5s 172.4ms/batch - loss: 46.51996 - diff: 25.86ml
Test 0.8s: val_loss: 31.19814 - diff: 21.68ml

Epoch 95: current best loss = 23.78501, at epoch 91
Train batch 1/16 - 263.1ms/batch - loss: 23.25140 - diff: 20.60mlTrain batch 2/16 - 259.9ms/batch - loss: 25.68758 - diff: 22.19mlTrain batch 3/16 - 260.3ms/batch - loss: 29.18511 - diff: 23.98mlTrain batch 4/16 - 259.6ms/batch - loss: 28.62361 - diff: 24.37mlTrain batch 5/16 - 261.0ms/batch - loss: 25.52938 - diff: 22.67mlTrain batch 6/16 - 261.0ms/batch - loss: 25.15532 - diff: 22.10mlTrain batch 7/16 - 259.3ms/batch - loss: 24.75032 - diff: 21.73mlTrain batch 8/16 - 259.5ms/batch - loss: 24.03921 - diff: 21.24mlTrain batch 9/16 - 258.6ms/batch - loss: 29.24598 - diff: 22.92mlTrain batch 10/16 - 262.8ms/batch - loss: 43.24467 - diff: 25.01mlTrain batch 11/16 - 261.3ms/batch - loss: 42.98462 - diff: 25.55mlTrain batch 12/16 - 259.5ms/batch - loss: 49.32497 - diff: 27.96mlTrain batch 13/16 - 267.0ms/batch - loss: 47.64273 - diff: 27.69mlTrain batch 14/16 - 261.4ms/batch - loss: 46.13639 - diff: 27.33mlTrain batch 15/16 - 258.4ms/batch - loss: 46.42763 - diff: 27.34mlTrain batch 16/16 - 172.5ms/batch - loss: 48.36372 - diff: 27.61mlTrain batch 16/16 - 10.5s 172.5ms/batch - loss: 48.36372 - diff: 27.61ml
Test 0.8s: val_loss: 64.10664 - diff: 32.84ml

Epoch 96: current best loss = 23.78501, at epoch 91
Train batch 1/16 - 260.7ms/batch - loss: 36.57268 - diff: 25.14mlTrain batch 2/16 - 258.2ms/batch - loss: 37.08576 - diff: 26.51mlTrain batch 3/16 - 258.7ms/batch - loss: 40.62221 - diff: 27.08mlTrain batch 4/16 - 258.6ms/batch - loss: 37.42157 - diff: 26.15mlTrain batch 5/16 - 258.7ms/batch - loss: 36.34604 - diff: 26.16mlTrain batch 6/16 - 258.6ms/batch - loss: 37.23789 - diff: 26.96mlTrain batch 7/16 - 260.5ms/batch - loss: 36.47916 - diff: 27.19mlTrain batch 8/16 - 258.9ms/batch - loss: 37.99572 - diff: 27.55mlTrain batch 9/16 - 258.7ms/batch - loss: 37.57541 - diff: 26.94mlTrain batch 10/16 - 261.0ms/batch - loss: 36.49711 - diff: 26.47mlTrain batch 11/16 - 260.2ms/batch - loss: 35.07097 - diff: 25.51mlTrain batch 12/16 - 258.6ms/batch - loss: 35.39544 - diff: 25.09mlTrain batch 13/16 - 261.6ms/batch - loss: 33.98532 - diff: 24.35mlTrain batch 14/16 - 259.1ms/batch - loss: 35.52454 - diff: 24.32mlTrain batch 15/16 - 258.3ms/batch - loss: 34.52032 - diff: 24.10mlTrain batch 16/16 - 174.1ms/batch - loss: 35.54506 - diff: 24.29mlTrain batch 16/16 - 10.5s 174.1ms/batch - loss: 35.54506 - diff: 24.29ml
Test 0.8s: val_loss: 47.27398 - diff: 29.92ml

Epoch 97: current best loss = 23.78501, at epoch 91
Train batch 1/16 - 263.5ms/batch - loss: 22.37508 - diff: 21.31mlTrain batch 2/16 - 258.7ms/batch - loss: 28.87044 - diff: 20.25mlTrain batch 3/16 - 260.6ms/batch - loss: 27.52777 - diff: 20.36mlTrain batch 4/16 - 259.3ms/batch - loss: 22.99551 - diff: 18.79mlTrain batch 5/16 - 264.0ms/batch - loss: 22.13282 - diff: 18.97mlTrain batch 6/16 - 258.8ms/batch - loss: 22.92389 - diff: 19.60mlTrain batch 7/16 - 260.7ms/batch - loss: 24.96718 - diff: 19.74mlTrain batch 8/16 - 258.9ms/batch - loss: 25.42251 - diff: 20.01mlTrain batch 9/16 - 264.3ms/batch - loss: 26.43016 - diff: 20.51mlTrain batch 10/16 - 259.5ms/batch - loss: 26.38587 - diff: 20.45mlTrain batch 11/16 - 261.7ms/batch - loss: 25.62071 - diff: 20.18mlTrain batch 12/16 - 262.0ms/batch - loss: 27.63646 - diff: 20.74mlTrain batch 13/16 - 261.3ms/batch - loss: 28.22724 - diff: 21.06mlTrain batch 14/16 - 260.6ms/batch - loss: 27.69735 - diff: 20.92mlTrain batch 15/16 - 258.1ms/batch - loss: 27.34036 - diff: 20.94mlTrain batch 16/16 - 174.3ms/batch - loss: 27.52775 - diff: 20.95mlTrain batch 16/16 - 10.5s 174.3ms/batch - loss: 27.52775 - diff: 20.95ml
Test 0.8s: val_loss: 62.06686 - diff: 33.65ml

Epoch 98: current best loss = 23.78501, at epoch 91
Train batch 1/16 - 259.9ms/batch - loss: 37.08838 - diff: 28.29mlTrain batch 2/16 - 259.5ms/batch - loss: 27.73557 - diff: 23.51mlTrain batch 3/16 - 257.7ms/batch - loss: 26.46178 - diff: 21.71mlTrain batch 4/16 - 258.8ms/batch - loss: 39.72246 - diff: 21.90mlTrain batch 5/16 - 259.5ms/batch - loss: 37.03545 - diff: 20.92mlTrain batch 6/16 - 258.8ms/batch - loss: 32.92355 - diff: 19.96mlTrain batch 7/16 - 258.7ms/batch - loss: 36.53948 - diff: 20.86mlTrain batch 8/16 - 257.9ms/batch - loss: 35.52336 - diff: 21.06mlTrain batch 9/16 - 258.1ms/batch - loss: 33.62395 - diff: 21.04mlTrain batch 10/16 - 259.7ms/batch - loss: 33.55442 - diff: 21.69mlTrain batch 11/16 - 258.0ms/batch - loss: 32.39069 - diff: 21.57mlTrain batch 12/16 - 259.4ms/batch - loss: 30.97315 - diff: 21.32mlTrain batch 13/16 - 260.5ms/batch - loss: 29.66198 - diff: 20.89mlTrain batch 14/16 - 259.6ms/batch - loss: 28.33265 - diff: 20.39mlTrain batch 15/16 - 258.9ms/batch - loss: 27.89366 - diff: 20.31mlTrain batch 16/16 - 173.2ms/batch - loss: 30.62529 - diff: 20.73mlTrain batch 16/16 - 10.5s 173.2ms/batch - loss: 30.62529 - diff: 20.73ml
Test 0.8s: val_loss: 26.05258 - diff: 17.80ml

Epoch 99: current best loss = 23.78501, at epoch 91
Train batch 1/16 - 264.7ms/batch - loss: 14.31002 - diff: 16.58mlTrain batch 2/16 - 259.4ms/batch - loss: 15.31070 - diff: 16.29mlTrain batch 3/16 - 258.2ms/batch - loss: 19.56447 - diff: 18.74mlTrain batch 4/16 - 260.1ms/batch - loss: 26.60646 - diff: 20.20mlTrain batch 5/16 - 261.5ms/batch - loss: 32.03182 - diff: 23.34mlTrain batch 6/16 - 259.5ms/batch - loss: 30.55735 - diff: 23.14mlTrain batch 7/16 - 262.9ms/batch - loss: 28.26038 - diff: 22.46mlTrain batch 8/16 - 259.7ms/batch - loss: 27.36403 - diff: 22.20mlTrain batch 9/16 - 258.5ms/batch - loss: 28.01101 - diff: 22.39mlTrain batch 10/16 - 258.2ms/batch - loss: 26.87618 - diff: 21.78mlTrain batch 11/16 - 261.5ms/batch - loss: 27.70650 - diff: 22.07mlTrain batch 12/16 - 259.6ms/batch - loss: 27.52884 - diff: 21.94mlTrain batch 13/16 - 258.7ms/batch - loss: 29.06683 - diff: 22.13mlTrain batch 14/16 - 258.3ms/batch - loss: 28.63963 - diff: 22.10mlTrain batch 15/16 - 258.7ms/batch - loss: 29.78278 - diff: 22.52mlTrain batch 16/16 - 173.0ms/batch - loss: 30.86842 - diff: 22.64mlTrain batch 16/16 - 10.5s 173.0ms/batch - loss: 30.86842 - diff: 22.64ml
Test 0.9s: val_loss: 21.00040 - diff: 17.93ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Systole_VGG19_Adam-0.001_MSE_DA3_best

Epoch 100: current best loss = 21.00040, at epoch 99
Train batch 1/16 - 264.8ms/batch - loss: 20.29142 - diff: 18.26mlTrain batch 2/16 - 259.4ms/batch - loss: 22.23209 - diff: 19.83mlTrain batch 3/16 - 265.1ms/batch - loss: 22.12585 - diff: 19.80mlTrain batch 4/16 - 259.6ms/batch - loss: 25.98043 - diff: 21.18mlTrain batch 5/16 - 260.5ms/batch - loss: 32.57645 - diff: 22.05mlTrain batch 6/16 - 258.1ms/batch - loss: 31.31060 - diff: 21.41mlTrain batch 7/16 - 261.8ms/batch - loss: 31.70390 - diff: 21.82mlTrain batch 8/16 - 259.3ms/batch - loss: 30.95832 - diff: 22.19mlTrain batch 9/16 - 261.3ms/batch - loss: 31.80126 - diff: 23.13mlTrain batch 10/16 - 258.4ms/batch - loss: 31.72370 - diff: 23.54mlTrain batch 11/16 - 258.2ms/batch - loss: 34.87634 - diff: 24.12mlTrain batch 12/16 - 259.5ms/batch - loss: 34.29627 - diff: 23.91mlTrain batch 13/16 - 261.6ms/batch - loss: 37.58441 - diff: 23.88mlTrain batch 14/16 - 259.0ms/batch - loss: 36.33506 - diff: 23.51mlTrain batch 15/16 - 258.6ms/batch - loss: 35.38429 - diff: 23.19mlTrain batch 16/16 - 172.9ms/batch - loss: 34.96783 - diff: 22.90mlTrain batch 16/16 - 10.4s 172.9ms/batch - loss: 34.96783 - diff: 22.90ml
Test 0.8s: val_loss: 29.05163 - diff: 21.53ml

Epoch 101: current best loss = 21.00040, at epoch 99
Train batch 1/16 - 262.1ms/batch - loss: 19.19379 - diff: 18.50mlTrain batch 2/16 - 258.7ms/batch - loss: 24.78186 - diff: 21.49mlTrain batch 3/16 - 263.7ms/batch - loss: 23.47409 - diff: 21.69mlTrain batch 4/16 - 260.8ms/batch - loss: 21.95421 - diff: 21.27mlTrain batch 5/16 - 261.4ms/batch - loss: 19.92018 - diff: 20.21mlTrain batch 6/16 - 261.2ms/batch - loss: 19.09113 - diff: 19.19mlTrain batch 7/16 - 262.2ms/batch - loss: 19.59628 - diff: 19.41mlTrain batch 8/16 - 261.2ms/batch - loss: 24.06827 - diff: 20.39mlTrain batch 9/16 - 260.3ms/batch - loss: 24.23665 - diff: 20.61mlTrain batch 10/16 - 258.9ms/batch - loss: 23.76417 - diff: 20.54mlTrain batch 11/16 - 265.5ms/batch - loss: 23.72287 - diff: 20.30mlTrain batch 12/16 - 258.4ms/batch - loss: 24.77685 - diff: 20.73mlTrain batch 13/16 - 261.3ms/batch - loss: 23.90643 - diff: 20.39mlTrain batch 14/16 - 260.8ms/batch - loss: 26.36313 - diff: 20.86mlTrain batch 15/16 - 258.2ms/batch - loss: 27.57748 - diff: 20.91mlTrain batch 16/16 - 172.8ms/batch - loss: 27.62495 - diff: 20.74mlTrain batch 16/16 - 10.4s 172.8ms/batch - loss: 27.62495 - diff: 20.74ml
Test 0.8s: val_loss: 25.02440 - diff: 18.47ml

Epoch 102: current best loss = 21.00040, at epoch 99
Train batch 1/16 - 258.3ms/batch - loss: 19.36597 - diff: 19.67mlTrain batch 2/16 - 259.2ms/batch - loss: 20.59158 - diff: 20.37mlTrain batch 3/16 - 263.1ms/batch - loss: 22.44905 - diff: 20.38mlTrain batch 4/16 - 258.9ms/batch - loss: 23.14407 - diff: 21.04mlTrain batch 5/16 - 260.6ms/batch - loss: 29.65609 - diff: 22.07mlTrain batch 6/16 - 259.3ms/batch - loss: 27.50067 - diff: 21.14mlTrain batch 7/16 - 259.5ms/batch - loss: 25.88615 - diff: 20.74mlTrain batch 8/16 - 258.6ms/batch - loss: 24.58366 - diff: 20.07mlTrain batch 9/16 - 258.7ms/batch - loss: 25.11180 - diff: 20.31mlTrain batch 10/16 - 258.5ms/batch - loss: 24.36531 - diff: 20.22mlTrain batch 11/16 - 263.4ms/batch - loss: 24.03393 - diff: 19.89mlTrain batch 12/16 - 265.6ms/batch - loss: 23.33778 - diff: 19.48mlTrain batch 13/16 - 260.3ms/batch - loss: 24.40126 - diff: 19.67mlTrain batch 14/16 - 258.7ms/batch - loss: 23.95918 - diff: 19.49mlTrain batch 15/16 - 258.9ms/batch - loss: 23.94169 - diff: 19.57mlTrain batch 16/16 - 172.8ms/batch - loss: 24.13084 - diff: 19.52mlTrain batch 16/16 - 10.5s 172.8ms/batch - loss: 24.13084 - diff: 19.52ml
Test 0.8s: val_loss: 24.43679 - diff: 18.16ml

Epoch 103: current best loss = 21.00040, at epoch 99
Train batch 1/16 - 259.5ms/batch - loss: 21.93729 - diff: 18.59mlTrain batch 2/16 - 260.2ms/batch - loss: 23.12075 - diff: 19.34mlTrain batch 3/16 - 259.0ms/batch - loss: 21.92171 - diff: 19.14mlTrain batch 4/16 - 258.9ms/batch - loss: 23.81723 - diff: 20.71mlTrain batch 5/16 - 259.3ms/batch - loss: 22.47540 - diff: 20.29mlTrain batch 6/16 - 259.4ms/batch - loss: 21.91670 - diff: 20.09mlTrain batch 7/16 - 276.1ms/batch - loss: 22.05270 - diff: 20.05mlTrain batch 8/16 - 258.7ms/batch - loss: 21.57100 - diff: 19.54mlTrain batch 9/16 - 263.9ms/batch - loss: 20.04709 - diff: 18.72mlTrain batch 10/16 - 259.3ms/batch - loss: 21.93674 - diff: 19.29mlTrain batch 11/16 - 258.6ms/batch - loss: 25.77056 - diff: 20.06mlTrain batch 12/16 - 261.6ms/batch - loss: 24.66378 - diff: 19.66mlTrain batch 13/16 - 260.5ms/batch - loss: 27.31017 - diff: 20.68mlTrain batch 14/16 - 258.7ms/batch - loss: 27.92916 - diff: 21.00mlTrain batch 15/16 - 261.1ms/batch - loss: 28.06518 - diff: 21.07mlTrain batch 16/16 - 172.1ms/batch - loss: 28.48942 - diff: 21.00mlTrain batch 16/16 - 10.5s 172.1ms/batch - loss: 28.48942 - diff: 21.00ml
Test 0.8s: val_loss: 38.24063 - diff: 22.28ml

Epoch 104: current best loss = 21.00040, at epoch 99
Train batch 1/16 - 257.7ms/batch - loss: 16.85931 - diff: 18.08mlTrain batch 2/16 - 258.4ms/batch - loss: 26.04750 - diff: 21.09mlTrain batch 3/16 - 271.5ms/batch - loss: 28.21336 - diff: 21.58mlTrain batch 4/16 - 259.0ms/batch - loss: 23.69130 - diff: 19.62mlTrain batch 5/16 - 261.9ms/batch - loss: 21.83122 - diff: 18.23mlTrain batch 6/16 - 260.3ms/batch - loss: 24.04797 - diff: 19.24mlTrain batch 7/16 - 274.8ms/batch - loss: 30.08178 - diff: 20.41mlTrain batch 8/16 - 259.1ms/batch - loss: 29.53737 - diff: 20.88mlTrain batch 9/16 - 276.0ms/batch - loss: 30.28020 - diff: 21.73mlTrain batch 10/16 - 259.3ms/batch - loss: 30.26674 - diff: 22.02mlTrain batch 11/16 - 259.1ms/batch - loss: 29.49760 - diff: 22.06mlTrain batch 12/16 - 259.0ms/batch - loss: 29.91978 - diff: 22.08mlTrain batch 13/16 - 258.5ms/batch - loss: 29.38686 - diff: 21.79mlTrain batch 14/16 - 259.0ms/batch - loss: 28.55016 - diff: 21.61mlTrain batch 15/16 - 259.2ms/batch - loss: 27.73526 - diff: 21.40mlTrain batch 16/16 - 172.6ms/batch - loss: 28.85947 - diff: 21.31mlTrain batch 16/16 - 10.5s 172.6ms/batch - loss: 28.85947 - diff: 21.31ml
Test 0.8s: val_loss: 21.43455 - diff: 18.07ml

Epoch 105: current best loss = 21.00040, at epoch 99
Train batch 1/16 - 263.9ms/batch - loss: 13.15912 - diff: 16.30mlTrain batch 2/16 - 258.1ms/batch - loss: 27.70357 - diff: 20.27mlTrain batch 3/16 - 260.5ms/batch - loss: 25.70578 - diff: 19.70mlTrain batch 4/16 - 260.0ms/batch - loss: 25.65158 - diff: 19.94mlTrain batch 5/16 - 258.1ms/batch - loss: 22.46448 - diff: 18.55mlTrain batch 6/16 - 258.9ms/batch - loss: 22.45651 - diff: 18.59mlTrain batch 7/16 - 260.7ms/batch - loss: 24.81512 - diff: 19.19mlTrain batch 8/16 - 260.5ms/batch - loss: 25.08771 - diff: 19.27mlTrain batch 9/16 - 264.1ms/batch - loss: 24.32022 - diff: 19.38mlTrain batch 10/16 - 258.5ms/batch - loss: 24.93027 - diff: 19.61mlTrain batch 11/16 - 257.6ms/batch - loss: 25.96736 - diff: 20.05mlTrain batch 12/16 - 258.6ms/batch - loss: 24.99316 - diff: 19.65mlTrain batch 13/16 - 258.5ms/batch - loss: 24.93227 - diff: 19.78mlTrain batch 14/16 - 260.4ms/batch - loss: 25.32111 - diff: 19.95mlTrain batch 15/16 - 259.0ms/batch - loss: 25.18806 - diff: 20.19mlTrain batch 16/16 - 174.3ms/batch - loss: 26.18886 - diff: 20.31mlTrain batch 16/16 - 10.4s 174.3ms/batch - loss: 26.18886 - diff: 20.31ml
Test 0.8s: val_loss: 25.15944 - diff: 20.62ml

Epoch 106: current best loss = 21.00040, at epoch 99
Train batch 1/16 - 259.2ms/batch - loss: 19.31861 - diff: 18.79mlTrain batch 2/16 - 263.6ms/batch - loss: 21.62274 - diff: 19.85mlTrain batch 3/16 - 258.8ms/batch - loss: 26.27186 - diff: 20.14mlTrain batch 4/16 - 261.4ms/batch - loss: 24.37944 - diff: 20.04mlTrain batch 5/16 - 259.8ms/batch - loss: 28.62155 - diff: 20.62mlTrain batch 6/16 - 262.5ms/batch - loss: 28.90451 - diff: 21.31mlTrain batch 7/16 - 259.4ms/batch - loss: 29.08272 - diff: 21.45mlTrain batch 8/16 - 259.7ms/batch - loss: 28.71819 - diff: 21.67mlTrain batch 9/16 - 259.2ms/batch - loss: 28.09044 - diff: 21.78mlTrain batch 10/16 - 262.0ms/batch - loss: 27.31449 - diff: 21.61mlTrain batch 11/16 - 258.6ms/batch - loss: 27.81685 - diff: 21.69mlTrain batch 12/16 - 261.4ms/batch - loss: 27.74677 - diff: 21.52mlTrain batch 13/16 - 261.3ms/batch - loss: 27.16684 - diff: 21.23mlTrain batch 14/16 - 260.4ms/batch - loss: 27.51070 - diff: 21.38mlTrain batch 15/16 - 259.2ms/batch - loss: 27.81647 - diff: 21.27mlTrain batch 16/16 - 172.4ms/batch - loss: 28.44072 - diff: 21.25mlTrain batch 16/16 - 10.5s 172.4ms/batch - loss: 28.44072 - diff: 21.25ml
Test 0.9s: val_loss: 22.50547 - diff: 17.99ml

Epoch 107: current best loss = 21.00040, at epoch 99
Train batch 1/16 - 264.4ms/batch - loss: 11.19731 - diff: 15.23mlTrain batch 2/16 - 259.7ms/batch - loss: 15.76019 - diff: 16.23mlTrain batch 3/16 - 263.6ms/batch - loss: 17.16265 - diff: 16.93mlTrain batch 4/16 - 260.1ms/batch - loss: 16.88985 - diff: 17.37mlTrain batch 5/16 - 265.1ms/batch - loss: 16.54094 - diff: 17.58mlTrain batch 6/16 - 260.6ms/batch - loss: 16.48148 - diff: 17.66mlTrain batch 7/16 - 259.7ms/batch - loss: 17.61105 - diff: 18.09mlTrain batch 8/16 - 258.7ms/batch - loss: 17.32590 - diff: 18.15mlTrain batch 9/16 - 260.9ms/batch - loss: 18.28093 - diff: 18.46mlTrain batch 10/16 - 259.1ms/batch - loss: 18.23859 - diff: 18.31mlTrain batch 11/16 - 258.5ms/batch - loss: 18.06753 - diff: 18.37mlTrain batch 12/16 - 259.5ms/batch - loss: 19.46378 - diff: 18.65mlTrain batch 13/16 - 260.9ms/batch - loss: 20.51905 - diff: 19.06mlTrain batch 14/16 - 258.3ms/batch - loss: 21.15753 - diff: 19.56mlTrain batch 15/16 - 258.8ms/batch - loss: 22.79103 - diff: 20.30mlTrain batch 16/16 - 173.9ms/batch - loss: 22.85329 - diff: 20.09mlTrain batch 16/16 - 10.5s 173.9ms/batch - loss: 22.85329 - diff: 20.09ml
Test 0.8s: val_loss: 33.36329 - diff: 21.91ml

Epoch 108: current best loss = 21.00040, at epoch 99
Train batch 1/16 - 264.0ms/batch - loss: 84.59191 - diff: 31.50mlTrain batch 2/16 - 258.2ms/batch - loss: 51.24452 - diff: 23.52mlTrain batch 3/16 - 263.3ms/batch - loss: 42.44532 - diff: 23.41mlTrain batch 4/16 - 258.2ms/batch - loss: 37.14764 - diff: 22.75mlTrain batch 5/16 - 262.9ms/batch - loss: 33.92541 - diff: 21.66mlTrain batch 6/16 - 258.9ms/batch - loss: 31.45708 - diff: 21.54mlTrain batch 7/16 - 261.7ms/batch - loss: 33.21404 - diff: 22.52mlTrain batch 8/16 - 260.9ms/batch - loss: 32.61256 - diff: 22.28mlTrain batch 9/16 - 261.7ms/batch - loss: 31.75295 - diff: 22.08mlTrain batch 10/16 - 260.5ms/batch - loss: 29.91355 - diff: 21.45mlTrain batch 11/16 - 260.8ms/batch - loss: 30.06111 - diff: 21.18mlTrain batch 12/16 - 260.3ms/batch - loss: 30.66475 - diff: 21.51mlTrain batch 13/16 - 263.3ms/batch - loss: 30.43786 - diff: 21.52mlTrain batch 14/16 - 267.2ms/batch - loss: 29.94017 - diff: 21.41mlTrain batch 15/16 - 258.5ms/batch - loss: 30.13812 - diff: 21.40mlTrain batch 16/16 - 173.0ms/batch - loss: 29.83680 - diff: 21.29mlTrain batch 16/16 - 10.5s 173.0ms/batch - loss: 29.83680 - diff: 21.29ml
Test 0.8s: val_loss: 34.44101 - diff: 26.35ml

Epoch 109: current best loss = 21.00040, at epoch 99
Train batch 1/16 - 261.6ms/batch - loss: 36.93386 - diff: 28.07mlTrain batch 2/16 - 261.3ms/batch - loss: 45.06240 - diff: 28.30mlTrain batch 3/16 - 259.0ms/batch - loss: 43.37356 - diff: 28.02mlTrain batch 4/16 - 259.6ms/batch - loss: 39.98826 - diff: 27.44mlTrain batch 5/16 - 258.0ms/batch - loss: 34.95849 - diff: 25.88mlTrain batch 6/16 - 258.7ms/batch - loss: 31.91176 - diff: 24.52mlTrain batch 7/16 - 260.1ms/batch - loss: 31.77361 - diff: 23.97mlTrain batch 8/16 - 261.0ms/batch - loss: 32.76066 - diff: 24.37mlTrain batch 9/16 - 258.9ms/batch - loss: 31.78192 - diff: 23.66mlTrain batch 10/16 - 259.4ms/batch - loss: 30.92566 - diff: 23.24mlTrain batch 11/16 - 258.8ms/batch - loss: 29.01834 - diff: 22.40mlTrain batch 12/16 - 259.2ms/batch - loss: 28.10258 - diff: 22.08mlTrain batch 13/16 - 258.6ms/batch - loss: 27.64586 - diff: 22.07mlTrain batch 14/16 - 263.0ms/batch - loss: 28.19728 - diff: 22.15mlTrain batch 15/16 - 258.3ms/batch - loss: 27.99754 - diff: 22.03mlTrain batch 16/16 - 171.8ms/batch - loss: 27.59907 - diff: 21.77mlTrain batch 16/16 - 10.5s 171.8ms/batch - loss: 27.59907 - diff: 21.77ml
Test 0.8s: val_loss: 24.14497 - diff: 18.40ml

Epoch 110: current best loss = 21.00040, at epoch 99
Train batch 1/16 - 261.5ms/batch - loss: 16.44905 - diff: 16.18mlTrain batch 2/16 - 258.7ms/batch - loss: 18.33361 - diff: 15.68mlTrain batch 3/16 - 261.1ms/batch - loss: 19.86619 - diff: 17.47mlTrain batch 4/16 - 260.5ms/batch - loss: 18.18669 - diff: 16.87mlTrain batch 5/16 - 259.5ms/batch - loss: 23.20149 - diff: 18.70mlTrain batch 6/16 - 258.0ms/batch - loss: 22.52008 - diff: 18.17mlTrain batch 7/16 - 259.4ms/batch - loss: 21.35141 - diff: 17.95mlTrain batch 8/16 - 258.3ms/batch - loss: 21.19241 - diff: 17.94mlTrain batch 9/16 - 261.0ms/batch - loss: 21.03074 - diff: 18.16mlTrain batch 10/16 - 260.2ms/batch - loss: 20.31945 - diff: 18.07mlTrain batch 11/16 - 262.3ms/batch - loss: 19.72544 - diff: 18.04mlTrain batch 12/16 - 259.2ms/batch - loss: 19.15088 - diff: 17.79mlTrain batch 13/16 - 258.5ms/batch - loss: 20.40025 - diff: 18.17mlTrain batch 14/16 - 261.7ms/batch - loss: 21.49424 - diff: 18.49mlTrain batch 15/16 - 258.8ms/batch - loss: 20.49455 - diff: 17.99mlTrain batch 16/16 - 172.0ms/batch - loss: 24.96552 - diff: 18.54mlTrain batch 16/16 - 10.6s 172.0ms/batch - loss: 24.96552 - diff: 18.54ml
Test 0.8s: val_loss: 57.17292 - diff: 33.61ml
Epoch   111: reducing learning rate of group 0 to 1.2500e-04.

Epoch 111: current best loss = 21.00040, at epoch 99
Train batch 1/16 - 260.6ms/batch - loss: 46.05159 - diff: 33.04mlTrain batch 2/16 - 260.0ms/batch - loss: 54.94427 - diff: 32.93mlTrain batch 3/16 - 277.3ms/batch - loss: 48.23723 - diff: 31.79mlTrain batch 4/16 - 260.8ms/batch - loss: 46.08796 - diff: 30.11mlTrain batch 5/16 - 259.6ms/batch - loss: 39.41620 - diff: 27.02mlTrain batch 6/16 - 258.0ms/batch - loss: 38.62551 - diff: 26.18mlTrain batch 7/16 - 261.4ms/batch - loss: 35.82552 - diff: 25.20mlTrain batch 8/16 - 259.3ms/batch - loss: 33.83005 - diff: 24.65mlTrain batch 9/16 - 281.8ms/batch - loss: 37.97772 - diff: 25.79mlTrain batch 10/16 - 258.3ms/batch - loss: 37.51748 - diff: 25.77mlTrain batch 11/16 - 266.9ms/batch - loss: 35.59133 - diff: 25.00mlTrain batch 12/16 - 258.5ms/batch - loss: 34.13379 - diff: 24.36mlTrain batch 13/16 - 258.8ms/batch - loss: 34.28287 - diff: 24.19mlTrain batch 14/16 - 259.1ms/batch - loss: 34.06876 - diff: 23.95mlTrain batch 15/16 - 257.6ms/batch - loss: 32.92825 - diff: 23.59mlTrain batch 16/16 - 172.6ms/batch - loss: 34.37200 - diff: 23.87mlTrain batch 16/16 - 10.4s 172.6ms/batch - loss: 34.37200 - diff: 23.87ml
Test 0.8s: val_loss: 34.74787 - diff: 25.91ml

Epoch 112: current best loss = 21.00040, at epoch 99
Train batch 1/16 - 261.6ms/batch - loss: 19.49956 - diff: 19.72mlTrain batch 2/16 - 259.8ms/batch - loss: 25.31049 - diff: 21.29mlTrain batch 3/16 - 258.0ms/batch - loss: 28.10667 - diff: 23.12mlTrain batch 4/16 - 261.5ms/batch - loss: 24.55263 - diff: 21.90mlTrain batch 5/16 - 263.7ms/batch - loss: 25.29746 - diff: 21.73mlTrain batch 6/16 - 260.4ms/batch - loss: 25.99672 - diff: 22.01mlTrain batch 7/16 - 264.2ms/batch - loss: 23.37939 - diff: 20.69mlTrain batch 8/16 - 260.4ms/batch - loss: 24.99483 - diff: 21.20mlTrain batch 9/16 - 261.2ms/batch - loss: 23.21668 - diff: 20.42mlTrain batch 10/16 - 259.6ms/batch - loss: 22.46413 - diff: 20.00mlTrain batch 11/16 - 261.1ms/batch - loss: 22.35168 - diff: 19.88mlTrain batch 12/16 - 258.0ms/batch - loss: 21.99662 - diff: 19.72mlTrain batch 13/16 - 258.1ms/batch - loss: 20.99160 - diff: 19.25mlTrain batch 14/16 - 258.3ms/batch - loss: 21.41950 - diff: 19.46mlTrain batch 15/16 - 258.7ms/batch - loss: 21.23219 - diff: 19.27mlTrain batch 16/16 - 172.5ms/batch - loss: 22.44458 - diff: 19.50mlTrain batch 16/16 - 10.5s 172.5ms/batch - loss: 22.44458 - diff: 19.50ml
Test 0.8s: val_loss: 23.50097 - diff: 18.13ml

Epoch 113: current best loss = 21.00040, at epoch 99
Train batch 1/16 - 259.8ms/batch - loss: 18.46111 - diff: 17.06mlTrain batch 2/16 - 258.3ms/batch - loss: 30.86707 - diff: 21.25mlTrain batch 3/16 - 262.5ms/batch - loss: 34.28040 - diff: 21.97mlTrain batch 4/16 - 258.5ms/batch - loss: 29.18552 - diff: 20.85mlTrain batch 5/16 - 263.4ms/batch - loss: 25.65666 - diff: 19.88mlTrain batch 6/16 - 258.5ms/batch - loss: 25.01114 - diff: 19.83mlTrain batch 7/16 - 261.5ms/batch - loss: 25.52469 - diff: 19.87mlTrain batch 8/16 - 258.7ms/batch - loss: 26.16260 - diff: 20.48mlTrain batch 9/16 - 261.0ms/batch - loss: 24.39448 - diff: 19.75mlTrain batch 10/16 - 259.7ms/batch - loss: 23.00767 - diff: 19.18mlTrain batch 11/16 - 260.6ms/batch - loss: 22.38974 - diff: 19.01mlTrain batch 12/16 - 260.4ms/batch - loss: 23.75654 - diff: 19.50mlTrain batch 13/16 - 261.2ms/batch - loss: 23.78518 - diff: 19.49mlTrain batch 14/16 - 258.0ms/batch - loss: 23.79061 - diff: 19.53mlTrain batch 15/16 - 258.7ms/batch - loss: 23.83301 - diff: 19.49mlTrain batch 16/16 - 173.0ms/batch - loss: 24.79006 - diff: 19.68mlTrain batch 16/16 - 10.5s 173.0ms/batch - loss: 24.79006 - diff: 19.68ml
Test 0.8s: val_loss: 21.80696 - diff: 18.05ml

Epoch 114: current best loss = 21.00040, at epoch 99
Train batch 1/16 - 263.0ms/batch - loss: 12.97403 - diff: 16.87mlTrain batch 2/16 - 259.7ms/batch - loss: 13.64190 - diff: 16.76mlTrain batch 3/16 - 258.3ms/batch - loss: 12.77478 - diff: 16.19mlTrain batch 4/16 - 259.2ms/batch - loss: 15.96523 - diff: 17.53mlTrain batch 5/16 - 260.2ms/batch - loss: 15.71424 - diff: 17.81mlTrain batch 6/16 - 260.1ms/batch - loss: 15.20886 - diff: 17.77mlTrain batch 7/16 - 262.8ms/batch - loss: 18.11510 - diff: 18.99mlTrain batch 8/16 - 259.4ms/batch - loss: 17.84112 - diff: 19.06mlTrain batch 9/16 - 262.8ms/batch - loss: 19.21133 - diff: 19.61mlTrain batch 10/16 - 260.0ms/batch - loss: 20.56847 - diff: 19.77mlTrain batch 11/16 - 261.8ms/batch - loss: 20.40146 - diff: 19.78mlTrain batch 12/16 - 261.4ms/batch - loss: 20.35457 - diff: 19.76mlTrain batch 13/16 - 260.0ms/batch - loss: 21.15651 - diff: 20.05mlTrain batch 14/16 - 259.8ms/batch - loss: 21.82299 - diff: 19.88mlTrain batch 15/16 - 258.4ms/batch - loss: 22.70132 - diff: 19.87mlTrain batch 16/16 - 172.2ms/batch - loss: 23.72220 - diff: 19.93mlTrain batch 16/16 - 10.5s 172.2ms/batch - loss: 23.72220 - diff: 19.93ml
Test 0.8s: val_loss: 20.51282 - diff: 18.10ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Systole_VGG19_Adam-0.001_MSE_DA3_best

Epoch 115: current best loss = 20.51282, at epoch 114
Train batch 1/16 - 264.9ms/batch - loss: 11.07108 - diff: 14.73mlTrain batch 2/16 - 258.8ms/batch - loss: 16.03935 - diff: 17.33mlTrain batch 3/16 - 264.8ms/batch - loss: 22.18824 - diff: 20.26mlTrain batch 4/16 - 258.7ms/batch - loss: 22.05704 - diff: 20.51mlTrain batch 5/16 - 261.2ms/batch - loss: 21.57048 - diff: 20.53mlTrain batch 6/16 - 259.7ms/batch - loss: 22.92274 - diff: 21.19mlTrain batch 7/16 - 260.7ms/batch - loss: 23.33029 - diff: 21.47mlTrain batch 8/16 - 259.7ms/batch - loss: 23.02611 - diff: 21.57mlTrain batch 9/16 - 260.7ms/batch - loss: 23.14561 - diff: 21.04mlTrain batch 10/16 - 259.0ms/batch - loss: 23.60133 - diff: 20.94mlTrain batch 11/16 - 263.1ms/batch - loss: 24.48344 - diff: 20.96mlTrain batch 12/16 - 260.9ms/batch - loss: 23.60531 - diff: 20.54mlTrain batch 13/16 - 263.4ms/batch - loss: 23.98101 - diff: 20.60mlTrain batch 14/16 - 258.9ms/batch - loss: 22.95341 - diff: 20.14mlTrain batch 15/16 - 258.7ms/batch - loss: 22.33386 - diff: 19.85mlTrain batch 16/16 - 172.7ms/batch - loss: 23.16298 - diff: 19.87mlTrain batch 16/16 - 10.5s 172.7ms/batch - loss: 23.16298 - diff: 19.87ml
Test 0.8s: val_loss: 24.85609 - diff: 19.24ml

Epoch 116: current best loss = 20.51282, at epoch 114
Train batch 1/16 - 259.4ms/batch - loss: 39.92091 - diff: 23.34mlTrain batch 2/16 - 259.8ms/batch - loss: 48.60524 - diff: 23.29mlTrain batch 3/16 - 259.5ms/batch - loss: 41.33239 - diff: 22.18mlTrain batch 4/16 - 258.0ms/batch - loss: 36.26507 - diff: 21.10mlTrain batch 5/16 - 261.2ms/batch - loss: 32.94589 - diff: 20.08mlTrain batch 6/16 - 263.1ms/batch - loss: 29.44149 - diff: 19.28mlTrain batch 7/16 - 259.1ms/batch - loss: 28.41517 - diff: 18.93mlTrain batch 8/16 - 260.4ms/batch - loss: 27.00746 - diff: 18.50mlTrain batch 9/16 - 258.5ms/batch - loss: 26.51823 - diff: 18.76mlTrain batch 10/16 - 259.8ms/batch - loss: 29.86417 - diff: 19.53mlTrain batch 11/16 - 259.2ms/batch - loss: 28.53386 - diff: 19.23mlTrain batch 12/16 - 259.4ms/batch - loss: 27.38401 - diff: 19.06mlTrain batch 13/16 - 258.6ms/batch - loss: 26.30123 - diff: 18.94mlTrain batch 14/16 - 258.4ms/batch - loss: 27.37945 - diff: 19.79mlTrain batch 15/16 - 257.8ms/batch - loss: 27.46765 - diff: 20.14mlTrain batch 16/16 - 172.0ms/batch - loss: 27.56229 - diff: 20.12mlTrain batch 16/16 - 10.5s 172.0ms/batch - loss: 27.56229 - diff: 20.12ml
Test 0.8s: val_loss: 27.70234 - diff: 21.44ml

Epoch 117: current best loss = 20.51282, at epoch 114
Train batch 1/16 - 261.7ms/batch - loss: 12.65079 - diff: 17.09mlTrain batch 2/16 - 259.6ms/batch - loss: 21.81264 - diff: 18.86mlTrain batch 3/16 - 262.4ms/batch - loss: 24.12182 - diff: 19.79mlTrain batch 4/16 - 261.1ms/batch - loss: 24.44504 - diff: 20.35mlTrain batch 5/16 - 265.0ms/batch - loss: 24.57766 - diff: 20.33mlTrain batch 6/16 - 260.1ms/batch - loss: 23.29619 - diff: 19.87mlTrain batch 7/16 - 261.9ms/batch - loss: 24.26528 - diff: 20.00mlTrain batch 8/16 - 259.2ms/batch - loss: 23.08919 - diff: 19.58mlTrain batch 9/16 - 260.6ms/batch - loss: 22.08004 - diff: 18.97mlTrain batch 10/16 - 261.1ms/batch - loss: 22.16562 - diff: 19.11mlTrain batch 11/16 - 261.8ms/batch - loss: 21.79466 - diff: 19.24mlTrain batch 12/16 - 259.0ms/batch - loss: 23.26936 - diff: 19.76mlTrain batch 13/16 - 259.5ms/batch - loss: 23.86463 - diff: 20.23mlTrain batch 14/16 - 260.3ms/batch - loss: 23.56670 - diff: 20.22mlTrain batch 15/16 - 261.4ms/batch - loss: 23.18927 - diff: 20.04mlTrain batch 16/16 - 172.0ms/batch - loss: 24.24967 - diff: 20.09mlTrain batch 16/16 - 10.5s 172.0ms/batch - loss: 24.24967 - diff: 20.09ml
Test 0.8s: val_loss: 24.96057 - diff: 17.62ml

Epoch 118: current best loss = 20.51282, at epoch 114
Train batch 1/16 - 259.0ms/batch - loss: 13.99997 - diff: 17.00mlTrain batch 2/16 - 259.7ms/batch - loss: 14.42065 - diff: 17.06mlTrain batch 3/16 - 258.6ms/batch - loss: 14.16255 - diff: 16.93mlTrain batch 4/16 - 258.6ms/batch - loss: 16.39923 - diff: 17.36mlTrain batch 5/16 - 259.3ms/batch - loss: 16.44263 - diff: 17.37mlTrain batch 6/16 - 261.1ms/batch - loss: 16.38392 - diff: 17.46mlTrain batch 7/16 - 258.6ms/batch - loss: 16.56211 - diff: 17.64mlTrain batch 8/16 - 259.5ms/batch - loss: 15.99248 - diff: 17.23mlTrain batch 9/16 - 259.9ms/batch - loss: 18.08327 - diff: 18.12mlTrain batch 10/16 - 258.5ms/batch - loss: 18.67819 - diff: 18.43mlTrain batch 11/16 - 260.5ms/batch - loss: 18.46166 - diff: 18.22mlTrain batch 12/16 - 258.5ms/batch - loss: 20.23438 - diff: 18.31mlTrain batch 13/16 - 259.2ms/batch - loss: 20.96616 - diff: 18.55mlTrain batch 14/16 - 259.4ms/batch - loss: 21.34277 - diff: 18.95mlTrain batch 15/16 - 261.7ms/batch - loss: 21.80446 - diff: 19.10mlTrain batch 16/16 - 172.7ms/batch - loss: 21.70727 - diff: 18.98mlTrain batch 16/16 - 10.5s 172.7ms/batch - loss: 21.70727 - diff: 18.98ml
Test 0.8s: val_loss: 22.52463 - diff: 17.42ml

Epoch 119: current best loss = 20.51282, at epoch 114
Train batch 1/16 - 260.7ms/batch - loss: 16.65793 - diff: 14.55mlTrain batch 2/16 - 258.8ms/batch - loss: 13.19463 - diff: 14.26mlTrain batch 3/16 - 260.6ms/batch - loss: 29.82443 - diff: 16.63mlTrain batch 4/16 - 257.9ms/batch - loss: 30.81786 - diff: 18.05mlTrain batch 5/16 - 259.7ms/batch - loss: 27.49342 - diff: 17.83mlTrain batch 6/16 - 258.7ms/batch - loss: 25.34416 - diff: 17.63mlTrain batch 7/16 - 257.8ms/batch - loss: 23.51581 - diff: 17.49mlTrain batch 8/16 - 258.8ms/batch - loss: 22.99726 - diff: 17.65mlTrain batch 9/16 - 258.6ms/batch - loss: 23.80211 - diff: 18.28mlTrain batch 10/16 - 258.9ms/batch - loss: 23.34377 - diff: 18.36mlTrain batch 11/16 - 260.0ms/batch - loss: 22.45210 - diff: 18.06mlTrain batch 12/16 - 258.8ms/batch - loss: 21.68269 - diff: 17.91mlTrain batch 13/16 - 260.1ms/batch - loss: 21.98900 - diff: 18.27mlTrain batch 14/16 - 262.4ms/batch - loss: 21.50989 - diff: 18.15mlTrain batch 15/16 - 259.1ms/batch - loss: 22.14618 - diff: 18.50mlTrain batch 16/16 - 173.8ms/batch - loss: 22.21988 - diff: 18.52mlTrain batch 16/16 - 10.5s 173.8ms/batch - loss: 22.21988 - diff: 18.52ml
Test 0.8s: val_loss: 20.88054 - diff: 17.94ml

Epoch 120: current best loss = 20.51282, at epoch 114
Train batch 1/16 - 259.8ms/batch - loss: 13.03799 - diff: 16.62mlTrain batch 2/16 - 259.0ms/batch - loss: 15.04397 - diff: 17.30mlTrain batch 3/16 - 260.4ms/batch - loss: 14.82083 - diff: 17.47mlTrain batch 4/16 - 259.5ms/batch - loss: 15.03095 - diff: 17.86mlTrain batch 5/16 - 260.0ms/batch - loss: 16.72129 - diff: 18.35mlTrain batch 6/16 - 258.2ms/batch - loss: 17.36556 - diff: 18.37mlTrain batch 7/16 - 261.0ms/batch - loss: 18.80070 - diff: 18.94mlTrain batch 8/16 - 259.8ms/batch - loss: 18.46657 - diff: 18.73mlTrain batch 9/16 - 260.5ms/batch - loss: 18.75312 - diff: 18.48mlTrain batch 10/16 - 261.7ms/batch - loss: 18.39402 - diff: 18.34mlTrain batch 11/16 - 262.0ms/batch - loss: 18.59460 - diff: 18.44mlTrain batch 12/16 - 260.9ms/batch - loss: 19.18731 - diff: 18.69mlTrain batch 13/16 - 258.8ms/batch - loss: 19.14663 - diff: 18.68mlTrain batch 14/16 - 260.9ms/batch - loss: 19.06431 - diff: 18.68mlTrain batch 15/16 - 257.5ms/batch - loss: 20.12002 - diff: 19.13mlTrain batch 16/16 - 175.2ms/batch - loss: 21.76447 - diff: 19.32mlTrain batch 16/16 - 10.5s 175.2ms/batch - loss: 21.76447 - diff: 19.32ml
Test 0.8s: val_loss: 27.46684 - diff: 20.09ml

Epoch 121: current best loss = 20.51282, at epoch 114
Train batch 1/16 - 259.9ms/batch - loss: 18.20306 - diff: 19.70mlTrain batch 2/16 - 258.8ms/batch - loss: 19.36015 - diff: 19.56mlTrain batch 3/16 - 259.9ms/batch - loss: 21.22652 - diff: 20.50mlTrain batch 4/16 - 259.9ms/batch - loss: 22.27554 - diff: 20.65mlTrain batch 5/16 - 258.6ms/batch - loss: 20.71436 - diff: 19.97mlTrain batch 6/16 - 259.7ms/batch - loss: 21.34465 - diff: 19.89mlTrain batch 7/16 - 260.2ms/batch - loss: 20.01679 - diff: 19.35mlTrain batch 8/16 - 260.6ms/batch - loss: 22.36655 - diff: 20.00mlTrain batch 9/16 - 261.5ms/batch - loss: 21.51969 - diff: 19.56mlTrain batch 10/16 - 258.8ms/batch - loss: 20.79659 - diff: 19.17mlTrain batch 11/16 - 259.0ms/batch - loss: 20.05619 - diff: 18.73mlTrain batch 12/16 - 259.3ms/batch - loss: 19.99475 - diff: 18.67mlTrain batch 13/16 - 259.7ms/batch - loss: 19.96039 - diff: 18.66mlTrain batch 14/16 - 259.1ms/batch - loss: 20.08404 - diff: 18.80mlTrain batch 15/16 - 257.8ms/batch - loss: 20.07845 - diff: 18.93mlTrain batch 16/16 - 174.5ms/batch - loss: 21.45109 - diff: 19.15mlTrain batch 16/16 - 10.5s 174.5ms/batch - loss: 21.45109 - diff: 19.15ml
Test 0.9s: val_loss: 19.28885 - diff: 17.68ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Systole_VGG19_Adam-0.001_MSE_DA3_best

Epoch 122: current best loss = 19.28885, at epoch 121
Train batch 1/16 - 263.7ms/batch - loss: 19.16696 - diff: 18.93mlTrain batch 2/16 - 260.0ms/batch - loss: 17.49827 - diff: 18.15mlTrain batch 3/16 - 261.5ms/batch - loss: 17.60729 - diff: 17.65mlTrain batch 4/16 - 259.8ms/batch - loss: 18.71869 - diff: 17.87mlTrain batch 5/16 - 263.7ms/batch - loss: 18.74021 - diff: 17.26mlTrain batch 6/16 - 258.9ms/batch - loss: 18.74508 - diff: 17.30mlTrain batch 7/16 - 262.6ms/batch - loss: 18.70664 - diff: 17.13mlTrain batch 8/16 - 260.2ms/batch - loss: 17.52167 - diff: 16.72mlTrain batch 9/16 - 263.9ms/batch - loss: 17.88259 - diff: 17.07mlTrain batch 10/16 - 261.1ms/batch - loss: 18.13165 - diff: 17.36mlTrain batch 11/16 - 261.9ms/batch - loss: 18.01549 - diff: 17.47mlTrain batch 12/16 - 258.3ms/batch - loss: 18.27467 - diff: 17.66mlTrain batch 13/16 - 260.4ms/batch - loss: 18.36487 - diff: 17.85mlTrain batch 14/16 - 260.2ms/batch - loss: 18.53089 - diff: 18.01mlTrain batch 15/16 - 260.0ms/batch - loss: 18.59945 - diff: 18.10mlTrain batch 16/16 - 172.9ms/batch - loss: 19.03417 - diff: 18.19mlTrain batch 16/16 - 10.4s 172.9ms/batch - loss: 19.03417 - diff: 18.19ml
Test 0.8s: val_loss: 24.53386 - diff: 19.52ml

Epoch 123: current best loss = 19.28885, at epoch 121
Train batch 1/16 - 260.6ms/batch - loss: 16.70861 - diff: 17.53mlTrain batch 2/16 - 258.8ms/batch - loss: 14.70205 - diff: 16.68mlTrain batch 3/16 - 259.5ms/batch - loss: 16.59891 - diff: 16.74mlTrain batch 4/16 - 259.2ms/batch - loss: 14.99906 - diff: 16.36mlTrain batch 5/16 - 259.2ms/batch - loss: 17.78457 - diff: 17.44mlTrain batch 6/16 - 260.1ms/batch - loss: 18.40136 - diff: 17.30mlTrain batch 7/16 - 260.5ms/batch - loss: 21.99367 - diff: 18.57mlTrain batch 8/16 - 259.5ms/batch - loss: 21.75355 - diff: 18.75mlTrain batch 9/16 - 259.4ms/batch - loss: 20.58883 - diff: 18.22mlTrain batch 10/16 - 259.3ms/batch - loss: 19.74115 - diff: 17.99mlTrain batch 11/16 - 260.1ms/batch - loss: 20.18709 - diff: 18.09mlTrain batch 12/16 - 258.8ms/batch - loss: 20.06388 - diff: 17.93mlTrain batch 13/16 - 261.8ms/batch - loss: 21.10983 - diff: 18.58mlTrain batch 14/16 - 260.6ms/batch - loss: 20.53898 - diff: 18.39mlTrain batch 15/16 - 260.0ms/batch - loss: 20.62146 - diff: 18.43mlTrain batch 16/16 - 176.3ms/batch - loss: 21.93432 - diff: 18.62mlTrain batch 16/16 - 10.5s 176.3ms/batch - loss: 21.93432 - diff: 18.62ml
Test 0.8s: val_loss: 19.08938 - diff: 17.40ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Systole_VGG19_Adam-0.001_MSE_DA3_best

Epoch 124: current best loss = 19.08938, at epoch 123
Train batch 1/16 - 265.4ms/batch - loss: 22.44898 - diff: 20.73mlTrain batch 2/16 - 260.0ms/batch - loss: 15.27821 - diff: 16.91mlTrain batch 3/16 - 265.0ms/batch - loss: 18.05816 - diff: 18.91mlTrain batch 4/16 - 259.9ms/batch - loss: 18.07855 - diff: 18.64mlTrain batch 5/16 - 263.3ms/batch - loss: 18.52901 - diff: 19.06mlTrain batch 6/16 - 260.4ms/batch - loss: 18.88498 - diff: 19.47mlTrain batch 7/16 - 261.3ms/batch - loss: 18.13884 - diff: 19.00mlTrain batch 8/16 - 260.6ms/batch - loss: 18.31199 - diff: 18.88mlTrain batch 9/16 - 264.1ms/batch - loss: 17.21034 - diff: 18.31mlTrain batch 10/16 - 260.6ms/batch - loss: 18.01390 - diff: 18.33mlTrain batch 11/16 - 260.9ms/batch - loss: 20.21051 - diff: 18.83mlTrain batch 12/16 - 265.2ms/batch - loss: 21.02867 - diff: 19.13mlTrain batch 13/16 - 260.8ms/batch - loss: 20.67047 - diff: 19.15mlTrain batch 14/16 - 263.6ms/batch - loss: 19.97748 - diff: 18.80mlTrain batch 15/16 - 263.1ms/batch - loss: 21.25164 - diff: 19.27mlTrain batch 16/16 - 171.9ms/batch - loss: 21.01991 - diff: 19.03mlTrain batch 16/16 - 10.5s 171.9ms/batch - loss: 21.01991 - diff: 19.03ml
Test 0.8s: val_loss: 22.10962 - diff: 17.86ml

Epoch 125: current best loss = 19.08938, at epoch 123
Train batch 1/16 - 262.4ms/batch - loss: 38.29642 - diff: 24.31mlTrain batch 2/16 - 259.6ms/batch - loss: 34.75962 - diff: 21.55mlTrain batch 3/16 - 263.0ms/batch - loss: 29.33025 - diff: 20.61mlTrain batch 4/16 - 260.8ms/batch - loss: 26.50552 - diff: 19.40mlTrain batch 5/16 - 264.0ms/batch - loss: 25.06468 - diff: 19.53mlTrain batch 6/16 - 258.8ms/batch - loss: 24.05428 - diff: 19.34mlTrain batch 7/16 - 262.2ms/batch - loss: 24.83544 - diff: 19.77mlTrain batch 8/16 - 259.8ms/batch - loss: 26.13130 - diff: 20.35mlTrain batch 9/16 - 263.4ms/batch - loss: 25.08548 - diff: 20.20mlTrain batch 10/16 - 259.8ms/batch - loss: 24.65926 - diff: 20.31mlTrain batch 11/16 - 264.0ms/batch - loss: 23.77929 - diff: 20.03mlTrain batch 12/16 - 259.1ms/batch - loss: 22.90705 - diff: 19.60mlTrain batch 13/16 - 264.9ms/batch - loss: 22.29364 - diff: 19.30mlTrain batch 14/16 - 258.3ms/batch - loss: 21.79641 - diff: 19.04mlTrain batch 15/16 - 262.7ms/batch - loss: 21.90707 - diff: 19.19mlTrain batch 16/16 - 172.2ms/batch - loss: 21.46619 - diff: 18.94mlTrain batch 16/16 - 10.5s 172.2ms/batch - loss: 21.46619 - diff: 18.94ml
Test 0.8s: val_loss: 20.39312 - diff: 17.23ml

Epoch 126: current best loss = 19.08938, at epoch 123
Train batch 1/16 - 260.5ms/batch - loss: 21.41684 - diff: 18.42mlTrain batch 2/16 - 262.5ms/batch - loss: 18.33159 - diff: 18.64mlTrain batch 3/16 - 260.2ms/batch - loss: 17.87200 - diff: 18.58mlTrain batch 4/16 - 261.2ms/batch - loss: 17.07689 - diff: 18.04mlTrain batch 5/16 - 259.3ms/batch - loss: 16.55908 - diff: 17.70mlTrain batch 6/16 - 259.2ms/batch - loss: 24.24029 - diff: 18.23mlTrain batch 7/16 - 259.6ms/batch - loss: 22.86635 - diff: 18.07mlTrain batch 8/16 - 259.1ms/batch - loss: 22.22535 - diff: 17.98mlTrain batch 9/16 - 262.2ms/batch - loss: 21.78417 - diff: 17.93mlTrain batch 10/16 - 260.5ms/batch - loss: 20.80745 - diff: 17.69mlTrain batch 11/16 - 258.1ms/batch - loss: 21.08691 - diff: 18.07mlTrain batch 12/16 - 258.5ms/batch - loss: 20.56397 - diff: 18.15mlTrain batch 13/16 - 260.5ms/batch - loss: 22.00710 - diff: 18.86mlTrain batch 14/16 - 259.4ms/batch - loss: 22.17892 - diff: 19.05mlTrain batch 15/16 - 257.9ms/batch - loss: 21.56755 - diff: 18.72mlTrain batch 16/16 - 174.4ms/batch - loss: 22.25564 - diff: 18.79mlTrain batch 16/16 - 10.4s 174.4ms/batch - loss: 22.25564 - diff: 18.79ml
Test 0.8s: val_loss: 31.11625 - diff: 18.79ml

Epoch 127: current best loss = 19.08938, at epoch 123
Train batch 1/16 - 260.9ms/batch - loss: 29.41489 - diff: 19.30mlTrain batch 2/16 - 258.5ms/batch - loss: 22.85501 - diff: 18.64mlTrain batch 3/16 - 262.5ms/batch - loss: 19.02590 - diff: 17.18mlTrain batch 4/16 - 259.9ms/batch - loss: 18.19629 - diff: 16.80mlTrain batch 5/16 - 260.0ms/batch - loss: 18.33887 - diff: 17.10mlTrain batch 6/16 - 259.8ms/batch - loss: 20.37095 - diff: 18.04mlTrain batch 7/16 - 258.2ms/batch - loss: 20.20863 - diff: 18.27mlTrain batch 8/16 - 258.4ms/batch - loss: 22.04468 - diff: 19.18mlTrain batch 9/16 - 259.4ms/batch - loss: 20.70571 - diff: 18.62mlTrain batch 10/16 - 259.3ms/batch - loss: 20.27465 - diff: 18.62mlTrain batch 11/16 - 259.7ms/batch - loss: 21.07211 - diff: 18.76mlTrain batch 12/16 - 260.1ms/batch - loss: 20.52190 - diff: 18.63mlTrain batch 13/16 - 260.5ms/batch - loss: 20.07414 - diff: 18.38mlTrain batch 14/16 - 260.3ms/batch - loss: 19.28500 - diff: 18.09mlTrain batch 15/16 - 258.0ms/batch - loss: 19.23417 - diff: 18.10mlTrain batch 16/16 - 176.7ms/batch - loss: 20.13413 - diff: 18.01mlTrain batch 16/16 - 10.5s 176.7ms/batch - loss: 20.13413 - diff: 18.01ml
Test 0.9s: val_loss: 20.21603 - diff: 17.36ml

Epoch 128: current best loss = 19.08938, at epoch 123
Train batch 1/16 - 260.0ms/batch - loss: 8.42789 - diff: 13.79mlTrain batch 2/16 - 261.0ms/batch - loss: 23.36137 - diff: 19.33mlTrain batch 3/16 - 257.9ms/batch - loss: 18.49527 - diff: 17.00mlTrain batch 4/16 - 259.7ms/batch - loss: 19.10065 - diff: 17.18mlTrain batch 5/16 - 260.6ms/batch - loss: 19.06649 - diff: 17.42mlTrain batch 6/16 - 259.8ms/batch - loss: 18.22054 - diff: 17.20mlTrain batch 7/16 - 260.7ms/batch - loss: 20.65515 - diff: 18.40mlTrain batch 8/16 - 258.7ms/batch - loss: 20.03898 - diff: 18.42mlTrain batch 9/16 - 261.2ms/batch - loss: 20.32767 - diff: 18.59mlTrain batch 10/16 - 259.9ms/batch - loss: 20.14639 - diff: 18.58mlTrain batch 11/16 - 258.9ms/batch - loss: 19.14693 - diff: 18.08mlTrain batch 12/16 - 258.6ms/batch - loss: 19.89871 - diff: 18.37mlTrain batch 13/16 - 259.4ms/batch - loss: 21.77640 - diff: 18.86mlTrain batch 14/16 - 261.1ms/batch - loss: 21.29378 - diff: 18.59mlTrain batch 15/16 - 259.0ms/batch - loss: 21.07830 - diff: 18.51mlTrain batch 16/16 - 175.2ms/batch - loss: 21.00463 - diff: 18.33mlTrain batch 16/16 - 10.5s 175.2ms/batch - loss: 21.00463 - diff: 18.33ml
Test 0.8s: val_loss: 24.02023 - diff: 19.40ml

Epoch 129: current best loss = 19.08938, at epoch 123
Train batch 1/16 - 259.2ms/batch - loss: 14.65285 - diff: 18.29mlTrain batch 2/16 - 258.7ms/batch - loss: 20.85725 - diff: 19.98mlTrain batch 3/16 - 283.5ms/batch - loss: 21.51433 - diff: 19.69mlTrain batch 4/16 - 261.1ms/batch - loss: 21.48708 - diff: 20.43mlTrain batch 5/16 - 272.8ms/batch - loss: 20.01382 - diff: 19.90mlTrain batch 6/16 - 260.0ms/batch - loss: 20.90160 - diff: 19.67mlTrain batch 7/16 - 277.9ms/batch - loss: 20.05511 - diff: 19.12mlTrain batch 8/16 - 259.0ms/batch - loss: 20.51433 - diff: 19.39mlTrain batch 9/16 - 269.7ms/batch - loss: 19.56590 - diff: 18.83mlTrain batch 10/16 - 258.9ms/batch - loss: 19.20426 - diff: 18.50mlTrain batch 11/16 - 259.0ms/batch - loss: 19.82119 - diff: 18.75mlTrain batch 12/16 - 260.8ms/batch - loss: 19.74360 - diff: 18.66mlTrain batch 13/16 - 275.1ms/batch - loss: 19.77147 - diff: 18.80mlTrain batch 14/16 - 259.3ms/batch - loss: 19.65051 - diff: 18.82mlTrain batch 15/16 - 258.1ms/batch - loss: 20.25186 - diff: 19.13mlTrain batch 16/16 - 173.5ms/batch - loss: 21.06322 - diff: 19.27mlTrain batch 16/16 - 10.4s 173.5ms/batch - loss: 21.06322 - diff: 19.27ml
Test 0.9s: val_loss: 19.88023 - diff: 17.49ml

Epoch 130: current best loss = 19.08938, at epoch 123
Train batch 1/16 - 259.3ms/batch - loss: 29.06192 - diff: 23.48mlTrain batch 2/16 - 260.3ms/batch - loss: 22.07329 - diff: 20.77mlTrain batch 3/16 - 271.6ms/batch - loss: 21.72638 - diff: 20.38mlTrain batch 4/16 - 258.8ms/batch - loss: 20.24151 - diff: 19.43mlTrain batch 5/16 - 260.5ms/batch - loss: 21.31677 - diff: 19.48mlTrain batch 6/16 - 258.9ms/batch - loss: 20.12110 - diff: 19.09mlTrain batch 7/16 - 260.2ms/batch - loss: 18.21630 - diff: 18.15mlTrain batch 8/16 - 258.3ms/batch - loss: 17.36063 - diff: 18.00mlTrain batch 9/16 - 258.9ms/batch - loss: 17.78947 - diff: 18.26mlTrain batch 10/16 - 258.5ms/batch - loss: 17.15830 - diff: 17.96mlTrain batch 11/16 - 260.1ms/batch - loss: 17.61811 - diff: 18.04mlTrain batch 12/16 - 259.6ms/batch - loss: 17.95191 - diff: 18.20mlTrain batch 13/16 - 275.2ms/batch - loss: 17.59276 - diff: 18.09mlTrain batch 14/16 - 258.1ms/batch - loss: 17.64045 - diff: 18.04mlTrain batch 15/16 - 258.5ms/batch - loss: 17.92430 - diff: 18.15mlTrain batch 16/16 - 172.2ms/batch - loss: 18.22174 - diff: 18.05mlTrain batch 16/16 - 10.4s 172.2ms/batch - loss: 18.22174 - diff: 18.05ml
Test 1.0s: val_loss: 22.57786 - diff: 19.70ml

Epoch 131: current best loss = 19.08938, at epoch 123
Train batch 1/16 - 259.5ms/batch - loss: 19.69828 - diff: 21.41mlTrain batch 2/16 - 259.9ms/batch - loss: 22.22799 - diff: 19.90mlTrain batch 3/16 - 264.5ms/batch - loss: 20.31765 - diff: 18.88mlTrain batch 4/16 - 260.1ms/batch - loss: 18.79554 - diff: 18.10mlTrain batch 5/16 - 274.1ms/batch - loss: 17.81158 - diff: 17.80mlTrain batch 6/16 - 260.6ms/batch - loss: 18.55107 - diff: 18.15mlTrain batch 7/16 - 279.4ms/batch - loss: 18.12621 - diff: 17.91mlTrain batch 8/16 - 259.7ms/batch - loss: 17.70034 - diff: 17.59mlTrain batch 9/16 - 258.2ms/batch - loss: 17.88017 - diff: 17.70mlTrain batch 10/16 - 258.2ms/batch - loss: 18.12344 - diff: 17.77mlTrain batch 11/16 - 268.8ms/batch - loss: 18.48207 - diff: 17.79mlTrain batch 12/16 - 261.1ms/batch - loss: 17.89166 - diff: 17.53mlTrain batch 13/16 - 261.9ms/batch - loss: 17.59655 - diff: 17.54mlTrain batch 14/16 - 258.6ms/batch - loss: 18.50329 - diff: 17.99mlTrain batch 15/16 - 257.9ms/batch - loss: 19.17816 - diff: 18.33mlTrain batch 16/16 - 173.5ms/batch - loss: 18.94248 - diff: 18.12mlTrain batch 16/16 - 10.4s 173.5ms/batch - loss: 18.94248 - diff: 18.12ml
Test 0.9s: val_loss: 18.91287 - diff: 17.62ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Systole_VGG19_Adam-0.001_MSE_DA3_best

Epoch 132: current best loss = 18.91287, at epoch 131
Train batch 1/16 - 261.5ms/batch - loss: 27.02081 - diff: 22.85mlTrain batch 2/16 - 260.0ms/batch - loss: 25.54848 - diff: 20.91mlTrain batch 3/16 - 263.4ms/batch - loss: 20.62511 - diff: 18.78mlTrain batch 4/16 - 260.0ms/batch - loss: 19.88978 - diff: 18.19mlTrain batch 5/16 - 264.3ms/batch - loss: 19.47641 - diff: 18.24mlTrain batch 6/16 - 258.8ms/batch - loss: 21.64764 - diff: 18.79mlTrain batch 7/16 - 258.8ms/batch - loss: 21.35305 - diff: 18.68mlTrain batch 8/16 - 259.0ms/batch - loss: 21.52160 - diff: 19.05mlTrain batch 9/16 - 258.3ms/batch - loss: 20.97154 - diff: 19.03mlTrain batch 10/16 - 259.2ms/batch - loss: 20.35105 - diff: 18.90mlTrain batch 11/16 - 258.8ms/batch - loss: 20.20418 - diff: 18.97mlTrain batch 12/16 - 258.9ms/batch - loss: 19.32044 - diff: 18.50mlTrain batch 13/16 - 263.8ms/batch - loss: 19.96457 - diff: 18.79mlTrain batch 14/16 - 257.9ms/batch - loss: 20.23664 - diff: 18.67mlTrain batch 15/16 - 261.6ms/batch - loss: 20.34712 - diff: 18.55mlTrain batch 16/16 - 173.2ms/batch - loss: 22.08588 - diff: 18.91mlTrain batch 16/16 - 10.6s 173.2ms/batch - loss: 22.08588 - diff: 18.91ml
Test 0.8s: val_loss: 21.70114 - diff: 17.57ml

Epoch 133: current best loss = 18.91287, at epoch 131
Train batch 1/16 - 259.3ms/batch - loss: 34.27168 - diff: 24.42mlTrain batch 2/16 - 258.5ms/batch - loss: 27.46228 - diff: 21.85mlTrain batch 3/16 - 259.4ms/batch - loss: 21.55140 - diff: 19.35mlTrain batch 4/16 - 259.4ms/batch - loss: 20.30410 - diff: 19.51mlTrain batch 5/16 - 258.4ms/batch - loss: 22.22716 - diff: 20.46mlTrain batch 6/16 - 258.5ms/batch - loss: 22.57260 - diff: 20.90mlTrain batch 7/16 - 261.6ms/batch - loss: 22.09585 - diff: 20.56mlTrain batch 8/16 - 260.4ms/batch - loss: 22.19525 - diff: 20.27mlTrain batch 9/16 - 260.1ms/batch - loss: 22.13800 - diff: 20.06mlTrain batch 10/16 - 259.5ms/batch - loss: 21.38744 - diff: 19.66mlTrain batch 11/16 - 259.8ms/batch - loss: 20.93786 - diff: 19.43mlTrain batch 12/16 - 259.5ms/batch - loss: 20.49041 - diff: 19.28mlTrain batch 13/16 - 259.6ms/batch - loss: 20.30518 - diff: 19.11mlTrain batch 14/16 - 259.0ms/batch - loss: 19.69992 - diff: 18.87mlTrain batch 15/16 - 261.1ms/batch - loss: 19.16521 - diff: 18.62mlTrain batch 16/16 - 172.8ms/batch - loss: 20.14721 - diff: 18.73mlTrain batch 16/16 - 10.5s 172.8ms/batch - loss: 20.14721 - diff: 18.73ml
Test 0.8s: val_loss: 18.99023 - diff: 17.22ml

Epoch 134: current best loss = 18.91287, at epoch 131
Train batch 1/16 - 258.6ms/batch - loss: 21.45739 - diff: 19.54mlTrain batch 2/16 - 259.1ms/batch - loss: 18.42509 - diff: 18.17mlTrain batch 3/16 - 258.6ms/batch - loss: 20.63521 - diff: 18.88mlTrain batch 4/16 - 259.5ms/batch - loss: 19.39637 - diff: 18.38mlTrain batch 5/16 - 260.8ms/batch - loss: 18.44709 - diff: 18.30mlTrain batch 6/16 - 261.2ms/batch - loss: 16.92470 - diff: 17.60mlTrain batch 7/16 - 259.8ms/batch - loss: 17.15604 - diff: 17.78mlTrain batch 8/16 - 259.5ms/batch - loss: 18.08321 - diff: 18.15mlTrain batch 9/16 - 259.6ms/batch - loss: 18.46024 - diff: 18.26mlTrain batch 10/16 - 259.3ms/batch - loss: 17.33532 - diff: 17.70mlTrain batch 11/16 - 259.2ms/batch - loss: 19.22004 - diff: 18.27mlTrain batch 12/16 - 259.9ms/batch - loss: 19.12106 - diff: 18.20mlTrain batch 13/16 - 259.9ms/batch - loss: 19.11978 - diff: 18.32mlTrain batch 14/16 - 258.9ms/batch - loss: 18.57376 - diff: 18.09mlTrain batch 15/16 - 263.4ms/batch - loss: 18.21049 - diff: 18.00mlTrain batch 16/16 - 172.5ms/batch - loss: 19.24278 - diff: 18.14mlTrain batch 16/16 - 10.6s 172.5ms/batch - loss: 19.24278 - diff: 18.14ml
Test 0.8s: val_loss: 21.52937 - diff: 16.58ml

Epoch 135: current best loss = 18.91287, at epoch 131
Train batch 1/16 - 260.6ms/batch - loss: 19.60850 - diff: 17.25mlTrain batch 2/16 - 258.3ms/batch - loss: 17.61106 - diff: 16.95mlTrain batch 3/16 - 259.5ms/batch - loss: 19.70059 - diff: 17.84mlTrain batch 4/16 - 260.0ms/batch - loss: 19.28894 - diff: 18.38mlTrain batch 5/16 - 258.3ms/batch - loss: 19.01155 - diff: 18.72mlTrain batch 6/16 - 258.9ms/batch - loss: 18.59532 - diff: 18.59mlTrain batch 7/16 - 258.4ms/batch - loss: 18.35453 - diff: 18.46mlTrain batch 8/16 - 259.4ms/batch - loss: 19.40328 - diff: 18.94mlTrain batch 9/16 - 259.8ms/batch - loss: 19.32685 - diff: 18.98mlTrain batch 10/16 - 258.4ms/batch - loss: 19.29929 - diff: 19.06mlTrain batch 11/16 - 261.4ms/batch - loss: 19.03602 - diff: 18.82mlTrain batch 12/16 - 261.3ms/batch - loss: 18.05233 - diff: 18.30mlTrain batch 13/16 - 258.9ms/batch - loss: 17.87355 - diff: 18.31mlTrain batch 14/16 - 258.6ms/batch - loss: 17.89744 - diff: 18.22mlTrain batch 15/16 - 259.6ms/batch - loss: 17.44036 - diff: 17.99mlTrain batch 16/16 - 173.6ms/batch - loss: 17.57590 - diff: 17.87mlTrain batch 16/16 - 10.4s 173.6ms/batch - loss: 17.57590 - diff: 17.87ml
Test 0.8s: val_loss: 20.74069 - diff: 18.59ml

Epoch 136: current best loss = 18.91287, at epoch 131
Train batch 1/16 - 261.7ms/batch - loss: 17.90972 - diff: 19.17mlTrain batch 2/16 - 259.3ms/batch - loss: 13.99147 - diff: 17.03mlTrain batch 3/16 - 260.2ms/batch - loss: 13.30772 - diff: 15.99mlTrain batch 4/16 - 259.3ms/batch - loss: 14.55864 - diff: 16.31mlTrain batch 5/16 - 261.9ms/batch - loss: 15.31792 - diff: 16.72mlTrain batch 6/16 - 259.4ms/batch - loss: 14.96949 - diff: 16.53mlTrain batch 7/16 - 259.3ms/batch - loss: 15.17557 - diff: 16.62mlTrain batch 8/16 - 259.8ms/batch - loss: 15.28786 - diff: 16.49mlTrain batch 9/16 - 262.3ms/batch - loss: 15.44581 - diff: 16.61mlTrain batch 10/16 - 258.8ms/batch - loss: 15.61374 - diff: 16.83mlTrain batch 11/16 - 259.3ms/batch - loss: 16.76766 - diff: 17.20mlTrain batch 12/16 - 258.8ms/batch - loss: 18.18059 - diff: 17.83mlTrain batch 13/16 - 260.5ms/batch - loss: 19.13926 - diff: 18.15mlTrain batch 14/16 - 258.5ms/batch - loss: 18.69828 - diff: 17.89mlTrain batch 15/16 - 258.7ms/batch - loss: 19.66947 - diff: 18.26mlTrain batch 16/16 - 177.7ms/batch - loss: 20.37824 - diff: 18.38mlTrain batch 16/16 - 10.4s 177.7ms/batch - loss: 20.37824 - diff: 18.38ml
Test 0.9s: val_loss: 27.80577 - diff: 19.79ml

Epoch 137: current best loss = 18.91287, at epoch 131
Train batch 1/16 - 260.3ms/batch - loss: 11.08656 - diff: 15.07mlTrain batch 2/16 - 260.1ms/batch - loss: 13.40458 - diff: 15.71mlTrain batch 3/16 - 260.8ms/batch - loss: 14.92092 - diff: 16.61mlTrain batch 4/16 - 260.4ms/batch - loss: 16.68673 - diff: 17.13mlTrain batch 5/16 - 278.4ms/batch - loss: 15.76071 - diff: 16.70mlTrain batch 6/16 - 259.7ms/batch - loss: 16.34240 - diff: 17.42mlTrain batch 7/16 - 261.9ms/batch - loss: 16.48533 - diff: 17.66mlTrain batch 8/16 - 259.3ms/batch - loss: 20.06400 - diff: 18.70mlTrain batch 9/16 - 277.1ms/batch - loss: 19.89507 - diff: 18.98mlTrain batch 10/16 - 260.8ms/batch - loss: 19.75724 - diff: 19.16mlTrain batch 11/16 - 274.1ms/batch - loss: 19.65634 - diff: 19.20mlTrain batch 12/16 - 258.4ms/batch - loss: 21.68597 - diff: 19.76mlTrain batch 13/16 - 272.4ms/batch - loss: 21.66662 - diff: 19.78mlTrain batch 14/16 - 258.4ms/batch - loss: 21.61098 - diff: 19.66mlTrain batch 15/16 - 258.1ms/batch - loss: 21.10584 - diff: 19.48mlTrain batch 16/16 - 174.2ms/batch - loss: 21.34209 - diff: 19.44mlTrain batch 16/16 - 10.3s 174.2ms/batch - loss: 21.34209 - diff: 19.44ml
Test 0.9s: val_loss: 19.16085 - diff: 17.14ml

Epoch 138: current best loss = 18.91287, at epoch 131
Train batch 1/16 - 261.7ms/batch - loss: 10.34764 - diff: 15.26mlTrain batch 2/16 - 262.1ms/batch - loss: 15.45305 - diff: 15.46mlTrain batch 3/16 - 260.0ms/batch - loss: 14.16876 - diff: 15.67mlTrain batch 4/16 - 259.8ms/batch - loss: 13.74280 - diff: 15.50mlTrain batch 5/16 - 259.0ms/batch - loss: 14.61920 - diff: 15.94mlTrain batch 6/16 - 258.8ms/batch - loss: 17.07554 - diff: 17.18mlTrain batch 7/16 - 259.9ms/batch - loss: 19.22653 - diff: 17.87mlTrain batch 8/16 - 258.5ms/batch - loss: 19.45683 - diff: 18.10mlTrain batch 9/16 - 259.2ms/batch - loss: 18.58454 - diff: 17.76mlTrain batch 10/16 - 259.0ms/batch - loss: 17.63860 - diff: 17.25mlTrain batch 11/16 - 259.4ms/batch - loss: 17.17675 - diff: 17.16mlTrain batch 12/16 - 259.7ms/batch - loss: 17.90045 - diff: 17.48mlTrain batch 13/16 - 258.9ms/batch - loss: 17.29032 - diff: 17.18mlTrain batch 14/16 - 258.4ms/batch - loss: 16.71322 - diff: 16.93mlTrain batch 15/16 - 257.7ms/batch - loss: 17.51322 - diff: 17.42mlTrain batch 16/16 - 173.7ms/batch - loss: 18.43435 - diff: 17.49mlTrain batch 16/16 - 10.5s 173.7ms/batch - loss: 18.43435 - diff: 17.49ml
Test 0.9s: val_loss: 22.33701 - diff: 18.08ml

Epoch 139: current best loss = 18.91287, at epoch 131
Train batch 1/16 - 259.7ms/batch - loss: 10.64145 - diff: 16.00mlTrain batch 2/16 - 259.7ms/batch - loss: 17.84328 - diff: 19.81mlTrain batch 3/16 - 259.0ms/batch - loss: 17.83990 - diff: 19.34mlTrain batch 4/16 - 259.0ms/batch - loss: 16.13770 - diff: 18.38mlTrain batch 5/16 - 262.0ms/batch - loss: 16.50594 - diff: 18.38mlTrain batch 6/16 - 260.5ms/batch - loss: 16.62465 - diff: 18.08mlTrain batch 7/16 - 259.7ms/batch - loss: 15.92716 - diff: 17.54mlTrain batch 8/16 - 258.7ms/batch - loss: 19.59228 - diff: 17.66mlTrain batch 9/16 - 258.0ms/batch - loss: 18.44870 - diff: 17.35mlTrain batch 10/16 - 258.2ms/batch - loss: 17.77280 - diff: 17.17mlTrain batch 11/16 - 257.8ms/batch - loss: 17.69034 - diff: 17.15mlTrain batch 12/16 - 259.1ms/batch - loss: 17.33545 - diff: 17.14mlTrain batch 13/16 - 259.6ms/batch - loss: 17.07396 - diff: 17.15mlTrain batch 14/16 - 258.9ms/batch - loss: 18.05413 - diff: 17.57mlTrain batch 15/16 - 257.2ms/batch - loss: 17.69208 - diff: 17.48mlTrain batch 16/16 - 172.2ms/batch - loss: 17.97628 - diff: 17.45mlTrain batch 16/16 - 10.4s 172.2ms/batch - loss: 17.97628 - diff: 17.45ml
Test 0.9s: val_loss: 23.22283 - diff: 19.70ml

Epoch 140: current best loss = 18.91287, at epoch 131
Train batch 1/16 - 264.0ms/batch - loss: 10.83260 - diff: 15.81mlTrain batch 2/16 - 258.5ms/batch - loss: 12.46569 - diff: 16.93mlTrain batch 3/16 - 258.2ms/batch - loss: 15.50468 - diff: 18.51mlTrain batch 4/16 - 257.9ms/batch - loss: 20.12561 - diff: 20.15mlTrain batch 5/16 - 258.1ms/batch - loss: 19.16191 - diff: 19.30mlTrain batch 6/16 - 259.3ms/batch - loss: 18.63728 - diff: 18.59mlTrain batch 7/16 - 260.9ms/batch - loss: 17.43658 - diff: 17.97mlTrain batch 8/16 - 259.6ms/batch - loss: 16.46533 - diff: 17.29mlTrain batch 9/16 - 260.6ms/batch - loss: 16.45298 - diff: 17.47mlTrain batch 10/16 - 259.3ms/batch - loss: 16.39222 - diff: 17.65mlTrain batch 11/16 - 259.6ms/batch - loss: 17.00889 - diff: 17.77mlTrain batch 12/16 - 258.5ms/batch - loss: 16.79049 - diff: 17.69mlTrain batch 13/16 - 261.0ms/batch - loss: 16.37667 - diff: 17.60mlTrain batch 14/16 - 260.3ms/batch - loss: 16.07427 - diff: 17.40mlTrain batch 15/16 - 257.7ms/batch - loss: 15.51674 - diff: 17.11mlTrain batch 16/16 - 173.2ms/batch - loss: 15.43041 - diff: 16.94mlTrain batch 16/16 - 10.6s 173.2ms/batch - loss: 15.43041 - diff: 16.94ml
Test 1.0s: val_loss: 22.66045 - diff: 17.54ml

Epoch 141: current best loss = 18.91287, at epoch 131
Train batch 1/16 - 258.0ms/batch - loss: 8.95579 - diff: 12.11mlTrain batch 2/16 - 259.8ms/batch - loss: 8.29428 - diff: 12.35mlTrain batch 3/16 - 262.1ms/batch - loss: 11.24576 - diff: 14.67mlTrain batch 4/16 - 260.7ms/batch - loss: 15.63624 - diff: 16.77mlTrain batch 5/16 - 268.6ms/batch - loss: 14.89328 - diff: 16.69mlTrain batch 6/16 - 258.2ms/batch - loss: 14.84508 - diff: 16.75mlTrain batch 7/16 - 259.5ms/batch - loss: 18.92665 - diff: 17.63mlTrain batch 8/16 - 260.5ms/batch - loss: 21.70410 - diff: 19.19mlTrain batch 9/16 - 279.9ms/batch - loss: 23.05459 - diff: 19.97mlTrain batch 10/16 - 258.8ms/batch - loss: 22.80491 - diff: 20.03mlTrain batch 11/16 - 278.9ms/batch - loss: 23.30123 - diff: 20.22mlTrain batch 12/16 - 259.3ms/batch - loss: 22.11968 - diff: 19.63mlTrain batch 13/16 - 278.7ms/batch - loss: 21.71685 - diff: 19.38mlTrain batch 14/16 - 258.2ms/batch - loss: 21.73239 - diff: 19.17mlTrain batch 15/16 - 257.7ms/batch - loss: 21.62497 - diff: 19.15mlTrain batch 16/16 - 172.9ms/batch - loss: 21.88076 - diff: 19.05mlTrain batch 16/16 - 10.5s 172.9ms/batch - loss: 21.88076 - diff: 19.05ml
Test 0.9s: val_loss: 22.53158 - diff: 18.57ml

Epoch 142: current best loss = 18.91287, at epoch 131
Train batch 1/16 - 261.4ms/batch - loss: 34.37235 - diff: 24.67mlTrain batch 2/16 - 260.4ms/batch - loss: 23.95880 - diff: 21.13mlTrain batch 3/16 - 258.1ms/batch - loss: 30.05590 - diff: 21.52mlTrain batch 4/16 - 259.1ms/batch - loss: 26.29356 - diff: 20.57mlTrain batch 5/16 - 263.3ms/batch - loss: 25.56106 - diff: 20.74mlTrain batch 6/16 - 260.5ms/batch - loss: 26.27730 - diff: 21.09mlTrain batch 7/16 - 262.0ms/batch - loss: 27.22786 - diff: 21.84mlTrain batch 8/16 - 259.3ms/batch - loss: 26.48703 - diff: 21.86mlTrain batch 9/16 - 259.9ms/batch - loss: 26.02237 - diff: 21.52mlTrain batch 10/16 - 258.0ms/batch - loss: 25.05443 - diff: 20.91mlTrain batch 11/16 - 260.7ms/batch - loss: 24.26696 - diff: 20.26mlTrain batch 12/16 - 259.7ms/batch - loss: 23.93022 - diff: 20.13mlTrain batch 13/16 - 258.3ms/batch - loss: 24.81456 - diff: 20.46mlTrain batch 14/16 - 259.3ms/batch - loss: 24.64675 - diff: 20.41mlTrain batch 15/16 - 258.1ms/batch - loss: 23.96719 - diff: 20.15mlTrain batch 16/16 - 172.8ms/batch - loss: 24.04463 - diff: 20.11mlTrain batch 16/16 - 10.4s 172.8ms/batch - loss: 24.04463 - diff: 20.11ml
Test 0.8s: val_loss: 34.27557 - diff: 23.16ml
Epoch   143: reducing learning rate of group 0 to 6.2500e-05.

Epoch 143: current best loss = 18.91287, at epoch 131
Train batch 1/16 - 261.2ms/batch - loss: 19.77682 - diff: 18.76mlTrain batch 2/16 - 259.6ms/batch - loss: 23.32821 - diff: 20.06mlTrain batch 3/16 - 262.9ms/batch - loss: 22.50428 - diff: 20.26mlTrain batch 4/16 - 259.4ms/batch - loss: 23.37042 - diff: 19.91mlTrain batch 5/16 - 264.6ms/batch - loss: 20.60342 - diff: 18.78mlTrain batch 6/16 - 260.6ms/batch - loss: 19.51631 - diff: 18.12mlTrain batch 7/16 - 264.1ms/batch - loss: 18.90894 - diff: 18.13mlTrain batch 8/16 - 259.6ms/batch - loss: 18.48907 - diff: 18.25mlTrain batch 9/16 - 263.0ms/batch - loss: 18.67061 - diff: 17.93mlTrain batch 10/16 - 260.7ms/batch - loss: 19.84913 - diff: 18.19mlTrain batch 11/16 - 262.5ms/batch - loss: 20.97514 - diff: 18.71mlTrain batch 12/16 - 258.3ms/batch - loss: 20.70527 - diff: 18.53mlTrain batch 13/16 - 263.9ms/batch - loss: 21.38097 - diff: 18.67mlTrain batch 14/16 - 258.8ms/batch - loss: 21.66328 - diff: 18.82mlTrain batch 15/16 - 258.3ms/batch - loss: 21.94494 - diff: 19.08mlTrain batch 16/16 - 172.4ms/batch - loss: 22.38987 - diff: 19.22mlTrain batch 16/16 - 10.4s 172.4ms/batch - loss: 22.38987 - diff: 19.22ml
Test 0.8s: val_loss: 21.60926 - diff: 19.29ml

Epoch 144: current best loss = 18.91287, at epoch 131
Train batch 1/16 - 262.5ms/batch - loss: 16.06847 - diff: 20.63mlTrain batch 2/16 - 260.0ms/batch - loss: 17.30813 - diff: 21.09mlTrain batch 3/16 - 259.2ms/batch - loss: 16.64183 - diff: 19.69mlTrain batch 4/16 - 259.7ms/batch - loss: 15.58748 - diff: 18.64mlTrain batch 5/16 - 258.4ms/batch - loss: 16.77713 - diff: 18.82mlTrain batch 6/16 - 259.2ms/batch - loss: 16.80095 - diff: 18.86mlTrain batch 7/16 - 258.6ms/batch - loss: 16.95184 - diff: 18.61mlTrain batch 8/16 - 259.6ms/batch - loss: 16.88840 - diff: 18.55mlTrain batch 9/16 - 259.2ms/batch - loss: 18.03142 - diff: 18.51mlTrain batch 10/16 - 259.6ms/batch - loss: 18.54402 - diff: 18.68mlTrain batch 11/16 - 260.0ms/batch - loss: 19.19766 - diff: 18.81mlTrain batch 12/16 - 258.4ms/batch - loss: 19.78741 - diff: 18.87mlTrain batch 13/16 - 259.4ms/batch - loss: 18.80566 - diff: 18.39mlTrain batch 14/16 - 259.5ms/batch - loss: 18.30713 - diff: 18.21mlTrain batch 15/16 - 257.5ms/batch - loss: 18.68234 - diff: 18.40mlTrain batch 16/16 - 172.3ms/batch - loss: 18.90447 - diff: 18.32mlTrain batch 16/16 - 10.5s 172.3ms/batch - loss: 18.90447 - diff: 18.32ml
Test 0.8s: val_loss: 20.62040 - diff: 18.91ml

Epoch 145: current best loss = 18.91287, at epoch 131
Train batch 1/16 - 258.3ms/batch - loss: 28.22396 - diff: 24.46mlTrain batch 2/16 - 258.4ms/batch - loss: 20.23352 - diff: 20.46mlTrain batch 3/16 - 260.9ms/batch - loss: 20.11871 - diff: 20.74mlTrain batch 4/16 - 259.0ms/batch - loss: 22.29026 - diff: 21.16mlTrain batch 5/16 - 257.2ms/batch - loss: 21.99941 - diff: 20.98mlTrain batch 6/16 - 258.0ms/batch - loss: 21.51071 - diff: 20.04mlTrain batch 7/16 - 258.0ms/batch - loss: 19.85704 - diff: 18.96mlTrain batch 8/16 - 259.4ms/batch - loss: 19.04314 - diff: 18.75mlTrain batch 9/16 - 259.2ms/batch - loss: 18.33221 - diff: 18.49mlTrain batch 10/16 - 258.7ms/batch - loss: 18.63279 - diff: 18.77mlTrain batch 11/16 - 258.4ms/batch - loss: 17.91476 - diff: 18.42mlTrain batch 12/16 - 258.5ms/batch - loss: 17.65499 - diff: 18.29mlTrain batch 13/16 - 260.3ms/batch - loss: 17.87265 - diff: 18.42mlTrain batch 14/16 - 259.9ms/batch - loss: 17.21258 - diff: 18.10mlTrain batch 15/16 - 258.7ms/batch - loss: 17.42588 - diff: 18.09mlTrain batch 16/16 - 172.2ms/batch - loss: 17.44564 - diff: 18.00mlTrain batch 16/16 - 10.5s 172.2ms/batch - loss: 17.44564 - diff: 18.00ml
Test 0.8s: val_loss: 25.14986 - diff: 18.81ml

Epoch 146: current best loss = 18.91287, at epoch 131
Train batch 1/16 - 263.2ms/batch - loss: 13.51422 - diff: 16.97mlTrain batch 2/16 - 258.2ms/batch - loss: 16.16846 - diff: 18.19mlTrain batch 3/16 - 258.6ms/batch - loss: 15.28973 - diff: 17.93mlTrain batch 4/16 - 260.4ms/batch - loss: 13.81121 - diff: 17.07mlTrain batch 5/16 - 259.7ms/batch - loss: 13.11128 - diff: 16.58mlTrain batch 6/16 - 259.3ms/batch - loss: 14.62332 - diff: 17.06mlTrain batch 7/16 - 259.8ms/batch - loss: 15.47802 - diff: 17.34mlTrain batch 8/16 - 259.5ms/batch - loss: 17.38724 - diff: 17.93mlTrain batch 9/16 - 259.0ms/batch - loss: 18.51447 - diff: 18.30mlTrain batch 10/16 - 259.0ms/batch - loss: 18.46068 - diff: 18.16mlTrain batch 11/16 - 259.4ms/batch - loss: 19.13133 - diff: 18.40mlTrain batch 12/16 - 259.6ms/batch - loss: 19.17604 - diff: 18.42mlTrain batch 13/16 - 259.3ms/batch - loss: 18.61745 - diff: 18.19mlTrain batch 14/16 - 258.2ms/batch - loss: 18.79558 - diff: 18.36mlTrain batch 15/16 - 260.1ms/batch - loss: 18.63711 - diff: 18.33mlTrain batch 16/16 - 173.2ms/batch - loss: 18.99992 - diff: 18.34mlTrain batch 16/16 - 10.5s 173.2ms/batch - loss: 18.99992 - diff: 18.34ml
Test 0.8s: val_loss: 23.17621 - diff: 18.73ml

Epoch 147: current best loss = 18.91287, at epoch 131
Train batch 1/16 - 260.4ms/batch - loss: 11.39670 - diff: 15.75mlTrain batch 2/16 - 258.5ms/batch - loss: 9.11145 - diff: 13.98mlTrain batch 3/16 - 260.3ms/batch - loss: 13.46636 - diff: 15.89mlTrain batch 4/16 - 259.5ms/batch - loss: 12.75358 - diff: 15.29mlTrain batch 5/16 - 272.6ms/batch - loss: 13.63393 - diff: 15.92mlTrain batch 6/16 - 258.8ms/batch - loss: 15.20751 - diff: 16.08mlTrain batch 7/16 - 269.9ms/batch - loss: 15.44989 - diff: 16.30mlTrain batch 8/16 - 259.3ms/batch - loss: 14.79028 - diff: 15.98mlTrain batch 9/16 - 272.7ms/batch - loss: 14.79497 - diff: 16.06mlTrain batch 10/16 - 258.4ms/batch - loss: 15.87714 - diff: 16.48mlTrain batch 11/16 - 269.7ms/batch - loss: 15.69210 - diff: 16.41mlTrain batch 12/16 - 260.2ms/batch - loss: 16.60598 - diff: 16.68mlTrain batch 13/16 - 269.7ms/batch - loss: 16.35821 - diff: 16.60mlTrain batch 14/16 - 258.6ms/batch - loss: 15.74214 - diff: 16.36mlTrain batch 15/16 - 260.1ms/batch - loss: 16.13819 - diff: 16.72mlTrain batch 16/16 - 173.5ms/batch - loss: 16.59981 - diff: 16.74mlTrain batch 16/16 - 10.5s 173.5ms/batch - loss: 16.59981 - diff: 16.74ml
Test 0.8s: val_loss: 19.11644 - diff: 17.90ml

Epoch 148: current best loss = 18.91287, at epoch 131
Train batch 1/16 - 262.4ms/batch - loss: 15.61569 - diff: 15.34mlTrain batch 2/16 - 258.5ms/batch - loss: 12.22526 - diff: 14.51mlTrain batch 3/16 - 263.9ms/batch - loss: 17.63826 - diff: 17.16mlTrain batch 4/16 - 259.3ms/batch - loss: 16.85428 - diff: 16.76mlTrain batch 5/16 - 262.8ms/batch - loss: 15.73467 - diff: 16.31mlTrain batch 6/16 - 258.9ms/batch - loss: 15.22736 - diff: 16.34mlTrain batch 7/16 - 265.5ms/batch - loss: 15.20277 - diff: 16.68mlTrain batch 8/16 - 259.6ms/batch - loss: 15.93243 - diff: 17.06mlTrain batch 9/16 - 273.9ms/batch - loss: 15.83361 - diff: 16.99mlTrain batch 10/16 - 258.4ms/batch - loss: 15.18157 - diff: 16.68mlTrain batch 11/16 - 280.7ms/batch - loss: 15.64148 - diff: 16.94mlTrain batch 12/16 - 257.7ms/batch - loss: 15.95645 - diff: 17.05mlTrain batch 13/16 - 283.1ms/batch - loss: 15.62054 - diff: 16.92mlTrain batch 14/16 - 259.7ms/batch - loss: 15.31512 - diff: 16.76mlTrain batch 15/16 - 259.0ms/batch - loss: 15.17368 - diff: 16.61mlTrain batch 16/16 - 172.3ms/batch - loss: 15.98491 - diff: 16.73mlTrain batch 16/16 - 10.5s 172.3ms/batch - loss: 15.98491 - diff: 16.73ml
Test 0.8s: val_loss: 22.26301 - diff: 17.43ml

Epoch 149: current best loss = 18.91287, at epoch 131
Train batch 1/16 - 259.2ms/batch - loss: 14.75961 - diff: 16.89mlTrain batch 2/16 - 259.3ms/batch - loss: 15.54106 - diff: 17.37mlTrain batch 3/16 - 262.9ms/batch - loss: 14.52235 - diff: 16.51mlTrain batch 4/16 - 258.7ms/batch - loss: 14.24448 - diff: 16.08mlTrain batch 5/16 - 259.2ms/batch - loss: 14.40258 - diff: 16.46mlTrain batch 6/16 - 259.8ms/batch - loss: 15.16069 - diff: 16.81mlTrain batch 7/16 - 258.5ms/batch - loss: 14.42851 - diff: 16.53mlTrain batch 8/16 - 260.5ms/batch - loss: 14.74541 - diff: 16.71mlTrain batch 9/16 - 261.7ms/batch - loss: 14.70369 - diff: 16.79mlTrain batch 10/16 - 261.1ms/batch - loss: 14.41359 - diff: 16.65mlTrain batch 11/16 - 260.7ms/batch - loss: 13.89230 - diff: 16.31mlTrain batch 12/16 - 258.6ms/batch - loss: 14.62775 - diff: 16.61mlTrain batch 13/16 - 260.0ms/batch - loss: 15.21539 - diff: 16.84mlTrain batch 14/16 - 259.1ms/batch - loss: 15.21957 - diff: 16.91mlTrain batch 15/16 - 258.5ms/batch - loss: 16.21216 - diff: 17.35mlTrain batch 16/16 - 172.5ms/batch - loss: 16.27104 - diff: 17.16mlTrain batch 16/16 - 10.5s 172.5ms/batch - loss: 16.27104 - diff: 17.16ml
Test 0.9s: val_loss: 19.02911 - diff: 17.99ml

