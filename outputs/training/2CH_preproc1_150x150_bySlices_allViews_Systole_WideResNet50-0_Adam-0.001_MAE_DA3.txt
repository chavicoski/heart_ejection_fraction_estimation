nohup: ignoring input
Running experiment 2CH_preproc1_150x150_bySlices_dataset_allViews_Systole_WideResNet50_0_Adam-0.001_MAE_DA3
Going to train with the GPU in the slot 1 -> device model: GeForce RTX 2080
Model architecture:
 WideResNet50_0(
  (first_conv): Conv2d(30, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (pretrained_block): Sequential(
    (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): ReLU(inplace=True)
    (2): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (3): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (4): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (5): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (4): Bottleneck(
        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (5): Bottleneck(
        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
  )
  (reduction_block): Sequential(
    (0): AdaptiveAvgPool2d(output_size=(1, 1))
    (1): Flatten()
  )
  (dense_block): Sequential(
    (0): Linear(in_features=1024, out_features=512, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.4, inplace=False)
    (3): Linear(in_features=512, out_features=1, bias=True)
  )
) 


############################
# TRAIN PHASE:  150 epochs #
############################

Epoch 0: 
Train batch 1/32 - 203.8ms/batch - loss: 3.73519 - diff: 59.76mlTrain batch 2/32 - 178.9ms/batch - loss: 4.18058 - diff: 66.89mlTrain batch 3/32 - 182.3ms/batch - loss: 4.36794 - diff: 69.89mlTrain batch 4/32 - 167.7ms/batch - loss: 4.24828 - diff: 67.97mlTrain batch 5/32 - 170.3ms/batch - loss: 4.11843 - diff: 65.89mlTrain batch 6/32 - 167.8ms/batch - loss: 4.15199 - diff: 66.43mlTrain batch 7/32 - 167.6ms/batch - loss: 4.14300 - diff: 66.29mlTrain batch 8/32 - 167.9ms/batch - loss: 4.06672 - diff: 65.07mlTrain batch 9/32 - 167.7ms/batch - loss: 4.07851 - diff: 65.26mlTrain batch 10/32 - 167.9ms/batch - loss: 4.04151 - diff: 64.66mlTrain batch 11/32 - 167.8ms/batch - loss: 4.02526 - diff: 64.40mlTrain batch 12/32 - 168.0ms/batch - loss: 3.98935 - diff: 63.83mlTrain batch 13/32 - 170.8ms/batch - loss: 3.95583 - diff: 63.29mlTrain batch 14/32 - 167.7ms/batch - loss: 3.97763 - diff: 63.64mlTrain batch 15/32 - 168.0ms/batch - loss: 4.01016 - diff: 64.16mlTrain batch 16/32 - 168.2ms/batch - loss: 4.00324 - diff: 64.05mlTrain batch 17/32 - 168.0ms/batch - loss: 3.99776 - diff: 63.96mlTrain batch 18/32 - 168.2ms/batch - loss: 4.03436 - diff: 64.55mlTrain batch 19/32 - 168.1ms/batch - loss: 4.08260 - diff: 65.32mlTrain batch 20/32 - 168.0ms/batch - loss: 4.16310 - diff: 66.61mlTrain batch 21/32 - 170.5ms/batch - loss: 4.14125 - diff: 66.26mlTrain batch 22/32 - 170.3ms/batch - loss: 4.12825 - diff: 66.05mlTrain batch 23/32 - 171.4ms/batch - loss: 4.10467 - diff: 65.67mlTrain batch 24/32 - 173.2ms/batch - loss: 4.09338 - diff: 65.49mlTrain batch 25/32 - 168.3ms/batch - loss: 4.11965 - diff: 65.91mlTrain batch 26/32 - 168.2ms/batch - loss: 4.09235 - diff: 65.48mlTrain batch 27/32 - 168.4ms/batch - loss: 4.07851 - diff: 65.26mlTrain batch 28/32 - 168.3ms/batch - loss: 4.12527 - diff: 66.00mlTrain batch 29/32 - 185.2ms/batch - loss: 4.10419 - diff: 65.67mlTrain batch 30/32 - 168.4ms/batch - loss: 4.08369 - diff: 65.34mlTrain batch 31/32 - 168.2ms/batch - loss: 4.08197 - diff: 65.31mlTrain batch 32/32 - 51.5ms/batch - loss: 4.12515 - diff: 65.09mlTrain batch 32/32 - 18.3s 51.5ms/batch - loss: 4.12515 - diff: 65.09ml
Test 1.4s: val_loss: 3.27254 - diff: 49.90ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Systole_WideResNet50_0_Adam-0.001_MAE_DA3_best

Epoch 1: current best loss = 3.27254, at epoch 0
Train batch 1/32 - 174.4ms/batch - loss: 3.29277 - diff: 52.68mlTrain batch 2/32 - 168.4ms/batch - loss: 3.69181 - diff: 59.07mlTrain batch 3/32 - 168.6ms/batch - loss: 3.90800 - diff: 62.53mlTrain batch 4/32 - 169.0ms/batch - loss: 3.58319 - diff: 57.33mlTrain batch 5/32 - 184.8ms/batch - loss: 3.45486 - diff: 55.28mlTrain batch 6/32 - 168.5ms/batch - loss: 3.22194 - diff: 51.55mlTrain batch 7/32 - 183.4ms/batch - loss: 3.03416 - diff: 48.55mlTrain batch 8/32 - 168.5ms/batch - loss: 3.04662 - diff: 48.75mlTrain batch 9/32 - 185.0ms/batch - loss: 2.91487 - diff: 46.64mlTrain batch 10/32 - 168.5ms/batch - loss: 2.83598 - diff: 45.38mlTrain batch 11/32 - 168.3ms/batch - loss: 2.73036 - diff: 43.69mlTrain batch 12/32 - 168.5ms/batch - loss: 2.68090 - diff: 42.89mlTrain batch 13/32 - 171.5ms/batch - loss: 2.67561 - diff: 42.81mlTrain batch 14/32 - 169.6ms/batch - loss: 2.62896 - diff: 42.06mlTrain batch 15/32 - 168.5ms/batch - loss: 2.55210 - diff: 40.83mlTrain batch 16/32 - 175.7ms/batch - loss: 2.49492 - diff: 39.92mlTrain batch 17/32 - 179.2ms/batch - loss: 2.45706 - diff: 39.31mlTrain batch 18/32 - 179.1ms/batch - loss: 2.40952 - diff: 38.55mlTrain batch 19/32 - 168.5ms/batch - loss: 2.47252 - diff: 39.56mlTrain batch 20/32 - 168.4ms/batch - loss: 2.44621 - diff: 39.14mlTrain batch 21/32 - 171.3ms/batch - loss: 2.42510 - diff: 38.80mlTrain batch 22/32 - 168.3ms/batch - loss: 2.39677 - diff: 38.35mlTrain batch 23/32 - 170.5ms/batch - loss: 2.33730 - diff: 37.40mlTrain batch 24/32 - 169.9ms/batch - loss: 2.31883 - diff: 37.10mlTrain batch 25/32 - 168.4ms/batch - loss: 2.33339 - diff: 37.33mlTrain batch 26/32 - 168.7ms/batch - loss: 2.30456 - diff: 36.87mlTrain batch 27/32 - 180.1ms/batch - loss: 2.27802 - diff: 36.45mlTrain batch 28/32 - 168.8ms/batch - loss: 2.29682 - diff: 36.75mlTrain batch 29/32 - 194.6ms/batch - loss: 2.29334 - diff: 36.69mlTrain batch 30/32 - 173.4ms/batch - loss: 2.30156 - diff: 36.83mlTrain batch 31/32 - 168.4ms/batch - loss: 2.27983 - diff: 36.48mlTrain batch 32/32 - 52.0ms/batch - loss: 2.33860 - diff: 36.49mlTrain batch 32/32 - 15.0s 52.0ms/batch - loss: 2.33860 - diff: 36.49ml
Test 1.3s: val_loss: 1.72369 - diff: 26.35ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Systole_WideResNet50_0_Adam-0.001_MAE_DA3_best

Epoch 2: current best loss = 1.72369, at epoch 1
Train batch 1/32 - 184.4ms/batch - loss: 1.78453 - diff: 28.55mlTrain batch 2/32 - 174.8ms/batch - loss: 1.63162 - diff: 26.11mlTrain batch 3/32 - 183.3ms/batch - loss: 1.55245 - diff: 24.84mlTrain batch 4/32 - 176.8ms/batch - loss: 2.04429 - diff: 32.71mlTrain batch 5/32 - 187.2ms/batch - loss: 2.17117 - diff: 34.74mlTrain batch 6/32 - 168.8ms/batch - loss: 2.12337 - diff: 33.97mlTrain batch 7/32 - 168.9ms/batch - loss: 2.12670 - diff: 34.03mlTrain batch 8/32 - 181.0ms/batch - loss: 2.03782 - diff: 32.61mlTrain batch 9/32 - 184.1ms/batch - loss: 1.99406 - diff: 31.90mlTrain batch 10/32 - 168.7ms/batch - loss: 1.93736 - diff: 31.00mlTrain batch 11/32 - 168.9ms/batch - loss: 1.95192 - diff: 31.23mlTrain batch 12/32 - 168.8ms/batch - loss: 1.97185 - diff: 31.55mlTrain batch 13/32 - 168.8ms/batch - loss: 1.92085 - diff: 30.73mlTrain batch 14/32 - 182.3ms/batch - loss: 1.90699 - diff: 30.51mlTrain batch 15/32 - 180.3ms/batch - loss: 1.94253 - diff: 31.08mlTrain batch 16/32 - 169.0ms/batch - loss: 1.93816 - diff: 31.01mlTrain batch 17/32 - 175.4ms/batch - loss: 1.90197 - diff: 30.43mlTrain batch 18/32 - 169.0ms/batch - loss: 1.85702 - diff: 29.71mlTrain batch 19/32 - 181.3ms/batch - loss: 1.83857 - diff: 29.42mlTrain batch 20/32 - 169.2ms/batch - loss: 1.81623 - diff: 29.06mlTrain batch 21/32 - 181.2ms/batch - loss: 1.81841 - diff: 29.09mlTrain batch 22/32 - 177.0ms/batch - loss: 1.80948 - diff: 28.95mlTrain batch 23/32 - 177.6ms/batch - loss: 1.81309 - diff: 29.01mlTrain batch 24/32 - 168.9ms/batch - loss: 1.78833 - diff: 28.61mlTrain batch 25/32 - 169.2ms/batch - loss: 1.77749 - diff: 28.44mlTrain batch 26/32 - 179.5ms/batch - loss: 1.75974 - diff: 28.16mlTrain batch 27/32 - 169.4ms/batch - loss: 1.72692 - diff: 27.63mlTrain batch 28/32 - 169.0ms/batch - loss: 1.74479 - diff: 27.92mlTrain batch 29/32 - 169.2ms/batch - loss: 1.73921 - diff: 27.83mlTrain batch 30/32 - 169.0ms/batch - loss: 1.71712 - diff: 27.47mlTrain batch 31/32 - 168.9ms/batch - loss: 1.75934 - diff: 28.15mlTrain batch 32/32 - 51.6ms/batch - loss: 1.78116 - diff: 28.07mlTrain batch 32/32 - 14.7s 51.6ms/batch - loss: 1.78116 - diff: 28.07ml
Test 1.4s: val_loss: 1.63521 - diff: 25.55ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Systole_WideResNet50_0_Adam-0.001_MAE_DA3_best

Epoch 3: current best loss = 1.63521, at epoch 2
Train batch 1/32 - 193.8ms/batch - loss: 0.97875 - diff: 15.66mlTrain batch 2/32 - 169.8ms/batch - loss: 0.87611 - diff: 14.02mlTrain batch 3/32 - 169.1ms/batch - loss: 0.94963 - diff: 15.19mlTrain batch 4/32 - 169.3ms/batch - loss: 1.26674 - diff: 20.27mlTrain batch 5/32 - 177.7ms/batch - loss: 1.43006 - diff: 22.88mlTrain batch 6/32 - 169.1ms/batch - loss: 1.45530 - diff: 23.28mlTrain batch 7/32 - 169.9ms/batch - loss: 1.40436 - diff: 22.47mlTrain batch 8/32 - 169.2ms/batch - loss: 1.49290 - diff: 23.89mlTrain batch 9/32 - 169.1ms/batch - loss: 1.66829 - diff: 26.69mlTrain batch 10/32 - 169.4ms/batch - loss: 1.68881 - diff: 27.02mlTrain batch 11/32 - 169.0ms/batch - loss: 1.67050 - diff: 26.73mlTrain batch 12/32 - 169.4ms/batch - loss: 1.62545 - diff: 26.01mlTrain batch 13/32 - 178.3ms/batch - loss: 1.62455 - diff: 25.99mlTrain batch 14/32 - 170.2ms/batch - loss: 1.78042 - diff: 28.49mlTrain batch 15/32 - 184.1ms/batch - loss: 1.76511 - diff: 28.24mlTrain batch 16/32 - 179.8ms/batch - loss: 1.76677 - diff: 28.27mlTrain batch 17/32 - 172.8ms/batch - loss: 1.76809 - diff: 28.29mlTrain batch 18/32 - 169.2ms/batch - loss: 1.81117 - diff: 28.98mlTrain batch 19/32 - 169.1ms/batch - loss: 1.79637 - diff: 28.74mlTrain batch 20/32 - 172.4ms/batch - loss: 1.79599 - diff: 28.74mlTrain batch 21/32 - 169.1ms/batch - loss: 1.80357 - diff: 28.86mlTrain batch 22/32 - 168.7ms/batch - loss: 1.78783 - diff: 28.61mlTrain batch 23/32 - 177.7ms/batch - loss: 1.78861 - diff: 28.62mlTrain batch 24/32 - 169.7ms/batch - loss: 1.78488 - diff: 28.56mlTrain batch 25/32 - 173.7ms/batch - loss: 1.78293 - diff: 28.53mlTrain batch 26/32 - 169.6ms/batch - loss: 1.79640 - diff: 28.74mlTrain batch 27/32 - 172.2ms/batch - loss: 1.77968 - diff: 28.47mlTrain batch 28/32 - 169.5ms/batch - loss: 1.75883 - diff: 28.14mlTrain batch 29/32 - 169.3ms/batch - loss: 1.74621 - diff: 27.94mlTrain batch 30/32 - 169.4ms/batch - loss: 1.73248 - diff: 27.72mlTrain batch 31/32 - 169.1ms/batch - loss: 1.74378 - diff: 27.90mlTrain batch 32/32 - 51.7ms/batch - loss: 1.78127 - diff: 27.88mlTrain batch 32/32 - 15.1s 51.7ms/batch - loss: 1.78127 - diff: 27.88ml
Test 1.5s: val_loss: 1.64442 - diff: 25.51ml

Epoch 4: current best loss = 1.63521, at epoch 2
Train batch 1/32 - 169.4ms/batch - loss: 1.52485 - diff: 24.40mlTrain batch 2/32 - 178.5ms/batch - loss: 1.42382 - diff: 22.78mlTrain batch 3/32 - 174.0ms/batch - loss: 1.67616 - diff: 26.82mlTrain batch 4/32 - 169.4ms/batch - loss: 1.82307 - diff: 29.17mlTrain batch 5/32 - 169.2ms/batch - loss: 1.83701 - diff: 29.39mlTrain batch 6/32 - 195.6ms/batch - loss: 1.82050 - diff: 29.13mlTrain batch 7/32 - 169.3ms/batch - loss: 1.77264 - diff: 28.36mlTrain batch 8/32 - 169.4ms/batch - loss: 1.82422 - diff: 29.19mlTrain batch 9/32 - 169.2ms/batch - loss: 1.80253 - diff: 28.84mlTrain batch 10/32 - 169.6ms/batch - loss: 1.76724 - diff: 28.28mlTrain batch 11/32 - 169.3ms/batch - loss: 1.82157 - diff: 29.15mlTrain batch 12/32 - 169.5ms/batch - loss: 1.82393 - diff: 29.18mlTrain batch 13/32 - 169.4ms/batch - loss: 1.79787 - diff: 28.77mlTrain batch 14/32 - 168.7ms/batch - loss: 1.90524 - diff: 30.48mlTrain batch 15/32 - 169.6ms/batch - loss: 1.85940 - diff: 29.75mlTrain batch 16/32 - 169.9ms/batch - loss: 1.84081 - diff: 29.45mlTrain batch 17/32 - 169.4ms/batch - loss: 1.79002 - diff: 28.64mlTrain batch 18/32 - 169.7ms/batch - loss: 1.80593 - diff: 28.89mlTrain batch 19/32 - 169.3ms/batch - loss: 1.77863 - diff: 28.46mlTrain batch 20/32 - 169.9ms/batch - loss: 1.78804 - diff: 28.61mlTrain batch 21/32 - 184.2ms/batch - loss: 1.77028 - diff: 28.32mlTrain batch 22/32 - 169.3ms/batch - loss: 1.76690 - diff: 28.27mlTrain batch 23/32 - 169.3ms/batch - loss: 1.76057 - diff: 28.17mlTrain batch 24/32 - 170.9ms/batch - loss: 1.76883 - diff: 28.30mlTrain batch 25/32 - 169.5ms/batch - loss: 1.74574 - diff: 27.93mlTrain batch 26/32 - 184.2ms/batch - loss: 1.76830 - diff: 28.29mlTrain batch 27/32 - 171.9ms/batch - loss: 1.77504 - diff: 28.40mlTrain batch 28/32 - 173.4ms/batch - loss: 1.75527 - diff: 28.08mlTrain batch 29/32 - 169.7ms/batch - loss: 1.75306 - diff: 28.05mlTrain batch 30/32 - 173.5ms/batch - loss: 1.74034 - diff: 27.85mlTrain batch 31/32 - 169.7ms/batch - loss: 1.74523 - diff: 27.92mlTrain batch 32/32 - 56.9ms/batch - loss: 1.76007 - diff: 27.82mlTrain batch 32/32 - 15.4s 56.9ms/batch - loss: 1.76007 - diff: 27.82ml
Test 1.5s: val_loss: 1.61366 - diff: 25.32ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Systole_WideResNet50_0_Adam-0.001_MAE_DA3_best

Epoch 5: current best loss = 1.61366, at epoch 4
Train batch 1/32 - 185.0ms/batch - loss: 1.99113 - diff: 31.86mlTrain batch 2/32 - 169.4ms/batch - loss: 1.60291 - diff: 25.65mlTrain batch 3/32 - 183.9ms/batch - loss: 1.45861 - diff: 23.34mlTrain batch 4/32 - 179.9ms/batch - loss: 1.36878 - diff: 21.90mlTrain batch 5/32 - 169.6ms/batch - loss: 1.58880 - diff: 25.42mlTrain batch 6/32 - 173.1ms/batch - loss: 1.70165 - diff: 27.23mlTrain batch 7/32 - 169.6ms/batch - loss: 1.76264 - diff: 28.20mlTrain batch 8/32 - 169.7ms/batch - loss: 1.75793 - diff: 28.13mlTrain batch 9/32 - 171.8ms/batch - loss: 1.68100 - diff: 26.90mlTrain batch 10/32 - 169.6ms/batch - loss: 1.64059 - diff: 26.25mlTrain batch 11/32 - 169.8ms/batch - loss: 1.65259 - diff: 26.44mlTrain batch 12/32 - 174.6ms/batch - loss: 1.62606 - diff: 26.02mlTrain batch 13/32 - 169.5ms/batch - loss: 1.62077 - diff: 25.93mlTrain batch 14/32 - 178.6ms/batch - loss: 1.66998 - diff: 26.72mlTrain batch 15/32 - 181.1ms/batch - loss: 1.62579 - diff: 26.01mlTrain batch 16/32 - 174.0ms/batch - loss: 1.61368 - diff: 25.82mlTrain batch 17/32 - 169.7ms/batch - loss: 1.61285 - diff: 25.81mlTrain batch 18/32 - 173.8ms/batch - loss: 1.63744 - diff: 26.20mlTrain batch 19/32 - 169.5ms/batch - loss: 1.63468 - diff: 26.15mlTrain batch 20/32 - 172.5ms/batch - loss: 1.62093 - diff: 25.93mlTrain batch 21/32 - 169.4ms/batch - loss: 1.60904 - diff: 25.74mlTrain batch 22/32 - 172.0ms/batch - loss: 1.59936 - diff: 25.59mlTrain batch 23/32 - 169.7ms/batch - loss: 1.59451 - diff: 25.51mlTrain batch 24/32 - 170.0ms/batch - loss: 1.60152 - diff: 25.62mlTrain batch 25/32 - 169.4ms/batch - loss: 1.60022 - diff: 25.60mlTrain batch 26/32 - 169.9ms/batch - loss: 1.68711 - diff: 26.99mlTrain batch 27/32 - 170.1ms/batch - loss: 1.70207 - diff: 27.23mlTrain batch 28/32 - 170.2ms/batch - loss: 1.70565 - diff: 27.29mlTrain batch 29/32 - 169.9ms/batch - loss: 1.70323 - diff: 27.25mlTrain batch 30/32 - 170.4ms/batch - loss: 1.73108 - diff: 27.70mlTrain batch 31/32 - 170.1ms/batch - loss: 1.73937 - diff: 27.83mlTrain batch 32/32 - 52.4ms/batch - loss: 1.75725 - diff: 27.73mlTrain batch 32/32 - 16.3s 52.4ms/batch - loss: 1.75725 - diff: 27.73ml
Test 1.4s: val_loss: 1.62213 - diff: 25.20ml

Epoch 6: current best loss = 1.61366, at epoch 4
Train batch 1/32 - 177.8ms/batch - loss: 1.20450 - diff: 19.27mlTrain batch 2/32 - 176.3ms/batch - loss: 1.63603 - diff: 26.18mlTrain batch 3/32 - 170.0ms/batch - loss: 1.65833 - diff: 26.53mlTrain batch 4/32 - 176.2ms/batch - loss: 1.58618 - diff: 25.38mlTrain batch 5/32 - 170.9ms/batch - loss: 1.53060 - diff: 24.49mlTrain batch 6/32 - 170.0ms/batch - loss: 1.59306 - diff: 25.49mlTrain batch 7/32 - 170.6ms/batch - loss: 1.61726 - diff: 25.88mlTrain batch 8/32 - 173.6ms/batch - loss: 1.61279 - diff: 25.80mlTrain batch 9/32 - 169.9ms/batch - loss: 1.60123 - diff: 25.62mlTrain batch 10/32 - 169.7ms/batch - loss: 1.56559 - diff: 25.05mlTrain batch 11/32 - 169.7ms/batch - loss: 1.54041 - diff: 24.65mlTrain batch 12/32 - 170.1ms/batch - loss: 1.51701 - diff: 24.27mlTrain batch 13/32 - 170.2ms/batch - loss: 1.50986 - diff: 24.16mlTrain batch 14/32 - 181.5ms/batch - loss: 1.58102 - diff: 25.30mlTrain batch 15/32 - 173.6ms/batch - loss: 1.58804 - diff: 25.41mlTrain batch 16/32 - 184.3ms/batch - loss: 1.64036 - diff: 26.25mlTrain batch 17/32 - 174.3ms/batch - loss: 1.73833 - diff: 27.81mlTrain batch 18/32 - 178.3ms/batch - loss: 1.80597 - diff: 28.90mlTrain batch 19/32 - 175.2ms/batch - loss: 1.79518 - diff: 28.72mlTrain batch 20/32 - 170.2ms/batch - loss: 1.79754 - diff: 28.76mlTrain batch 21/32 - 173.9ms/batch - loss: 1.79323 - diff: 28.69mlTrain batch 22/32 - 177.5ms/batch - loss: 1.84328 - diff: 29.49mlTrain batch 23/32 - 170.1ms/batch - loss: 1.84529 - diff: 29.52mlTrain batch 24/32 - 170.2ms/batch - loss: 1.82054 - diff: 29.13mlTrain batch 25/32 - 171.7ms/batch - loss: 1.79459 - diff: 28.71mlTrain batch 26/32 - 170.7ms/batch - loss: 1.77769 - diff: 28.44mlTrain batch 27/32 - 178.6ms/batch - loss: 1.75578 - diff: 28.09mlTrain batch 28/32 - 171.3ms/batch - loss: 1.75393 - diff: 28.06mlTrain batch 29/32 - 175.3ms/batch - loss: 1.76845 - diff: 28.30mlTrain batch 30/32 - 170.4ms/batch - loss: 1.76124 - diff: 28.18mlTrain batch 31/32 - 170.0ms/batch - loss: 1.73787 - diff: 27.81mlTrain batch 32/32 - 65.7ms/batch - loss: 1.77506 - diff: 27.79mlTrain batch 32/32 - 17.3s 65.7ms/batch - loss: 1.77506 - diff: 27.79ml
Test 1.4s: val_loss: 1.62866 - diff: 25.24ml

Epoch 7: current best loss = 1.61366, at epoch 4
Train batch 1/32 - 178.8ms/batch - loss: 1.87800 - diff: 30.05mlTrain batch 2/32 - 170.2ms/batch - loss: 1.79337 - diff: 28.69mlTrain batch 3/32 - 170.1ms/batch - loss: 1.71406 - diff: 27.42mlTrain batch 4/32 - 170.0ms/batch - loss: 1.54971 - diff: 24.80mlTrain batch 5/32 - 173.7ms/batch - loss: 1.86165 - diff: 29.79mlTrain batch 6/32 - 170.4ms/batch - loss: 1.74526 - diff: 27.92mlTrain batch 7/32 - 185.8ms/batch - loss: 1.66366 - diff: 26.62mlTrain batch 8/32 - 170.4ms/batch - loss: 1.60629 - diff: 25.70mlTrain batch 9/32 - 170.6ms/batch - loss: 1.60048 - diff: 25.61mlTrain batch 10/32 - 174.2ms/batch - loss: 1.58468 - diff: 25.35mlTrain batch 11/32 - 170.1ms/batch - loss: 1.58972 - diff: 25.44mlTrain batch 12/32 - 179.8ms/batch - loss: 1.75034 - diff: 28.01mlTrain batch 13/32 - 175.7ms/batch - loss: 1.70640 - diff: 27.30mlTrain batch 14/32 - 170.4ms/batch - loss: 1.72388 - diff: 27.58mlTrain batch 15/32 - 170.1ms/batch - loss: 1.72816 - diff: 27.65mlTrain batch 16/32 - 170.5ms/batch - loss: 1.71850 - diff: 27.50mlTrain batch 17/32 - 177.0ms/batch - loss: 1.73623 - diff: 27.78mlTrain batch 18/32 - 185.1ms/batch - loss: 1.71256 - diff: 27.40mlTrain batch 19/32 - 170.0ms/batch - loss: 1.75210 - diff: 28.03mlTrain batch 20/32 - 169.5ms/batch - loss: 1.76899 - diff: 28.30mlTrain batch 21/32 - 170.3ms/batch - loss: 1.78292 - diff: 28.53mlTrain batch 22/32 - 169.6ms/batch - loss: 1.79066 - diff: 28.65mlTrain batch 23/32 - 172.0ms/batch - loss: 1.80459 - diff: 28.87mlTrain batch 24/32 - 170.3ms/batch - loss: 1.80265 - diff: 28.84mlTrain batch 25/32 - 180.8ms/batch - loss: 1.79001 - diff: 28.64mlTrain batch 26/32 - 179.9ms/batch - loss: 1.82023 - diff: 29.12mlTrain batch 27/32 - 182.9ms/batch - loss: 1.79225 - diff: 28.68mlTrain batch 28/32 - 169.6ms/batch - loss: 1.76653 - diff: 28.26mlTrain batch 29/32 - 170.2ms/batch - loss: 1.74970 - diff: 28.00mlTrain batch 30/32 - 169.4ms/batch - loss: 1.73896 - diff: 27.82mlTrain batch 31/32 - 170.9ms/batch - loss: 1.72733 - diff: 27.64mlTrain batch 32/32 - 62.1ms/batch - loss: 1.76427 - diff: 27.62mlTrain batch 32/32 - 17.3s 62.1ms/batch - loss: 1.76427 - diff: 27.62ml
Test 1.5s: val_loss: 1.65112 - diff: 25.11ml

Epoch 8: current best loss = 1.61366, at epoch 4
Train batch 1/32 - 170.3ms/batch - loss: 1.95968 - diff: 31.35mlTrain batch 2/32 - 172.7ms/batch - loss: 1.67700 - diff: 26.83mlTrain batch 3/32 - 177.1ms/batch - loss: 1.69137 - diff: 27.06mlTrain batch 4/32 - 170.3ms/batch - loss: 1.85352 - diff: 29.66mlTrain batch 5/32 - 170.6ms/batch - loss: 1.72446 - diff: 27.59mlTrain batch 6/32 - 170.6ms/batch - loss: 1.66405 - diff: 26.62mlTrain batch 7/32 - 170.2ms/batch - loss: 1.63629 - diff: 26.18mlTrain batch 8/32 - 170.4ms/batch - loss: 1.62149 - diff: 25.94mlTrain batch 9/32 - 170.2ms/batch - loss: 1.65397 - diff: 26.46mlTrain batch 10/32 - 191.2ms/batch - loss: 1.64585 - diff: 26.33mlTrain batch 11/32 - 170.3ms/batch - loss: 1.57651 - diff: 25.22mlTrain batch 12/32 - 179.2ms/batch - loss: 1.60403 - diff: 25.66mlTrain batch 13/32 - 184.7ms/batch - loss: 1.60778 - diff: 25.72mlTrain batch 14/32 - 170.4ms/batch - loss: 1.58971 - diff: 25.44mlTrain batch 15/32 - 170.2ms/batch - loss: 1.60612 - diff: 25.70mlTrain batch 16/32 - 176.8ms/batch - loss: 1.59773 - diff: 25.56mlTrain batch 17/32 - 170.3ms/batch - loss: 1.64742 - diff: 26.36mlTrain batch 18/32 - 176.3ms/batch - loss: 1.70089 - diff: 27.21mlTrain batch 19/32 - 181.4ms/batch - loss: 1.75790 - diff: 28.13mlTrain batch 20/32 - 182.1ms/batch - loss: 1.74166 - diff: 27.87mlTrain batch 21/32 - 185.0ms/batch - loss: 1.73741 - diff: 27.80mlTrain batch 22/32 - 175.0ms/batch - loss: 1.74407 - diff: 27.91mlTrain batch 23/32 - 170.3ms/batch - loss: 1.71145 - diff: 27.38mlTrain batch 24/32 - 173.9ms/batch - loss: 1.79077 - diff: 28.65mlTrain batch 25/32 - 170.1ms/batch - loss: 1.76283 - diff: 28.21mlTrain batch 26/32 - 177.1ms/batch - loss: 1.73383 - diff: 27.74mlTrain batch 27/32 - 174.5ms/batch - loss: 1.72192 - diff: 27.55mlTrain batch 28/32 - 172.4ms/batch - loss: 1.70131 - diff: 27.22mlTrain batch 29/32 - 181.7ms/batch - loss: 1.71754 - diff: 27.48mlTrain batch 30/32 - 170.2ms/batch - loss: 1.71846 - diff: 27.50mlTrain batch 31/32 - 174.9ms/batch - loss: 1.72147 - diff: 27.54mlTrain batch 32/32 - 52.3ms/batch - loss: 1.77363 - diff: 27.59mlTrain batch 32/32 - 16.2s 52.3ms/batch - loss: 1.77363 - diff: 27.59ml
Test 1.5s: val_loss: 1.60037 - diff: 24.89ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Systole_WideResNet50_0_Adam-0.001_MAE_DA3_best

Epoch 9: current best loss = 1.60037, at epoch 8
Train batch 1/32 - 184.2ms/batch - loss: 1.30558 - diff: 20.89mlTrain batch 2/32 - 172.6ms/batch - loss: 1.71873 - diff: 27.50mlTrain batch 3/32 - 170.1ms/batch - loss: 1.60276 - diff: 25.64mlTrain batch 4/32 - 170.6ms/batch - loss: 1.63654 - diff: 26.18mlTrain batch 5/32 - 171.8ms/batch - loss: 1.62854 - diff: 26.06mlTrain batch 6/32 - 175.2ms/batch - loss: 1.68886 - diff: 27.02mlTrain batch 7/32 - 180.6ms/batch - loss: 1.73167 - diff: 27.71mlTrain batch 8/32 - 179.9ms/batch - loss: 1.75244 - diff: 28.04mlTrain batch 9/32 - 170.3ms/batch - loss: 1.75525 - diff: 28.08mlTrain batch 10/32 - 195.4ms/batch - loss: 1.72233 - diff: 27.56mlTrain batch 11/32 - 170.2ms/batch - loss: 1.70882 - diff: 27.34mlTrain batch 12/32 - 169.8ms/batch - loss: 1.67254 - diff: 26.76mlTrain batch 13/32 - 170.0ms/batch - loss: 1.64727 - diff: 26.36mlTrain batch 14/32 - 170.8ms/batch - loss: 1.64100 - diff: 26.26mlTrain batch 15/32 - 170.2ms/batch - loss: 1.71738 - diff: 27.48mlTrain batch 16/32 - 188.8ms/batch - loss: 1.72959 - diff: 27.67mlTrain batch 17/32 - 204.8ms/batch - loss: 1.68623 - diff: 26.98mlTrain batch 18/32 - 170.1ms/batch - loss: 1.70517 - diff: 27.28mlTrain batch 19/32 - 186.5ms/batch - loss: 1.73448 - diff: 27.75mlTrain batch 20/32 - 170.6ms/batch - loss: 1.73529 - diff: 27.76mlTrain batch 21/32 - 170.1ms/batch - loss: 1.76690 - diff: 28.27mlTrain batch 22/32 - 170.2ms/batch - loss: 1.74379 - diff: 27.90mlTrain batch 23/32 - 170.2ms/batch - loss: 1.74525 - diff: 27.92mlTrain batch 24/32 - 170.3ms/batch - loss: 1.70880 - diff: 27.34mlTrain batch 25/32 - 170.3ms/batch - loss: 1.71586 - diff: 27.45mlTrain batch 26/32 - 170.0ms/batch - loss: 1.71930 - diff: 27.51mlTrain batch 27/32 - 172.4ms/batch - loss: 1.71829 - diff: 27.49mlTrain batch 28/32 - 170.9ms/batch - loss: 1.69119 - diff: 27.06mlTrain batch 29/32 - 170.1ms/batch - loss: 1.69299 - diff: 27.09mlTrain batch 30/32 - 169.9ms/batch - loss: 1.70123 - diff: 27.22mlTrain batch 31/32 - 170.3ms/batch - loss: 1.72065 - diff: 27.53mlTrain batch 32/32 - 52.4ms/batch - loss: 1.72547 - diff: 27.38mlTrain batch 32/32 - 16.2s 52.4ms/batch - loss: 1.72547 - diff: 27.38ml
Test 1.6s: val_loss: 1.59920 - diff: 24.87ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Systole_WideResNet50_0_Adam-0.001_MAE_DA3_best

Epoch 10: current best loss = 1.59920, at epoch 9
Train batch 1/32 - 184.2ms/batch - loss: 1.05312 - diff: 16.85mlTrain batch 2/32 - 171.7ms/batch - loss: 1.16395 - diff: 18.62mlTrain batch 3/32 - 170.2ms/batch - loss: 1.18924 - diff: 19.03mlTrain batch 4/32 - 170.8ms/batch - loss: 1.35625 - diff: 21.70mlTrain batch 5/32 - 170.1ms/batch - loss: 1.50306 - diff: 24.05mlTrain batch 6/32 - 170.6ms/batch - loss: 1.52255 - diff: 24.36mlTrain batch 7/32 - 170.2ms/batch - loss: 1.58590 - diff: 25.37mlTrain batch 8/32 - 170.4ms/batch - loss: 1.54727 - diff: 24.76mlTrain batch 9/32 - 170.1ms/batch - loss: 1.60267 - diff: 25.64mlTrain batch 10/32 - 170.9ms/batch - loss: 1.53632 - diff: 24.58mlTrain batch 11/32 - 170.3ms/batch - loss: 1.57184 - diff: 25.15mlTrain batch 12/32 - 185.3ms/batch - loss: 1.56587 - diff: 25.05mlTrain batch 13/32 - 174.3ms/batch - loss: 1.53749 - diff: 24.60mlTrain batch 14/32 - 170.5ms/batch - loss: 1.51358 - diff: 24.22mlTrain batch 15/32 - 174.5ms/batch - loss: 1.52509 - diff: 24.40mlTrain batch 16/32 - 170.0ms/batch - loss: 1.49172 - diff: 23.87mlTrain batch 17/32 - 170.1ms/batch - loss: 1.52679 - diff: 24.43mlTrain batch 18/32 - 170.4ms/batch - loss: 1.55057 - diff: 24.81mlTrain batch 19/32 - 172.5ms/batch - loss: 1.51706 - diff: 24.27mlTrain batch 20/32 - 169.4ms/batch - loss: 1.60684 - diff: 25.71mlTrain batch 21/32 - 184.2ms/batch - loss: 1.61416 - diff: 25.83mlTrain batch 22/32 - 170.5ms/batch - loss: 1.60449 - diff: 25.67mlTrain batch 23/32 - 183.4ms/batch - loss: 1.60717 - diff: 25.71mlTrain batch 24/32 - 171.3ms/batch - loss: 1.62074 - diff: 25.93mlTrain batch 25/32 - 169.9ms/batch - loss: 1.65546 - diff: 26.49mlTrain batch 26/32 - 169.9ms/batch - loss: 1.65341 - diff: 26.45mlTrain batch 27/32 - 170.2ms/batch - loss: 1.70155 - diff: 27.22mlTrain batch 28/32 - 170.6ms/batch - loss: 1.69389 - diff: 27.10mlTrain batch 29/32 - 170.0ms/batch - loss: 1.73121 - diff: 27.70mlTrain batch 30/32 - 170.7ms/batch - loss: 1.71787 - diff: 27.49mlTrain batch 31/32 - 170.4ms/batch - loss: 1.71826 - diff: 27.49mlTrain batch 32/32 - 52.6ms/batch - loss: 1.77250 - diff: 27.54mlTrain batch 32/32 - 18.1s 52.6ms/batch - loss: 1.77250 - diff: 27.54ml
Test 1.4s: val_loss: 1.60074 - diff: 24.99ml

Epoch 11: current best loss = 1.59920, at epoch 9
Train batch 1/32 - 170.3ms/batch - loss: 2.47840 - diff: 39.65mlTrain batch 2/32 - 170.3ms/batch - loss: 1.96656 - diff: 31.47mlTrain batch 3/32 - 177.9ms/batch - loss: 1.90995 - diff: 30.56mlTrain batch 4/32 - 170.1ms/batch - loss: 1.98699 - diff: 31.79mlTrain batch 5/32 - 175.0ms/batch - loss: 2.07982 - diff: 33.28mlTrain batch 6/32 - 170.5ms/batch - loss: 1.96805 - diff: 31.49mlTrain batch 7/32 - 170.5ms/batch - loss: 1.93792 - diff: 31.01mlTrain batch 8/32 - 186.5ms/batch - loss: 1.92025 - diff: 30.72mlTrain batch 9/32 - 170.4ms/batch - loss: 1.86532 - diff: 29.85mlTrain batch 10/32 - 171.6ms/batch - loss: 1.84448 - diff: 29.51mlTrain batch 11/32 - 170.3ms/batch - loss: 1.82834 - diff: 29.25mlTrain batch 12/32 - 179.3ms/batch - loss: 1.75773 - diff: 28.12mlTrain batch 13/32 - 170.2ms/batch - loss: 1.82400 - diff: 29.18mlTrain batch 14/32 - 170.1ms/batch - loss: 1.78493 - diff: 28.56mlTrain batch 15/32 - 175.0ms/batch - loss: 1.84272 - diff: 29.48mlTrain batch 16/32 - 176.5ms/batch - loss: 1.83905 - diff: 29.42mlTrain batch 17/32 - 170.6ms/batch - loss: 1.80757 - diff: 28.92mlTrain batch 18/32 - 170.2ms/batch - loss: 1.80274 - diff: 28.84mlTrain batch 19/32 - 170.4ms/batch - loss: 1.79784 - diff: 28.77mlTrain batch 20/32 - 175.0ms/batch - loss: 1.82033 - diff: 29.13mlTrain batch 21/32 - 179.9ms/batch - loss: 1.80868 - diff: 28.94mlTrain batch 22/32 - 170.3ms/batch - loss: 1.81478 - diff: 29.04mlTrain batch 23/32 - 170.8ms/batch - loss: 1.80574 - diff: 28.89mlTrain batch 24/32 - 170.4ms/batch - loss: 1.80195 - diff: 28.83mlTrain batch 25/32 - 170.3ms/batch - loss: 1.78746 - diff: 28.60mlTrain batch 26/32 - 170.3ms/batch - loss: 1.78901 - diff: 28.62mlTrain batch 27/32 - 170.5ms/batch - loss: 1.77955 - diff: 28.47mlTrain batch 28/32 - 181.9ms/batch - loss: 1.75600 - diff: 28.10mlTrain batch 29/32 - 170.4ms/batch - loss: 1.72895 - diff: 27.66mlTrain batch 30/32 - 170.2ms/batch - loss: 1.70201 - diff: 27.23mlTrain batch 31/32 - 170.6ms/batch - loss: 1.69622 - diff: 27.14mlTrain batch 32/32 - 52.7ms/batch - loss: 1.75655 - diff: 27.22mlTrain batch 32/32 - 16.6s 52.7ms/batch - loss: 1.75655 - diff: 27.22ml
Test 1.6s: val_loss: 1.63000 - diff: 24.80ml

Epoch 12: current best loss = 1.59920, at epoch 9
Train batch 1/32 - 170.3ms/batch - loss: 1.44431 - diff: 23.11mlTrain batch 2/32 - 170.5ms/batch - loss: 2.24173 - diff: 35.87mlTrain batch 3/32 - 175.2ms/batch - loss: 1.96828 - diff: 31.49mlTrain batch 4/32 - 170.4ms/batch - loss: 1.92780 - diff: 30.84mlTrain batch 5/32 - 175.9ms/batch - loss: 1.85137 - diff: 29.62mlTrain batch 6/32 - 170.6ms/batch - loss: 1.77623 - diff: 28.42mlTrain batch 7/32 - 170.3ms/batch - loss: 1.64988 - diff: 26.40mlTrain batch 8/32 - 170.5ms/batch - loss: 1.64834 - diff: 26.37mlTrain batch 9/32 - 170.3ms/batch - loss: 1.64990 - diff: 26.40mlTrain batch 10/32 - 170.4ms/batch - loss: 1.62903 - diff: 26.06mlTrain batch 11/32 - 170.3ms/batch - loss: 1.64053 - diff: 26.25mlTrain batch 12/32 - 175.3ms/batch - loss: 1.62942 - diff: 26.07mlTrain batch 13/32 - 170.3ms/batch - loss: 1.63148 - diff: 26.10mlTrain batch 14/32 - 178.1ms/batch - loss: 1.68913 - diff: 27.03mlTrain batch 15/32 - 184.6ms/batch - loss: 1.71169 - diff: 27.39mlTrain batch 16/32 - 170.4ms/batch - loss: 1.73076 - diff: 27.69mlTrain batch 17/32 - 173.8ms/batch - loss: 1.70298 - diff: 27.25mlTrain batch 18/32 - 170.4ms/batch - loss: 1.69241 - diff: 27.08mlTrain batch 19/32 - 186.7ms/batch - loss: 1.67584 - diff: 26.81mlTrain batch 20/32 - 170.7ms/batch - loss: 1.65753 - diff: 26.52mlTrain batch 21/32 - 191.9ms/batch - loss: 1.65120 - diff: 26.42mlTrain batch 22/32 - 170.9ms/batch - loss: 1.62068 - diff: 25.93mlTrain batch 23/32 - 171.7ms/batch - loss: 1.65017 - diff: 26.40mlTrain batch 24/32 - 178.3ms/batch - loss: 1.65025 - diff: 26.40mlTrain batch 25/32 - 171.7ms/batch - loss: 1.64101 - diff: 26.26mlTrain batch 26/32 - 170.8ms/batch - loss: 1.62582 - diff: 26.01mlTrain batch 27/32 - 170.5ms/batch - loss: 1.64246 - diff: 26.28mlTrain batch 28/32 - 172.0ms/batch - loss: 1.63141 - diff: 26.10mlTrain batch 29/32 - 184.6ms/batch - loss: 1.67612 - diff: 26.82mlTrain batch 30/32 - 170.0ms/batch - loss: 1.67790 - diff: 26.85mlTrain batch 31/32 - 170.3ms/batch - loss: 1.70373 - diff: 27.26mlTrain batch 32/32 - 52.4ms/batch - loss: 1.78968 - diff: 27.44mlTrain batch 32/32 - 16.8s 52.4ms/batch - loss: 1.78968 - diff: 27.44ml
Test 1.6s: val_loss: 1.60468 - diff: 24.53ml

Epoch 13: current best loss = 1.59920, at epoch 9
Train batch 1/32 - 170.4ms/batch - loss: 1.14921 - diff: 18.39mlTrain batch 2/32 - 185.5ms/batch - loss: 1.54068 - diff: 24.65mlTrain batch 3/32 - 170.7ms/batch - loss: 1.49211 - diff: 23.87mlTrain batch 4/32 - 170.4ms/batch - loss: 1.40813 - diff: 22.53mlTrain batch 5/32 - 170.5ms/batch - loss: 1.36574 - diff: 21.85mlTrain batch 6/32 - 181.6ms/batch - loss: 1.48438 - diff: 23.75mlTrain batch 7/32 - 186.4ms/batch - loss: 1.50670 - diff: 24.11mlTrain batch 8/32 - 195.7ms/batch - loss: 1.52253 - diff: 24.36mlTrain batch 9/32 - 176.1ms/batch - loss: 1.47279 - diff: 23.56mlTrain batch 10/32 - 170.5ms/batch - loss: 1.62042 - diff: 25.93mlTrain batch 11/32 - 183.4ms/batch - loss: 1.64635 - diff: 26.34mlTrain batch 12/32 - 170.5ms/batch - loss: 1.66387 - diff: 26.62mlTrain batch 13/32 - 170.5ms/batch - loss: 1.65930 - diff: 26.55mlTrain batch 14/32 - 171.0ms/batch - loss: 1.68164 - diff: 26.91mlTrain batch 15/32 - 170.3ms/batch - loss: 1.68442 - diff: 26.95mlTrain batch 16/32 - 170.3ms/batch - loss: 1.67696 - diff: 26.83mlTrain batch 17/32 - 188.9ms/batch - loss: 1.68083 - diff: 26.89mlTrain batch 18/32 - 170.6ms/batch - loss: 1.66909 - diff: 26.71mlTrain batch 19/32 - 196.2ms/batch - loss: 1.69056 - diff: 27.05mlTrain batch 20/32 - 170.5ms/batch - loss: 1.65315 - diff: 26.45mlTrain batch 21/32 - 192.1ms/batch - loss: 1.68481 - diff: 26.96mlTrain batch 22/32 - 182.1ms/batch - loss: 1.68119 - diff: 26.90mlTrain batch 23/32 - 184.0ms/batch - loss: 1.72492 - diff: 27.60mlTrain batch 24/32 - 182.6ms/batch - loss: 1.74249 - diff: 27.88mlTrain batch 25/32 - 170.4ms/batch - loss: 1.75806 - diff: 28.13mlTrain batch 26/32 - 170.5ms/batch - loss: 1.74306 - diff: 27.89mlTrain batch 27/32 - 170.4ms/batch - loss: 1.74265 - diff: 27.88mlTrain batch 28/32 - 180.9ms/batch - loss: 1.75481 - diff: 28.08mlTrain batch 29/32 - 174.1ms/batch - loss: 1.74477 - diff: 27.92mlTrain batch 30/32 - 170.7ms/batch - loss: 1.71971 - diff: 27.52mlTrain batch 31/32 - 170.2ms/batch - loss: 1.71185 - diff: 27.39mlTrain batch 32/32 - 52.5ms/batch - loss: 1.72969 - diff: 27.30mlTrain batch 32/32 - 15.1s 52.5ms/batch - loss: 1.72969 - diff: 27.30ml
Test 1.4s: val_loss: 1.60208 - diff: 25.05ml

Epoch 14: current best loss = 1.59920, at epoch 9
Train batch 1/32 - 170.2ms/batch - loss: 1.33662 - diff: 21.39mlTrain batch 2/32 - 170.6ms/batch - loss: 1.65536 - diff: 26.49mlTrain batch 3/32 - 170.5ms/batch - loss: 1.45483 - diff: 23.28mlTrain batch 4/32 - 170.8ms/batch - loss: 1.31640 - diff: 21.06mlTrain batch 5/32 - 170.3ms/batch - loss: 1.46404 - diff: 23.42mlTrain batch 6/32 - 171.2ms/batch - loss: 1.41007 - diff: 22.56mlTrain batch 7/32 - 170.8ms/batch - loss: 1.48510 - diff: 23.76mlTrain batch 8/32 - 170.6ms/batch - loss: 1.53534 - diff: 24.57mlTrain batch 9/32 - 170.4ms/batch - loss: 1.64406 - diff: 26.31mlTrain batch 10/32 - 170.7ms/batch - loss: 1.60377 - diff: 25.66mlTrain batch 11/32 - 170.4ms/batch - loss: 1.57458 - diff: 25.19mlTrain batch 12/32 - 176.0ms/batch - loss: 1.66912 - diff: 26.71mlTrain batch 13/32 - 175.9ms/batch - loss: 1.62890 - diff: 26.06mlTrain batch 14/32 - 188.5ms/batch - loss: 1.65181 - diff: 26.43mlTrain batch 15/32 - 170.5ms/batch - loss: 1.64184 - diff: 26.27mlTrain batch 16/32 - 186.5ms/batch - loss: 1.59662 - diff: 25.55mlTrain batch 17/32 - 178.2ms/batch - loss: 1.56069 - diff: 24.97mlTrain batch 18/32 - 188.7ms/batch - loss: 1.61033 - diff: 25.77mlTrain batch 19/32 - 170.8ms/batch - loss: 1.62269 - diff: 25.96mlTrain batch 20/32 - 188.1ms/batch - loss: 1.58836 - diff: 25.41mlTrain batch 21/32 - 176.2ms/batch - loss: 1.56777 - diff: 25.08mlTrain batch 22/32 - 196.3ms/batch - loss: 1.58018 - diff: 25.28mlTrain batch 23/32 - 174.9ms/batch - loss: 1.59240 - diff: 25.48mlTrain batch 24/32 - 190.0ms/batch - loss: 1.57074 - diff: 25.13mlTrain batch 25/32 - 170.5ms/batch - loss: 1.58433 - diff: 25.35mlTrain batch 26/32 - 171.1ms/batch - loss: 1.60575 - diff: 25.69mlTrain batch 27/32 - 172.7ms/batch - loss: 1.63377 - diff: 26.14mlTrain batch 28/32 - 173.0ms/batch - loss: 1.67132 - diff: 26.74mlTrain batch 29/32 - 185.4ms/batch - loss: 1.67580 - diff: 26.81mlTrain batch 30/32 - 170.6ms/batch - loss: 1.67815 - diff: 26.85mlTrain batch 31/32 - 170.2ms/batch - loss: 1.68965 - diff: 27.03mlTrain batch 32/32 - 52.5ms/batch - loss: 1.72320 - diff: 27.01mlTrain batch 32/32 - 16.6s 52.5ms/batch - loss: 1.72320 - diff: 27.01ml
Test 1.5s: val_loss: 1.61621 - diff: 25.18ml

Epoch 15: current best loss = 1.59920, at epoch 9
Train batch 1/32 - 184.5ms/batch - loss: 1.28324 - diff: 20.53mlTrain batch 2/32 - 170.9ms/batch - loss: 1.49697 - diff: 23.95mlTrain batch 3/32 - 170.3ms/batch - loss: 1.68634 - diff: 26.98mlTrain batch 4/32 - 170.7ms/batch - loss: 1.51888 - diff: 24.30mlTrain batch 5/32 - 175.8ms/batch - loss: 1.55205 - diff: 24.83mlTrain batch 6/32 - 185.5ms/batch - loss: 1.59526 - diff: 25.52mlTrain batch 7/32 - 170.4ms/batch - loss: 1.57693 - diff: 25.23mlTrain batch 8/32 - 173.5ms/batch - loss: 1.54684 - diff: 24.75mlTrain batch 9/32 - 170.2ms/batch - loss: 1.66354 - diff: 26.62mlTrain batch 10/32 - 170.7ms/batch - loss: 1.64102 - diff: 26.26mlTrain batch 11/32 - 184.6ms/batch - loss: 1.61048 - diff: 25.77mlTrain batch 12/32 - 170.7ms/batch - loss: 1.62277 - diff: 25.96mlTrain batch 13/32 - 170.4ms/batch - loss: 1.60548 - diff: 25.69mlTrain batch 14/32 - 175.5ms/batch - loss: 1.58958 - diff: 25.43mlTrain batch 15/32 - 187.5ms/batch - loss: 1.55690 - diff: 24.91mlTrain batch 16/32 - 171.0ms/batch - loss: 1.61525 - diff: 25.84mlTrain batch 17/32 - 185.5ms/batch - loss: 1.59256 - diff: 25.48mlTrain batch 18/32 - 170.8ms/batch - loss: 1.57760 - diff: 25.24mlTrain batch 19/32 - 197.4ms/batch - loss: 1.61741 - diff: 25.88mlTrain batch 20/32 - 187.1ms/batch - loss: 1.61324 - diff: 25.81mlTrain batch 21/32 - 170.4ms/batch - loss: 1.63827 - diff: 26.21mlTrain batch 22/32 - 174.3ms/batch - loss: 1.60409 - diff: 25.67mlTrain batch 23/32 - 170.7ms/batch - loss: 1.60524 - diff: 25.68mlTrain batch 24/32 - 170.2ms/batch - loss: 1.65848 - diff: 26.54mlTrain batch 25/32 - 186.0ms/batch - loss: 1.68417 - diff: 26.95mlTrain batch 26/32 - 170.7ms/batch - loss: 1.66929 - diff: 26.71mlTrain batch 27/32 - 171.3ms/batch - loss: 1.67245 - diff: 26.76mlTrain batch 28/32 - 175.5ms/batch - loss: 1.66043 - diff: 26.57mlTrain batch 29/32 - 175.4ms/batch - loss: 1.65623 - diff: 26.50mlTrain batch 30/32 - 170.9ms/batch - loss: 1.63749 - diff: 26.20mlTrain batch 31/32 - 170.4ms/batch - loss: 1.69132 - diff: 27.06mlTrain batch 32/32 - 52.7ms/batch - loss: 1.75611 - diff: 27.16mlTrain batch 32/32 - 17.6s 52.7ms/batch - loss: 1.75611 - diff: 27.16ml
Test 1.5s: val_loss: 1.58178 - diff: 24.56ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Systole_WideResNet50_0_Adam-0.001_MAE_DA3_best

Epoch 16: current best loss = 1.58178, at epoch 15
Train batch 1/32 - 184.3ms/batch - loss: 1.14618 - diff: 18.34mlTrain batch 2/32 - 171.4ms/batch - loss: 1.54317 - diff: 24.69mlTrain batch 3/32 - 170.1ms/batch - loss: 1.61252 - diff: 25.80mlTrain batch 4/32 - 176.7ms/batch - loss: 1.74344 - diff: 27.90mlTrain batch 5/32 - 170.3ms/batch - loss: 1.65967 - diff: 26.55mlTrain batch 6/32 - 192.4ms/batch - loss: 1.68399 - diff: 26.94mlTrain batch 7/32 - 170.4ms/batch - loss: 1.82446 - diff: 29.19mlTrain batch 8/32 - 170.8ms/batch - loss: 1.74242 - diff: 27.88mlTrain batch 9/32 - 170.5ms/batch - loss: 1.85633 - diff: 29.70mlTrain batch 10/32 - 170.6ms/batch - loss: 1.84917 - diff: 29.59mlTrain batch 11/32 - 170.2ms/batch - loss: 1.76035 - diff: 28.17mlTrain batch 12/32 - 171.1ms/batch - loss: 1.78349 - diff: 28.54mlTrain batch 13/32 - 170.3ms/batch - loss: 1.81953 - diff: 29.11mlTrain batch 14/32 - 170.5ms/batch - loss: 1.83400 - diff: 29.34mlTrain batch 15/32 - 170.6ms/batch - loss: 1.81207 - diff: 28.99mlTrain batch 16/32 - 179.5ms/batch - loss: 1.76413 - diff: 28.23mlTrain batch 17/32 - 170.4ms/batch - loss: 1.76424 - diff: 28.23mlTrain batch 18/32 - 178.9ms/batch - loss: 1.72662 - diff: 27.63mlTrain batch 19/32 - 170.5ms/batch - loss: 1.69813 - diff: 27.17mlTrain batch 20/32 - 170.6ms/batch - loss: 1.69394 - diff: 27.10mlTrain batch 21/32 - 170.3ms/batch - loss: 1.68867 - diff: 27.02mlTrain batch 22/32 - 182.0ms/batch - loss: 1.65622 - diff: 26.50mlTrain batch 23/32 - 184.2ms/batch - loss: 1.62385 - diff: 25.98mlTrain batch 24/32 - 171.8ms/batch - loss: 1.62229 - diff: 25.96mlTrain batch 25/32 - 171.3ms/batch - loss: 1.64076 - diff: 26.25mlTrain batch 26/32 - 179.3ms/batch - loss: 1.69359 - diff: 27.10mlTrain batch 27/32 - 175.4ms/batch - loss: 1.68110 - diff: 26.90mlTrain batch 28/32 - 170.5ms/batch - loss: 1.68426 - diff: 26.95mlTrain batch 29/32 - 176.6ms/batch - loss: 1.70337 - diff: 27.25mlTrain batch 30/32 - 174.0ms/batch - loss: 1.69389 - diff: 27.10mlTrain batch 31/32 - 170.3ms/batch - loss: 1.69303 - diff: 27.09mlTrain batch 32/32 - 52.5ms/batch - loss: 1.71634 - diff: 27.02mlTrain batch 32/32 - 16.6s 52.5ms/batch - loss: 1.71634 - diff: 27.02ml
Test 1.4s: val_loss: 1.53999 - diff: 24.11ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Systole_WideResNet50_0_Adam-0.001_MAE_DA3_best

Epoch 17: current best loss = 1.53999, at epoch 16
Train batch 1/32 - 184.7ms/batch - loss: 1.47219 - diff: 23.56mlTrain batch 2/32 - 183.0ms/batch - loss: 1.74381 - diff: 27.90mlTrain batch 3/32 - 170.5ms/batch - loss: 1.69362 - diff: 27.10mlTrain batch 4/32 - 176.3ms/batch - loss: 1.74472 - diff: 27.92mlTrain batch 5/32 - 170.5ms/batch - loss: 1.83963 - diff: 29.43mlTrain batch 6/32 - 170.3ms/batch - loss: 1.92505 - diff: 30.80mlTrain batch 7/32 - 170.5ms/batch - loss: 1.77921 - diff: 28.47mlTrain batch 8/32 - 174.8ms/batch - loss: 1.71477 - diff: 27.44mlTrain batch 9/32 - 172.3ms/batch - loss: 1.73849 - diff: 27.82mlTrain batch 10/32 - 170.5ms/batch - loss: 1.75933 - diff: 28.15mlTrain batch 11/32 - 170.2ms/batch - loss: 1.71822 - diff: 27.49mlTrain batch 12/32 - 172.0ms/batch - loss: 1.81534 - diff: 29.05mlTrain batch 13/32 - 170.3ms/batch - loss: 1.80683 - diff: 28.91mlTrain batch 14/32 - 170.9ms/batch - loss: 1.77415 - diff: 28.39mlTrain batch 15/32 - 170.4ms/batch - loss: 1.77955 - diff: 28.47mlTrain batch 16/32 - 170.3ms/batch - loss: 1.77612 - diff: 28.42mlTrain batch 17/32 - 170.5ms/batch - loss: 1.74693 - diff: 27.95mlTrain batch 18/32 - 170.7ms/batch - loss: 1.76125 - diff: 28.18mlTrain batch 19/32 - 170.4ms/batch - loss: 1.79049 - diff: 28.65mlTrain batch 20/32 - 179.6ms/batch - loss: 1.79227 - diff: 28.68mlTrain batch 21/32 - 170.2ms/batch - loss: 1.79268 - diff: 28.68mlTrain batch 22/32 - 170.7ms/batch - loss: 1.76794 - diff: 28.29mlTrain batch 23/32 - 170.4ms/batch - loss: 1.73856 - diff: 27.82mlTrain batch 24/32 - 170.9ms/batch - loss: 1.76145 - diff: 28.18mlTrain batch 25/32 - 170.1ms/batch - loss: 1.75965 - diff: 28.15mlTrain batch 26/32 - 170.6ms/batch - loss: 1.73689 - diff: 27.79mlTrain batch 27/32 - 170.3ms/batch - loss: 1.74797 - diff: 27.97mlTrain batch 28/32 - 170.5ms/batch - loss: 1.72323 - diff: 27.57mlTrain batch 29/32 - 170.4ms/batch - loss: 1.69833 - diff: 27.17mlTrain batch 30/32 - 170.5ms/batch - loss: 1.71177 - diff: 27.39mlTrain batch 31/32 - 177.2ms/batch - loss: 1.69308 - diff: 27.09mlTrain batch 32/32 - 52.5ms/batch - loss: 1.72168 - diff: 27.04mlTrain batch 32/32 - 16.7s 52.5ms/batch - loss: 1.72168 - diff: 27.04ml
Test 1.6s: val_loss: 1.58823 - diff: 24.30ml

Epoch 18: current best loss = 1.53999, at epoch 16
Train batch 1/32 - 170.5ms/batch - loss: 1.76498 - diff: 28.24mlTrain batch 2/32 - 170.9ms/batch - loss: 1.60137 - diff: 25.62mlTrain batch 3/32 - 180.9ms/batch - loss: 1.59698 - diff: 25.55mlTrain batch 4/32 - 170.4ms/batch - loss: 1.44931 - diff: 23.19mlTrain batch 5/32 - 170.3ms/batch - loss: 1.45978 - diff: 23.36mlTrain batch 6/32 - 170.7ms/batch - loss: 1.53948 - diff: 24.63mlTrain batch 7/32 - 170.6ms/batch - loss: 1.46711 - diff: 23.47mlTrain batch 8/32 - 181.7ms/batch - loss: 1.39097 - diff: 22.26mlTrain batch 9/32 - 180.7ms/batch - loss: 1.39508 - diff: 22.32mlTrain batch 10/32 - 170.3ms/batch - loss: 1.40843 - diff: 22.53mlTrain batch 11/32 - 171.0ms/batch - loss: 1.42540 - diff: 22.81mlTrain batch 12/32 - 170.8ms/batch - loss: 1.46078 - diff: 23.37mlTrain batch 13/32 - 170.5ms/batch - loss: 1.44682 - diff: 23.15mlTrain batch 14/32 - 170.2ms/batch - loss: 1.53734 - diff: 24.60mlTrain batch 15/32 - 170.5ms/batch - loss: 1.51435 - diff: 24.23mlTrain batch 16/32 - 171.0ms/batch - loss: 1.50634 - diff: 24.10mlTrain batch 17/32 - 185.3ms/batch - loss: 1.47633 - diff: 23.62mlTrain batch 18/32 - 170.9ms/batch - loss: 1.49275 - diff: 23.88mlTrain batch 19/32 - 170.4ms/batch - loss: 1.47045 - diff: 23.53mlTrain batch 20/32 - 173.0ms/batch - loss: 1.49933 - diff: 23.99mlTrain batch 21/32 - 170.4ms/batch - loss: 1.56037 - diff: 24.97mlTrain batch 22/32 - 170.9ms/batch - loss: 1.57318 - diff: 25.17mlTrain batch 23/32 - 170.0ms/batch - loss: 1.57684 - diff: 25.23mlTrain batch 24/32 - 170.8ms/batch - loss: 1.58237 - diff: 25.32mlTrain batch 25/32 - 170.6ms/batch - loss: 1.63905 - diff: 26.22mlTrain batch 26/32 - 170.5ms/batch - loss: 1.67594 - diff: 26.81mlTrain batch 27/32 - 170.9ms/batch - loss: 1.65786 - diff: 26.53mlTrain batch 28/32 - 170.5ms/batch - loss: 1.64221 - diff: 26.28mlTrain batch 29/32 - 170.3ms/batch - loss: 1.66741 - diff: 26.68mlTrain batch 30/32 - 185.8ms/batch - loss: 1.65224 - diff: 26.44mlTrain batch 31/32 - 169.7ms/batch - loss: 1.65016 - diff: 26.40mlTrain batch 32/32 - 52.5ms/batch - loss: 1.74767 - diff: 26.63mlTrain batch 32/32 - 16.3s 52.5ms/batch - loss: 1.74767 - diff: 26.63ml
Test 1.5s: val_loss: 1.67664 - diff: 25.08ml

Epoch 19: current best loss = 1.53999, at epoch 16
Train batch 1/32 - 170.5ms/batch - loss: 1.43372 - diff: 22.94mlTrain batch 2/32 - 170.5ms/batch - loss: 1.63236 - diff: 26.12mlTrain batch 3/32 - 170.4ms/batch - loss: 1.38365 - diff: 22.14mlTrain batch 4/32 - 170.8ms/batch - loss: 1.62585 - diff: 26.01mlTrain batch 5/32 - 179.3ms/batch - loss: 1.61909 - diff: 25.91mlTrain batch 6/32 - 170.6ms/batch - loss: 1.55453 - diff: 24.87mlTrain batch 7/32 - 170.4ms/batch - loss: 1.55415 - diff: 24.87mlTrain batch 8/32 - 170.3ms/batch - loss: 1.59142 - diff: 25.46mlTrain batch 9/32 - 180.9ms/batch - loss: 1.58915 - diff: 25.43mlTrain batch 10/32 - 170.6ms/batch - loss: 1.54729 - diff: 24.76mlTrain batch 11/32 - 181.0ms/batch - loss: 1.59514 - diff: 25.52mlTrain batch 12/32 - 170.7ms/batch - loss: 1.60022 - diff: 25.60mlTrain batch 13/32 - 170.3ms/batch - loss: 1.58337 - diff: 25.33mlTrain batch 14/32 - 170.9ms/batch - loss: 1.56011 - diff: 24.96mlTrain batch 15/32 - 173.9ms/batch - loss: 1.59014 - diff: 25.44mlTrain batch 16/32 - 174.0ms/batch - loss: 1.58053 - diff: 25.29mlTrain batch 17/32 - 170.7ms/batch - loss: 1.60570 - diff: 25.69mlTrain batch 18/32 - 181.4ms/batch - loss: 1.63139 - diff: 26.10mlTrain batch 19/32 - 175.1ms/batch - loss: 1.60693 - diff: 25.71mlTrain batch 20/32 - 170.6ms/batch - loss: 1.61256 - diff: 25.80mlTrain batch 21/32 - 170.4ms/batch - loss: 1.67563 - diff: 26.81mlTrain batch 22/32 - 170.6ms/batch - loss: 1.65016 - diff: 26.40mlTrain batch 23/32 - 170.4ms/batch - loss: 1.62382 - diff: 25.98mlTrain batch 24/32 - 171.7ms/batch - loss: 1.63174 - diff: 26.11mlTrain batch 25/32 - 179.5ms/batch - loss: 1.62453 - diff: 25.99mlTrain batch 26/32 - 170.3ms/batch - loss: 1.62682 - diff: 26.03mlTrain batch 27/32 - 186.9ms/batch - loss: 1.61381 - diff: 25.82mlTrain batch 28/32 - 170.4ms/batch - loss: 1.61648 - diff: 25.86mlTrain batch 29/32 - 170.6ms/batch - loss: 1.60609 - diff: 25.70mlTrain batch 30/32 - 170.7ms/batch - loss: 1.61401 - diff: 25.82mlTrain batch 31/32 - 170.5ms/batch - loss: 1.67370 - diff: 26.78mlTrain batch 32/32 - 52.5ms/batch - loss: 1.71493 - diff: 26.78mlTrain batch 32/32 - 17.0s 52.5ms/batch - loss: 1.71493 - diff: 26.78ml
Test 1.6s: val_loss: 1.56468 - diff: 24.02ml

Epoch 20: current best loss = 1.53999, at epoch 16
Train batch 1/32 - 172.7ms/batch - loss: 1.54568 - diff: 24.73mlTrain batch 2/32 - 170.7ms/batch - loss: 1.37741 - diff: 22.04mlTrain batch 3/32 - 170.7ms/batch - loss: 1.33197 - diff: 21.31mlTrain batch 4/32 - 174.4ms/batch - loss: 1.66923 - diff: 26.71mlTrain batch 5/32 - 189.3ms/batch - loss: 1.75022 - diff: 28.00mlTrain batch 6/32 - 170.6ms/batch - loss: 1.71159 - diff: 27.39mlTrain batch 7/32 - 170.7ms/batch - loss: 1.61597 - diff: 25.86mlTrain batch 8/32 - 170.6ms/batch - loss: 1.60392 - diff: 25.66mlTrain batch 9/32 - 170.3ms/batch - loss: 1.56411 - diff: 25.03mlTrain batch 10/32 - 170.7ms/batch - loss: 1.60166 - diff: 25.63mlTrain batch 11/32 - 170.6ms/batch - loss: 1.70983 - diff: 27.36mlTrain batch 12/32 - 170.8ms/batch - loss: 1.66061 - diff: 26.57mlTrain batch 13/32 - 170.5ms/batch - loss: 1.65509 - diff: 26.48mlTrain batch 14/32 - 198.3ms/batch - loss: 1.68225 - diff: 26.92mlTrain batch 15/32 - 184.0ms/batch - loss: 1.66010 - diff: 26.56mlTrain batch 16/32 - 194.3ms/batch - loss: 1.67629 - diff: 26.82mlTrain batch 17/32 - 170.5ms/batch - loss: 1.67832 - diff: 26.85mlTrain batch 18/32 - 173.9ms/batch - loss: 1.74247 - diff: 27.88mlTrain batch 19/32 - 170.6ms/batch - loss: 1.73448 - diff: 27.75mlTrain batch 20/32 - 171.0ms/batch - loss: 1.74009 - diff: 27.84mlTrain batch 21/32 - 170.6ms/batch - loss: 1.70741 - diff: 27.32mlTrain batch 22/32 - 187.3ms/batch - loss: 1.71951 - diff: 27.51mlTrain batch 23/32 - 170.4ms/batch - loss: 1.72119 - diff: 27.54mlTrain batch 24/32 - 170.7ms/batch - loss: 1.71217 - diff: 27.39mlTrain batch 25/32 - 170.6ms/batch - loss: 1.69852 - diff: 27.18mlTrain batch 26/32 - 170.9ms/batch - loss: 1.68933 - diff: 27.03mlTrain batch 27/32 - 171.1ms/batch - loss: 1.66287 - diff: 26.61mlTrain batch 28/32 - 175.4ms/batch - loss: 1.65994 - diff: 26.56mlTrain batch 29/32 - 170.5ms/batch - loss: 1.66672 - diff: 26.67mlTrain batch 30/32 - 174.1ms/batch - loss: 1.66607 - diff: 26.66mlTrain batch 31/32 - 170.4ms/batch - loss: 1.64428 - diff: 26.31mlTrain batch 32/32 - 52.6ms/batch - loss: 1.76265 - diff: 26.62mlTrain batch 32/32 - 17.5s 52.6ms/batch - loss: 1.76265 - diff: 26.62ml
Test 1.6s: val_loss: 1.55740 - diff: 23.78ml

Epoch 21: current best loss = 1.53999, at epoch 16
Train batch 1/32 - 170.6ms/batch - loss: 1.63382 - diff: 26.14mlTrain batch 2/32 - 171.5ms/batch - loss: 1.86364 - diff: 29.82mlTrain batch 3/32 - 170.5ms/batch - loss: 1.78873 - diff: 28.62mlTrain batch 4/32 - 170.7ms/batch - loss: 1.79512 - diff: 28.72mlTrain batch 5/32 - 170.4ms/batch - loss: 1.78296 - diff: 28.53mlTrain batch 6/32 - 171.0ms/batch - loss: 1.79515 - diff: 28.72mlTrain batch 7/32 - 179.7ms/batch - loss: 1.77362 - diff: 28.38mlTrain batch 8/32 - 170.8ms/batch - loss: 1.80957 - diff: 28.95mlTrain batch 9/32 - 189.7ms/batch - loss: 1.76125 - diff: 28.18mlTrain batch 10/32 - 181.9ms/batch - loss: 1.70587 - diff: 27.29mlTrain batch 11/32 - 173.1ms/batch - loss: 1.71637 - diff: 27.46mlTrain batch 12/32 - 170.8ms/batch - loss: 1.67578 - diff: 26.81mlTrain batch 13/32 - 170.5ms/batch - loss: 1.69939 - diff: 27.19mlTrain batch 14/32 - 176.5ms/batch - loss: 1.66861 - diff: 26.70mlTrain batch 15/32 - 170.4ms/batch - loss: 1.64777 - diff: 26.36mlTrain batch 16/32 - 171.0ms/batch - loss: 1.63547 - diff: 26.17mlTrain batch 17/32 - 174.0ms/batch - loss: 1.62380 - diff: 25.98mlTrain batch 18/32 - 170.9ms/batch - loss: 1.59920 - diff: 25.59mlTrain batch 19/32 - 170.5ms/batch - loss: 1.59935 - diff: 25.59mlTrain batch 20/32 - 171.1ms/batch - loss: 1.57649 - diff: 25.22mlTrain batch 21/32 - 170.6ms/batch - loss: 1.65448 - diff: 26.47mlTrain batch 22/32 - 170.9ms/batch - loss: 1.65519 - diff: 26.48mlTrain batch 23/32 - 173.5ms/batch - loss: 1.64788 - diff: 26.37mlTrain batch 24/32 - 175.7ms/batch - loss: 1.63862 - diff: 26.22mlTrain batch 25/32 - 170.5ms/batch - loss: 1.63678 - diff: 26.19mlTrain batch 26/32 - 177.4ms/batch - loss: 1.62238 - diff: 25.96mlTrain batch 27/32 - 170.3ms/batch - loss: 1.64190 - diff: 26.27mlTrain batch 28/32 - 171.3ms/batch - loss: 1.62698 - diff: 26.03mlTrain batch 29/32 - 170.5ms/batch - loss: 1.61777 - diff: 25.88mlTrain batch 30/32 - 172.9ms/batch - loss: 1.62258 - diff: 25.96mlTrain batch 31/32 - 170.7ms/batch - loss: 1.66154 - diff: 26.58mlTrain batch 32/32 - 59.9ms/batch - loss: 1.76065 - diff: 26.82mlTrain batch 32/32 - 17.3s 59.9ms/batch - loss: 1.76065 - diff: 26.82ml
Test 1.4s: val_loss: 1.53536 - diff: 23.90ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Systole_WideResNet50_0_Adam-0.001_MAE_DA3_best

Epoch 22: current best loss = 1.53536, at epoch 21
Train batch 1/32 - 179.2ms/batch - loss: 0.97928 - diff: 15.67mlTrain batch 2/32 - 170.7ms/batch - loss: 1.24183 - diff: 19.87mlTrain batch 3/32 - 170.6ms/batch - loss: 1.46047 - diff: 23.37mlTrain batch 4/32 - 179.1ms/batch - loss: 1.41039 - diff: 22.57mlTrain batch 5/32 - 170.3ms/batch - loss: 1.32853 - diff: 21.26mlTrain batch 6/32 - 185.2ms/batch - loss: 1.44771 - diff: 23.16mlTrain batch 7/32 - 171.0ms/batch - loss: 1.40073 - diff: 22.41mlTrain batch 8/32 - 183.5ms/batch - loss: 1.52487 - diff: 24.40mlTrain batch 9/32 - 175.8ms/batch - loss: 1.48166 - diff: 23.71mlTrain batch 10/32 - 170.8ms/batch - loss: 1.52573 - diff: 24.41mlTrain batch 11/32 - 171.8ms/batch - loss: 1.50978 - diff: 24.16mlTrain batch 12/32 - 179.7ms/batch - loss: 1.49423 - diff: 23.91mlTrain batch 13/32 - 170.6ms/batch - loss: 1.53071 - diff: 24.49mlTrain batch 14/32 - 171.1ms/batch - loss: 1.49736 - diff: 23.96mlTrain batch 15/32 - 170.7ms/batch - loss: 1.51247 - diff: 24.20mlTrain batch 16/32 - 171.1ms/batch - loss: 1.55410 - diff: 24.87mlTrain batch 17/32 - 170.5ms/batch - loss: 1.66203 - diff: 26.59mlTrain batch 18/32 - 170.9ms/batch - loss: 1.65790 - diff: 26.53mlTrain batch 19/32 - 170.7ms/batch - loss: 1.64183 - diff: 26.27mlTrain batch 20/32 - 170.6ms/batch - loss: 1.67139 - diff: 26.74mlTrain batch 21/32 - 170.5ms/batch - loss: 1.66115 - diff: 26.58mlTrain batch 22/32 - 171.1ms/batch - loss: 1.66140 - diff: 26.58mlTrain batch 23/32 - 186.1ms/batch - loss: 1.68406 - diff: 26.94mlTrain batch 24/32 - 171.0ms/batch - loss: 1.66953 - diff: 26.71mlTrain batch 25/32 - 170.5ms/batch - loss: 1.69450 - diff: 27.11mlTrain batch 26/32 - 171.1ms/batch - loss: 1.68429 - diff: 26.95mlTrain batch 27/32 - 170.7ms/batch - loss: 1.69872 - diff: 27.18mlTrain batch 28/32 - 177.9ms/batch - loss: 1.70070 - diff: 27.21mlTrain batch 29/32 - 170.6ms/batch - loss: 1.68566 - diff: 26.97mlTrain batch 30/32 - 171.0ms/batch - loss: 1.66840 - diff: 26.69mlTrain batch 31/32 - 170.6ms/batch - loss: 1.67904 - diff: 26.86mlTrain batch 32/32 - 52.8ms/batch - loss: 1.68368 - diff: 26.72mlTrain batch 32/32 - 17.1s 52.8ms/batch - loss: 1.68368 - diff: 26.72ml
Test 1.5s: val_loss: 1.57767 - diff: 24.23ml

Epoch 23: current best loss = 1.53536, at epoch 21
Train batch 1/32 - 170.6ms/batch - loss: 1.75251 - diff: 28.04mlTrain batch 2/32 - 171.2ms/batch - loss: 1.73873 - diff: 27.82mlTrain batch 3/32 - 170.6ms/batch - loss: 1.67379 - diff: 26.78mlTrain batch 4/32 - 178.9ms/batch - loss: 1.73775 - diff: 27.80mlTrain batch 5/32 - 179.8ms/batch - loss: 1.61858 - diff: 25.90mlTrain batch 6/32 - 172.0ms/batch - loss: 1.74640 - diff: 27.94mlTrain batch 7/32 - 170.6ms/batch - loss: 1.77190 - diff: 28.35mlTrain batch 8/32 - 179.8ms/batch - loss: 1.73081 - diff: 27.69mlTrain batch 9/32 - 172.1ms/batch - loss: 1.73334 - diff: 27.73mlTrain batch 10/32 - 170.9ms/batch - loss: 1.72529 - diff: 27.60mlTrain batch 11/32 - 170.5ms/batch - loss: 1.74047 - diff: 27.85mlTrain batch 12/32 - 171.2ms/batch - loss: 1.74489 - diff: 27.92mlTrain batch 13/32 - 170.6ms/batch - loss: 1.70684 - diff: 27.31mlTrain batch 14/32 - 170.8ms/batch - loss: 1.69443 - diff: 27.11mlTrain batch 15/32 - 179.9ms/batch - loss: 1.65488 - diff: 26.48mlTrain batch 16/32 - 171.0ms/batch - loss: 1.75856 - diff: 28.14mlTrain batch 17/32 - 170.7ms/batch - loss: 1.72849 - diff: 27.66mlTrain batch 18/32 - 177.4ms/batch - loss: 1.70645 - diff: 27.30mlTrain batch 19/32 - 170.8ms/batch - loss: 1.72255 - diff: 27.56mlTrain batch 20/32 - 178.1ms/batch - loss: 1.69753 - diff: 27.16mlTrain batch 21/32 - 185.3ms/batch - loss: 1.66167 - diff: 26.59mlTrain batch 22/32 - 171.0ms/batch - loss: 1.65577 - diff: 26.49mlTrain batch 23/32 - 184.9ms/batch - loss: 1.70480 - diff: 27.28mlTrain batch 24/32 - 171.0ms/batch - loss: 1.74052 - diff: 27.85mlTrain batch 25/32 - 170.5ms/batch - loss: 1.72311 - diff: 27.57mlTrain batch 26/32 - 176.7ms/batch - loss: 1.71858 - diff: 27.50mlTrain batch 27/32 - 170.6ms/batch - loss: 1.71526 - diff: 27.44mlTrain batch 28/32 - 175.0ms/batch - loss: 1.69552 - diff: 27.13mlTrain batch 29/32 - 170.6ms/batch - loss: 1.67935 - diff: 26.87mlTrain batch 30/32 - 169.7ms/batch - loss: 1.68224 - diff: 26.92mlTrain batch 31/32 - 170.6ms/batch - loss: 1.67633 - diff: 26.82mlTrain batch 32/32 - 52.5ms/batch - loss: 1.70345 - diff: 26.77mlTrain batch 32/32 - 17.9s 52.5ms/batch - loss: 1.70345 - diff: 26.77ml
Test 1.4s: val_loss: 1.49568 - diff: 23.48ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Systole_WideResNet50_0_Adam-0.001_MAE_DA3_best

Epoch 24: current best loss = 1.49568, at epoch 23
Train batch 1/32 - 180.9ms/batch - loss: 2.06843 - diff: 33.09mlTrain batch 2/32 - 175.1ms/batch - loss: 1.67439 - diff: 26.79mlTrain batch 3/32 - 170.2ms/batch - loss: 1.52313 - diff: 24.37mlTrain batch 4/32 - 170.3ms/batch - loss: 1.42814 - diff: 22.85mlTrain batch 5/32 - 176.2ms/batch - loss: 1.48696 - diff: 23.79mlTrain batch 6/32 - 170.6ms/batch - loss: 1.52964 - diff: 24.47mlTrain batch 7/32 - 170.5ms/batch - loss: 1.40317 - diff: 22.45mlTrain batch 8/32 - 171.2ms/batch - loss: 1.34695 - diff: 21.55mlTrain batch 9/32 - 171.3ms/batch - loss: 1.44132 - diff: 23.06mlTrain batch 10/32 - 170.9ms/batch - loss: 1.45100 - diff: 23.22mlTrain batch 11/32 - 170.5ms/batch - loss: 1.44628 - diff: 23.14mlTrain batch 12/32 - 172.5ms/batch - loss: 1.44730 - diff: 23.16mlTrain batch 13/32 - 185.3ms/batch - loss: 1.42343 - diff: 22.77mlTrain batch 14/32 - 171.0ms/batch - loss: 1.55428 - diff: 24.87mlTrain batch 15/32 - 170.5ms/batch - loss: 1.60021 - diff: 25.60mlTrain batch 16/32 - 170.7ms/batch - loss: 1.60371 - diff: 25.66mlTrain batch 17/32 - 170.4ms/batch - loss: 1.66083 - diff: 26.57mlTrain batch 18/32 - 172.5ms/batch - loss: 1.63043 - diff: 26.09mlTrain batch 19/32 - 170.5ms/batch - loss: 1.60483 - diff: 25.68mlTrain batch 20/32 - 170.6ms/batch - loss: 1.58670 - diff: 25.39mlTrain batch 21/32 - 170.5ms/batch - loss: 1.63186 - diff: 26.11mlTrain batch 22/32 - 170.9ms/batch - loss: 1.63165 - diff: 26.11mlTrain batch 23/32 - 170.6ms/batch - loss: 1.65950 - diff: 26.55mlTrain batch 24/32 - 197.5ms/batch - loss: 1.66123 - diff: 26.58mlTrain batch 25/32 - 170.8ms/batch - loss: 1.62564 - diff: 26.01mlTrain batch 26/32 - 178.9ms/batch - loss: 1.63018 - diff: 26.08mlTrain batch 27/32 - 170.6ms/batch - loss: 1.64105 - diff: 26.26mlTrain batch 28/32 - 170.6ms/batch - loss: 1.66029 - diff: 26.56mlTrain batch 29/32 - 183.0ms/batch - loss: 1.68660 - diff: 26.99mlTrain batch 30/32 - 179.4ms/batch - loss: 1.67200 - diff: 26.75mlTrain batch 31/32 - 178.2ms/batch - loss: 1.65127 - diff: 26.42mlTrain batch 32/32 - 52.8ms/batch - loss: 1.71734 - diff: 26.53mlTrain batch 32/32 - 16.2s 52.8ms/batch - loss: 1.71734 - diff: 26.53ml
Test 1.4s: val_loss: 1.58773 - diff: 24.74ml

Epoch 25: current best loss = 1.49568, at epoch 23
Train batch 1/32 - 177.0ms/batch - loss: 1.68264 - diff: 26.92mlTrain batch 2/32 - 170.7ms/batch - loss: 1.56710 - diff: 25.07mlTrain batch 3/32 - 170.7ms/batch - loss: 1.58999 - diff: 25.44mlTrain batch 4/32 - 179.0ms/batch - loss: 1.53839 - diff: 24.61mlTrain batch 5/32 - 170.5ms/batch - loss: 1.60780 - diff: 25.72mlTrain batch 6/32 - 170.7ms/batch - loss: 1.61010 - diff: 25.76mlTrain batch 7/32 - 177.8ms/batch - loss: 1.58308 - diff: 25.33mlTrain batch 8/32 - 170.6ms/batch - loss: 1.53696 - diff: 24.59mlTrain batch 9/32 - 173.4ms/batch - loss: 1.58261 - diff: 25.32mlTrain batch 10/32 - 170.2ms/batch - loss: 1.50521 - diff: 24.08mlTrain batch 11/32 - 170.6ms/batch - loss: 1.54106 - diff: 24.66mlTrain batch 12/32 - 170.7ms/batch - loss: 1.51903 - diff: 24.30mlTrain batch 13/32 - 170.5ms/batch - loss: 1.52396 - diff: 24.38mlTrain batch 14/32 - 176.0ms/batch - loss: 1.49869 - diff: 23.98mlTrain batch 15/32 - 170.7ms/batch - loss: 1.50367 - diff: 24.06mlTrain batch 16/32 - 170.5ms/batch - loss: 1.51456 - diff: 24.23mlTrain batch 17/32 - 170.5ms/batch - loss: 1.52008 - diff: 24.32mlTrain batch 18/32 - 170.6ms/batch - loss: 1.49621 - diff: 23.94mlTrain batch 19/32 - 180.8ms/batch - loss: 1.50525 - diff: 24.08mlTrain batch 20/32 - 170.4ms/batch - loss: 1.52405 - diff: 24.38mlTrain batch 21/32 - 170.7ms/batch - loss: 1.50971 - diff: 24.16mlTrain batch 22/32 - 170.9ms/batch - loss: 1.50552 - diff: 24.09mlTrain batch 23/32 - 170.7ms/batch - loss: 1.53291 - diff: 24.53mlTrain batch 24/32 - 170.7ms/batch - loss: 1.57825 - diff: 25.25mlTrain batch 25/32 - 170.3ms/batch - loss: 1.55575 - diff: 24.89mlTrain batch 26/32 - 170.5ms/batch - loss: 1.57023 - diff: 25.12mlTrain batch 27/32 - 170.7ms/batch - loss: 1.55945 - diff: 24.95mlTrain batch 28/32 - 180.4ms/batch - loss: 1.64544 - diff: 26.33mlTrain batch 29/32 - 170.6ms/batch - loss: 1.64283 - diff: 26.29mlTrain batch 30/32 - 170.7ms/batch - loss: 1.63524 - diff: 26.16mlTrain batch 31/32 - 170.8ms/batch - loss: 1.64123 - diff: 26.26mlTrain batch 32/32 - 54.5ms/batch - loss: 1.64262 - diff: 26.11mlTrain batch 32/32 - 17.0s 54.5ms/batch - loss: 1.64262 - diff: 26.11ml
Test 1.5s: val_loss: 1.48807 - diff: 23.25ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Systole_WideResNet50_0_Adam-0.001_MAE_DA3_best

Epoch 26: current best loss = 1.48807, at epoch 25
Train batch 1/32 - 185.6ms/batch - loss: 1.06811 - diff: 17.09mlTrain batch 2/32 - 173.1ms/batch - loss: 1.10378 - diff: 17.66mlTrain batch 3/32 - 177.2ms/batch - loss: 1.06103 - diff: 16.98mlTrain batch 4/32 - 170.9ms/batch - loss: 1.12687 - diff: 18.03mlTrain batch 5/32 - 181.2ms/batch - loss: 1.30621 - diff: 20.90mlTrain batch 6/32 - 174.0ms/batch - loss: 1.29097 - diff: 20.66mlTrain batch 7/32 - 170.4ms/batch - loss: 1.39608 - diff: 22.34mlTrain batch 8/32 - 171.0ms/batch - loss: 1.40776 - diff: 22.52mlTrain batch 9/32 - 176.2ms/batch - loss: 1.34955 - diff: 21.59mlTrain batch 10/32 - 170.6ms/batch - loss: 1.37205 - diff: 21.95mlTrain batch 11/32 - 170.5ms/batch - loss: 1.40519 - diff: 22.48mlTrain batch 12/32 - 170.7ms/batch - loss: 1.42611 - diff: 22.82mlTrain batch 13/32 - 170.3ms/batch - loss: 1.43688 - diff: 22.99mlTrain batch 14/32 - 170.6ms/batch - loss: 1.40702 - diff: 22.51mlTrain batch 15/32 - 170.5ms/batch - loss: 1.42788 - diff: 22.85mlTrain batch 16/32 - 170.6ms/batch - loss: 1.48072 - diff: 23.69mlTrain batch 17/32 - 170.7ms/batch - loss: 1.53237 - diff: 24.52mlTrain batch 18/32 - 177.7ms/batch - loss: 1.53609 - diff: 24.58mlTrain batch 19/32 - 170.6ms/batch - loss: 1.54444 - diff: 24.71mlTrain batch 20/32 - 170.8ms/batch - loss: 1.53110 - diff: 24.50mlTrain batch 21/32 - 178.0ms/batch - loss: 1.52254 - diff: 24.36mlTrain batch 22/32 - 170.6ms/batch - loss: 1.56699 - diff: 25.07mlTrain batch 23/32 - 170.8ms/batch - loss: 1.59437 - diff: 25.51mlTrain batch 24/32 - 170.4ms/batch - loss: 1.59207 - diff: 25.47mlTrain batch 25/32 - 170.7ms/batch - loss: 1.67552 - diff: 26.81mlTrain batch 26/32 - 170.7ms/batch - loss: 1.69132 - diff: 27.06mlTrain batch 27/32 - 183.5ms/batch - loss: 1.65894 - diff: 26.54mlTrain batch 28/32 - 174.9ms/batch - loss: 1.64157 - diff: 26.27mlTrain batch 29/32 - 177.3ms/batch - loss: 1.65004 - diff: 26.40mlTrain batch 30/32 - 175.0ms/batch - loss: 1.64572 - diff: 26.33mlTrain batch 31/32 - 170.6ms/batch - loss: 1.68005 - diff: 26.88mlTrain batch 32/32 - 57.3ms/batch - loss: 1.72274 - diff: 26.89mlTrain batch 32/32 - 17.5s 57.3ms/batch - loss: 1.72274 - diff: 26.89ml
Test 1.4s: val_loss: 1.63241 - diff: 25.06ml

Epoch 27: current best loss = 1.48807, at epoch 25
Train batch 1/32 - 170.6ms/batch - loss: 1.76313 - diff: 28.21mlTrain batch 2/32 - 170.9ms/batch - loss: 1.69735 - diff: 27.16mlTrain batch 3/32 - 170.4ms/batch - loss: 1.70964 - diff: 27.35mlTrain batch 4/32 - 170.6ms/batch - loss: 1.48959 - diff: 23.83mlTrain batch 5/32 - 172.3ms/batch - loss: 1.55866 - diff: 24.94mlTrain batch 6/32 - 185.9ms/batch - loss: 1.43952 - diff: 23.03mlTrain batch 7/32 - 170.9ms/batch - loss: 1.43648 - diff: 22.98mlTrain batch 8/32 - 182.1ms/batch - loss: 1.48091 - diff: 23.69mlTrain batch 9/32 - 189.3ms/batch - loss: 1.52743 - diff: 24.44mlTrain batch 10/32 - 170.7ms/batch - loss: 1.50258 - diff: 24.04mlTrain batch 11/32 - 170.9ms/batch - loss: 1.50389 - diff: 24.06mlTrain batch 12/32 - 170.5ms/batch - loss: 1.64534 - diff: 26.33mlTrain batch 13/32 - 181.9ms/batch - loss: 1.67349 - diff: 26.78mlTrain batch 14/32 - 170.8ms/batch - loss: 1.67955 - diff: 26.87mlTrain batch 15/32 - 170.7ms/batch - loss: 1.64109 - diff: 26.26mlTrain batch 16/32 - 179.8ms/batch - loss: 1.70224 - diff: 27.24mlTrain batch 17/32 - 179.7ms/batch - loss: 1.65046 - diff: 26.41mlTrain batch 18/32 - 172.5ms/batch - loss: 1.66637 - diff: 26.66mlTrain batch 19/32 - 176.6ms/batch - loss: 1.69555 - diff: 27.13mlTrain batch 20/32 - 170.7ms/batch - loss: 1.67583 - diff: 26.81mlTrain batch 21/32 - 170.7ms/batch - loss: 1.65102 - diff: 26.42mlTrain batch 22/32 - 170.5ms/batch - loss: 1.63448 - diff: 26.15mlTrain batch 23/32 - 171.1ms/batch - loss: 1.61340 - diff: 25.81mlTrain batch 24/32 - 170.4ms/batch - loss: 1.66495 - diff: 26.64mlTrain batch 25/32 - 175.2ms/batch - loss: 1.66410 - diff: 26.63mlTrain batch 26/32 - 186.7ms/batch - loss: 1.64776 - diff: 26.36mlTrain batch 27/32 - 170.9ms/batch - loss: 1.64453 - diff: 26.31mlTrain batch 28/32 - 184.5ms/batch - loss: 1.64313 - diff: 26.29mlTrain batch 29/32 - 170.8ms/batch - loss: 1.63598 - diff: 26.18mlTrain batch 30/32 - 170.5ms/batch - loss: 1.61714 - diff: 25.87mlTrain batch 31/32 - 174.7ms/batch - loss: 1.61059 - diff: 25.77mlTrain batch 32/32 - 52.6ms/batch - loss: 1.68028 - diff: 25.89mlTrain batch 32/32 - 16.4s 52.6ms/batch - loss: 1.68028 - diff: 25.89ml
Test 1.6s: val_loss: 1.56832 - diff: 22.91ml

Epoch 28: current best loss = 1.48807, at epoch 25
Train batch 1/32 - 170.8ms/batch - loss: 1.51763 - diff: 24.28mlTrain batch 2/32 - 170.7ms/batch - loss: 2.01176 - diff: 32.19mlTrain batch 3/32 - 170.8ms/batch - loss: 2.15443 - diff: 34.47mlTrain batch 4/32 - 179.5ms/batch - loss: 1.97993 - diff: 31.68mlTrain batch 5/32 - 184.4ms/batch - loss: 1.86866 - diff: 29.90mlTrain batch 6/32 - 182.1ms/batch - loss: 1.73208 - diff: 27.71mlTrain batch 7/32 - 174.7ms/batch - loss: 1.73472 - diff: 27.76mlTrain batch 8/32 - 170.5ms/batch - loss: 1.71022 - diff: 27.36mlTrain batch 9/32 - 170.6ms/batch - loss: 1.61988 - diff: 25.92mlTrain batch 10/32 - 170.7ms/batch - loss: 1.61431 - diff: 25.83mlTrain batch 11/32 - 170.6ms/batch - loss: 1.62327 - diff: 25.97mlTrain batch 12/32 - 170.5ms/batch - loss: 1.61210 - diff: 25.79mlTrain batch 13/32 - 170.6ms/batch - loss: 1.67896 - diff: 26.86mlTrain batch 14/32 - 170.7ms/batch - loss: 1.69195 - diff: 27.07mlTrain batch 15/32 - 170.7ms/batch - loss: 1.72446 - diff: 27.59mlTrain batch 16/32 - 170.7ms/batch - loss: 1.72529 - diff: 27.60mlTrain batch 17/32 - 170.6ms/batch - loss: 1.73878 - diff: 27.82mlTrain batch 18/32 - 171.5ms/batch - loss: 1.71735 - diff: 27.48mlTrain batch 19/32 - 180.4ms/batch - loss: 1.70422 - diff: 27.27mlTrain batch 20/32 - 177.8ms/batch - loss: 1.67030 - diff: 26.72mlTrain batch 21/32 - 170.6ms/batch - loss: 1.62884 - diff: 26.06mlTrain batch 22/32 - 170.6ms/batch - loss: 1.62983 - diff: 26.08mlTrain batch 23/32 - 171.0ms/batch - loss: 1.61297 - diff: 25.81mlTrain batch 24/32 - 170.6ms/batch - loss: 1.60477 - diff: 25.68mlTrain batch 25/32 - 170.7ms/batch - loss: 1.58809 - diff: 25.41mlTrain batch 26/32 - 170.7ms/batch - loss: 1.56537 - diff: 25.05mlTrain batch 27/32 - 177.1ms/batch - loss: 1.57625 - diff: 25.22mlTrain batch 28/32 - 170.5ms/batch - loss: 1.58242 - diff: 25.32mlTrain batch 29/32 - 173.1ms/batch - loss: 1.58239 - diff: 25.32mlTrain batch 30/32 - 170.7ms/batch - loss: 1.57929 - diff: 25.27mlTrain batch 31/32 - 170.8ms/batch - loss: 1.57849 - diff: 25.26mlTrain batch 32/32 - 62.7ms/batch - loss: 1.80015 - diff: 25.99mlTrain batch 32/32 - 17.2s 62.7ms/batch - loss: 1.80015 - diff: 25.99ml
Test 1.6s: val_loss: 1.53371 - diff: 24.07ml

Epoch 29: current best loss = 1.48807, at epoch 25
Train batch 1/32 - 184.5ms/batch - loss: 1.17807 - diff: 18.85mlTrain batch 2/32 - 206.6ms/batch - loss: 1.56436 - diff: 25.03mlTrain batch 3/32 - 194.1ms/batch - loss: 1.48000 - diff: 23.68mlTrain batch 4/32 - 170.6ms/batch - loss: 1.54452 - diff: 24.71mlTrain batch 5/32 - 170.8ms/batch - loss: 1.53968 - diff: 24.63mlTrain batch 6/32 - 176.2ms/batch - loss: 1.63908 - diff: 26.23mlTrain batch 7/32 - 181.8ms/batch - loss: 1.63738 - diff: 26.20mlTrain batch 8/32 - 173.2ms/batch - loss: 1.57840 - diff: 25.25mlTrain batch 9/32 - 170.6ms/batch - loss: 1.57800 - diff: 25.25mlTrain batch 10/32 - 176.9ms/batch - loss: 1.56829 - diff: 25.09mlTrain batch 11/32 - 172.2ms/batch - loss: 1.54682 - diff: 24.75mlTrain batch 12/32 - 171.3ms/batch - loss: 1.53556 - diff: 24.57mlTrain batch 13/32 - 197.6ms/batch - loss: 1.48843 - diff: 23.81mlTrain batch 14/32 - 170.9ms/batch - loss: 1.51006 - diff: 24.16mlTrain batch 15/32 - 170.6ms/batch - loss: 1.47566 - diff: 23.61mlTrain batch 16/32 - 170.4ms/batch - loss: 1.49861 - diff: 23.98mlTrain batch 17/32 - 170.7ms/batch - loss: 1.48257 - diff: 23.72mlTrain batch 18/32 - 177.2ms/batch - loss: 1.61779 - diff: 25.88mlTrain batch 19/32 - 172.9ms/batch - loss: 1.61369 - diff: 25.82mlTrain batch 20/32 - 176.7ms/batch - loss: 1.61577 - diff: 25.85mlTrain batch 21/32 - 170.8ms/batch - loss: 1.59709 - diff: 25.55mlTrain batch 22/32 - 171.5ms/batch - loss: 1.58298 - diff: 25.33mlTrain batch 23/32 - 170.7ms/batch - loss: 1.58269 - diff: 25.32mlTrain batch 24/32 - 170.8ms/batch - loss: 1.57437 - diff: 25.19mlTrain batch 25/32 - 170.6ms/batch - loss: 1.57892 - diff: 25.26mlTrain batch 26/32 - 171.8ms/batch - loss: 1.58318 - diff: 25.33mlTrain batch 27/32 - 185.2ms/batch - loss: 1.58687 - diff: 25.39mlTrain batch 28/32 - 170.4ms/batch - loss: 1.58343 - diff: 25.33mlTrain batch 29/32 - 171.1ms/batch - loss: 1.60936 - diff: 25.75mlTrain batch 30/32 - 170.7ms/batch - loss: 1.61846 - diff: 25.90mlTrain batch 31/32 - 171.8ms/batch - loss: 1.65154 - diff: 26.42mlTrain batch 32/32 - 52.5ms/batch - loss: 1.66080 - diff: 26.30mlTrain batch 32/32 - 15.5s 52.5ms/batch - loss: 1.66080 - diff: 26.30ml
Test 1.5s: val_loss: 1.47129 - diff: 22.88ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Systole_WideResNet50_0_Adam-0.001_MAE_DA3_best

Epoch 30: current best loss = 1.47129, at epoch 29
Train batch 1/32 - 180.1ms/batch - loss: 2.06109 - diff: 32.98mlTrain batch 2/32 - 187.2ms/batch - loss: 1.56262 - diff: 25.00mlTrain batch 3/32 - 170.6ms/batch - loss: 1.62532 - diff: 26.01mlTrain batch 4/32 - 171.2ms/batch - loss: 1.57580 - diff: 25.21mlTrain batch 5/32 - 171.9ms/batch - loss: 1.48742 - diff: 23.80mlTrain batch 6/32 - 192.2ms/batch - loss: 1.46290 - diff: 23.41mlTrain batch 7/32 - 170.8ms/batch - loss: 1.48556 - diff: 23.77mlTrain batch 8/32 - 188.5ms/batch - loss: 1.43630 - diff: 22.98mlTrain batch 9/32 - 170.9ms/batch - loss: 1.43693 - diff: 22.99mlTrain batch 10/32 - 169.8ms/batch - loss: 1.68057 - diff: 26.89mlTrain batch 11/32 - 171.8ms/batch - loss: 1.69806 - diff: 27.17mlTrain batch 12/32 - 171.4ms/batch - loss: 1.64025 - diff: 26.24mlTrain batch 13/32 - 170.6ms/batch - loss: 1.62783 - diff: 26.05mlTrain batch 14/32 - 171.1ms/batch - loss: 1.66672 - diff: 26.67mlTrain batch 15/32 - 170.5ms/batch - loss: 1.65193 - diff: 26.43mlTrain batch 16/32 - 171.2ms/batch - loss: 1.66130 - diff: 26.58mlTrain batch 17/32 - 175.1ms/batch - loss: 1.68863 - diff: 27.02mlTrain batch 18/32 - 190.3ms/batch - loss: 1.66030 - diff: 26.56mlTrain batch 19/32 - 183.9ms/batch - loss: 1.63048 - diff: 26.09mlTrain batch 20/32 - 175.8ms/batch - loss: 1.60962 - diff: 25.75mlTrain batch 21/32 - 178.0ms/batch - loss: 1.58185 - diff: 25.31mlTrain batch 22/32 - 179.4ms/batch - loss: 1.57375 - diff: 25.18mlTrain batch 23/32 - 178.6ms/batch - loss: 1.55020 - diff: 24.80mlTrain batch 24/32 - 171.0ms/batch - loss: 1.53421 - diff: 24.55mlTrain batch 25/32 - 176.0ms/batch - loss: 1.53941 - diff: 24.63mlTrain batch 26/32 - 176.1ms/batch - loss: 1.57683 - diff: 25.23mlTrain batch 27/32 - 172.8ms/batch - loss: 1.62020 - diff: 25.92mlTrain batch 28/32 - 171.9ms/batch - loss: 1.59841 - diff: 25.57mlTrain batch 29/32 - 170.5ms/batch - loss: 1.60849 - diff: 25.74mlTrain batch 30/32 - 171.0ms/batch - loss: 1.64328 - diff: 26.29mlTrain batch 31/32 - 170.9ms/batch - loss: 1.63928 - diff: 26.23mlTrain batch 32/32 - 52.7ms/batch - loss: 1.65771 - diff: 26.14mlTrain batch 32/32 - 17.5s 52.7ms/batch - loss: 1.65771 - diff: 26.14ml
Test 1.6s: val_loss: 1.49889 - diff: 22.76ml

Epoch 31: current best loss = 1.47129, at epoch 29
Train batch 1/32 - 175.9ms/batch - loss: 0.83624 - diff: 13.38mlTrain batch 2/32 - 170.7ms/batch - loss: 1.84887 - diff: 29.58mlTrain batch 3/32 - 172.4ms/batch - loss: 1.86125 - diff: 29.78mlTrain batch 4/32 - 170.7ms/batch - loss: 1.63588 - diff: 26.17mlTrain batch 5/32 - 184.3ms/batch - loss: 1.66963 - diff: 26.71mlTrain batch 6/32 - 170.9ms/batch - loss: 1.56647 - diff: 25.06mlTrain batch 7/32 - 176.5ms/batch - loss: 1.55975 - diff: 24.96mlTrain batch 8/32 - 170.9ms/batch - loss: 1.57924 - diff: 25.27mlTrain batch 9/32 - 170.5ms/batch - loss: 1.61031 - diff: 25.76mlTrain batch 10/32 - 170.8ms/batch - loss: 1.55125 - diff: 24.82mlTrain batch 11/32 - 170.4ms/batch - loss: 1.51011 - diff: 24.16mlTrain batch 12/32 - 170.7ms/batch - loss: 1.53792 - diff: 24.61mlTrain batch 13/32 - 170.8ms/batch - loss: 1.50268 - diff: 24.04mlTrain batch 14/32 - 176.1ms/batch - loss: 1.50095 - diff: 24.02mlTrain batch 15/32 - 170.5ms/batch - loss: 1.54326 - diff: 24.69mlTrain batch 16/32 - 170.4ms/batch - loss: 1.52068 - diff: 24.33mlTrain batch 17/32 - 174.5ms/batch - loss: 1.54772 - diff: 24.76mlTrain batch 18/32 - 199.2ms/batch - loss: 1.60112 - diff: 25.62mlTrain batch 19/32 - 171.0ms/batch - loss: 1.59081 - diff: 25.45mlTrain batch 20/32 - 170.7ms/batch - loss: 1.58168 - diff: 25.31mlTrain batch 21/32 - 176.2ms/batch - loss: 1.58398 - diff: 25.34mlTrain batch 22/32 - 170.6ms/batch - loss: 1.57738 - diff: 25.24mlTrain batch 23/32 - 175.0ms/batch - loss: 1.59110 - diff: 25.46mlTrain batch 24/32 - 170.8ms/batch - loss: 1.60841 - diff: 25.73mlTrain batch 25/32 - 170.7ms/batch - loss: 1.62850 - diff: 26.06mlTrain batch 26/32 - 170.6ms/batch - loss: 1.61875 - diff: 25.90mlTrain batch 27/32 - 170.9ms/batch - loss: 1.62747 - diff: 26.04mlTrain batch 28/32 - 184.5ms/batch - loss: 1.63807 - diff: 26.21mlTrain batch 29/32 - 175.8ms/batch - loss: 1.61679 - diff: 25.87mlTrain batch 30/32 - 178.3ms/batch - loss: 1.61529 - diff: 25.84mlTrain batch 31/32 - 175.9ms/batch - loss: 1.64281 - diff: 26.28mlTrain batch 32/32 - 52.4ms/batch - loss: 1.66341 - diff: 26.21mlTrain batch 32/32 - 16.0s 52.4ms/batch - loss: 1.66341 - diff: 26.21ml
Test 1.5s: val_loss: 1.46727 - diff: 22.61ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Systole_WideResNet50_0_Adam-0.001_MAE_DA3_best

Epoch 32: current best loss = 1.46727, at epoch 31
Train batch 1/32 - 184.1ms/batch - loss: 0.94071 - diff: 15.05mlTrain batch 2/32 - 180.1ms/batch - loss: 1.11848 - diff: 17.90mlTrain batch 3/32 - 170.8ms/batch - loss: 1.17138 - diff: 18.74mlTrain batch 4/32 - 184.8ms/batch - loss: 1.38466 - diff: 22.15mlTrain batch 5/32 - 171.8ms/batch - loss: 1.35799 - diff: 21.73mlTrain batch 6/32 - 178.6ms/batch - loss: 1.37365 - diff: 21.98mlTrain batch 7/32 - 170.5ms/batch - loss: 1.64146 - diff: 26.26mlTrain batch 8/32 - 180.7ms/batch - loss: 1.65962 - diff: 26.55mlTrain batch 9/32 - 189.1ms/batch - loss: 1.62966 - diff: 26.07mlTrain batch 10/32 - 170.7ms/batch - loss: 1.61122 - diff: 25.78mlTrain batch 11/32 - 170.7ms/batch - loss: 1.57665 - diff: 25.23mlTrain batch 12/32 - 171.4ms/batch - loss: 1.59462 - diff: 25.51mlTrain batch 13/32 - 170.6ms/batch - loss: 1.57381 - diff: 25.18mlTrain batch 14/32 - 170.3ms/batch - loss: 1.53400 - diff: 24.54mlTrain batch 15/32 - 176.8ms/batch - loss: 1.51064 - diff: 24.17mlTrain batch 16/32 - 171.2ms/batch - loss: 1.49649 - diff: 23.94mlTrain batch 17/32 - 170.6ms/batch - loss: 1.48176 - diff: 23.71mlTrain batch 18/32 - 173.8ms/batch - loss: 1.47118 - diff: 23.54mlTrain batch 19/32 - 174.4ms/batch - loss: 1.46906 - diff: 23.50mlTrain batch 20/32 - 183.7ms/batch - loss: 1.45565 - diff: 23.29mlTrain batch 21/32 - 170.6ms/batch - loss: 1.49210 - diff: 23.87mlTrain batch 22/32 - 171.0ms/batch - loss: 1.50223 - diff: 24.04mlTrain batch 23/32 - 186.8ms/batch - loss: 1.50345 - diff: 24.06mlTrain batch 24/32 - 185.5ms/batch - loss: 1.51206 - diff: 24.19mlTrain batch 25/32 - 182.2ms/batch - loss: 1.53365 - diff: 24.54mlTrain batch 26/32 - 171.4ms/batch - loss: 1.59579 - diff: 25.53mlTrain batch 27/32 - 170.8ms/batch - loss: 1.61841 - diff: 25.89mlTrain batch 28/32 - 170.2ms/batch - loss: 1.59695 - diff: 25.55mlTrain batch 29/32 - 170.7ms/batch - loss: 1.58792 - diff: 25.41mlTrain batch 30/32 - 170.8ms/batch - loss: 1.58245 - diff: 25.32mlTrain batch 31/32 - 170.7ms/batch - loss: 1.59118 - diff: 25.46mlTrain batch 32/32 - 52.7ms/batch - loss: 1.70928 - diff: 25.78mlTrain batch 32/32 - 16.9s 52.7ms/batch - loss: 1.70928 - diff: 25.78ml
Test 1.6s: val_loss: 1.56968 - diff: 24.42ml

Epoch 33: current best loss = 1.46727, at epoch 31
Train batch 1/32 - 170.5ms/batch - loss: 1.67026 - diff: 26.72mlTrain batch 2/32 - 171.0ms/batch - loss: 2.25986 - diff: 36.16mlTrain batch 3/32 - 177.7ms/batch - loss: 2.16738 - diff: 34.68mlTrain batch 4/32 - 173.5ms/batch - loss: 1.89382 - diff: 30.30mlTrain batch 5/32 - 170.5ms/batch - loss: 1.92107 - diff: 30.74mlTrain batch 6/32 - 170.9ms/batch - loss: 1.95916 - diff: 31.35mlTrain batch 7/32 - 170.6ms/batch - loss: 1.85387 - diff: 29.66mlTrain batch 8/32 - 183.1ms/batch - loss: 1.78014 - diff: 28.48mlTrain batch 9/32 - 170.5ms/batch - loss: 1.73579 - diff: 27.77mlTrain batch 10/32 - 186.3ms/batch - loss: 1.66527 - diff: 26.64mlTrain batch 11/32 - 170.7ms/batch - loss: 1.65779 - diff: 26.52mlTrain batch 12/32 - 170.7ms/batch - loss: 1.67881 - diff: 26.86mlTrain batch 13/32 - 170.6ms/batch - loss: 1.65851 - diff: 26.54mlTrain batch 14/32 - 170.9ms/batch - loss: 1.62724 - diff: 26.04mlTrain batch 15/32 - 184.0ms/batch - loss: 1.59086 - diff: 25.45mlTrain batch 16/32 - 179.6ms/batch - loss: 1.60495 - diff: 25.68mlTrain batch 17/32 - 170.7ms/batch - loss: 1.62760 - diff: 26.04mlTrain batch 18/32 - 170.9ms/batch - loss: 1.63122 - diff: 26.10mlTrain batch 19/32 - 170.6ms/batch - loss: 1.65264 - diff: 26.44mlTrain batch 20/32 - 171.0ms/batch - loss: 1.65844 - diff: 26.54mlTrain batch 21/32 - 170.7ms/batch - loss: 1.66176 - diff: 26.59mlTrain batch 22/32 - 171.0ms/batch - loss: 1.66959 - diff: 26.71mlTrain batch 23/32 - 170.7ms/batch - loss: 1.66132 - diff: 26.58mlTrain batch 24/32 - 171.0ms/batch - loss: 1.65363 - diff: 26.46mlTrain batch 25/32 - 170.6ms/batch - loss: 1.65620 - diff: 26.50mlTrain batch 26/32 - 170.9ms/batch - loss: 1.62833 - diff: 26.05mlTrain batch 27/32 - 170.6ms/batch - loss: 1.63193 - diff: 26.11mlTrain batch 28/32 - 171.2ms/batch - loss: 1.63206 - diff: 26.11mlTrain batch 29/32 - 170.7ms/batch - loss: 1.62016 - diff: 25.92mlTrain batch 30/32 - 171.0ms/batch - loss: 1.61509 - diff: 25.84mlTrain batch 31/32 - 170.8ms/batch - loss: 1.62974 - diff: 26.08mlTrain batch 32/32 - 59.9ms/batch - loss: 1.65366 - diff: 26.02mlTrain batch 32/32 - 15.2s 59.9ms/batch - loss: 1.65366 - diff: 26.02ml
Test 1.5s: val_loss: 1.44907 - diff: 22.23ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Systole_WideResNet50_0_Adam-0.001_MAE_DA3_best

Epoch 34: current best loss = 1.44907, at epoch 33
Train batch 1/32 - 183.1ms/batch - loss: 1.29713 - diff: 20.75mlTrain batch 2/32 - 186.0ms/batch - loss: 1.43437 - diff: 22.95mlTrain batch 3/32 - 177.5ms/batch - loss: 1.46970 - diff: 23.52mlTrain batch 4/32 - 172.1ms/batch - loss: 1.55031 - diff: 24.80mlTrain batch 5/32 - 170.6ms/batch - loss: 1.56177 - diff: 24.99mlTrain batch 6/32 - 181.8ms/batch - loss: 1.65065 - diff: 26.41mlTrain batch 7/32 - 176.9ms/batch - loss: 1.57696 - diff: 25.23mlTrain batch 8/32 - 170.8ms/batch - loss: 1.57846 - diff: 25.26mlTrain batch 9/32 - 170.8ms/batch - loss: 1.67958 - diff: 26.87mlTrain batch 10/32 - 170.8ms/batch - loss: 1.61272 - diff: 25.80mlTrain batch 11/32 - 170.7ms/batch - loss: 1.62220 - diff: 25.96mlTrain batch 12/32 - 181.3ms/batch - loss: 1.60410 - diff: 25.67mlTrain batch 13/32 - 184.0ms/batch - loss: 1.68630 - diff: 26.98mlTrain batch 14/32 - 170.8ms/batch - loss: 1.68877 - diff: 27.02mlTrain batch 15/32 - 195.2ms/batch - loss: 1.66619 - diff: 26.66mlTrain batch 16/32 - 170.5ms/batch - loss: 1.64166 - diff: 26.27mlTrain batch 17/32 - 180.5ms/batch - loss: 1.61354 - diff: 25.82mlTrain batch 18/32 - 170.7ms/batch - loss: 1.58645 - diff: 25.38mlTrain batch 19/32 - 170.8ms/batch - loss: 1.58451 - diff: 25.35mlTrain batch 20/32 - 170.6ms/batch - loss: 1.64959 - diff: 26.39mlTrain batch 21/32 - 170.8ms/batch - loss: 1.64591 - diff: 26.33mlTrain batch 22/32 - 185.9ms/batch - loss: 1.64855 - diff: 26.38mlTrain batch 23/32 - 178.2ms/batch - loss: 1.63855 - diff: 26.22mlTrain batch 24/32 - 170.7ms/batch - loss: 1.62083 - diff: 25.93mlTrain batch 25/32 - 170.5ms/batch - loss: 1.62992 - diff: 26.08mlTrain batch 26/32 - 170.7ms/batch - loss: 1.63194 - diff: 26.11mlTrain batch 27/32 - 170.8ms/batch - loss: 1.62449 - diff: 25.99mlTrain batch 28/32 - 176.9ms/batch - loss: 1.61026 - diff: 25.76mlTrain batch 29/32 - 170.6ms/batch - loss: 1.60820 - diff: 25.73mlTrain batch 30/32 - 170.6ms/batch - loss: 1.60530 - diff: 25.68mlTrain batch 31/32 - 170.8ms/batch - loss: 1.58851 - diff: 25.42mlTrain batch 32/32 - 52.8ms/batch - loss: 1.67059 - diff: 25.59mlTrain batch 32/32 - 16.1s 52.8ms/batch - loss: 1.67059 - diff: 25.59ml
Test 1.5s: val_loss: 1.44117 - diff: 22.12ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Systole_WideResNet50_0_Adam-0.001_MAE_DA3_best

Epoch 35: current best loss = 1.44117, at epoch 34
Train batch 1/32 - 193.9ms/batch - loss: 1.10631 - diff: 17.70mlTrain batch 2/32 - 170.7ms/batch - loss: 1.29823 - diff: 20.77mlTrain batch 3/32 - 172.8ms/batch - loss: 1.33645 - diff: 21.38mlTrain batch 4/32 - 176.3ms/batch - loss: 1.54286 - diff: 24.69mlTrain batch 5/32 - 171.9ms/batch - loss: 1.50336 - diff: 24.05mlTrain batch 6/32 - 170.7ms/batch - loss: 1.45038 - diff: 23.21mlTrain batch 7/32 - 170.6ms/batch - loss: 1.38893 - diff: 22.22mlTrain batch 8/32 - 170.5ms/batch - loss: 1.36424 - diff: 21.83mlTrain batch 9/32 - 177.8ms/batch - loss: 1.39926 - diff: 22.39mlTrain batch 10/32 - 171.6ms/batch - loss: 1.38677 - diff: 22.19mlTrain batch 11/32 - 170.7ms/batch - loss: 1.37131 - diff: 21.94mlTrain batch 12/32 - 170.4ms/batch - loss: 1.40537 - diff: 22.49mlTrain batch 13/32 - 170.8ms/batch - loss: 1.44555 - diff: 23.13mlTrain batch 14/32 - 170.7ms/batch - loss: 1.51385 - diff: 24.22mlTrain batch 15/32 - 188.7ms/batch - loss: 1.51828 - diff: 24.29mlTrain batch 16/32 - 170.6ms/batch - loss: 1.51656 - diff: 24.26mlTrain batch 17/32 - 185.0ms/batch - loss: 1.54029 - diff: 24.64mlTrain batch 18/32 - 170.5ms/batch - loss: 1.54418 - diff: 24.71mlTrain batch 19/32 - 178.5ms/batch - loss: 1.52381 - diff: 24.38mlTrain batch 20/32 - 170.7ms/batch - loss: 1.51460 - diff: 24.23mlTrain batch 21/32 - 173.0ms/batch - loss: 1.49675 - diff: 23.95mlTrain batch 22/32 - 183.6ms/batch - loss: 1.49708 - diff: 23.95mlTrain batch 23/32 - 170.8ms/batch - loss: 1.52045 - diff: 24.33mlTrain batch 24/32 - 173.4ms/batch - loss: 1.53370 - diff: 24.54mlTrain batch 25/32 - 170.7ms/batch - loss: 1.57189 - diff: 25.15mlTrain batch 26/32 - 180.2ms/batch - loss: 1.61262 - diff: 25.80mlTrain batch 27/32 - 179.2ms/batch - loss: 1.59440 - diff: 25.51mlTrain batch 28/32 - 170.6ms/batch - loss: 1.61131 - diff: 25.78mlTrain batch 29/32 - 170.9ms/batch - loss: 1.61762 - diff: 25.88mlTrain batch 30/32 - 170.6ms/batch - loss: 1.60887 - diff: 25.74mlTrain batch 31/32 - 170.7ms/batch - loss: 1.59409 - diff: 25.51mlTrain batch 32/32 - 55.3ms/batch - loss: 1.60568 - diff: 25.40mlTrain batch 32/32 - 16.2s 55.3ms/batch - loss: 1.60568 - diff: 25.40ml
Test 1.5s: val_loss: 1.53006 - diff: 23.77ml

Epoch 36: current best loss = 1.44117, at epoch 34
Train batch 1/32 - 170.4ms/batch - loss: 0.93271 - diff: 14.92mlTrain batch 2/32 - 170.2ms/batch - loss: 0.99214 - diff: 15.87mlTrain batch 3/32 - 175.9ms/batch - loss: 1.22337 - diff: 19.57mlTrain batch 4/32 - 178.4ms/batch - loss: 1.35789 - diff: 21.73mlTrain batch 5/32 - 171.7ms/batch - loss: 1.35726 - diff: 21.72mlTrain batch 6/32 - 170.7ms/batch - loss: 1.49779 - diff: 23.96mlTrain batch 7/32 - 170.7ms/batch - loss: 1.46084 - diff: 23.37mlTrain batch 8/32 - 188.3ms/batch - loss: 1.47469 - diff: 23.60mlTrain batch 9/32 - 170.8ms/batch - loss: 1.51268 - diff: 24.20mlTrain batch 10/32 - 173.3ms/batch - loss: 1.47766 - diff: 23.64mlTrain batch 11/32 - 172.5ms/batch - loss: 1.52981 - diff: 24.48mlTrain batch 12/32 - 180.8ms/batch - loss: 1.56346 - diff: 25.02mlTrain batch 13/32 - 170.7ms/batch - loss: 1.52823 - diff: 24.45mlTrain batch 14/32 - 170.9ms/batch - loss: 1.52415 - diff: 24.39mlTrain batch 15/32 - 170.1ms/batch - loss: 1.54740 - diff: 24.76mlTrain batch 16/32 - 171.0ms/batch - loss: 1.53156 - diff: 24.50mlTrain batch 17/32 - 170.8ms/batch - loss: 1.53433 - diff: 24.55mlTrain batch 18/32 - 170.9ms/batch - loss: 1.57852 - diff: 25.26mlTrain batch 19/32 - 171.2ms/batch - loss: 1.58553 - diff: 25.37mlTrain batch 20/32 - 171.3ms/batch - loss: 1.55744 - diff: 24.92mlTrain batch 21/32 - 176.9ms/batch - loss: 1.54826 - diff: 24.77mlTrain batch 22/32 - 176.8ms/batch - loss: 1.57020 - diff: 25.12mlTrain batch 23/32 - 171.2ms/batch - loss: 1.55815 - diff: 24.93mlTrain batch 24/32 - 170.5ms/batch - loss: 1.59538 - diff: 25.53mlTrain batch 25/32 - 171.4ms/batch - loss: 1.61354 - diff: 25.82mlTrain batch 26/32 - 174.3ms/batch - loss: 1.66971 - diff: 26.72mlTrain batch 27/32 - 170.8ms/batch - loss: 1.64870 - diff: 26.38mlTrain batch 28/32 - 178.0ms/batch - loss: 1.64035 - diff: 26.25mlTrain batch 29/32 - 170.6ms/batch - loss: 1.61428 - diff: 25.83mlTrain batch 30/32 - 184.3ms/batch - loss: 1.59749 - diff: 25.56mlTrain batch 31/32 - 170.8ms/batch - loss: 1.60898 - diff: 25.74mlTrain batch 32/32 - 52.7ms/batch - loss: 1.64410 - diff: 25.73mlTrain batch 32/32 - 15.0s 52.7ms/batch - loss: 1.64410 - diff: 25.73ml
Test 1.5s: val_loss: 1.62963 - diff: 24.94ml

Epoch 37: current best loss = 1.44117, at epoch 34
Train batch 1/32 - 170.8ms/batch - loss: 2.16171 - diff: 34.59mlTrain batch 2/32 - 170.8ms/batch - loss: 1.68647 - diff: 26.98mlTrain batch 3/32 - 170.8ms/batch - loss: 1.62628 - diff: 26.02mlTrain batch 4/32 - 170.7ms/batch - loss: 1.70391 - diff: 27.26mlTrain batch 5/32 - 185.0ms/batch - loss: 1.70951 - diff: 27.35mlTrain batch 6/32 - 170.9ms/batch - loss: 1.80064 - diff: 28.81mlTrain batch 7/32 - 186.1ms/batch - loss: 1.99705 - diff: 31.95mlTrain batch 8/32 - 170.7ms/batch - loss: 1.91252 - diff: 30.60mlTrain batch 9/32 - 170.5ms/batch - loss: 1.88794 - diff: 30.21mlTrain batch 10/32 - 170.7ms/batch - loss: 1.82675 - diff: 29.23mlTrain batch 11/32 - 170.6ms/batch - loss: 1.81895 - diff: 29.10mlTrain batch 12/32 - 170.8ms/batch - loss: 1.81122 - diff: 28.98mlTrain batch 13/32 - 172.0ms/batch - loss: 1.78607 - diff: 28.58mlTrain batch 14/32 - 171.3ms/batch - loss: 1.73499 - diff: 27.76mlTrain batch 15/32 - 172.9ms/batch - loss: 1.71256 - diff: 27.40mlTrain batch 16/32 - 171.0ms/batch - loss: 1.67720 - diff: 26.84mlTrain batch 17/32 - 174.5ms/batch - loss: 1.67772 - diff: 26.84mlTrain batch 18/32 - 175.9ms/batch - loss: 1.67216 - diff: 26.75mlTrain batch 19/32 - 172.3ms/batch - loss: 1.63307 - diff: 26.13mlTrain batch 20/32 - 170.2ms/batch - loss: 1.62887 - diff: 26.06mlTrain batch 21/32 - 170.8ms/batch - loss: 1.64635 - diff: 26.34mlTrain batch 22/32 - 171.1ms/batch - loss: 1.62459 - diff: 25.99mlTrain batch 23/32 - 170.7ms/batch - loss: 1.63142 - diff: 26.10mlTrain batch 24/32 - 170.0ms/batch - loss: 1.64572 - diff: 26.33mlTrain batch 25/32 - 177.4ms/batch - loss: 1.63200 - diff: 26.11mlTrain batch 26/32 - 176.0ms/batch - loss: 1.63691 - diff: 26.19mlTrain batch 27/32 - 174.5ms/batch - loss: 1.60285 - diff: 25.65mlTrain batch 28/32 - 174.8ms/batch - loss: 1.58253 - diff: 25.32mlTrain batch 29/32 - 170.7ms/batch - loss: 1.59017 - diff: 25.44mlTrain batch 30/32 - 170.7ms/batch - loss: 1.57651 - diff: 25.22mlTrain batch 31/32 - 170.6ms/batch - loss: 1.59783 - diff: 25.57mlTrain batch 32/32 - 52.7ms/batch - loss: 1.62533 - diff: 25.52mlTrain batch 32/32 - 16.5s 52.7ms/batch - loss: 1.62533 - diff: 25.52ml
Test 1.6s: val_loss: 1.41148 - diff: 22.08ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Systole_WideResNet50_0_Adam-0.001_MAE_DA3_best

Epoch 38: current best loss = 1.41148, at epoch 37
Train batch 1/32 - 203.5ms/batch - loss: 1.18780 - diff: 19.00mlTrain batch 2/32 - 179.8ms/batch - loss: 1.49145 - diff: 23.86mlTrain batch 3/32 - 170.6ms/batch - loss: 1.40753 - diff: 22.52mlTrain batch 4/32 - 177.8ms/batch - loss: 1.41246 - diff: 22.60mlTrain batch 5/32 - 172.0ms/batch - loss: 1.49645 - diff: 23.94mlTrain batch 6/32 - 171.0ms/batch - loss: 1.46534 - diff: 23.45mlTrain batch 7/32 - 170.7ms/batch - loss: 1.51710 - diff: 24.27mlTrain batch 8/32 - 170.9ms/batch - loss: 1.51945 - diff: 24.31mlTrain batch 9/32 - 173.9ms/batch - loss: 1.61699 - diff: 25.87mlTrain batch 10/32 - 187.1ms/batch - loss: 1.63439 - diff: 26.15mlTrain batch 11/32 - 172.6ms/batch - loss: 1.57945 - diff: 25.27mlTrain batch 12/32 - 174.9ms/batch - loss: 1.53094 - diff: 24.50mlTrain batch 13/32 - 172.1ms/batch - loss: 1.57843 - diff: 25.25mlTrain batch 14/32 - 173.9ms/batch - loss: 1.57124 - diff: 25.14mlTrain batch 15/32 - 170.8ms/batch - loss: 1.58566 - diff: 25.37mlTrain batch 16/32 - 171.8ms/batch - loss: 1.64237 - diff: 26.28mlTrain batch 17/32 - 170.8ms/batch - loss: 1.61518 - diff: 25.84mlTrain batch 18/32 - 171.0ms/batch - loss: 1.59568 - diff: 25.53mlTrain batch 19/32 - 183.6ms/batch - loss: 1.58529 - diff: 25.36mlTrain batch 20/32 - 175.6ms/batch - loss: 1.56089 - diff: 24.97mlTrain batch 21/32 - 170.2ms/batch - loss: 1.62043 - diff: 25.93mlTrain batch 22/32 - 177.1ms/batch - loss: 1.61105 - diff: 25.78mlTrain batch 23/32 - 173.2ms/batch - loss: 1.58616 - diff: 25.38mlTrain batch 24/32 - 179.2ms/batch - loss: 1.59378 - diff: 25.50mlTrain batch 25/32 - 184.8ms/batch - loss: 1.61092 - diff: 25.77mlTrain batch 26/32 - 171.0ms/batch - loss: 1.61904 - diff: 25.90mlTrain batch 27/32 - 170.6ms/batch - loss: 1.59781 - diff: 25.56mlTrain batch 28/32 - 170.7ms/batch - loss: 1.57842 - diff: 25.25mlTrain batch 29/32 - 170.6ms/batch - loss: 1.59105 - diff: 25.46mlTrain batch 30/32 - 170.6ms/batch - loss: 1.59128 - diff: 25.46mlTrain batch 31/32 - 170.7ms/batch - loss: 1.56842 - diff: 25.09mlTrain batch 32/32 - 52.6ms/batch - loss: 1.69415 - diff: 25.45mlTrain batch 32/32 - 17.9s 52.6ms/batch - loss: 1.69415 - diff: 25.45ml
Test 1.5s: val_loss: 1.53035 - diff: 22.15ml

Epoch 39: current best loss = 1.41148, at epoch 37
Train batch 1/32 - 177.1ms/batch - loss: 2.28848 - diff: 36.62mlTrain batch 2/32 - 180.3ms/batch - loss: 2.01085 - diff: 32.17mlTrain batch 3/32 - 170.7ms/batch - loss: 2.02547 - diff: 32.41mlTrain batch 4/32 - 172.8ms/batch - loss: 1.96091 - diff: 31.37mlTrain batch 5/32 - 170.7ms/batch - loss: 1.83073 - diff: 29.29mlTrain batch 6/32 - 174.0ms/batch - loss: 1.73311 - diff: 27.73mlTrain batch 7/32 - 170.7ms/batch - loss: 1.68776 - diff: 27.00mlTrain batch 8/32 - 181.8ms/batch - loss: 1.62273 - diff: 25.96mlTrain batch 9/32 - 170.5ms/batch - loss: 1.63636 - diff: 26.18mlTrain batch 10/32 - 170.6ms/batch - loss: 1.62914 - diff: 26.07mlTrain batch 11/32 - 170.7ms/batch - loss: 1.67786 - diff: 26.85mlTrain batch 12/32 - 174.0ms/batch - loss: 1.62382 - diff: 25.98mlTrain batch 13/32 - 170.6ms/batch - loss: 1.63471 - diff: 26.16mlTrain batch 14/32 - 175.7ms/batch - loss: 1.66531 - diff: 26.64mlTrain batch 15/32 - 170.8ms/batch - loss: 1.62351 - diff: 25.98mlTrain batch 16/32 - 176.2ms/batch - loss: 1.60024 - diff: 25.60mlTrain batch 17/32 - 170.7ms/batch - loss: 1.57672 - diff: 25.23mlTrain batch 18/32 - 170.8ms/batch - loss: 1.57466 - diff: 25.19mlTrain batch 19/32 - 172.5ms/batch - loss: 1.57425 - diff: 25.19mlTrain batch 20/32 - 183.3ms/batch - loss: 1.57869 - diff: 25.26mlTrain batch 21/32 - 171.7ms/batch - loss: 1.55530 - diff: 24.88mlTrain batch 22/32 - 170.6ms/batch - loss: 1.52455 - diff: 24.39mlTrain batch 23/32 - 170.7ms/batch - loss: 1.56943 - diff: 25.11mlTrain batch 24/32 - 170.9ms/batch - loss: 1.59836 - diff: 25.57mlTrain batch 25/32 - 171.0ms/batch - loss: 1.57242 - diff: 25.16mlTrain batch 26/32 - 179.0ms/batch - loss: 1.59893 - diff: 25.58mlTrain batch 27/32 - 170.8ms/batch - loss: 1.58191 - diff: 25.31mlTrain batch 28/32 - 170.7ms/batch - loss: 1.59704 - diff: 25.55mlTrain batch 29/32 - 170.8ms/batch - loss: 1.58805 - diff: 25.41mlTrain batch 30/32 - 170.7ms/batch - loss: 1.59187 - diff: 25.47mlTrain batch 31/32 - 170.7ms/batch - loss: 1.57084 - diff: 25.13mlTrain batch 32/32 - 52.6ms/batch - loss: 1.59736 - diff: 25.09mlTrain batch 32/32 - 15.7s 52.6ms/batch - loss: 1.59736 - diff: 25.09ml
Test 1.6s: val_loss: 1.40349 - diff: 21.76ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Systole_WideResNet50_0_Adam-0.001_MAE_DA3_best

Epoch 40: current best loss = 1.40349, at epoch 39
Train batch 1/32 - 179.8ms/batch - loss: 1.22374 - diff: 19.58mlTrain batch 2/32 - 182.3ms/batch - loss: 1.64532 - diff: 26.33mlTrain batch 3/32 - 170.8ms/batch - loss: 1.45624 - diff: 23.30mlTrain batch 4/32 - 180.4ms/batch - loss: 1.42410 - diff: 22.79mlTrain batch 5/32 - 170.7ms/batch - loss: 1.49246 - diff: 23.88mlTrain batch 6/32 - 170.8ms/batch - loss: 1.54127 - diff: 24.66mlTrain batch 7/32 - 170.7ms/batch - loss: 1.53295 - diff: 24.53mlTrain batch 8/32 - 170.9ms/batch - loss: 1.51332 - diff: 24.21mlTrain batch 9/32 - 170.5ms/batch - loss: 1.52674 - diff: 24.43mlTrain batch 10/32 - 171.0ms/batch - loss: 1.47844 - diff: 23.65mlTrain batch 11/32 - 170.7ms/batch - loss: 1.55105 - diff: 24.82mlTrain batch 12/32 - 171.0ms/batch - loss: 1.63717 - diff: 26.19mlTrain batch 13/32 - 170.6ms/batch - loss: 1.62720 - diff: 26.04mlTrain batch 14/32 - 171.0ms/batch - loss: 1.58404 - diff: 25.34mlTrain batch 15/32 - 170.7ms/batch - loss: 1.57017 - diff: 25.12mlTrain batch 16/32 - 170.1ms/batch - loss: 1.62959 - diff: 26.07mlTrain batch 17/32 - 170.7ms/batch - loss: 1.61943 - diff: 25.91mlTrain batch 18/32 - 171.0ms/batch - loss: 1.70374 - diff: 27.26mlTrain batch 19/32 - 170.7ms/batch - loss: 1.72035 - diff: 27.53mlTrain batch 20/32 - 171.2ms/batch - loss: 1.71658 - diff: 27.47mlTrain batch 21/32 - 177.8ms/batch - loss: 1.69989 - diff: 27.20mlTrain batch 22/32 - 183.7ms/batch - loss: 1.70153 - diff: 27.22mlTrain batch 23/32 - 172.0ms/batch - loss: 1.69091 - diff: 27.05mlTrain batch 24/32 - 171.2ms/batch - loss: 1.65909 - diff: 26.55mlTrain batch 25/32 - 170.7ms/batch - loss: 1.65556 - diff: 26.49mlTrain batch 26/32 - 170.1ms/batch - loss: 1.64365 - diff: 26.30mlTrain batch 27/32 - 174.1ms/batch - loss: 1.63005 - diff: 26.08mlTrain batch 28/32 - 170.8ms/batch - loss: 1.62028 - diff: 25.92mlTrain batch 29/32 - 170.8ms/batch - loss: 1.61208 - diff: 25.79mlTrain batch 30/32 - 171.2ms/batch - loss: 1.61391 - diff: 25.82mlTrain batch 31/32 - 170.7ms/batch - loss: 1.59481 - diff: 25.52mlTrain batch 32/32 - 52.7ms/batch - loss: 1.60988 - diff: 25.42mlTrain batch 32/32 - 16.8s 52.7ms/batch - loss: 1.60988 - diff: 25.42ml
Test 1.5s: val_loss: 1.49540 - diff: 22.08ml

Epoch 41: current best loss = 1.40349, at epoch 39
Train batch 1/32 - 182.3ms/batch - loss: 1.11127 - diff: 17.78mlTrain batch 2/32 - 170.8ms/batch - loss: 1.65572 - diff: 26.49mlTrain batch 3/32 - 170.7ms/batch - loss: 1.42839 - diff: 22.85mlTrain batch 4/32 - 170.3ms/batch - loss: 1.49793 - diff: 23.97mlTrain batch 5/32 - 185.4ms/batch - loss: 1.52132 - diff: 24.34mlTrain batch 6/32 - 171.1ms/batch - loss: 1.50528 - diff: 24.08mlTrain batch 7/32 - 170.6ms/batch - loss: 1.54568 - diff: 24.73mlTrain batch 8/32 - 170.7ms/batch - loss: 1.46304 - diff: 23.41mlTrain batch 9/32 - 170.6ms/batch - loss: 1.52018 - diff: 24.32mlTrain batch 10/32 - 170.8ms/batch - loss: 1.46484 - diff: 23.44mlTrain batch 11/32 - 179.3ms/batch - loss: 1.48210 - diff: 23.71mlTrain batch 12/32 - 172.4ms/batch - loss: 1.50578 - diff: 24.09mlTrain batch 13/32 - 170.8ms/batch - loss: 1.56449 - diff: 25.03mlTrain batch 14/32 - 172.1ms/batch - loss: 1.59328 - diff: 25.49mlTrain batch 15/32 - 179.5ms/batch - loss: 1.70567 - diff: 27.29mlTrain batch 16/32 - 180.4ms/batch - loss: 1.66725 - diff: 26.68mlTrain batch 17/32 - 170.7ms/batch - loss: 1.64751 - diff: 26.36mlTrain batch 18/32 - 170.7ms/batch - loss: 1.61510 - diff: 25.84mlTrain batch 19/32 - 170.6ms/batch - loss: 1.59486 - diff: 25.52mlTrain batch 20/32 - 170.9ms/batch - loss: 1.59159 - diff: 25.47mlTrain batch 21/32 - 171.0ms/batch - loss: 1.56559 - diff: 25.05mlTrain batch 22/32 - 183.2ms/batch - loss: 1.57521 - diff: 25.20mlTrain batch 23/32 - 170.7ms/batch - loss: 1.57048 - diff: 25.13mlTrain batch 24/32 - 171.0ms/batch - loss: 1.55784 - diff: 24.93mlTrain batch 25/32 - 179.8ms/batch - loss: 1.55419 - diff: 24.87mlTrain batch 26/32 - 170.7ms/batch - loss: 1.55717 - diff: 24.91mlTrain batch 27/32 - 170.8ms/batch - loss: 1.55796 - diff: 24.93mlTrain batch 28/32 - 170.6ms/batch - loss: 1.55874 - diff: 24.94mlTrain batch 29/32 - 171.4ms/batch - loss: 1.55455 - diff: 24.87mlTrain batch 30/32 - 170.7ms/batch - loss: 1.54650 - diff: 24.74mlTrain batch 31/32 - 174.3ms/batch - loss: 1.55290 - diff: 24.85mlTrain batch 32/32 - 53.0ms/batch - loss: 1.59975 - diff: 24.88mlTrain batch 32/32 - 16.0s 53.0ms/batch - loss: 1.59975 - diff: 24.88ml
Test 1.4s: val_loss: 1.42351 - diff: 21.82ml

Epoch 42: current best loss = 1.40349, at epoch 39
Train batch 1/32 - 170.9ms/batch - loss: 1.87846 - diff: 30.06mlTrain batch 2/32 - 177.7ms/batch - loss: 1.55863 - diff: 24.94mlTrain batch 3/32 - 171.0ms/batch - loss: 1.39006 - diff: 22.24mlTrain batch 4/32 - 171.4ms/batch - loss: 1.38314 - diff: 22.13mlTrain batch 5/32 - 170.7ms/batch - loss: 1.42568 - diff: 22.81mlTrain batch 6/32 - 171.0ms/batch - loss: 1.54786 - diff: 24.77mlTrain batch 7/32 - 170.7ms/batch - loss: 1.48925 - diff: 23.83mlTrain batch 8/32 - 178.6ms/batch - loss: 1.46883 - diff: 23.50mlTrain batch 9/32 - 171.0ms/batch - loss: 1.42111 - diff: 22.74mlTrain batch 10/32 - 170.9ms/batch - loss: 1.45429 - diff: 23.27mlTrain batch 11/32 - 185.3ms/batch - loss: 1.52487 - diff: 24.40mlTrain batch 12/32 - 171.1ms/batch - loss: 1.50916 - diff: 24.15mlTrain batch 13/32 - 182.3ms/batch - loss: 1.48981 - diff: 23.84mlTrain batch 14/32 - 170.8ms/batch - loss: 1.46522 - diff: 23.44mlTrain batch 15/32 - 170.7ms/batch - loss: 1.44287 - diff: 23.09mlTrain batch 16/32 - 170.7ms/batch - loss: 1.52540 - diff: 24.41mlTrain batch 17/32 - 170.8ms/batch - loss: 1.52310 - diff: 24.37mlTrain batch 18/32 - 170.8ms/batch - loss: 1.53100 - diff: 24.50mlTrain batch 19/32 - 170.8ms/batch - loss: 1.53230 - diff: 24.52mlTrain batch 20/32 - 170.6ms/batch - loss: 1.52010 - diff: 24.32mlTrain batch 21/32 - 170.7ms/batch - loss: 1.52328 - diff: 24.37mlTrain batch 22/32 - 170.9ms/batch - loss: 1.51073 - diff: 24.17mlTrain batch 23/32 - 170.8ms/batch - loss: 1.53622 - diff: 24.58mlTrain batch 24/32 - 185.8ms/batch - loss: 1.53907 - diff: 24.63mlTrain batch 25/32 - 170.8ms/batch - loss: 1.52524 - diff: 24.40mlTrain batch 26/32 - 170.6ms/batch - loss: 1.51725 - diff: 24.28mlTrain batch 27/32 - 170.9ms/batch - loss: 1.53983 - diff: 24.64mlTrain batch 28/32 - 170.8ms/batch - loss: 1.53718 - diff: 24.59mlTrain batch 29/32 - 175.6ms/batch - loss: 1.55809 - diff: 24.93mlTrain batch 30/32 - 170.9ms/batch - loss: 1.54311 - diff: 24.69mlTrain batch 31/32 - 182.7ms/batch - loss: 1.54292 - diff: 24.69mlTrain batch 32/32 - 66.3ms/batch - loss: 1.55030 - diff: 24.57mlTrain batch 32/32 - 16.8s 66.3ms/batch - loss: 1.55030 - diff: 24.57ml
Test 1.5s: val_loss: 1.44979 - diff: 22.10ml

Epoch 43: current best loss = 1.40349, at epoch 39
Train batch 1/32 - 171.0ms/batch - loss: 1.20550 - diff: 19.29mlTrain batch 2/32 - 175.7ms/batch - loss: 1.72670 - diff: 27.63mlTrain batch 3/32 - 170.7ms/batch - loss: 1.71780 - diff: 27.48mlTrain batch 4/32 - 171.0ms/batch - loss: 1.71380 - diff: 27.42mlTrain batch 5/32 - 171.8ms/batch - loss: 1.56746 - diff: 25.08mlTrain batch 6/32 - 182.6ms/batch - loss: 1.62819 - diff: 26.05mlTrain batch 7/32 - 178.2ms/batch - loss: 1.66445 - diff: 26.63mlTrain batch 8/32 - 175.2ms/batch - loss: 1.67271 - diff: 26.76mlTrain batch 9/32 - 170.9ms/batch - loss: 1.60198 - diff: 25.63mlTrain batch 10/32 - 171.2ms/batch - loss: 1.59005 - diff: 25.44mlTrain batch 11/32 - 171.0ms/batch - loss: 1.55014 - diff: 24.80mlTrain batch 12/32 - 171.0ms/batch - loss: 1.55142 - diff: 24.82mlTrain batch 13/32 - 170.5ms/batch - loss: 1.56993 - diff: 25.12mlTrain batch 14/32 - 173.8ms/batch - loss: 1.74666 - diff: 27.95mlTrain batch 15/32 - 170.5ms/batch - loss: 1.69980 - diff: 27.20mlTrain batch 16/32 - 171.4ms/batch - loss: 1.72000 - diff: 27.52mlTrain batch 17/32 - 181.7ms/batch - loss: 1.71494 - diff: 27.44mlTrain batch 18/32 - 172.8ms/batch - loss: 1.67108 - diff: 26.74mlTrain batch 19/32 - 170.8ms/batch - loss: 1.63195 - diff: 26.11mlTrain batch 20/32 - 170.9ms/batch - loss: 1.63461 - diff: 26.15mlTrain batch 21/32 - 170.9ms/batch - loss: 1.62391 - diff: 25.98mlTrain batch 22/32 - 187.0ms/batch - loss: 1.60580 - diff: 25.69mlTrain batch 23/32 - 170.8ms/batch - loss: 1.57503 - diff: 25.20mlTrain batch 24/32 - 171.0ms/batch - loss: 1.57340 - diff: 25.17mlTrain batch 25/32 - 170.7ms/batch - loss: 1.57493 - diff: 25.20mlTrain batch 26/32 - 171.0ms/batch - loss: 1.58364 - diff: 25.34mlTrain batch 27/32 - 170.7ms/batch - loss: 1.58566 - diff: 25.37mlTrain batch 28/32 - 178.9ms/batch - loss: 1.59828 - diff: 25.57mlTrain batch 29/32 - 173.3ms/batch - loss: 1.57917 - diff: 25.27mlTrain batch 30/32 - 170.8ms/batch - loss: 1.56740 - diff: 25.08mlTrain batch 31/32 - 170.6ms/batch - loss: 1.56317 - diff: 25.01mlTrain batch 32/32 - 52.4ms/batch - loss: 1.59004 - diff: 24.97mlTrain batch 32/32 - 17.5s 52.4ms/batch - loss: 1.59004 - diff: 24.97ml
Test 1.5s: val_loss: 1.43583 - diff: 21.46ml

Epoch 44: current best loss = 1.40349, at epoch 39
Train batch 1/32 - 182.8ms/batch - loss: 1.02348 - diff: 16.38mlTrain batch 2/32 - 178.4ms/batch - loss: 1.95572 - diff: 31.29mlTrain batch 3/32 - 171.0ms/batch - loss: 1.81761 - diff: 29.08mlTrain batch 4/32 - 186.3ms/batch - loss: 1.68983 - diff: 27.04mlTrain batch 5/32 - 172.1ms/batch - loss: 1.65549 - diff: 26.49mlTrain batch 6/32 - 171.0ms/batch - loss: 1.58429 - diff: 25.35mlTrain batch 7/32 - 178.1ms/batch - loss: 1.65421 - diff: 26.47mlTrain batch 8/32 - 171.5ms/batch - loss: 1.64416 - diff: 26.31mlTrain batch 9/32 - 179.9ms/batch - loss: 1.60822 - diff: 25.73mlTrain batch 10/32 - 170.8ms/batch - loss: 1.56825 - diff: 25.09mlTrain batch 11/32 - 187.7ms/batch - loss: 1.53710 - diff: 24.59mlTrain batch 12/32 - 170.7ms/batch - loss: 1.50655 - diff: 24.10mlTrain batch 13/32 - 171.1ms/batch - loss: 1.51894 - diff: 24.30mlTrain batch 14/32 - 181.3ms/batch - loss: 1.47510 - diff: 23.60mlTrain batch 15/32 - 186.2ms/batch - loss: 1.47241 - diff: 23.56mlTrain batch 16/32 - 170.8ms/batch - loss: 1.48466 - diff: 23.75mlTrain batch 17/32 - 178.3ms/batch - loss: 1.47199 - diff: 23.55mlTrain batch 18/32 - 175.3ms/batch - loss: 1.45749 - diff: 23.32mlTrain batch 19/32 - 201.2ms/batch - loss: 1.49588 - diff: 23.93mlTrain batch 20/32 - 185.6ms/batch - loss: 1.50777 - diff: 24.12mlTrain batch 21/32 - 177.3ms/batch - loss: 1.53215 - diff: 24.51mlTrain batch 22/32 - 180.3ms/batch - loss: 1.50683 - diff: 24.11mlTrain batch 23/32 - 170.8ms/batch - loss: 1.50749 - diff: 24.12mlTrain batch 24/32 - 187.2ms/batch - loss: 1.49381 - diff: 23.90mlTrain batch 25/32 - 170.6ms/batch - loss: 1.48532 - diff: 23.77mlTrain batch 26/32 - 170.6ms/batch - loss: 1.49056 - diff: 23.85mlTrain batch 27/32 - 176.2ms/batch - loss: 1.48552 - diff: 23.77mlTrain batch 28/32 - 171.0ms/batch - loss: 1.48972 - diff: 23.84mlTrain batch 29/32 - 170.9ms/batch - loss: 1.49580 - diff: 23.93mlTrain batch 30/32 - 173.6ms/batch - loss: 1.54128 - diff: 24.66mlTrain batch 31/32 - 174.8ms/batch - loss: 1.55352 - diff: 24.86mlTrain batch 32/32 - 52.4ms/batch - loss: 1.58920 - diff: 24.85mlTrain batch 32/32 - 18.0s 52.4ms/batch - loss: 1.58920 - diff: 24.85ml
Test 1.4s: val_loss: 1.43405 - diff: 21.98ml

Epoch 45: current best loss = 1.40349, at epoch 39
Going to unfreeze the pretrained weights
Train batch 1/32 - 232.0ms/batch - loss: 0.85733 - diff: 13.72mlTrain batch 2/32 - 233.7ms/batch - loss: 1.43558 - diff: 22.97mlTrain batch 3/32 - 233.4ms/batch - loss: 1.62205 - diff: 25.95mlTrain batch 4/32 - 234.4ms/batch - loss: 1.90862 - diff: 30.54mlTrain batch 5/32 - 233.7ms/batch - loss: 1.81705 - diff: 29.07mlTrain batch 6/32 - 232.6ms/batch - loss: 1.77824 - diff: 28.45mlTrain batch 7/32 - 234.0ms/batch - loss: 1.81829 - diff: 29.09mlTrain batch 8/32 - 234.4ms/batch - loss: 1.75632 - diff: 28.10mlTrain batch 9/32 - 233.6ms/batch - loss: 1.73551 - diff: 27.77mlTrain batch 10/32 - 232.4ms/batch - loss: 1.67374 - diff: 26.78mlTrain batch 11/32 - 233.4ms/batch - loss: 1.68951 - diff: 27.03mlTrain batch 12/32 - 254.6ms/batch - loss: 1.66276 - diff: 26.60mlTrain batch 13/32 - 233.4ms/batch - loss: 1.64679 - diff: 26.35mlTrain batch 14/32 - 233.6ms/batch - loss: 1.65288 - diff: 26.45mlTrain batch 15/32 - 233.3ms/batch - loss: 1.65387 - diff: 26.46mlTrain batch 16/32 - 264.0ms/batch - loss: 1.62135 - diff: 25.94mlTrain batch 17/32 - 233.4ms/batch - loss: 1.61865 - diff: 25.90mlTrain batch 18/32 - 233.9ms/batch - loss: 1.63799 - diff: 26.21mlTrain batch 19/32 - 233.3ms/batch - loss: 1.64765 - diff: 26.36mlTrain batch 20/32 - 233.6ms/batch - loss: 1.63689 - diff: 26.19mlTrain batch 21/32 - 233.4ms/batch - loss: 1.67619 - diff: 26.82mlTrain batch 22/32 - 232.5ms/batch - loss: 1.67928 - diff: 26.87mlTrain batch 23/32 - 233.5ms/batch - loss: 1.66562 - diff: 26.65mlTrain batch 24/32 - 238.3ms/batch - loss: 1.64620 - diff: 26.34mlTrain batch 25/32 - 233.4ms/batch - loss: 1.65233 - diff: 26.44mlTrain batch 26/32 - 233.9ms/batch - loss: 1.64220 - diff: 26.28mlTrain batch 27/32 - 233.6ms/batch - loss: 1.63051 - diff: 26.09mlTrain batch 28/32 - 243.3ms/batch - loss: 1.62379 - diff: 25.98mlTrain batch 29/32 - 234.0ms/batch - loss: 1.65201 - diff: 26.43mlTrain batch 30/32 - 239.3ms/batch - loss: 1.62782 - diff: 26.05mlTrain batch 31/32 - 233.6ms/batch - loss: 1.62256 - diff: 25.96mlTrain batch 32/32 - 76.3ms/batch - loss: 1.66101 - diff: 25.96mlTrain batch 32/32 - 17.0s 76.3ms/batch - loss: 1.66101 - diff: 25.96ml
Test 1.4s: val_loss: 1.82213 - diff: 28.43ml

Epoch 46: current best loss = 1.40349, at epoch 39
Train batch 1/32 - 233.4ms/batch - loss: 1.98437 - diff: 31.75mlTrain batch 2/32 - 250.8ms/batch - loss: 1.51970 - diff: 24.32mlTrain batch 3/32 - 233.9ms/batch - loss: 1.49958 - diff: 23.99mlTrain batch 4/32 - 234.0ms/batch - loss: 1.48193 - diff: 23.71mlTrain batch 5/32 - 233.7ms/batch - loss: 1.50761 - diff: 24.12mlTrain batch 6/32 - 247.3ms/batch - loss: 1.52969 - diff: 24.48mlTrain batch 7/32 - 233.5ms/batch - loss: 1.47313 - diff: 23.57mlTrain batch 8/32 - 234.3ms/batch - loss: 1.46804 - diff: 23.49mlTrain batch 9/32 - 233.7ms/batch - loss: 1.49635 - diff: 23.94mlTrain batch 10/32 - 234.2ms/batch - loss: 1.54069 - diff: 24.65mlTrain batch 11/32 - 233.6ms/batch - loss: 1.51711 - diff: 24.27mlTrain batch 12/32 - 234.1ms/batch - loss: 1.52432 - diff: 24.39mlTrain batch 13/32 - 233.7ms/batch - loss: 1.48230 - diff: 23.72mlTrain batch 14/32 - 237.6ms/batch - loss: 1.46293 - diff: 23.41mlTrain batch 15/32 - 233.8ms/batch - loss: 1.48577 - diff: 23.77mlTrain batch 16/32 - 234.7ms/batch - loss: 1.54835 - diff: 24.77mlTrain batch 17/32 - 233.6ms/batch - loss: 1.56022 - diff: 24.96mlTrain batch 18/32 - 233.7ms/batch - loss: 1.55048 - diff: 24.81mlTrain batch 19/32 - 233.6ms/batch - loss: 1.54599 - diff: 24.74mlTrain batch 20/32 - 233.6ms/batch - loss: 1.52365 - diff: 24.38mlTrain batch 21/32 - 233.7ms/batch - loss: 1.52082 - diff: 24.33mlTrain batch 22/32 - 234.4ms/batch - loss: 1.57097 - diff: 25.14mlTrain batch 23/32 - 233.6ms/batch - loss: 1.55709 - diff: 24.91mlTrain batch 24/32 - 234.2ms/batch - loss: 1.57404 - diff: 25.18mlTrain batch 25/32 - 233.7ms/batch - loss: 1.55628 - diff: 24.90mlTrain batch 26/32 - 238.5ms/batch - loss: 1.54265 - diff: 24.68mlTrain batch 27/32 - 234.1ms/batch - loss: 1.56121 - diff: 24.98mlTrain batch 28/32 - 234.8ms/batch - loss: 1.55155 - diff: 24.82mlTrain batch 29/32 - 233.8ms/batch - loss: 1.53803 - diff: 24.61mlTrain batch 30/32 - 233.8ms/batch - loss: 1.55044 - diff: 24.81mlTrain batch 31/32 - 233.5ms/batch - loss: 1.54382 - diff: 24.70mlTrain batch 32/32 - 75.9ms/batch - loss: 1.57253 - diff: 24.67mlTrain batch 32/32 - 16.8s 75.9ms/batch - loss: 1.57253 - diff: 24.67ml
Test 1.5s: val_loss: 1.64741 - diff: 25.70ml

Epoch 47: current best loss = 1.40349, at epoch 39
Train batch 1/32 - 233.9ms/batch - loss: 1.26037 - diff: 20.17mlTrain batch 2/32 - 233.6ms/batch - loss: 1.43609 - diff: 22.98mlTrain batch 3/32 - 233.6ms/batch - loss: 1.39913 - diff: 22.39mlTrain batch 4/32 - 233.8ms/batch - loss: 1.45444 - diff: 23.27mlTrain batch 5/32 - 233.6ms/batch - loss: 1.42285 - diff: 22.77mlTrain batch 6/32 - 234.1ms/batch - loss: 1.35085 - diff: 21.61mlTrain batch 7/32 - 233.7ms/batch - loss: 1.41003 - diff: 22.56mlTrain batch 8/32 - 234.3ms/batch - loss: 1.50057 - diff: 24.01mlTrain batch 9/32 - 234.8ms/batch - loss: 1.46148 - diff: 23.38mlTrain batch 10/32 - 236.0ms/batch - loss: 1.45377 - diff: 23.26mlTrain batch 11/32 - 233.5ms/batch - loss: 1.39862 - diff: 22.38mlTrain batch 12/32 - 236.0ms/batch - loss: 1.41570 - diff: 22.65mlTrain batch 13/32 - 233.4ms/batch - loss: 1.41074 - diff: 22.57mlTrain batch 14/32 - 236.5ms/batch - loss: 1.44116 - diff: 23.06mlTrain batch 15/32 - 233.6ms/batch - loss: 1.46605 - diff: 23.46mlTrain batch 16/32 - 232.8ms/batch - loss: 1.45506 - diff: 23.28mlTrain batch 17/32 - 233.4ms/batch - loss: 1.50676 - diff: 24.11mlTrain batch 18/32 - 232.4ms/batch - loss: 1.52126 - diff: 24.34mlTrain batch 19/32 - 233.4ms/batch - loss: 1.49792 - diff: 23.97mlTrain batch 20/32 - 232.5ms/batch - loss: 1.47869 - diff: 23.66mlTrain batch 21/32 - 233.5ms/batch - loss: 1.47782 - diff: 23.65mlTrain batch 22/32 - 233.7ms/batch - loss: 1.49370 - diff: 23.90mlTrain batch 23/32 - 233.5ms/batch - loss: 1.49262 - diff: 23.88mlTrain batch 24/32 - 234.2ms/batch - loss: 1.51617 - diff: 24.26mlTrain batch 25/32 - 233.7ms/batch - loss: 1.56005 - diff: 24.96mlTrain batch 26/32 - 233.7ms/batch - loss: 1.55425 - diff: 24.87mlTrain batch 27/32 - 233.7ms/batch - loss: 1.55080 - diff: 24.81mlTrain batch 28/32 - 234.3ms/batch - loss: 1.59895 - diff: 25.58mlTrain batch 29/32 - 233.8ms/batch - loss: 1.60574 - diff: 25.69mlTrain batch 30/32 - 236.9ms/batch - loss: 1.59829 - diff: 25.57mlTrain batch 31/32 - 233.5ms/batch - loss: 1.57579 - diff: 25.21mlTrain batch 32/32 - 82.7ms/batch - loss: 1.68831 - diff: 25.51mlTrain batch 32/32 - 17.5s 82.7ms/batch - loss: 1.68831 - diff: 25.51ml
Test 1.5s: val_loss: 1.94368 - diff: 29.10ml

Epoch 48: current best loss = 1.40349, at epoch 39
Train batch 1/32 - 233.9ms/batch - loss: 1.50759 - diff: 24.12mlTrain batch 2/32 - 236.7ms/batch - loss: 1.77209 - diff: 28.35mlTrain batch 3/32 - 233.6ms/batch - loss: 1.68008 - diff: 26.88mlTrain batch 4/32 - 238.6ms/batch - loss: 1.68877 - diff: 27.02mlTrain batch 5/32 - 233.5ms/batch - loss: 1.73992 - diff: 27.84mlTrain batch 6/32 - 237.1ms/batch - loss: 1.77373 - diff: 28.38mlTrain batch 7/32 - 233.6ms/batch - loss: 1.72647 - diff: 27.62mlTrain batch 8/32 - 238.8ms/batch - loss: 1.71185 - diff: 27.39mlTrain batch 9/32 - 233.3ms/batch - loss: 1.61830 - diff: 25.89mlTrain batch 10/32 - 234.2ms/batch - loss: 1.61781 - diff: 25.89mlTrain batch 11/32 - 233.5ms/batch - loss: 1.69145 - diff: 27.06mlTrain batch 12/32 - 233.6ms/batch - loss: 1.65134 - diff: 26.42mlTrain batch 13/32 - 250.0ms/batch - loss: 1.60960 - diff: 25.75mlTrain batch 14/32 - 233.8ms/batch - loss: 1.58946 - diff: 25.43mlTrain batch 15/32 - 233.5ms/batch - loss: 1.57361 - diff: 25.18mlTrain batch 16/32 - 234.1ms/batch - loss: 1.59283 - diff: 25.49mlTrain batch 17/32 - 233.7ms/batch - loss: 1.57978 - diff: 25.28mlTrain batch 18/32 - 234.3ms/batch - loss: 1.60736 - diff: 25.72mlTrain batch 19/32 - 240.3ms/batch - loss: 1.56452 - diff: 25.03mlTrain batch 20/32 - 233.9ms/batch - loss: 1.56947 - diff: 25.11mlTrain batch 21/32 - 233.6ms/batch - loss: 1.54878 - diff: 24.78mlTrain batch 22/32 - 243.5ms/batch - loss: 1.53049 - diff: 24.49mlTrain batch 23/32 - 233.5ms/batch - loss: 1.53035 - diff: 24.49mlTrain batch 24/32 - 233.6ms/batch - loss: 1.52345 - diff: 24.38mlTrain batch 25/32 - 234.5ms/batch - loss: 1.49666 - diff: 23.95mlTrain batch 26/32 - 234.1ms/batch - loss: 1.51099 - diff: 24.18mlTrain batch 27/32 - 234.2ms/batch - loss: 1.49810 - diff: 23.97mlTrain batch 28/32 - 234.4ms/batch - loss: 1.48772 - diff: 23.80mlTrain batch 29/32 - 233.3ms/batch - loss: 1.52281 - diff: 24.37mlTrain batch 30/32 - 234.1ms/batch - loss: 1.49887 - diff: 23.98mlTrain batch 31/32 - 233.6ms/batch - loss: 1.53184 - diff: 24.51mlTrain batch 32/32 - 82.7ms/batch - loss: 1.54224 - diff: 24.40mlTrain batch 32/32 - 17.0s 82.7ms/batch - loss: 1.54224 - diff: 24.40ml
Test 1.5s: val_loss: 1.50106 - diff: 23.02ml

Epoch 49: current best loss = 1.40349, at epoch 39
Train batch 1/32 - 233.8ms/batch - loss: 1.33535 - diff: 21.37mlTrain batch 2/32 - 240.3ms/batch - loss: 1.42583 - diff: 22.81mlTrain batch 3/32 - 233.7ms/batch - loss: 1.25700 - diff: 20.11mlTrain batch 4/32 - 234.1ms/batch - loss: 1.25876 - diff: 20.14mlTrain batch 5/32 - 233.4ms/batch - loss: 1.24178 - diff: 19.87mlTrain batch 6/32 - 234.1ms/batch - loss: 1.23759 - diff: 19.80mlTrain batch 7/32 - 233.7ms/batch - loss: 1.34070 - diff: 21.45mlTrain batch 8/32 - 251.4ms/batch - loss: 1.41198 - diff: 22.59mlTrain batch 9/32 - 233.3ms/batch - loss: 1.42937 - diff: 22.87mlTrain batch 10/32 - 233.6ms/batch - loss: 1.42480 - diff: 22.80mlTrain batch 11/32 - 233.5ms/batch - loss: 1.37851 - diff: 22.06mlTrain batch 12/32 - 234.0ms/batch - loss: 1.35918 - diff: 21.75mlTrain batch 13/32 - 233.8ms/batch - loss: 1.40137 - diff: 22.42mlTrain batch 14/32 - 233.6ms/batch - loss: 1.39374 - diff: 22.30mlTrain batch 15/32 - 233.8ms/batch - loss: 1.39609 - diff: 22.34mlTrain batch 16/32 - 233.9ms/batch - loss: 1.40381 - diff: 22.46mlTrain batch 17/32 - 233.6ms/batch - loss: 1.41001 - diff: 22.56mlTrain batch 18/32 - 233.8ms/batch - loss: 1.50421 - diff: 24.07mlTrain batch 19/32 - 233.7ms/batch - loss: 1.53769 - diff: 24.60mlTrain batch 20/32 - 233.9ms/batch - loss: 1.52585 - diff: 24.41mlTrain batch 21/32 - 233.3ms/batch - loss: 1.52932 - diff: 24.47mlTrain batch 22/32 - 233.8ms/batch - loss: 1.53544 - diff: 24.57mlTrain batch 23/32 - 233.8ms/batch - loss: 1.52895 - diff: 24.46mlTrain batch 24/32 - 232.9ms/batch - loss: 1.51247 - diff: 24.20mlTrain batch 25/32 - 233.4ms/batch - loss: 1.50446 - diff: 24.07mlTrain batch 26/32 - 242.8ms/batch - loss: 1.52831 - diff: 24.45mlTrain batch 27/32 - 241.6ms/batch - loss: 1.51680 - diff: 24.27mlTrain batch 28/32 - 233.7ms/batch - loss: 1.50309 - diff: 24.05mlTrain batch 29/32 - 233.7ms/batch - loss: 1.50243 - diff: 24.04mlTrain batch 30/32 - 232.6ms/batch - loss: 1.47142 - diff: 23.54mlTrain batch 31/32 - 233.7ms/batch - loss: 1.47446 - diff: 23.59mlTrain batch 32/32 - 76.2ms/batch - loss: 1.48897 - diff: 23.51mlTrain batch 32/32 - 17.1s 76.2ms/batch - loss: 1.48897 - diff: 23.51ml
Test 1.6s: val_loss: 2.00955 - diff: 30.21ml

Epoch 50: current best loss = 1.40349, at epoch 39
Train batch 1/32 - 238.5ms/batch - loss: 1.09691 - diff: 17.55mlTrain batch 2/32 - 232.6ms/batch - loss: 1.26847 - diff: 20.30mlTrain batch 3/32 - 233.6ms/batch - loss: 1.54967 - diff: 24.79mlTrain batch 4/32 - 233.5ms/batch - loss: 1.60503 - diff: 25.68mlTrain batch 5/32 - 233.9ms/batch - loss: 1.57697 - diff: 25.23mlTrain batch 6/32 - 233.9ms/batch - loss: 1.71893 - diff: 27.50mlTrain batch 7/32 - 233.9ms/batch - loss: 1.71856 - diff: 27.50mlTrain batch 8/32 - 234.0ms/batch - loss: 1.61696 - diff: 25.87mlTrain batch 9/32 - 233.6ms/batch - loss: 1.54291 - diff: 24.69mlTrain batch 10/32 - 233.8ms/batch - loss: 1.52494 - diff: 24.40mlTrain batch 11/32 - 233.6ms/batch - loss: 1.50232 - diff: 24.04mlTrain batch 12/32 - 233.7ms/batch - loss: 1.46573 - diff: 23.45mlTrain batch 13/32 - 233.7ms/batch - loss: 1.41027 - diff: 22.56mlTrain batch 14/32 - 233.8ms/batch - loss: 1.39263 - diff: 22.28mlTrain batch 15/32 - 234.5ms/batch - loss: 1.45688 - diff: 23.31mlTrain batch 16/32 - 233.6ms/batch - loss: 1.51487 - diff: 24.24mlTrain batch 17/32 - 234.6ms/batch - loss: 1.51387 - diff: 24.22mlTrain batch 18/32 - 245.5ms/batch - loss: 1.49289 - diff: 23.89mlTrain batch 19/32 - 236.4ms/batch - loss: 1.48128 - diff: 23.70mlTrain batch 20/32 - 234.1ms/batch - loss: 1.49406 - diff: 23.90mlTrain batch 21/32 - 244.5ms/batch - loss: 1.46983 - diff: 23.52mlTrain batch 22/32 - 233.7ms/batch - loss: 1.48298 - diff: 23.73mlTrain batch 23/32 - 234.1ms/batch - loss: 1.48639 - diff: 23.78mlTrain batch 24/32 - 233.7ms/batch - loss: 1.46373 - diff: 23.42mlTrain batch 25/32 - 234.1ms/batch - loss: 1.46632 - diff: 23.46mlTrain batch 26/32 - 233.8ms/batch - loss: 1.46681 - diff: 23.47mlTrain batch 27/32 - 234.3ms/batch - loss: 1.46857 - diff: 23.50mlTrain batch 28/32 - 233.4ms/batch - loss: 1.50000 - diff: 24.00mlTrain batch 29/32 - 234.4ms/batch - loss: 1.48910 - diff: 23.83mlTrain batch 30/32 - 233.7ms/batch - loss: 1.48387 - diff: 23.74mlTrain batch 31/32 - 234.2ms/batch - loss: 1.47324 - diff: 23.57mlTrain batch 32/32 - 76.6ms/batch - loss: 1.50174 - diff: 23.54mlTrain batch 32/32 - 15.8s 76.6ms/batch - loss: 1.50174 - diff: 23.54ml
Test 1.5s: val_loss: 1.53290 - diff: 23.53ml
Epoch    51: reducing learning rate of group 0 to 5.0000e-04.

Epoch 51: current best loss = 1.40349, at epoch 39
Train batch 1/32 - 233.9ms/batch - loss: 1.16330 - diff: 18.61mlTrain batch 2/32 - 233.6ms/batch - loss: 1.18557 - diff: 18.97mlTrain batch 3/32 - 233.8ms/batch - loss: 1.17946 - diff: 18.87mlTrain batch 4/32 - 234.6ms/batch - loss: 1.34233 - diff: 21.48mlTrain batch 5/32 - 233.6ms/batch - loss: 1.26852 - diff: 20.30mlTrain batch 6/32 - 233.7ms/batch - loss: 1.27966 - diff: 20.47mlTrain batch 7/32 - 233.6ms/batch - loss: 1.31744 - diff: 21.08mlTrain batch 8/32 - 233.9ms/batch - loss: 1.33872 - diff: 21.42mlTrain batch 9/32 - 233.8ms/batch - loss: 1.39474 - diff: 22.32mlTrain batch 10/32 - 246.2ms/batch - loss: 1.37489 - diff: 22.00mlTrain batch 11/32 - 257.1ms/batch - loss: 1.34604 - diff: 21.54mlTrain batch 12/32 - 234.3ms/batch - loss: 1.31986 - diff: 21.12mlTrain batch 13/32 - 234.6ms/batch - loss: 1.30778 - diff: 20.92mlTrain batch 14/32 - 234.4ms/batch - loss: 1.38692 - diff: 22.19mlTrain batch 15/32 - 234.3ms/batch - loss: 1.39135 - diff: 22.26mlTrain batch 16/32 - 234.6ms/batch - loss: 1.36173 - diff: 21.79mlTrain batch 17/32 - 234.8ms/batch - loss: 1.34956 - diff: 21.59mlTrain batch 18/32 - 234.6ms/batch - loss: 1.33730 - diff: 21.40mlTrain batch 19/32 - 234.4ms/batch - loss: 1.32786 - diff: 21.25mlTrain batch 20/32 - 234.1ms/batch - loss: 1.35498 - diff: 21.68mlTrain batch 21/32 - 234.8ms/batch - loss: 1.36517 - diff: 21.84mlTrain batch 22/32 - 234.5ms/batch - loss: 1.35180 - diff: 21.63mlTrain batch 23/32 - 234.4ms/batch - loss: 1.34368 - diff: 21.50mlTrain batch 24/32 - 234.5ms/batch - loss: 1.33614 - diff: 21.38mlTrain batch 25/32 - 234.7ms/batch - loss: 1.32907 - diff: 21.27mlTrain batch 26/32 - 233.8ms/batch - loss: 1.41752 - diff: 22.68mlTrain batch 27/32 - 237.0ms/batch - loss: 1.41571 - diff: 22.65mlTrain batch 28/32 - 233.9ms/batch - loss: 1.43032 - diff: 22.89mlTrain batch 29/32 - 234.5ms/batch - loss: 1.42438 - diff: 22.79mlTrain batch 30/32 - 233.9ms/batch - loss: 1.41721 - diff: 22.68mlTrain batch 31/32 - 234.1ms/batch - loss: 1.43437 - diff: 22.95mlTrain batch 32/32 - 84.3ms/batch - loss: 1.45220 - diff: 22.88mlTrain batch 32/32 - 16.6s 84.3ms/batch - loss: 1.45220 - diff: 22.88ml
Test 1.6s: val_loss: 1.26353 - diff: 19.16ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Systole_WideResNet50_0_Adam-0.001_MAE_DA3_best

Epoch 52: current best loss = 1.26353, at epoch 51
Train batch 1/32 - 249.6ms/batch - loss: 1.44706 - diff: 23.15mlTrain batch 2/32 - 237.8ms/batch - loss: 1.62132 - diff: 25.94mlTrain batch 3/32 - 233.6ms/batch - loss: 1.78318 - diff: 28.53mlTrain batch 4/32 - 233.9ms/batch - loss: 1.59792 - diff: 25.57mlTrain batch 5/32 - 233.8ms/batch - loss: 1.54257 - diff: 24.68mlTrain batch 6/32 - 233.6ms/batch - loss: 1.45875 - diff: 23.34mlTrain batch 7/32 - 234.1ms/batch - loss: 1.52809 - diff: 24.45mlTrain batch 8/32 - 234.2ms/batch - loss: 1.49089 - diff: 23.85mlTrain batch 9/32 - 233.5ms/batch - loss: 1.46719 - diff: 23.48mlTrain batch 10/32 - 233.8ms/batch - loss: 1.47422 - diff: 23.59mlTrain batch 11/32 - 233.6ms/batch - loss: 1.45180 - diff: 23.23mlTrain batch 12/32 - 233.5ms/batch - loss: 1.40206 - diff: 22.43mlTrain batch 13/32 - 233.6ms/batch - loss: 1.39180 - diff: 22.27mlTrain batch 14/32 - 233.8ms/batch - loss: 1.40091 - diff: 22.41mlTrain batch 15/32 - 233.6ms/batch - loss: 1.38056 - diff: 22.09mlTrain batch 16/32 - 237.8ms/batch - loss: 1.44931 - diff: 23.19mlTrain batch 17/32 - 234.0ms/batch - loss: 1.50647 - diff: 24.10mlTrain batch 18/32 - 233.8ms/batch - loss: 1.47804 - diff: 23.65mlTrain batch 19/32 - 233.6ms/batch - loss: 1.51031 - diff: 24.16mlTrain batch 20/32 - 234.2ms/batch - loss: 1.48313 - diff: 23.73mlTrain batch 21/32 - 233.6ms/batch - loss: 1.46407 - diff: 23.43mlTrain batch 22/32 - 237.9ms/batch - loss: 1.46728 - diff: 23.48mlTrain batch 23/32 - 233.8ms/batch - loss: 1.45311 - diff: 23.25mlTrain batch 24/32 - 233.8ms/batch - loss: 1.42621 - diff: 22.82mlTrain batch 25/32 - 233.7ms/batch - loss: 1.42839 - diff: 22.85mlTrain batch 26/32 - 234.0ms/batch - loss: 1.43695 - diff: 22.99mlTrain batch 27/32 - 238.4ms/batch - loss: 1.42952 - diff: 22.87mlTrain batch 28/32 - 234.0ms/batch - loss: 1.44668 - diff: 23.15mlTrain batch 29/32 - 233.4ms/batch - loss: 1.44139 - diff: 23.06mlTrain batch 30/32 - 234.2ms/batch - loss: 1.43391 - diff: 22.94mlTrain batch 31/32 - 233.7ms/batch - loss: 1.42389 - diff: 22.78mlTrain batch 32/32 - 76.1ms/batch - loss: 1.43848 - diff: 22.70mlTrain batch 32/32 - 18.4s 76.1ms/batch - loss: 1.43848 - diff: 22.70ml
Test 1.6s: val_loss: 1.83759 - diff: 28.56ml

Epoch 53: current best loss = 1.26353, at epoch 51
Train batch 1/32 - 241.1ms/batch - loss: 1.39641 - diff: 22.34mlTrain batch 2/32 - 233.5ms/batch - loss: 1.09272 - diff: 17.48mlTrain batch 3/32 - 233.7ms/batch - loss: 0.97186 - diff: 15.55mlTrain batch 4/32 - 234.1ms/batch - loss: 1.41594 - diff: 22.65mlTrain batch 5/32 - 233.6ms/batch - loss: 1.45253 - diff: 23.24mlTrain batch 6/32 - 235.1ms/batch - loss: 1.52724 - diff: 24.44mlTrain batch 7/32 - 233.3ms/batch - loss: 1.47082 - diff: 23.53mlTrain batch 8/32 - 245.2ms/batch - loss: 1.46320 - diff: 23.41mlTrain batch 9/32 - 238.4ms/batch - loss: 1.39955 - diff: 22.39mlTrain batch 10/32 - 234.1ms/batch - loss: 1.44737 - diff: 23.16mlTrain batch 11/32 - 233.7ms/batch - loss: 1.41533 - diff: 22.65mlTrain batch 12/32 - 233.9ms/batch - loss: 1.40756 - diff: 22.52mlTrain batch 13/32 - 233.7ms/batch - loss: 1.39872 - diff: 22.38mlTrain batch 14/32 - 264.8ms/batch - loss: 1.40857 - diff: 22.54mlTrain batch 15/32 - 233.5ms/batch - loss: 1.37890 - diff: 22.06mlTrain batch 16/32 - 234.0ms/batch - loss: 1.39026 - diff: 22.24mlTrain batch 17/32 - 233.4ms/batch - loss: 1.38280 - diff: 22.12mlTrain batch 18/32 - 237.6ms/batch - loss: 1.37630 - diff: 22.02mlTrain batch 19/32 - 233.7ms/batch - loss: 1.37867 - diff: 22.06mlTrain batch 20/32 - 238.3ms/batch - loss: 1.36619 - diff: 21.86mlTrain batch 21/32 - 233.8ms/batch - loss: 1.39641 - diff: 22.34mlTrain batch 22/32 - 238.4ms/batch - loss: 1.37965 - diff: 22.07mlTrain batch 23/32 - 233.7ms/batch - loss: 1.39688 - diff: 22.35mlTrain batch 24/32 - 234.2ms/batch - loss: 1.38614 - diff: 22.18mlTrain batch 25/32 - 233.6ms/batch - loss: 1.40210 - diff: 22.43mlTrain batch 26/32 - 238.1ms/batch - loss: 1.39899 - diff: 22.38mlTrain batch 27/32 - 233.8ms/batch - loss: 1.38785 - diff: 22.21mlTrain batch 28/32 - 233.8ms/batch - loss: 1.37575 - diff: 22.01mlTrain batch 29/32 - 233.9ms/batch - loss: 1.38772 - diff: 22.20mlTrain batch 30/32 - 236.4ms/batch - loss: 1.37927 - diff: 22.07mlTrain batch 31/32 - 233.8ms/batch - loss: 1.38411 - diff: 22.15mlTrain batch 32/32 - 76.3ms/batch - loss: 1.43942 - diff: 22.23mlTrain batch 32/32 - 17.1s 76.3ms/batch - loss: 1.43942 - diff: 22.23ml
Test 1.5s: val_loss: 1.38678 - diff: 21.61ml

Epoch 54: current best loss = 1.26353, at epoch 51
Train batch 1/32 - 234.0ms/batch - loss: 1.12652 - diff: 18.02mlTrain batch 2/32 - 236.2ms/batch - loss: 1.25254 - diff: 20.04mlTrain batch 3/32 - 233.7ms/batch - loss: 1.11009 - diff: 17.76mlTrain batch 4/32 - 233.9ms/batch - loss: 1.12569 - diff: 18.01mlTrain batch 5/32 - 233.9ms/batch - loss: 1.08186 - diff: 17.31mlTrain batch 6/32 - 234.0ms/batch - loss: 1.12956 - diff: 18.07mlTrain batch 7/32 - 233.7ms/batch - loss: 1.12758 - diff: 18.04mlTrain batch 8/32 - 233.5ms/batch - loss: 1.08954 - diff: 17.43mlTrain batch 9/32 - 233.8ms/batch - loss: 1.20776 - diff: 19.32mlTrain batch 10/32 - 248.5ms/batch - loss: 1.16259 - diff: 18.60mlTrain batch 11/32 - 233.9ms/batch - loss: 1.17188 - diff: 18.75mlTrain batch 12/32 - 233.7ms/batch - loss: 1.14559 - diff: 18.33mlTrain batch 13/32 - 233.8ms/batch - loss: 1.16164 - diff: 18.59mlTrain batch 14/32 - 233.6ms/batch - loss: 1.23909 - diff: 19.83mlTrain batch 15/32 - 233.9ms/batch - loss: 1.23124 - diff: 19.70mlTrain batch 16/32 - 234.0ms/batch - loss: 1.26868 - diff: 20.30mlTrain batch 17/32 - 233.8ms/batch - loss: 1.25230 - diff: 20.04mlTrain batch 18/32 - 233.8ms/batch - loss: 1.23593 - diff: 19.77mlTrain batch 19/32 - 233.7ms/batch - loss: 1.28929 - diff: 20.63mlTrain batch 20/32 - 233.8ms/batch - loss: 1.29473 - diff: 20.72mlTrain batch 21/32 - 233.5ms/batch - loss: 1.27544 - diff: 20.41mlTrain batch 22/32 - 237.9ms/batch - loss: 1.30262 - diff: 20.84mlTrain batch 23/32 - 233.6ms/batch - loss: 1.36259 - diff: 21.80mlTrain batch 24/32 - 237.4ms/batch - loss: 1.36461 - diff: 21.83mlTrain batch 25/32 - 233.8ms/batch - loss: 1.36348 - diff: 21.82mlTrain batch 26/32 - 237.0ms/batch - loss: 1.35314 - diff: 21.65mlTrain batch 27/32 - 233.7ms/batch - loss: 1.36052 - diff: 21.77mlTrain batch 28/32 - 236.5ms/batch - loss: 1.34449 - diff: 21.51mlTrain batch 29/32 - 233.7ms/batch - loss: 1.34189 - diff: 21.47mlTrain batch 30/32 - 234.1ms/batch - loss: 1.34706 - diff: 21.55mlTrain batch 31/32 - 233.8ms/batch - loss: 1.33264 - diff: 21.32mlTrain batch 32/32 - 80.2ms/batch - loss: 1.36345 - diff: 21.32mlTrain batch 32/32 - 16.9s 80.2ms/batch - loss: 1.36345 - diff: 21.32ml
Test 1.5s: val_loss: 1.30127 - diff: 20.42ml

Epoch 55: current best loss = 1.26353, at epoch 51
Train batch 1/32 - 250.7ms/batch - loss: 1.39832 - diff: 22.37mlTrain batch 2/32 - 241.6ms/batch - loss: 1.31180 - diff: 20.99mlTrain batch 3/32 - 235.5ms/batch - loss: 1.31295 - diff: 21.01mlTrain batch 4/32 - 233.9ms/batch - loss: 1.25858 - diff: 20.14mlTrain batch 5/32 - 233.8ms/batch - loss: 1.35527 - diff: 21.68mlTrain batch 6/32 - 234.2ms/batch - loss: 1.32212 - diff: 21.15mlTrain batch 7/32 - 233.6ms/batch - loss: 1.30349 - diff: 20.86mlTrain batch 8/32 - 246.1ms/batch - loss: 1.28169 - diff: 20.51mlTrain batch 9/32 - 234.8ms/batch - loss: 1.30140 - diff: 20.82mlTrain batch 10/32 - 235.8ms/batch - loss: 1.32597 - diff: 21.22mlTrain batch 11/32 - 234.0ms/batch - loss: 1.44187 - diff: 23.07mlTrain batch 12/32 - 234.3ms/batch - loss: 1.42824 - diff: 22.85mlTrain batch 13/32 - 233.7ms/batch - loss: 1.43597 - diff: 22.98mlTrain batch 14/32 - 249.5ms/batch - loss: 1.38936 - diff: 22.23mlTrain batch 15/32 - 233.7ms/batch - loss: 1.41435 - diff: 22.63mlTrain batch 16/32 - 233.0ms/batch - loss: 1.39014 - diff: 22.24mlTrain batch 17/32 - 233.4ms/batch - loss: 1.40455 - diff: 22.47mlTrain batch 18/32 - 246.6ms/batch - loss: 1.40719 - diff: 22.51mlTrain batch 19/32 - 233.8ms/batch - loss: 1.42782 - diff: 22.85mlTrain batch 20/32 - 236.8ms/batch - loss: 1.40708 - diff: 22.51mlTrain batch 21/32 - 233.8ms/batch - loss: 1.40505 - diff: 22.48mlTrain batch 22/32 - 234.2ms/batch - loss: 1.39489 - diff: 22.32mlTrain batch 23/32 - 233.6ms/batch - loss: 1.38772 - diff: 22.20mlTrain batch 24/32 - 248.2ms/batch - loss: 1.37252 - diff: 21.96mlTrain batch 25/32 - 233.6ms/batch - loss: 1.36316 - diff: 21.81mlTrain batch 26/32 - 251.8ms/batch - loss: 1.36811 - diff: 21.89mlTrain batch 27/32 - 233.7ms/batch - loss: 1.35267 - diff: 21.64mlTrain batch 28/32 - 233.6ms/batch - loss: 1.34315 - diff: 21.49mlTrain batch 29/32 - 233.8ms/batch - loss: 1.34392 - diff: 21.50mlTrain batch 30/32 - 233.9ms/batch - loss: 1.33210 - diff: 21.31mlTrain batch 31/32 - 233.7ms/batch - loss: 1.33637 - diff: 21.38mlTrain batch 32/32 - 76.4ms/batch - loss: 1.38759 - diff: 21.46mlTrain batch 32/32 - 18.2s 76.4ms/batch - loss: 1.38759 - diff: 21.46ml
Test 1.6s: val_loss: 1.30407 - diff: 19.56ml

Epoch 56: current best loss = 1.26353, at epoch 51
Train batch 1/32 - 233.9ms/batch - loss: 0.90768 - diff: 14.52mlTrain batch 2/32 - 240.1ms/batch - loss: 1.10164 - diff: 17.63mlTrain batch 3/32 - 233.6ms/batch - loss: 0.99799 - diff: 15.97mlTrain batch 4/32 - 234.3ms/batch - loss: 1.02161 - diff: 16.35mlTrain batch 5/32 - 233.7ms/batch - loss: 1.04029 - diff: 16.64mlTrain batch 6/32 - 234.3ms/batch - loss: 1.03753 - diff: 16.60mlTrain batch 7/32 - 233.5ms/batch - loss: 1.25096 - diff: 20.02mlTrain batch 8/32 - 233.7ms/batch - loss: 1.32848 - diff: 21.26mlTrain batch 9/32 - 233.8ms/batch - loss: 1.27346 - diff: 20.38mlTrain batch 10/32 - 234.0ms/batch - loss: 1.27746 - diff: 20.44mlTrain batch 11/32 - 233.7ms/batch - loss: 1.25470 - diff: 20.08mlTrain batch 12/32 - 238.0ms/batch - loss: 1.27641 - diff: 20.42mlTrain batch 13/32 - 233.8ms/batch - loss: 1.33708 - diff: 21.39mlTrain batch 14/32 - 234.3ms/batch - loss: 1.39436 - diff: 22.31mlTrain batch 15/32 - 233.8ms/batch - loss: 1.38228 - diff: 22.12mlTrain batch 16/32 - 238.4ms/batch - loss: 1.36409 - diff: 21.83mlTrain batch 17/32 - 233.5ms/batch - loss: 1.38027 - diff: 22.08mlTrain batch 18/32 - 234.0ms/batch - loss: 1.37781 - diff: 22.04mlTrain batch 19/32 - 233.6ms/batch - loss: 1.36243 - diff: 21.80mlTrain batch 20/32 - 234.3ms/batch - loss: 1.36009 - diff: 21.76mlTrain batch 21/32 - 233.8ms/batch - loss: 1.36768 - diff: 21.88mlTrain batch 22/32 - 234.9ms/batch - loss: 1.37526 - diff: 22.00mlTrain batch 23/32 - 233.9ms/batch - loss: 1.38665 - diff: 22.19mlTrain batch 24/32 - 233.2ms/batch - loss: 1.44339 - diff: 23.09mlTrain batch 25/32 - 233.9ms/batch - loss: 1.43707 - diff: 22.99mlTrain batch 26/32 - 233.7ms/batch - loss: 1.44200 - diff: 23.07mlTrain batch 27/32 - 234.1ms/batch - loss: 1.42602 - diff: 22.82mlTrain batch 28/32 - 233.7ms/batch - loss: 1.41281 - diff: 22.61mlTrain batch 29/32 - 234.2ms/batch - loss: 1.42308 - diff: 22.77mlTrain batch 30/32 - 233.8ms/batch - loss: 1.43582 - diff: 22.97mlTrain batch 31/32 - 233.8ms/batch - loss: 1.43766 - diff: 23.00mlTrain batch 32/32 - 76.5ms/batch - loss: 1.44997 - diff: 22.91mlTrain batch 32/32 - 16.2s 76.5ms/batch - loss: 1.44997 - diff: 22.91ml
Test 1.6s: val_loss: 1.39096 - diff: 21.70ml

Epoch 57: current best loss = 1.26353, at epoch 51
Train batch 1/32 - 233.8ms/batch - loss: 1.15968 - diff: 18.55mlTrain batch 2/32 - 243.3ms/batch - loss: 1.27333 - diff: 20.37mlTrain batch 3/32 - 233.6ms/batch - loss: 1.24566 - diff: 19.93mlTrain batch 4/32 - 234.7ms/batch - loss: 1.18907 - diff: 19.03mlTrain batch 5/32 - 234.0ms/batch - loss: 1.15968 - diff: 18.55mlTrain batch 6/32 - 233.9ms/batch - loss: 1.21083 - diff: 19.37mlTrain batch 7/32 - 233.5ms/batch - loss: 1.21195 - diff: 19.39mlTrain batch 8/32 - 235.7ms/batch - loss: 1.24777 - diff: 19.96mlTrain batch 9/32 - 234.0ms/batch - loss: 1.20503 - diff: 19.28mlTrain batch 10/32 - 233.2ms/batch - loss: 1.25436 - diff: 20.07mlTrain batch 11/32 - 246.7ms/batch - loss: 1.46438 - diff: 23.43mlTrain batch 12/32 - 234.3ms/batch - loss: 1.44042 - diff: 23.05mlTrain batch 13/32 - 233.6ms/batch - loss: 1.43884 - diff: 23.02mlTrain batch 14/32 - 234.2ms/batch - loss: 1.41299 - diff: 22.61mlTrain batch 15/32 - 233.6ms/batch - loss: 1.38083 - diff: 22.09mlTrain batch 16/32 - 234.2ms/batch - loss: 1.35746 - diff: 21.72mlTrain batch 17/32 - 233.9ms/batch - loss: 1.33714 - diff: 21.39mlTrain batch 18/32 - 233.8ms/batch - loss: 1.38314 - diff: 22.13mlTrain batch 19/32 - 233.7ms/batch - loss: 1.36613 - diff: 21.86mlTrain batch 20/32 - 234.0ms/batch - loss: 1.34039 - diff: 21.45mlTrain batch 21/32 - 234.0ms/batch - loss: 1.33054 - diff: 21.29mlTrain batch 22/32 - 233.9ms/batch - loss: 1.33329 - diff: 21.33mlTrain batch 23/32 - 234.1ms/batch - loss: 1.31443 - diff: 21.03mlTrain batch 24/32 - 233.8ms/batch - loss: 1.30787 - diff: 20.93mlTrain batch 25/32 - 239.0ms/batch - loss: 1.28955 - diff: 20.63mlTrain batch 26/32 - 233.8ms/batch - loss: 1.30887 - diff: 20.94mlTrain batch 27/32 - 238.2ms/batch - loss: 1.31561 - diff: 21.05mlTrain batch 28/32 - 233.9ms/batch - loss: 1.30794 - diff: 20.93mlTrain batch 29/32 - 234.0ms/batch - loss: 1.32043 - diff: 21.13mlTrain batch 30/32 - 234.2ms/batch - loss: 1.33297 - diff: 21.33mlTrain batch 31/32 - 233.9ms/batch - loss: 1.30584 - diff: 20.89mlTrain batch 32/32 - 76.8ms/batch - loss: 1.33397 - diff: 20.88mlTrain batch 32/32 - 16.6s 76.8ms/batch - loss: 1.33397 - diff: 20.88ml
Test 1.5s: val_loss: 2.01802 - diff: 30.30ml

Epoch 58: current best loss = 1.26353, at epoch 51
Train batch 1/32 - 233.8ms/batch - loss: 1.59257 - diff: 25.48mlTrain batch 2/32 - 234.0ms/batch - loss: 1.36158 - diff: 21.79mlTrain batch 3/32 - 233.8ms/batch - loss: 1.08806 - diff: 17.41mlTrain batch 4/32 - 249.6ms/batch - loss: 1.24749 - diff: 19.96mlTrain batch 5/32 - 233.9ms/batch - loss: 1.19433 - diff: 19.11mlTrain batch 6/32 - 234.3ms/batch - loss: 1.09820 - diff: 17.57mlTrain batch 7/32 - 233.8ms/batch - loss: 1.16970 - diff: 18.72mlTrain batch 8/32 - 234.2ms/batch - loss: 1.14277 - diff: 18.28mlTrain batch 9/32 - 234.1ms/batch - loss: 1.14481 - diff: 18.32mlTrain batch 10/32 - 234.5ms/batch - loss: 1.17449 - diff: 18.79mlTrain batch 11/32 - 239.3ms/batch - loss: 1.18076 - diff: 18.89mlTrain batch 12/32 - 234.4ms/batch - loss: 1.14851 - diff: 18.38mlTrain batch 13/32 - 233.8ms/batch - loss: 1.26283 - diff: 20.21mlTrain batch 14/32 - 242.5ms/batch - loss: 1.23856 - diff: 19.82mlTrain batch 15/32 - 233.7ms/batch - loss: 1.26796 - diff: 20.29mlTrain batch 16/32 - 233.4ms/batch - loss: 1.26650 - diff: 20.26mlTrain batch 17/32 - 236.8ms/batch - loss: 1.24990 - diff: 20.00mlTrain batch 18/32 - 234.2ms/batch - loss: 1.26215 - diff: 20.19mlTrain batch 19/32 - 234.2ms/batch - loss: 1.25350 - diff: 20.06mlTrain batch 20/32 - 234.9ms/batch - loss: 1.25372 - diff: 20.06mlTrain batch 21/32 - 234.7ms/batch - loss: 1.24349 - diff: 19.90mlTrain batch 22/32 - 234.5ms/batch - loss: 1.24468 - diff: 19.91mlTrain batch 23/32 - 233.8ms/batch - loss: 1.24705 - diff: 19.95mlTrain batch 24/32 - 243.3ms/batch - loss: 1.24061 - diff: 19.85mlTrain batch 25/32 - 234.4ms/batch - loss: 1.23725 - diff: 19.80mlTrain batch 26/32 - 234.0ms/batch - loss: 1.23229 - diff: 19.72mlTrain batch 27/32 - 234.7ms/batch - loss: 1.25140 - diff: 20.02mlTrain batch 28/32 - 234.4ms/batch - loss: 1.28134 - diff: 20.50mlTrain batch 29/32 - 234.3ms/batch - loss: 1.27546 - diff: 20.41mlTrain batch 30/32 - 234.9ms/batch - loss: 1.28555 - diff: 20.57mlTrain batch 31/32 - 233.9ms/batch - loss: 1.28695 - diff: 20.59mlTrain batch 32/32 - 79.9ms/batch - loss: 1.31509 - diff: 20.58mlTrain batch 32/32 - 16.1s 79.9ms/batch - loss: 1.31509 - diff: 20.58ml
Test 1.5s: val_loss: 1.17378 - diff: 18.01ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Systole_WideResNet50_0_Adam-0.001_MAE_DA3_best

Epoch 59: current best loss = 1.17378, at epoch 58
Train batch 1/32 - 264.2ms/batch - loss: 0.96370 - diff: 15.42mlTrain batch 2/32 - 234.3ms/batch - loss: 0.94768 - diff: 15.16mlTrain batch 3/32 - 233.6ms/batch - loss: 0.93123 - diff: 14.90mlTrain batch 4/32 - 244.6ms/batch - loss: 0.94558 - diff: 15.13mlTrain batch 5/32 - 233.7ms/batch - loss: 1.04049 - diff: 16.65mlTrain batch 6/32 - 234.9ms/batch - loss: 1.05826 - diff: 16.93mlTrain batch 7/32 - 233.5ms/batch - loss: 1.08250 - diff: 17.32mlTrain batch 8/32 - 242.0ms/batch - loss: 1.14461 - diff: 18.31mlTrain batch 9/32 - 233.7ms/batch - loss: 1.13204 - diff: 18.11mlTrain batch 10/32 - 234.9ms/batch - loss: 1.09382 - diff: 17.50mlTrain batch 11/32 - 233.7ms/batch - loss: 1.11955 - diff: 17.91mlTrain batch 12/32 - 235.8ms/batch - loss: 1.14746 - diff: 18.36mlTrain batch 13/32 - 233.7ms/batch - loss: 1.16300 - diff: 18.61mlTrain batch 14/32 - 234.1ms/batch - loss: 1.23308 - diff: 19.73mlTrain batch 15/32 - 233.8ms/batch - loss: 1.22859 - diff: 19.66mlTrain batch 16/32 - 233.9ms/batch - loss: 1.24052 - diff: 19.85mlTrain batch 17/32 - 233.8ms/batch - loss: 1.22508 - diff: 19.60mlTrain batch 18/32 - 262.2ms/batch - loss: 1.23743 - diff: 19.80mlTrain batch 19/32 - 234.0ms/batch - loss: 1.23936 - diff: 19.83mlTrain batch 20/32 - 234.0ms/batch - loss: 1.23170 - diff: 19.71mlTrain batch 21/32 - 233.7ms/batch - loss: 1.20288 - diff: 19.25mlTrain batch 22/32 - 234.2ms/batch - loss: 1.18835 - diff: 19.01mlTrain batch 23/32 - 233.7ms/batch - loss: 1.18914 - diff: 19.03mlTrain batch 24/32 - 250.1ms/batch - loss: 1.18061 - diff: 18.89mlTrain batch 25/32 - 233.8ms/batch - loss: 1.15926 - diff: 18.55mlTrain batch 26/32 - 234.1ms/batch - loss: 1.19706 - diff: 19.15mlTrain batch 27/32 - 233.9ms/batch - loss: 1.24790 - diff: 19.97mlTrain batch 28/32 - 238.5ms/batch - loss: 1.25840 - diff: 20.13mlTrain batch 29/32 - 233.7ms/batch - loss: 1.27082 - diff: 20.33mlTrain batch 30/32 - 233.9ms/batch - loss: 1.26114 - diff: 20.18mlTrain batch 31/32 - 233.9ms/batch - loss: 1.26042 - diff: 20.17mlTrain batch 32/32 - 76.3ms/batch - loss: 1.26687 - diff: 20.07mlTrain batch 32/32 - 17.1s 76.3ms/batch - loss: 1.26687 - diff: 20.07ml
Test 1.6s: val_loss: 1.34055 - diff: 20.74ml

Epoch 60: current best loss = 1.17378, at epoch 58
Train batch 1/32 - 246.0ms/batch - loss: 1.49509 - diff: 23.92mlTrain batch 2/32 - 233.7ms/batch - loss: 1.46968 - diff: 23.51mlTrain batch 3/32 - 233.8ms/batch - loss: 1.43093 - diff: 22.89mlTrain batch 4/32 - 234.3ms/batch - loss: 1.34514 - diff: 21.52mlTrain batch 5/32 - 233.6ms/batch - loss: 1.22550 - diff: 19.61mlTrain batch 6/32 - 234.6ms/batch - loss: 1.23316 - diff: 19.73mlTrain batch 7/32 - 233.9ms/batch - loss: 1.26479 - diff: 20.24mlTrain batch 8/32 - 234.6ms/batch - loss: 1.25847 - diff: 20.14mlTrain batch 9/32 - 233.8ms/batch - loss: 1.24475 - diff: 19.92mlTrain batch 10/32 - 234.2ms/batch - loss: 1.21731 - diff: 19.48mlTrain batch 11/32 - 234.1ms/batch - loss: 1.18502 - diff: 18.96mlTrain batch 12/32 - 234.0ms/batch - loss: 1.18927 - diff: 19.03mlTrain batch 13/32 - 233.8ms/batch - loss: 1.19949 - diff: 19.19mlTrain batch 14/32 - 233.8ms/batch - loss: 1.20981 - diff: 19.36mlTrain batch 15/32 - 233.8ms/batch - loss: 1.20322 - diff: 19.25mlTrain batch 16/32 - 234.0ms/batch - loss: 1.18685 - diff: 18.99mlTrain batch 17/32 - 233.7ms/batch - loss: 1.20536 - diff: 19.29mlTrain batch 18/32 - 234.6ms/batch - loss: 1.22061 - diff: 19.53mlTrain batch 19/32 - 234.0ms/batch - loss: 1.22702 - diff: 19.63mlTrain batch 20/32 - 234.2ms/batch - loss: 1.21039 - diff: 19.37mlTrain batch 21/32 - 233.7ms/batch - loss: 1.19375 - diff: 19.10mlTrain batch 22/32 - 233.9ms/batch - loss: 1.19381 - diff: 19.10mlTrain batch 23/32 - 233.5ms/batch - loss: 1.18316 - diff: 18.93mlTrain batch 24/32 - 234.4ms/batch - loss: 1.24841 - diff: 19.97mlTrain batch 25/32 - 234.2ms/batch - loss: 1.23561 - diff: 19.77mlTrain batch 26/32 - 234.3ms/batch - loss: 1.21891 - diff: 19.50mlTrain batch 27/32 - 233.6ms/batch - loss: 1.21862 - diff: 19.50mlTrain batch 28/32 - 234.2ms/batch - loss: 1.25486 - diff: 20.08mlTrain batch 29/32 - 233.8ms/batch - loss: 1.26222 - diff: 20.20mlTrain batch 30/32 - 233.9ms/batch - loss: 1.28112 - diff: 20.50mlTrain batch 31/32 - 233.9ms/batch - loss: 1.28835 - diff: 20.61mlTrain batch 32/32 - 77.7ms/batch - loss: 1.30434 - diff: 20.55mlTrain batch 32/32 - 17.3s 77.7ms/batch - loss: 1.30434 - diff: 20.55ml
Test 1.7s: val_loss: 2.01778 - diff: 30.88ml

Epoch 61: current best loss = 1.17378, at epoch 58
Train batch 1/32 - 234.1ms/batch - loss: 1.20105 - diff: 19.22mlTrain batch 2/32 - 234.7ms/batch - loss: 1.02970 - diff: 16.48mlTrain batch 3/32 - 233.7ms/batch - loss: 1.16233 - diff: 18.60mlTrain batch 4/32 - 234.8ms/batch - loss: 1.15169 - diff: 18.43mlTrain batch 5/32 - 234.1ms/batch - loss: 1.08889 - diff: 17.42mlTrain batch 6/32 - 238.1ms/batch - loss: 1.13630 - diff: 18.18mlTrain batch 7/32 - 233.8ms/batch - loss: 1.07217 - diff: 17.15mlTrain batch 8/32 - 238.1ms/batch - loss: 1.10265 - diff: 17.64mlTrain batch 9/32 - 233.9ms/batch - loss: 1.07607 - diff: 17.22mlTrain batch 10/32 - 234.5ms/batch - loss: 1.21518 - diff: 19.44mlTrain batch 11/32 - 233.7ms/batch - loss: 1.21587 - diff: 19.45mlTrain batch 12/32 - 234.8ms/batch - loss: 1.24383 - diff: 19.90mlTrain batch 13/32 - 233.7ms/batch - loss: 1.22832 - diff: 19.65mlTrain batch 14/32 - 233.5ms/batch - loss: 1.21808 - diff: 19.49mlTrain batch 15/32 - 234.1ms/batch - loss: 1.22956 - diff: 19.67mlTrain batch 16/32 - 233.3ms/batch - loss: 1.21015 - diff: 19.36mlTrain batch 17/32 - 233.7ms/batch - loss: 1.22715 - diff: 19.63mlTrain batch 18/32 - 233.9ms/batch - loss: 1.24216 - diff: 19.87mlTrain batch 19/32 - 233.6ms/batch - loss: 1.24942 - diff: 19.99mlTrain batch 20/32 - 233.9ms/batch - loss: 1.23337 - diff: 19.73mlTrain batch 21/32 - 233.9ms/batch - loss: 1.23222 - diff: 19.72mlTrain batch 22/32 - 233.7ms/batch - loss: 1.24315 - diff: 19.89mlTrain batch 23/32 - 233.4ms/batch - loss: 1.29828 - diff: 20.77mlTrain batch 24/32 - 235.4ms/batch - loss: 1.29010 - diff: 20.64mlTrain batch 25/32 - 234.0ms/batch - loss: 1.28262 - diff: 20.52mlTrain batch 26/32 - 244.8ms/batch - loss: 1.27182 - diff: 20.35mlTrain batch 27/32 - 233.8ms/batch - loss: 1.27007 - diff: 20.32mlTrain batch 28/32 - 233.9ms/batch - loss: 1.26314 - diff: 20.21mlTrain batch 29/32 - 233.9ms/batch - loss: 1.25439 - diff: 20.07mlTrain batch 30/32 - 233.7ms/batch - loss: 1.24645 - diff: 19.94mlTrain batch 31/32 - 234.4ms/batch - loss: 1.25708 - diff: 20.11mlTrain batch 32/32 - 86.0ms/batch - loss: 1.29538 - diff: 20.15mlTrain batch 32/32 - 17.8s 86.0ms/batch - loss: 1.29538 - diff: 20.15ml
Test 1.5s: val_loss: 1.98842 - diff: 30.73ml

Epoch 62: current best loss = 1.17378, at epoch 58
Train batch 1/32 - 233.9ms/batch - loss: 0.98852 - diff: 15.82mlTrain batch 2/32 - 233.9ms/batch - loss: 1.31548 - diff: 21.05mlTrain batch 3/32 - 233.7ms/batch - loss: 1.56736 - diff: 25.08mlTrain batch 4/32 - 233.5ms/batch - loss: 1.54829 - diff: 24.77mlTrain batch 5/32 - 233.6ms/batch - loss: 1.46162 - diff: 23.39mlTrain batch 6/32 - 235.0ms/batch - loss: 1.39983 - diff: 22.40mlTrain batch 7/32 - 238.2ms/batch - loss: 1.35828 - diff: 21.73mlTrain batch 8/32 - 234.2ms/batch - loss: 1.38116 - diff: 22.10mlTrain batch 9/32 - 233.6ms/batch - loss: 1.34490 - diff: 21.52mlTrain batch 10/32 - 234.1ms/batch - loss: 1.29435 - diff: 20.71mlTrain batch 11/32 - 234.1ms/batch - loss: 1.25041 - diff: 20.01mlTrain batch 12/32 - 234.0ms/batch - loss: 1.21491 - diff: 19.44mlTrain batch 13/32 - 233.8ms/batch - loss: 1.21218 - diff: 19.39mlTrain batch 14/32 - 234.3ms/batch - loss: 1.20747 - diff: 19.32mlTrain batch 15/32 - 234.1ms/batch - loss: 1.22202 - diff: 19.55mlTrain batch 16/32 - 234.2ms/batch - loss: 1.23736 - diff: 19.80mlTrain batch 17/32 - 234.0ms/batch - loss: 1.26089 - diff: 20.17mlTrain batch 18/32 - 236.9ms/batch - loss: 1.26564 - diff: 20.25mlTrain batch 19/32 - 233.9ms/batch - loss: 1.28259 - diff: 20.52mlTrain batch 20/32 - 234.2ms/batch - loss: 1.28130 - diff: 20.50mlTrain batch 21/32 - 234.1ms/batch - loss: 1.33274 - diff: 21.32mlTrain batch 22/32 - 234.2ms/batch - loss: 1.33319 - diff: 21.33mlTrain batch 23/32 - 233.8ms/batch - loss: 1.33193 - diff: 21.31mlTrain batch 24/32 - 233.9ms/batch - loss: 1.32708 - diff: 21.23mlTrain batch 25/32 - 234.3ms/batch - loss: 1.32285 - diff: 21.17mlTrain batch 26/32 - 234.0ms/batch - loss: 1.31440 - diff: 21.03mlTrain batch 27/32 - 234.5ms/batch - loss: 1.35007 - diff: 21.60mlTrain batch 28/32 - 233.9ms/batch - loss: 1.34343 - diff: 21.49mlTrain batch 29/32 - 234.7ms/batch - loss: 1.32007 - diff: 21.12mlTrain batch 30/32 - 233.7ms/batch - loss: 1.30791 - diff: 20.93mlTrain batch 31/32 - 235.9ms/batch - loss: 1.29785 - diff: 20.77mlTrain batch 32/32 - 84.3ms/batch - loss: 1.33736 - diff: 20.80mlTrain batch 32/32 - 17.2s 84.3ms/batch - loss: 1.33736 - diff: 20.80ml
Test 1.6s: val_loss: 1.44353 - diff: 21.85ml

Epoch 63: current best loss = 1.17378, at epoch 58
Train batch 1/32 - 234.0ms/batch - loss: 0.88984 - diff: 14.24mlTrain batch 2/32 - 234.3ms/batch - loss: 1.21561 - diff: 19.45mlTrain batch 3/32 - 233.6ms/batch - loss: 1.11092 - diff: 17.77mlTrain batch 4/32 - 234.4ms/batch - loss: 1.41684 - diff: 22.67mlTrain batch 5/32 - 233.8ms/batch - loss: 1.62798 - diff: 26.05mlTrain batch 6/32 - 235.0ms/batch - loss: 1.59903 - diff: 25.58mlTrain batch 7/32 - 234.1ms/batch - loss: 1.48933 - diff: 23.83mlTrain batch 8/32 - 238.1ms/batch - loss: 1.45467 - diff: 23.27mlTrain batch 9/32 - 234.0ms/batch - loss: 1.37503 - diff: 22.00mlTrain batch 10/32 - 234.4ms/batch - loss: 1.33721 - diff: 21.40mlTrain batch 11/32 - 234.0ms/batch - loss: 1.30123 - diff: 20.82mlTrain batch 12/32 - 234.4ms/batch - loss: 1.27673 - diff: 20.43mlTrain batch 13/32 - 234.1ms/batch - loss: 1.27690 - diff: 20.43mlTrain batch 14/32 - 234.1ms/batch - loss: 1.34377 - diff: 21.50mlTrain batch 15/32 - 233.7ms/batch - loss: 1.31064 - diff: 20.97mlTrain batch 16/32 - 234.6ms/batch - loss: 1.31166 - diff: 20.99mlTrain batch 17/32 - 234.0ms/batch - loss: 1.32985 - diff: 21.28mlTrain batch 18/32 - 233.1ms/batch - loss: 1.31942 - diff: 21.11mlTrain batch 19/32 - 233.8ms/batch - loss: 1.34320 - diff: 21.49mlTrain batch 20/32 - 237.9ms/batch - loss: 1.34827 - diff: 21.57mlTrain batch 21/32 - 234.2ms/batch - loss: 1.33139 - diff: 21.30mlTrain batch 22/32 - 242.7ms/batch - loss: 1.33770 - diff: 21.40mlTrain batch 23/32 - 233.6ms/batch - loss: 1.32334 - diff: 21.17mlTrain batch 24/32 - 234.6ms/batch - loss: 1.32014 - diff: 21.12mlTrain batch 25/32 - 233.9ms/batch - loss: 1.30464 - diff: 20.87mlTrain batch 26/32 - 234.6ms/batch - loss: 1.29295 - diff: 20.69mlTrain batch 27/32 - 233.8ms/batch - loss: 1.30116 - diff: 20.82mlTrain batch 28/32 - 233.9ms/batch - loss: 1.30134 - diff: 20.82mlTrain batch 29/32 - 234.2ms/batch - loss: 1.29576 - diff: 20.73mlTrain batch 30/32 - 234.4ms/batch - loss: 1.30387 - diff: 20.86mlTrain batch 31/32 - 235.7ms/batch - loss: 1.30686 - diff: 20.91mlTrain batch 32/32 - 76.8ms/batch - loss: 1.32914 - diff: 20.87mlTrain batch 32/32 - 16.4s 76.8ms/batch - loss: 1.32914 - diff: 20.87ml
Test 1.6s: val_loss: 1.21570 - diff: 18.85ml

Epoch 64: current best loss = 1.17378, at epoch 58
Train batch 1/32 - 234.0ms/batch - loss: 1.13385 - diff: 18.14mlTrain batch 2/32 - 233.9ms/batch - loss: 1.21957 - diff: 19.51mlTrain batch 3/32 - 233.7ms/batch - loss: 1.36315 - diff: 21.81mlTrain batch 4/32 - 234.3ms/batch - loss: 1.41218 - diff: 22.59mlTrain batch 5/32 - 234.0ms/batch - loss: 1.37622 - diff: 22.02mlTrain batch 6/32 - 234.2ms/batch - loss: 1.30725 - diff: 20.92mlTrain batch 7/32 - 240.2ms/batch - loss: 1.23619 - diff: 19.78mlTrain batch 8/32 - 234.8ms/batch - loss: 1.23608 - diff: 19.78mlTrain batch 9/32 - 233.7ms/batch - loss: 1.18964 - diff: 19.03mlTrain batch 10/32 - 233.5ms/batch - loss: 1.20142 - diff: 19.22mlTrain batch 11/32 - 233.9ms/batch - loss: 1.27100 - diff: 20.34mlTrain batch 12/32 - 233.9ms/batch - loss: 1.26326 - diff: 20.21mlTrain batch 13/32 - 233.7ms/batch - loss: 1.29197 - diff: 20.67mlTrain batch 14/32 - 234.2ms/batch - loss: 1.25583 - diff: 20.09mlTrain batch 15/32 - 237.0ms/batch - loss: 1.31652 - diff: 21.06mlTrain batch 16/32 - 234.2ms/batch - loss: 1.27784 - diff: 20.45mlTrain batch 17/32 - 233.6ms/batch - loss: 1.26700 - diff: 20.27mlTrain batch 18/32 - 233.2ms/batch - loss: 1.25061 - diff: 20.01mlTrain batch 19/32 - 233.8ms/batch - loss: 1.27662 - diff: 20.43mlTrain batch 20/32 - 233.9ms/batch - loss: 1.26865 - diff: 20.30mlTrain batch 21/32 - 234.0ms/batch - loss: 1.25689 - diff: 20.11mlTrain batch 22/32 - 234.3ms/batch - loss: 1.25501 - diff: 20.08mlTrain batch 23/32 - 234.1ms/batch - loss: 1.25395 - diff: 20.06mlTrain batch 24/32 - 234.3ms/batch - loss: 1.25351 - diff: 20.06mlTrain batch 25/32 - 233.7ms/batch - loss: 1.28982 - diff: 20.64mlTrain batch 26/32 - 233.3ms/batch - loss: 1.29010 - diff: 20.64mlTrain batch 27/32 - 233.7ms/batch - loss: 1.28410 - diff: 20.55mlTrain batch 28/32 - 233.7ms/batch - loss: 1.27167 - diff: 20.35mlTrain batch 29/32 - 234.0ms/batch - loss: 1.26438 - diff: 20.23mlTrain batch 30/32 - 234.2ms/batch - loss: 1.26516 - diff: 20.24mlTrain batch 31/32 - 233.7ms/batch - loss: 1.25959 - diff: 20.15mlTrain batch 32/32 - 76.5ms/batch - loss: 1.27154 - diff: 20.08mlTrain batch 32/32 - 18.3s 76.5ms/batch - loss: 1.27154 - diff: 20.08ml
Test 1.7s: val_loss: 1.73269 - diff: 27.07ml

Epoch 65: current best loss = 1.17378, at epoch 58
Train batch 1/32 - 233.8ms/batch - loss: 1.58803 - diff: 25.41mlTrain batch 2/32 - 238.1ms/batch - loss: 1.42850 - diff: 22.86mlTrain batch 3/32 - 233.5ms/batch - loss: 1.20681 - diff: 19.31mlTrain batch 4/32 - 234.3ms/batch - loss: 1.24604 - diff: 19.94mlTrain batch 5/32 - 233.8ms/batch - loss: 1.29349 - diff: 20.70mlTrain batch 6/32 - 233.9ms/batch - loss: 1.34400 - diff: 21.50mlTrain batch 7/32 - 233.6ms/batch - loss: 1.34370 - diff: 21.50mlTrain batch 8/32 - 234.0ms/batch - loss: 1.34707 - diff: 21.55mlTrain batch 9/32 - 233.6ms/batch - loss: 1.31135 - diff: 20.98mlTrain batch 10/32 - 234.3ms/batch - loss: 1.28899 - diff: 20.62mlTrain batch 11/32 - 233.9ms/batch - loss: 1.27768 - diff: 20.44mlTrain batch 12/32 - 234.1ms/batch - loss: 1.28317 - diff: 20.53mlTrain batch 13/32 - 233.7ms/batch - loss: 1.33675 - diff: 21.39mlTrain batch 14/32 - 234.3ms/batch - loss: 1.31906 - diff: 21.10mlTrain batch 15/32 - 234.0ms/batch - loss: 1.30553 - diff: 20.89mlTrain batch 16/32 - 238.0ms/batch - loss: 1.29032 - diff: 20.65mlTrain batch 17/32 - 233.8ms/batch - loss: 1.29740 - diff: 20.76mlTrain batch 18/32 - 233.7ms/batch - loss: 1.28362 - diff: 20.54mlTrain batch 19/32 - 233.5ms/batch - loss: 1.27578 - diff: 20.41mlTrain batch 20/32 - 233.7ms/batch - loss: 1.25553 - diff: 20.09mlTrain batch 21/32 - 233.8ms/batch - loss: 1.27409 - diff: 20.39mlTrain batch 22/32 - 233.9ms/batch - loss: 1.26389 - diff: 20.22mlTrain batch 23/32 - 233.8ms/batch - loss: 1.25302 - diff: 20.05mlTrain batch 24/32 - 234.7ms/batch - loss: 1.23769 - diff: 19.80mlTrain batch 25/32 - 233.8ms/batch - loss: 1.22006 - diff: 19.52mlTrain batch 26/32 - 246.8ms/batch - loss: 1.22889 - diff: 19.66mlTrain batch 27/32 - 233.9ms/batch - loss: 1.28225 - diff: 20.52mlTrain batch 28/32 - 234.2ms/batch - loss: 1.30093 - diff: 20.81mlTrain batch 29/32 - 238.9ms/batch - loss: 1.31402 - diff: 21.02mlTrain batch 30/32 - 234.2ms/batch - loss: 1.29444 - diff: 20.71mlTrain batch 31/32 - 234.0ms/batch - loss: 1.28661 - diff: 20.59mlTrain batch 32/32 - 76.6ms/batch - loss: 1.34243 - diff: 20.69mlTrain batch 32/32 - 17.8s 76.6ms/batch - loss: 1.34243 - diff: 20.69ml
Test 1.6s: val_loss: 1.15178 - diff: 17.68ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Systole_WideResNet50_0_Adam-0.001_MAE_DA3_best

Epoch 66: current best loss = 1.15178, at epoch 65
Train batch 1/32 - 242.9ms/batch - loss: 0.87470 - diff: 14.00mlTrain batch 2/32 - 233.9ms/batch - loss: 1.08983 - diff: 17.44mlTrain batch 3/32 - 233.5ms/batch - loss: 1.05095 - diff: 16.82mlTrain batch 4/32 - 238.0ms/batch - loss: 1.09660 - diff: 17.55mlTrain batch 5/32 - 233.7ms/batch - loss: 1.19773 - diff: 19.16mlTrain batch 6/32 - 237.6ms/batch - loss: 1.17452 - diff: 18.79mlTrain batch 7/32 - 233.3ms/batch - loss: 1.13499 - diff: 18.16mlTrain batch 8/32 - 234.2ms/batch - loss: 1.15407 - diff: 18.47mlTrain batch 9/32 - 233.7ms/batch - loss: 1.16181 - diff: 18.59mlTrain batch 10/32 - 233.9ms/batch - loss: 1.15644 - diff: 18.50mlTrain batch 11/32 - 233.7ms/batch - loss: 1.14449 - diff: 18.31mlTrain batch 12/32 - 237.1ms/batch - loss: 1.18269 - diff: 18.92mlTrain batch 13/32 - 233.7ms/batch - loss: 1.19501 - diff: 19.12mlTrain batch 14/32 - 237.9ms/batch - loss: 1.17127 - diff: 18.74mlTrain batch 15/32 - 233.8ms/batch - loss: 1.15081 - diff: 18.41mlTrain batch 16/32 - 233.9ms/batch - loss: 1.15267 - diff: 18.44mlTrain batch 17/32 - 234.1ms/batch - loss: 1.15758 - diff: 18.52mlTrain batch 18/32 - 233.7ms/batch - loss: 1.18126 - diff: 18.90mlTrain batch 19/32 - 233.8ms/batch - loss: 1.19407 - diff: 19.11mlTrain batch 20/32 - 237.5ms/batch - loss: 1.19952 - diff: 19.19mlTrain batch 21/32 - 233.4ms/batch - loss: 1.18454 - diff: 18.95mlTrain batch 22/32 - 250.6ms/batch - loss: 1.17663 - diff: 18.83mlTrain batch 23/32 - 233.9ms/batch - loss: 1.22373 - diff: 19.58mlTrain batch 24/32 - 234.3ms/batch - loss: 1.26237 - diff: 20.20mlTrain batch 25/32 - 233.9ms/batch - loss: 1.24041 - diff: 19.85mlTrain batch 26/32 - 234.1ms/batch - loss: 1.24270 - diff: 19.88mlTrain batch 27/32 - 233.9ms/batch - loss: 1.25735 - diff: 20.12mlTrain batch 28/32 - 236.7ms/batch - loss: 1.26212 - diff: 20.19mlTrain batch 29/32 - 234.0ms/batch - loss: 1.28061 - diff: 20.49mlTrain batch 30/32 - 234.0ms/batch - loss: 1.27013 - diff: 20.32mlTrain batch 31/32 - 234.2ms/batch - loss: 1.25704 - diff: 20.11mlTrain batch 32/32 - 76.4ms/batch - loss: 1.28721 - diff: 20.11mlTrain batch 32/32 - 17.1s 76.4ms/batch - loss: 1.28721 - diff: 20.11ml
Test 1.5s: val_loss: 1.34577 - diff: 20.40ml

Epoch 67: current best loss = 1.15178, at epoch 65
Train batch 1/32 - 246.9ms/batch - loss: 0.86101 - diff: 13.78mlTrain batch 2/32 - 234.0ms/batch - loss: 1.20956 - diff: 19.35mlTrain batch 3/32 - 236.1ms/batch - loss: 1.09728 - diff: 17.56mlTrain batch 4/32 - 234.2ms/batch - loss: 1.06447 - diff: 17.03mlTrain batch 5/32 - 234.8ms/batch - loss: 1.23944 - diff: 19.83mlTrain batch 6/32 - 233.7ms/batch - loss: 1.25129 - diff: 20.02mlTrain batch 7/32 - 233.5ms/batch - loss: 1.20529 - diff: 19.28mlTrain batch 8/32 - 234.9ms/batch - loss: 1.24343 - diff: 19.89mlTrain batch 9/32 - 233.9ms/batch - loss: 1.23784 - diff: 19.81mlTrain batch 10/32 - 238.3ms/batch - loss: 1.21946 - diff: 19.51mlTrain batch 11/32 - 233.6ms/batch - loss: 1.19356 - diff: 19.10mlTrain batch 12/32 - 233.8ms/batch - loss: 1.16703 - diff: 18.67mlTrain batch 13/32 - 236.7ms/batch - loss: 1.15574 - diff: 18.49mlTrain batch 14/32 - 234.2ms/batch - loss: 1.14596 - diff: 18.34mlTrain batch 15/32 - 233.9ms/batch - loss: 1.20135 - diff: 19.22mlTrain batch 16/32 - 238.0ms/batch - loss: 1.20519 - diff: 19.28mlTrain batch 17/32 - 233.8ms/batch - loss: 1.18842 - diff: 19.01mlTrain batch 18/32 - 238.5ms/batch - loss: 1.16494 - diff: 18.64mlTrain batch 19/32 - 233.8ms/batch - loss: 1.15331 - diff: 18.45mlTrain batch 20/32 - 234.2ms/batch - loss: 1.14375 - diff: 18.30mlTrain batch 21/32 - 233.6ms/batch - loss: 1.13652 - diff: 18.18mlTrain batch 22/32 - 234.0ms/batch - loss: 1.12542 - diff: 18.01mlTrain batch 23/32 - 233.8ms/batch - loss: 1.13107 - diff: 18.10mlTrain batch 24/32 - 233.8ms/batch - loss: 1.12306 - diff: 17.97mlTrain batch 25/32 - 233.8ms/batch - loss: 1.11279 - diff: 17.80mlTrain batch 26/32 - 233.6ms/batch - loss: 1.12059 - diff: 17.93mlTrain batch 27/32 - 233.8ms/batch - loss: 1.13743 - diff: 18.20mlTrain batch 28/32 - 238.1ms/batch - loss: 1.16213 - diff: 18.59mlTrain batch 29/32 - 233.6ms/batch - loss: 1.15943 - diff: 18.55mlTrain batch 30/32 - 234.5ms/batch - loss: 1.17149 - diff: 18.74mlTrain batch 31/32 - 233.8ms/batch - loss: 1.21800 - diff: 19.49mlTrain batch 32/32 - 76.7ms/batch - loss: 1.22755 - diff: 19.41mlTrain batch 32/32 - 17.6s 76.7ms/batch - loss: 1.22755 - diff: 19.41ml
Test 1.6s: val_loss: 1.46102 - diff: 22.73ml

Epoch 68: current best loss = 1.15178, at epoch 65
Train batch 1/32 - 233.6ms/batch - loss: 0.73998 - diff: 11.84mlTrain batch 2/32 - 240.5ms/batch - loss: 0.70498 - diff: 11.28mlTrain batch 3/32 - 233.7ms/batch - loss: 0.95041 - diff: 15.21mlTrain batch 4/32 - 238.0ms/batch - loss: 1.06647 - diff: 17.06mlTrain batch 5/32 - 233.7ms/batch - loss: 1.03270 - diff: 16.52mlTrain batch 6/32 - 234.4ms/batch - loss: 1.01859 - diff: 16.30mlTrain batch 7/32 - 233.9ms/batch - loss: 1.09819 - diff: 17.57mlTrain batch 8/32 - 233.1ms/batch - loss: 1.11733 - diff: 17.88mlTrain batch 9/32 - 233.7ms/batch - loss: 1.13369 - diff: 18.14mlTrain batch 10/32 - 234.5ms/batch - loss: 1.15523 - diff: 18.48mlTrain batch 11/32 - 233.8ms/batch - loss: 1.12904 - diff: 18.06mlTrain batch 12/32 - 234.5ms/batch - loss: 1.11195 - diff: 17.79mlTrain batch 13/32 - 233.8ms/batch - loss: 1.09468 - diff: 17.51mlTrain batch 14/32 - 234.0ms/batch - loss: 1.12848 - diff: 18.06mlTrain batch 15/32 - 235.3ms/batch - loss: 1.11980 - diff: 17.92mlTrain batch 16/32 - 242.9ms/batch - loss: 1.14200 - diff: 18.27mlTrain batch 17/32 - 233.7ms/batch - loss: 1.17165 - diff: 18.75mlTrain batch 18/32 - 245.1ms/batch - loss: 1.16350 - diff: 18.62mlTrain batch 19/32 - 233.7ms/batch - loss: 1.14806 - diff: 18.37mlTrain batch 20/32 - 242.8ms/batch - loss: 1.12837 - diff: 18.05mlTrain batch 21/32 - 233.6ms/batch - loss: 1.14334 - diff: 18.29mlTrain batch 22/32 - 242.2ms/batch - loss: 1.14494 - diff: 18.32mlTrain batch 23/32 - 233.9ms/batch - loss: 1.14050 - diff: 18.25mlTrain batch 24/32 - 243.1ms/batch - loss: 1.13506 - diff: 18.16mlTrain batch 25/32 - 233.8ms/batch - loss: 1.13947 - diff: 18.23mlTrain batch 26/32 - 233.6ms/batch - loss: 1.15314 - diff: 18.45mlTrain batch 27/32 - 233.8ms/batch - loss: 1.14778 - diff: 18.36mlTrain batch 28/32 - 234.5ms/batch - loss: 1.14887 - diff: 18.38mlTrain batch 29/32 - 233.8ms/batch - loss: 1.17028 - diff: 18.72mlTrain batch 30/32 - 233.5ms/batch - loss: 1.21198 - diff: 19.39mlTrain batch 31/32 - 233.6ms/batch - loss: 1.21145 - diff: 19.38mlTrain batch 32/32 - 84.0ms/batch - loss: 1.23684 - diff: 19.37mlTrain batch 32/32 - 17.5s 84.0ms/batch - loss: 1.23684 - diff: 19.37ml
Test 1.6s: val_loss: 2.02520 - diff: 30.88ml

Epoch 69: current best loss = 1.15178, at epoch 65
Train batch 1/32 - 233.7ms/batch - loss: 1.09084 - diff: 17.45mlTrain batch 2/32 - 235.6ms/batch - loss: 1.03109 - diff: 16.50mlTrain batch 3/32 - 233.3ms/batch - loss: 1.14004 - diff: 18.24mlTrain batch 4/32 - 234.5ms/batch - loss: 1.05613 - diff: 16.90mlTrain batch 5/32 - 233.9ms/batch - loss: 1.12233 - diff: 17.96mlTrain batch 6/32 - 239.2ms/batch - loss: 1.36931 - diff: 21.91mlTrain batch 7/32 - 233.4ms/batch - loss: 1.30869 - diff: 20.94mlTrain batch 8/32 - 244.3ms/batch - loss: 1.25848 - diff: 20.14mlTrain batch 9/32 - 233.5ms/batch - loss: 1.32136 - diff: 21.14mlTrain batch 10/32 - 234.4ms/batch - loss: 1.40556 - diff: 22.49mlTrain batch 11/32 - 235.4ms/batch - loss: 1.35384 - diff: 21.66mlTrain batch 12/32 - 234.1ms/batch - loss: 1.36470 - diff: 21.84mlTrain batch 13/32 - 233.8ms/batch - loss: 1.33699 - diff: 21.39mlTrain batch 14/32 - 233.8ms/batch - loss: 1.31526 - diff: 21.04mlTrain batch 15/32 - 233.7ms/batch - loss: 1.29490 - diff: 20.72mlTrain batch 16/32 - 237.9ms/batch - loss: 1.27345 - diff: 20.38mlTrain batch 17/32 - 233.5ms/batch - loss: 1.24802 - diff: 19.97mlTrain batch 18/32 - 238.1ms/batch - loss: 1.21915 - diff: 19.51mlTrain batch 19/32 - 233.6ms/batch - loss: 1.19833 - diff: 19.17mlTrain batch 20/32 - 236.9ms/batch - loss: 1.22020 - diff: 19.52mlTrain batch 21/32 - 234.0ms/batch - loss: 1.21001 - diff: 19.36mlTrain batch 22/32 - 238.6ms/batch - loss: 1.19484 - diff: 19.12mlTrain batch 23/32 - 233.7ms/batch - loss: 1.19977 - diff: 19.20mlTrain batch 24/32 - 234.5ms/batch - loss: 1.20772 - diff: 19.32mlTrain batch 25/32 - 233.7ms/batch - loss: 1.19987 - diff: 19.20mlTrain batch 26/32 - 234.4ms/batch - loss: 1.19935 - diff: 19.19mlTrain batch 27/32 - 233.8ms/batch - loss: 1.19379 - diff: 19.10mlTrain batch 28/32 - 234.5ms/batch - loss: 1.19278 - diff: 19.08mlTrain batch 29/32 - 233.7ms/batch - loss: 1.17741 - diff: 18.84mlTrain batch 30/32 - 234.3ms/batch - loss: 1.20006 - diff: 19.20mlTrain batch 31/32 - 233.6ms/batch - loss: 1.19984 - diff: 19.20mlTrain batch 32/32 - 76.5ms/batch - loss: 1.23268 - diff: 19.21mlTrain batch 32/32 - 18.1s 76.5ms/batch - loss: 1.23268 - diff: 19.21ml
Test 1.4s: val_loss: 1.18168 - diff: 18.59ml

Epoch 70: current best loss = 1.15178, at epoch 65
Train batch 1/32 - 233.5ms/batch - loss: 1.24033 - diff: 19.85mlTrain batch 2/32 - 234.0ms/batch - loss: 1.09034 - diff: 17.45mlTrain batch 3/32 - 233.8ms/batch - loss: 1.14710 - diff: 18.35mlTrain batch 4/32 - 239.6ms/batch - loss: 1.07812 - diff: 17.25mlTrain batch 5/32 - 233.8ms/batch - loss: 1.15470 - diff: 18.48mlTrain batch 6/32 - 234.1ms/batch - loss: 1.19344 - diff: 19.10mlTrain batch 7/32 - 233.8ms/batch - loss: 1.26341 - diff: 20.21mlTrain batch 8/32 - 234.3ms/batch - loss: 1.33606 - diff: 21.38mlTrain batch 9/32 - 233.6ms/batch - loss: 1.33139 - diff: 21.30mlTrain batch 10/32 - 234.2ms/batch - loss: 1.29014 - diff: 20.64mlTrain batch 11/32 - 239.3ms/batch - loss: 1.27369 - diff: 20.38mlTrain batch 12/32 - 256.1ms/batch - loss: 1.28895 - diff: 20.62mlTrain batch 13/32 - 233.5ms/batch - loss: 1.31669 - diff: 21.07mlTrain batch 14/32 - 234.0ms/batch - loss: 1.28984 - diff: 20.64mlTrain batch 15/32 - 233.5ms/batch - loss: 1.27734 - diff: 20.44mlTrain batch 16/32 - 233.9ms/batch - loss: 1.27015 - diff: 20.32mlTrain batch 17/32 - 233.6ms/batch - loss: 1.25951 - diff: 20.15mlTrain batch 18/32 - 233.8ms/batch - loss: 1.28168 - diff: 20.51mlTrain batch 19/32 - 234.9ms/batch - loss: 1.27862 - diff: 20.46mlTrain batch 20/32 - 234.0ms/batch - loss: 1.25990 - diff: 20.16mlTrain batch 21/32 - 233.7ms/batch - loss: 1.24358 - diff: 19.90mlTrain batch 22/32 - 234.2ms/batch - loss: 1.25862 - diff: 20.14mlTrain batch 23/32 - 233.7ms/batch - loss: 1.25202 - diff: 20.03mlTrain batch 24/32 - 234.5ms/batch - loss: 1.24118 - diff: 19.86mlTrain batch 25/32 - 233.8ms/batch - loss: 1.27364 - diff: 20.38mlTrain batch 26/32 - 234.1ms/batch - loss: 1.25843 - diff: 20.13mlTrain batch 27/32 - 233.6ms/batch - loss: 1.27154 - diff: 20.34mlTrain batch 28/32 - 237.8ms/batch - loss: 1.25367 - diff: 20.06mlTrain batch 29/32 - 233.9ms/batch - loss: 1.24012 - diff: 19.84mlTrain batch 30/32 - 233.9ms/batch - loss: 1.22393 - diff: 19.58mlTrain batch 31/32 - 234.1ms/batch - loss: 1.22218 - diff: 19.55mlTrain batch 32/32 - 76.6ms/batch - loss: 1.26147 - diff: 19.59mlTrain batch 32/32 - 17.0s 76.6ms/batch - loss: 1.26147 - diff: 19.59ml
Test 1.6s: val_loss: 1.64506 - diff: 25.40ml

Epoch 71: current best loss = 1.15178, at epoch 65
Train batch 1/32 - 233.6ms/batch - loss: 1.09895 - diff: 17.58mlTrain batch 2/32 - 233.9ms/batch - loss: 1.08302 - diff: 17.33mlTrain batch 3/32 - 234.0ms/batch - loss: 1.09472 - diff: 17.52mlTrain batch 4/32 - 237.5ms/batch - loss: 1.08896 - diff: 17.42mlTrain batch 5/32 - 233.7ms/batch - loss: 1.07350 - diff: 17.18mlTrain batch 6/32 - 239.3ms/batch - loss: 1.09394 - diff: 17.50mlTrain batch 7/32 - 233.4ms/batch - loss: 1.04347 - diff: 16.70mlTrain batch 8/32 - 238.3ms/batch - loss: 1.19570 - diff: 19.13mlTrain batch 9/32 - 233.9ms/batch - loss: 1.24041 - diff: 19.85mlTrain batch 10/32 - 234.6ms/batch - loss: 1.22845 - diff: 19.66mlTrain batch 11/32 - 233.8ms/batch - loss: 1.22547 - diff: 19.61mlTrain batch 12/32 - 233.9ms/batch - loss: 1.25251 - diff: 20.04mlTrain batch 13/32 - 235.8ms/batch - loss: 1.28666 - diff: 20.59mlTrain batch 14/32 - 233.9ms/batch - loss: 1.29624 - diff: 20.74mlTrain batch 15/32 - 234.5ms/batch - loss: 1.28156 - diff: 20.50mlTrain batch 16/32 - 233.7ms/batch - loss: 1.27413 - diff: 20.39mlTrain batch 17/32 - 240.7ms/batch - loss: 1.27521 - diff: 20.40mlTrain batch 18/32 - 233.7ms/batch - loss: 1.27567 - diff: 20.41mlTrain batch 19/32 - 234.5ms/batch - loss: 1.27125 - diff: 20.34mlTrain batch 20/32 - 234.2ms/batch - loss: 1.25388 - diff: 20.06mlTrain batch 21/32 - 234.5ms/batch - loss: 1.24101 - diff: 19.86mlTrain batch 22/32 - 233.8ms/batch - loss: 1.26656 - diff: 20.26mlTrain batch 23/32 - 242.1ms/batch - loss: 1.26026 - diff: 20.16mlTrain batch 24/32 - 233.7ms/batch - loss: 1.27101 - diff: 20.34mlTrain batch 25/32 - 246.2ms/batch - loss: 1.26770 - diff: 20.28mlTrain batch 26/32 - 234.0ms/batch - loss: 1.29991 - diff: 20.80mlTrain batch 27/32 - 234.2ms/batch - loss: 1.28135 - diff: 20.50mlTrain batch 28/32 - 235.1ms/batch - loss: 1.27299 - diff: 20.37mlTrain batch 29/32 - 233.8ms/batch - loss: 1.26122 - diff: 20.18mlTrain batch 30/32 - 237.5ms/batch - loss: 1.25621 - diff: 20.10mlTrain batch 31/32 - 233.9ms/batch - loss: 1.24918 - diff: 19.99mlTrain batch 32/32 - 76.8ms/batch - loss: 1.32200 - diff: 20.16mlTrain batch 32/32 - 16.4s 76.8ms/batch - loss: 1.32200 - diff: 20.16ml
Test 1.6s: val_loss: 1.73909 - diff: 26.44ml

Epoch 72: current best loss = 1.15178, at epoch 65
Train batch 1/32 - 233.8ms/batch - loss: 0.68513 - diff: 10.96mlTrain batch 2/32 - 234.1ms/batch - loss: 0.86788 - diff: 13.89mlTrain batch 3/32 - 236.3ms/batch - loss: 1.04094 - diff: 16.66mlTrain batch 4/32 - 233.5ms/batch - loss: 1.05259 - diff: 16.84mlTrain batch 5/32 - 233.8ms/batch - loss: 1.01808 - diff: 16.29mlTrain batch 6/32 - 234.2ms/batch - loss: 0.99088 - diff: 15.85mlTrain batch 7/32 - 249.3ms/batch - loss: 0.95579 - diff: 15.29mlTrain batch 8/32 - 233.8ms/batch - loss: 0.99322 - diff: 15.89mlTrain batch 9/32 - 233.6ms/batch - loss: 1.00072 - diff: 16.01mlTrain batch 10/32 - 234.0ms/batch - loss: 1.07956 - diff: 17.27mlTrain batch 11/32 - 233.7ms/batch - loss: 1.07717 - diff: 17.23mlTrain batch 12/32 - 234.2ms/batch - loss: 1.10462 - diff: 17.67mlTrain batch 13/32 - 234.0ms/batch - loss: 1.09573 - diff: 17.53mlTrain batch 14/32 - 238.3ms/batch - loss: 1.11768 - diff: 17.88mlTrain batch 15/32 - 233.9ms/batch - loss: 1.18784 - diff: 19.01mlTrain batch 16/32 - 233.8ms/batch - loss: 1.17567 - diff: 18.81mlTrain batch 17/32 - 234.1ms/batch - loss: 1.18544 - diff: 18.97mlTrain batch 18/32 - 234.7ms/batch - loss: 1.16715 - diff: 18.67mlTrain batch 19/32 - 233.8ms/batch - loss: 1.16386 - diff: 18.62mlTrain batch 20/32 - 234.0ms/batch - loss: 1.13545 - diff: 18.17mlTrain batch 21/32 - 234.1ms/batch - loss: 1.15014 - diff: 18.40mlTrain batch 22/32 - 234.2ms/batch - loss: 1.14378 - diff: 18.30mlTrain batch 23/32 - 233.7ms/batch - loss: 1.17312 - diff: 18.77mlTrain batch 24/32 - 234.0ms/batch - loss: 1.16398 - diff: 18.62mlTrain batch 25/32 - 234.1ms/batch - loss: 1.15981 - diff: 18.56mlTrain batch 26/32 - 234.0ms/batch - loss: 1.16249 - diff: 18.60mlTrain batch 27/32 - 242.7ms/batch - loss: 1.14601 - diff: 18.34mlTrain batch 28/32 - 233.8ms/batch - loss: 1.16897 - diff: 18.70mlTrain batch 29/32 - 234.0ms/batch - loss: 1.16829 - diff: 18.69mlTrain batch 30/32 - 234.1ms/batch - loss: 1.16686 - diff: 18.67mlTrain batch 31/32 - 234.0ms/batch - loss: 1.16749 - diff: 18.68mlTrain batch 32/32 - 82.4ms/batch - loss: 1.18309 - diff: 18.63mlTrain batch 32/32 - 16.8s 82.4ms/batch - loss: 1.18309 - diff: 18.63ml
Test 1.5s: val_loss: 1.69779 - diff: 25.80ml

Epoch 73: current best loss = 1.15178, at epoch 65
Train batch 1/32 - 233.5ms/batch - loss: 0.85288 - diff: 13.65mlTrain batch 2/32 - 234.1ms/batch - loss: 1.13898 - diff: 18.22mlTrain batch 3/32 - 233.7ms/batch - loss: 1.05741 - diff: 16.92mlTrain batch 4/32 - 233.9ms/batch - loss: 1.08516 - diff: 17.36mlTrain batch 5/32 - 233.8ms/batch - loss: 1.03820 - diff: 16.61mlTrain batch 6/32 - 234.5ms/batch - loss: 1.01724 - diff: 16.28mlTrain batch 7/32 - 233.5ms/batch - loss: 1.05280 - diff: 16.84mlTrain batch 8/32 - 242.8ms/batch - loss: 1.11949 - diff: 17.91mlTrain batch 9/32 - 234.0ms/batch - loss: 1.06167 - diff: 16.99mlTrain batch 10/32 - 238.3ms/batch - loss: 1.07394 - diff: 17.18mlTrain batch 11/32 - 233.8ms/batch - loss: 1.04982 - diff: 16.80mlTrain batch 12/32 - 234.1ms/batch - loss: 1.07460 - diff: 17.19mlTrain batch 13/32 - 233.8ms/batch - loss: 1.02896 - diff: 16.46mlTrain batch 14/32 - 234.8ms/batch - loss: 1.02926 - diff: 16.47mlTrain batch 15/32 - 233.1ms/batch - loss: 1.05187 - diff: 16.83mlTrain batch 16/32 - 233.5ms/batch - loss: 1.03436 - diff: 16.55mlTrain batch 17/32 - 233.7ms/batch - loss: 1.05059 - diff: 16.81mlTrain batch 18/32 - 233.6ms/batch - loss: 1.06931 - diff: 17.11mlTrain batch 19/32 - 233.5ms/batch - loss: 1.06463 - diff: 17.03mlTrain batch 20/32 - 237.5ms/batch - loss: 1.07657 - diff: 17.23mlTrain batch 21/32 - 250.6ms/batch - loss: 1.16142 - diff: 18.58mlTrain batch 22/32 - 244.8ms/batch - loss: 1.16043 - diff: 18.57mlTrain batch 23/32 - 234.0ms/batch - loss: 1.15687 - diff: 18.51mlTrain batch 24/32 - 234.6ms/batch - loss: 1.16069 - diff: 18.57mlTrain batch 25/32 - 233.9ms/batch - loss: 1.16090 - diff: 18.57mlTrain batch 26/32 - 240.5ms/batch - loss: 1.16132 - diff: 18.58mlTrain batch 27/32 - 233.7ms/batch - loss: 1.16097 - diff: 18.58mlTrain batch 28/32 - 233.7ms/batch - loss: 1.17067 - diff: 18.73mlTrain batch 29/32 - 233.7ms/batch - loss: 1.16672 - diff: 18.67mlTrain batch 30/32 - 234.2ms/batch - loss: 1.16618 - diff: 18.66mlTrain batch 31/32 - 233.4ms/batch - loss: 1.15791 - diff: 18.53mlTrain batch 32/32 - 77.5ms/batch - loss: 1.18993 - diff: 18.54mlTrain batch 32/32 - 17.7s 77.5ms/batch - loss: 1.18993 - diff: 18.54ml
Test 1.4s: val_loss: 1.41871 - diff: 21.49ml

Epoch 74: current best loss = 1.15178, at epoch 65
Train batch 1/32 - 233.8ms/batch - loss: 1.54616 - diff: 24.74mlTrain batch 2/32 - 240.6ms/batch - loss: 1.40898 - diff: 22.54mlTrain batch 3/32 - 233.7ms/batch - loss: 1.33130 - diff: 21.30mlTrain batch 4/32 - 234.1ms/batch - loss: 1.25039 - diff: 20.01mlTrain batch 5/32 - 233.7ms/batch - loss: 1.25793 - diff: 20.13mlTrain batch 6/32 - 234.0ms/batch - loss: 1.19535 - diff: 19.13mlTrain batch 7/32 - 233.8ms/batch - loss: 1.20415 - diff: 19.27mlTrain batch 8/32 - 234.0ms/batch - loss: 1.24959 - diff: 19.99mlTrain batch 9/32 - 246.4ms/batch - loss: 1.20595 - diff: 19.30mlTrain batch 10/32 - 234.2ms/batch - loss: 1.21671 - diff: 19.47mlTrain batch 11/32 - 233.5ms/batch - loss: 1.18261 - diff: 18.92mlTrain batch 12/32 - 234.6ms/batch - loss: 1.14443 - diff: 18.31mlTrain batch 13/32 - 233.6ms/batch - loss: 1.15469 - diff: 18.48mlTrain batch 14/32 - 233.9ms/batch - loss: 1.13544 - diff: 18.17mlTrain batch 15/32 - 233.8ms/batch - loss: 1.13960 - diff: 18.23mlTrain batch 16/32 - 234.1ms/batch - loss: 1.13430 - diff: 18.15mlTrain batch 17/32 - 233.8ms/batch - loss: 1.13332 - diff: 18.13mlTrain batch 18/32 - 233.4ms/batch - loss: 1.15788 - diff: 18.53mlTrain batch 19/32 - 233.7ms/batch - loss: 1.16095 - diff: 18.58mlTrain batch 20/32 - 234.3ms/batch - loss: 1.22432 - diff: 19.59mlTrain batch 21/32 - 233.7ms/batch - loss: 1.21201 - diff: 19.39mlTrain batch 22/32 - 233.7ms/batch - loss: 1.19250 - diff: 19.08mlTrain batch 23/32 - 233.7ms/batch - loss: 1.21097 - diff: 19.38mlTrain batch 24/32 - 233.6ms/batch - loss: 1.20371 - diff: 19.26mlTrain batch 25/32 - 234.1ms/batch - loss: 1.20669 - diff: 19.31mlTrain batch 26/32 - 239.5ms/batch - loss: 1.19774 - diff: 19.16mlTrain batch 27/32 - 233.9ms/batch - loss: 1.19226 - diff: 19.08mlTrain batch 28/32 - 233.6ms/batch - loss: 1.18572 - diff: 18.97mlTrain batch 29/32 - 233.9ms/batch - loss: 1.17749 - diff: 18.84mlTrain batch 30/32 - 233.8ms/batch - loss: 1.17916 - diff: 18.87mlTrain batch 31/32 - 233.9ms/batch - loss: 1.18157 - diff: 18.91mlTrain batch 32/32 - 76.3ms/batch - loss: 1.29995 - diff: 19.27mlTrain batch 32/32 - 17.8s 76.3ms/batch - loss: 1.29995 - diff: 19.27ml
Test 1.4s: val_loss: 1.84140 - diff: 28.69ml

Epoch 75: current best loss = 1.15178, at epoch 65
Train batch 1/32 - 233.7ms/batch - loss: 0.83559 - diff: 13.37mlTrain batch 2/32 - 237.8ms/batch - loss: 0.77062 - diff: 12.33mlTrain batch 3/32 - 234.1ms/batch - loss: 0.86822 - diff: 13.89mlTrain batch 4/32 - 233.9ms/batch - loss: 0.82457 - diff: 13.19mlTrain batch 5/32 - 233.7ms/batch - loss: 0.89678 - diff: 14.35mlTrain batch 6/32 - 233.9ms/batch - loss: 0.85871 - diff: 13.74mlTrain batch 7/32 - 233.9ms/batch - loss: 0.89610 - diff: 14.34mlTrain batch 8/32 - 234.2ms/batch - loss: 0.97720 - diff: 15.64mlTrain batch 9/32 - 233.9ms/batch - loss: 1.16069 - diff: 18.57mlTrain batch 10/32 - 233.6ms/batch - loss: 1.14002 - diff: 18.24mlTrain batch 11/32 - 233.7ms/batch - loss: 1.22410 - diff: 19.59mlTrain batch 12/32 - 237.4ms/batch - loss: 1.28163 - diff: 20.51mlTrain batch 13/32 - 233.8ms/batch - loss: 1.31535 - diff: 21.05mlTrain batch 14/32 - 234.0ms/batch - loss: 1.27632 - diff: 20.42mlTrain batch 15/32 - 233.8ms/batch - loss: 1.27828 - diff: 20.45mlTrain batch 16/32 - 234.2ms/batch - loss: 1.24967 - diff: 19.99mlTrain batch 17/32 - 233.8ms/batch - loss: 1.22855 - diff: 19.66mlTrain batch 18/32 - 234.2ms/batch - loss: 1.23916 - diff: 19.83mlTrain batch 19/32 - 233.8ms/batch - loss: 1.23474 - diff: 19.76mlTrain batch 20/32 - 233.8ms/batch - loss: 1.22577 - diff: 19.61mlTrain batch 21/32 - 233.7ms/batch - loss: 1.22824 - diff: 19.65mlTrain batch 22/32 - 234.2ms/batch - loss: 1.22627 - diff: 19.62mlTrain batch 23/32 - 233.9ms/batch - loss: 1.23998 - diff: 19.84mlTrain batch 24/32 - 233.9ms/batch - loss: 1.23209 - diff: 19.71mlTrain batch 25/32 - 234.0ms/batch - loss: 1.22480 - diff: 19.60mlTrain batch 26/32 - 233.7ms/batch - loss: 1.21566 - diff: 19.45mlTrain batch 27/32 - 233.9ms/batch - loss: 1.20176 - diff: 19.23mlTrain batch 28/32 - 233.9ms/batch - loss: 1.20177 - diff: 19.23mlTrain batch 29/32 - 233.9ms/batch - loss: 1.20066 - diff: 19.21mlTrain batch 30/32 - 237.5ms/batch - loss: 1.19427 - diff: 19.11mlTrain batch 31/32 - 233.7ms/batch - loss: 1.18857 - diff: 19.02mlTrain batch 32/32 - 76.7ms/batch - loss: 1.21631 - diff: 19.01mlTrain batch 32/32 - 17.2s 76.7ms/batch - loss: 1.21631 - diff: 19.01ml
Test 1.4s: val_loss: 1.48990 - diff: 23.12ml

Epoch 76: current best loss = 1.15178, at epoch 65
Train batch 1/32 - 233.8ms/batch - loss: 0.88225 - diff: 14.12mlTrain batch 2/32 - 234.5ms/batch - loss: 0.80924 - diff: 12.95mlTrain batch 3/32 - 233.9ms/batch - loss: 0.73273 - diff: 11.72mlTrain batch 4/32 - 234.0ms/batch - loss: 0.80177 - diff: 12.83mlTrain batch 5/32 - 233.7ms/batch - loss: 1.03393 - diff: 16.54mlTrain batch 6/32 - 236.9ms/batch - loss: 1.05750 - diff: 16.92mlTrain batch 7/32 - 233.7ms/batch - loss: 1.09032 - diff: 17.45mlTrain batch 8/32 - 233.8ms/batch - loss: 1.15578 - diff: 18.49mlTrain batch 9/32 - 234.0ms/batch - loss: 1.14575 - diff: 18.33mlTrain batch 10/32 - 233.6ms/batch - loss: 1.15864 - diff: 18.54mlTrain batch 11/32 - 233.5ms/batch - loss: 1.18792 - diff: 19.01mlTrain batch 12/32 - 233.8ms/batch - loss: 1.18855 - diff: 19.02mlTrain batch 13/32 - 233.5ms/batch - loss: 1.17412 - diff: 18.79mlTrain batch 14/32 - 234.5ms/batch - loss: 1.15843 - diff: 18.53mlTrain batch 15/32 - 234.0ms/batch - loss: 1.15313 - diff: 18.45mlTrain batch 16/32 - 234.4ms/batch - loss: 1.17182 - diff: 18.75mlTrain batch 17/32 - 234.0ms/batch - loss: 1.16093 - diff: 18.57mlTrain batch 18/32 - 234.0ms/batch - loss: 1.15264 - diff: 18.44mlTrain batch 19/32 - 233.9ms/batch - loss: 1.13770 - diff: 18.20mlTrain batch 20/32 - 238.2ms/batch - loss: 1.18342 - diff: 18.93mlTrain batch 21/32 - 233.9ms/batch - loss: 1.21193 - diff: 19.39mlTrain batch 22/32 - 233.6ms/batch - loss: 1.21890 - diff: 19.50mlTrain batch 23/32 - 233.8ms/batch - loss: 1.23271 - diff: 19.72mlTrain batch 24/32 - 234.5ms/batch - loss: 1.25429 - diff: 20.07mlTrain batch 25/32 - 233.9ms/batch - loss: 1.26947 - diff: 20.31mlTrain batch 26/32 - 233.4ms/batch - loss: 1.26839 - diff: 20.29mlTrain batch 27/32 - 265.0ms/batch - loss: 1.27599 - diff: 20.42mlTrain batch 28/32 - 233.8ms/batch - loss: 1.27635 - diff: 20.42mlTrain batch 29/32 - 233.9ms/batch - loss: 1.27806 - diff: 20.45mlTrain batch 30/32 - 234.3ms/batch - loss: 1.27881 - diff: 20.46mlTrain batch 31/32 - 233.7ms/batch - loss: 1.26810 - diff: 20.29mlTrain batch 32/32 - 76.7ms/batch - loss: 1.28768 - diff: 20.25mlTrain batch 32/32 - 17.9s 76.7ms/batch - loss: 1.28768 - diff: 20.25ml
Test 1.5s: val_loss: 1.09831 - diff: 16.92ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Systole_WideResNet50_0_Adam-0.001_MAE_DA3_best

Epoch 77: current best loss = 1.09831, at epoch 76
Train batch 1/32 - 249.8ms/batch - loss: 1.03275 - diff: 16.52mlTrain batch 2/32 - 237.8ms/batch - loss: 1.02461 - diff: 16.39mlTrain batch 3/32 - 233.9ms/batch - loss: 1.03817 - diff: 16.61mlTrain batch 4/32 - 234.2ms/batch - loss: 1.16768 - diff: 18.68mlTrain batch 5/32 - 233.8ms/batch - loss: 1.11645 - diff: 17.86mlTrain batch 6/32 - 234.4ms/batch - loss: 1.11522 - diff: 17.84mlTrain batch 7/32 - 233.9ms/batch - loss: 1.09168 - diff: 17.47mlTrain batch 8/32 - 233.2ms/batch - loss: 1.09894 - diff: 17.58mlTrain batch 9/32 - 233.5ms/batch - loss: 1.07012 - diff: 17.12mlTrain batch 10/32 - 234.5ms/batch - loss: 1.08967 - diff: 17.43mlTrain batch 11/32 - 233.5ms/batch - loss: 1.09627 - diff: 17.54mlTrain batch 12/32 - 244.3ms/batch - loss: 1.14021 - diff: 18.24mlTrain batch 13/32 - 233.7ms/batch - loss: 1.15129 - diff: 18.42mlTrain batch 14/32 - 238.3ms/batch - loss: 1.14428 - diff: 18.31mlTrain batch 15/32 - 233.7ms/batch - loss: 1.28334 - diff: 20.53mlTrain batch 16/32 - 238.3ms/batch - loss: 1.26549 - diff: 20.25mlTrain batch 17/32 - 233.8ms/batch - loss: 1.21667 - diff: 19.47mlTrain batch 18/32 - 234.3ms/batch - loss: 1.21180 - diff: 19.39mlTrain batch 19/32 - 236.8ms/batch - loss: 1.19866 - diff: 19.18mlTrain batch 20/32 - 233.9ms/batch - loss: 1.17465 - diff: 18.79mlTrain batch 21/32 - 233.9ms/batch - loss: 1.17289 - diff: 18.77mlTrain batch 22/32 - 234.0ms/batch - loss: 1.15443 - diff: 18.47mlTrain batch 23/32 - 233.5ms/batch - loss: 1.15148 - diff: 18.42mlTrain batch 24/32 - 238.3ms/batch - loss: 1.15301 - diff: 18.45mlTrain batch 25/32 - 233.7ms/batch - loss: 1.16185 - diff: 18.59mlTrain batch 26/32 - 236.0ms/batch - loss: 1.15747 - diff: 18.52mlTrain batch 27/32 - 233.8ms/batch - loss: 1.17468 - diff: 18.79mlTrain batch 28/32 - 234.3ms/batch - loss: 1.16849 - diff: 18.70mlTrain batch 29/32 - 233.6ms/batch - loss: 1.15832 - diff: 18.53mlTrain batch 30/32 - 233.6ms/batch - loss: 1.15294 - diff: 18.45mlTrain batch 31/32 - 233.4ms/batch - loss: 1.16153 - diff: 18.58mlTrain batch 32/32 - 76.3ms/batch - loss: 1.20898 - diff: 18.66mlTrain batch 32/32 - 18.0s 76.3ms/batch - loss: 1.20898 - diff: 18.66ml
Test 1.5s: val_loss: 1.21584 - diff: 18.45ml

Epoch 78: current best loss = 1.09831, at epoch 76
Train batch 1/32 - 233.8ms/batch - loss: 0.79001 - diff: 12.64mlTrain batch 2/32 - 233.6ms/batch - loss: 1.18089 - diff: 18.89mlTrain batch 3/32 - 233.6ms/batch - loss: 1.04830 - diff: 16.77mlTrain batch 4/32 - 234.0ms/batch - loss: 1.25085 - diff: 20.01mlTrain batch 5/32 - 233.8ms/batch - loss: 1.24417 - diff: 19.91mlTrain batch 6/32 - 233.9ms/batch - loss: 1.22990 - diff: 19.68mlTrain batch 7/32 - 235.9ms/batch - loss: 1.21787 - diff: 19.49mlTrain batch 8/32 - 233.6ms/batch - loss: 1.24210 - diff: 19.87mlTrain batch 9/32 - 234.0ms/batch - loss: 1.16464 - diff: 18.63mlTrain batch 10/32 - 233.9ms/batch - loss: 1.14613 - diff: 18.34mlTrain batch 11/32 - 233.6ms/batch - loss: 1.25178 - diff: 20.03mlTrain batch 12/32 - 233.8ms/batch - loss: 1.22994 - diff: 19.68mlTrain batch 13/32 - 234.1ms/batch - loss: 1.25095 - diff: 20.02mlTrain batch 14/32 - 234.4ms/batch - loss: 1.22939 - diff: 19.67mlTrain batch 15/32 - 235.2ms/batch - loss: 1.22968 - diff: 19.67mlTrain batch 16/32 - 234.2ms/batch - loss: 1.22903 - diff: 19.66mlTrain batch 17/32 - 233.9ms/batch - loss: 1.22000 - diff: 19.52mlTrain batch 18/32 - 234.1ms/batch - loss: 1.22382 - diff: 19.58mlTrain batch 19/32 - 233.4ms/batch - loss: 1.19506 - diff: 19.12mlTrain batch 20/32 - 234.7ms/batch - loss: 1.19300 - diff: 19.09mlTrain batch 21/32 - 233.7ms/batch - loss: 1.17842 - diff: 18.85mlTrain batch 22/32 - 233.8ms/batch - loss: 1.16371 - diff: 18.62mlTrain batch 23/32 - 233.8ms/batch - loss: 1.16579 - diff: 18.65mlTrain batch 24/32 - 233.8ms/batch - loss: 1.14632 - diff: 18.34mlTrain batch 25/32 - 233.9ms/batch - loss: 1.14090 - diff: 18.25mlTrain batch 26/32 - 234.2ms/batch - loss: 1.15024 - diff: 18.40mlTrain batch 27/32 - 234.0ms/batch - loss: 1.14147 - diff: 18.26mlTrain batch 28/32 - 233.0ms/batch - loss: 1.14574 - diff: 18.33mlTrain batch 29/32 - 233.5ms/batch - loss: 1.13987 - diff: 18.24mlTrain batch 30/32 - 233.4ms/batch - loss: 1.13221 - diff: 18.12mlTrain batch 31/32 - 233.8ms/batch - loss: 1.17025 - diff: 18.72mlTrain batch 32/32 - 76.5ms/batch - loss: 1.21530 - diff: 18.79mlTrain batch 32/32 - 16.5s 76.5ms/batch - loss: 1.21530 - diff: 18.79ml
Test 1.5s: val_loss: 1.11677 - diff: 17.24ml

Epoch 79: current best loss = 1.09831, at epoch 76
Train batch 1/32 - 233.7ms/batch - loss: 1.13803 - diff: 18.21mlTrain batch 2/32 - 239.5ms/batch - loss: 1.14132 - diff: 18.26mlTrain batch 3/32 - 237.7ms/batch - loss: 1.04102 - diff: 16.66mlTrain batch 4/32 - 234.1ms/batch - loss: 0.98445 - diff: 15.75mlTrain batch 5/32 - 234.1ms/batch - loss: 1.04201 - diff: 16.67mlTrain batch 6/32 - 234.1ms/batch - loss: 1.00600 - diff: 16.10mlTrain batch 7/32 - 234.0ms/batch - loss: 1.10940 - diff: 17.75mlTrain batch 8/32 - 233.8ms/batch - loss: 1.08375 - diff: 17.34mlTrain batch 9/32 - 233.8ms/batch - loss: 1.10151 - diff: 17.62mlTrain batch 10/32 - 234.0ms/batch - loss: 1.12363 - diff: 17.98mlTrain batch 11/32 - 237.9ms/batch - loss: 1.12887 - diff: 18.06mlTrain batch 12/32 - 233.7ms/batch - loss: 1.12104 - diff: 17.94mlTrain batch 13/32 - 233.5ms/batch - loss: 1.16763 - diff: 18.68mlTrain batch 14/32 - 233.6ms/batch - loss: 1.15829 - diff: 18.53mlTrain batch 15/32 - 250.2ms/batch - loss: 1.21723 - diff: 19.48mlTrain batch 16/32 - 233.9ms/batch - loss: 1.20180 - diff: 19.23mlTrain batch 17/32 - 234.8ms/batch - loss: 1.19097 - diff: 19.06mlTrain batch 18/32 - 234.1ms/batch - loss: 1.18728 - diff: 19.00mlTrain batch 19/32 - 234.1ms/batch - loss: 1.17959 - diff: 18.87mlTrain batch 20/32 - 233.9ms/batch - loss: 1.15497 - diff: 18.48mlTrain batch 21/32 - 234.7ms/batch - loss: 1.15523 - diff: 18.48mlTrain batch 22/32 - 233.6ms/batch - loss: 1.14894 - diff: 18.38mlTrain batch 23/32 - 262.3ms/batch - loss: 1.13646 - diff: 18.18mlTrain batch 24/32 - 233.6ms/batch - loss: 1.14766 - diff: 18.36mlTrain batch 25/32 - 234.1ms/batch - loss: 1.15538 - diff: 18.49mlTrain batch 26/32 - 233.8ms/batch - loss: 1.15340 - diff: 18.45mlTrain batch 27/32 - 233.8ms/batch - loss: 1.19476 - diff: 19.12mlTrain batch 28/32 - 247.2ms/batch - loss: 1.17654 - diff: 18.82mlTrain batch 29/32 - 234.3ms/batch - loss: 1.15622 - diff: 18.50mlTrain batch 30/32 - 233.8ms/batch - loss: 1.15747 - diff: 18.52mlTrain batch 31/32 - 233.9ms/batch - loss: 1.15315 - diff: 18.45mlTrain batch 32/32 - 76.2ms/batch - loss: 1.17604 - diff: 18.43mlTrain batch 32/32 - 17.8s 76.2ms/batch - loss: 1.17604 - diff: 18.43ml
Test 1.5s: val_loss: 1.06246 - diff: 16.54ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Systole_WideResNet50_0_Adam-0.001_MAE_DA3_best

Epoch 80: current best loss = 1.06246, at epoch 79
Train batch 1/32 - 251.9ms/batch - loss: 1.41269 - diff: 22.60mlTrain batch 2/32 - 237.6ms/batch - loss: 1.04691 - diff: 16.75mlTrain batch 3/32 - 233.4ms/batch - loss: 1.50630 - diff: 24.10mlTrain batch 4/32 - 234.0ms/batch - loss: 1.42972 - diff: 22.88mlTrain batch 5/32 - 233.6ms/batch - loss: 1.37872 - diff: 22.06mlTrain batch 6/32 - 233.6ms/batch - loss: 1.37577 - diff: 22.01mlTrain batch 7/32 - 233.8ms/batch - loss: 1.36787 - diff: 21.89mlTrain batch 8/32 - 233.9ms/batch - loss: 1.35868 - diff: 21.74mlTrain batch 9/32 - 233.6ms/batch - loss: 1.31526 - diff: 21.04mlTrain batch 10/32 - 233.6ms/batch - loss: 1.27468 - diff: 20.39mlTrain batch 11/32 - 233.7ms/batch - loss: 1.22370 - diff: 19.58mlTrain batch 12/32 - 234.0ms/batch - loss: 1.21834 - diff: 19.49mlTrain batch 13/32 - 233.8ms/batch - loss: 1.18692 - diff: 18.99mlTrain batch 14/32 - 233.9ms/batch - loss: 1.16280 - diff: 18.60mlTrain batch 15/32 - 234.0ms/batch - loss: 1.16948 - diff: 18.71mlTrain batch 16/32 - 233.3ms/batch - loss: 1.16654 - diff: 18.66mlTrain batch 17/32 - 234.4ms/batch - loss: 1.17302 - diff: 18.77mlTrain batch 18/32 - 233.6ms/batch - loss: 1.27034 - diff: 20.33mlTrain batch 19/32 - 234.2ms/batch - loss: 1.25843 - diff: 20.13mlTrain batch 20/32 - 233.6ms/batch - loss: 1.25084 - diff: 20.01mlTrain batch 21/32 - 241.2ms/batch - loss: 1.26653 - diff: 20.26mlTrain batch 22/32 - 233.7ms/batch - loss: 1.27141 - diff: 20.34mlTrain batch 23/32 - 234.3ms/batch - loss: 1.26016 - diff: 20.16mlTrain batch 24/32 - 233.8ms/batch - loss: 1.26160 - diff: 20.19mlTrain batch 25/32 - 246.0ms/batch - loss: 1.27913 - diff: 20.47mlTrain batch 26/32 - 239.4ms/batch - loss: 1.26266 - diff: 20.20mlTrain batch 27/32 - 233.5ms/batch - loss: 1.25238 - diff: 20.04mlTrain batch 28/32 - 233.7ms/batch - loss: 1.24591 - diff: 19.93mlTrain batch 29/32 - 233.2ms/batch - loss: 1.24095 - diff: 19.86mlTrain batch 30/32 - 234.0ms/batch - loss: 1.26625 - diff: 20.26mlTrain batch 31/32 - 233.7ms/batch - loss: 1.25327 - diff: 20.05mlTrain batch 32/32 - 80.6ms/batch - loss: 1.27030 - diff: 20.00mlTrain batch 32/32 - 17.6s 80.6ms/batch - loss: 1.27030 - diff: 20.00ml
Test 1.5s: val_loss: 1.63106 - diff: 25.31ml

Epoch 81: current best loss = 1.06246, at epoch 79
Train batch 1/32 - 233.7ms/batch - loss: 0.94147 - diff: 15.06mlTrain batch 2/32 - 240.4ms/batch - loss: 1.05245 - diff: 16.84mlTrain batch 3/32 - 233.4ms/batch - loss: 1.06663 - diff: 17.07mlTrain batch 4/32 - 234.2ms/batch - loss: 1.04647 - diff: 16.74mlTrain batch 5/32 - 233.4ms/batch - loss: 1.06849 - diff: 17.10mlTrain batch 6/32 - 237.5ms/batch - loss: 1.12393 - diff: 17.98mlTrain batch 7/32 - 240.1ms/batch - loss: 1.10221 - diff: 17.64mlTrain batch 8/32 - 233.8ms/batch - loss: 1.20663 - diff: 19.31mlTrain batch 9/32 - 235.5ms/batch - loss: 1.23193 - diff: 19.71mlTrain batch 10/32 - 233.8ms/batch - loss: 1.21313 - diff: 19.41mlTrain batch 11/32 - 233.8ms/batch - loss: 1.17217 - diff: 18.75mlTrain batch 12/32 - 233.8ms/batch - loss: 1.20210 - diff: 19.23mlTrain batch 13/32 - 234.1ms/batch - loss: 1.22341 - diff: 19.57mlTrain batch 14/32 - 233.9ms/batch - loss: 1.22824 - diff: 19.65mlTrain batch 15/32 - 233.9ms/batch - loss: 1.23781 - diff: 19.81mlTrain batch 16/32 - 234.4ms/batch - loss: 1.22912 - diff: 19.67mlTrain batch 17/32 - 233.8ms/batch - loss: 1.22984 - diff: 19.68mlTrain batch 18/32 - 234.1ms/batch - loss: 1.21380 - diff: 19.42mlTrain batch 19/32 - 233.7ms/batch - loss: 1.19736 - diff: 19.16mlTrain batch 20/32 - 233.6ms/batch - loss: 1.19362 - diff: 19.10mlTrain batch 21/32 - 233.6ms/batch - loss: 1.20467 - diff: 19.27mlTrain batch 22/32 - 233.7ms/batch - loss: 1.18670 - diff: 18.99mlTrain batch 23/32 - 233.7ms/batch - loss: 1.17085 - diff: 18.73mlTrain batch 24/32 - 233.6ms/batch - loss: 1.19466 - diff: 19.11mlTrain batch 25/32 - 234.6ms/batch - loss: 1.19448 - diff: 19.11mlTrain batch 26/32 - 233.6ms/batch - loss: 1.19389 - diff: 19.10mlTrain batch 27/32 - 233.8ms/batch - loss: 1.17892 - diff: 18.86mlTrain batch 28/32 - 233.9ms/batch - loss: 1.17206 - diff: 18.75mlTrain batch 29/32 - 233.9ms/batch - loss: 1.19120 - diff: 19.06mlTrain batch 30/32 - 233.9ms/batch - loss: 1.19563 - diff: 19.13mlTrain batch 31/32 - 234.3ms/batch - loss: 1.18482 - diff: 18.96mlTrain batch 32/32 - 84.0ms/batch - loss: 1.20817 - diff: 18.94mlTrain batch 32/32 - 17.1s 84.0ms/batch - loss: 1.20817 - diff: 18.94ml
Test 1.4s: val_loss: 1.46701 - diff: 22.90ml

Epoch 82: current best loss = 1.06246, at epoch 79
Train batch 1/32 - 233.7ms/batch - loss: 0.99970 - diff: 16.00mlTrain batch 2/32 - 240.5ms/batch - loss: 1.39965 - diff: 22.39mlTrain batch 3/32 - 233.8ms/batch - loss: 1.43037 - diff: 22.89mlTrain batch 4/32 - 234.3ms/batch - loss: 1.30640 - diff: 20.90mlTrain batch 5/32 - 233.8ms/batch - loss: 1.23808 - diff: 19.81mlTrain batch 6/32 - 246.8ms/batch - loss: 1.20795 - diff: 19.33mlTrain batch 7/32 - 233.7ms/batch - loss: 1.14174 - diff: 18.27mlTrain batch 8/32 - 234.3ms/batch - loss: 1.17003 - diff: 18.72mlTrain batch 9/32 - 233.7ms/batch - loss: 1.18647 - diff: 18.98mlTrain batch 10/32 - 233.9ms/batch - loss: 1.17453 - diff: 18.79mlTrain batch 11/32 - 233.9ms/batch - loss: 1.29789 - diff: 20.77mlTrain batch 12/32 - 235.4ms/batch - loss: 1.32044 - diff: 21.13mlTrain batch 13/32 - 233.7ms/batch - loss: 1.27811 - diff: 20.45mlTrain batch 14/32 - 242.1ms/batch - loss: 1.23670 - diff: 19.79mlTrain batch 15/32 - 238.5ms/batch - loss: 1.22099 - diff: 19.54mlTrain batch 16/32 - 234.8ms/batch - loss: 1.21199 - diff: 19.39mlTrain batch 17/32 - 233.8ms/batch - loss: 1.19756 - diff: 19.16mlTrain batch 18/32 - 234.1ms/batch - loss: 1.17810 - diff: 18.85mlTrain batch 19/32 - 233.8ms/batch - loss: 1.18972 - diff: 19.04mlTrain batch 20/32 - 234.0ms/batch - loss: 1.17023 - diff: 18.72mlTrain batch 21/32 - 233.3ms/batch - loss: 1.15821 - diff: 18.53mlTrain batch 22/32 - 234.1ms/batch - loss: 1.16532 - diff: 18.65mlTrain batch 23/32 - 233.7ms/batch - loss: 1.16362 - diff: 18.62mlTrain batch 24/32 - 234.5ms/batch - loss: 1.15592 - diff: 18.49mlTrain batch 25/32 - 233.9ms/batch - loss: 1.15476 - diff: 18.48mlTrain batch 26/32 - 238.3ms/batch - loss: 1.15701 - diff: 18.51mlTrain batch 27/32 - 234.8ms/batch - loss: 1.15360 - diff: 18.46mlTrain batch 28/32 - 234.6ms/batch - loss: 1.15172 - diff: 18.43mlTrain batch 29/32 - 233.5ms/batch - loss: 1.14253 - diff: 18.28mlTrain batch 30/32 - 234.8ms/batch - loss: 1.15855 - diff: 18.54mlTrain batch 31/32 - 233.9ms/batch - loss: 1.16349 - diff: 18.62mlTrain batch 32/32 - 83.8ms/batch - loss: 1.17425 - diff: 18.55mlTrain batch 32/32 - 17.1s 83.8ms/batch - loss: 1.17425 - diff: 18.55ml
Test 1.6s: val_loss: 1.08795 - diff: 16.55ml

Epoch 83: current best loss = 1.06246, at epoch 79
Train batch 1/32 - 233.9ms/batch - loss: 0.97540 - diff: 15.61mlTrain batch 2/32 - 234.6ms/batch - loss: 0.77937 - diff: 12.47mlTrain batch 3/32 - 237.3ms/batch - loss: 0.79824 - diff: 12.77mlTrain batch 4/32 - 234.1ms/batch - loss: 0.94256 - diff: 15.08mlTrain batch 5/32 - 239.2ms/batch - loss: 0.95857 - diff: 15.34mlTrain batch 6/32 - 234.3ms/batch - loss: 0.94544 - diff: 15.13mlTrain batch 7/32 - 245.1ms/batch - loss: 0.95798 - diff: 15.33mlTrain batch 8/32 - 234.1ms/batch - loss: 0.98655 - diff: 15.78mlTrain batch 9/32 - 233.7ms/batch - loss: 1.05240 - diff: 16.84mlTrain batch 10/32 - 238.4ms/batch - loss: 1.01562 - diff: 16.25mlTrain batch 11/32 - 233.9ms/batch - loss: 1.01871 - diff: 16.30mlTrain batch 12/32 - 233.1ms/batch - loss: 1.00511 - diff: 16.08mlTrain batch 13/32 - 233.4ms/batch - loss: 1.03151 - diff: 16.50mlTrain batch 14/32 - 233.7ms/batch - loss: 1.04573 - diff: 16.73mlTrain batch 15/32 - 233.8ms/batch - loss: 1.06696 - diff: 17.07mlTrain batch 16/32 - 234.0ms/batch - loss: 1.06231 - diff: 17.00mlTrain batch 17/32 - 233.7ms/batch - loss: 1.04653 - diff: 16.74mlTrain batch 18/32 - 233.8ms/batch - loss: 1.07416 - diff: 17.19mlTrain batch 19/32 - 236.9ms/batch - loss: 1.07550 - diff: 17.21mlTrain batch 20/32 - 235.8ms/batch - loss: 1.06249 - diff: 17.00mlTrain batch 21/32 - 233.6ms/batch - loss: 1.05744 - diff: 16.92mlTrain batch 22/32 - 234.1ms/batch - loss: 1.05176 - diff: 16.83mlTrain batch 23/32 - 234.6ms/batch - loss: 1.09268 - diff: 17.48mlTrain batch 24/32 - 234.4ms/batch - loss: 1.08511 - diff: 17.36mlTrain batch 25/32 - 238.1ms/batch - loss: 1.06625 - diff: 17.06mlTrain batch 26/32 - 234.0ms/batch - loss: 1.05949 - diff: 16.95mlTrain batch 27/32 - 236.9ms/batch - loss: 1.06200 - diff: 16.99mlTrain batch 28/32 - 233.7ms/batch - loss: 1.04953 - diff: 16.79mlTrain batch 29/32 - 233.6ms/batch - loss: 1.04554 - diff: 16.73mlTrain batch 30/32 - 234.1ms/batch - loss: 1.07753 - diff: 17.24mlTrain batch 31/32 - 233.8ms/batch - loss: 1.09227 - diff: 17.48mlTrain batch 32/32 - 76.6ms/batch - loss: 1.11967 - diff: 17.48mlTrain batch 32/32 - 17.7s 76.6ms/batch - loss: 1.11967 - diff: 17.48ml
Test 1.7s: val_loss: 1.09394 - diff: 16.91ml

Epoch 84: current best loss = 1.06246, at epoch 79
Train batch 1/32 - 233.8ms/batch - loss: 1.31204 - diff: 20.99mlTrain batch 2/32 - 238.3ms/batch - loss: 1.14850 - diff: 18.38mlTrain batch 3/32 - 233.8ms/batch - loss: 1.27231 - diff: 20.36mlTrain batch 4/32 - 233.6ms/batch - loss: 1.21392 - diff: 19.42mlTrain batch 5/32 - 245.7ms/batch - loss: 1.48612 - diff: 23.78mlTrain batch 6/32 - 233.8ms/batch - loss: 1.53121 - diff: 24.50mlTrain batch 7/32 - 233.5ms/batch - loss: 1.39384 - diff: 22.30mlTrain batch 8/32 - 234.6ms/batch - loss: 1.37964 - diff: 22.07mlTrain batch 9/32 - 233.7ms/batch - loss: 1.38436 - diff: 22.15mlTrain batch 10/32 - 233.8ms/batch - loss: 1.35159 - diff: 21.63mlTrain batch 11/32 - 233.7ms/batch - loss: 1.30584 - diff: 20.89mlTrain batch 12/32 - 233.6ms/batch - loss: 1.29472 - diff: 20.72mlTrain batch 13/32 - 233.6ms/batch - loss: 1.27129 - diff: 20.34mlTrain batch 14/32 - 233.4ms/batch - loss: 1.23474 - diff: 19.76mlTrain batch 15/32 - 233.7ms/batch - loss: 1.22519 - diff: 19.60mlTrain batch 16/32 - 233.8ms/batch - loss: 1.24626 - diff: 19.94mlTrain batch 17/32 - 233.9ms/batch - loss: 1.23312 - diff: 19.73mlTrain batch 18/32 - 233.8ms/batch - loss: 1.24029 - diff: 19.84mlTrain batch 19/32 - 233.9ms/batch - loss: 1.24801 - diff: 19.97mlTrain batch 20/32 - 233.9ms/batch - loss: 1.22993 - diff: 19.68mlTrain batch 21/32 - 234.0ms/batch - loss: 1.22291 - diff: 19.57mlTrain batch 22/32 - 233.6ms/batch - loss: 1.20940 - diff: 19.35mlTrain batch 23/32 - 233.9ms/batch - loss: 1.21615 - diff: 19.46mlTrain batch 24/32 - 233.5ms/batch - loss: 1.19295 - diff: 19.09mlTrain batch 25/32 - 249.7ms/batch - loss: 1.19005 - diff: 19.04mlTrain batch 26/32 - 234.1ms/batch - loss: 1.18137 - diff: 18.90mlTrain batch 27/32 - 234.0ms/batch - loss: 1.17669 - diff: 18.83mlTrain batch 28/32 - 233.9ms/batch - loss: 1.17494 - diff: 18.80mlTrain batch 29/32 - 233.9ms/batch - loss: 1.16046 - diff: 18.57mlTrain batch 30/32 - 233.4ms/batch - loss: 1.17953 - diff: 18.87mlTrain batch 31/32 - 233.9ms/batch - loss: 1.19336 - diff: 19.09mlTrain batch 32/32 - 76.7ms/batch - loss: 1.22257 - diff: 19.10mlTrain batch 32/32 - 17.0s 76.7ms/batch - loss: 1.22257 - diff: 19.10ml
Test 1.5s: val_loss: 1.65150 - diff: 25.45ml

Epoch 85: current best loss = 1.06246, at epoch 79
Train batch 1/32 - 252.3ms/batch - loss: 0.55457 - diff: 8.87mlTrain batch 2/32 - 241.4ms/batch - loss: 0.70728 - diff: 11.32mlTrain batch 3/32 - 233.7ms/batch - loss: 0.82896 - diff: 13.26mlTrain batch 4/32 - 236.6ms/batch - loss: 0.74449 - diff: 11.91mlTrain batch 5/32 - 233.5ms/batch - loss: 0.83443 - diff: 13.35mlTrain batch 6/32 - 233.0ms/batch - loss: 0.80771 - diff: 12.92mlTrain batch 7/32 - 233.6ms/batch - loss: 0.79740 - diff: 12.76mlTrain batch 8/32 - 234.9ms/batch - loss: 0.79659 - diff: 12.75mlTrain batch 9/32 - 233.6ms/batch - loss: 0.83386 - diff: 13.34mlTrain batch 10/32 - 234.2ms/batch - loss: 0.82643 - diff: 13.22mlTrain batch 11/32 - 235.6ms/batch - loss: 0.88171 - diff: 14.11mlTrain batch 12/32 - 234.4ms/batch - loss: 0.90211 - diff: 14.43mlTrain batch 13/32 - 233.8ms/batch - loss: 0.92966 - diff: 14.87mlTrain batch 14/32 - 233.2ms/batch - loss: 0.94749 - diff: 15.16mlTrain batch 15/32 - 234.5ms/batch - loss: 0.93520 - diff: 14.96mlTrain batch 16/32 - 233.6ms/batch - loss: 0.94522 - diff: 15.12mlTrain batch 17/32 - 233.7ms/batch - loss: 0.97151 - diff: 15.54mlTrain batch 18/32 - 234.3ms/batch - loss: 1.00182 - diff: 16.03mlTrain batch 19/32 - 240.5ms/batch - loss: 1.04066 - diff: 16.65mlTrain batch 20/32 - 235.8ms/batch - loss: 1.03299 - diff: 16.53mlTrain batch 21/32 - 236.2ms/batch - loss: 1.02970 - diff: 16.48mlTrain batch 22/32 - 233.5ms/batch - loss: 1.02902 - diff: 16.46mlTrain batch 23/32 - 233.8ms/batch - loss: 1.06491 - diff: 17.04mlTrain batch 24/32 - 246.5ms/batch - loss: 1.05279 - diff: 16.84mlTrain batch 25/32 - 233.8ms/batch - loss: 1.06007 - diff: 16.96mlTrain batch 26/32 - 238.2ms/batch - loss: 1.06809 - diff: 17.09mlTrain batch 27/32 - 242.7ms/batch - loss: 1.09197 - diff: 17.47mlTrain batch 28/32 - 233.1ms/batch - loss: 1.07968 - diff: 17.27mlTrain batch 29/32 - 236.2ms/batch - loss: 1.08134 - diff: 17.30mlTrain batch 30/32 - 233.1ms/batch - loss: 1.08883 - diff: 17.42mlTrain batch 31/32 - 233.5ms/batch - loss: 1.10604 - diff: 17.70mlTrain batch 32/32 - 76.2ms/batch - loss: 1.15223 - diff: 17.78mlTrain batch 32/32 - 17.6s 76.2ms/batch - loss: 1.15223 - diff: 17.78ml
Test 1.5s: val_loss: 1.02431 - diff: 15.57ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Systole_WideResNet50_0_Adam-0.001_MAE_DA3_best

Epoch 86: current best loss = 1.02431, at epoch 85
Train batch 1/32 - 242.1ms/batch - loss: 0.80213 - diff: 12.83mlTrain batch 2/32 - 233.8ms/batch - loss: 0.83156 - diff: 13.30mlTrain batch 3/32 - 233.6ms/batch - loss: 0.93989 - diff: 15.04mlTrain batch 4/32 - 234.0ms/batch - loss: 1.00584 - diff: 16.09mlTrain batch 5/32 - 233.4ms/batch - loss: 1.01196 - diff: 16.19mlTrain batch 6/32 - 238.1ms/batch - loss: 1.10805 - diff: 17.73mlTrain batch 7/32 - 233.5ms/batch - loss: 1.17382 - diff: 18.78mlTrain batch 8/32 - 237.5ms/batch - loss: 1.13810 - diff: 18.21mlTrain batch 9/32 - 238.5ms/batch - loss: 1.12641 - diff: 18.02mlTrain batch 10/32 - 233.6ms/batch - loss: 1.13568 - diff: 18.17mlTrain batch 11/32 - 235.0ms/batch - loss: 1.11256 - diff: 17.80mlTrain batch 12/32 - 233.9ms/batch - loss: 1.10234 - diff: 17.64mlTrain batch 13/32 - 233.8ms/batch - loss: 1.09918 - diff: 17.59mlTrain batch 14/32 - 237.5ms/batch - loss: 1.11263 - diff: 17.80mlTrain batch 15/32 - 233.4ms/batch - loss: 1.10860 - diff: 17.74mlTrain batch 16/32 - 253.0ms/batch - loss: 1.13986 - diff: 18.24mlTrain batch 17/32 - 233.5ms/batch - loss: 1.13321 - diff: 18.13mlTrain batch 18/32 - 233.8ms/batch - loss: 1.23733 - diff: 19.80mlTrain batch 19/32 - 233.6ms/batch - loss: 1.22417 - diff: 19.59mlTrain batch 20/32 - 233.9ms/batch - loss: 1.22128 - diff: 19.54mlTrain batch 21/32 - 233.8ms/batch - loss: 1.21834 - diff: 19.49mlTrain batch 22/32 - 238.2ms/batch - loss: 1.19205 - diff: 19.07mlTrain batch 23/32 - 233.7ms/batch - loss: 1.19472 - diff: 19.12mlTrain batch 24/32 - 233.5ms/batch - loss: 1.18383 - diff: 18.94mlTrain batch 25/32 - 242.8ms/batch - loss: 1.17979 - diff: 18.88mlTrain batch 26/32 - 234.3ms/batch - loss: 1.17741 - diff: 18.84mlTrain batch 27/32 - 233.7ms/batch - loss: 1.16762 - diff: 18.68mlTrain batch 28/32 - 233.8ms/batch - loss: 1.16707 - diff: 18.67mlTrain batch 29/32 - 233.6ms/batch - loss: 1.16048 - diff: 18.57mlTrain batch 30/32 - 233.7ms/batch - loss: 1.17003 - diff: 18.72mlTrain batch 31/32 - 233.6ms/batch - loss: 1.17491 - diff: 18.80mlTrain batch 32/32 - 84.4ms/batch - loss: 1.21178 - diff: 18.83mlTrain batch 32/32 - 17.2s 84.4ms/batch - loss: 1.21178 - diff: 18.83ml
Test 1.6s: val_loss: 1.58775 - diff: 24.88ml

Epoch 87: current best loss = 1.02431, at epoch 85
Train batch 1/32 - 233.6ms/batch - loss: 0.87020 - diff: 13.92mlTrain batch 2/32 - 234.3ms/batch - loss: 0.94388 - diff: 15.10mlTrain batch 3/32 - 233.7ms/batch - loss: 0.95894 - diff: 15.34mlTrain batch 4/32 - 233.7ms/batch - loss: 0.96383 - diff: 15.42mlTrain batch 5/32 - 233.7ms/batch - loss: 1.07101 - diff: 17.14mlTrain batch 6/32 - 233.7ms/batch - loss: 1.14577 - diff: 18.33mlTrain batch 7/32 - 234.7ms/batch - loss: 1.09721 - diff: 17.56mlTrain batch 8/32 - 233.9ms/batch - loss: 1.09799 - diff: 17.57mlTrain batch 9/32 - 234.0ms/batch - loss: 1.11369 - diff: 17.82mlTrain batch 10/32 - 233.8ms/batch - loss: 1.09154 - diff: 17.46mlTrain batch 11/32 - 233.9ms/batch - loss: 1.04359 - diff: 16.70mlTrain batch 12/32 - 233.7ms/batch - loss: 1.04741 - diff: 16.76mlTrain batch 13/32 - 233.8ms/batch - loss: 1.04014 - diff: 16.64mlTrain batch 14/32 - 233.5ms/batch - loss: 1.06224 - diff: 17.00mlTrain batch 15/32 - 233.6ms/batch - loss: 1.08104 - diff: 17.30mlTrain batch 16/32 - 233.7ms/batch - loss: 1.08893 - diff: 17.42mlTrain batch 17/32 - 233.8ms/batch - loss: 1.08897 - diff: 17.42mlTrain batch 18/32 - 233.8ms/batch - loss: 1.10029 - diff: 17.60mlTrain batch 19/32 - 233.5ms/batch - loss: 1.10685 - diff: 17.71mlTrain batch 20/32 - 234.1ms/batch - loss: 1.09997 - diff: 17.60mlTrain batch 21/32 - 233.8ms/batch - loss: 1.08390 - diff: 17.34mlTrain batch 22/32 - 234.0ms/batch - loss: 1.07626 - diff: 17.22mlTrain batch 23/32 - 233.6ms/batch - loss: 1.06649 - diff: 17.06mlTrain batch 24/32 - 233.9ms/batch - loss: 1.09212 - diff: 17.47mlTrain batch 25/32 - 233.7ms/batch - loss: 1.10463 - diff: 17.67mlTrain batch 26/32 - 233.9ms/batch - loss: 1.14095 - diff: 18.26mlTrain batch 27/32 - 234.0ms/batch - loss: 1.13880 - diff: 18.22mlTrain batch 28/32 - 233.6ms/batch - loss: 1.13206 - diff: 18.11mlTrain batch 29/32 - 232.9ms/batch - loss: 1.13032 - diff: 18.09mlTrain batch 30/32 - 234.0ms/batch - loss: 1.14034 - diff: 18.25mlTrain batch 31/32 - 233.2ms/batch - loss: 1.13766 - diff: 18.20mlTrain batch 32/32 - 84.4ms/batch - loss: 1.15766 - diff: 18.17mlTrain batch 32/32 - 16.2s 84.4ms/batch - loss: 1.15766 - diff: 18.17ml
Test 1.5s: val_loss: 1.14459 - diff: 17.72ml

Epoch 88: current best loss = 1.02431, at epoch 85
Train batch 1/32 - 233.9ms/batch - loss: 1.20101 - diff: 19.22mlTrain batch 2/32 - 234.3ms/batch - loss: 1.20919 - diff: 19.35mlTrain batch 3/32 - 233.7ms/batch - loss: 1.14364 - diff: 18.30mlTrain batch 4/32 - 234.3ms/batch - loss: 1.29833 - diff: 20.77mlTrain batch 5/32 - 233.5ms/batch - loss: 1.25889 - diff: 20.14mlTrain batch 6/32 - 234.2ms/batch - loss: 1.26144 - diff: 20.18mlTrain batch 7/32 - 233.9ms/batch - loss: 1.19849 - diff: 19.18mlTrain batch 8/32 - 232.9ms/batch - loss: 1.18575 - diff: 18.97mlTrain batch 9/32 - 233.7ms/batch - loss: 1.13810 - diff: 18.21mlTrain batch 10/32 - 234.3ms/batch - loss: 1.14697 - diff: 18.35mlTrain batch 11/32 - 233.6ms/batch - loss: 1.14204 - diff: 18.27mlTrain batch 12/32 - 246.7ms/batch - loss: 1.12461 - diff: 17.99mlTrain batch 13/32 - 233.8ms/batch - loss: 1.09041 - diff: 17.45mlTrain batch 14/32 - 234.0ms/batch - loss: 1.08350 - diff: 17.34mlTrain batch 15/32 - 234.0ms/batch - loss: 1.17760 - diff: 18.84mlTrain batch 16/32 - 238.4ms/batch - loss: 1.16011 - diff: 18.56mlTrain batch 17/32 - 233.7ms/batch - loss: 1.15419 - diff: 18.47mlTrain batch 18/32 - 234.9ms/batch - loss: 1.12895 - diff: 18.06mlTrain batch 19/32 - 234.0ms/batch - loss: 1.11516 - diff: 17.84mlTrain batch 20/32 - 233.9ms/batch - loss: 1.10460 - diff: 17.67mlTrain batch 21/32 - 233.5ms/batch - loss: 1.10129 - diff: 17.62mlTrain batch 22/32 - 233.7ms/batch - loss: 1.12290 - diff: 17.97mlTrain batch 23/32 - 233.7ms/batch - loss: 1.12621 - diff: 18.02mlTrain batch 24/32 - 239.4ms/batch - loss: 1.11658 - diff: 17.87mlTrain batch 25/32 - 233.7ms/batch - loss: 1.11626 - diff: 17.86mlTrain batch 26/32 - 234.1ms/batch - loss: 1.12443 - diff: 17.99mlTrain batch 27/32 - 239.8ms/batch - loss: 1.12450 - diff: 17.99mlTrain batch 28/32 - 233.9ms/batch - loss: 1.11945 - diff: 17.91mlTrain batch 29/32 - 234.0ms/batch - loss: 1.10923 - diff: 17.75mlTrain batch 30/32 - 233.9ms/batch - loss: 1.10193 - diff: 17.63mlTrain batch 31/32 - 233.9ms/batch - loss: 1.09695 - diff: 17.55mlTrain batch 32/32 - 76.4ms/batch - loss: 1.12416 - diff: 17.55mlTrain batch 32/32 - 16.3s 76.4ms/batch - loss: 1.12416 - diff: 17.55ml
Test 1.5s: val_loss: 1.01540 - diff: 15.88ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Systole_WideResNet50_0_Adam-0.001_MAE_DA3_best

Epoch 89: current best loss = 1.01540, at epoch 88
Train batch 1/32 - 252.2ms/batch - loss: 0.68900 - diff: 11.02mlTrain batch 2/32 - 233.8ms/batch - loss: 0.92247 - diff: 14.76mlTrain batch 3/32 - 233.4ms/batch - loss: 0.87821 - diff: 14.05mlTrain batch 4/32 - 234.2ms/batch - loss: 0.89211 - diff: 14.27mlTrain batch 5/32 - 240.8ms/batch - loss: 1.01856 - diff: 16.30mlTrain batch 6/32 - 233.9ms/batch - loss: 1.08974 - diff: 17.44mlTrain batch 7/32 - 237.0ms/batch - loss: 1.10202 - diff: 17.63mlTrain batch 8/32 - 233.4ms/batch - loss: 1.13890 - diff: 18.22mlTrain batch 9/32 - 234.1ms/batch - loss: 1.08754 - diff: 17.40mlTrain batch 10/32 - 233.5ms/batch - loss: 1.12445 - diff: 17.99mlTrain batch 11/32 - 233.6ms/batch - loss: 1.15162 - diff: 18.43mlTrain batch 12/32 - 237.5ms/batch - loss: 1.12266 - diff: 17.96mlTrain batch 13/32 - 233.7ms/batch - loss: 1.11157 - diff: 17.79mlTrain batch 14/32 - 234.6ms/batch - loss: 1.08833 - diff: 17.41mlTrain batch 15/32 - 237.8ms/batch - loss: 1.07711 - diff: 17.23mlTrain batch 16/32 - 234.3ms/batch - loss: 1.06361 - diff: 17.02mlTrain batch 17/32 - 233.7ms/batch - loss: 1.08395 - diff: 17.34mlTrain batch 18/32 - 233.6ms/batch - loss: 1.05951 - diff: 16.95mlTrain batch 19/32 - 234.0ms/batch - loss: 1.05085 - diff: 16.81mlTrain batch 20/32 - 233.7ms/batch - loss: 1.05107 - diff: 16.82mlTrain batch 21/32 - 233.7ms/batch - loss: 1.07410 - diff: 17.19mlTrain batch 22/32 - 233.7ms/batch - loss: 1.12003 - diff: 17.92mlTrain batch 23/32 - 233.9ms/batch - loss: 1.11609 - diff: 17.86mlTrain batch 24/32 - 234.0ms/batch - loss: 1.09681 - diff: 17.55mlTrain batch 25/32 - 233.4ms/batch - loss: 1.09175 - diff: 17.47mlTrain batch 26/32 - 233.9ms/batch - loss: 1.08979 - diff: 17.44mlTrain batch 27/32 - 234.1ms/batch - loss: 1.12866 - diff: 18.06mlTrain batch 28/32 - 234.2ms/batch - loss: 1.12487 - diff: 18.00mlTrain batch 29/32 - 233.7ms/batch - loss: 1.11900 - diff: 17.90mlTrain batch 30/32 - 233.8ms/batch - loss: 1.11726 - diff: 17.88mlTrain batch 31/32 - 233.7ms/batch - loss: 1.11071 - diff: 17.77mlTrain batch 32/32 - 76.5ms/batch - loss: 1.12114 - diff: 17.71mlTrain batch 32/32 - 17.8s 76.5ms/batch - loss: 1.12114 - diff: 17.71ml
Test 1.6s: val_loss: 1.65132 - diff: 25.08ml

Epoch 90: current best loss = 1.01540, at epoch 88
Train batch 1/32 - 233.7ms/batch - loss: 0.95826 - diff: 15.33mlTrain batch 2/32 - 237.8ms/batch - loss: 0.98956 - diff: 15.83mlTrain batch 3/32 - 233.7ms/batch - loss: 1.04504 - diff: 16.72mlTrain batch 4/32 - 238.2ms/batch - loss: 1.10780 - diff: 17.72mlTrain batch 5/32 - 233.5ms/batch - loss: 1.08699 - diff: 17.39mlTrain batch 6/32 - 233.9ms/batch - loss: 1.25067 - diff: 20.01mlTrain batch 7/32 - 233.7ms/batch - loss: 1.29259 - diff: 20.68mlTrain batch 8/32 - 234.1ms/batch - loss: 1.24234 - diff: 19.88mlTrain batch 9/32 - 234.2ms/batch - loss: 1.21120 - diff: 19.38mlTrain batch 10/32 - 234.1ms/batch - loss: 1.20331 - diff: 19.25mlTrain batch 11/32 - 233.8ms/batch - loss: 1.19895 - diff: 19.18mlTrain batch 12/32 - 234.1ms/batch - loss: 1.18157 - diff: 18.91mlTrain batch 13/32 - 239.9ms/batch - loss: 1.18132 - diff: 18.90mlTrain batch 14/32 - 234.1ms/batch - loss: 1.16660 - diff: 18.67mlTrain batch 15/32 - 233.8ms/batch - loss: 1.14522 - diff: 18.32mlTrain batch 16/32 - 234.3ms/batch - loss: 1.13911 - diff: 18.23mlTrain batch 17/32 - 233.6ms/batch - loss: 1.12863 - diff: 18.06mlTrain batch 18/32 - 234.5ms/batch - loss: 1.13452 - diff: 18.15mlTrain batch 19/32 - 233.4ms/batch - loss: 1.11137 - diff: 17.78mlTrain batch 20/32 - 233.9ms/batch - loss: 1.08851 - diff: 17.42mlTrain batch 21/32 - 235.6ms/batch - loss: 1.13229 - diff: 18.12mlTrain batch 22/32 - 233.7ms/batch - loss: 1.13118 - diff: 18.10mlTrain batch 23/32 - 233.6ms/batch - loss: 1.12892 - diff: 18.06mlTrain batch 24/32 - 234.0ms/batch - loss: 1.12386 - diff: 17.98mlTrain batch 25/32 - 247.4ms/batch - loss: 1.13477 - diff: 18.16mlTrain batch 26/32 - 233.9ms/batch - loss: 1.12221 - diff: 17.96mlTrain batch 27/32 - 234.4ms/batch - loss: 1.11472 - diff: 17.84mlTrain batch 28/32 - 233.7ms/batch - loss: 1.12059 - diff: 17.93mlTrain batch 29/32 - 233.6ms/batch - loss: 1.13354 - diff: 18.14mlTrain batch 30/32 - 233.6ms/batch - loss: 1.13536 - diff: 18.17mlTrain batch 31/32 - 234.4ms/batch - loss: 1.13952 - diff: 18.23mlTrain batch 32/32 - 85.8ms/batch - loss: 1.15693 - diff: 18.19mlTrain batch 32/32 - 17.3s 85.8ms/batch - loss: 1.15693 - diff: 18.19ml
Test 1.5s: val_loss: 1.87442 - diff: 28.72ml

Epoch 91: current best loss = 1.01540, at epoch 88
Train batch 1/32 - 248.6ms/batch - loss: 0.87578 - diff: 14.01mlTrain batch 2/32 - 238.1ms/batch - loss: 0.76003 - diff: 12.16mlTrain batch 3/32 - 233.7ms/batch - loss: 0.88712 - diff: 14.19mlTrain batch 4/32 - 238.1ms/batch - loss: 0.90255 - diff: 14.44mlTrain batch 5/32 - 233.8ms/batch - loss: 1.06053 - diff: 16.97mlTrain batch 6/32 - 235.2ms/batch - loss: 1.02958 - diff: 16.47mlTrain batch 7/32 - 233.6ms/batch - loss: 1.08217 - diff: 17.31mlTrain batch 8/32 - 234.8ms/batch - loss: 1.05621 - diff: 16.90mlTrain batch 9/32 - 233.5ms/batch - loss: 1.04075 - diff: 16.65mlTrain batch 10/32 - 234.3ms/batch - loss: 1.05662 - diff: 16.91mlTrain batch 11/32 - 233.7ms/batch - loss: 1.19827 - diff: 19.17mlTrain batch 12/32 - 233.9ms/batch - loss: 1.14990 - diff: 18.40mlTrain batch 13/32 - 233.8ms/batch - loss: 1.13395 - diff: 18.14mlTrain batch 14/32 - 233.6ms/batch - loss: 1.12309 - diff: 17.97mlTrain batch 15/32 - 243.3ms/batch - loss: 1.08692 - diff: 17.39mlTrain batch 16/32 - 234.5ms/batch - loss: 1.08380 - diff: 17.34mlTrain batch 17/32 - 233.7ms/batch - loss: 1.10891 - diff: 17.74mlTrain batch 18/32 - 244.7ms/batch - loss: 1.10953 - diff: 17.75mlTrain batch 19/32 - 234.7ms/batch - loss: 1.11023 - diff: 17.76mlTrain batch 20/32 - 233.9ms/batch - loss: 1.12405 - diff: 17.98mlTrain batch 21/32 - 233.8ms/batch - loss: 1.13059 - diff: 18.09mlTrain batch 22/32 - 233.4ms/batch - loss: 1.11824 - diff: 17.89mlTrain batch 23/32 - 233.6ms/batch - loss: 1.11535 - diff: 17.85mlTrain batch 24/32 - 238.6ms/batch - loss: 1.11743 - diff: 17.88mlTrain batch 25/32 - 233.6ms/batch - loss: 1.13142 - diff: 18.10mlTrain batch 26/32 - 233.1ms/batch - loss: 1.12349 - diff: 17.98mlTrain batch 27/32 - 233.7ms/batch - loss: 1.13004 - diff: 18.08mlTrain batch 28/32 - 234.5ms/batch - loss: 1.12255 - diff: 17.96mlTrain batch 29/32 - 233.6ms/batch - loss: 1.11292 - diff: 17.81mlTrain batch 30/32 - 232.9ms/batch - loss: 1.11817 - diff: 17.89mlTrain batch 31/32 - 233.5ms/batch - loss: 1.12874 - diff: 18.06mlTrain batch 32/32 - 76.6ms/batch - loss: 1.18087 - diff: 18.16mlTrain batch 32/32 - 18.2s 76.6ms/batch - loss: 1.18087 - diff: 18.16ml
Test 1.5s: val_loss: 1.19583 - diff: 18.68ml

Epoch 92: current best loss = 1.01540, at epoch 88
Train batch 1/32 - 249.2ms/batch - loss: 0.79248 - diff: 12.68mlTrain batch 2/32 - 234.4ms/batch - loss: 1.16222 - diff: 18.60mlTrain batch 3/32 - 233.7ms/batch - loss: 1.11236 - diff: 17.80mlTrain batch 4/32 - 233.4ms/batch - loss: 1.16308 - diff: 18.61mlTrain batch 5/32 - 233.4ms/batch - loss: 1.13672 - diff: 18.19mlTrain batch 6/32 - 234.1ms/batch - loss: 1.17971 - diff: 18.88mlTrain batch 7/32 - 233.6ms/batch - loss: 1.11764 - diff: 17.88mlTrain batch 8/32 - 238.2ms/batch - loss: 1.06980 - diff: 17.12mlTrain batch 9/32 - 233.7ms/batch - loss: 1.18881 - diff: 19.02mlTrain batch 10/32 - 234.0ms/batch - loss: 1.26141 - diff: 20.18mlTrain batch 11/32 - 233.8ms/batch - loss: 1.23630 - diff: 19.78mlTrain batch 12/32 - 239.6ms/batch - loss: 1.20487 - diff: 19.28mlTrain batch 13/32 - 233.4ms/batch - loss: 1.21656 - diff: 19.46mlTrain batch 14/32 - 234.0ms/batch - loss: 1.21079 - diff: 19.37mlTrain batch 15/32 - 233.8ms/batch - loss: 1.25758 - diff: 20.12mlTrain batch 16/32 - 233.8ms/batch - loss: 1.24519 - diff: 19.92mlTrain batch 17/32 - 234.1ms/batch - loss: 1.24880 - diff: 19.98mlTrain batch 18/32 - 234.0ms/batch - loss: 1.23112 - diff: 19.70mlTrain batch 19/32 - 233.5ms/batch - loss: 1.22386 - diff: 19.58mlTrain batch 20/32 - 233.9ms/batch - loss: 1.21188 - diff: 19.39mlTrain batch 21/32 - 233.9ms/batch - loss: 1.21745 - diff: 19.48mlTrain batch 22/32 - 234.5ms/batch - loss: 1.24961 - diff: 19.99mlTrain batch 23/32 - 233.8ms/batch - loss: 1.24518 - diff: 19.92mlTrain batch 24/32 - 238.4ms/batch - loss: 1.23505 - diff: 19.76mlTrain batch 25/32 - 233.6ms/batch - loss: 1.21557 - diff: 19.45mlTrain batch 26/32 - 235.0ms/batch - loss: 1.20960 - diff: 19.35mlTrain batch 27/32 - 233.7ms/batch - loss: 1.18955 - diff: 19.03mlTrain batch 28/32 - 240.0ms/batch - loss: 1.19011 - diff: 19.04mlTrain batch 29/32 - 238.1ms/batch - loss: 1.18481 - diff: 18.96mlTrain batch 30/32 - 235.9ms/batch - loss: 1.16872 - diff: 18.70mlTrain batch 31/32 - 233.6ms/batch - loss: 1.16188 - diff: 18.59mlTrain batch 32/32 - 89.6ms/batch - loss: 1.17824 - diff: 18.54mlTrain batch 32/32 - 16.6s 89.6ms/batch - loss: 1.17824 - diff: 18.54ml
Test 1.6s: val_loss: 1.08378 - diff: 16.52ml

Epoch 93: current best loss = 1.01540, at epoch 88
Train batch 1/32 - 233.7ms/batch - loss: 1.26999 - diff: 20.32mlTrain batch 2/32 - 232.8ms/batch - loss: 1.11284 - diff: 17.81mlTrain batch 3/32 - 233.7ms/batch - loss: 1.30644 - diff: 20.90mlTrain batch 4/32 - 233.8ms/batch - loss: 1.16979 - diff: 18.72mlTrain batch 5/32 - 233.7ms/batch - loss: 1.25084 - diff: 20.01mlTrain batch 6/32 - 233.9ms/batch - loss: 1.31345 - diff: 21.02mlTrain batch 7/32 - 233.7ms/batch - loss: 1.25806 - diff: 20.13mlTrain batch 8/32 - 234.0ms/batch - loss: 1.20484 - diff: 19.28mlTrain batch 9/32 - 236.3ms/batch - loss: 1.15797 - diff: 18.53mlTrain batch 10/32 - 233.8ms/batch - loss: 1.13805 - diff: 18.21mlTrain batch 11/32 - 233.8ms/batch - loss: 1.13088 - diff: 18.09mlTrain batch 12/32 - 233.8ms/batch - loss: 1.10136 - diff: 17.62mlTrain batch 13/32 - 233.6ms/batch - loss: 1.10527 - diff: 17.68mlTrain batch 14/32 - 234.7ms/batch - loss: 1.06389 - diff: 17.02mlTrain batch 15/32 - 233.7ms/batch - loss: 1.07034 - diff: 17.13mlTrain batch 16/32 - 233.7ms/batch - loss: 1.09154 - diff: 17.46mlTrain batch 17/32 - 233.7ms/batch - loss: 1.06949 - diff: 17.11mlTrain batch 18/32 - 233.9ms/batch - loss: 1.07225 - diff: 17.16mlTrain batch 19/32 - 234.1ms/batch - loss: 1.09125 - diff: 17.46mlTrain batch 20/32 - 233.9ms/batch - loss: 1.11056 - diff: 17.77mlTrain batch 21/32 - 233.9ms/batch - loss: 1.11541 - diff: 17.85mlTrain batch 22/32 - 234.1ms/batch - loss: 1.11075 - diff: 17.77mlTrain batch 23/32 - 233.7ms/batch - loss: 1.11919 - diff: 17.91mlTrain batch 24/32 - 234.9ms/batch - loss: 1.11282 - diff: 17.81mlTrain batch 25/32 - 233.8ms/batch - loss: 1.10424 - diff: 17.67mlTrain batch 26/32 - 250.1ms/batch - loss: 1.10166 - diff: 17.63mlTrain batch 27/32 - 233.6ms/batch - loss: 1.13820 - diff: 18.21mlTrain batch 28/32 - 235.5ms/batch - loss: 1.14961 - diff: 18.39mlTrain batch 29/32 - 234.1ms/batch - loss: 1.15422 - diff: 18.47mlTrain batch 30/32 - 233.4ms/batch - loss: 1.14488 - diff: 18.32mlTrain batch 31/32 - 233.8ms/batch - loss: 1.14878 - diff: 18.38mlTrain batch 32/32 - 76.7ms/batch - loss: 1.17930 - diff: 18.39mlTrain batch 32/32 - 16.9s 76.7ms/batch - loss: 1.17930 - diff: 18.39ml
Test 1.7s: val_loss: 1.47663 - diff: 22.47ml

Epoch 94: current best loss = 1.01540, at epoch 88
Train batch 1/32 - 243.8ms/batch - loss: 0.93282 - diff: 14.93mlTrain batch 2/32 - 238.2ms/batch - loss: 0.91765 - diff: 14.68mlTrain batch 3/32 - 233.7ms/batch - loss: 1.43031 - diff: 22.88mlTrain batch 4/32 - 233.2ms/batch - loss: 1.30683 - diff: 20.91mlTrain batch 5/32 - 233.7ms/batch - loss: 1.18452 - diff: 18.95mlTrain batch 6/32 - 234.3ms/batch - loss: 1.20259 - diff: 19.24mlTrain batch 7/32 - 233.5ms/batch - loss: 1.21404 - diff: 19.42mlTrain batch 8/32 - 233.9ms/batch - loss: 1.13805 - diff: 18.21mlTrain batch 9/32 - 233.9ms/batch - loss: 1.20459 - diff: 19.27mlTrain batch 10/32 - 233.8ms/batch - loss: 1.14564 - diff: 18.33mlTrain batch 11/32 - 234.0ms/batch - loss: 1.25568 - diff: 20.09mlTrain batch 12/32 - 233.7ms/batch - loss: 1.22428 - diff: 19.59mlTrain batch 13/32 - 234.2ms/batch - loss: 1.19175 - diff: 19.07mlTrain batch 14/32 - 233.5ms/batch - loss: 1.17973 - diff: 18.88mlTrain batch 15/32 - 234.0ms/batch - loss: 1.21734 - diff: 19.48mlTrain batch 16/32 - 234.2ms/batch - loss: 1.20620 - diff: 19.30mlTrain batch 17/32 - 233.7ms/batch - loss: 1.18645 - diff: 18.98mlTrain batch 18/32 - 237.1ms/batch - loss: 1.18264 - diff: 18.92mlTrain batch 19/32 - 234.2ms/batch - loss: 1.16492 - diff: 18.64mlTrain batch 20/32 - 233.5ms/batch - loss: 1.18194 - diff: 18.91mlTrain batch 21/32 - 233.9ms/batch - loss: 1.17601 - diff: 18.82mlTrain batch 22/32 - 234.0ms/batch - loss: 1.18032 - diff: 18.89mlTrain batch 23/32 - 233.8ms/batch - loss: 1.16912 - diff: 18.71mlTrain batch 24/32 - 233.8ms/batch - loss: 1.17605 - diff: 18.82mlTrain batch 25/32 - 234.2ms/batch - loss: 1.16477 - diff: 18.64mlTrain batch 26/32 - 233.8ms/batch - loss: 1.15158 - diff: 18.43mlTrain batch 27/32 - 233.9ms/batch - loss: 1.13298 - diff: 18.13mlTrain batch 28/32 - 234.0ms/batch - loss: 1.12622 - diff: 18.02mlTrain batch 29/32 - 233.6ms/batch - loss: 1.12099 - diff: 17.94mlTrain batch 30/32 - 239.8ms/batch - loss: 1.10674 - diff: 17.71mlTrain batch 31/32 - 234.0ms/batch - loss: 1.11416 - diff: 17.83mlTrain batch 32/32 - 76.5ms/batch - loss: 1.16728 - diff: 17.93mlTrain batch 32/32 - 17.5s 76.5ms/batch - loss: 1.16728 - diff: 17.93ml
Test 1.5s: val_loss: 1.04516 - diff: 15.69ml

Epoch 95: current best loss = 1.01540, at epoch 88
Train batch 1/32 - 237.3ms/batch - loss: 1.40453 - diff: 22.47mlTrain batch 2/32 - 233.8ms/batch - loss: 1.99678 - diff: 31.95mlTrain batch 3/32 - 233.6ms/batch - loss: 1.62070 - diff: 25.93mlTrain batch 4/32 - 234.1ms/batch - loss: 1.44016 - diff: 23.04mlTrain batch 5/32 - 233.8ms/batch - loss: 1.30865 - diff: 20.94mlTrain batch 6/32 - 240.1ms/batch - loss: 1.25430 - diff: 20.07mlTrain batch 7/32 - 234.0ms/batch - loss: 1.18278 - diff: 18.92mlTrain batch 8/32 - 234.2ms/batch - loss: 1.13367 - diff: 18.14mlTrain batch 9/32 - 233.4ms/batch - loss: 1.10484 - diff: 17.68mlTrain batch 10/32 - 234.2ms/batch - loss: 1.06644 - diff: 17.06mlTrain batch 11/32 - 233.7ms/batch - loss: 1.08621 - diff: 17.38mlTrain batch 12/32 - 234.2ms/batch - loss: 1.05645 - diff: 16.90mlTrain batch 13/32 - 233.7ms/batch - loss: 1.09315 - diff: 17.49mlTrain batch 14/32 - 238.4ms/batch - loss: 1.07846 - diff: 17.26mlTrain batch 15/32 - 233.9ms/batch - loss: 1.06515 - diff: 17.04mlTrain batch 16/32 - 244.8ms/batch - loss: 1.08311 - diff: 17.33mlTrain batch 17/32 - 234.0ms/batch - loss: 1.07077 - diff: 17.13mlTrain batch 18/32 - 233.8ms/batch - loss: 1.04820 - diff: 16.77mlTrain batch 19/32 - 233.8ms/batch - loss: 1.05475 - diff: 16.88mlTrain batch 20/32 - 239.9ms/batch - loss: 1.02816 - diff: 16.45mlTrain batch 21/32 - 234.0ms/batch - loss: 1.01655 - diff: 16.26mlTrain batch 22/32 - 238.6ms/batch - loss: 0.99826 - diff: 15.97mlTrain batch 23/32 - 233.8ms/batch - loss: 1.04468 - diff: 16.71mlTrain batch 24/32 - 233.8ms/batch - loss: 1.05225 - diff: 16.84mlTrain batch 25/32 - 249.7ms/batch - loss: 1.03777 - diff: 16.60mlTrain batch 26/32 - 234.4ms/batch - loss: 1.05911 - diff: 16.95mlTrain batch 27/32 - 234.6ms/batch - loss: 1.04835 - diff: 16.77mlTrain batch 28/32 - 233.7ms/batch - loss: 1.08067 - diff: 17.29mlTrain batch 29/32 - 233.9ms/batch - loss: 1.07790 - diff: 17.25mlTrain batch 30/32 - 233.8ms/batch - loss: 1.06889 - diff: 17.10mlTrain batch 31/32 - 233.7ms/batch - loss: 1.06763 - diff: 17.08mlTrain batch 32/32 - 76.6ms/batch - loss: 1.09496 - diff: 17.09mlTrain batch 32/32 - 16.6s 76.6ms/batch - loss: 1.09496 - diff: 17.09ml
Test 1.5s: val_loss: 1.10645 - diff: 16.96ml

Epoch 96: current best loss = 1.01540, at epoch 88
Train batch 1/32 - 233.8ms/batch - loss: 0.70002 - diff: 11.20mlTrain batch 2/32 - 238.1ms/batch - loss: 0.85825 - diff: 13.73mlTrain batch 3/32 - 233.6ms/batch - loss: 0.87200 - diff: 13.95mlTrain batch 4/32 - 234.4ms/batch - loss: 0.85643 - diff: 13.70mlTrain batch 5/32 - 233.5ms/batch - loss: 0.89935 - diff: 14.39mlTrain batch 6/32 - 234.6ms/batch - loss: 0.94209 - diff: 15.07mlTrain batch 7/32 - 237.2ms/batch - loss: 0.98361 - diff: 15.74mlTrain batch 8/32 - 233.7ms/batch - loss: 0.99443 - diff: 15.91mlTrain batch 9/32 - 233.4ms/batch - loss: 1.02801 - diff: 16.45mlTrain batch 10/32 - 234.3ms/batch - loss: 0.98903 - diff: 15.82mlTrain batch 11/32 - 233.5ms/batch - loss: 0.98674 - diff: 15.79mlTrain batch 12/32 - 234.3ms/batch - loss: 1.02554 - diff: 16.41mlTrain batch 13/32 - 233.8ms/batch - loss: 1.02090 - diff: 16.33mlTrain batch 14/32 - 234.2ms/batch - loss: 1.02687 - diff: 16.43mlTrain batch 15/32 - 233.8ms/batch - loss: 1.00760 - diff: 16.12mlTrain batch 16/32 - 238.2ms/batch - loss: 1.03361 - diff: 16.54mlTrain batch 17/32 - 233.7ms/batch - loss: 1.01733 - diff: 16.28mlTrain batch 18/32 - 234.3ms/batch - loss: 1.06856 - diff: 17.10mlTrain batch 19/32 - 233.5ms/batch - loss: 1.05583 - diff: 16.89mlTrain batch 20/32 - 234.4ms/batch - loss: 1.03645 - diff: 16.58mlTrain batch 21/32 - 233.8ms/batch - loss: 1.04057 - diff: 16.65mlTrain batch 22/32 - 234.4ms/batch - loss: 1.03564 - diff: 16.57mlTrain batch 23/32 - 233.7ms/batch - loss: 1.04238 - diff: 16.68mlTrain batch 24/32 - 243.4ms/batch - loss: 1.03849 - diff: 16.62mlTrain batch 25/32 - 233.6ms/batch - loss: 1.09702 - diff: 17.55mlTrain batch 26/32 - 234.0ms/batch - loss: 1.08373 - diff: 17.34mlTrain batch 27/32 - 233.6ms/batch - loss: 1.09091 - diff: 17.45mlTrain batch 28/32 - 234.8ms/batch - loss: 1.10255 - diff: 17.64mlTrain batch 29/32 - 233.6ms/batch - loss: 1.12376 - diff: 17.98mlTrain batch 30/32 - 234.2ms/batch - loss: 1.12957 - diff: 18.07mlTrain batch 31/32 - 233.6ms/batch - loss: 1.12436 - diff: 17.99mlTrain batch 32/32 - 76.7ms/batch - loss: 1.14289 - diff: 17.96mlTrain batch 32/32 - 17.9s 76.7ms/batch - loss: 1.14289 - diff: 17.96ml
Test 1.5s: val_loss: 2.03283 - diff: 30.65ml

Epoch 97: current best loss = 1.01540, at epoch 88
Train batch 1/32 - 233.7ms/batch - loss: 1.05592 - diff: 16.89mlTrain batch 2/32 - 234.1ms/batch - loss: 1.02149 - diff: 16.34mlTrain batch 3/32 - 233.7ms/batch - loss: 1.06380 - diff: 17.02mlTrain batch 4/32 - 234.2ms/batch - loss: 1.19509 - diff: 19.12mlTrain batch 5/32 - 233.5ms/batch - loss: 1.15860 - diff: 18.54mlTrain batch 6/32 - 234.3ms/batch - loss: 1.17812 - diff: 18.85mlTrain batch 7/32 - 233.7ms/batch - loss: 1.17539 - diff: 18.81mlTrain batch 8/32 - 234.3ms/batch - loss: 1.24017 - diff: 19.84mlTrain batch 9/32 - 233.6ms/batch - loss: 1.25498 - diff: 20.08mlTrain batch 10/32 - 234.9ms/batch - loss: 1.31563 - diff: 21.05mlTrain batch 11/32 - 233.8ms/batch - loss: 1.30434 - diff: 20.87mlTrain batch 12/32 - 234.1ms/batch - loss: 1.30833 - diff: 20.93mlTrain batch 13/32 - 233.6ms/batch - loss: 1.30761 - diff: 20.92mlTrain batch 14/32 - 238.8ms/batch - loss: 1.29691 - diff: 20.75mlTrain batch 15/32 - 233.8ms/batch - loss: 1.26325 - diff: 20.21mlTrain batch 16/32 - 234.8ms/batch - loss: 1.24817 - diff: 19.97mlTrain batch 17/32 - 234.1ms/batch - loss: 1.24428 - diff: 19.91mlTrain batch 18/32 - 233.1ms/batch - loss: 1.24581 - diff: 19.93mlTrain batch 19/32 - 234.1ms/batch - loss: 1.20654 - diff: 19.30mlTrain batch 20/32 - 234.4ms/batch - loss: 1.20040 - diff: 19.21mlTrain batch 21/32 - 234.0ms/batch - loss: 1.21103 - diff: 19.38mlTrain batch 22/32 - 237.5ms/batch - loss: 1.19135 - diff: 19.06mlTrain batch 23/32 - 234.5ms/batch - loss: 1.17473 - diff: 18.80mlTrain batch 24/32 - 232.9ms/batch - loss: 1.16903 - diff: 18.70mlTrain batch 25/32 - 239.5ms/batch - loss: 1.19974 - diff: 19.20mlTrain batch 26/32 - 234.6ms/batch - loss: 1.17679 - diff: 18.83mlTrain batch 27/32 - 233.9ms/batch - loss: 1.17273 - diff: 18.76mlTrain batch 28/32 - 244.8ms/batch - loss: 1.17166 - diff: 18.75mlTrain batch 29/32 - 234.1ms/batch - loss: 1.15852 - diff: 18.54mlTrain batch 30/32 - 233.8ms/batch - loss: 1.14369 - diff: 18.30mlTrain batch 31/32 - 234.0ms/batch - loss: 1.13502 - diff: 18.16mlTrain batch 32/32 - 76.6ms/batch - loss: 1.22405 - diff: 18.41mlTrain batch 32/32 - 16.3s 76.6ms/batch - loss: 1.22405 - diff: 18.41ml
Test 1.5s: val_loss: 1.89014 - diff: 28.98ml

Epoch 98: current best loss = 1.01540, at epoch 88
Train batch 1/32 - 233.8ms/batch - loss: 1.20439 - diff: 19.27mlTrain batch 2/32 - 234.3ms/batch - loss: 1.25999 - diff: 20.16mlTrain batch 3/32 - 236.8ms/batch - loss: 1.11459 - diff: 17.83mlTrain batch 4/32 - 234.7ms/batch - loss: 1.01860 - diff: 16.30mlTrain batch 5/32 - 235.3ms/batch - loss: 1.06503 - diff: 17.04mlTrain batch 6/32 - 234.0ms/batch - loss: 1.05398 - diff: 16.86mlTrain batch 7/32 - 233.6ms/batch - loss: 1.13721 - diff: 18.20mlTrain batch 8/32 - 234.4ms/batch - loss: 1.20790 - diff: 19.33mlTrain batch 9/32 - 233.7ms/batch - loss: 1.17273 - diff: 18.76mlTrain batch 10/32 - 247.4ms/batch - loss: 1.19979 - diff: 19.20mlTrain batch 11/32 - 234.0ms/batch - loss: 1.19323 - diff: 19.09mlTrain batch 12/32 - 250.9ms/batch - loss: 1.19102 - diff: 19.06mlTrain batch 13/32 - 233.7ms/batch - loss: 1.16908 - diff: 18.71mlTrain batch 14/32 - 235.0ms/batch - loss: 1.18318 - diff: 18.93mlTrain batch 15/32 - 239.2ms/batch - loss: 1.20067 - diff: 19.21mlTrain batch 16/32 - 251.0ms/batch - loss: 1.17562 - diff: 18.81mlTrain batch 17/32 - 234.0ms/batch - loss: 1.16644 - diff: 18.66mlTrain batch 18/32 - 234.6ms/batch - loss: 1.16136 - diff: 18.58mlTrain batch 19/32 - 233.7ms/batch - loss: 1.20340 - diff: 19.25mlTrain batch 20/32 - 246.0ms/batch - loss: 1.20166 - diff: 19.23mlTrain batch 21/32 - 233.9ms/batch - loss: 1.18622 - diff: 18.98mlTrain batch 22/32 - 259.6ms/batch - loss: 1.16601 - diff: 18.66mlTrain batch 23/32 - 234.1ms/batch - loss: 1.15649 - diff: 18.50mlTrain batch 24/32 - 234.3ms/batch - loss: 1.15379 - diff: 18.46mlTrain batch 25/32 - 233.6ms/batch - loss: 1.14731 - diff: 18.36mlTrain batch 26/32 - 258.2ms/batch - loss: 1.14692 - diff: 18.35mlTrain batch 27/32 - 233.9ms/batch - loss: 1.12530 - diff: 18.00mlTrain batch 28/32 - 248.1ms/batch - loss: 1.11472 - diff: 17.84mlTrain batch 29/32 - 233.7ms/batch - loss: 1.09950 - diff: 17.59mlTrain batch 30/32 - 234.1ms/batch - loss: 1.09302 - diff: 17.49mlTrain batch 31/32 - 233.9ms/batch - loss: 1.08601 - diff: 17.38mlTrain batch 32/32 - 86.0ms/batch - loss: 1.11292 - diff: 17.38mlTrain batch 32/32 - 18.0s 86.0ms/batch - loss: 1.11292 - diff: 17.38ml
Test 1.4s: val_loss: 1.13243 - diff: 17.52ml

Epoch 99: current best loss = 1.01540, at epoch 88
Train batch 1/32 - 233.8ms/batch - loss: 0.96920 - diff: 15.51mlTrain batch 2/32 - 238.0ms/batch - loss: 1.15193 - diff: 18.43mlTrain batch 3/32 - 233.9ms/batch - loss: 1.07785 - diff: 17.25mlTrain batch 4/32 - 237.7ms/batch - loss: 1.03783 - diff: 16.61mlTrain batch 5/32 - 234.0ms/batch - loss: 1.03769 - diff: 16.60mlTrain batch 6/32 - 234.5ms/batch - loss: 1.09612 - diff: 17.54mlTrain batch 7/32 - 233.9ms/batch - loss: 1.08296 - diff: 17.33mlTrain batch 8/32 - 253.4ms/batch - loss: 1.06848 - diff: 17.10mlTrain batch 9/32 - 233.8ms/batch - loss: 1.07306 - diff: 17.17mlTrain batch 10/32 - 239.3ms/batch - loss: 1.06516 - diff: 17.04mlTrain batch 11/32 - 233.9ms/batch - loss: 1.18641 - diff: 18.98mlTrain batch 12/32 - 234.1ms/batch - loss: 1.24725 - diff: 19.96mlTrain batch 13/32 - 233.8ms/batch - loss: 1.21944 - diff: 19.51mlTrain batch 14/32 - 238.6ms/batch - loss: 1.21354 - diff: 19.42mlTrain batch 15/32 - 233.6ms/batch - loss: 1.19554 - diff: 19.13mlTrain batch 16/32 - 234.4ms/batch - loss: 1.18489 - diff: 18.96mlTrain batch 17/32 - 235.1ms/batch - loss: 1.18495 - diff: 18.96mlTrain batch 18/32 - 233.5ms/batch - loss: 1.18013 - diff: 18.88mlTrain batch 19/32 - 234.1ms/batch - loss: 1.17811 - diff: 18.85mlTrain batch 20/32 - 234.3ms/batch - loss: 1.17679 - diff: 18.83mlTrain batch 21/32 - 233.7ms/batch - loss: 1.16894 - diff: 18.70mlTrain batch 22/32 - 234.4ms/batch - loss: 1.16780 - diff: 18.68mlTrain batch 23/32 - 233.9ms/batch - loss: 1.19089 - diff: 19.05mlTrain batch 24/32 - 234.2ms/batch - loss: 1.19239 - diff: 19.08mlTrain batch 25/32 - 233.8ms/batch - loss: 1.17782 - diff: 18.85mlTrain batch 26/32 - 234.0ms/batch - loss: 1.17145 - diff: 18.74mlTrain batch 27/32 - 236.8ms/batch - loss: 1.18193 - diff: 18.91mlTrain batch 28/32 - 235.8ms/batch - loss: 1.16975 - diff: 18.72mlTrain batch 29/32 - 233.8ms/batch - loss: 1.15863 - diff: 18.54mlTrain batch 30/32 - 234.0ms/batch - loss: 1.15876 - diff: 18.54mlTrain batch 31/32 - 233.7ms/batch - loss: 1.15212 - diff: 18.43mlTrain batch 32/32 - 76.6ms/batch - loss: 1.16341 - diff: 18.37mlTrain batch 32/32 - 17.5s 76.6ms/batch - loss: 1.16341 - diff: 18.37ml
Test 1.5s: val_loss: 1.14587 - diff: 17.27ml
Epoch   100: reducing learning rate of group 0 to 2.5000e-04.

Epoch 100: current best loss = 1.01540, at epoch 88
Train batch 1/32 - 234.2ms/batch - loss: 0.92575 - diff: 14.81mlTrain batch 2/32 - 238.7ms/batch - loss: 0.76010 - diff: 12.16mlTrain batch 3/32 - 234.0ms/batch - loss: 0.70521 - diff: 11.28mlTrain batch 4/32 - 234.4ms/batch - loss: 0.67939 - diff: 10.87mlTrain batch 5/32 - 233.9ms/batch - loss: 0.75489 - diff: 12.08mlTrain batch 6/32 - 238.3ms/batch - loss: 0.83628 - diff: 13.38mlTrain batch 7/32 - 233.8ms/batch - loss: 0.92516 - diff: 14.80mlTrain batch 8/32 - 234.1ms/batch - loss: 1.02618 - diff: 16.42mlTrain batch 9/32 - 234.1ms/batch - loss: 0.99211 - diff: 15.87mlTrain batch 10/32 - 234.0ms/batch - loss: 1.05896 - diff: 16.94mlTrain batch 11/32 - 233.8ms/batch - loss: 1.08559 - diff: 17.37mlTrain batch 12/32 - 234.1ms/batch - loss: 1.07489 - diff: 17.20mlTrain batch 13/32 - 233.6ms/batch - loss: 1.06536 - diff: 17.05mlTrain batch 14/32 - 234.6ms/batch - loss: 1.05573 - diff: 16.89mlTrain batch 15/32 - 233.7ms/batch - loss: 1.03705 - diff: 16.59mlTrain batch 16/32 - 237.2ms/batch - loss: 1.01583 - diff: 16.25mlTrain batch 17/32 - 233.8ms/batch - loss: 0.99789 - diff: 15.97mlTrain batch 18/32 - 237.9ms/batch - loss: 0.99905 - diff: 15.98mlTrain batch 19/32 - 245.5ms/batch - loss: 0.99084 - diff: 15.85mlTrain batch 20/32 - 234.3ms/batch - loss: 0.99398 - diff: 15.90mlTrain batch 21/32 - 233.5ms/batch - loss: 1.01872 - diff: 16.30mlTrain batch 22/32 - 237.0ms/batch - loss: 1.03831 - diff: 16.61mlTrain batch 23/32 - 233.7ms/batch - loss: 1.03869 - diff: 16.62mlTrain batch 24/32 - 234.4ms/batch - loss: 1.02538 - diff: 16.41mlTrain batch 25/32 - 234.5ms/batch - loss: 1.02650 - diff: 16.42mlTrain batch 26/32 - 236.4ms/batch - loss: 1.01931 - diff: 16.31mlTrain batch 27/32 - 234.6ms/batch - loss: 1.02182 - diff: 16.35mlTrain batch 28/32 - 234.4ms/batch - loss: 1.03142 - diff: 16.50mlTrain batch 29/32 - 234.8ms/batch - loss: 1.02211 - diff: 16.35mlTrain batch 30/32 - 237.5ms/batch - loss: 1.01996 - diff: 16.32mlTrain batch 31/32 - 234.6ms/batch - loss: 1.00502 - diff: 16.08mlTrain batch 32/32 - 83.7ms/batch - loss: 1.02361 - diff: 16.06mlTrain batch 32/32 - 17.4s 83.7ms/batch - loss: 1.02361 - diff: 16.06ml
Test 1.6s: val_loss: 1.17546 - diff: 18.19ml

Epoch 101: current best loss = 1.01540, at epoch 88
Train batch 1/32 - 233.9ms/batch - loss: 0.89891 - diff: 14.38mlTrain batch 2/32 - 240.6ms/batch - loss: 0.92985 - diff: 14.88mlTrain batch 3/32 - 233.7ms/batch - loss: 1.04821 - diff: 16.77mlTrain batch 4/32 - 234.2ms/batch - loss: 0.98920 - diff: 15.83mlTrain batch 5/32 - 236.1ms/batch - loss: 0.95124 - diff: 15.22mlTrain batch 6/32 - 234.6ms/batch - loss: 0.94191 - diff: 15.07mlTrain batch 7/32 - 233.8ms/batch - loss: 0.97108 - diff: 15.54mlTrain batch 8/32 - 243.1ms/batch - loss: 1.16724 - diff: 18.68mlTrain batch 9/32 - 234.4ms/batch - loss: 1.15910 - diff: 18.55mlTrain batch 10/32 - 233.7ms/batch - loss: 1.17283 - diff: 18.77mlTrain batch 11/32 - 234.6ms/batch - loss: 1.13581 - diff: 18.17mlTrain batch 12/32 - 234.3ms/batch - loss: 1.11605 - diff: 17.86mlTrain batch 13/32 - 234.3ms/batch - loss: 1.10298 - diff: 17.65mlTrain batch 14/32 - 234.0ms/batch - loss: 1.08818 - diff: 17.41mlTrain batch 15/32 - 236.0ms/batch - loss: 1.09765 - diff: 17.56mlTrain batch 16/32 - 234.1ms/batch - loss: 1.07502 - diff: 17.20mlTrain batch 17/32 - 234.2ms/batch - loss: 1.06097 - diff: 16.98mlTrain batch 18/32 - 233.9ms/batch - loss: 1.14775 - diff: 18.36mlTrain batch 19/32 - 234.0ms/batch - loss: 1.15502 - diff: 18.48mlTrain batch 20/32 - 233.7ms/batch - loss: 1.12717 - diff: 18.03mlTrain batch 21/32 - 233.9ms/batch - loss: 1.14097 - diff: 18.26mlTrain batch 22/32 - 233.5ms/batch - loss: 1.11552 - diff: 17.85mlTrain batch 23/32 - 233.9ms/batch - loss: 1.10753 - diff: 17.72mlTrain batch 24/32 - 237.3ms/batch - loss: 1.10656 - diff: 17.71mlTrain batch 25/32 - 234.5ms/batch - loss: 1.09314 - diff: 17.49mlTrain batch 26/32 - 234.4ms/batch - loss: 1.08604 - diff: 17.38mlTrain batch 27/32 - 234.0ms/batch - loss: 1.08198 - diff: 17.31mlTrain batch 28/32 - 234.3ms/batch - loss: 1.08494 - diff: 17.36mlTrain batch 29/32 - 233.8ms/batch - loss: 1.07418 - diff: 17.19mlTrain batch 30/32 - 234.2ms/batch - loss: 1.07411 - diff: 17.19mlTrain batch 31/32 - 233.6ms/batch - loss: 1.06080 - diff: 16.97mlTrain batch 32/32 - 79.8ms/batch - loss: 1.11082 - diff: 17.07mlTrain batch 32/32 - 16.9s 79.8ms/batch - loss: 1.11082 - diff: 17.07ml
Test 1.5s: val_loss: 0.97979 - diff: 15.40ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Systole_WideResNet50_0_Adam-0.001_MAE_DA3_best

Epoch 102: current best loss = 0.97979, at epoch 101
Train batch 1/32 - 243.1ms/batch - loss: 0.80121 - diff: 12.82mlTrain batch 2/32 - 234.2ms/batch - loss: 0.75742 - diff: 12.12mlTrain batch 3/32 - 233.9ms/batch - loss: 0.75618 - diff: 12.10mlTrain batch 4/32 - 237.6ms/batch - loss: 0.71480 - diff: 11.44mlTrain batch 5/32 - 234.0ms/batch - loss: 0.75537 - diff: 12.09mlTrain batch 6/32 - 236.4ms/batch - loss: 0.85374 - diff: 13.66mlTrain batch 7/32 - 233.8ms/batch - loss: 0.85595 - diff: 13.70mlTrain batch 8/32 - 238.6ms/batch - loss: 0.86904 - diff: 13.90mlTrain batch 9/32 - 234.1ms/batch - loss: 0.87820 - diff: 14.05mlTrain batch 10/32 - 234.2ms/batch - loss: 0.86778 - diff: 13.88mlTrain batch 11/32 - 234.1ms/batch - loss: 0.86008 - diff: 13.76mlTrain batch 12/32 - 234.3ms/batch - loss: 0.87092 - diff: 13.93mlTrain batch 13/32 - 233.8ms/batch - loss: 0.90074 - diff: 14.41mlTrain batch 14/32 - 238.2ms/batch - loss: 0.90216 - diff: 14.43mlTrain batch 15/32 - 233.9ms/batch - loss: 0.90024 - diff: 14.40mlTrain batch 16/32 - 234.7ms/batch - loss: 0.96742 - diff: 15.48mlTrain batch 17/32 - 234.0ms/batch - loss: 0.97159 - diff: 15.55mlTrain batch 18/32 - 234.1ms/batch - loss: 0.96326 - diff: 15.41mlTrain batch 19/32 - 233.7ms/batch - loss: 1.01063 - diff: 16.17mlTrain batch 20/32 - 236.3ms/batch - loss: 1.01441 - diff: 16.23mlTrain batch 21/32 - 234.0ms/batch - loss: 1.00963 - diff: 16.15mlTrain batch 22/32 - 237.2ms/batch - loss: 0.99544 - diff: 15.93mlTrain batch 23/32 - 234.3ms/batch - loss: 0.99409 - diff: 15.91mlTrain batch 24/32 - 234.9ms/batch - loss: 0.98997 - diff: 15.84mlTrain batch 25/32 - 233.9ms/batch - loss: 0.98706 - diff: 15.79mlTrain batch 26/32 - 234.1ms/batch - loss: 0.99450 - diff: 15.91mlTrain batch 27/32 - 234.1ms/batch - loss: 0.97871 - diff: 15.66mlTrain batch 28/32 - 234.0ms/batch - loss: 0.97247 - diff: 15.56mlTrain batch 29/32 - 234.3ms/batch - loss: 0.97278 - diff: 15.56mlTrain batch 30/32 - 238.2ms/batch - loss: 0.97238 - diff: 15.56mlTrain batch 31/32 - 234.0ms/batch - loss: 0.96256 - diff: 15.40mlTrain batch 32/32 - 82.7ms/batch - loss: 1.02261 - diff: 15.55mlTrain batch 32/32 - 17.6s 82.7ms/batch - loss: 1.02261 - diff: 15.55ml
Test 1.6s: val_loss: 1.06180 - diff: 16.47ml

Epoch 103: current best loss = 0.97979, at epoch 101
Train batch 1/32 - 250.4ms/batch - loss: 0.52435 - diff: 8.39mlTrain batch 2/32 - 234.2ms/batch - loss: 0.73652 - diff: 11.78mlTrain batch 3/32 - 233.9ms/batch - loss: 0.80960 - diff: 12.95mlTrain batch 4/32 - 233.4ms/batch - loss: 0.86719 - diff: 13.88mlTrain batch 5/32 - 234.1ms/batch - loss: 0.89025 - diff: 14.24mlTrain batch 6/32 - 233.8ms/batch - loss: 0.84712 - diff: 13.55mlTrain batch 7/32 - 233.9ms/batch - loss: 0.84444 - diff: 13.51mlTrain batch 8/32 - 234.7ms/batch - loss: 0.85323 - diff: 13.65mlTrain batch 9/32 - 233.9ms/batch - loss: 0.82913 - diff: 13.27mlTrain batch 10/32 - 234.3ms/batch - loss: 0.84891 - diff: 13.58mlTrain batch 11/32 - 234.1ms/batch - loss: 0.81881 - diff: 13.10mlTrain batch 12/32 - 233.9ms/batch - loss: 0.87230 - diff: 13.96mlTrain batch 13/32 - 233.9ms/batch - loss: 0.84971 - diff: 13.60mlTrain batch 14/32 - 234.1ms/batch - loss: 0.88294 - diff: 14.13mlTrain batch 15/32 - 233.6ms/batch - loss: 0.87417 - diff: 13.99mlTrain batch 16/32 - 234.0ms/batch - loss: 0.99043 - diff: 15.85mlTrain batch 17/32 - 234.0ms/batch - loss: 0.98379 - diff: 15.74mlTrain batch 18/32 - 233.6ms/batch - loss: 1.08000 - diff: 17.28mlTrain batch 19/32 - 233.8ms/batch - loss: 1.10495 - diff: 17.68mlTrain batch 20/32 - 234.3ms/batch - loss: 1.09360 - diff: 17.50mlTrain batch 21/32 - 234.0ms/batch - loss: 1.08188 - diff: 17.31mlTrain batch 22/32 - 234.2ms/batch - loss: 1.06996 - diff: 17.12mlTrain batch 23/32 - 234.2ms/batch - loss: 1.06716 - diff: 17.07mlTrain batch 24/32 - 238.1ms/batch - loss: 1.05944 - diff: 16.95mlTrain batch 25/32 - 233.8ms/batch - loss: 1.07487 - diff: 17.20mlTrain batch 26/32 - 233.9ms/batch - loss: 1.06476 - diff: 17.04mlTrain batch 27/32 - 234.0ms/batch - loss: 1.06777 - diff: 17.08mlTrain batch 28/32 - 233.6ms/batch - loss: 1.05619 - diff: 16.90mlTrain batch 29/32 - 233.7ms/batch - loss: 1.06977 - diff: 17.12mlTrain batch 30/32 - 234.4ms/batch - loss: 1.06149 - diff: 16.98mlTrain batch 31/32 - 233.5ms/batch - loss: 1.04953 - diff: 16.79mlTrain batch 32/32 - 76.8ms/batch - loss: 1.07470 - diff: 16.79mlTrain batch 32/32 - 17.2s 76.8ms/batch - loss: 1.07470 - diff: 16.79ml
Test 1.8s: val_loss: 1.15546 - diff: 17.78ml

Epoch 104: current best loss = 0.97979, at epoch 101
Train batch 1/32 - 242.4ms/batch - loss: 0.87906 - diff: 14.07mlTrain batch 2/32 - 234.5ms/batch - loss: 1.01495 - diff: 16.24mlTrain batch 3/32 - 236.4ms/batch - loss: 1.03200 - diff: 16.51mlTrain batch 4/32 - 234.3ms/batch - loss: 1.04368 - diff: 16.70mlTrain batch 5/32 - 233.9ms/batch - loss: 0.95714 - diff: 15.31mlTrain batch 6/32 - 233.7ms/batch - loss: 0.97267 - diff: 15.56mlTrain batch 7/32 - 234.0ms/batch - loss: 0.96408 - diff: 15.43mlTrain batch 8/32 - 233.8ms/batch - loss: 0.95055 - diff: 15.21mlTrain batch 9/32 - 233.7ms/batch - loss: 0.96391 - diff: 15.42mlTrain batch 10/32 - 233.8ms/batch - loss: 0.97132 - diff: 15.54mlTrain batch 11/32 - 233.8ms/batch - loss: 1.00327 - diff: 16.05mlTrain batch 12/32 - 233.9ms/batch - loss: 1.00149 - diff: 16.02mlTrain batch 13/32 - 234.0ms/batch - loss: 1.02517 - diff: 16.40mlTrain batch 14/32 - 233.9ms/batch - loss: 1.12428 - diff: 17.99mlTrain batch 15/32 - 234.4ms/batch - loss: 1.10789 - diff: 17.73mlTrain batch 16/32 - 233.9ms/batch - loss: 1.10158 - diff: 17.63mlTrain batch 17/32 - 234.1ms/batch - loss: 1.10252 - diff: 17.64mlTrain batch 18/32 - 233.8ms/batch - loss: 1.09409 - diff: 17.51mlTrain batch 19/32 - 233.9ms/batch - loss: 1.08822 - diff: 17.41mlTrain batch 20/32 - 234.2ms/batch - loss: 1.07851 - diff: 17.26mlTrain batch 21/32 - 233.8ms/batch - loss: 1.08515 - diff: 17.36mlTrain batch 22/32 - 233.9ms/batch - loss: 1.07448 - diff: 17.19mlTrain batch 23/32 - 234.3ms/batch - loss: 1.07655 - diff: 17.22mlTrain batch 24/32 - 233.6ms/batch - loss: 1.08250 - diff: 17.32mlTrain batch 25/32 - 233.8ms/batch - loss: 1.06683 - diff: 17.07mlTrain batch 26/32 - 234.2ms/batch - loss: 1.05984 - diff: 16.96mlTrain batch 27/32 - 234.2ms/batch - loss: 1.04631 - diff: 16.74mlTrain batch 28/32 - 234.1ms/batch - loss: 1.04303 - diff: 16.69mlTrain batch 29/32 - 233.6ms/batch - loss: 1.02905 - diff: 16.46mlTrain batch 30/32 - 234.0ms/batch - loss: 1.01509 - diff: 16.24mlTrain batch 31/32 - 233.6ms/batch - loss: 1.01640 - diff: 16.26mlTrain batch 32/32 - 76.3ms/batch - loss: 1.05026 - diff: 16.30mlTrain batch 32/32 - 16.3s 76.3ms/batch - loss: 1.05026 - diff: 16.30ml
Test 1.5s: val_loss: 0.99187 - diff: 15.14ml

Epoch 105: current best loss = 0.97979, at epoch 101
Train batch 1/32 - 233.5ms/batch - loss: 0.91658 - diff: 14.67mlTrain batch 2/32 - 233.6ms/batch - loss: 0.82022 - diff: 13.12mlTrain batch 3/32 - 234.0ms/batch - loss: 1.26092 - diff: 20.17mlTrain batch 4/32 - 233.9ms/batch - loss: 1.13484 - diff: 18.16mlTrain batch 5/32 - 234.3ms/batch - loss: 0.99717 - diff: 15.95mlTrain batch 6/32 - 234.1ms/batch - loss: 0.97843 - diff: 15.65mlTrain batch 7/32 - 243.2ms/batch - loss: 0.95278 - diff: 15.24mlTrain batch 8/32 - 235.2ms/batch - loss: 1.02744 - diff: 16.44mlTrain batch 9/32 - 233.7ms/batch - loss: 1.03681 - diff: 16.59mlTrain batch 10/32 - 233.9ms/batch - loss: 1.01475 - diff: 16.24mlTrain batch 11/32 - 233.7ms/batch - loss: 1.03688 - diff: 16.59mlTrain batch 12/32 - 233.8ms/batch - loss: 1.06234 - diff: 17.00mlTrain batch 13/32 - 238.1ms/batch - loss: 1.04337 - diff: 16.69mlTrain batch 14/32 - 233.9ms/batch - loss: 1.05420 - diff: 16.87mlTrain batch 15/32 - 234.6ms/batch - loss: 1.03279 - diff: 16.52mlTrain batch 16/32 - 234.0ms/batch - loss: 1.03088 - diff: 16.49mlTrain batch 17/32 - 234.0ms/batch - loss: 1.02643 - diff: 16.42mlTrain batch 18/32 - 233.8ms/batch - loss: 1.02156 - diff: 16.34mlTrain batch 19/32 - 234.0ms/batch - loss: 1.00793 - diff: 16.13mlTrain batch 20/32 - 234.1ms/batch - loss: 1.00285 - diff: 16.05mlTrain batch 21/32 - 233.4ms/batch - loss: 1.01341 - diff: 16.21mlTrain batch 22/32 - 238.0ms/batch - loss: 1.01455 - diff: 16.23mlTrain batch 23/32 - 233.9ms/batch - loss: 1.00175 - diff: 16.03mlTrain batch 24/32 - 234.4ms/batch - loss: 0.99603 - diff: 15.94mlTrain batch 25/32 - 235.6ms/batch - loss: 0.99531 - diff: 15.92mlTrain batch 26/32 - 234.4ms/batch - loss: 0.98518 - diff: 15.76mlTrain batch 27/32 - 233.8ms/batch - loss: 0.98591 - diff: 15.77mlTrain batch 28/32 - 234.4ms/batch - loss: 0.99147 - diff: 15.86mlTrain batch 29/32 - 233.8ms/batch - loss: 0.99661 - diff: 15.95mlTrain batch 30/32 - 234.7ms/batch - loss: 0.99078 - diff: 15.85mlTrain batch 31/32 - 233.7ms/batch - loss: 0.98461 - diff: 15.75mlTrain batch 32/32 - 76.5ms/batch - loss: 0.98748 - diff: 15.67mlTrain batch 32/32 - 16.7s 76.5ms/batch - loss: 0.98748 - diff: 15.67ml
Test 1.6s: val_loss: 1.51529 - diff: 23.29ml

Epoch 106: current best loss = 0.97979, at epoch 101
Train batch 1/32 - 233.9ms/batch - loss: 2.13993 - diff: 34.24mlTrain batch 2/32 - 234.2ms/batch - loss: 1.71845 - diff: 27.50mlTrain batch 3/32 - 233.8ms/batch - loss: 1.35850 - diff: 21.74mlTrain batch 4/32 - 234.8ms/batch - loss: 1.21282 - diff: 19.41mlTrain batch 5/32 - 233.9ms/batch - loss: 1.21895 - diff: 19.50mlTrain batch 6/32 - 238.8ms/batch - loss: 1.16974 - diff: 18.72mlTrain batch 7/32 - 234.1ms/batch - loss: 1.10498 - diff: 17.68mlTrain batch 8/32 - 234.3ms/batch - loss: 1.09800 - diff: 17.57mlTrain batch 9/32 - 233.9ms/batch - loss: 1.05930 - diff: 16.95mlTrain batch 10/32 - 233.7ms/batch - loss: 1.05521 - diff: 16.88mlTrain batch 11/32 - 234.1ms/batch - loss: 1.04066 - diff: 16.65mlTrain batch 12/32 - 248.9ms/batch - loss: 1.00672 - diff: 16.11mlTrain batch 13/32 - 234.0ms/batch - loss: 1.01191 - diff: 16.19mlTrain batch 14/32 - 234.5ms/batch - loss: 1.05772 - diff: 16.92mlTrain batch 15/32 - 233.9ms/batch - loss: 1.04189 - diff: 16.67mlTrain batch 16/32 - 237.7ms/batch - loss: 1.06105 - diff: 16.98mlTrain batch 17/32 - 234.6ms/batch - loss: 1.02743 - diff: 16.44mlTrain batch 18/32 - 234.1ms/batch - loss: 1.02010 - diff: 16.32mlTrain batch 19/32 - 234.8ms/batch - loss: 1.04137 - diff: 16.66mlTrain batch 20/32 - 235.2ms/batch - loss: 1.04025 - diff: 16.64mlTrain batch 21/32 - 234.3ms/batch - loss: 1.03061 - diff: 16.49mlTrain batch 22/32 - 234.3ms/batch - loss: 1.00870 - diff: 16.14mlTrain batch 23/32 - 234.9ms/batch - loss: 0.99086 - diff: 15.85mlTrain batch 24/32 - 233.9ms/batch - loss: 0.99882 - diff: 15.98mlTrain batch 25/32 - 235.2ms/batch - loss: 0.99697 - diff: 15.95mlTrain batch 26/32 - 233.9ms/batch - loss: 1.00296 - diff: 16.05mlTrain batch 27/32 - 238.1ms/batch - loss: 1.00452 - diff: 16.07mlTrain batch 28/32 - 233.9ms/batch - loss: 0.99260 - diff: 15.88mlTrain batch 29/32 - 232.7ms/batch - loss: 1.00108 - diff: 16.02mlTrain batch 30/32 - 234.0ms/batch - loss: 0.99220 - diff: 15.88mlTrain batch 31/32 - 234.2ms/batch - loss: 0.98770 - diff: 15.80mlTrain batch 32/32 - 82.4ms/batch - loss: 1.01234 - diff: 15.81mlTrain batch 32/32 - 17.4s 82.4ms/batch - loss: 1.01234 - diff: 15.81ml
Test 1.7s: val_loss: 1.10788 - diff: 16.75ml

Epoch 107: current best loss = 0.97979, at epoch 101
Train batch 1/32 - 233.7ms/batch - loss: 0.85801 - diff: 13.73mlTrain batch 2/32 - 234.1ms/batch - loss: 0.99166 - diff: 15.87mlTrain batch 3/32 - 234.0ms/batch - loss: 1.02919 - diff: 16.47mlTrain batch 4/32 - 234.1ms/batch - loss: 1.09206 - diff: 17.47mlTrain batch 5/32 - 233.6ms/batch - loss: 1.06190 - diff: 16.99mlTrain batch 6/32 - 233.9ms/batch - loss: 1.02658 - diff: 16.43mlTrain batch 7/32 - 233.8ms/batch - loss: 1.01254 - diff: 16.20mlTrain batch 8/32 - 234.2ms/batch - loss: 1.19846 - diff: 19.18mlTrain batch 9/32 - 234.0ms/batch - loss: 1.16183 - diff: 18.59mlTrain batch 10/32 - 233.8ms/batch - loss: 1.11869 - diff: 17.90mlTrain batch 11/32 - 233.8ms/batch - loss: 1.11922 - diff: 17.91mlTrain batch 12/32 - 234.0ms/batch - loss: 1.07884 - diff: 17.26mlTrain batch 13/32 - 233.7ms/batch - loss: 1.08855 - diff: 17.42mlTrain batch 14/32 - 235.1ms/batch - loss: 1.09329 - diff: 17.49mlTrain batch 15/32 - 233.9ms/batch - loss: 1.06348 - diff: 17.02mlTrain batch 16/32 - 234.2ms/batch - loss: 1.13249 - diff: 18.12mlTrain batch 17/32 - 234.2ms/batch - loss: 1.13378 - diff: 18.14mlTrain batch 18/32 - 240.4ms/batch - loss: 1.11963 - diff: 17.91mlTrain batch 19/32 - 234.2ms/batch - loss: 1.10418 - diff: 17.67mlTrain batch 20/32 - 234.3ms/batch - loss: 1.08139 - diff: 17.30mlTrain batch 21/32 - 233.9ms/batch - loss: 1.05415 - diff: 16.87mlTrain batch 22/32 - 234.6ms/batch - loss: 1.04774 - diff: 16.76mlTrain batch 23/32 - 234.1ms/batch - loss: 1.03372 - diff: 16.54mlTrain batch 24/32 - 234.3ms/batch - loss: 1.01496 - diff: 16.24mlTrain batch 25/32 - 233.7ms/batch - loss: 0.99785 - diff: 15.97mlTrain batch 26/32 - 234.2ms/batch - loss: 0.99432 - diff: 15.91mlTrain batch 27/32 - 233.6ms/batch - loss: 0.98830 - diff: 15.81mlTrain batch 28/32 - 233.8ms/batch - loss: 0.98628 - diff: 15.78mlTrain batch 29/32 - 234.5ms/batch - loss: 0.99641 - diff: 15.94mlTrain batch 30/32 - 233.8ms/batch - loss: 0.99847 - diff: 15.98mlTrain batch 31/32 - 234.7ms/batch - loss: 0.99237 - diff: 15.88mlTrain batch 32/32 - 76.5ms/batch - loss: 1.08655 - diff: 16.16mlTrain batch 32/32 - 16.4s 76.5ms/batch - loss: 1.08655 - diff: 16.16ml
Test 1.6s: val_loss: 1.02443 - diff: 15.63ml

Epoch 108: current best loss = 0.97979, at epoch 101
Train batch 1/32 - 233.9ms/batch - loss: 0.86670 - diff: 13.87mlTrain batch 2/32 - 233.8ms/batch - loss: 0.91527 - diff: 14.64mlTrain batch 3/32 - 233.8ms/batch - loss: 0.93342 - diff: 14.93mlTrain batch 4/32 - 233.7ms/batch - loss: 0.98748 - diff: 15.80mlTrain batch 5/32 - 234.0ms/batch - loss: 0.95545 - diff: 15.29mlTrain batch 6/32 - 234.2ms/batch - loss: 0.97970 - diff: 15.68mlTrain batch 7/32 - 234.0ms/batch - loss: 0.99003 - diff: 15.84mlTrain batch 8/32 - 233.9ms/batch - loss: 0.98678 - diff: 15.79mlTrain batch 9/32 - 234.2ms/batch - loss: 0.95999 - diff: 15.36mlTrain batch 10/32 - 233.9ms/batch - loss: 0.96236 - diff: 15.40mlTrain batch 11/32 - 234.1ms/batch - loss: 0.97315 - diff: 15.57mlTrain batch 12/32 - 233.9ms/batch - loss: 0.96716 - diff: 15.47mlTrain batch 13/32 - 234.0ms/batch - loss: 1.13855 - diff: 18.22mlTrain batch 14/32 - 234.1ms/batch - loss: 1.17208 - diff: 18.75mlTrain batch 15/32 - 233.8ms/batch - loss: 1.16773 - diff: 18.68mlTrain batch 16/32 - 234.8ms/batch - loss: 1.15262 - diff: 18.44mlTrain batch 17/32 - 234.0ms/batch - loss: 1.13644 - diff: 18.18mlTrain batch 18/32 - 234.3ms/batch - loss: 1.18794 - diff: 19.01mlTrain batch 19/32 - 233.6ms/batch - loss: 1.18947 - diff: 19.03mlTrain batch 20/32 - 234.7ms/batch - loss: 1.18905 - diff: 19.02mlTrain batch 21/32 - 237.1ms/batch - loss: 1.17208 - diff: 18.75mlTrain batch 22/32 - 234.3ms/batch - loss: 1.15199 - diff: 18.43mlTrain batch 23/32 - 234.2ms/batch - loss: 1.15606 - diff: 18.50mlTrain batch 24/32 - 233.7ms/batch - loss: 1.13472 - diff: 18.16mlTrain batch 25/32 - 234.1ms/batch - loss: 1.12077 - diff: 17.93mlTrain batch 26/32 - 238.3ms/batch - loss: 1.11439 - diff: 17.83mlTrain batch 27/32 - 234.3ms/batch - loss: 1.10406 - diff: 17.66mlTrain batch 28/32 - 244.4ms/batch - loss: 1.10123 - diff: 17.62mlTrain batch 29/32 - 233.7ms/batch - loss: 1.09096 - diff: 17.46mlTrain batch 30/32 - 234.6ms/batch - loss: 1.07491 - diff: 17.20mlTrain batch 31/32 - 234.7ms/batch - loss: 1.07107 - diff: 17.14mlTrain batch 32/32 - 76.8ms/batch - loss: 1.08463 - diff: 17.09mlTrain batch 32/32 - 16.7s 76.8ms/batch - loss: 1.08463 - diff: 17.09ml
Test 1.5s: val_loss: 1.10751 - diff: 16.86ml

Epoch 109: current best loss = 0.97979, at epoch 101
Train batch 1/32 - 234.1ms/batch - loss: 0.97062 - diff: 15.53mlTrain batch 2/32 - 239.5ms/batch - loss: 0.91545 - diff: 14.65mlTrain batch 3/32 - 235.1ms/batch - loss: 1.04425 - diff: 16.71mlTrain batch 4/32 - 234.8ms/batch - loss: 1.06263 - diff: 17.00mlTrain batch 5/32 - 233.7ms/batch - loss: 0.96907 - diff: 15.51mlTrain batch 6/32 - 235.0ms/batch - loss: 0.94786 - diff: 15.17mlTrain batch 7/32 - 233.7ms/batch - loss: 0.92335 - diff: 14.77mlTrain batch 8/32 - 234.8ms/batch - loss: 0.90023 - diff: 14.40mlTrain batch 9/32 - 234.3ms/batch - loss: 0.91728 - diff: 14.68mlTrain batch 10/32 - 234.6ms/batch - loss: 0.90830 - diff: 14.53mlTrain batch 11/32 - 234.0ms/batch - loss: 0.94956 - diff: 15.19mlTrain batch 12/32 - 238.1ms/batch - loss: 0.93702 - diff: 14.99mlTrain batch 13/32 - 234.2ms/batch - loss: 0.94197 - diff: 15.07mlTrain batch 14/32 - 238.5ms/batch - loss: 0.94184 - diff: 15.07mlTrain batch 15/32 - 234.4ms/batch - loss: 0.93478 - diff: 14.96mlTrain batch 16/32 - 238.5ms/batch - loss: 0.94083 - diff: 15.05mlTrain batch 17/32 - 233.8ms/batch - loss: 0.93327 - diff: 14.93mlTrain batch 18/32 - 234.8ms/batch - loss: 0.96551 - diff: 15.45mlTrain batch 19/32 - 233.7ms/batch - loss: 0.97244 - diff: 15.56mlTrain batch 20/32 - 238.9ms/batch - loss: 0.99348 - diff: 15.90mlTrain batch 21/32 - 234.5ms/batch - loss: 0.99329 - diff: 15.89mlTrain batch 22/32 - 238.9ms/batch - loss: 0.98798 - diff: 15.81mlTrain batch 23/32 - 234.3ms/batch - loss: 1.00454 - diff: 16.07mlTrain batch 24/32 - 234.7ms/batch - loss: 1.02743 - diff: 16.44mlTrain batch 25/32 - 234.1ms/batch - loss: 1.03046 - diff: 16.49mlTrain batch 26/32 - 237.3ms/batch - loss: 1.03184 - diff: 16.51mlTrain batch 27/32 - 233.9ms/batch - loss: 1.02783 - diff: 16.45mlTrain batch 28/32 - 235.0ms/batch - loss: 1.00887 - diff: 16.14mlTrain batch 29/32 - 234.0ms/batch - loss: 1.00696 - diff: 16.11mlTrain batch 30/32 - 234.2ms/batch - loss: 1.01128 - diff: 16.18mlTrain batch 31/32 - 234.1ms/batch - loss: 1.03558 - diff: 16.57mlTrain batch 32/32 - 84.8ms/batch - loss: 1.06487 - diff: 16.59mlTrain batch 32/32 - 18.0s 84.8ms/batch - loss: 1.06487 - diff: 16.59ml
Test 1.5s: val_loss: 1.23186 - diff: 19.00ml

Epoch 110: current best loss = 0.97979, at epoch 101
Train batch 1/32 - 233.7ms/batch - loss: 0.77980 - diff: 12.48mlTrain batch 2/32 - 241.1ms/batch - loss: 0.80971 - diff: 12.96mlTrain batch 3/32 - 233.7ms/batch - loss: 0.85835 - diff: 13.73mlTrain batch 4/32 - 234.4ms/batch - loss: 0.93850 - diff: 15.02mlTrain batch 5/32 - 245.5ms/batch - loss: 0.96418 - diff: 15.43mlTrain batch 6/32 - 234.3ms/batch - loss: 0.93264 - diff: 14.92mlTrain batch 7/32 - 233.9ms/batch - loss: 0.94568 - diff: 15.13mlTrain batch 8/32 - 237.4ms/batch - loss: 0.92991 - diff: 14.88mlTrain batch 9/32 - 234.4ms/batch - loss: 0.91625 - diff: 14.66mlTrain batch 10/32 - 234.8ms/batch - loss: 0.89648 - diff: 14.34mlTrain batch 11/32 - 234.3ms/batch - loss: 0.91287 - diff: 14.61mlTrain batch 12/32 - 233.9ms/batch - loss: 0.89725 - diff: 14.36mlTrain batch 13/32 - 234.2ms/batch - loss: 0.89430 - diff: 14.31mlTrain batch 14/32 - 234.4ms/batch - loss: 0.88198 - diff: 14.11mlTrain batch 15/32 - 233.9ms/batch - loss: 0.89841 - diff: 14.37mlTrain batch 16/32 - 234.2ms/batch - loss: 0.96432 - diff: 15.43mlTrain batch 17/32 - 233.9ms/batch - loss: 0.96518 - diff: 15.44mlTrain batch 18/32 - 234.2ms/batch - loss: 0.95200 - diff: 15.23mlTrain batch 19/32 - 234.1ms/batch - loss: 0.92728 - diff: 14.84mlTrain batch 20/32 - 234.2ms/batch - loss: 0.92868 - diff: 14.86mlTrain batch 21/32 - 238.6ms/batch - loss: 0.96882 - diff: 15.50mlTrain batch 22/32 - 234.4ms/batch - loss: 0.96487 - diff: 15.44mlTrain batch 23/32 - 234.0ms/batch - loss: 0.96298 - diff: 15.41mlTrain batch 24/32 - 233.9ms/batch - loss: 0.96292 - diff: 15.41mlTrain batch 25/32 - 234.5ms/batch - loss: 0.97431 - diff: 15.59mlTrain batch 26/32 - 236.8ms/batch - loss: 0.96928 - diff: 15.51mlTrain batch 27/32 - 234.4ms/batch - loss: 0.95937 - diff: 15.35mlTrain batch 28/32 - 234.1ms/batch - loss: 0.95647 - diff: 15.30mlTrain batch 29/32 - 234.1ms/batch - loss: 0.95392 - diff: 15.26mlTrain batch 30/32 - 234.2ms/batch - loss: 0.97263 - diff: 15.56mlTrain batch 31/32 - 234.6ms/batch - loss: 0.96872 - diff: 15.50mlTrain batch 32/32 - 77.3ms/batch - loss: 0.98175 - diff: 15.46mlTrain batch 32/32 - 17.2s 77.3ms/batch - loss: 0.98175 - diff: 15.46ml
Test 1.5s: val_loss: 1.09975 - diff: 16.31ml

Epoch 111: current best loss = 0.97979, at epoch 101
Train batch 1/32 - 233.8ms/batch - loss: 0.62924 - diff: 10.07mlTrain batch 2/32 - 251.8ms/batch - loss: 0.95507 - diff: 15.28mlTrain batch 3/32 - 234.0ms/batch - loss: 0.87885 - diff: 14.06mlTrain batch 4/32 - 234.0ms/batch - loss: 0.86536 - diff: 13.85mlTrain batch 5/32 - 234.4ms/batch - loss: 0.79563 - diff: 12.73mlTrain batch 6/32 - 233.8ms/batch - loss: 0.82147 - diff: 13.14mlTrain batch 7/32 - 234.2ms/batch - loss: 0.85730 - diff: 13.72mlTrain batch 8/32 - 234.3ms/batch - loss: 0.84546 - diff: 13.53mlTrain batch 9/32 - 233.9ms/batch - loss: 0.83627 - diff: 13.38mlTrain batch 10/32 - 234.0ms/batch - loss: 0.82196 - diff: 13.15mlTrain batch 11/32 - 234.0ms/batch - loss: 0.85264 - diff: 13.64mlTrain batch 12/32 - 242.0ms/batch - loss: 0.86418 - diff: 13.83mlTrain batch 13/32 - 233.8ms/batch - loss: 0.86301 - diff: 13.81mlTrain batch 14/32 - 234.0ms/batch - loss: 0.86921 - diff: 13.91mlTrain batch 15/32 - 233.9ms/batch - loss: 0.87307 - diff: 13.97mlTrain batch 16/32 - 233.8ms/batch - loss: 0.86949 - diff: 13.91mlTrain batch 17/32 - 234.1ms/batch - loss: 0.85356 - diff: 13.66mlTrain batch 18/32 - 234.0ms/batch - loss: 0.85406 - diff: 13.66mlTrain batch 19/32 - 233.9ms/batch - loss: 0.85831 - diff: 13.73mlTrain batch 20/32 - 234.3ms/batch - loss: 0.86165 - diff: 13.79mlTrain batch 21/32 - 252.4ms/batch - loss: 0.86411 - diff: 13.83mlTrain batch 22/32 - 234.8ms/batch - loss: 0.87016 - diff: 13.92mlTrain batch 23/32 - 233.7ms/batch - loss: 0.87202 - diff: 13.95mlTrain batch 24/32 - 239.4ms/batch - loss: 0.88082 - diff: 14.09mlTrain batch 25/32 - 236.2ms/batch - loss: 0.87963 - diff: 14.07mlTrain batch 26/32 - 233.6ms/batch - loss: 0.88612 - diff: 14.18mlTrain batch 27/32 - 234.0ms/batch - loss: 0.96593 - diff: 15.45mlTrain batch 28/32 - 234.8ms/batch - loss: 0.97563 - diff: 15.61mlTrain batch 29/32 - 233.6ms/batch - loss: 0.97078 - diff: 15.53mlTrain batch 30/32 - 233.1ms/batch - loss: 0.96761 - diff: 15.48mlTrain batch 31/32 - 233.8ms/batch - loss: 0.95921 - diff: 15.35mlTrain batch 32/32 - 84.3ms/batch - loss: 1.01866 - diff: 15.49mlTrain batch 32/32 - 16.9s 84.3ms/batch - loss: 1.01866 - diff: 15.49ml
Test 1.7s: val_loss: 1.20278 - diff: 18.63ml

Epoch 112: current best loss = 0.97979, at epoch 101
Train batch 1/32 - 233.9ms/batch - loss: 0.98726 - diff: 15.80mlTrain batch 2/32 - 234.4ms/batch - loss: 0.97326 - diff: 15.57mlTrain batch 3/32 - 233.7ms/batch - loss: 1.00906 - diff: 16.14mlTrain batch 4/32 - 234.1ms/batch - loss: 0.92541 - diff: 14.81mlTrain batch 5/32 - 237.9ms/batch - loss: 0.89935 - diff: 14.39mlTrain batch 6/32 - 234.4ms/batch - loss: 0.91057 - diff: 14.57mlTrain batch 7/32 - 234.0ms/batch - loss: 0.97113 - diff: 15.54mlTrain batch 8/32 - 234.7ms/batch - loss: 0.97682 - diff: 15.63mlTrain batch 9/32 - 234.0ms/batch - loss: 1.04621 - diff: 16.74mlTrain batch 10/32 - 234.6ms/batch - loss: 1.00712 - diff: 16.11mlTrain batch 11/32 - 234.2ms/batch - loss: 0.99186 - diff: 15.87mlTrain batch 12/32 - 238.7ms/batch - loss: 0.97322 - diff: 15.57mlTrain batch 13/32 - 233.7ms/batch - loss: 0.97541 - diff: 15.61mlTrain batch 14/32 - 233.9ms/batch - loss: 0.98836 - diff: 15.81mlTrain batch 15/32 - 234.1ms/batch - loss: 0.99306 - diff: 15.89mlTrain batch 16/32 - 235.8ms/batch - loss: 0.99173 - diff: 15.87mlTrain batch 17/32 - 233.8ms/batch - loss: 0.97894 - diff: 15.66mlTrain batch 18/32 - 234.4ms/batch - loss: 0.96618 - diff: 15.46mlTrain batch 19/32 - 234.0ms/batch - loss: 0.96974 - diff: 15.52mlTrain batch 20/32 - 234.1ms/batch - loss: 0.96083 - diff: 15.37mlTrain batch 21/32 - 234.3ms/batch - loss: 0.95551 - diff: 15.29mlTrain batch 22/32 - 234.4ms/batch - loss: 0.93926 - diff: 15.03mlTrain batch 23/32 - 237.3ms/batch - loss: 0.94236 - diff: 15.08mlTrain batch 24/32 - 234.5ms/batch - loss: 0.93901 - diff: 15.02mlTrain batch 25/32 - 233.8ms/batch - loss: 0.92596 - diff: 14.82mlTrain batch 26/32 - 234.4ms/batch - loss: 0.93846 - diff: 15.02mlTrain batch 27/32 - 234.0ms/batch - loss: 0.94388 - diff: 15.10mlTrain batch 28/32 - 234.2ms/batch - loss: 0.98500 - diff: 15.76mlTrain batch 29/32 - 234.2ms/batch - loss: 0.97449 - diff: 15.59mlTrain batch 30/32 - 234.3ms/batch - loss: 0.97589 - diff: 15.61mlTrain batch 31/32 - 234.1ms/batch - loss: 0.98154 - diff: 15.70mlTrain batch 32/32 - 76.4ms/batch - loss: 0.98899 - diff: 15.64mlTrain batch 32/32 - 16.2s 76.4ms/batch - loss: 0.98899 - diff: 15.64ml
Test 1.6s: val_loss: 1.08469 - diff: 16.77ml
Epoch   113: reducing learning rate of group 0 to 1.2500e-04.

Epoch 113: current best loss = 0.97979, at epoch 101
Train batch 1/32 - 234.0ms/batch - loss: 0.73323 - diff: 11.73mlTrain batch 2/32 - 254.9ms/batch - loss: 0.72144 - diff: 11.54mlTrain batch 3/32 - 234.3ms/batch - loss: 0.71417 - diff: 11.43mlTrain batch 4/32 - 235.0ms/batch - loss: 0.70521 - diff: 11.28mlTrain batch 5/32 - 234.1ms/batch - loss: 0.72667 - diff: 11.63mlTrain batch 6/32 - 236.7ms/batch - loss: 0.72392 - diff: 11.58mlTrain batch 7/32 - 234.2ms/batch - loss: 0.74207 - diff: 11.87mlTrain batch 8/32 - 233.9ms/batch - loss: 0.77033 - diff: 12.33mlTrain batch 9/32 - 234.3ms/batch - loss: 0.82467 - diff: 13.19mlTrain batch 10/32 - 233.7ms/batch - loss: 0.88439 - diff: 14.15mlTrain batch 11/32 - 234.5ms/batch - loss: 0.88588 - diff: 14.17mlTrain batch 12/32 - 233.9ms/batch - loss: 0.86459 - diff: 13.83mlTrain batch 13/32 - 235.7ms/batch - loss: 0.84348 - diff: 13.50mlTrain batch 14/32 - 234.0ms/batch - loss: 0.88326 - diff: 14.13mlTrain batch 15/32 - 234.3ms/batch - loss: 0.90651 - diff: 14.50mlTrain batch 16/32 - 234.3ms/batch - loss: 0.88714 - diff: 14.19mlTrain batch 17/32 - 234.1ms/batch - loss: 0.87866 - diff: 14.06mlTrain batch 18/32 - 234.0ms/batch - loss: 0.90604 - diff: 14.50mlTrain batch 19/32 - 234.1ms/batch - loss: 0.95077 - diff: 15.21mlTrain batch 20/32 - 234.6ms/batch - loss: 0.95961 - diff: 15.35mlTrain batch 21/32 - 235.0ms/batch - loss: 0.95525 - diff: 15.28mlTrain batch 22/32 - 234.4ms/batch - loss: 0.95037 - diff: 15.21mlTrain batch 23/32 - 233.8ms/batch - loss: 0.95416 - diff: 15.27mlTrain batch 24/32 - 234.2ms/batch - loss: 0.94876 - diff: 15.18mlTrain batch 25/32 - 233.9ms/batch - loss: 0.94009 - diff: 15.04mlTrain batch 26/32 - 234.4ms/batch - loss: 0.93574 - diff: 14.97mlTrain batch 27/32 - 233.7ms/batch - loss: 0.92111 - diff: 14.74mlTrain batch 28/32 - 241.2ms/batch - loss: 0.91868 - diff: 14.70mlTrain batch 29/32 - 234.3ms/batch - loss: 0.91876 - diff: 14.70mlTrain batch 30/32 - 234.0ms/batch - loss: 0.93043 - diff: 14.89mlTrain batch 31/32 - 234.0ms/batch - loss: 0.93242 - diff: 14.92mlTrain batch 32/32 - 82.9ms/batch - loss: 0.93757 - diff: 14.85mlTrain batch 32/32 - 15.4s 82.9ms/batch - loss: 0.93757 - diff: 14.85ml
Test 1.6s: val_loss: 1.02813 - diff: 16.00ml

Epoch 114: current best loss = 0.97979, at epoch 101
Train batch 1/32 - 234.2ms/batch - loss: 0.72819 - diff: 11.65mlTrain batch 2/32 - 238.4ms/batch - loss: 0.68254 - diff: 10.92mlTrain batch 3/32 - 234.0ms/batch - loss: 0.77045 - diff: 12.33mlTrain batch 4/32 - 238.6ms/batch - loss: 0.84338 - diff: 13.49mlTrain batch 5/32 - 234.2ms/batch - loss: 0.81573 - diff: 13.05mlTrain batch 6/32 - 234.6ms/batch - loss: 0.77547 - diff: 12.41mlTrain batch 7/32 - 234.1ms/batch - loss: 0.92752 - diff: 14.84mlTrain batch 8/32 - 234.4ms/batch - loss: 0.95747 - diff: 15.32mlTrain batch 9/32 - 234.3ms/batch - loss: 0.97412 - diff: 15.59mlTrain batch 10/32 - 234.8ms/batch - loss: 0.97534 - diff: 15.61mlTrain batch 11/32 - 234.1ms/batch - loss: 1.01468 - diff: 16.23mlTrain batch 12/32 - 233.8ms/batch - loss: 0.98865 - diff: 15.82mlTrain batch 13/32 - 233.8ms/batch - loss: 0.96108 - diff: 15.38mlTrain batch 14/32 - 233.8ms/batch - loss: 0.95899 - diff: 15.34mlTrain batch 15/32 - 234.2ms/batch - loss: 0.97240 - diff: 15.56mlTrain batch 16/32 - 235.0ms/batch - loss: 0.95941 - diff: 15.35mlTrain batch 17/32 - 235.7ms/batch - loss: 0.96182 - diff: 15.39mlTrain batch 18/32 - 235.0ms/batch - loss: 0.98550 - diff: 15.77mlTrain batch 19/32 - 234.3ms/batch - loss: 0.97530 - diff: 15.60mlTrain batch 20/32 - 234.5ms/batch - loss: 0.97670 - diff: 15.63mlTrain batch 21/32 - 234.1ms/batch - loss: 0.97781 - diff: 15.65mlTrain batch 22/32 - 234.3ms/batch - loss: 0.97870 - diff: 15.66mlTrain batch 23/32 - 233.6ms/batch - loss: 0.97190 - diff: 15.55mlTrain batch 24/32 - 234.7ms/batch - loss: 1.02295 - diff: 16.37mlTrain batch 25/32 - 233.8ms/batch - loss: 1.02784 - diff: 16.45mlTrain batch 26/32 - 233.7ms/batch - loss: 1.02235 - diff: 16.36mlTrain batch 27/32 - 233.9ms/batch - loss: 1.01125 - diff: 16.18mlTrain batch 28/32 - 234.6ms/batch - loss: 1.00326 - diff: 16.05mlTrain batch 29/32 - 234.2ms/batch - loss: 1.00416 - diff: 16.07mlTrain batch 30/32 - 234.6ms/batch - loss: 0.99437 - diff: 15.91mlTrain batch 31/32 - 234.3ms/batch - loss: 0.98869 - diff: 15.82mlTrain batch 32/32 - 86.2ms/batch - loss: 1.01471 - diff: 15.83mlTrain batch 32/32 - 17.3s 86.2ms/batch - loss: 1.01471 - diff: 15.83ml
Test 1.5s: val_loss: 0.99710 - diff: 15.50ml

Epoch 115: current best loss = 0.97979, at epoch 101
Train batch 1/32 - 234.0ms/batch - loss: 1.15212 - diff: 18.43mlTrain batch 2/32 - 234.2ms/batch - loss: 1.01924 - diff: 16.31mlTrain batch 3/32 - 234.0ms/batch - loss: 0.97090 - diff: 15.53mlTrain batch 4/32 - 234.4ms/batch - loss: 1.12584 - diff: 18.01mlTrain batch 5/32 - 233.8ms/batch - loss: 1.12731 - diff: 18.04mlTrain batch 6/32 - 234.7ms/batch - loss: 1.04701 - diff: 16.75mlTrain batch 7/32 - 238.4ms/batch - loss: 1.21404 - diff: 19.42mlTrain batch 8/32 - 234.8ms/batch - loss: 1.14527 - diff: 18.32mlTrain batch 9/32 - 233.8ms/batch - loss: 1.10642 - diff: 17.70mlTrain batch 10/32 - 238.8ms/batch - loss: 1.07786 - diff: 17.25mlTrain batch 11/32 - 234.2ms/batch - loss: 1.07022 - diff: 17.12mlTrain batch 12/32 - 234.6ms/batch - loss: 1.03222 - diff: 16.52mlTrain batch 13/32 - 236.7ms/batch - loss: 1.01848 - diff: 16.30mlTrain batch 14/32 - 234.3ms/batch - loss: 0.98459 - diff: 15.75mlTrain batch 15/32 - 233.8ms/batch - loss: 0.97189 - diff: 15.55mlTrain batch 16/32 - 234.2ms/batch - loss: 0.95209 - diff: 15.23mlTrain batch 17/32 - 234.7ms/batch - loss: 0.93160 - diff: 14.91mlTrain batch 18/32 - 234.4ms/batch - loss: 0.95923 - diff: 15.35mlTrain batch 19/32 - 237.7ms/batch - loss: 0.94904 - diff: 15.18mlTrain batch 20/32 - 234.1ms/batch - loss: 0.95448 - diff: 15.27mlTrain batch 21/32 - 234.1ms/batch - loss: 0.94467 - diff: 15.11mlTrain batch 22/32 - 234.2ms/batch - loss: 0.95597 - diff: 15.30mlTrain batch 23/32 - 235.5ms/batch - loss: 0.95667 - diff: 15.31mlTrain batch 24/32 - 234.1ms/batch - loss: 0.94755 - diff: 15.16mlTrain batch 25/32 - 237.9ms/batch - loss: 0.94301 - diff: 15.09mlTrain batch 26/32 - 233.9ms/batch - loss: 0.94055 - diff: 15.05mlTrain batch 27/32 - 234.1ms/batch - loss: 0.93703 - diff: 14.99mlTrain batch 28/32 - 233.8ms/batch - loss: 0.94377 - diff: 15.10mlTrain batch 29/32 - 234.7ms/batch - loss: 0.98734 - diff: 15.80mlTrain batch 30/32 - 233.8ms/batch - loss: 0.97771 - diff: 15.64mlTrain batch 31/32 - 234.7ms/batch - loss: 0.98160 - diff: 15.71mlTrain batch 32/32 - 80.4ms/batch - loss: 0.99684 - diff: 15.67mlTrain batch 32/32 - 17.4s 80.4ms/batch - loss: 0.99684 - diff: 15.67ml
Test 1.6s: val_loss: 1.01657 - diff: 15.76ml

Epoch 116: current best loss = 0.97979, at epoch 101
Train batch 1/32 - 244.1ms/batch - loss: 0.87903 - diff: 14.06mlTrain batch 2/32 - 240.5ms/batch - loss: 0.84254 - diff: 13.48mlTrain batch 3/32 - 233.9ms/batch - loss: 0.98076 - diff: 15.69mlTrain batch 4/32 - 234.4ms/batch - loss: 0.91584 - diff: 14.65mlTrain batch 5/32 - 234.1ms/batch - loss: 0.95235 - diff: 15.24mlTrain batch 6/32 - 238.5ms/batch - loss: 0.91563 - diff: 14.65mlTrain batch 7/32 - 234.0ms/batch - loss: 0.95039 - diff: 15.21mlTrain batch 8/32 - 238.5ms/batch - loss: 0.93350 - diff: 14.94mlTrain batch 9/32 - 234.0ms/batch - loss: 0.91246 - diff: 14.60mlTrain batch 10/32 - 234.2ms/batch - loss: 0.98402 - diff: 15.74mlTrain batch 11/32 - 233.7ms/batch - loss: 0.94962 - diff: 15.19mlTrain batch 12/32 - 238.6ms/batch - loss: 1.01920 - diff: 16.31mlTrain batch 13/32 - 234.0ms/batch - loss: 0.98997 - diff: 15.84mlTrain batch 14/32 - 234.6ms/batch - loss: 0.95457 - diff: 15.27mlTrain batch 15/32 - 233.9ms/batch - loss: 0.93451 - diff: 14.95mlTrain batch 16/32 - 243.1ms/batch - loss: 0.92658 - diff: 14.83mlTrain batch 17/32 - 234.2ms/batch - loss: 0.92111 - diff: 14.74mlTrain batch 18/32 - 234.5ms/batch - loss: 0.92847 - diff: 14.86mlTrain batch 19/32 - 233.9ms/batch - loss: 0.93748 - diff: 15.00mlTrain batch 20/32 - 234.4ms/batch - loss: 0.93771 - diff: 15.00mlTrain batch 21/32 - 233.9ms/batch - loss: 0.95441 - diff: 15.27mlTrain batch 22/32 - 234.3ms/batch - loss: 0.95104 - diff: 15.22mlTrain batch 23/32 - 234.2ms/batch - loss: 0.94917 - diff: 15.19mlTrain batch 24/32 - 233.3ms/batch - loss: 0.95857 - diff: 15.34mlTrain batch 25/32 - 234.1ms/batch - loss: 0.95850 - diff: 15.34mlTrain batch 26/32 - 249.0ms/batch - loss: 0.94748 - diff: 15.16mlTrain batch 27/32 - 233.5ms/batch - loss: 0.93748 - diff: 15.00mlTrain batch 28/32 - 234.9ms/batch - loss: 0.94281 - diff: 15.08mlTrain batch 29/32 - 237.9ms/batch - loss: 0.93815 - diff: 15.01mlTrain batch 30/32 - 234.3ms/batch - loss: 0.92788 - diff: 14.85mlTrain batch 31/32 - 234.2ms/batch - loss: 0.92045 - diff: 14.73mlTrain batch 32/32 - 81.9ms/batch - loss: 0.95272 - diff: 14.77mlTrain batch 32/32 - 16.6s 81.9ms/batch - loss: 0.95272 - diff: 14.77ml
Test 1.6s: val_loss: 0.94355 - diff: 14.44ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Systole_WideResNet50_0_Adam-0.001_MAE_DA3_best

Epoch 117: current best loss = 0.94355, at epoch 116
Train batch 1/32 - 242.1ms/batch - loss: 1.02001 - diff: 16.32mlTrain batch 2/32 - 233.9ms/batch - loss: 1.00742 - diff: 16.12mlTrain batch 3/32 - 234.0ms/batch - loss: 0.86815 - diff: 13.89mlTrain batch 4/32 - 238.3ms/batch - loss: 1.04920 - diff: 16.79mlTrain batch 5/32 - 234.0ms/batch - loss: 1.02655 - diff: 16.42mlTrain batch 6/32 - 233.8ms/batch - loss: 0.98104 - diff: 15.70mlTrain batch 7/32 - 233.7ms/batch - loss: 0.98672 - diff: 15.79mlTrain batch 8/32 - 234.4ms/batch - loss: 0.94693 - diff: 15.15mlTrain batch 9/32 - 233.5ms/batch - loss: 0.87951 - diff: 14.07mlTrain batch 10/32 - 237.6ms/batch - loss: 0.86239 - diff: 13.80mlTrain batch 11/32 - 233.9ms/batch - loss: 0.86655 - diff: 13.86mlTrain batch 12/32 - 234.4ms/batch - loss: 0.89896 - diff: 14.38mlTrain batch 13/32 - 233.9ms/batch - loss: 0.87150 - diff: 13.94mlTrain batch 14/32 - 238.2ms/batch - loss: 0.93261 - diff: 14.92mlTrain batch 15/32 - 234.1ms/batch - loss: 0.91101 - diff: 14.58mlTrain batch 16/32 - 237.4ms/batch - loss: 0.90306 - diff: 14.45mlTrain batch 17/32 - 234.2ms/batch - loss: 0.89569 - diff: 14.33mlTrain batch 18/32 - 234.3ms/batch - loss: 0.88081 - diff: 14.09mlTrain batch 19/32 - 233.9ms/batch - loss: 0.86816 - diff: 13.89mlTrain batch 20/32 - 234.0ms/batch - loss: 0.86520 - diff: 13.84mlTrain batch 21/32 - 234.1ms/batch - loss: 0.85119 - diff: 13.62mlTrain batch 22/32 - 234.9ms/batch - loss: 0.84690 - diff: 13.55mlTrain batch 23/32 - 233.8ms/batch - loss: 0.84871 - diff: 13.58mlTrain batch 24/32 - 234.4ms/batch - loss: 0.84607 - diff: 13.54mlTrain batch 25/32 - 233.8ms/batch - loss: 0.83070 - diff: 13.29mlTrain batch 26/32 - 234.2ms/batch - loss: 0.87640 - diff: 14.02mlTrain batch 27/32 - 234.0ms/batch - loss: 0.88454 - diff: 14.15mlTrain batch 28/32 - 234.4ms/batch - loss: 0.87997 - diff: 14.08mlTrain batch 29/32 - 233.8ms/batch - loss: 0.89797 - diff: 14.37mlTrain batch 30/32 - 234.4ms/batch - loss: 0.90857 - diff: 14.54mlTrain batch 31/32 - 234.3ms/batch - loss: 0.90644 - diff: 14.50mlTrain batch 32/32 - 83.2ms/batch - loss: 0.92748 - diff: 14.50mlTrain batch 32/32 - 18.2s 83.2ms/batch - loss: 0.92748 - diff: 14.50ml
Test 1.6s: val_loss: 1.02136 - diff: 15.78ml

Epoch 118: current best loss = 0.94355, at epoch 116
Train batch 1/32 - 249.6ms/batch - loss: 0.86952 - diff: 13.91mlTrain batch 2/32 - 234.3ms/batch - loss: 1.19337 - diff: 19.09mlTrain batch 3/32 - 234.0ms/batch - loss: 1.07877 - diff: 17.26mlTrain batch 4/32 - 234.3ms/batch - loss: 1.00584 - diff: 16.09mlTrain batch 5/32 - 233.6ms/batch - loss: 1.00006 - diff: 16.00mlTrain batch 6/32 - 234.4ms/batch - loss: 0.97241 - diff: 15.56mlTrain batch 7/32 - 233.7ms/batch - loss: 0.98954 - diff: 15.83mlTrain batch 8/32 - 234.5ms/batch - loss: 0.99635 - diff: 15.94mlTrain batch 9/32 - 233.7ms/batch - loss: 0.97955 - diff: 15.67mlTrain batch 10/32 - 234.1ms/batch - loss: 0.97532 - diff: 15.61mlTrain batch 11/32 - 233.6ms/batch - loss: 0.93838 - diff: 15.01mlTrain batch 12/32 - 234.3ms/batch - loss: 0.91758 - diff: 14.68mlTrain batch 13/32 - 233.6ms/batch - loss: 0.90812 - diff: 14.53mlTrain batch 14/32 - 238.7ms/batch - loss: 0.91867 - diff: 14.70mlTrain batch 15/32 - 233.6ms/batch - loss: 0.94572 - diff: 15.13mlTrain batch 16/32 - 238.7ms/batch - loss: 0.92413 - diff: 14.79mlTrain batch 17/32 - 233.5ms/batch - loss: 0.90239 - diff: 14.44mlTrain batch 18/32 - 239.9ms/batch - loss: 0.88223 - diff: 14.12mlTrain batch 19/32 - 233.4ms/batch - loss: 0.88849 - diff: 14.22mlTrain batch 20/32 - 237.9ms/batch - loss: 0.93430 - diff: 14.95mlTrain batch 21/32 - 233.5ms/batch - loss: 0.94447 - diff: 15.11mlTrain batch 22/32 - 234.3ms/batch - loss: 0.93493 - diff: 14.96mlTrain batch 23/32 - 234.2ms/batch - loss: 0.92331 - diff: 14.77mlTrain batch 24/32 - 234.5ms/batch - loss: 0.90909 - diff: 14.55mlTrain batch 25/32 - 233.5ms/batch - loss: 0.92383 - diff: 14.78mlTrain batch 26/32 - 234.3ms/batch - loss: 0.91640 - diff: 14.66mlTrain batch 27/32 - 233.9ms/batch - loss: 0.90959 - diff: 14.55mlTrain batch 28/32 - 233.9ms/batch - loss: 0.90758 - diff: 14.52mlTrain batch 29/32 - 233.6ms/batch - loss: 0.90284 - diff: 14.45mlTrain batch 30/32 - 234.3ms/batch - loss: 0.88980 - diff: 14.24mlTrain batch 31/32 - 233.7ms/batch - loss: 0.88546 - diff: 14.17mlTrain batch 32/32 - 81.3ms/batch - loss: 0.91637 - diff: 14.21mlTrain batch 32/32 - 18.9s 81.3ms/batch - loss: 0.91637 - diff: 14.21ml
Test 1.6s: val_loss: 0.95388 - diff: 14.65ml

Epoch 119: current best loss = 0.94355, at epoch 116
Train batch 1/32 - 233.6ms/batch - loss: 1.09441 - diff: 17.51mlTrain batch 2/32 - 237.6ms/batch - loss: 0.91137 - diff: 14.58mlTrain batch 3/32 - 233.9ms/batch - loss: 0.84666 - diff: 13.55mlTrain batch 4/32 - 234.5ms/batch - loss: 0.87539 - diff: 14.01mlTrain batch 5/32 - 233.7ms/batch - loss: 0.86053 - diff: 13.77mlTrain batch 6/32 - 233.9ms/batch - loss: 0.83062 - diff: 13.29mlTrain batch 7/32 - 233.6ms/batch - loss: 0.94786 - diff: 15.17mlTrain batch 8/32 - 234.8ms/batch - loss: 0.96266 - diff: 15.40mlTrain batch 9/32 - 233.9ms/batch - loss: 0.92475 - diff: 14.80mlTrain batch 10/32 - 234.0ms/batch - loss: 0.95289 - diff: 15.25mlTrain batch 11/32 - 233.9ms/batch - loss: 0.93702 - diff: 14.99mlTrain batch 12/32 - 234.7ms/batch - loss: 0.93479 - diff: 14.96mlTrain batch 13/32 - 233.8ms/batch - loss: 0.90644 - diff: 14.50mlTrain batch 14/32 - 234.2ms/batch - loss: 0.88915 - diff: 14.23mlTrain batch 15/32 - 233.9ms/batch - loss: 0.89574 - diff: 14.33mlTrain batch 16/32 - 237.9ms/batch - loss: 0.88449 - diff: 14.15mlTrain batch 17/32 - 235.6ms/batch - loss: 0.94484 - diff: 15.12mlTrain batch 18/32 - 234.0ms/batch - loss: 0.95908 - diff: 15.35mlTrain batch 19/32 - 236.4ms/batch - loss: 0.96088 - diff: 15.37mlTrain batch 20/32 - 233.9ms/batch - loss: 0.99505 - diff: 15.92mlTrain batch 21/32 - 233.7ms/batch - loss: 0.97958 - diff: 15.67mlTrain batch 22/32 - 234.5ms/batch - loss: 0.96776 - diff: 15.48mlTrain batch 23/32 - 234.0ms/batch - loss: 0.96219 - diff: 15.40mlTrain batch 24/32 - 233.9ms/batch - loss: 0.95853 - diff: 15.34mlTrain batch 25/32 - 234.2ms/batch - loss: 0.95580 - diff: 15.29mlTrain batch 26/32 - 234.3ms/batch - loss: 0.94393 - diff: 15.10mlTrain batch 27/32 - 233.6ms/batch - loss: 0.95062 - diff: 15.21mlTrain batch 28/32 - 234.5ms/batch - loss: 0.94815 - diff: 15.17mlTrain batch 29/32 - 234.0ms/batch - loss: 0.94158 - diff: 15.07mlTrain batch 30/32 - 236.2ms/batch - loss: 0.93352 - diff: 14.94mlTrain batch 31/32 - 233.8ms/batch - loss: 0.92796 - diff: 14.85mlTrain batch 32/32 - 76.5ms/batch - loss: 1.01000 - diff: 15.09mlTrain batch 32/32 - 16.6s 76.5ms/batch - loss: 1.01000 - diff: 15.09ml
Test 1.5s: val_loss: 1.08194 - diff: 16.66ml

Epoch 120: current best loss = 0.94355, at epoch 116
Train batch 1/32 - 234.2ms/batch - loss: 0.95414 - diff: 15.27mlTrain batch 2/32 - 234.0ms/batch - loss: 0.90064 - diff: 14.41mlTrain batch 3/32 - 233.8ms/batch - loss: 0.76696 - diff: 12.27mlTrain batch 4/32 - 234.4ms/batch - loss: 0.81441 - diff: 13.03mlTrain batch 5/32 - 234.2ms/batch - loss: 0.79718 - diff: 12.75mlTrain batch 6/32 - 234.7ms/batch - loss: 0.79598 - diff: 12.74mlTrain batch 7/32 - 234.0ms/batch - loss: 0.79956 - diff: 12.79mlTrain batch 8/32 - 233.9ms/batch - loss: 0.83318 - diff: 13.33mlTrain batch 9/32 - 234.0ms/batch - loss: 0.81282 - diff: 13.01mlTrain batch 10/32 - 233.8ms/batch - loss: 0.81876 - diff: 13.10mlTrain batch 11/32 - 233.9ms/batch - loss: 0.82748 - diff: 13.24mlTrain batch 12/32 - 234.6ms/batch - loss: 0.84073 - diff: 13.45mlTrain batch 13/32 - 233.8ms/batch - loss: 0.90527 - diff: 14.48mlTrain batch 14/32 - 234.0ms/batch - loss: 0.98133 - diff: 15.70mlTrain batch 15/32 - 234.1ms/batch - loss: 0.96599 - diff: 15.46mlTrain batch 16/32 - 234.1ms/batch - loss: 0.99271 - diff: 15.88mlTrain batch 17/32 - 234.4ms/batch - loss: 0.99245 - diff: 15.88mlTrain batch 18/32 - 233.8ms/batch - loss: 0.99056 - diff: 15.85mlTrain batch 19/32 - 234.1ms/batch - loss: 0.96102 - diff: 15.38mlTrain batch 20/32 - 233.9ms/batch - loss: 0.97150 - diff: 15.54mlTrain batch 21/32 - 234.4ms/batch - loss: 0.96432 - diff: 15.43mlTrain batch 22/32 - 234.0ms/batch - loss: 0.97510 - diff: 15.60mlTrain batch 23/32 - 234.5ms/batch - loss: 0.96744 - diff: 15.48mlTrain batch 24/32 - 234.1ms/batch - loss: 0.96851 - diff: 15.50mlTrain batch 25/32 - 234.3ms/batch - loss: 0.97441 - diff: 15.59mlTrain batch 26/32 - 237.3ms/batch - loss: 0.96415 - diff: 15.43mlTrain batch 27/32 - 234.1ms/batch - loss: 0.96694 - diff: 15.47mlTrain batch 28/32 - 233.9ms/batch - loss: 0.96000 - diff: 15.36mlTrain batch 29/32 - 234.4ms/batch - loss: 0.94518 - diff: 15.12mlTrain batch 30/32 - 237.3ms/batch - loss: 0.96221 - diff: 15.40mlTrain batch 31/32 - 234.1ms/batch - loss: 0.95486 - diff: 15.28mlTrain batch 32/32 - 76.7ms/batch - loss: 0.97199 - diff: 15.25mlTrain batch 32/32 - 16.3s 76.7ms/batch - loss: 0.97199 - diff: 15.25ml
Test 1.6s: val_loss: 1.20227 - diff: 18.24ml

Epoch 121: current best loss = 0.94355, at epoch 116
Train batch 1/32 - 234.0ms/batch - loss: 0.73008 - diff: 11.68mlTrain batch 2/32 - 234.6ms/batch - loss: 1.23801 - diff: 19.81mlTrain batch 3/32 - 234.1ms/batch - loss: 1.11028 - diff: 17.76mlTrain batch 4/32 - 234.1ms/batch - loss: 1.05845 - diff: 16.94mlTrain batch 5/32 - 234.2ms/batch - loss: 0.96914 - diff: 15.51mlTrain batch 6/32 - 235.2ms/batch - loss: 0.94006 - diff: 15.04mlTrain batch 7/32 - 234.0ms/batch - loss: 1.01921 - diff: 16.31mlTrain batch 8/32 - 233.9ms/batch - loss: 1.15979 - diff: 18.56mlTrain batch 9/32 - 234.3ms/batch - loss: 1.15182 - diff: 18.43mlTrain batch 10/32 - 233.6ms/batch - loss: 1.13408 - diff: 18.15mlTrain batch 11/32 - 233.9ms/batch - loss: 1.08841 - diff: 17.41mlTrain batch 12/32 - 234.1ms/batch - loss: 1.07533 - diff: 17.21mlTrain batch 13/32 - 234.3ms/batch - loss: 1.03848 - diff: 16.62mlTrain batch 14/32 - 234.1ms/batch - loss: 1.02242 - diff: 16.36mlTrain batch 15/32 - 234.1ms/batch - loss: 1.01199 - diff: 16.19mlTrain batch 16/32 - 234.0ms/batch - loss: 1.00943 - diff: 16.15mlTrain batch 17/32 - 234.6ms/batch - loss: 1.00974 - diff: 16.16mlTrain batch 18/32 - 233.8ms/batch - loss: 1.00498 - diff: 16.08mlTrain batch 19/32 - 233.7ms/batch - loss: 1.00927 - diff: 16.15mlTrain batch 20/32 - 234.4ms/batch - loss: 0.98681 - diff: 15.79mlTrain batch 21/32 - 234.2ms/batch - loss: 0.97777 - diff: 15.64mlTrain batch 22/32 - 233.8ms/batch - loss: 0.95872 - diff: 15.34mlTrain batch 23/32 - 238.3ms/batch - loss: 0.93947 - diff: 15.03mlTrain batch 24/32 - 234.1ms/batch - loss: 0.93503 - diff: 14.96mlTrain batch 25/32 - 238.3ms/batch - loss: 0.93521 - diff: 14.96mlTrain batch 26/32 - 234.3ms/batch - loss: 0.93583 - diff: 14.97mlTrain batch 27/32 - 233.4ms/batch - loss: 0.94064 - diff: 15.05mlTrain batch 28/32 - 234.1ms/batch - loss: 0.93562 - diff: 14.97mlTrain batch 29/32 - 235.0ms/batch - loss: 0.92029 - diff: 14.72mlTrain batch 30/32 - 233.7ms/batch - loss: 0.91566 - diff: 14.65mlTrain batch 31/32 - 241.3ms/batch - loss: 0.91426 - diff: 14.63mlTrain batch 32/32 - 76.5ms/batch - loss: 0.94298 - diff: 14.66mlTrain batch 32/32 - 16.3s 76.5ms/batch - loss: 0.94298 - diff: 14.66ml
Test 1.5s: val_loss: 1.00378 - diff: 15.07ml

Epoch 122: current best loss = 0.94355, at epoch 116
Train batch 1/32 - 234.1ms/batch - loss: 0.63441 - diff: 10.15mlTrain batch 2/32 - 246.8ms/batch - loss: 0.84271 - diff: 13.48mlTrain batch 3/32 - 246.8ms/batch - loss: 0.89857 - diff: 14.38mlTrain batch 4/32 - 234.9ms/batch - loss: 0.79347 - diff: 12.70mlTrain batch 5/32 - 234.1ms/batch - loss: 0.77987 - diff: 12.48mlTrain batch 6/32 - 234.3ms/batch - loss: 0.76575 - diff: 12.25mlTrain batch 7/32 - 234.2ms/batch - loss: 0.87847 - diff: 14.06mlTrain batch 8/32 - 241.7ms/batch - loss: 0.85496 - diff: 13.68mlTrain batch 9/32 - 233.8ms/batch - loss: 0.97106 - diff: 15.54mlTrain batch 10/32 - 234.5ms/batch - loss: 0.94229 - diff: 15.08mlTrain batch 11/32 - 233.8ms/batch - loss: 0.92253 - diff: 14.76mlTrain batch 12/32 - 234.8ms/batch - loss: 0.92863 - diff: 14.86mlTrain batch 13/32 - 233.8ms/batch - loss: 0.90497 - diff: 14.48mlTrain batch 14/32 - 234.5ms/batch - loss: 0.89274 - diff: 14.28mlTrain batch 15/32 - 233.7ms/batch - loss: 0.89740 - diff: 14.36mlTrain batch 16/32 - 234.5ms/batch - loss: 0.90632 - diff: 14.50mlTrain batch 17/32 - 234.0ms/batch - loss: 0.91763 - diff: 14.68mlTrain batch 18/32 - 233.7ms/batch - loss: 0.94223 - diff: 15.08mlTrain batch 19/32 - 233.8ms/batch - loss: 0.93915 - diff: 15.03mlTrain batch 20/32 - 233.8ms/batch - loss: 0.94655 - diff: 15.14mlTrain batch 21/32 - 233.8ms/batch - loss: 0.93674 - diff: 14.99mlTrain batch 22/32 - 234.3ms/batch - loss: 0.94116 - diff: 15.06mlTrain batch 23/32 - 236.3ms/batch - loss: 0.93246 - diff: 14.92mlTrain batch 24/32 - 237.8ms/batch - loss: 0.93371 - diff: 14.94mlTrain batch 25/32 - 234.0ms/batch - loss: 0.92892 - diff: 14.86mlTrain batch 26/32 - 241.8ms/batch - loss: 0.91349 - diff: 14.62mlTrain batch 27/32 - 242.3ms/batch - loss: 0.90787 - diff: 14.53mlTrain batch 28/32 - 234.1ms/batch - loss: 0.93460 - diff: 14.95mlTrain batch 29/32 - 234.1ms/batch - loss: 0.92024 - diff: 14.72mlTrain batch 30/32 - 235.3ms/batch - loss: 0.91700 - diff: 14.67mlTrain batch 31/32 - 234.0ms/batch - loss: 0.90649 - diff: 14.50mlTrain batch 32/32 - 84.0ms/batch - loss: 0.91296 - diff: 14.44mlTrain batch 32/32 - 16.7s 84.0ms/batch - loss: 0.91296 - diff: 14.44ml
Test 1.6s: val_loss: 1.10007 - diff: 16.87ml

Epoch 123: current best loss = 0.94355, at epoch 116
Train batch 1/32 - 234.0ms/batch - loss: 1.39128 - diff: 22.26mlTrain batch 2/32 - 236.2ms/batch - loss: 1.68263 - diff: 26.92mlTrain batch 3/32 - 233.9ms/batch - loss: 1.28392 - diff: 20.54mlTrain batch 4/32 - 234.2ms/batch - loss: 1.25314 - diff: 20.05mlTrain batch 5/32 - 234.3ms/batch - loss: 1.24141 - diff: 19.86mlTrain batch 6/32 - 234.3ms/batch - loss: 1.19897 - diff: 19.18mlTrain batch 7/32 - 233.6ms/batch - loss: 1.14665 - diff: 18.35mlTrain batch 8/32 - 238.8ms/batch - loss: 1.13523 - diff: 18.16mlTrain batch 9/32 - 233.8ms/batch - loss: 1.09111 - diff: 17.46mlTrain batch 10/32 - 234.4ms/batch - loss: 1.06175 - diff: 16.99mlTrain batch 11/32 - 234.2ms/batch - loss: 1.03236 - diff: 16.52mlTrain batch 12/32 - 238.5ms/batch - loss: 1.01236 - diff: 16.20mlTrain batch 13/32 - 234.3ms/batch - loss: 0.97220 - diff: 15.56mlTrain batch 14/32 - 233.8ms/batch - loss: 0.94995 - diff: 15.20mlTrain batch 15/32 - 240.6ms/batch - loss: 0.94983 - diff: 15.20mlTrain batch 16/32 - 236.5ms/batch - loss: 0.93705 - diff: 14.99mlTrain batch 17/32 - 234.0ms/batch - loss: 0.96129 - diff: 15.38mlTrain batch 18/32 - 234.3ms/batch - loss: 0.97977 - diff: 15.68mlTrain batch 19/32 - 247.3ms/batch - loss: 0.96778 - diff: 15.48mlTrain batch 20/32 - 233.0ms/batch - loss: 0.96858 - diff: 15.50mlTrain batch 21/32 - 234.0ms/batch - loss: 0.95498 - diff: 15.28mlTrain batch 22/32 - 234.4ms/batch - loss: 0.94924 - diff: 15.19mlTrain batch 23/32 - 234.1ms/batch - loss: 0.94371 - diff: 15.10mlTrain batch 24/32 - 239.3ms/batch - loss: 0.96150 - diff: 15.38mlTrain batch 25/32 - 234.4ms/batch - loss: 0.95270 - diff: 15.24mlTrain batch 26/32 - 234.1ms/batch - loss: 0.94832 - diff: 15.17mlTrain batch 27/32 - 234.3ms/batch - loss: 0.93410 - diff: 14.95mlTrain batch 28/32 - 237.5ms/batch - loss: 0.92976 - diff: 14.88mlTrain batch 29/32 - 234.0ms/batch - loss: 0.92464 - diff: 14.79mlTrain batch 30/32 - 233.7ms/batch - loss: 0.93003 - diff: 14.88mlTrain batch 31/32 - 234.0ms/batch - loss: 0.92527 - diff: 14.80mlTrain batch 32/32 - 79.1ms/batch - loss: 0.93708 - diff: 14.76mlTrain batch 32/32 - 17.4s 79.1ms/batch - loss: 0.93708 - diff: 14.76ml
Test 1.6s: val_loss: 1.01166 - diff: 15.54ml

Epoch 124: current best loss = 0.94355, at epoch 116
Train batch 1/32 - 241.5ms/batch - loss: 0.63340 - diff: 10.13mlTrain batch 2/32 - 234.8ms/batch - loss: 0.98473 - diff: 15.76mlTrain batch 3/32 - 233.6ms/batch - loss: 1.16343 - diff: 18.61mlTrain batch 4/32 - 253.8ms/batch - loss: 1.05033 - diff: 16.81mlTrain batch 5/32 - 233.7ms/batch - loss: 1.05332 - diff: 16.85mlTrain batch 6/32 - 234.1ms/batch - loss: 1.00832 - diff: 16.13mlTrain batch 7/32 - 233.9ms/batch - loss: 1.00083 - diff: 16.01mlTrain batch 8/32 - 233.6ms/batch - loss: 1.01155 - diff: 16.18mlTrain batch 9/32 - 234.4ms/batch - loss: 0.97459 - diff: 15.59mlTrain batch 10/32 - 233.9ms/batch - loss: 0.96439 - diff: 15.43mlTrain batch 11/32 - 238.9ms/batch - loss: 0.95129 - diff: 15.22mlTrain batch 12/32 - 233.9ms/batch - loss: 0.93840 - diff: 15.01mlTrain batch 13/32 - 234.3ms/batch - loss: 0.94371 - diff: 15.10mlTrain batch 14/32 - 233.7ms/batch - loss: 0.93830 - diff: 15.01mlTrain batch 15/32 - 234.8ms/batch - loss: 0.92564 - diff: 14.81mlTrain batch 16/32 - 234.2ms/batch - loss: 0.92339 - diff: 14.77mlTrain batch 17/32 - 234.5ms/batch - loss: 0.91434 - diff: 14.63mlTrain batch 18/32 - 233.8ms/batch - loss: 0.90511 - diff: 14.48mlTrain batch 19/32 - 234.9ms/batch - loss: 0.90383 - diff: 14.46mlTrain batch 20/32 - 234.2ms/batch - loss: 0.89377 - diff: 14.30mlTrain batch 21/32 - 234.6ms/batch - loss: 0.88875 - diff: 14.22mlTrain batch 22/32 - 234.3ms/batch - loss: 0.91091 - diff: 14.57mlTrain batch 23/32 - 234.8ms/batch - loss: 0.89923 - diff: 14.39mlTrain batch 24/32 - 234.9ms/batch - loss: 0.88197 - diff: 14.11mlTrain batch 25/32 - 234.8ms/batch - loss: 0.87461 - diff: 13.99mlTrain batch 26/32 - 234.1ms/batch - loss: 0.86912 - diff: 13.91mlTrain batch 27/32 - 238.2ms/batch - loss: 0.89026 - diff: 14.24mlTrain batch 28/32 - 240.8ms/batch - loss: 0.89899 - diff: 14.38mlTrain batch 29/32 - 234.2ms/batch - loss: 0.90314 - diff: 14.45mlTrain batch 30/32 - 234.1ms/batch - loss: 0.89994 - diff: 14.40mlTrain batch 31/32 - 234.9ms/batch - loss: 0.89885 - diff: 14.38mlTrain batch 32/32 - 83.5ms/batch - loss: 0.91678 - diff: 14.37mlTrain batch 32/32 - 16.0s 83.5ms/batch - loss: 0.91678 - diff: 14.37ml
Test 1.7s: val_loss: 0.99663 - diff: 15.53ml

Epoch 125: current best loss = 0.94355, at epoch 116
Train batch 1/32 - 233.9ms/batch - loss: 0.68260 - diff: 10.92mlTrain batch 2/32 - 234.1ms/batch - loss: 0.80243 - diff: 12.84mlTrain batch 3/32 - 244.4ms/batch - loss: 0.68511 - diff: 10.96mlTrain batch 4/32 - 244.0ms/batch - loss: 0.73874 - diff: 11.82mlTrain batch 5/32 - 234.5ms/batch - loss: 0.73017 - diff: 11.68mlTrain batch 6/32 - 234.7ms/batch - loss: 0.96475 - diff: 15.44mlTrain batch 7/32 - 233.8ms/batch - loss: 0.95062 - diff: 15.21mlTrain batch 8/32 - 234.2ms/batch - loss: 0.91944 - diff: 14.71mlTrain batch 9/32 - 234.1ms/batch - loss: 0.91991 - diff: 14.72mlTrain batch 10/32 - 234.3ms/batch - loss: 0.87975 - diff: 14.08mlTrain batch 11/32 - 233.8ms/batch - loss: 0.88045 - diff: 14.09mlTrain batch 12/32 - 234.1ms/batch - loss: 0.86132 - diff: 13.78mlTrain batch 13/32 - 234.1ms/batch - loss: 0.86321 - diff: 13.81mlTrain batch 14/32 - 234.2ms/batch - loss: 0.83203 - diff: 13.31mlTrain batch 15/32 - 234.3ms/batch - loss: 0.84336 - diff: 13.49mlTrain batch 16/32 - 234.1ms/batch - loss: 0.82895 - diff: 13.26mlTrain batch 17/32 - 234.8ms/batch - loss: 0.80960 - diff: 12.95mlTrain batch 18/32 - 234.3ms/batch - loss: 0.81175 - diff: 12.99mlTrain batch 19/32 - 237.9ms/batch - loss: 0.80305 - diff: 12.85mlTrain batch 20/32 - 234.0ms/batch - loss: 0.82186 - diff: 13.15mlTrain batch 21/32 - 234.4ms/batch - loss: 0.82840 - diff: 13.25mlTrain batch 22/32 - 234.2ms/batch - loss: 0.82607 - diff: 13.22mlTrain batch 23/32 - 234.3ms/batch - loss: 0.83620 - diff: 13.38mlTrain batch 24/32 - 234.1ms/batch - loss: 0.83738 - diff: 13.40mlTrain batch 25/32 - 245.7ms/batch - loss: 0.86315 - diff: 13.81mlTrain batch 26/32 - 233.9ms/batch - loss: 0.86845 - diff: 13.90mlTrain batch 27/32 - 245.7ms/batch - loss: 0.88164 - diff: 14.11mlTrain batch 28/32 - 233.8ms/batch - loss: 0.87822 - diff: 14.05mlTrain batch 29/32 - 259.8ms/batch - loss: 0.87057 - diff: 13.93mlTrain batch 30/32 - 233.6ms/batch - loss: 0.86723 - diff: 13.88mlTrain batch 31/32 - 234.5ms/batch - loss: 0.85743 - diff: 13.72mlTrain batch 32/32 - 76.4ms/batch - loss: 0.86992 - diff: 13.69mlTrain batch 32/32 - 16.2s 76.4ms/batch - loss: 0.86992 - diff: 13.69ml
Test 1.6s: val_loss: 1.11932 - diff: 17.21ml

Epoch 126: current best loss = 0.94355, at epoch 116
Train batch 1/32 - 233.9ms/batch - loss: 1.07052 - diff: 17.13mlTrain batch 2/32 - 233.7ms/batch - loss: 0.83658 - diff: 13.39mlTrain batch 3/32 - 234.1ms/batch - loss: 0.73557 - diff: 11.77mlTrain batch 4/32 - 234.6ms/batch - loss: 0.77060 - diff: 12.33mlTrain batch 5/32 - 233.9ms/batch - loss: 0.77369 - diff: 12.38mlTrain batch 6/32 - 238.6ms/batch - loss: 0.79856 - diff: 12.78mlTrain batch 7/32 - 234.3ms/batch - loss: 0.77339 - diff: 12.37mlTrain batch 8/32 - 234.7ms/batch - loss: 0.77390 - diff: 12.38mlTrain batch 9/32 - 233.9ms/batch - loss: 0.77793 - diff: 12.45mlTrain batch 10/32 - 235.5ms/batch - loss: 0.77294 - diff: 12.37mlTrain batch 11/32 - 234.0ms/batch - loss: 0.77797 - diff: 12.45mlTrain batch 12/32 - 234.3ms/batch - loss: 0.80846 - diff: 12.94mlTrain batch 13/32 - 234.5ms/batch - loss: 0.84829 - diff: 13.57mlTrain batch 14/32 - 233.9ms/batch - loss: 0.88374 - diff: 14.14mlTrain batch 15/32 - 234.1ms/batch - loss: 0.88493 - diff: 14.16mlTrain batch 16/32 - 233.6ms/batch - loss: 0.90425 - diff: 14.47mlTrain batch 17/32 - 234.4ms/batch - loss: 0.89606 - diff: 14.34mlTrain batch 18/32 - 234.2ms/batch - loss: 0.88809 - diff: 14.21mlTrain batch 19/32 - 238.9ms/batch - loss: 0.90152 - diff: 14.42mlTrain batch 20/32 - 234.2ms/batch - loss: 0.88486 - diff: 14.16mlTrain batch 21/32 - 234.8ms/batch - loss: 0.88800 - diff: 14.21mlTrain batch 22/32 - 233.7ms/batch - loss: 0.92200 - diff: 14.75mlTrain batch 23/32 - 234.6ms/batch - loss: 0.93679 - diff: 14.99mlTrain batch 24/32 - 237.2ms/batch - loss: 0.93503 - diff: 14.96mlTrain batch 25/32 - 234.5ms/batch - loss: 0.94178 - diff: 15.07mlTrain batch 26/32 - 248.7ms/batch - loss: 0.93980 - diff: 15.04mlTrain batch 27/32 - 234.8ms/batch - loss: 0.92580 - diff: 14.81mlTrain batch 28/32 - 233.7ms/batch - loss: 0.92331 - diff: 14.77mlTrain batch 29/32 - 234.1ms/batch - loss: 0.90833 - diff: 14.53mlTrain batch 30/32 - 234.2ms/batch - loss: 0.90460 - diff: 14.47mlTrain batch 31/32 - 234.6ms/batch - loss: 0.89898 - diff: 14.38mlTrain batch 32/32 - 77.0ms/batch - loss: 0.90229 - diff: 14.31mlTrain batch 32/32 - 17.5s 77.0ms/batch - loss: 0.90229 - diff: 14.31ml
Test 1.6s: val_loss: 0.99517 - diff: 15.31ml

Epoch 127: current best loss = 0.94355, at epoch 116
Train batch 1/32 - 233.9ms/batch - loss: 0.89535 - diff: 14.33mlTrain batch 2/32 - 235.3ms/batch - loss: 0.82140 - diff: 13.14mlTrain batch 3/32 - 234.0ms/batch - loss: 0.86990 - diff: 13.92mlTrain batch 4/32 - 233.5ms/batch - loss: 0.92964 - diff: 14.87mlTrain batch 5/32 - 233.8ms/batch - loss: 0.86664 - diff: 13.87mlTrain batch 6/32 - 234.3ms/batch - loss: 0.92665 - diff: 14.83mlTrain batch 7/32 - 234.2ms/batch - loss: 0.87839 - diff: 14.05mlTrain batch 8/32 - 234.2ms/batch - loss: 0.90851 - diff: 14.54mlTrain batch 9/32 - 233.7ms/batch - loss: 0.90480 - diff: 14.48mlTrain batch 10/32 - 234.4ms/batch - loss: 0.90991 - diff: 14.56mlTrain batch 11/32 - 234.1ms/batch - loss: 0.87555 - diff: 14.01mlTrain batch 12/32 - 239.0ms/batch - loss: 0.89819 - diff: 14.37mlTrain batch 13/32 - 236.0ms/batch - loss: 0.87152 - diff: 13.94mlTrain batch 14/32 - 249.0ms/batch - loss: 0.86747 - diff: 13.88mlTrain batch 15/32 - 233.6ms/batch - loss: 0.86160 - diff: 13.79mlTrain batch 16/32 - 235.0ms/batch - loss: 0.84734 - diff: 13.56mlTrain batch 17/32 - 234.1ms/batch - loss: 0.83846 - diff: 13.42mlTrain batch 18/32 - 234.4ms/batch - loss: 0.81874 - diff: 13.10mlTrain batch 19/32 - 233.8ms/batch - loss: 0.80619 - diff: 12.90mlTrain batch 20/32 - 234.9ms/batch - loss: 0.80839 - diff: 12.93mlTrain batch 21/32 - 233.9ms/batch - loss: 0.80637 - diff: 12.90mlTrain batch 22/32 - 233.9ms/batch - loss: 0.82205 - diff: 13.15mlTrain batch 23/32 - 233.8ms/batch - loss: 0.82389 - diff: 13.18mlTrain batch 24/32 - 250.2ms/batch - loss: 0.82939 - diff: 13.27mlTrain batch 25/32 - 233.8ms/batch - loss: 0.82057 - diff: 13.13mlTrain batch 26/32 - 235.2ms/batch - loss: 0.81919 - diff: 13.11mlTrain batch 27/32 - 233.5ms/batch - loss: 0.81949 - diff: 13.11mlTrain batch 28/32 - 234.0ms/batch - loss: 0.84553 - diff: 13.53mlTrain batch 29/32 - 233.7ms/batch - loss: 0.84984 - diff: 13.60mlTrain batch 30/32 - 234.3ms/batch - loss: 0.84810 - diff: 13.57mlTrain batch 31/32 - 234.0ms/batch - loss: 0.84890 - diff: 13.58mlTrain batch 32/32 - 76.7ms/batch - loss: 0.87194 - diff: 13.59mlTrain batch 32/32 - 17.1s 76.7ms/batch - loss: 0.87194 - diff: 13.59ml
Test 1.6s: val_loss: 1.14135 - diff: 17.58ml
Epoch   128: reducing learning rate of group 0 to 6.2500e-05.

Epoch 128: current best loss = 0.94355, at epoch 116
Train batch 1/32 - 250.0ms/batch - loss: 0.90422 - diff: 14.47mlTrain batch 2/32 - 245.0ms/batch - loss: 1.79663 - diff: 28.75mlTrain batch 3/32 - 237.4ms/batch - loss: 1.53925 - diff: 24.63mlTrain batch 4/32 - 234.7ms/batch - loss: 1.34127 - diff: 21.46mlTrain batch 5/32 - 233.9ms/batch - loss: 1.23430 - diff: 19.75mlTrain batch 6/32 - 233.8ms/batch - loss: 1.14128 - diff: 18.26mlTrain batch 7/32 - 233.9ms/batch - loss: 1.07223 - diff: 17.16mlTrain batch 8/32 - 233.7ms/batch - loss: 1.04428 - diff: 16.71mlTrain batch 9/32 - 234.1ms/batch - loss: 1.05849 - diff: 16.94mlTrain batch 10/32 - 234.1ms/batch - loss: 1.03118 - diff: 16.50mlTrain batch 11/32 - 234.0ms/batch - loss: 0.99600 - diff: 15.94mlTrain batch 12/32 - 234.1ms/batch - loss: 1.01127 - diff: 16.18mlTrain batch 13/32 - 234.3ms/batch - loss: 1.02079 - diff: 16.33mlTrain batch 14/32 - 234.2ms/batch - loss: 1.00352 - diff: 16.06mlTrain batch 15/32 - 234.3ms/batch - loss: 0.97138 - diff: 15.54mlTrain batch 16/32 - 233.9ms/batch - loss: 0.95539 - diff: 15.29mlTrain batch 17/32 - 232.9ms/batch - loss: 0.93248 - diff: 14.92mlTrain batch 18/32 - 234.7ms/batch - loss: 0.93207 - diff: 14.91mlTrain batch 19/32 - 233.0ms/batch - loss: 0.94707 - diff: 15.15mlTrain batch 20/32 - 233.8ms/batch - loss: 0.92637 - diff: 14.82mlTrain batch 21/32 - 234.5ms/batch - loss: 0.92540 - diff: 14.81mlTrain batch 22/32 - 238.8ms/batch - loss: 0.91546 - diff: 14.65mlTrain batch 23/32 - 234.1ms/batch - loss: 0.89131 - diff: 14.26mlTrain batch 24/32 - 233.5ms/batch - loss: 0.87996 - diff: 14.08mlTrain batch 25/32 - 234.8ms/batch - loss: 0.87820 - diff: 14.05mlTrain batch 26/32 - 237.4ms/batch - loss: 0.86431 - diff: 13.83mlTrain batch 27/32 - 235.1ms/batch - loss: 0.87948 - diff: 14.07mlTrain batch 28/32 - 235.1ms/batch - loss: 0.87838 - diff: 14.05mlTrain batch 29/32 - 239.9ms/batch - loss: 0.87144 - diff: 13.94mlTrain batch 30/32 - 234.1ms/batch - loss: 0.86998 - diff: 13.92mlTrain batch 31/32 - 233.3ms/batch - loss: 0.86981 - diff: 13.92mlTrain batch 32/32 - 76.6ms/batch - loss: 0.88289 - diff: 13.89mlTrain batch 32/32 - 16.9s 76.6ms/batch - loss: 0.88289 - diff: 13.89ml
Test 1.5s: val_loss: 0.94807 - diff: 14.71ml

Epoch 129: current best loss = 0.94355, at epoch 116
Train batch 1/32 - 233.9ms/batch - loss: 0.63298 - diff: 10.13mlTrain batch 2/32 - 234.0ms/batch - loss: 0.61211 - diff: 9.79mlTrain batch 3/32 - 234.0ms/batch - loss: 0.70363 - diff: 11.26mlTrain batch 4/32 - 234.5ms/batch - loss: 0.86183 - diff: 13.79mlTrain batch 5/32 - 234.0ms/batch - loss: 0.85002 - diff: 13.60mlTrain batch 6/32 - 237.7ms/batch - loss: 0.88010 - diff: 14.08mlTrain batch 7/32 - 234.1ms/batch - loss: 0.82584 - diff: 13.21mlTrain batch 8/32 - 234.9ms/batch - loss: 0.90165 - diff: 14.43mlTrain batch 9/32 - 234.0ms/batch - loss: 0.85028 - diff: 13.60mlTrain batch 10/32 - 234.2ms/batch - loss: 0.83172 - diff: 13.31mlTrain batch 11/32 - 234.0ms/batch - loss: 0.80314 - diff: 12.85mlTrain batch 12/32 - 238.0ms/batch - loss: 0.81147 - diff: 12.98mlTrain batch 13/32 - 233.8ms/batch - loss: 0.82459 - diff: 13.19mlTrain batch 14/32 - 233.8ms/batch - loss: 0.82842 - diff: 13.25mlTrain batch 15/32 - 234.2ms/batch - loss: 0.82720 - diff: 13.24mlTrain batch 16/32 - 238.1ms/batch - loss: 0.80352 - diff: 12.86mlTrain batch 17/32 - 240.2ms/batch - loss: 0.79138 - diff: 12.66mlTrain batch 18/32 - 234.4ms/batch - loss: 0.81521 - diff: 13.04mlTrain batch 19/32 - 234.1ms/batch - loss: 0.83129 - diff: 13.30mlTrain batch 20/32 - 234.2ms/batch - loss: 0.82667 - diff: 13.23mlTrain batch 21/32 - 235.8ms/batch - loss: 0.85070 - diff: 13.61mlTrain batch 22/32 - 234.4ms/batch - loss: 0.83745 - diff: 13.40mlTrain batch 23/32 - 233.7ms/batch - loss: 0.86319 - diff: 13.81mlTrain batch 24/32 - 234.2ms/batch - loss: 0.86376 - diff: 13.82mlTrain batch 25/32 - 233.6ms/batch - loss: 0.85658 - diff: 13.71mlTrain batch 26/32 - 239.0ms/batch - loss: 0.85600 - diff: 13.70mlTrain batch 27/32 - 233.7ms/batch - loss: 0.85839 - diff: 13.73mlTrain batch 28/32 - 234.3ms/batch - loss: 0.85453 - diff: 13.67mlTrain batch 29/32 - 233.7ms/batch - loss: 0.88971 - diff: 14.24mlTrain batch 30/32 - 234.1ms/batch - loss: 0.88142 - diff: 14.10mlTrain batch 31/32 - 233.9ms/batch - loss: 0.87507 - diff: 14.00mlTrain batch 32/32 - 81.3ms/batch - loss: 0.88014 - diff: 13.94mlTrain batch 32/32 - 17.8s 81.3ms/batch - loss: 0.88014 - diff: 13.94ml
Test 1.6s: val_loss: 0.99216 - diff: 15.56ml

Epoch 130: current best loss = 0.94355, at epoch 116
Train batch 1/32 - 234.3ms/batch - loss: 1.20310 - diff: 19.25mlTrain batch 2/32 - 234.1ms/batch - loss: 0.89845 - diff: 14.38mlTrain batch 3/32 - 234.1ms/batch - loss: 0.86939 - diff: 13.91mlTrain batch 4/32 - 234.5ms/batch - loss: 0.84620 - diff: 13.54mlTrain batch 5/32 - 233.8ms/batch - loss: 0.86623 - diff: 13.86mlTrain batch 6/32 - 234.4ms/batch - loss: 0.85070 - diff: 13.61mlTrain batch 7/32 - 234.0ms/batch - loss: 0.91071 - diff: 14.57mlTrain batch 8/32 - 233.6ms/batch - loss: 1.11649 - diff: 17.86mlTrain batch 9/32 - 234.3ms/batch - loss: 1.07326 - diff: 17.17mlTrain batch 10/32 - 234.6ms/batch - loss: 1.04228 - diff: 16.68mlTrain batch 11/32 - 234.1ms/batch - loss: 1.01819 - diff: 16.29mlTrain batch 12/32 - 234.3ms/batch - loss: 0.98385 - diff: 15.74mlTrain batch 13/32 - 233.7ms/batch - loss: 0.95842 - diff: 15.33mlTrain batch 14/32 - 234.5ms/batch - loss: 0.93316 - diff: 14.93mlTrain batch 15/32 - 233.9ms/batch - loss: 0.92225 - diff: 14.76mlTrain batch 16/32 - 238.3ms/batch - loss: 0.91654 - diff: 14.66mlTrain batch 17/32 - 234.2ms/batch - loss: 0.92804 - diff: 14.85mlTrain batch 18/32 - 234.5ms/batch - loss: 0.92150 - diff: 14.74mlTrain batch 19/32 - 234.3ms/batch - loss: 0.90015 - diff: 14.40mlTrain batch 20/32 - 234.4ms/batch - loss: 0.89169 - diff: 14.27mlTrain batch 21/32 - 233.7ms/batch - loss: 0.88797 - diff: 14.21mlTrain batch 22/32 - 234.4ms/batch - loss: 0.88268 - diff: 14.12mlTrain batch 23/32 - 233.6ms/batch - loss: 0.87918 - diff: 14.07mlTrain batch 24/32 - 234.3ms/batch - loss: 0.87150 - diff: 13.94mlTrain batch 25/32 - 233.8ms/batch - loss: 0.86335 - diff: 13.81mlTrain batch 26/32 - 234.1ms/batch - loss: 0.85563 - diff: 13.69mlTrain batch 27/32 - 239.5ms/batch - loss: 0.84915 - diff: 13.59mlTrain batch 28/32 - 234.5ms/batch - loss: 0.83978 - diff: 13.44mlTrain batch 29/32 - 233.7ms/batch - loss: 0.84419 - diff: 13.51mlTrain batch 30/32 - 250.1ms/batch - loss: 0.86886 - diff: 13.90mlTrain batch 31/32 - 233.6ms/batch - loss: 0.86776 - diff: 13.88mlTrain batch 32/32 - 76.6ms/batch - loss: 0.89360 - diff: 13.90mlTrain batch 32/32 - 16.4s 76.6ms/batch - loss: 0.89360 - diff: 13.90ml
Test 1.6s: val_loss: 0.95831 - diff: 14.91ml

Epoch 131: current best loss = 0.94355, at epoch 116
Train batch 1/32 - 233.7ms/batch - loss: 0.90066 - diff: 14.41mlTrain batch 2/32 - 234.1ms/batch - loss: 0.75860 - diff: 12.14mlTrain batch 3/32 - 234.1ms/batch - loss: 0.79428 - diff: 12.71mlTrain batch 4/32 - 233.9ms/batch - loss: 0.71874 - diff: 11.50mlTrain batch 5/32 - 234.2ms/batch - loss: 0.69195 - diff: 11.07mlTrain batch 6/32 - 234.3ms/batch - loss: 0.74210 - diff: 11.87mlTrain batch 7/32 - 237.1ms/batch - loss: 0.75012 - diff: 12.00mlTrain batch 8/32 - 234.2ms/batch - loss: 0.91823 - diff: 14.69mlTrain batch 9/32 - 233.9ms/batch - loss: 1.01087 - diff: 16.17mlTrain batch 10/32 - 237.4ms/batch - loss: 0.98271 - diff: 15.72mlTrain batch 11/32 - 233.9ms/batch - loss: 0.94941 - diff: 15.19mlTrain batch 12/32 - 234.2ms/batch - loss: 0.91700 - diff: 14.67mlTrain batch 13/32 - 233.7ms/batch - loss: 0.90958 - diff: 14.55mlTrain batch 14/32 - 234.4ms/batch - loss: 0.89369 - diff: 14.30mlTrain batch 15/32 - 234.2ms/batch - loss: 0.89620 - diff: 14.34mlTrain batch 16/32 - 234.2ms/batch - loss: 0.88143 - diff: 14.10mlTrain batch 17/32 - 234.0ms/batch - loss: 0.89049 - diff: 14.25mlTrain batch 18/32 - 234.3ms/batch - loss: 0.88143 - diff: 14.10mlTrain batch 19/32 - 234.3ms/batch - loss: 0.87868 - diff: 14.06mlTrain batch 20/32 - 234.1ms/batch - loss: 0.87074 - diff: 13.93mlTrain batch 21/32 - 237.6ms/batch - loss: 0.86448 - diff: 13.83mlTrain batch 22/32 - 237.2ms/batch - loss: 0.86818 - diff: 13.89mlTrain batch 23/32 - 234.2ms/batch - loss: 0.87424 - diff: 13.99mlTrain batch 24/32 - 234.0ms/batch - loss: 0.87651 - diff: 14.02mlTrain batch 25/32 - 233.8ms/batch - loss: 0.88578 - diff: 14.17mlTrain batch 26/32 - 234.1ms/batch - loss: 0.87926 - diff: 14.07mlTrain batch 27/32 - 234.0ms/batch - loss: 0.87132 - diff: 13.94mlTrain batch 28/32 - 234.7ms/batch - loss: 0.85476 - diff: 13.68mlTrain batch 29/32 - 234.3ms/batch - loss: 0.85014 - diff: 13.60mlTrain batch 30/32 - 233.4ms/batch - loss: 0.83585 - diff: 13.37mlTrain batch 31/32 - 233.9ms/batch - loss: 0.82965 - diff: 13.27mlTrain batch 32/32 - 76.6ms/batch - loss: 0.86872 - diff: 13.35mlTrain batch 32/32 - 16.2s 76.6ms/batch - loss: 0.86872 - diff: 13.35ml
Test 1.5s: val_loss: 1.00188 - diff: 15.67ml

Epoch 132: current best loss = 0.94355, at epoch 116
Train batch 1/32 - 248.5ms/batch - loss: 0.98668 - diff: 15.79mlTrain batch 2/32 - 234.5ms/batch - loss: 0.74315 - diff: 11.89mlTrain batch 3/32 - 234.0ms/batch - loss: 0.67887 - diff: 10.86mlTrain batch 4/32 - 234.4ms/batch - loss: 0.72756 - diff: 11.64mlTrain batch 5/32 - 234.1ms/batch - loss: 0.69454 - diff: 11.11mlTrain batch 6/32 - 234.2ms/batch - loss: 0.70426 - diff: 11.27mlTrain batch 7/32 - 233.8ms/batch - loss: 0.77006 - diff: 12.32mlTrain batch 8/32 - 234.1ms/batch - loss: 0.76389 - diff: 12.22mlTrain batch 9/32 - 233.6ms/batch - loss: 0.76793 - diff: 12.29mlTrain batch 10/32 - 234.6ms/batch - loss: 0.81043 - diff: 12.97mlTrain batch 11/32 - 233.9ms/batch - loss: 0.79765 - diff: 12.76mlTrain batch 12/32 - 238.9ms/batch - loss: 0.78635 - diff: 12.58mlTrain batch 13/32 - 234.3ms/batch - loss: 0.83245 - diff: 13.32mlTrain batch 14/32 - 234.1ms/batch - loss: 0.80862 - diff: 12.94mlTrain batch 15/32 - 234.1ms/batch - loss: 0.85374 - diff: 13.66mlTrain batch 16/32 - 234.2ms/batch - loss: 0.83504 - diff: 13.36mlTrain batch 17/32 - 234.0ms/batch - loss: 0.81913 - diff: 13.11mlTrain batch 18/32 - 234.0ms/batch - loss: 0.82872 - diff: 13.26mlTrain batch 19/32 - 233.9ms/batch - loss: 0.83354 - diff: 13.34mlTrain batch 20/32 - 234.0ms/batch - loss: 0.81714 - diff: 13.07mlTrain batch 21/32 - 233.9ms/batch - loss: 0.80539 - diff: 12.89mlTrain batch 22/32 - 234.0ms/batch - loss: 0.80370 - diff: 12.86mlTrain batch 23/32 - 234.0ms/batch - loss: 0.79555 - diff: 12.73mlTrain batch 24/32 - 234.3ms/batch - loss: 0.79374 - diff: 12.70mlTrain batch 25/32 - 233.7ms/batch - loss: 0.78743 - diff: 12.60mlTrain batch 26/32 - 234.3ms/batch - loss: 0.77939 - diff: 12.47mlTrain batch 27/32 - 233.6ms/batch - loss: 0.79823 - diff: 12.77mlTrain batch 28/32 - 234.9ms/batch - loss: 0.79455 - diff: 12.71mlTrain batch 29/32 - 243.4ms/batch - loss: 0.79681 - diff: 12.75mlTrain batch 30/32 - 234.2ms/batch - loss: 0.81627 - diff: 13.06mlTrain batch 31/32 - 233.6ms/batch - loss: 0.82411 - diff: 13.19mlTrain batch 32/32 - 84.4ms/batch - loss: 0.86617 - diff: 13.27mlTrain batch 32/32 - 18.2s 84.4ms/batch - loss: 0.86617 - diff: 13.27ml
Test 1.7s: val_loss: 1.07535 - diff: 16.09ml

Epoch 133: current best loss = 0.94355, at epoch 116
Train batch 1/32 - 233.7ms/batch - loss: 0.76096 - diff: 12.18mlTrain batch 2/32 - 237.0ms/batch - loss: 0.66848 - diff: 10.70mlTrain batch 3/32 - 234.2ms/batch - loss: 0.70762 - diff: 11.32mlTrain batch 4/32 - 234.1ms/batch - loss: 0.72135 - diff: 11.54mlTrain batch 5/32 - 235.7ms/batch - loss: 0.97331 - diff: 15.57mlTrain batch 6/32 - 239.6ms/batch - loss: 0.90607 - diff: 14.50mlTrain batch 7/32 - 233.5ms/batch - loss: 1.03150 - diff: 16.50mlTrain batch 8/32 - 238.1ms/batch - loss: 1.00299 - diff: 16.05mlTrain batch 9/32 - 234.2ms/batch - loss: 1.00394 - diff: 16.06mlTrain batch 10/32 - 246.3ms/batch - loss: 0.97221 - diff: 15.56mlTrain batch 11/32 - 233.6ms/batch - loss: 0.94604 - diff: 15.14mlTrain batch 12/32 - 234.8ms/batch - loss: 0.92746 - diff: 14.84mlTrain batch 13/32 - 234.1ms/batch - loss: 0.90268 - diff: 14.44mlTrain batch 14/32 - 234.5ms/batch - loss: 0.94156 - diff: 15.07mlTrain batch 15/32 - 234.3ms/batch - loss: 0.92513 - diff: 14.80mlTrain batch 16/32 - 234.4ms/batch - loss: 0.92999 - diff: 14.88mlTrain batch 17/32 - 234.1ms/batch - loss: 0.92657 - diff: 14.83mlTrain batch 18/32 - 233.4ms/batch - loss: 0.91899 - diff: 14.70mlTrain batch 19/32 - 233.6ms/batch - loss: 0.91889 - diff: 14.70mlTrain batch 20/32 - 234.6ms/batch - loss: 0.91244 - diff: 14.60mlTrain batch 21/32 - 234.1ms/batch - loss: 0.90682 - diff: 14.51mlTrain batch 22/32 - 234.9ms/batch - loss: 0.89881 - diff: 14.38mlTrain batch 23/32 - 233.9ms/batch - loss: 0.89695 - diff: 14.35mlTrain batch 24/32 - 234.8ms/batch - loss: 0.90388 - diff: 14.46mlTrain batch 25/32 - 240.8ms/batch - loss: 0.89105 - diff: 14.26mlTrain batch 26/32 - 234.2ms/batch - loss: 0.89881 - diff: 14.38mlTrain batch 27/32 - 234.0ms/batch - loss: 0.88693 - diff: 14.19mlTrain batch 28/32 - 240.0ms/batch - loss: 0.89405 - diff: 14.30mlTrain batch 29/32 - 234.2ms/batch - loss: 0.88998 - diff: 14.24mlTrain batch 30/32 - 238.8ms/batch - loss: 0.89503 - diff: 14.32mlTrain batch 31/32 - 234.0ms/batch - loss: 0.88017 - diff: 14.08mlTrain batch 32/32 - 76.6ms/batch - loss: 0.93461 - diff: 14.22mlTrain batch 32/32 - 16.3s 76.6ms/batch - loss: 0.93461 - diff: 14.22ml
Test 1.6s: val_loss: 0.95641 - diff: 14.74ml

Epoch 134: current best loss = 0.94355, at epoch 116
Train batch 1/32 - 248.5ms/batch - loss: 0.59457 - diff: 9.51mlTrain batch 2/32 - 238.4ms/batch - loss: 0.74432 - diff: 11.91mlTrain batch 3/32 - 233.9ms/batch - loss: 0.66539 - diff: 10.65mlTrain batch 4/32 - 233.8ms/batch - loss: 0.85374 - diff: 13.66mlTrain batch 5/32 - 234.1ms/batch - loss: 0.84044 - diff: 13.45mlTrain batch 6/32 - 234.2ms/batch - loss: 0.78964 - diff: 12.63mlTrain batch 7/32 - 245.1ms/batch - loss: 0.74226 - diff: 11.88mlTrain batch 8/32 - 234.6ms/batch - loss: 0.74574 - diff: 11.93mlTrain batch 9/32 - 233.9ms/batch - loss: 0.73897 - diff: 11.82mlTrain batch 10/32 - 236.1ms/batch - loss: 0.74979 - diff: 12.00mlTrain batch 11/32 - 234.2ms/batch - loss: 0.80116 - diff: 12.82mlTrain batch 12/32 - 234.5ms/batch - loss: 0.81041 - diff: 12.97mlTrain batch 13/32 - 234.3ms/batch - loss: 0.81871 - diff: 13.10mlTrain batch 14/32 - 233.4ms/batch - loss: 0.83183 - diff: 13.31mlTrain batch 15/32 - 234.2ms/batch - loss: 0.85353 - diff: 13.66mlTrain batch 16/32 - 238.1ms/batch - loss: 0.85004 - diff: 13.60mlTrain batch 17/32 - 233.5ms/batch - loss: 0.83439 - diff: 13.35mlTrain batch 18/32 - 233.9ms/batch - loss: 0.84585 - diff: 13.53mlTrain batch 19/32 - 233.6ms/batch - loss: 0.84269 - diff: 13.48mlTrain batch 20/32 - 234.2ms/batch - loss: 0.83509 - diff: 13.36mlTrain batch 21/32 - 233.7ms/batch - loss: 0.83114 - diff: 13.30mlTrain batch 22/32 - 234.1ms/batch - loss: 0.85916 - diff: 13.75mlTrain batch 23/32 - 233.6ms/batch - loss: 0.85253 - diff: 13.64mlTrain batch 24/32 - 238.2ms/batch - loss: 0.84245 - diff: 13.48mlTrain batch 25/32 - 234.0ms/batch - loss: 0.84858 - diff: 13.58mlTrain batch 26/32 - 233.9ms/batch - loss: 0.84440 - diff: 13.51mlTrain batch 27/32 - 249.3ms/batch - loss: 0.84416 - diff: 13.51mlTrain batch 28/32 - 234.3ms/batch - loss: 0.83416 - diff: 13.35mlTrain batch 29/32 - 233.6ms/batch - loss: 0.83432 - diff: 13.35mlTrain batch 30/32 - 234.0ms/batch - loss: 0.83481 - diff: 13.36mlTrain batch 31/32 - 234.0ms/batch - loss: 0.83179 - diff: 13.31mlTrain batch 32/32 - 76.6ms/batch - loss: 0.84653 - diff: 13.29mlTrain batch 32/32 - 18.6s 76.6ms/batch - loss: 0.84653 - diff: 13.29ml
Test 1.7s: val_loss: 0.98056 - diff: 15.18ml

Epoch 135: current best loss = 0.94355, at epoch 116
Train batch 1/32 - 233.7ms/batch - loss: 0.85205 - diff: 13.63mlTrain batch 2/32 - 234.5ms/batch - loss: 0.97252 - diff: 15.56mlTrain batch 3/32 - 233.8ms/batch - loss: 0.83341 - diff: 13.33mlTrain batch 4/32 - 234.3ms/batch - loss: 0.92191 - diff: 14.75mlTrain batch 5/32 - 233.7ms/batch - loss: 0.83775 - diff: 13.40mlTrain batch 6/32 - 234.7ms/batch - loss: 0.82205 - diff: 13.15mlTrain batch 7/32 - 234.0ms/batch - loss: 0.81372 - diff: 13.02mlTrain batch 8/32 - 238.4ms/batch - loss: 0.80959 - diff: 12.95mlTrain batch 9/32 - 234.1ms/batch - loss: 0.79920 - diff: 12.79mlTrain batch 10/32 - 234.3ms/batch - loss: 0.77530 - diff: 12.40mlTrain batch 11/32 - 233.8ms/batch - loss: 0.80630 - diff: 12.90mlTrain batch 12/32 - 234.7ms/batch - loss: 0.77770 - diff: 12.44mlTrain batch 13/32 - 234.2ms/batch - loss: 0.77641 - diff: 12.42mlTrain batch 14/32 - 238.3ms/batch - loss: 0.78212 - diff: 12.51mlTrain batch 15/32 - 233.5ms/batch - loss: 0.77029 - diff: 12.32mlTrain batch 16/32 - 234.8ms/batch - loss: 0.77005 - diff: 12.32mlTrain batch 17/32 - 233.7ms/batch - loss: 0.77335 - diff: 12.37mlTrain batch 18/32 - 234.3ms/batch - loss: 0.78884 - diff: 12.62mlTrain batch 19/32 - 233.5ms/batch - loss: 0.79620 - diff: 12.74mlTrain batch 20/32 - 234.2ms/batch - loss: 0.78455 - diff: 12.55mlTrain batch 21/32 - 233.7ms/batch - loss: 0.79958 - diff: 12.79mlTrain batch 22/32 - 234.7ms/batch - loss: 0.78403 - diff: 12.54mlTrain batch 23/32 - 233.6ms/batch - loss: 0.78256 - diff: 12.52mlTrain batch 24/32 - 238.8ms/batch - loss: 0.79002 - diff: 12.64mlTrain batch 25/32 - 233.6ms/batch - loss: 0.82120 - diff: 13.14mlTrain batch 26/32 - 234.0ms/batch - loss: 0.81523 - diff: 13.04mlTrain batch 27/32 - 234.0ms/batch - loss: 0.80154 - diff: 12.82mlTrain batch 28/32 - 234.9ms/batch - loss: 0.79263 - diff: 12.68mlTrain batch 29/32 - 233.9ms/batch - loss: 0.79386 - diff: 12.70mlTrain batch 30/32 - 233.2ms/batch - loss: 0.79020 - diff: 12.64mlTrain batch 31/32 - 233.8ms/batch - loss: 0.79012 - diff: 12.64mlTrain batch 32/32 - 76.5ms/batch - loss: 0.87036 - diff: 12.89mlTrain batch 32/32 - 17.5s 76.5ms/batch - loss: 0.87036 - diff: 12.89ml
Test 1.7s: val_loss: 0.98978 - diff: 15.20ml

Epoch 136: current best loss = 0.94355, at epoch 116
Train batch 1/32 - 233.9ms/batch - loss: 0.60807 - diff: 9.73mlTrain batch 2/32 - 233.8ms/batch - loss: 0.90335 - diff: 14.45mlTrain batch 3/32 - 233.9ms/batch - loss: 0.74132 - diff: 11.86mlTrain batch 4/32 - 233.9ms/batch - loss: 0.70782 - diff: 11.33mlTrain batch 5/32 - 234.1ms/batch - loss: 0.69364 - diff: 11.10mlTrain batch 6/32 - 233.9ms/batch - loss: 0.82144 - diff: 13.14mlTrain batch 7/32 - 237.6ms/batch - loss: 0.84947 - diff: 13.59mlTrain batch 8/32 - 234.1ms/batch - loss: 0.84515 - diff: 13.52mlTrain batch 9/32 - 237.9ms/batch - loss: 0.80345 - diff: 12.86mlTrain batch 10/32 - 236.8ms/batch - loss: 0.81933 - diff: 13.11mlTrain batch 11/32 - 233.7ms/batch - loss: 0.82997 - diff: 13.28mlTrain batch 12/32 - 234.2ms/batch - loss: 0.83065 - diff: 13.29mlTrain batch 13/32 - 235.6ms/batch - loss: 0.81867 - diff: 13.10mlTrain batch 14/32 - 234.3ms/batch - loss: 0.81667 - diff: 13.07mlTrain batch 15/32 - 234.3ms/batch - loss: 0.80119 - diff: 12.82mlTrain batch 16/32 - 233.9ms/batch - loss: 0.78544 - diff: 12.57mlTrain batch 17/32 - 234.1ms/batch - loss: 0.79250 - diff: 12.68mlTrain batch 18/32 - 233.9ms/batch - loss: 0.77298 - diff: 12.37mlTrain batch 19/32 - 234.1ms/batch - loss: 0.78908 - diff: 12.63mlTrain batch 20/32 - 234.8ms/batch - loss: 0.78393 - diff: 12.54mlTrain batch 21/32 - 234.1ms/batch - loss: 0.77191 - diff: 12.35mlTrain batch 22/32 - 233.9ms/batch - loss: 0.78022 - diff: 12.48mlTrain batch 23/32 - 233.9ms/batch - loss: 0.78664 - diff: 12.59mlTrain batch 24/32 - 234.5ms/batch - loss: 0.78531 - diff: 12.56mlTrain batch 25/32 - 233.9ms/batch - loss: 0.77478 - diff: 12.40mlTrain batch 26/32 - 233.8ms/batch - loss: 0.76416 - diff: 12.23mlTrain batch 27/32 - 233.8ms/batch - loss: 0.75762 - diff: 12.12mlTrain batch 28/32 - 233.7ms/batch - loss: 0.75621 - diff: 12.10mlTrain batch 29/32 - 234.2ms/batch - loss: 0.75315 - diff: 12.05mlTrain batch 30/32 - 234.1ms/batch - loss: 0.75004 - diff: 12.00mlTrain batch 31/32 - 233.6ms/batch - loss: 0.76316 - diff: 12.21mlTrain batch 32/32 - 76.1ms/batch - loss: 0.78707 - diff: 12.23mlTrain batch 32/32 - 17.1s 76.1ms/batch - loss: 0.78707 - diff: 12.23ml
Test 1.6s: val_loss: 1.07000 - diff: 16.36ml

Epoch 137: current best loss = 0.94355, at epoch 116
Train batch 1/32 - 234.0ms/batch - loss: 1.39464 - diff: 22.31mlTrain batch 2/32 - 238.1ms/batch - loss: 1.60375 - diff: 25.66mlTrain batch 3/32 - 233.9ms/batch - loss: 1.31652 - diff: 21.06mlTrain batch 4/32 - 234.1ms/batch - loss: 1.15012 - diff: 18.40mlTrain batch 5/32 - 234.0ms/batch - loss: 1.05382 - diff: 16.86mlTrain batch 6/32 - 233.7ms/batch - loss: 1.02950 - diff: 16.47mlTrain batch 7/32 - 233.7ms/batch - loss: 0.97617 - diff: 15.62mlTrain batch 8/32 - 237.5ms/batch - loss: 0.96177 - diff: 15.39mlTrain batch 9/32 - 233.7ms/batch - loss: 0.96967 - diff: 15.51mlTrain batch 10/32 - 237.7ms/batch - loss: 0.96451 - diff: 15.43mlTrain batch 11/32 - 233.9ms/batch - loss: 0.96241 - diff: 15.40mlTrain batch 12/32 - 233.9ms/batch - loss: 0.94874 - diff: 15.18mlTrain batch 13/32 - 233.7ms/batch - loss: 0.93415 - diff: 14.95mlTrain batch 14/32 - 245.7ms/batch - loss: 0.93493 - diff: 14.96mlTrain batch 15/32 - 234.1ms/batch - loss: 0.91244 - diff: 14.60mlTrain batch 16/32 - 236.4ms/batch - loss: 0.92842 - diff: 14.85mlTrain batch 17/32 - 234.4ms/batch - loss: 0.91612 - diff: 14.66mlTrain batch 18/32 - 233.5ms/batch - loss: 0.90868 - diff: 14.54mlTrain batch 19/32 - 233.8ms/batch - loss: 0.91435 - diff: 14.63mlTrain batch 20/32 - 234.3ms/batch - loss: 0.88678 - diff: 14.19mlTrain batch 21/32 - 236.0ms/batch - loss: 0.90249 - diff: 14.44mlTrain batch 22/32 - 234.8ms/batch - loss: 0.89538 - diff: 14.33mlTrain batch 23/32 - 233.8ms/batch - loss: 0.87820 - diff: 14.05mlTrain batch 24/32 - 233.2ms/batch - loss: 0.86527 - diff: 13.84mlTrain batch 25/32 - 234.1ms/batch - loss: 0.86295 - diff: 13.81mlTrain batch 26/32 - 249.4ms/batch - loss: 0.86726 - diff: 13.88mlTrain batch 27/32 - 234.1ms/batch - loss: 0.86899 - diff: 13.90mlTrain batch 28/32 - 233.6ms/batch - loss: 0.86909 - diff: 13.91mlTrain batch 29/32 - 233.8ms/batch - loss: 0.87735 - diff: 14.04mlTrain batch 30/32 - 234.6ms/batch - loss: 0.87228 - diff: 13.96mlTrain batch 31/32 - 234.0ms/batch - loss: 0.87004 - diff: 13.92mlTrain batch 32/32 - 76.4ms/batch - loss: 0.88671 - diff: 13.90mlTrain batch 32/32 - 17.5s 76.4ms/batch - loss: 0.88671 - diff: 13.90ml
Test 1.6s: val_loss: 1.00556 - diff: 15.60ml

Epoch 138: current best loss = 0.94355, at epoch 116
Train batch 1/32 - 233.8ms/batch - loss: 0.93668 - diff: 14.99mlTrain batch 2/32 - 234.1ms/batch - loss: 0.80405 - diff: 12.86mlTrain batch 3/32 - 243.2ms/batch - loss: 0.86123 - diff: 13.78mlTrain batch 4/32 - 234.5ms/batch - loss: 0.83693 - diff: 13.39mlTrain batch 5/32 - 234.0ms/batch - loss: 0.94923 - diff: 15.19mlTrain batch 6/32 - 234.3ms/batch - loss: 0.88482 - diff: 14.16mlTrain batch 7/32 - 233.9ms/batch - loss: 0.84968 - diff: 13.59mlTrain batch 8/32 - 234.0ms/batch - loss: 0.82994 - diff: 13.28mlTrain batch 9/32 - 233.7ms/batch - loss: 0.86509 - diff: 13.84mlTrain batch 10/32 - 234.4ms/batch - loss: 0.90251 - diff: 14.44mlTrain batch 11/32 - 233.9ms/batch - loss: 0.90502 - diff: 14.48mlTrain batch 12/32 - 236.9ms/batch - loss: 0.87413 - diff: 13.99mlTrain batch 13/32 - 236.3ms/batch - loss: 0.86128 - diff: 13.78mlTrain batch 14/32 - 239.8ms/batch - loss: 0.83092 - diff: 13.29mlTrain batch 15/32 - 233.5ms/batch - loss: 0.81882 - diff: 13.10mlTrain batch 16/32 - 234.5ms/batch - loss: 0.80825 - diff: 12.93mlTrain batch 17/32 - 234.0ms/batch - loss: 0.79687 - diff: 12.75mlTrain batch 18/32 - 234.5ms/batch - loss: 0.77753 - diff: 12.44mlTrain batch 19/32 - 233.6ms/batch - loss: 0.77231 - diff: 12.36mlTrain batch 20/32 - 234.4ms/batch - loss: 0.76602 - diff: 12.26mlTrain batch 21/32 - 234.0ms/batch - loss: 0.76383 - diff: 12.22mlTrain batch 22/32 - 234.2ms/batch - loss: 0.75771 - diff: 12.12mlTrain batch 23/32 - 233.7ms/batch - loss: 0.75130 - diff: 12.02mlTrain batch 24/32 - 233.8ms/batch - loss: 0.76354 - diff: 12.22mlTrain batch 25/32 - 233.6ms/batch - loss: 0.75466 - diff: 12.07mlTrain batch 26/32 - 233.9ms/batch - loss: 0.76806 - diff: 12.29mlTrain batch 27/32 - 233.5ms/batch - loss: 0.77343 - diff: 12.37mlTrain batch 28/32 - 233.9ms/batch - loss: 0.77608 - diff: 12.42mlTrain batch 29/32 - 234.0ms/batch - loss: 0.77029 - diff: 12.32mlTrain batch 30/32 - 234.2ms/batch - loss: 0.77149 - diff: 12.34mlTrain batch 31/32 - 234.3ms/batch - loss: 0.77721 - diff: 12.44mlTrain batch 32/32 - 76.6ms/batch - loss: 0.97703 - diff: 13.16mlTrain batch 32/32 - 16.5s 76.6ms/batch - loss: 0.97703 - diff: 13.16ml
Test 1.6s: val_loss: 0.98936 - diff: 15.22ml
Epoch   139: reducing learning rate of group 0 to 3.1250e-05.

Epoch 139: current best loss = 0.94355, at epoch 116
Train batch 1/32 - 234.0ms/batch - loss: 0.77280 - diff: 12.36mlTrain batch 2/32 - 234.7ms/batch - loss: 0.78051 - diff: 12.49mlTrain batch 3/32 - 233.7ms/batch - loss: 0.79109 - diff: 12.66mlTrain batch 4/32 - 234.0ms/batch - loss: 0.70828 - diff: 11.33mlTrain batch 5/32 - 233.9ms/batch - loss: 0.76235 - diff: 12.20mlTrain batch 6/32 - 238.4ms/batch - loss: 0.76685 - diff: 12.27mlTrain batch 7/32 - 233.6ms/batch - loss: 0.80180 - diff: 12.83mlTrain batch 8/32 - 234.2ms/batch - loss: 0.80371 - diff: 12.86mlTrain batch 9/32 - 233.9ms/batch - loss: 0.79506 - diff: 12.72mlTrain batch 10/32 - 233.8ms/batch - loss: 0.81912 - diff: 13.11mlTrain batch 11/32 - 233.5ms/batch - loss: 0.80951 - diff: 12.95mlTrain batch 12/32 - 234.6ms/batch - loss: 0.79811 - diff: 12.77mlTrain batch 13/32 - 234.0ms/batch - loss: 0.78365 - diff: 12.54mlTrain batch 14/32 - 234.1ms/batch - loss: 0.76043 - diff: 12.17mlTrain batch 15/32 - 233.7ms/batch - loss: 0.74417 - diff: 11.91mlTrain batch 16/32 - 233.6ms/batch - loss: 0.74282 - diff: 11.89mlTrain batch 17/32 - 233.9ms/batch - loss: 0.74583 - diff: 11.93mlTrain batch 18/32 - 234.3ms/batch - loss: 0.75696 - diff: 12.11mlTrain batch 19/32 - 234.1ms/batch - loss: 0.76696 - diff: 12.27mlTrain batch 20/32 - 233.9ms/batch - loss: 0.75505 - diff: 12.08mlTrain batch 21/32 - 233.7ms/batch - loss: 0.75147 - diff: 12.02mlTrain batch 22/32 - 234.9ms/batch - loss: 0.74701 - diff: 11.95mlTrain batch 23/32 - 233.7ms/batch - loss: 0.75060 - diff: 12.01mlTrain batch 24/32 - 234.0ms/batch - loss: 0.75987 - diff: 12.16mlTrain batch 25/32 - 234.3ms/batch - loss: 0.79435 - diff: 12.71mlTrain batch 26/32 - 234.1ms/batch - loss: 0.79007 - diff: 12.64mlTrain batch 27/32 - 234.2ms/batch - loss: 0.78540 - diff: 12.57mlTrain batch 28/32 - 234.0ms/batch - loss: 0.80117 - diff: 12.82mlTrain batch 29/32 - 251.7ms/batch - loss: 0.80159 - diff: 12.83mlTrain batch 30/32 - 233.9ms/batch - loss: 0.79582 - diff: 12.73mlTrain batch 31/32 - 234.0ms/batch - loss: 0.79321 - diff: 12.69mlTrain batch 32/32 - 84.6ms/batch - loss: 0.80848 - diff: 12.68mlTrain batch 32/32 - 16.7s 84.6ms/batch - loss: 0.80848 - diff: 12.68ml
Test 1.7s: val_loss: 1.00331 - diff: 15.48ml

Epoch 140: current best loss = 0.94355, at epoch 116
Train batch 1/32 - 234.0ms/batch - loss: 0.96728 - diff: 15.48mlTrain batch 2/32 - 234.5ms/batch - loss: 0.84261 - diff: 13.48mlTrain batch 3/32 - 233.7ms/batch - loss: 0.77034 - diff: 12.33mlTrain batch 4/32 - 234.0ms/batch - loss: 0.73011 - diff: 11.68mlTrain batch 5/32 - 238.5ms/batch - loss: 0.70146 - diff: 11.22mlTrain batch 6/32 - 233.7ms/batch - loss: 0.70129 - diff: 11.22mlTrain batch 7/32 - 238.1ms/batch - loss: 0.70076 - diff: 11.21mlTrain batch 8/32 - 233.8ms/batch - loss: 0.68555 - diff: 10.97mlTrain batch 9/32 - 237.5ms/batch - loss: 0.66863 - diff: 10.70mlTrain batch 10/32 - 234.1ms/batch - loss: 0.65715 - diff: 10.51mlTrain batch 11/32 - 243.7ms/batch - loss: 0.74416 - diff: 11.91mlTrain batch 12/32 - 234.0ms/batch - loss: 0.73207 - diff: 11.71mlTrain batch 13/32 - 243.6ms/batch - loss: 0.71305 - diff: 11.41mlTrain batch 14/32 - 233.9ms/batch - loss: 0.71989 - diff: 11.52mlTrain batch 15/32 - 234.3ms/batch - loss: 0.72577 - diff: 11.61mlTrain batch 16/32 - 233.9ms/batch - loss: 0.71482 - diff: 11.44mlTrain batch 17/32 - 234.7ms/batch - loss: 0.82319 - diff: 13.17mlTrain batch 18/32 - 233.6ms/batch - loss: 0.81232 - diff: 13.00mlTrain batch 19/32 - 234.4ms/batch - loss: 0.84037 - diff: 13.45mlTrain batch 20/32 - 233.7ms/batch - loss: 0.83638 - diff: 13.38mlTrain batch 21/32 - 246.6ms/batch - loss: 0.82829 - diff: 13.25mlTrain batch 22/32 - 234.0ms/batch - loss: 0.82735 - diff: 13.24mlTrain batch 23/32 - 243.2ms/batch - loss: 0.82277 - diff: 13.16mlTrain batch 24/32 - 234.0ms/batch - loss: 0.81440 - diff: 13.03mlTrain batch 25/32 - 234.3ms/batch - loss: 0.80688 - diff: 12.91mlTrain batch 26/32 - 233.8ms/batch - loss: 0.80253 - diff: 12.84mlTrain batch 27/32 - 234.3ms/batch - loss: 0.79438 - diff: 12.71mlTrain batch 28/32 - 235.4ms/batch - loss: 0.80794 - diff: 12.93mlTrain batch 29/32 - 234.3ms/batch - loss: 0.81135 - diff: 12.98mlTrain batch 30/32 - 233.7ms/batch - loss: 0.80573 - diff: 12.89mlTrain batch 31/32 - 234.2ms/batch - loss: 0.81628 - diff: 13.06mlTrain batch 32/32 - 76.3ms/batch - loss: 0.84932 - diff: 13.11mlTrain batch 32/32 - 17.0s 76.3ms/batch - loss: 0.84932 - diff: 13.11ml
Test 1.5s: val_loss: 1.01947 - diff: 15.58ml

Epoch 141: current best loss = 0.94355, at epoch 116
Train batch 1/32 - 233.8ms/batch - loss: 0.87254 - diff: 13.96mlTrain batch 2/32 - 240.1ms/batch - loss: 0.82406 - diff: 13.18mlTrain batch 3/32 - 233.9ms/batch - loss: 0.83067 - diff: 13.29mlTrain batch 4/32 - 234.7ms/batch - loss: 0.99012 - diff: 15.84mlTrain batch 5/32 - 234.9ms/batch - loss: 0.92337 - diff: 14.77mlTrain batch 6/32 - 232.9ms/batch - loss: 0.88348 - diff: 14.14mlTrain batch 7/32 - 235.1ms/batch - loss: 0.83326 - diff: 13.33mlTrain batch 8/32 - 234.5ms/batch - loss: 0.83653 - diff: 13.38mlTrain batch 9/32 - 233.6ms/batch - loss: 0.84540 - diff: 13.53mlTrain batch 10/32 - 233.8ms/batch - loss: 0.84338 - diff: 13.49mlTrain batch 11/32 - 234.1ms/batch - loss: 0.84677 - diff: 13.55mlTrain batch 12/32 - 233.9ms/batch - loss: 0.84368 - diff: 13.50mlTrain batch 13/32 - 233.8ms/batch - loss: 0.86135 - diff: 13.78mlTrain batch 14/32 - 234.0ms/batch - loss: 0.84271 - diff: 13.48mlTrain batch 15/32 - 235.1ms/batch - loss: 0.84063 - diff: 13.45mlTrain batch 16/32 - 233.4ms/batch - loss: 0.83273 - diff: 13.32mlTrain batch 17/32 - 238.3ms/batch - loss: 0.82859 - diff: 13.26mlTrain batch 18/32 - 234.0ms/batch - loss: 0.84963 - diff: 13.59mlTrain batch 19/32 - 237.0ms/batch - loss: 0.83452 - diff: 13.35mlTrain batch 20/32 - 233.8ms/batch - loss: 0.83335 - diff: 13.33mlTrain batch 21/32 - 234.0ms/batch - loss: 0.84170 - diff: 13.47mlTrain batch 22/32 - 234.3ms/batch - loss: 0.85030 - diff: 13.60mlTrain batch 23/32 - 233.9ms/batch - loss: 0.86189 - diff: 13.79mlTrain batch 24/32 - 234.2ms/batch - loss: 0.86617 - diff: 13.86mlTrain batch 25/32 - 234.6ms/batch - loss: 0.85725 - diff: 13.72mlTrain batch 26/32 - 234.2ms/batch - loss: 0.85969 - diff: 13.76mlTrain batch 27/32 - 240.5ms/batch - loss: 0.84920 - diff: 13.59mlTrain batch 28/32 - 234.1ms/batch - loss: 0.84825 - diff: 13.57mlTrain batch 29/32 - 235.0ms/batch - loss: 0.85019 - diff: 13.60mlTrain batch 30/32 - 234.0ms/batch - loss: 0.84029 - diff: 13.44mlTrain batch 31/32 - 234.8ms/batch - loss: 0.83633 - diff: 13.38mlTrain batch 32/32 - 77.0ms/batch - loss: 0.84858 - diff: 13.35mlTrain batch 32/32 - 17.4s 77.0ms/batch - loss: 0.84858 - diff: 13.35ml
Test 1.6s: val_loss: 0.98489 - diff: 15.18ml

Epoch 142: current best loss = 0.94355, at epoch 116
Train batch 1/32 - 236.9ms/batch - loss: 0.51437 - diff: 8.23mlTrain batch 2/32 - 233.6ms/batch - loss: 0.57094 - diff: 9.14mlTrain batch 3/32 - 234.1ms/batch - loss: 0.58066 - diff: 9.29mlTrain batch 4/32 - 234.6ms/batch - loss: 0.56061 - diff: 8.97mlTrain batch 5/32 - 234.2ms/batch - loss: 0.55912 - diff: 8.95mlTrain batch 6/32 - 234.8ms/batch - loss: 0.57552 - diff: 9.21mlTrain batch 7/32 - 234.0ms/batch - loss: 0.57710 - diff: 9.23mlTrain batch 8/32 - 236.7ms/batch - loss: 0.63441 - diff: 10.15mlTrain batch 9/32 - 234.3ms/batch - loss: 0.62400 - diff: 9.98mlTrain batch 10/32 - 237.3ms/batch - loss: 0.62403 - diff: 9.98mlTrain batch 11/32 - 234.2ms/batch - loss: 0.60708 - diff: 9.71mlTrain batch 12/32 - 234.9ms/batch - loss: 0.62291 - diff: 9.97mlTrain batch 13/32 - 233.7ms/batch - loss: 0.64777 - diff: 10.36mlTrain batch 14/32 - 250.6ms/batch - loss: 0.65482 - diff: 10.48mlTrain batch 15/32 - 233.8ms/batch - loss: 0.64965 - diff: 10.39mlTrain batch 16/32 - 234.0ms/batch - loss: 0.66915 - diff: 10.71mlTrain batch 17/32 - 234.3ms/batch - loss: 0.67319 - diff: 10.77mlTrain batch 18/32 - 234.6ms/batch - loss: 0.67503 - diff: 10.80mlTrain batch 19/32 - 234.2ms/batch - loss: 0.67763 - diff: 10.84mlTrain batch 20/32 - 234.6ms/batch - loss: 0.66927 - diff: 10.71mlTrain batch 21/32 - 249.1ms/batch - loss: 0.67339 - diff: 10.77mlTrain batch 22/32 - 234.5ms/batch - loss: 0.70905 - diff: 11.34mlTrain batch 23/32 - 234.1ms/batch - loss: 0.70591 - diff: 11.29mlTrain batch 24/32 - 234.4ms/batch - loss: 0.71240 - diff: 11.40mlTrain batch 25/32 - 234.1ms/batch - loss: 0.71722 - diff: 11.48mlTrain batch 26/32 - 238.7ms/batch - loss: 0.71002 - diff: 11.36mlTrain batch 27/32 - 233.8ms/batch - loss: 0.70571 - diff: 11.29mlTrain batch 28/32 - 244.0ms/batch - loss: 0.70528 - diff: 11.28mlTrain batch 29/32 - 234.3ms/batch - loss: 0.72148 - diff: 11.54mlTrain batch 30/32 - 235.2ms/batch - loss: 0.71126 - diff: 11.38mlTrain batch 31/32 - 234.2ms/batch - loss: 0.72223 - diff: 11.56mlTrain batch 32/32 - 88.5ms/batch - loss: 0.74909 - diff: 11.59mlTrain batch 32/32 - 17.3s 88.5ms/batch - loss: 0.74909 - diff: 11.59ml
Test 1.6s: val_loss: 1.00551 - diff: 15.49ml

Epoch 143: current best loss = 0.94355, at epoch 116
Train batch 1/32 - 248.7ms/batch - loss: 0.71874 - diff: 11.50mlTrain batch 2/32 - 238.6ms/batch - loss: 0.72026 - diff: 11.52mlTrain batch 3/32 - 233.7ms/batch - loss: 0.74344 - diff: 11.90mlTrain batch 4/32 - 238.6ms/batch - loss: 0.67751 - diff: 10.84mlTrain batch 5/32 - 233.7ms/batch - loss: 0.66023 - diff: 10.56mlTrain batch 6/32 - 234.4ms/batch - loss: 0.67321 - diff: 10.77mlTrain batch 7/32 - 234.3ms/batch - loss: 0.71049 - diff: 11.37mlTrain batch 8/32 - 234.3ms/batch - loss: 0.70567 - diff: 11.29mlTrain batch 9/32 - 233.8ms/batch - loss: 0.69090 - diff: 11.05mlTrain batch 10/32 - 234.0ms/batch - loss: 0.70022 - diff: 11.20mlTrain batch 11/32 - 233.9ms/batch - loss: 0.69395 - diff: 11.10mlTrain batch 12/32 - 233.8ms/batch - loss: 0.70892 - diff: 11.34mlTrain batch 13/32 - 234.2ms/batch - loss: 0.70163 - diff: 11.23mlTrain batch 14/32 - 234.1ms/batch - loss: 0.67531 - diff: 10.80mlTrain batch 15/32 - 234.4ms/batch - loss: 0.66382 - diff: 10.62mlTrain batch 16/32 - 234.3ms/batch - loss: 0.65550 - diff: 10.49mlTrain batch 17/32 - 234.3ms/batch - loss: 0.66659 - diff: 10.67mlTrain batch 18/32 - 243.3ms/batch - loss: 0.72830 - diff: 11.65mlTrain batch 19/32 - 236.5ms/batch - loss: 0.73248 - diff: 11.72mlTrain batch 20/32 - 233.8ms/batch - loss: 0.73622 - diff: 11.78mlTrain batch 21/32 - 239.2ms/batch - loss: 0.75312 - diff: 12.05mlTrain batch 22/32 - 237.1ms/batch - loss: 0.74578 - diff: 11.93mlTrain batch 23/32 - 234.4ms/batch - loss: 0.74191 - diff: 11.87mlTrain batch 24/32 - 236.4ms/batch - loss: 0.74084 - diff: 11.85mlTrain batch 25/32 - 239.9ms/batch - loss: 0.74117 - diff: 11.86mlTrain batch 26/32 - 233.9ms/batch - loss: 0.73170 - diff: 11.71mlTrain batch 27/32 - 235.0ms/batch - loss: 0.74089 - diff: 11.85mlTrain batch 28/32 - 234.2ms/batch - loss: 0.76097 - diff: 12.18mlTrain batch 29/32 - 234.7ms/batch - loss: 0.76338 - diff: 12.21mlTrain batch 30/32 - 233.8ms/batch - loss: 0.75576 - diff: 12.09mlTrain batch 31/32 - 234.6ms/batch - loss: 0.75911 - diff: 12.15mlTrain batch 32/32 - 76.2ms/batch - loss: 0.80374 - diff: 12.25mlTrain batch 32/32 - 17.2s 76.2ms/batch - loss: 0.80374 - diff: 12.25ml
Test 1.5s: val_loss: 1.05443 - diff: 15.66ml

Epoch 144: current best loss = 0.94355, at epoch 116
Train batch 1/32 - 234.2ms/batch - loss: 0.59919 - diff: 9.59mlTrain batch 2/32 - 240.2ms/batch - loss: 0.70940 - diff: 11.35mlTrain batch 3/32 - 233.9ms/batch - loss: 0.62614 - diff: 10.02mlTrain batch 4/32 - 249.5ms/batch - loss: 0.64052 - diff: 10.25mlTrain batch 5/32 - 234.1ms/batch - loss: 0.66761 - diff: 10.68mlTrain batch 6/32 - 234.1ms/batch - loss: 0.64460 - diff: 10.31mlTrain batch 7/32 - 234.1ms/batch - loss: 0.65867 - diff: 10.54mlTrain batch 8/32 - 234.7ms/batch - loss: 0.65577 - diff: 10.49mlTrain batch 9/32 - 234.0ms/batch - loss: 0.66589 - diff: 10.65mlTrain batch 10/32 - 234.0ms/batch - loss: 0.65393 - diff: 10.46mlTrain batch 11/32 - 234.0ms/batch - loss: 0.64452 - diff: 10.31mlTrain batch 12/32 - 234.8ms/batch - loss: 0.65663 - diff: 10.51mlTrain batch 13/32 - 233.8ms/batch - loss: 0.65223 - diff: 10.44mlTrain batch 14/32 - 238.2ms/batch - loss: 0.62463 - diff: 9.99mlTrain batch 15/32 - 233.7ms/batch - loss: 0.61518 - diff: 9.84mlTrain batch 16/32 - 234.6ms/batch - loss: 0.67338 - diff: 10.77mlTrain batch 17/32 - 233.7ms/batch - loss: 0.66753 - diff: 10.68mlTrain batch 18/32 - 234.3ms/batch - loss: 0.67904 - diff: 10.86mlTrain batch 19/32 - 234.0ms/batch - loss: 0.67792 - diff: 10.85mlTrain batch 20/32 - 233.9ms/batch - loss: 0.72155 - diff: 11.54mlTrain batch 21/32 - 233.6ms/batch - loss: 0.72490 - diff: 11.60mlTrain batch 22/32 - 246.5ms/batch - loss: 0.73652 - diff: 11.78mlTrain batch 23/32 - 233.7ms/batch - loss: 0.74417 - diff: 11.91mlTrain batch 24/32 - 234.8ms/batch - loss: 0.73492 - diff: 11.76mlTrain batch 25/32 - 233.8ms/batch - loss: 0.72524 - diff: 11.60mlTrain batch 26/32 - 234.2ms/batch - loss: 0.72924 - diff: 11.67mlTrain batch 27/32 - 234.5ms/batch - loss: 0.73920 - diff: 11.83mlTrain batch 28/32 - 234.4ms/batch - loss: 0.74924 - diff: 11.99mlTrain batch 29/32 - 234.1ms/batch - loss: 0.76816 - diff: 12.29mlTrain batch 30/32 - 234.5ms/batch - loss: 0.77530 - diff: 12.40mlTrain batch 31/32 - 234.0ms/batch - loss: 0.77200 - diff: 12.35mlTrain batch 32/32 - 76.6ms/batch - loss: 0.79366 - diff: 12.36mlTrain batch 32/32 - 18.1s 76.6ms/batch - loss: 0.79366 - diff: 12.36ml
Test 1.6s: val_loss: 1.00555 - diff: 15.55ml

Epoch 145: current best loss = 0.94355, at epoch 116
Train batch 1/32 - 242.5ms/batch - loss: 0.67713 - diff: 10.83mlTrain batch 2/32 - 234.3ms/batch - loss: 0.63349 - diff: 10.14mlTrain batch 3/32 - 233.9ms/batch - loss: 0.63163 - diff: 10.11mlTrain batch 4/32 - 252.1ms/batch - loss: 0.68585 - diff: 10.97mlTrain batch 5/32 - 233.7ms/batch - loss: 0.73395 - diff: 11.74mlTrain batch 6/32 - 232.5ms/batch - loss: 0.70915 - diff: 11.35mlTrain batch 7/32 - 234.0ms/batch - loss: 0.67236 - diff: 10.76mlTrain batch 8/32 - 234.3ms/batch - loss: 0.70559 - diff: 11.29mlTrain batch 9/32 - 234.0ms/batch - loss: 0.78816 - diff: 12.61mlTrain batch 10/32 - 233.6ms/batch - loss: 0.78794 - diff: 12.61mlTrain batch 11/32 - 233.9ms/batch - loss: 0.76387 - diff: 12.22mlTrain batch 12/32 - 234.2ms/batch - loss: 0.77491 - diff: 12.40mlTrain batch 13/32 - 234.2ms/batch - loss: 0.76994 - diff: 12.32mlTrain batch 14/32 - 234.3ms/batch - loss: 0.77127 - diff: 12.34mlTrain batch 15/32 - 234.0ms/batch - loss: 0.80148 - diff: 12.82mlTrain batch 16/32 - 234.5ms/batch - loss: 0.81190 - diff: 12.99mlTrain batch 17/32 - 233.9ms/batch - loss: 0.83601 - diff: 13.38mlTrain batch 18/32 - 234.7ms/batch - loss: 0.84968 - diff: 13.59mlTrain batch 19/32 - 233.9ms/batch - loss: 0.83867 - diff: 13.42mlTrain batch 20/32 - 234.4ms/batch - loss: 0.82096 - diff: 13.14mlTrain batch 21/32 - 234.1ms/batch - loss: 0.81509 - diff: 13.04mlTrain batch 22/32 - 234.4ms/batch - loss: 0.80819 - diff: 12.93mlTrain batch 23/32 - 234.0ms/batch - loss: 0.79646 - diff: 12.74mlTrain batch 24/32 - 234.0ms/batch - loss: 0.80196 - diff: 12.83mlTrain batch 25/32 - 234.3ms/batch - loss: 0.81652 - diff: 13.06mlTrain batch 26/32 - 234.8ms/batch - loss: 0.81504 - diff: 13.04mlTrain batch 27/32 - 234.1ms/batch - loss: 0.81328 - diff: 13.01mlTrain batch 28/32 - 234.9ms/batch - loss: 0.81205 - diff: 12.99mlTrain batch 29/32 - 233.9ms/batch - loss: 0.81431 - diff: 13.03mlTrain batch 30/32 - 234.6ms/batch - loss: 0.80679 - diff: 12.91mlTrain batch 31/32 - 234.1ms/batch - loss: 0.80237 - diff: 12.84mlTrain batch 32/32 - 76.7ms/batch - loss: 0.89207 - diff: 13.12mlTrain batch 32/32 - 16.8s 76.7ms/batch - loss: 0.89207 - diff: 13.12ml
Test 1.6s: val_loss: 0.99405 - diff: 15.52ml

Epoch 146: current best loss = 0.94355, at epoch 116
Train batch 1/32 - 233.6ms/batch - loss: 0.40064 - diff: 6.41mlTrain batch 2/32 - 233.7ms/batch - loss: 0.73770 - diff: 11.80mlTrain batch 3/32 - 233.5ms/batch - loss: 0.84526 - diff: 13.52mlTrain batch 4/32 - 234.7ms/batch - loss: 0.79608 - diff: 12.74mlTrain batch 5/32 - 233.9ms/batch - loss: 0.79087 - diff: 12.65mlTrain batch 6/32 - 237.4ms/batch - loss: 0.75315 - diff: 12.05mlTrain batch 7/32 - 234.1ms/batch - loss: 0.69831 - diff: 11.17mlTrain batch 8/32 - 234.8ms/batch - loss: 0.76519 - diff: 12.24mlTrain batch 9/32 - 234.2ms/batch - loss: 0.75492 - diff: 12.08mlTrain batch 10/32 - 234.6ms/batch - loss: 0.76028 - diff: 12.16mlTrain batch 11/32 - 234.1ms/batch - loss: 0.76005 - diff: 12.16mlTrain batch 12/32 - 234.0ms/batch - loss: 0.80356 - diff: 12.86mlTrain batch 13/32 - 233.7ms/batch - loss: 0.80348 - diff: 12.86mlTrain batch 14/32 - 236.5ms/batch - loss: 0.79023 - diff: 12.64mlTrain batch 15/32 - 234.0ms/batch - loss: 0.78932 - diff: 12.63mlTrain batch 16/32 - 245.2ms/batch - loss: 0.77777 - diff: 12.44mlTrain batch 17/32 - 234.0ms/batch - loss: 0.77529 - diff: 12.40mlTrain batch 18/32 - 236.7ms/batch - loss: 0.76492 - diff: 12.24mlTrain batch 19/32 - 233.7ms/batch - loss: 0.75984 - diff: 12.16mlTrain batch 20/32 - 238.3ms/batch - loss: 0.75024 - diff: 12.00mlTrain batch 21/32 - 234.1ms/batch - loss: 0.79072 - diff: 12.65mlTrain batch 22/32 - 238.2ms/batch - loss: 0.79434 - diff: 12.71mlTrain batch 23/32 - 234.0ms/batch - loss: 0.79271 - diff: 12.68mlTrain batch 24/32 - 246.4ms/batch - loss: 0.80399 - diff: 12.86mlTrain batch 25/32 - 240.0ms/batch - loss: 0.80282 - diff: 12.85mlTrain batch 26/32 - 234.5ms/batch - loss: 0.80400 - diff: 12.86mlTrain batch 27/32 - 234.3ms/batch - loss: 0.79709 - diff: 12.75mlTrain batch 28/32 - 234.5ms/batch - loss: 0.79364 - diff: 12.70mlTrain batch 29/32 - 234.1ms/batch - loss: 0.79097 - diff: 12.66mlTrain batch 30/32 - 234.5ms/batch - loss: 0.78797 - diff: 12.61mlTrain batch 31/32 - 234.0ms/batch - loss: 0.79808 - diff: 12.77mlTrain batch 32/32 - 89.9ms/batch - loss: 0.80787 - diff: 12.73mlTrain batch 32/32 - 16.8s 89.9ms/batch - loss: 0.80787 - diff: 12.73ml
Test 1.7s: val_loss: 0.98773 - diff: 15.26ml

Epoch 147: current best loss = 0.94355, at epoch 116
Train batch 1/32 - 250.0ms/batch - loss: 0.55948 - diff: 8.95mlTrain batch 2/32 - 235.0ms/batch - loss: 0.53559 - diff: 8.57mlTrain batch 3/32 - 233.8ms/batch - loss: 0.54747 - diff: 8.76mlTrain batch 4/32 - 234.5ms/batch - loss: 0.50846 - diff: 8.14mlTrain batch 5/32 - 233.7ms/batch - loss: 0.51575 - diff: 8.25mlTrain batch 6/32 - 234.7ms/batch - loss: 0.54312 - diff: 8.69mlTrain batch 7/32 - 233.7ms/batch - loss: 0.54569 - diff: 8.73mlTrain batch 8/32 - 240.9ms/batch - loss: 0.56622 - diff: 9.06mlTrain batch 9/32 - 238.0ms/batch - loss: 0.62080 - diff: 9.93mlTrain batch 10/32 - 235.9ms/batch - loss: 0.69526 - diff: 11.12mlTrain batch 11/32 - 234.2ms/batch - loss: 0.75990 - diff: 12.16mlTrain batch 12/32 - 234.3ms/batch - loss: 0.73669 - diff: 11.79mlTrain batch 13/32 - 233.9ms/batch - loss: 0.85940 - diff: 13.75mlTrain batch 14/32 - 245.4ms/batch - loss: 0.84422 - diff: 13.51mlTrain batch 15/32 - 234.1ms/batch - loss: 0.82558 - diff: 13.21mlTrain batch 16/32 - 233.6ms/batch - loss: 0.81683 - diff: 13.07mlTrain batch 17/32 - 233.9ms/batch - loss: 0.80943 - diff: 12.95mlTrain batch 18/32 - 241.4ms/batch - loss: 0.81353 - diff: 13.02mlTrain batch 19/32 - 234.3ms/batch - loss: 0.81109 - diff: 12.98mlTrain batch 20/32 - 238.3ms/batch - loss: 0.79801 - diff: 12.77mlTrain batch 21/32 - 234.1ms/batch - loss: 0.79934 - diff: 12.79mlTrain batch 22/32 - 234.8ms/batch - loss: 0.79931 - diff: 12.79mlTrain batch 23/32 - 233.7ms/batch - loss: 0.81348 - diff: 13.02mlTrain batch 24/32 - 234.5ms/batch - loss: 0.82555 - diff: 13.21mlTrain batch 25/32 - 233.9ms/batch - loss: 0.82074 - diff: 13.13mlTrain batch 26/32 - 234.3ms/batch - loss: 0.80741 - diff: 12.92mlTrain batch 27/32 - 234.4ms/batch - loss: 0.79573 - diff: 12.73mlTrain batch 28/32 - 235.1ms/batch - loss: 0.78774 - diff: 12.60mlTrain batch 29/32 - 236.1ms/batch - loss: 0.79288 - diff: 12.69mlTrain batch 30/32 - 241.7ms/batch - loss: 0.78282 - diff: 12.53mlTrain batch 31/32 - 234.4ms/batch - loss: 0.78700 - diff: 12.59mlTrain batch 32/32 - 76.6ms/batch - loss: 0.80583 - diff: 12.59mlTrain batch 32/32 - 17.1s 76.6ms/batch - loss: 0.80583 - diff: 12.59ml
Test 1.7s: val_loss: 0.99123 - diff: 15.29ml

Epoch 148: current best loss = 0.94355, at epoch 116
Train batch 1/32 - 234.0ms/batch - loss: 0.48475 - diff: 7.76mlTrain batch 2/32 - 239.6ms/batch - loss: 0.50834 - diff: 8.13mlTrain batch 3/32 - 250.9ms/batch - loss: 0.51789 - diff: 8.29mlTrain batch 4/32 - 234.2ms/batch - loss: 0.56158 - diff: 8.99mlTrain batch 5/32 - 234.4ms/batch - loss: 0.62294 - diff: 9.97mlTrain batch 6/32 - 234.3ms/batch - loss: 0.68471 - diff: 10.96mlTrain batch 7/32 - 233.9ms/batch - loss: 0.84833 - diff: 13.57mlTrain batch 8/32 - 234.4ms/batch - loss: 0.88995 - diff: 14.24mlTrain batch 9/32 - 234.4ms/batch - loss: 0.84711 - diff: 13.55mlTrain batch 10/32 - 234.8ms/batch - loss: 0.81481 - diff: 13.04mlTrain batch 11/32 - 234.1ms/batch - loss: 0.79435 - diff: 12.71mlTrain batch 12/32 - 234.6ms/batch - loss: 0.80612 - diff: 12.90mlTrain batch 13/32 - 233.8ms/batch - loss: 0.79877 - diff: 12.78mlTrain batch 14/32 - 234.7ms/batch - loss: 0.78835 - diff: 12.61mlTrain batch 15/32 - 233.7ms/batch - loss: 0.78092 - diff: 12.49mlTrain batch 16/32 - 233.2ms/batch - loss: 0.77903 - diff: 12.46mlTrain batch 17/32 - 234.4ms/batch - loss: 0.76750 - diff: 12.28mlTrain batch 18/32 - 234.5ms/batch - loss: 0.75713 - diff: 12.11mlTrain batch 19/32 - 233.9ms/batch - loss: 0.75045 - diff: 12.01mlTrain batch 20/32 - 233.6ms/batch - loss: 0.75615 - diff: 12.10mlTrain batch 21/32 - 234.6ms/batch - loss: 0.75679 - diff: 12.11mlTrain batch 22/32 - 235.2ms/batch - loss: 0.75865 - diff: 12.14mlTrain batch 23/32 - 233.9ms/batch - loss: 0.75290 - diff: 12.05mlTrain batch 24/32 - 240.9ms/batch - loss: 0.75070 - diff: 12.01mlTrain batch 25/32 - 234.0ms/batch - loss: 0.74577 - diff: 11.93mlTrain batch 26/32 - 234.8ms/batch - loss: 0.74293 - diff: 11.89mlTrain batch 27/32 - 234.2ms/batch - loss: 0.75552 - diff: 12.09mlTrain batch 28/32 - 238.1ms/batch - loss: 0.76144 - diff: 12.18mlTrain batch 29/32 - 235.0ms/batch - loss: 0.75981 - diff: 12.16mlTrain batch 30/32 - 234.8ms/batch - loss: 0.77074 - diff: 12.33mlTrain batch 31/32 - 234.1ms/batch - loss: 0.76365 - diff: 12.22mlTrain batch 32/32 - 83.6ms/batch - loss: 0.78331 - diff: 12.22mlTrain batch 32/32 - 16.0s 83.6ms/batch - loss: 0.78331 - diff: 12.22ml
Test 1.7s: val_loss: 1.01879 - diff: 15.30ml

Epoch 149: current best loss = 0.94355, at epoch 116
Train batch 1/32 - 234.2ms/batch - loss: 0.79488 - diff: 12.72mlTrain batch 2/32 - 234.4ms/batch - loss: 0.72895 - diff: 11.66mlTrain batch 3/32 - 233.8ms/batch - loss: 0.66834 - diff: 10.69mlTrain batch 4/32 - 234.3ms/batch - loss: 0.69307 - diff: 11.09mlTrain batch 5/32 - 233.6ms/batch - loss: 0.71391 - diff: 11.42mlTrain batch 6/32 - 234.0ms/batch - loss: 0.88091 - diff: 14.09mlTrain batch 7/32 - 233.8ms/batch - loss: 0.86150 - diff: 13.78mlTrain batch 8/32 - 234.3ms/batch - loss: 0.84157 - diff: 13.47mlTrain batch 9/32 - 234.2ms/batch - loss: 0.85547 - diff: 13.69mlTrain batch 10/32 - 234.1ms/batch - loss: 0.84821 - diff: 13.57mlTrain batch 11/32 - 233.9ms/batch - loss: 0.84548 - diff: 13.53mlTrain batch 12/32 - 234.1ms/batch - loss: 0.80790 - diff: 12.93mlTrain batch 13/32 - 234.0ms/batch - loss: 0.80682 - diff: 12.91mlTrain batch 14/32 - 245.8ms/batch - loss: 0.79186 - diff: 12.67mlTrain batch 15/32 - 234.1ms/batch - loss: 0.78628 - diff: 12.58mlTrain batch 16/32 - 233.6ms/batch - loss: 0.78129 - diff: 12.50mlTrain batch 17/32 - 234.0ms/batch - loss: 0.77120 - diff: 12.34mlTrain batch 18/32 - 234.4ms/batch - loss: 0.77330 - diff: 12.37mlTrain batch 19/32 - 233.8ms/batch - loss: 0.76285 - diff: 12.21mlTrain batch 20/32 - 234.9ms/batch - loss: 0.76503 - diff: 12.24mlTrain batch 21/32 - 234.1ms/batch - loss: 0.76650 - diff: 12.26mlTrain batch 22/32 - 234.3ms/batch - loss: 0.83416 - diff: 13.35mlTrain batch 23/32 - 233.9ms/batch - loss: 0.82606 - diff: 13.22mlTrain batch 24/32 - 238.6ms/batch - loss: 0.82739 - diff: 13.24mlTrain batch 25/32 - 234.2ms/batch - loss: 0.81815 - diff: 13.09mlTrain batch 26/32 - 234.3ms/batch - loss: 0.80854 - diff: 12.94mlTrain batch 27/32 - 234.7ms/batch - loss: 0.80463 - diff: 12.87mlTrain batch 28/32 - 234.2ms/batch - loss: 0.79353 - diff: 12.70mlTrain batch 29/32 - 238.3ms/batch - loss: 0.79121 - diff: 12.66mlTrain batch 30/32 - 234.8ms/batch - loss: 0.78640 - diff: 12.58mlTrain batch 31/32 - 233.6ms/batch - loss: 0.78597 - diff: 12.58mlTrain batch 32/32 - 76.8ms/batch - loss: 0.80957 - diff: 12.59mlTrain batch 32/32 - 17.6s 76.8ms/batch - loss: 0.80957 - diff: 12.59ml
Test 1.5s: val_loss: 1.00528 - diff: 15.44ml
Epoch   150: reducing learning rate of group 0 to 1.5625e-05.

