nohup: ignoring input
Running experiment 4CH_preproc1_150x150_bySlices_dataset_allViews_Systole_VGG19_Adam-0.001_MSE_DA3
Going to train with the GPU in the slot 0 -> device model: GeForce RTX 2080
Model architecture:
 VGG19(
  (first_conv): Sequential(
    (0): Conv2d(30, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU()
    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (pretrained_block): Sequential(
    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU(inplace=True)
    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): ReLU(inplace=True)
    (5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (6): ReLU(inplace=True)
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (9): ReLU(inplace=True)
    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): ReLU(inplace=True)
    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (13): ReLU(inplace=True)
    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (15): ReLU(inplace=True)
    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (18): ReLU(inplace=True)
    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (20): ReLU(inplace=True)
    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (22): ReLU(inplace=True)
    (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (24): ReLU(inplace=True)
    (25): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (27): ReLU(inplace=True)
    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (29): ReLU(inplace=True)
    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (31): ReLU(inplace=True)
    (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (33): ReLU(inplace=True)
    (34): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (reduction_block): Sequential(
    (0): AdaptiveAvgPool2d(output_size=(1, 1))
    (1): Flatten()
  )
  (dense_block): Sequential(
    (0): Linear(in_features=512, out_features=512, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.4, inplace=False)
    (3): Linear(in_features=512, out_features=1, bias=True)
  )
) 


############################
# TRAIN PHASE:  150 epochs #
############################

Epoch 0: 
Train batch 1/16 - 158.1ms/batch - loss: 124.25987 - diff: 57.46mlTrain batch 2/16 - 130.0ms/batch - loss: 176.22891 - diff: 64.28mlTrain batch 3/16 - 129.7ms/batch - loss: 153.77326 - diff: 61.42mlTrain batch 4/16 - 131.4ms/batch - loss: 163.90449 - diff: 63.32mlTrain batch 5/16 - 122.3ms/batch - loss: 228.16153 - diff: 68.95mlTrain batch 6/16 - 124.0ms/batch - loss: 225.53978 - diff: 70.06mlTrain batch 7/16 - 144.3ms/batch - loss: 215.98562 - diff: 69.28mlTrain batch 8/16 - 131.0ms/batch - loss: 208.26285 - diff: 68.29mlTrain batch 9/16 - 136.3ms/batch - loss: 201.24433 - diff: 67.01mlTrain batch 10/16 - 121.8ms/batch - loss: 191.43297 - diff: 65.27mlTrain batch 11/16 - 146.0ms/batch - loss: 187.85870 - diff: 64.56mlTrain batch 12/16 - 132.0ms/batch - loss: 185.76110 - diff: 64.15mlTrain batch 13/16 - 122.3ms/batch - loss: 178.59748 - diff: 62.87mlTrain batch 14/16 - 121.6ms/batch - loss: 174.16361 - diff: 61.28mlTrain batch 15/16 - 122.2ms/batch - loss: 176.28236 - diff: 61.21mlTrain batch 16/16 - 40.1ms/batch - loss: 177.55726 - diff: 60.89mlTrain batch 16/16 - 16.2s 40.1ms/batch - loss: 177.55726 - diff: 60.89ml
Test 1.0s: val_loss: 164.05875 - diff: 58.15ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Systole_VGG19_Adam-0.001_MSE_DA3_best

Epoch 1: current best loss = 164.05875, at epoch 0
Train batch 1/16 - 129.0ms/batch - loss: 122.42093 - diff: 40.39mlTrain batch 2/16 - 135.8ms/batch - loss: 133.78526 - diff: 43.50mlTrain batch 3/16 - 125.0ms/batch - loss: 117.00671 - diff: 41.61mlTrain batch 4/16 - 123.8ms/batch - loss: 103.40868 - diff: 38.51mlTrain batch 5/16 - 139.2ms/batch - loss: 90.37218 - diff: 36.24mlTrain batch 6/16 - 128.0ms/batch - loss: 81.00622 - diff: 34.48mlTrain batch 7/16 - 122.5ms/batch - loss: 75.55664 - diff: 32.98mlTrain batch 8/16 - 122.5ms/batch - loss: 73.03403 - diff: 32.75mlTrain batch 9/16 - 122.4ms/batch - loss: 68.74250 - diff: 32.16mlTrain batch 10/16 - 126.8ms/batch - loss: 64.45627 - diff: 31.29mlTrain batch 11/16 - 165.7ms/batch - loss: 65.00924 - diff: 31.63mlTrain batch 12/16 - 126.7ms/batch - loss: 61.89497 - diff: 30.88mlTrain batch 13/16 - 122.8ms/batch - loss: 62.76957 - diff: 30.99mlTrain batch 14/16 - 136.7ms/batch - loss: 75.10318 - diff: 31.66mlTrain batch 15/16 - 122.8ms/batch - loss: 75.44627 - diff: 32.08mlTrain batch 16/16 - 40.4ms/batch - loss: 74.85516 - diff: 31.80mlTrain batch 16/16 - 14.7s 40.4ms/batch - loss: 74.85516 - diff: 31.80ml
Test 1.0s: val_loss: 108.55628 - diff: 38.03ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Systole_VGG19_Adam-0.001_MSE_DA3_best

Epoch 2: current best loss = 108.55628, at epoch 1
Train batch 1/16 - 136.8ms/batch - loss: 34.64211 - diff: 28.33mlTrain batch 2/16 - 129.0ms/batch - loss: 67.08956 - diff: 31.68mlTrain batch 3/16 - 122.4ms/batch - loss: 58.52048 - diff: 28.19mlTrain batch 4/16 - 126.3ms/batch - loss: 51.28480 - diff: 26.89mlTrain batch 5/16 - 122.7ms/batch - loss: 50.05492 - diff: 26.60mlTrain batch 6/16 - 122.5ms/batch - loss: 48.34254 - diff: 26.70mlTrain batch 7/16 - 122.5ms/batch - loss: 46.80987 - diff: 26.69mlTrain batch 8/16 - 122.6ms/batch - loss: 53.28407 - diff: 28.25mlTrain batch 9/16 - 129.6ms/batch - loss: 50.71152 - diff: 27.51mlTrain batch 10/16 - 122.6ms/batch - loss: 50.35951 - diff: 27.82mlTrain batch 11/16 - 122.6ms/batch - loss: 48.41508 - diff: 27.53mlTrain batch 12/16 - 126.7ms/batch - loss: 49.57467 - diff: 28.22mlTrain batch 13/16 - 122.6ms/batch - loss: 51.80130 - diff: 28.83mlTrain batch 14/16 - 128.3ms/batch - loss: 50.94326 - diff: 28.81mlTrain batch 15/16 - 122.6ms/batch - loss: 61.85614 - diff: 29.82mlTrain batch 16/16 - 40.3ms/batch - loss: 62.01969 - diff: 29.65mlTrain batch 16/16 - 16.4s 40.3ms/batch - loss: 62.01969 - diff: 29.65ml
Test 1.1s: val_loss: 76.51952 - diff: 33.01ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Systole_VGG19_Adam-0.001_MSE_DA3_best

Epoch 3: current best loss = 76.51952, at epoch 2
Train batch 1/16 - 136.9ms/batch - loss: 122.62260 - diff: 39.83mlTrain batch 2/16 - 126.6ms/batch - loss: 78.82696 - diff: 33.27mlTrain batch 3/16 - 122.6ms/batch - loss: 62.73228 - diff: 30.55mlTrain batch 4/16 - 123.7ms/batch - loss: 71.40846 - diff: 30.08mlTrain batch 5/16 - 125.7ms/batch - loss: 65.28749 - diff: 29.75mlTrain batch 6/16 - 136.7ms/batch - loss: 62.50976 - diff: 29.99mlTrain batch 7/16 - 122.7ms/batch - loss: 57.93515 - diff: 29.13mlTrain batch 8/16 - 122.6ms/batch - loss: 53.33806 - diff: 28.13mlTrain batch 9/16 - 138.0ms/batch - loss: 52.64286 - diff: 28.23mlTrain batch 10/16 - 129.2ms/batch - loss: 50.92356 - diff: 27.99mlTrain batch 11/16 - 136.3ms/batch - loss: 50.19428 - diff: 28.15mlTrain batch 12/16 - 124.8ms/batch - loss: 52.93014 - diff: 29.21mlTrain batch 13/16 - 122.5ms/batch - loss: 50.62972 - diff: 28.49mlTrain batch 14/16 - 122.5ms/batch - loss: 49.90109 - diff: 28.53mlTrain batch 15/16 - 125.9ms/batch - loss: 60.25283 - diff: 29.00mlTrain batch 16/16 - 47.2ms/batch - loss: 66.14070 - diff: 29.12mlTrain batch 16/16 - 16.7s 47.2ms/batch - loss: 66.14070 - diff: 29.12ml
Test 1.0s: val_loss: 83.65556 - diff: 32.84ml

Epoch 4: current best loss = 76.51952, at epoch 2
Train batch 1/16 - 137.0ms/batch - loss: 24.30413 - diff: 22.86mlTrain batch 2/16 - 123.1ms/batch - loss: 51.74193 - diff: 29.15mlTrain batch 3/16 - 134.4ms/batch - loss: 54.45627 - diff: 28.94mlTrain batch 4/16 - 122.9ms/batch - loss: 46.61928 - diff: 26.98mlTrain batch 5/16 - 123.5ms/batch - loss: 48.40919 - diff: 28.16mlTrain batch 6/16 - 121.5ms/batch - loss: 74.86263 - diff: 30.53mlTrain batch 7/16 - 137.1ms/batch - loss: 69.67070 - diff: 29.58mlTrain batch 8/16 - 121.7ms/batch - loss: 69.88388 - diff: 29.96mlTrain batch 9/16 - 136.6ms/batch - loss: 66.17698 - diff: 29.79mlTrain batch 10/16 - 131.5ms/batch - loss: 63.02921 - diff: 29.54mlTrain batch 11/16 - 143.7ms/batch - loss: 60.62397 - diff: 29.39mlTrain batch 12/16 - 123.3ms/batch - loss: 58.80818 - diff: 29.30mlTrain batch 13/16 - 122.6ms/batch - loss: 58.96967 - diff: 29.58mlTrain batch 14/16 - 122.4ms/batch - loss: 62.53628 - diff: 30.14mlTrain batch 15/16 - 136.9ms/batch - loss: 60.00335 - diff: 29.66mlTrain batch 16/16 - 54.5ms/batch - loss: 61.01920 - diff: 29.57mlTrain batch 16/16 - 18.0s 54.5ms/batch - loss: 61.01920 - diff: 29.57ml
Test 1.1s: val_loss: 63.09099 - diff: 29.55ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Systole_VGG19_Adam-0.001_MSE_DA3_best

Epoch 5: current best loss = 63.09099, at epoch 4
Train batch 1/16 - 139.4ms/batch - loss: 32.45012 - diff: 24.72mlTrain batch 2/16 - 122.6ms/batch - loss: 34.41407 - diff: 25.93mlTrain batch 3/16 - 124.1ms/batch - loss: 38.25418 - diff: 26.65mlTrain batch 4/16 - 123.1ms/batch - loss: 34.79510 - diff: 25.17mlTrain batch 5/16 - 153.4ms/batch - loss: 37.70714 - diff: 25.70mlTrain batch 6/16 - 123.8ms/batch - loss: 36.26042 - diff: 24.99mlTrain batch 7/16 - 136.2ms/batch - loss: 42.59502 - diff: 26.56mlTrain batch 8/16 - 122.7ms/batch - loss: 47.96712 - diff: 27.69mlTrain batch 9/16 - 133.6ms/batch - loss: 45.78957 - diff: 27.35mlTrain batch 10/16 - 143.5ms/batch - loss: 59.99147 - diff: 28.26mlTrain batch 11/16 - 150.3ms/batch - loss: 57.16424 - diff: 28.20mlTrain batch 12/16 - 131.8ms/batch - loss: 59.41498 - diff: 28.87mlTrain batch 13/16 - 122.9ms/batch - loss: 56.52857 - diff: 28.21mlTrain batch 14/16 - 121.6ms/batch - loss: 56.39456 - diff: 28.34mlTrain batch 15/16 - 136.9ms/batch - loss: 56.22715 - diff: 28.33mlTrain batch 16/16 - 46.2ms/batch - loss: 62.50785 - diff: 28.62mlTrain batch 16/16 - 17.3s 46.2ms/batch - loss: 62.50785 - diff: 28.62ml
Test 0.9s: val_loss: 67.30992 - diff: 28.67ml

Epoch 6: current best loss = 63.09099, at epoch 4
Train batch 1/16 - 136.9ms/batch - loss: 28.81478 - diff: 24.24mlTrain batch 2/16 - 121.8ms/batch - loss: 42.44379 - diff: 27.97mlTrain batch 3/16 - 141.0ms/batch - loss: 39.08362 - diff: 25.80mlTrain batch 4/16 - 131.2ms/batch - loss: 55.79357 - diff: 28.45mlTrain batch 5/16 - 136.6ms/batch - loss: 50.36775 - diff: 27.48mlTrain batch 6/16 - 121.7ms/batch - loss: 45.87419 - diff: 26.57mlTrain batch 7/16 - 136.6ms/batch - loss: 45.42719 - diff: 27.22mlTrain batch 8/16 - 142.1ms/batch - loss: 46.15200 - diff: 27.25mlTrain batch 9/16 - 121.9ms/batch - loss: 49.93594 - diff: 28.04mlTrain batch 10/16 - 130.6ms/batch - loss: 46.31149 - diff: 26.93mlTrain batch 11/16 - 142.1ms/batch - loss: 45.61886 - diff: 26.82mlTrain batch 12/16 - 124.4ms/batch - loss: 45.60896 - diff: 26.69mlTrain batch 13/16 - 123.3ms/batch - loss: 60.76725 - diff: 27.95mlTrain batch 14/16 - 133.6ms/batch - loss: 58.82203 - diff: 27.90mlTrain batch 15/16 - 146.2ms/batch - loss: 57.55946 - diff: 27.84mlTrain batch 16/16 - 45.8ms/batch - loss: 59.36075 - diff: 27.90mlTrain batch 16/16 - 17.4s 45.8ms/batch - loss: 59.36075 - diff: 27.90ml
Test 1.1s: val_loss: 47.12473 - diff: 25.75ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Systole_VGG19_Adam-0.001_MSE_DA3_best

Epoch 7: current best loss = 47.12473, at epoch 6
Train batch 1/16 - 137.0ms/batch - loss: 32.35678 - diff: 25.31mlTrain batch 2/16 - 123.1ms/batch - loss: 34.40051 - diff: 26.87mlTrain batch 3/16 - 123.2ms/batch - loss: 48.58883 - diff: 29.04mlTrain batch 4/16 - 136.8ms/batch - loss: 46.61080 - diff: 28.70mlTrain batch 5/16 - 126.3ms/batch - loss: 47.83751 - diff: 28.09mlTrain batch 6/16 - 131.2ms/batch - loss: 44.11580 - diff: 27.37mlTrain batch 7/16 - 145.0ms/batch - loss: 42.03550 - diff: 26.73mlTrain batch 8/16 - 132.8ms/batch - loss: 39.17883 - diff: 26.11mlTrain batch 9/16 - 135.6ms/batch - loss: 38.44834 - diff: 25.73mlTrain batch 10/16 - 133.1ms/batch - loss: 44.03242 - diff: 26.32mlTrain batch 11/16 - 135.2ms/batch - loss: 43.59423 - diff: 26.69mlTrain batch 12/16 - 122.0ms/batch - loss: 57.28444 - diff: 27.38mlTrain batch 13/16 - 123.2ms/batch - loss: 55.08915 - diff: 27.23mlTrain batch 14/16 - 127.6ms/batch - loss: 55.83148 - diff: 27.57mlTrain batch 15/16 - 123.3ms/batch - loss: 55.09931 - diff: 27.55mlTrain batch 16/16 - 47.0ms/batch - loss: 60.81514 - diff: 27.63mlTrain batch 16/16 - 17.6s 47.0ms/batch - loss: 60.81514 - diff: 27.63ml
Test 1.1s: val_loss: 50.38999 - diff: 24.77ml

Epoch 8: current best loss = 47.12473, at epoch 6
Train batch 1/16 - 136.8ms/batch - loss: 47.66941 - diff: 23.58mlTrain batch 2/16 - 130.6ms/batch - loss: 143.95125 - diff: 31.86mlTrain batch 3/16 - 140.1ms/batch - loss: 104.79427 - diff: 28.83mlTrain batch 4/16 - 122.8ms/batch - loss: 100.72711 - diff: 30.69mlTrain batch 5/16 - 139.3ms/batch - loss: 88.90823 - diff: 29.67mlTrain batch 6/16 - 136.0ms/batch - loss: 80.33541 - diff: 29.32mlTrain batch 7/16 - 124.1ms/batch - loss: 77.17690 - diff: 29.61mlTrain batch 8/16 - 123.0ms/batch - loss: 71.23639 - diff: 29.26mlTrain batch 9/16 - 123.1ms/batch - loss: 65.64456 - diff: 28.13mlTrain batch 10/16 - 138.4ms/batch - loss: 62.14802 - diff: 27.85mlTrain batch 11/16 - 136.8ms/batch - loss: 59.09286 - diff: 27.61mlTrain batch 12/16 - 131.3ms/batch - loss: 56.76767 - diff: 27.52mlTrain batch 13/16 - 133.6ms/batch - loss: 55.97733 - diff: 27.61mlTrain batch 14/16 - 123.7ms/batch - loss: 53.83967 - diff: 27.31mlTrain batch 15/16 - 123.2ms/batch - loss: 53.31776 - diff: 27.41mlTrain batch 16/16 - 40.4ms/batch - loss: 54.30375 - diff: 27.31mlTrain batch 16/16 - 15.7s 40.4ms/batch - loss: 54.30375 - diff: 27.31ml
Test 1.0s: val_loss: 59.39321 - diff: 24.75ml

Epoch 9: current best loss = 47.12473, at epoch 6
Train batch 1/16 - 136.9ms/batch - loss: 190.68073 - diff: 30.01mlTrain batch 2/16 - 133.6ms/batch - loss: 126.39668 - diff: 29.87mlTrain batch 3/16 - 136.9ms/batch - loss: 98.23831 - diff: 28.47mlTrain batch 4/16 - 136.3ms/batch - loss: 93.66653 - diff: 29.19mlTrain batch 5/16 - 136.7ms/batch - loss: 85.15871 - diff: 29.26mlTrain batch 6/16 - 136.4ms/batch - loss: 75.07317 - diff: 28.35mlTrain batch 7/16 - 136.8ms/batch - loss: 67.07087 - diff: 27.08mlTrain batch 8/16 - 129.7ms/batch - loss: 64.20698 - diff: 27.26mlTrain batch 9/16 - 136.8ms/batch - loss: 61.59267 - diff: 27.40mlTrain batch 10/16 - 135.1ms/batch - loss: 60.36000 - diff: 27.84mlTrain batch 11/16 - 123.4ms/batch - loss: 61.16401 - diff: 28.25mlTrain batch 12/16 - 123.2ms/batch - loss: 58.46857 - diff: 27.87mlTrain batch 13/16 - 144.1ms/batch - loss: 56.42135 - diff: 27.80mlTrain batch 14/16 - 135.0ms/batch - loss: 55.29229 - diff: 27.84mlTrain batch 15/16 - 123.3ms/batch - loss: 56.02821 - diff: 28.15mlTrain batch 16/16 - 44.2ms/batch - loss: 56.43057 - diff: 28.07mlTrain batch 16/16 - 17.1s 44.2ms/batch - loss: 56.43057 - diff: 28.07ml
Test 1.0s: val_loss: 46.09832 - diff: 24.72ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Systole_VGG19_Adam-0.001_MSE_DA3_best

Epoch 10: current best loss = 46.09832, at epoch 9
Train batch 1/16 - 133.8ms/batch - loss: 17.92513 - diff: 19.22mlTrain batch 2/16 - 128.6ms/batch - loss: 30.61854 - diff: 23.88mlTrain batch 3/16 - 123.2ms/batch - loss: 32.71850 - diff: 24.05mlTrain batch 4/16 - 136.2ms/batch - loss: 31.75812 - diff: 24.09mlTrain batch 5/16 - 123.9ms/batch - loss: 31.93135 - diff: 24.23mlTrain batch 6/16 - 139.0ms/batch - loss: 30.00275 - diff: 23.68mlTrain batch 7/16 - 127.5ms/batch - loss: 40.10715 - diff: 25.02mlTrain batch 8/16 - 128.5ms/batch - loss: 40.09419 - diff: 24.86mlTrain batch 9/16 - 123.2ms/batch - loss: 40.38427 - diff: 24.57mlTrain batch 10/16 - 140.7ms/batch - loss: 39.59064 - diff: 24.14mlTrain batch 11/16 - 123.1ms/batch - loss: 40.63259 - diff: 24.90mlTrain batch 12/16 - 132.4ms/batch - loss: 39.79583 - diff: 25.04mlTrain batch 13/16 - 124.6ms/batch - loss: 41.05102 - diff: 25.37mlTrain batch 14/16 - 128.2ms/batch - loss: 54.79590 - diff: 26.75mlTrain batch 15/16 - 123.1ms/batch - loss: 53.91826 - diff: 26.85mlTrain batch 16/16 - 55.3ms/batch - loss: 54.17935 - diff: 26.76mlTrain batch 16/16 - 16.9s 55.3ms/batch - loss: 54.17935 - diff: 26.76ml
Test 1.1s: val_loss: 51.63180 - diff: 24.10ml

Epoch 11: current best loss = 46.09832, at epoch 9
Train batch 1/16 - 133.7ms/batch - loss: 37.25167 - diff: 27.52mlTrain batch 2/16 - 124.7ms/batch - loss: 40.37119 - diff: 27.24mlTrain batch 3/16 - 137.1ms/batch - loss: 39.73169 - diff: 28.06mlTrain batch 4/16 - 127.3ms/batch - loss: 40.30428 - diff: 28.41mlTrain batch 5/16 - 123.1ms/batch - loss: 36.39274 - diff: 26.94mlTrain batch 6/16 - 133.4ms/batch - loss: 37.46091 - diff: 27.18mlTrain batch 7/16 - 136.6ms/batch - loss: 59.71883 - diff: 28.23mlTrain batch 8/16 - 123.4ms/batch - loss: 59.23046 - diff: 28.34mlTrain batch 9/16 - 123.2ms/batch - loss: 60.01898 - diff: 28.80mlTrain batch 10/16 - 123.5ms/batch - loss: 58.52137 - diff: 28.84mlTrain batch 11/16 - 126.1ms/batch - loss: 57.17631 - diff: 28.44mlTrain batch 12/16 - 123.3ms/batch - loss: 58.61809 - diff: 28.43mlTrain batch 13/16 - 123.3ms/batch - loss: 55.77795 - diff: 27.92mlTrain batch 14/16 - 123.2ms/batch - loss: 54.88945 - diff: 27.93mlTrain batch 15/16 - 123.1ms/batch - loss: 52.19269 - diff: 27.26mlTrain batch 16/16 - 40.4ms/batch - loss: 56.33635 - diff: 27.37mlTrain batch 16/16 - 16.2s 40.4ms/batch - loss: 56.33635 - diff: 27.37ml
Test 0.7s: val_loss: 41.33895 - diff: 23.53ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Systole_VGG19_Adam-0.001_MSE_DA3_best

Epoch 12: current best loss = 41.33895, at epoch 11
Train batch 1/16 - 137.0ms/batch - loss: 26.35390 - diff: 22.04mlTrain batch 2/16 - 131.3ms/batch - loss: 44.11138 - diff: 27.54mlTrain batch 3/16 - 123.2ms/batch - loss: 42.10804 - diff: 27.20mlTrain batch 4/16 - 140.8ms/batch - loss: 41.47894 - diff: 27.04mlTrain batch 5/16 - 123.3ms/batch - loss: 44.09478 - diff: 27.58mlTrain batch 6/16 - 123.2ms/batch - loss: 41.29000 - diff: 26.57mlTrain batch 7/16 - 136.8ms/batch - loss: 67.01976 - diff: 29.09mlTrain batch 8/16 - 135.6ms/batch - loss: 62.71753 - diff: 29.03mlTrain batch 9/16 - 136.8ms/batch - loss: 59.46315 - diff: 28.64mlTrain batch 10/16 - 138.7ms/batch - loss: 62.47175 - diff: 28.95mlTrain batch 11/16 - 125.7ms/batch - loss: 59.32710 - diff: 28.18mlTrain batch 12/16 - 123.3ms/batch - loss: 57.66625 - diff: 28.14mlTrain batch 13/16 - 132.2ms/batch - loss: 54.76071 - diff: 27.60mlTrain batch 14/16 - 136.9ms/batch - loss: 51.98304 - diff: 26.87mlTrain batch 15/16 - 123.3ms/batch - loss: 50.16043 - diff: 26.65mlTrain batch 16/16 - 40.5ms/batch - loss: 51.07208 - diff: 26.60mlTrain batch 16/16 - 17.1s 40.5ms/batch - loss: 51.07208 - diff: 26.60ml
Test 1.0s: val_loss: 46.86449 - diff: 24.36ml

Epoch 13: current best loss = 41.33895, at epoch 11
Train batch 1/16 - 134.3ms/batch - loss: 26.01088 - diff: 23.25mlTrain batch 2/16 - 123.5ms/batch - loss: 30.50770 - diff: 24.34mlTrain batch 3/16 - 152.1ms/batch - loss: 27.95090 - diff: 23.23mlTrain batch 4/16 - 131.1ms/batch - loss: 29.03178 - diff: 23.79mlTrain batch 5/16 - 123.2ms/batch - loss: 32.09412 - diff: 24.62mlTrain batch 6/16 - 127.6ms/batch - loss: 31.13027 - diff: 23.97mlTrain batch 7/16 - 136.9ms/batch - loss: 34.06329 - diff: 24.49mlTrain batch 8/16 - 123.8ms/batch - loss: 34.01466 - diff: 24.65mlTrain batch 9/16 - 136.4ms/batch - loss: 34.30626 - diff: 24.69mlTrain batch 10/16 - 130.5ms/batch - loss: 50.00007 - diff: 25.67mlTrain batch 11/16 - 143.8ms/batch - loss: 51.88593 - diff: 26.30mlTrain batch 12/16 - 124.7ms/batch - loss: 52.17811 - diff: 26.69mlTrain batch 13/16 - 142.5ms/batch - loss: 49.34774 - diff: 26.10mlTrain batch 14/16 - 125.3ms/batch - loss: 48.56303 - diff: 26.01mlTrain batch 15/16 - 132.3ms/batch - loss: 47.24843 - diff: 25.98mlTrain batch 16/16 - 40.4ms/batch - loss: 64.11646 - diff: 26.51mlTrain batch 16/16 - 16.7s 40.4ms/batch - loss: 64.11646 - diff: 26.51ml
Test 1.0s: val_loss: 49.94888 - diff: 23.44ml

Epoch 14: current best loss = 41.33895, at epoch 11
Train batch 1/16 - 136.9ms/batch - loss: 63.53989 - diff: 33.16mlTrain batch 2/16 - 133.1ms/batch - loss: 88.54246 - diff: 36.22mlTrain batch 3/16 - 136.9ms/batch - loss: 79.64440 - diff: 35.31mlTrain batch 4/16 - 123.3ms/batch - loss: 103.96142 - diff: 35.21mlTrain batch 5/16 - 132.3ms/batch - loss: 93.70227 - diff: 35.02mlTrain batch 6/16 - 126.6ms/batch - loss: 82.71949 - diff: 33.43mlTrain batch 7/16 - 126.1ms/batch - loss: 75.12861 - diff: 32.16mlTrain batch 8/16 - 123.4ms/batch - loss: 70.42094 - diff: 31.61mlTrain batch 9/16 - 153.0ms/batch - loss: 65.19350 - diff: 30.60mlTrain batch 10/16 - 125.5ms/batch - loss: 62.41008 - diff: 30.20mlTrain batch 11/16 - 132.8ms/batch - loss: 58.34084 - diff: 29.12mlTrain batch 12/16 - 123.5ms/batch - loss: 56.18974 - diff: 28.63mlTrain batch 13/16 - 123.1ms/batch - loss: 55.25348 - diff: 28.42mlTrain batch 14/16 - 123.1ms/batch - loss: 52.74427 - diff: 27.84mlTrain batch 15/16 - 123.4ms/batch - loss: 50.75956 - diff: 27.32mlTrain batch 16/16 - 40.5ms/batch - loss: 50.64464 - diff: 27.13mlTrain batch 16/16 - 15.8s 40.5ms/batch - loss: 50.64464 - diff: 27.13ml
Test 1.0s: val_loss: 40.79415 - diff: 23.79ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Systole_VGG19_Adam-0.001_MSE_DA3_best

Epoch 15: current best loss = 40.79415, at epoch 14
Train batch 1/16 - 136.6ms/batch - loss: 31.96614 - diff: 22.99mlTrain batch 2/16 - 124.7ms/batch - loss: 59.78381 - diff: 26.44mlTrain batch 3/16 - 128.1ms/batch - loss: 56.59473 - diff: 26.97mlTrain batch 4/16 - 131.8ms/batch - loss: 55.46556 - diff: 27.74mlTrain batch 5/16 - 123.1ms/batch - loss: 53.29822 - diff: 28.33mlTrain batch 6/16 - 128.5ms/batch - loss: 52.19786 - diff: 28.90mlTrain batch 7/16 - 134.0ms/batch - loss: 47.41923 - diff: 27.70mlTrain batch 8/16 - 132.3ms/batch - loss: 46.84523 - diff: 27.65mlTrain batch 9/16 - 135.8ms/batch - loss: 61.46578 - diff: 28.85mlTrain batch 10/16 - 123.6ms/batch - loss: 57.11570 - diff: 27.87mlTrain batch 11/16 - 163.2ms/batch - loss: 56.61278 - diff: 27.99mlTrain batch 12/16 - 123.4ms/batch - loss: 54.29829 - diff: 27.82mlTrain batch 13/16 - 123.2ms/batch - loss: 51.78004 - diff: 27.42mlTrain batch 14/16 - 123.2ms/batch - loss: 51.08797 - diff: 27.47mlTrain batch 15/16 - 123.3ms/batch - loss: 50.52197 - diff: 27.19mlTrain batch 16/16 - 40.4ms/batch - loss: 50.77548 - diff: 27.06mlTrain batch 16/16 - 16.0s 40.4ms/batch - loss: 50.77548 - diff: 27.06ml
Test 1.1s: val_loss: 41.25066 - diff: 24.14ml

Epoch 16: current best loss = 40.79415, at epoch 14
Train batch 1/16 - 134.4ms/batch - loss: 61.72828 - diff: 31.80mlTrain batch 2/16 - 128.2ms/batch - loss: 59.80640 - diff: 30.23mlTrain batch 3/16 - 123.1ms/batch - loss: 48.68863 - diff: 27.47mlTrain batch 4/16 - 125.8ms/batch - loss: 54.84963 - diff: 27.73mlTrain batch 5/16 - 123.2ms/batch - loss: 48.77809 - diff: 26.57mlTrain batch 6/16 - 123.2ms/batch - loss: 47.65046 - diff: 26.23mlTrain batch 7/16 - 135.8ms/batch - loss: 44.26041 - diff: 25.48mlTrain batch 8/16 - 123.3ms/batch - loss: 46.08524 - diff: 26.38mlTrain batch 9/16 - 123.3ms/batch - loss: 46.48775 - diff: 26.77mlTrain batch 10/16 - 133.3ms/batch - loss: 44.20655 - diff: 26.24mlTrain batch 11/16 - 128.0ms/batch - loss: 41.84691 - diff: 25.75mlTrain batch 12/16 - 124.6ms/batch - loss: 40.01056 - diff: 25.34mlTrain batch 13/16 - 136.7ms/batch - loss: 50.40766 - diff: 25.69mlTrain batch 14/16 - 136.3ms/batch - loss: 50.56822 - diff: 25.88mlTrain batch 15/16 - 136.5ms/batch - loss: 49.77578 - diff: 25.62mlTrain batch 16/16 - 40.4ms/batch - loss: 50.21735 - diff: 25.52mlTrain batch 16/16 - 17.5s 40.4ms/batch - loss: 50.21735 - diff: 25.52ml
Test 0.9s: val_loss: 42.61308 - diff: 23.63ml

Epoch 17: current best loss = 40.79415, at epoch 14
Train batch 1/16 - 136.9ms/batch - loss: 36.15021 - diff: 26.53mlTrain batch 2/16 - 133.3ms/batch - loss: 39.84457 - diff: 26.73mlTrain batch 3/16 - 134.9ms/batch - loss: 38.72390 - diff: 25.35mlTrain batch 4/16 - 123.4ms/batch - loss: 38.03459 - diff: 24.48mlTrain batch 5/16 - 123.1ms/batch - loss: 35.59090 - diff: 24.33mlTrain batch 6/16 - 135.3ms/batch - loss: 37.16388 - diff: 24.50mlTrain batch 7/16 - 148.3ms/batch - loss: 37.19226 - diff: 25.12mlTrain batch 8/16 - 129.9ms/batch - loss: 35.40629 - diff: 24.50mlTrain batch 9/16 - 123.4ms/batch - loss: 35.23332 - diff: 24.50mlTrain batch 10/16 - 128.4ms/batch - loss: 50.70819 - diff: 25.86mlTrain batch 11/16 - 123.9ms/batch - loss: 56.75413 - diff: 27.02mlTrain batch 12/16 - 123.9ms/batch - loss: 57.27684 - diff: 27.71mlTrain batch 13/16 - 127.4ms/batch - loss: 54.66151 - diff: 27.35mlTrain batch 14/16 - 123.8ms/batch - loss: 51.62841 - diff: 26.58mlTrain batch 15/16 - 129.9ms/batch - loss: 50.38777 - diff: 26.43mlTrain batch 16/16 - 47.0ms/batch - loss: 53.43061 - diff: 26.59mlTrain batch 16/16 - 15.5s 47.0ms/batch - loss: 53.43061 - diff: 26.59ml
Test 1.0s: val_loss: 45.13703 - diff: 23.81ml

Epoch 18: current best loss = 40.79415, at epoch 14
Train batch 1/16 - 136.8ms/batch - loss: 27.51645 - diff: 24.72mlTrain batch 2/16 - 124.5ms/batch - loss: 22.22252 - diff: 22.04mlTrain batch 3/16 - 123.0ms/batch - loss: 31.84739 - diff: 23.84mlTrain batch 4/16 - 123.3ms/batch - loss: 38.42924 - diff: 26.41mlTrain batch 5/16 - 123.2ms/batch - loss: 35.72494 - diff: 25.80mlTrain batch 6/16 - 123.2ms/batch - loss: 57.23579 - diff: 27.47mlTrain batch 7/16 - 123.2ms/batch - loss: 61.05543 - diff: 27.82mlTrain batch 8/16 - 124.9ms/batch - loss: 55.64656 - diff: 26.77mlTrain batch 9/16 - 124.7ms/batch - loss: 52.38748 - diff: 26.14mlTrain batch 10/16 - 136.9ms/batch - loss: 49.36752 - diff: 25.84mlTrain batch 11/16 - 123.2ms/batch - loss: 47.01658 - diff: 25.38mlTrain batch 12/16 - 127.3ms/batch - loss: 46.06404 - diff: 25.26mlTrain batch 13/16 - 123.2ms/batch - loss: 44.99522 - diff: 24.96mlTrain batch 14/16 - 123.3ms/batch - loss: 45.16174 - diff: 24.92mlTrain batch 15/16 - 123.3ms/batch - loss: 45.54101 - diff: 25.04mlTrain batch 16/16 - 40.6ms/batch - loss: 45.94758 - diff: 24.95mlTrain batch 16/16 - 15.9s 40.6ms/batch - loss: 45.94758 - diff: 24.95ml
Test 1.0s: val_loss: 36.63144 - diff: 22.67ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Systole_VGG19_Adam-0.001_MSE_DA3_best

Epoch 19: current best loss = 36.63144, at epoch 18
Train batch 1/16 - 136.8ms/batch - loss: 85.54420 - diff: 30.64mlTrain batch 2/16 - 128.6ms/batch - loss: 57.50994 - diff: 27.64mlTrain batch 3/16 - 139.7ms/batch - loss: 46.22734 - diff: 25.65mlTrain batch 4/16 - 141.1ms/batch - loss: 40.20514 - diff: 25.11mlTrain batch 5/16 - 123.1ms/batch - loss: 41.38574 - diff: 25.19mlTrain batch 6/16 - 123.3ms/batch - loss: 63.76255 - diff: 26.54mlTrain batch 7/16 - 134.8ms/batch - loss: 58.85091 - diff: 26.15mlTrain batch 8/16 - 129.7ms/batch - loss: 56.39248 - diff: 26.11mlTrain batch 9/16 - 141.1ms/batch - loss: 53.60530 - diff: 26.14mlTrain batch 10/16 - 129.1ms/batch - loss: 54.31822 - diff: 26.24mlTrain batch 11/16 - 123.6ms/batch - loss: 52.58899 - diff: 26.21mlTrain batch 12/16 - 127.2ms/batch - loss: 53.68057 - diff: 26.84mlTrain batch 13/16 - 123.4ms/batch - loss: 51.05582 - diff: 26.14mlTrain batch 14/16 - 123.5ms/batch - loss: 50.37761 - diff: 26.20mlTrain batch 15/16 - 123.4ms/batch - loss: 48.70603 - diff: 26.05mlTrain batch 16/16 - 48.4ms/batch - loss: 49.79917 - diff: 26.08mlTrain batch 16/16 - 15.5s 48.4ms/batch - loss: 49.79917 - diff: 26.08ml
Test 1.1s: val_loss: 37.86889 - diff: 22.55ml

Epoch 20: current best loss = 36.63144, at epoch 18
Train batch 1/16 - 157.5ms/batch - loss: 30.85908 - diff: 23.93mlTrain batch 2/16 - 124.1ms/batch - loss: 34.18723 - diff: 26.55mlTrain batch 3/16 - 123.3ms/batch - loss: 30.89562 - diff: 25.11mlTrain batch 4/16 - 123.3ms/batch - loss: 27.09418 - diff: 23.44mlTrain batch 5/16 - 132.3ms/batch - loss: 39.32741 - diff: 24.90mlTrain batch 6/16 - 142.9ms/batch - loss: 39.21522 - diff: 25.27mlTrain batch 7/16 - 127.5ms/batch - loss: 36.90767 - diff: 24.75mlTrain batch 8/16 - 132.1ms/batch - loss: 36.60943 - diff: 24.65mlTrain batch 9/16 - 140.3ms/batch - loss: 38.84552 - diff: 25.20mlTrain batch 10/16 - 123.2ms/batch - loss: 36.76919 - diff: 24.64mlTrain batch 11/16 - 138.5ms/batch - loss: 52.09893 - diff: 26.00mlTrain batch 12/16 - 136.8ms/batch - loss: 49.02063 - diff: 25.31mlTrain batch 13/16 - 124.0ms/batch - loss: 49.81725 - diff: 25.87mlTrain batch 14/16 - 123.3ms/batch - loss: 48.48105 - diff: 25.79mlTrain batch 15/16 - 123.3ms/batch - loss: 47.54950 - diff: 25.88mlTrain batch 16/16 - 40.3ms/batch - loss: 48.64004 - diff: 25.89mlTrain batch 16/16 - 14.8s 40.3ms/batch - loss: 48.64004 - diff: 25.89ml
Test 1.0s: val_loss: 35.20208 - diff: 23.37ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Systole_VGG19_Adam-0.001_MSE_DA3_best

Epoch 21: current best loss = 35.20208, at epoch 20
Train batch 1/16 - 139.4ms/batch - loss: 37.65578 - diff: 28.54mlTrain batch 2/16 - 128.5ms/batch - loss: 31.10586 - diff: 25.80mlTrain batch 3/16 - 137.2ms/batch - loss: 34.15692 - diff: 26.51mlTrain batch 4/16 - 133.5ms/batch - loss: 73.59468 - diff: 30.59mlTrain batch 5/16 - 123.3ms/batch - loss: 63.92064 - diff: 29.13mlTrain batch 6/16 - 131.6ms/batch - loss: 59.58225 - diff: 28.32mlTrain batch 7/16 - 137.1ms/batch - loss: 53.20325 - diff: 26.69mlTrain batch 8/16 - 133.6ms/batch - loss: 50.40700 - diff: 25.94mlTrain batch 9/16 - 134.2ms/batch - loss: 48.81850 - diff: 25.78mlTrain batch 10/16 - 126.5ms/batch - loss: 51.85332 - diff: 26.16mlTrain batch 11/16 - 123.3ms/batch - loss: 49.60002 - diff: 25.73mlTrain batch 12/16 - 139.3ms/batch - loss: 49.21293 - diff: 25.77mlTrain batch 13/16 - 166.6ms/batch - loss: 47.87635 - diff: 25.54mlTrain batch 14/16 - 137.7ms/batch - loss: 47.84373 - diff: 25.61mlTrain batch 15/16 - 131.7ms/batch - loss: 48.33948 - diff: 25.75mlTrain batch 16/16 - 48.0ms/batch - loss: 50.02083 - diff: 25.79mlTrain batch 16/16 - 16.2s 48.0ms/batch - loss: 50.02083 - diff: 25.79ml
Test 1.1s: val_loss: 59.75445 - diff: 22.75ml

Epoch 22: current best loss = 35.20208, at epoch 20
Train batch 1/16 - 145.4ms/batch - loss: 15.26200 - diff: 18.66mlTrain batch 2/16 - 128.4ms/batch - loss: 30.54516 - diff: 22.50mlTrain batch 3/16 - 123.1ms/batch - loss: 34.57507 - diff: 24.12mlTrain batch 4/16 - 127.1ms/batch - loss: 37.11051 - diff: 25.00mlTrain batch 5/16 - 123.3ms/batch - loss: 33.83405 - diff: 24.10mlTrain batch 6/16 - 123.6ms/batch - loss: 32.27223 - diff: 23.41mlTrain batch 7/16 - 123.3ms/batch - loss: 36.93469 - diff: 24.37mlTrain batch 8/16 - 123.1ms/batch - loss: 41.28385 - diff: 25.16mlTrain batch 9/16 - 130.5ms/batch - loss: 39.14390 - diff: 24.91mlTrain batch 10/16 - 123.4ms/batch - loss: 38.45955 - diff: 25.10mlTrain batch 11/16 - 133.1ms/batch - loss: 37.73332 - diff: 25.12mlTrain batch 12/16 - 123.2ms/batch - loss: 48.46815 - diff: 25.72mlTrain batch 13/16 - 126.9ms/batch - loss: 50.75842 - diff: 26.32mlTrain batch 14/16 - 129.9ms/batch - loss: 49.51323 - diff: 26.26mlTrain batch 15/16 - 123.2ms/batch - loss: 48.05939 - diff: 26.11mlTrain batch 16/16 - 47.2ms/batch - loss: 49.05049 - diff: 26.05mlTrain batch 16/16 - 15.3s 47.2ms/batch - loss: 49.05049 - diff: 26.05ml
Test 1.1s: val_loss: 34.66205 - diff: 21.53ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Systole_VGG19_Adam-0.001_MSE_DA3_best

Epoch 23: current best loss = 34.66205, at epoch 22
Train batch 1/16 - 140.2ms/batch - loss: 39.89199 - diff: 26.69mlTrain batch 2/16 - 138.1ms/batch - loss: 43.44492 - diff: 26.30mlTrain batch 3/16 - 136.8ms/batch - loss: 33.37950 - diff: 22.99mlTrain batch 4/16 - 126.8ms/batch - loss: 35.64386 - diff: 23.62mlTrain batch 5/16 - 123.3ms/batch - loss: 44.66219 - diff: 24.61mlTrain batch 6/16 - 123.5ms/batch - loss: 42.06738 - diff: 24.37mlTrain batch 7/16 - 123.2ms/batch - loss: 42.90435 - diff: 25.04mlTrain batch 8/16 - 123.3ms/batch - loss: 42.37756 - diff: 25.25mlTrain batch 9/16 - 123.3ms/batch - loss: 41.25425 - diff: 25.30mlTrain batch 10/16 - 136.0ms/batch - loss: 40.92620 - diff: 25.41mlTrain batch 11/16 - 123.4ms/batch - loss: 54.30654 - diff: 26.50mlTrain batch 12/16 - 123.2ms/batch - loss: 51.37280 - diff: 25.95mlTrain batch 13/16 - 123.6ms/batch - loss: 48.91758 - diff: 25.53mlTrain batch 14/16 - 123.3ms/batch - loss: 48.97279 - diff: 25.86mlTrain batch 15/16 - 123.6ms/batch - loss: 49.41625 - diff: 25.77mlTrain batch 16/16 - 40.5ms/batch - loss: 49.08324 - diff: 25.55mlTrain batch 16/16 - 15.9s 40.5ms/batch - loss: 49.08324 - diff: 25.55ml
Test 1.1s: val_loss: 36.36421 - diff: 21.80ml

Epoch 24: current best loss = 34.66205, at epoch 22
Train batch 1/16 - 142.1ms/batch - loss: 35.50764 - diff: 27.56mlTrain batch 2/16 - 123.1ms/batch - loss: 34.75996 - diff: 25.86mlTrain batch 3/16 - 135.9ms/batch - loss: 38.11751 - diff: 25.58mlTrain batch 4/16 - 122.8ms/batch - loss: 34.65250 - diff: 24.24mlTrain batch 5/16 - 130.9ms/batch - loss: 36.18909 - diff: 24.61mlTrain batch 6/16 - 135.9ms/batch - loss: 33.56702 - diff: 24.11mlTrain batch 7/16 - 137.1ms/batch - loss: 32.27883 - diff: 23.15mlTrain batch 8/16 - 133.7ms/batch - loss: 31.22359 - diff: 23.08mlTrain batch 9/16 - 138.1ms/batch - loss: 29.72437 - diff: 22.68mlTrain batch 10/16 - 128.2ms/batch - loss: 43.25617 - diff: 24.20mlTrain batch 11/16 - 147.9ms/batch - loss: 42.68864 - diff: 24.16mlTrain batch 12/16 - 131.7ms/batch - loss: 40.71212 - diff: 23.67mlTrain batch 13/16 - 136.7ms/batch - loss: 45.36636 - diff: 24.78mlTrain batch 14/16 - 128.2ms/batch - loss: 44.09842 - diff: 24.68mlTrain batch 15/16 - 138.2ms/batch - loss: 43.82857 - diff: 24.86mlTrain batch 16/16 - 47.2ms/batch - loss: 47.02010 - diff: 25.01mlTrain batch 16/16 - 17.6s 47.2ms/batch - loss: 47.02010 - diff: 25.01ml
Test 1.2s: val_loss: 32.37109 - diff: 21.35ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Systole_VGG19_Adam-0.001_MSE_DA3_best

Epoch 25: current best loss = 32.37109, at epoch 24
Train batch 1/16 - 137.1ms/batch - loss: 166.49178 - diff: 34.82mlTrain batch 2/16 - 122.2ms/batch - loss: 102.55893 - diff: 31.05mlTrain batch 3/16 - 137.2ms/batch - loss: 74.96134 - diff: 27.58mlTrain batch 4/16 - 122.7ms/batch - loss: 62.02450 - diff: 26.10mlTrain batch 5/16 - 137.7ms/batch - loss: 54.30519 - diff: 25.31mlTrain batch 6/16 - 123.7ms/batch - loss: 49.23978 - diff: 24.72mlTrain batch 7/16 - 128.4ms/batch - loss: 54.02838 - diff: 26.34mlTrain batch 8/16 - 123.7ms/batch - loss: 49.31360 - diff: 25.24mlTrain batch 9/16 - 127.7ms/batch - loss: 46.57646 - diff: 24.68mlTrain batch 10/16 - 123.1ms/batch - loss: 46.10167 - diff: 24.86mlTrain batch 11/16 - 135.2ms/batch - loss: 46.17582 - diff: 25.47mlTrain batch 12/16 - 131.1ms/batch - loss: 48.20926 - diff: 25.54mlTrain batch 13/16 - 123.4ms/batch - loss: 47.76491 - diff: 25.72mlTrain batch 14/16 - 123.3ms/batch - loss: 46.15464 - diff: 25.36mlTrain batch 15/16 - 140.3ms/batch - loss: 44.78856 - diff: 25.24mlTrain batch 16/16 - 50.6ms/batch - loss: 51.85857 - diff: 25.53mlTrain batch 16/16 - 15.5s 50.6ms/batch - loss: 51.85857 - diff: 25.53ml
Test 1.1s: val_loss: 68.15436 - diff: 33.10ml

Epoch 26: current best loss = 32.37109, at epoch 24
Train batch 1/16 - 135.6ms/batch - loss: 59.72897 - diff: 30.13mlTrain batch 2/16 - 132.7ms/batch - loss: 49.42480 - diff: 28.85mlTrain batch 3/16 - 123.2ms/batch - loss: 46.72321 - diff: 28.85mlTrain batch 4/16 - 123.1ms/batch - loss: 43.69661 - diff: 27.56mlTrain batch 5/16 - 123.3ms/batch - loss: 43.81028 - diff: 27.64mlTrain batch 6/16 - 123.3ms/batch - loss: 43.70033 - diff: 27.45mlTrain batch 7/16 - 123.1ms/batch - loss: 40.02060 - diff: 26.37mlTrain batch 8/16 - 128.8ms/batch - loss: 38.40186 - diff: 25.87mlTrain batch 9/16 - 129.9ms/batch - loss: 42.58215 - diff: 26.39mlTrain batch 10/16 - 123.1ms/batch - loss: 40.83723 - diff: 26.19mlTrain batch 11/16 - 137.1ms/batch - loss: 38.84161 - diff: 25.55mlTrain batch 12/16 - 123.2ms/batch - loss: 40.35741 - diff: 25.86mlTrain batch 13/16 - 128.2ms/batch - loss: 39.69455 - diff: 25.66mlTrain batch 14/16 - 128.3ms/batch - loss: 38.20674 - diff: 25.08mlTrain batch 15/16 - 123.4ms/batch - loss: 46.85657 - diff: 25.39mlTrain batch 16/16 - 40.4ms/batch - loss: 47.54642 - diff: 25.38mlTrain batch 16/16 - 15.8s 40.4ms/batch - loss: 47.54642 - diff: 25.38ml
Test 1.0s: val_loss: 39.05806 - diff: 22.16ml

Epoch 27: current best loss = 32.37109, at epoch 24
Train batch 1/16 - 135.5ms/batch - loss: 26.56008 - diff: 25.12mlTrain batch 2/16 - 123.5ms/batch - loss: 27.17939 - diff: 23.84mlTrain batch 3/16 - 123.2ms/batch - loss: 41.92082 - diff: 26.33mlTrain batch 4/16 - 122.9ms/batch - loss: 35.43144 - diff: 23.98mlTrain batch 5/16 - 136.6ms/batch - loss: 36.23314 - diff: 23.56mlTrain batch 6/16 - 124.3ms/batch - loss: 34.08164 - diff: 23.06mlTrain batch 7/16 - 123.2ms/batch - loss: 44.51120 - diff: 24.55mlTrain batch 8/16 - 122.6ms/batch - loss: 42.21064 - diff: 24.14mlTrain batch 9/16 - 123.4ms/batch - loss: 42.56261 - diff: 24.36mlTrain batch 10/16 - 123.5ms/batch - loss: 58.62187 - diff: 25.86mlTrain batch 11/16 - 123.3ms/batch - loss: 56.22138 - diff: 25.65mlTrain batch 12/16 - 123.2ms/batch - loss: 53.07839 - diff: 25.00mlTrain batch 13/16 - 123.2ms/batch - loss: 51.15790 - diff: 25.07mlTrain batch 14/16 - 136.8ms/batch - loss: 51.66796 - diff: 25.70mlTrain batch 15/16 - 133.0ms/batch - loss: 51.09383 - diff: 25.88mlTrain batch 16/16 - 40.2ms/batch - loss: 51.46787 - diff: 25.78mlTrain batch 16/16 - 15.0s 40.2ms/batch - loss: 51.46787 - diff: 25.78ml
Test 1.2s: val_loss: 36.87320 - diff: 21.94ml

Epoch 28: current best loss = 32.37109, at epoch 24
Train batch 1/16 - 141.9ms/batch - loss: 181.79532 - diff: 41.97mlTrain batch 2/16 - 123.5ms/batch - loss: 111.56391 - diff: 36.15mlTrain batch 3/16 - 123.3ms/batch - loss: 82.94118 - diff: 32.04mlTrain batch 4/16 - 122.6ms/batch - loss: 66.65935 - diff: 28.79mlTrain batch 5/16 - 148.9ms/batch - loss: 56.39669 - diff: 26.33mlTrain batch 6/16 - 122.3ms/batch - loss: 52.88564 - diff: 26.05mlTrain batch 7/16 - 132.9ms/batch - loss: 47.90044 - diff: 24.96mlTrain batch 8/16 - 140.5ms/batch - loss: 45.83103 - diff: 24.50mlTrain batch 9/16 - 131.9ms/batch - loss: 45.01796 - diff: 24.34mlTrain batch 10/16 - 134.6ms/batch - loss: 49.51613 - diff: 25.79mlTrain batch 11/16 - 123.1ms/batch - loss: 47.93641 - diff: 25.40mlTrain batch 12/16 - 123.5ms/batch - loss: 49.63710 - diff: 25.53mlTrain batch 13/16 - 123.3ms/batch - loss: 50.10654 - diff: 25.72mlTrain batch 14/16 - 122.9ms/batch - loss: 49.07163 - diff: 25.20mlTrain batch 15/16 - 123.2ms/batch - loss: 46.59301 - diff: 24.62mlTrain batch 16/16 - 40.4ms/batch - loss: 53.27769 - diff: 25.01mlTrain batch 16/16 - 16.0s 40.4ms/batch - loss: 53.27769 - diff: 25.01ml
Test 1.0s: val_loss: 34.48561 - diff: 21.69ml

Epoch 29: current best loss = 32.37109, at epoch 24
Train batch 1/16 - 135.9ms/batch - loss: 164.25011 - diff: 34.69mlTrain batch 2/16 - 129.7ms/batch - loss: 100.09288 - diff: 30.26mlTrain batch 3/16 - 140.3ms/batch - loss: 84.56916 - diff: 31.76mlTrain batch 4/16 - 129.1ms/batch - loss: 70.77325 - diff: 30.29mlTrain batch 5/16 - 123.2ms/batch - loss: 60.20975 - diff: 28.32mlTrain batch 6/16 - 123.9ms/batch - loss: 58.06648 - diff: 28.77mlTrain batch 7/16 - 123.4ms/batch - loss: 54.46602 - diff: 28.22mlTrain batch 8/16 - 134.0ms/batch - loss: 49.98818 - diff: 27.10mlTrain batch 9/16 - 123.4ms/batch - loss: 54.59125 - diff: 27.89mlTrain batch 10/16 - 123.3ms/batch - loss: 52.03163 - diff: 27.42mlTrain batch 11/16 - 137.2ms/batch - loss: 49.42432 - diff: 26.87mlTrain batch 12/16 - 132.3ms/batch - loss: 49.06570 - diff: 26.80mlTrain batch 13/16 - 135.8ms/batch - loss: 48.31405 - diff: 26.72mlTrain batch 14/16 - 132.9ms/batch - loss: 47.13562 - diff: 26.58mlTrain batch 15/16 - 123.2ms/batch - loss: 48.97150 - diff: 26.80mlTrain batch 16/16 - 40.5ms/batch - loss: 50.22202 - diff: 26.67mlTrain batch 16/16 - 16.4s 40.5ms/batch - loss: 50.22202 - diff: 26.67ml
Test 1.1s: val_loss: 29.83492 - diff: 22.03ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Systole_VGG19_Adam-0.001_MSE_DA3_best

Epoch 30: current best loss = 29.83492, at epoch 29
Train batch 1/16 - 135.6ms/batch - loss: 21.78134 - diff: 19.72mlTrain batch 2/16 - 127.8ms/batch - loss: 37.32755 - diff: 24.48mlTrain batch 3/16 - 136.7ms/batch - loss: 40.79469 - diff: 25.55mlTrain batch 4/16 - 132.5ms/batch - loss: 73.48370 - diff: 27.28mlTrain batch 5/16 - 123.4ms/batch - loss: 67.20767 - diff: 27.21mlTrain batch 6/16 - 123.5ms/batch - loss: 65.05665 - diff: 27.73mlTrain batch 7/16 - 123.3ms/batch - loss: 60.97851 - diff: 27.54mlTrain batch 8/16 - 123.5ms/batch - loss: 60.11191 - diff: 27.76mlTrain batch 9/16 - 134.0ms/batch - loss: 55.36744 - diff: 26.89mlTrain batch 10/16 - 131.4ms/batch - loss: 52.95579 - diff: 26.86mlTrain batch 11/16 - 137.3ms/batch - loss: 51.66100 - diff: 26.80mlTrain batch 12/16 - 131.7ms/batch - loss: 50.79290 - diff: 27.10mlTrain batch 13/16 - 143.7ms/batch - loss: 48.49092 - diff: 26.62mlTrain batch 14/16 - 123.3ms/batch - loss: 46.28124 - diff: 26.04mlTrain batch 15/16 - 142.8ms/batch - loss: 48.59906 - diff: 26.43mlTrain batch 16/16 - 45.8ms/batch - loss: 49.46296 - diff: 26.43mlTrain batch 16/16 - 17.5s 45.8ms/batch - loss: 49.46296 - diff: 26.43ml
Test 1.1s: val_loss: 36.40726 - diff: 21.94ml

Epoch 31: current best loss = 29.83492, at epoch 29
Train batch 1/16 - 136.6ms/batch - loss: 16.89115 - diff: 19.21mlTrain batch 2/16 - 124.6ms/batch - loss: 34.43944 - diff: 22.83mlTrain batch 3/16 - 137.2ms/batch - loss: 44.18998 - diff: 25.42mlTrain batch 4/16 - 132.9ms/batch - loss: 40.08774 - diff: 24.47mlTrain batch 5/16 - 136.8ms/batch - loss: 40.17638 - diff: 24.53mlTrain batch 6/16 - 124.8ms/batch - loss: 38.61095 - diff: 24.11mlTrain batch 7/16 - 145.4ms/batch - loss: 42.17674 - diff: 24.97mlTrain batch 8/16 - 133.8ms/batch - loss: 39.04812 - diff: 24.13mlTrain batch 9/16 - 136.7ms/batch - loss: 38.23946 - diff: 24.10mlTrain batch 10/16 - 127.3ms/batch - loss: 50.92846 - diff: 25.46mlTrain batch 11/16 - 133.8ms/batch - loss: 48.13952 - diff: 25.11mlTrain batch 12/16 - 122.5ms/batch - loss: 49.92345 - diff: 25.20mlTrain batch 13/16 - 136.9ms/batch - loss: 49.01016 - diff: 25.17mlTrain batch 14/16 - 157.4ms/batch - loss: 47.29722 - diff: 25.06mlTrain batch 15/16 - 123.4ms/batch - loss: 45.58319 - diff: 24.84mlTrain batch 16/16 - 41.0ms/batch - loss: 46.26369 - diff: 24.73mlTrain batch 16/16 - 17.2s 41.0ms/batch - loss: 46.26369 - diff: 24.73ml
Test 0.7s: val_loss: 32.57641 - diff: 21.56ml

Epoch 32: current best loss = 29.83492, at epoch 29
Train batch 1/16 - 123.4ms/batch - loss: 50.70975 - diff: 29.15mlTrain batch 2/16 - 124.2ms/batch - loss: 135.22578 - diff: 35.86mlTrain batch 3/16 - 124.5ms/batch - loss: 98.57540 - diff: 31.75mlTrain batch 4/16 - 123.9ms/batch - loss: 78.75660 - diff: 28.79mlTrain batch 5/16 - 136.7ms/batch - loss: 69.22413 - diff: 28.29mlTrain batch 6/16 - 138.7ms/batch - loss: 61.88870 - diff: 27.01mlTrain batch 7/16 - 142.7ms/batch - loss: 55.16581 - diff: 25.68mlTrain batch 8/16 - 143.8ms/batch - loss: 51.40875 - diff: 25.33mlTrain batch 9/16 - 136.1ms/batch - loss: 50.26511 - diff: 25.72mlTrain batch 10/16 - 131.8ms/batch - loss: 47.65613 - diff: 25.25mlTrain batch 11/16 - 123.2ms/batch - loss: 47.14596 - diff: 25.41mlTrain batch 12/16 - 125.4ms/batch - loss: 46.46817 - diff: 25.37mlTrain batch 13/16 - 123.4ms/batch - loss: 46.77324 - diff: 25.74mlTrain batch 14/16 - 123.2ms/batch - loss: 46.54283 - diff: 25.63mlTrain batch 15/16 - 123.4ms/batch - loss: 45.83897 - diff: 25.37mlTrain batch 16/16 - 40.5ms/batch - loss: 50.35250 - diff: 25.43mlTrain batch 16/16 - 15.0s 40.5ms/batch - loss: 50.35250 - diff: 25.43ml
Test 1.0s: val_loss: 39.00404 - diff: 21.11ml

Epoch 33: current best loss = 29.83492, at epoch 29
Train batch 1/16 - 136.8ms/batch - loss: 24.59002 - diff: 22.71mlTrain batch 2/16 - 127.5ms/batch - loss: 28.34820 - diff: 22.73mlTrain batch 3/16 - 123.3ms/batch - loss: 36.50258 - diff: 24.39mlTrain batch 4/16 - 133.2ms/batch - loss: 33.84568 - diff: 23.03mlTrain batch 5/16 - 136.9ms/batch - loss: 32.46114 - diff: 23.17mlTrain batch 6/16 - 132.5ms/batch - loss: 30.96145 - diff: 22.64mlTrain batch 7/16 - 123.4ms/batch - loss: 30.27367 - diff: 22.57mlTrain batch 8/16 - 123.2ms/batch - loss: 43.80728 - diff: 23.25mlTrain batch 9/16 - 136.1ms/batch - loss: 48.74671 - diff: 24.59mlTrain batch 10/16 - 123.4ms/batch - loss: 48.18861 - diff: 25.02mlTrain batch 11/16 - 123.3ms/batch - loss: 46.45581 - diff: 24.91mlTrain batch 12/16 - 123.4ms/batch - loss: 45.33070 - diff: 24.95mlTrain batch 13/16 - 132.7ms/batch - loss: 43.57747 - diff: 24.86mlTrain batch 14/16 - 129.1ms/batch - loss: 43.15797 - diff: 25.07mlTrain batch 15/16 - 136.8ms/batch - loss: 42.46378 - diff: 25.08mlTrain batch 16/16 - 44.4ms/batch - loss: 44.02035 - diff: 25.05mlTrain batch 16/16 - 15.2s 44.4ms/batch - loss: 44.02035 - diff: 25.05ml
Test 1.0s: val_loss: 36.39703 - diff: 21.23ml

Epoch 34: current best loss = 29.83492, at epoch 29
Train batch 1/16 - 137.1ms/batch - loss: 87.46304 - diff: 30.09mlTrain batch 2/16 - 123.7ms/batch - loss: 51.60233 - diff: 23.72mlTrain batch 3/16 - 137.2ms/batch - loss: 48.83725 - diff: 25.02mlTrain batch 4/16 - 133.3ms/batch - loss: 51.48470 - diff: 26.24mlTrain batch 5/16 - 137.0ms/batch - loss: 49.69843 - diff: 26.18mlTrain batch 6/16 - 130.2ms/batch - loss: 47.37204 - diff: 25.56mlTrain batch 7/16 - 123.3ms/batch - loss: 44.36535 - diff: 25.34mlTrain batch 8/16 - 122.3ms/batch - loss: 43.22965 - diff: 25.22mlTrain batch 9/16 - 136.8ms/batch - loss: 39.35440 - diff: 23.76mlTrain batch 10/16 - 125.2ms/batch - loss: 38.20499 - diff: 23.79mlTrain batch 11/16 - 132.5ms/batch - loss: 51.59541 - diff: 25.11mlTrain batch 12/16 - 123.9ms/batch - loss: 50.06922 - diff: 24.95mlTrain batch 13/16 - 136.6ms/batch - loss: 49.99856 - diff: 25.55mlTrain batch 14/16 - 132.8ms/batch - loss: 47.62105 - diff: 25.08mlTrain batch 15/16 - 123.4ms/batch - loss: 46.88863 - diff: 25.33mlTrain batch 16/16 - 40.5ms/batch - loss: 50.82938 - diff: 25.44mlTrain batch 16/16 - 17.4s 40.5ms/batch - loss: 50.82938 - diff: 25.44ml
Test 1.1s: val_loss: 42.68200 - diff: 20.64ml

Epoch 35: current best loss = 29.83492, at epoch 29
Train batch 1/16 - 123.4ms/batch - loss: 31.43225 - diff: 22.91mlTrain batch 2/16 - 123.4ms/batch - loss: 26.43202 - diff: 21.44mlTrain batch 3/16 - 130.2ms/batch - loss: 32.87063 - diff: 23.45mlTrain batch 4/16 - 132.1ms/batch - loss: 33.33007 - diff: 23.38mlTrain batch 5/16 - 132.0ms/batch - loss: 55.97944 - diff: 24.78mlTrain batch 6/16 - 130.1ms/batch - loss: 54.87546 - diff: 25.65mlTrain batch 7/16 - 136.0ms/batch - loss: 51.57902 - diff: 25.08mlTrain batch 8/16 - 123.3ms/batch - loss: 56.23770 - diff: 26.46mlTrain batch 9/16 - 135.6ms/batch - loss: 52.73675 - diff: 26.09mlTrain batch 10/16 - 139.1ms/batch - loss: 49.81205 - diff: 25.60mlTrain batch 11/16 - 123.6ms/batch - loss: 47.56187 - diff: 25.35mlTrain batch 12/16 - 123.3ms/batch - loss: 44.99080 - diff: 24.78mlTrain batch 13/16 - 123.4ms/batch - loss: 45.25727 - diff: 25.12mlTrain batch 14/16 - 123.4ms/batch - loss: 44.05924 - diff: 25.04mlTrain batch 15/16 - 123.3ms/batch - loss: 42.51774 - diff: 24.67mlTrain batch 16/16 - 40.4ms/batch - loss: 44.04085 - diff: 24.69mlTrain batch 16/16 - 15.7s 40.4ms/batch - loss: 44.04085 - diff: 24.69ml
Test 1.0s: val_loss: 33.22112 - diff: 22.59ml

Epoch 36: current best loss = 29.83492, at epoch 29
Train batch 1/16 - 135.6ms/batch - loss: 23.95484 - diff: 24.06mlTrain batch 2/16 - 123.3ms/batch - loss: 25.53853 - diff: 24.31mlTrain batch 3/16 - 123.3ms/batch - loss: 69.28017 - diff: 26.34mlTrain batch 4/16 - 134.3ms/batch - loss: 59.17498 - diff: 24.57mlTrain batch 5/16 - 131.7ms/batch - loss: 50.53303 - diff: 23.19mlTrain batch 6/16 - 133.1ms/batch - loss: 46.73231 - diff: 22.66mlTrain batch 7/16 - 123.2ms/batch - loss: 56.43033 - diff: 25.30mlTrain batch 8/16 - 137.4ms/batch - loss: 54.63388 - diff: 25.20mlTrain batch 9/16 - 128.0ms/batch - loss: 51.08509 - diff: 24.70mlTrain batch 10/16 - 125.4ms/batch - loss: 50.25180 - diff: 24.70mlTrain batch 11/16 - 124.1ms/batch - loss: 49.45725 - diff: 24.99mlTrain batch 12/16 - 123.4ms/batch - loss: 48.10817 - diff: 24.73mlTrain batch 13/16 - 129.2ms/batch - loss: 45.43003 - diff: 24.13mlTrain batch 14/16 - 133.5ms/batch - loss: 45.70004 - diff: 24.61mlTrain batch 15/16 - 123.9ms/batch - loss: 44.50998 - diff: 24.55mlTrain batch 16/16 - 40.5ms/batch - loss: 44.92305 - diff: 24.47mlTrain batch 16/16 - 16.0s 40.5ms/batch - loss: 44.92305 - diff: 24.47ml
Test 1.2s: val_loss: 42.48512 - diff: 23.16ml

Epoch 37: current best loss = 29.83492, at epoch 29
Train batch 1/16 - 141.1ms/batch - loss: 46.80607 - diff: 26.92mlTrain batch 2/16 - 132.6ms/batch - loss: 57.92122 - diff: 27.79mlTrain batch 3/16 - 127.3ms/batch - loss: 49.30080 - diff: 26.85mlTrain batch 4/16 - 124.7ms/batch - loss: 47.83655 - diff: 27.00mlTrain batch 5/16 - 123.2ms/batch - loss: 47.79811 - diff: 27.81mlTrain batch 6/16 - 127.1ms/batch - loss: 45.55088 - diff: 27.29mlTrain batch 7/16 - 123.6ms/batch - loss: 43.36364 - diff: 27.00mlTrain batch 8/16 - 127.4ms/batch - loss: 57.74980 - diff: 27.76mlTrain batch 9/16 - 150.1ms/batch - loss: 57.22406 - diff: 28.09mlTrain batch 10/16 - 123.7ms/batch - loss: 54.65495 - diff: 27.88mlTrain batch 11/16 - 127.6ms/batch - loss: 50.93161 - diff: 26.84mlTrain batch 12/16 - 129.4ms/batch - loss: 48.49978 - diff: 26.24mlTrain batch 13/16 - 131.9ms/batch - loss: 46.55672 - diff: 26.00mlTrain batch 14/16 - 123.1ms/batch - loss: 45.12141 - diff: 25.76mlTrain batch 15/16 - 123.5ms/batch - loss: 43.18244 - diff: 25.17mlTrain batch 16/16 - 40.2ms/batch - loss: 42.98744 - diff: 25.00mlTrain batch 16/16 - 15.8s 40.2ms/batch - loss: 42.98744 - diff: 25.00ml
Test 1.1s: val_loss: 32.76080 - diff: 21.09ml

Epoch 38: current best loss = 29.83492, at epoch 29
Train batch 1/16 - 144.8ms/batch - loss: 34.15768 - diff: 20.98mlTrain batch 2/16 - 131.3ms/batch - loss: 26.37562 - diff: 19.92mlTrain batch 3/16 - 144.1ms/batch - loss: 26.11160 - diff: 18.88mlTrain batch 4/16 - 123.4ms/batch - loss: 31.26079 - diff: 20.31mlTrain batch 5/16 - 123.2ms/batch - loss: 35.31173 - diff: 21.21mlTrain batch 6/16 - 123.2ms/batch - loss: 40.53285 - diff: 22.47mlTrain batch 7/16 - 130.7ms/batch - loss: 38.55610 - diff: 22.53mlTrain batch 8/16 - 123.4ms/batch - loss: 37.04543 - diff: 22.52mlTrain batch 9/16 - 136.9ms/batch - loss: 50.76867 - diff: 23.90mlTrain batch 10/16 - 123.3ms/batch - loss: 48.62029 - diff: 23.43mlTrain batch 11/16 - 123.3ms/batch - loss: 46.66977 - diff: 23.45mlTrain batch 12/16 - 123.8ms/batch - loss: 45.05500 - diff: 23.54mlTrain batch 13/16 - 135.6ms/batch - loss: 42.96404 - diff: 23.28mlTrain batch 14/16 - 122.5ms/batch - loss: 42.26080 - diff: 23.44mlTrain batch 15/16 - 123.3ms/batch - loss: 40.79076 - diff: 23.32mlTrain batch 16/16 - 40.5ms/batch - loss: 44.65937 - diff: 23.47mlTrain batch 16/16 - 17.4s 40.5ms/batch - loss: 44.65937 - diff: 23.47ml
Test 1.0s: val_loss: 32.93596 - diff: 20.97ml

Epoch 39: current best loss = 29.83492, at epoch 29
Train batch 1/16 - 146.2ms/batch - loss: 28.30507 - diff: 24.39mlTrain batch 2/16 - 128.5ms/batch - loss: 53.26945 - diff: 27.29mlTrain batch 3/16 - 123.2ms/batch - loss: 45.04927 - diff: 26.21mlTrain batch 4/16 - 133.6ms/batch - loss: 39.70242 - diff: 24.81mlTrain batch 5/16 - 131.1ms/batch - loss: 38.60483 - diff: 24.34mlTrain batch 6/16 - 123.2ms/batch - loss: 36.23716 - diff: 24.00mlTrain batch 7/16 - 127.7ms/batch - loss: 34.99339 - diff: 23.64mlTrain batch 8/16 - 129.5ms/batch - loss: 34.52182 - diff: 23.82mlTrain batch 9/16 - 138.9ms/batch - loss: 33.12282 - diff: 23.46mlTrain batch 10/16 - 132.4ms/batch - loss: 34.92052 - diff: 23.97mlTrain batch 11/16 - 142.3ms/batch - loss: 35.44042 - diff: 23.79mlTrain batch 12/16 - 133.6ms/batch - loss: 46.58750 - diff: 25.08mlTrain batch 13/16 - 123.7ms/batch - loss: 45.05198 - diff: 25.06mlTrain batch 14/16 - 122.7ms/batch - loss: 43.49717 - diff: 24.77mlTrain batch 15/16 - 123.2ms/batch - loss: 42.67276 - diff: 24.65mlTrain batch 16/16 - 40.4ms/batch - loss: 44.33710 - diff: 24.76mlTrain batch 16/16 - 16.7s 40.4ms/batch - loss: 44.33710 - diff: 24.76ml
Test 1.1s: val_loss: 37.22772 - diff: 21.16ml

Epoch 40: current best loss = 29.83492, at epoch 29
Train batch 1/16 - 139.0ms/batch - loss: 39.67215 - diff: 23.38mlTrain batch 2/16 - 130.7ms/batch - loss: 33.58471 - diff: 23.73mlTrain batch 3/16 - 124.5ms/batch - loss: 34.15294 - diff: 24.45mlTrain batch 4/16 - 123.2ms/batch - loss: 72.80673 - diff: 29.74mlTrain batch 5/16 - 137.1ms/batch - loss: 64.81145 - diff: 28.36mlTrain batch 6/16 - 123.3ms/batch - loss: 60.18563 - diff: 28.32mlTrain batch 7/16 - 130.7ms/batch - loss: 55.74917 - diff: 27.39mlTrain batch 8/16 - 123.5ms/batch - loss: 56.34697 - diff: 27.09mlTrain batch 9/16 - 134.8ms/batch - loss: 53.60592 - diff: 26.72mlTrain batch 10/16 - 123.3ms/batch - loss: 50.01986 - diff: 25.97mlTrain batch 11/16 - 134.7ms/batch - loss: 47.57138 - diff: 25.55mlTrain batch 12/16 - 143.5ms/batch - loss: 45.80244 - diff: 24.95mlTrain batch 13/16 - 131.6ms/batch - loss: 44.57716 - diff: 24.74mlTrain batch 14/16 - 138.3ms/batch - loss: 42.29273 - diff: 24.14mlTrain batch 15/16 - 123.4ms/batch - loss: 41.82452 - diff: 24.38mlTrain batch 16/16 - 40.5ms/batch - loss: 42.51596 - diff: 24.35mlTrain batch 16/16 - 16.7s 40.5ms/batch - loss: 42.51596 - diff: 24.35ml
Test 1.0s: val_loss: 41.74398 - diff: 25.29ml
Epoch    41: reducing learning rate of group 0 to 5.0000e-04.

Epoch 41: current best loss = 29.83492, at epoch 29
Train batch 1/16 - 136.7ms/batch - loss: 46.12022 - diff: 27.67mlTrain batch 2/16 - 123.6ms/batch - loss: 33.32301 - diff: 24.46mlTrain batch 3/16 - 131.5ms/batch - loss: 29.48591 - diff: 23.43mlTrain batch 4/16 - 129.8ms/batch - loss: 39.07847 - diff: 23.72mlTrain batch 5/16 - 137.9ms/batch - loss: 36.02207 - diff: 22.53mlTrain batch 6/16 - 123.4ms/batch - loss: 33.95181 - diff: 22.36mlTrain batch 7/16 - 123.4ms/batch - loss: 34.71760 - diff: 22.61mlTrain batch 8/16 - 123.4ms/batch - loss: 37.26962 - diff: 23.14mlTrain batch 9/16 - 123.4ms/batch - loss: 36.38633 - diff: 23.22mlTrain batch 10/16 - 123.4ms/batch - loss: 35.43115 - diff: 23.29mlTrain batch 11/16 - 140.7ms/batch - loss: 35.92571 - diff: 23.58mlTrain batch 12/16 - 127.3ms/batch - loss: 34.74190 - diff: 23.37mlTrain batch 13/16 - 123.4ms/batch - loss: 44.72801 - diff: 24.48mlTrain batch 14/16 - 123.4ms/batch - loss: 42.67324 - diff: 23.98mlTrain batch 15/16 - 131.2ms/batch - loss: 42.27190 - diff: 24.21mlTrain batch 16/16 - 40.4ms/batch - loss: 42.49264 - diff: 24.13mlTrain batch 16/16 - 14.5s 40.4ms/batch - loss: 42.49264 - diff: 24.13ml
Test 1.1s: val_loss: 33.65810 - diff: 21.98ml

Epoch 42: current best loss = 29.83492, at epoch 29
Train batch 1/16 - 136.5ms/batch - loss: 23.69970 - diff: 21.15mlTrain batch 2/16 - 143.1ms/batch - loss: 30.22057 - diff: 22.09mlTrain batch 3/16 - 123.5ms/batch - loss: 32.27859 - diff: 22.90mlTrain batch 4/16 - 123.9ms/batch - loss: 31.84645 - diff: 23.21mlTrain batch 5/16 - 123.4ms/batch - loss: 31.51281 - diff: 23.67mlTrain batch 6/16 - 123.9ms/batch - loss: 33.65172 - diff: 23.90mlTrain batch 7/16 - 125.8ms/batch - loss: 32.52500 - diff: 23.57mlTrain batch 8/16 - 128.4ms/batch - loss: 32.54987 - diff: 23.53mlTrain batch 9/16 - 123.4ms/batch - loss: 34.41388 - diff: 24.22mlTrain batch 10/16 - 128.5ms/batch - loss: 34.12307 - diff: 24.23mlTrain batch 11/16 - 136.7ms/batch - loss: 34.56448 - diff: 24.53mlTrain batch 12/16 - 125.1ms/batch - loss: 44.17345 - diff: 24.97mlTrain batch 13/16 - 136.5ms/batch - loss: 47.88577 - diff: 25.47mlTrain batch 14/16 - 131.3ms/batch - loss: 46.71662 - diff: 25.49mlTrain batch 15/16 - 123.1ms/batch - loss: 45.01867 - diff: 25.28mlTrain batch 16/16 - 55.3ms/batch - loss: 45.45128 - diff: 25.21mlTrain batch 16/16 - 15.5s 55.3ms/batch - loss: 45.45128 - diff: 25.21ml
Test 1.0s: val_loss: 31.24509 - diff: 20.66ml

Epoch 43: current best loss = 29.83492, at epoch 29
Train batch 1/16 - 137.0ms/batch - loss: 25.49391 - diff: 21.11mlTrain batch 2/16 - 123.4ms/batch - loss: 41.10604 - diff: 26.41mlTrain batch 3/16 - 123.5ms/batch - loss: 37.85126 - diff: 24.80mlTrain batch 4/16 - 124.2ms/batch - loss: 58.79747 - diff: 26.00mlTrain batch 5/16 - 123.3ms/batch - loss: 51.77995 - diff: 25.41mlTrain batch 6/16 - 130.1ms/batch - loss: 46.66398 - diff: 24.94mlTrain batch 7/16 - 139.2ms/batch - loss: 46.59862 - diff: 25.61mlTrain batch 8/16 - 128.7ms/batch - loss: 47.02483 - diff: 25.88mlTrain batch 9/16 - 135.8ms/batch - loss: 43.52500 - diff: 25.04mlTrain batch 10/16 - 139.6ms/batch - loss: 45.48961 - diff: 25.34mlTrain batch 11/16 - 135.5ms/batch - loss: 43.15810 - diff: 24.66mlTrain batch 12/16 - 123.3ms/batch - loss: 41.77353 - diff: 24.65mlTrain batch 13/16 - 123.3ms/batch - loss: 41.25223 - diff: 24.87mlTrain batch 14/16 - 123.4ms/batch - loss: 41.43148 - diff: 25.08mlTrain batch 15/16 - 123.2ms/batch - loss: 41.78572 - diff: 25.15mlTrain batch 16/16 - 40.4ms/batch - loss: 42.11540 - diff: 25.06mlTrain batch 16/16 - 15.0s 40.4ms/batch - loss: 42.11540 - diff: 25.06ml
Test 0.9s: val_loss: 38.03589 - diff: 21.00ml

Epoch 44: current best loss = 29.83492, at epoch 29
Train batch 1/16 - 142.7ms/batch - loss: 30.07241 - diff: 23.75mlTrain batch 2/16 - 125.7ms/batch - loss: 48.95909 - diff: 25.64mlTrain batch 3/16 - 123.3ms/batch - loss: 47.77917 - diff: 26.62mlTrain batch 4/16 - 131.8ms/batch - loss: 41.55106 - diff: 24.90mlTrain batch 5/16 - 127.8ms/batch - loss: 40.41278 - diff: 24.68mlTrain batch 6/16 - 123.3ms/batch - loss: 40.30029 - diff: 25.07mlTrain batch 7/16 - 139.3ms/batch - loss: 40.31517 - diff: 25.33mlTrain batch 8/16 - 123.7ms/batch - loss: 51.17152 - diff: 25.87mlTrain batch 9/16 - 123.4ms/batch - loss: 48.81545 - diff: 25.70mlTrain batch 10/16 - 123.7ms/batch - loss: 46.76241 - diff: 25.51mlTrain batch 11/16 - 139.2ms/batch - loss: 44.81625 - diff: 25.31mlTrain batch 12/16 - 132.6ms/batch - loss: 44.68833 - diff: 25.41mlTrain batch 13/16 - 127.7ms/batch - loss: 42.97450 - diff: 24.99mlTrain batch 14/16 - 127.9ms/batch - loss: 40.99313 - diff: 24.49mlTrain batch 15/16 - 134.3ms/batch - loss: 40.43852 - diff: 24.66mlTrain batch 16/16 - 48.3ms/batch - loss: 40.94787 - diff: 24.60mlTrain batch 16/16 - 16.1s 48.3ms/batch - loss: 40.94787 - diff: 24.60ml
Test 1.1s: val_loss: 33.71015 - diff: 20.25ml

Epoch 45: current best loss = 29.83492, at epoch 29
Going to unfreeze the pretrained weights
Train batch 1/16 - 184.6ms/batch - loss: 59.91396 - diff: 23.40mlTrain batch 2/16 - 171.3ms/batch - loss: 73075.48823 - diff: 1077.15mlTrain batch 3/16 - 208.0ms/batch - loss: 48743.09714 - diff: 731.58mlTrain batch 4/16 - 170.0ms/batch - loss: 36595.42858 - diff: 563.60mlTrain batch 5/16 - 180.3ms/batch - loss: 29280.11666 - diff: 455.25mlTrain batch 6/16 - 169.9ms/batch - loss: 24411.42178 - diff: 386.08mlTrain batch 7/16 - 169.8ms/batch - loss: 20931.13274 - diff: 335.30mlTrain batch 8/16 - 175.3ms/batch - loss: 18326.02480 - diff: 297.56mlTrain batch 9/16 - 169.7ms/batch - loss: 16315.78492 - diff: 270.96mlTrain batch 10/16 - 172.8ms/batch - loss: 14691.64922 - diff: 248.00mlTrain batch 11/16 - 169.6ms/batch - loss: 13367.90179 - diff: 229.37mlTrain batch 12/16 - 169.6ms/batch - loss: 12255.73289 - diff: 211.93mlTrain batch 13/16 - 178.7ms/batch - loss: 11316.13331 - diff: 198.07mlTrain batch 14/16 - 173.5ms/batch - loss: 10512.82948 - diff: 186.26mlTrain batch 15/16 - 169.6ms/batch - loss: 9816.37525 - diff: 175.88mlTrain batch 16/16 - 56.0ms/batch - loss: 9678.58116 - diff: 173.84mlTrain batch 16/16 - 16.8s 56.0ms/batch - loss: 9678.58116 - diff: 173.84ml
Test 1.1s: val_loss: 57.47382 - diff: 26.97ml

Epoch 46: current best loss = 29.83492, at epoch 29
Train batch 1/16 - 185.3ms/batch - loss: 273.15588 - diff: 50.29mlTrain batch 2/16 - 169.4ms/batch - loss: 147.56885 - diff: 36.25mlTrain batch 3/16 - 191.1ms/batch - loss: 118.65425 - diff: 36.39mlTrain batch 4/16 - 174.8ms/batch - loss: 95.80917 - diff: 32.86mlTrain batch 5/16 - 172.1ms/batch - loss: 84.72388 - diff: 31.45mlTrain batch 6/16 - 169.6ms/batch - loss: 86.59316 - diff: 33.06mlTrain batch 7/16 - 169.7ms/batch - loss: 80.05559 - diff: 32.55mlTrain batch 8/16 - 171.1ms/batch - loss: 78.46177 - diff: 33.59mlTrain batch 9/16 - 182.6ms/batch - loss: 83.20891 - diff: 34.52mlTrain batch 10/16 - 170.1ms/batch - loss: 79.26561 - diff: 33.90mlTrain batch 11/16 - 169.5ms/batch - loss: 74.09149 - diff: 32.86mlTrain batch 12/16 - 170.0ms/batch - loss: 77.33395 - diff: 33.64mlTrain batch 13/16 - 169.8ms/batch - loss: 77.60385 - diff: 33.62mlTrain batch 14/16 - 169.9ms/batch - loss: 76.47095 - diff: 33.95mlTrain batch 15/16 - 169.6ms/batch - loss: 76.68880 - diff: 34.17mlTrain batch 16/16 - 56.0ms/batch - loss: 76.82320 - diff: 33.98mlTrain batch 16/16 - 17.3s 56.0ms/batch - loss: 76.82320 - diff: 33.98ml
Test 1.1s: val_loss: 43.82030 - diff: 24.87ml

Epoch 47: current best loss = 29.83492, at epoch 29
Train batch 1/16 - 188.6ms/batch - loss: 97.22786 - diff: 28.60mlTrain batch 2/16 - 184.7ms/batch - loss: 60.95140 - diff: 24.70mlTrain batch 3/16 - 188.8ms/batch - loss: 61.80553 - diff: 27.89mlTrain batch 4/16 - 169.8ms/batch - loss: 55.12687 - diff: 27.27mlTrain batch 5/16 - 187.7ms/batch - loss: 49.02956 - diff: 25.77mlTrain batch 6/16 - 177.0ms/batch - loss: 47.65952 - diff: 25.83mlTrain batch 7/16 - 185.2ms/batch - loss: 49.46961 - diff: 27.23mlTrain batch 8/16 - 174.3ms/batch - loss: 56.12580 - diff: 28.58mlTrain batch 9/16 - 183.7ms/batch - loss: 56.89966 - diff: 28.63mlTrain batch 10/16 - 170.0ms/batch - loss: 54.02731 - diff: 28.22mlTrain batch 11/16 - 216.0ms/batch - loss: 52.23058 - diff: 28.16mlTrain batch 12/16 - 183.8ms/batch - loss: 50.87896 - diff: 28.02mlTrain batch 13/16 - 172.7ms/batch - loss: 48.27065 - diff: 27.17mlTrain batch 14/16 - 184.3ms/batch - loss: 50.57054 - diff: 27.45mlTrain batch 15/16 - 169.7ms/batch - loss: 51.44621 - diff: 27.70mlTrain batch 16/16 - 56.0ms/batch - loss: 101.01221 - diff: 28.39mlTrain batch 16/16 - 18.2s 56.0ms/batch - loss: 101.01221 - diff: 28.39ml
Test 1.0s: val_loss: 208.79975 - diff: 69.65ml

Epoch 48: current best loss = 29.83492, at epoch 29
Train batch 1/16 - 186.1ms/batch - loss: 213.59811 - diff: 76.22mlTrain batch 2/16 - 169.5ms/batch - loss: 160.34922 - diff: 56.92mlTrain batch 3/16 - 169.3ms/batch - loss: 133.90525 - diff: 49.86mlTrain batch 4/16 - 169.4ms/batch - loss: 128.97554 - diff: 49.54mlTrain batch 5/16 - 169.6ms/batch - loss: 128.94670 - diff: 48.71mlTrain batch 6/16 - 169.3ms/batch - loss: 121.60706 - diff: 47.22mlTrain batch 7/16 - 169.6ms/batch - loss: 111.28743 - diff: 44.71mlTrain batch 8/16 - 169.6ms/batch - loss: 103.17064 - diff: 42.36mlTrain batch 9/16 - 169.6ms/batch - loss: 96.57545 - diff: 40.60mlTrain batch 10/16 - 169.6ms/batch - loss: 93.83521 - diff: 40.72mlTrain batch 11/16 - 169.8ms/batch - loss: 104.86210 - diff: 41.92mlTrain batch 12/16 - 183.0ms/batch - loss: 99.98492 - diff: 41.20mlTrain batch 13/16 - 180.4ms/batch - loss: 95.83700 - diff: 40.22mlTrain batch 14/16 - 169.7ms/batch - loss: 93.11303 - diff: 39.73mlTrain batch 15/16 - 169.7ms/batch - loss: 94.90336 - diff: 39.58mlTrain batch 16/16 - 57.0ms/batch - loss: 94.88026 - diff: 39.31mlTrain batch 16/16 - 15.8s 57.0ms/batch - loss: 94.88026 - diff: 39.31ml
Test 1.0s: val_loss: 45.67891 - diff: 24.91ml

Epoch 49: current best loss = 29.83492, at epoch 29
Train batch 1/16 - 185.9ms/batch - loss: 59.95604 - diff: 35.69mlTrain batch 2/16 - 181.8ms/batch - loss: 131.74499 - diff: 36.73mlTrain batch 3/16 - 169.6ms/batch - loss: 100.32078 - diff: 33.80mlTrain batch 4/16 - 173.7ms/batch - loss: 95.04196 - diff: 34.97mlTrain batch 5/16 - 169.8ms/batch - loss: 84.63718 - diff: 33.75mlTrain batch 6/16 - 170.1ms/batch - loss: 84.77655 - diff: 32.96mlTrain batch 7/16 - 169.9ms/batch - loss: 84.70045 - diff: 33.20mlTrain batch 8/16 - 169.9ms/batch - loss: 77.23479 - diff: 31.70mlTrain batch 9/16 - 169.7ms/batch - loss: 77.76969 - diff: 31.93mlTrain batch 10/16 - 174.1ms/batch - loss: 74.59128 - diff: 31.32mlTrain batch 11/16 - 170.1ms/batch - loss: 70.30824 - diff: 30.80mlTrain batch 12/16 - 169.9ms/batch - loss: 66.80818 - diff: 30.17mlTrain batch 13/16 - 169.8ms/batch - loss: 66.31048 - diff: 30.54mlTrain batch 14/16 - 169.9ms/batch - loss: 63.96044 - diff: 30.39mlTrain batch 15/16 - 176.2ms/batch - loss: 62.78982 - diff: 30.43mlTrain batch 16/16 - 56.4ms/batch - loss: 64.58834 - diff: 30.45mlTrain batch 16/16 - 15.4s 56.4ms/batch - loss: 64.58834 - diff: 30.45ml
Test 1.0s: val_loss: 46.74491 - diff: 24.76ml

Epoch 50: current best loss = 29.83492, at epoch 29
Train batch 1/16 - 187.7ms/batch - loss: 30.01028 - diff: 22.48mlTrain batch 2/16 - 172.1ms/batch - loss: 42.29136 - diff: 24.68mlTrain batch 3/16 - 170.1ms/batch - loss: 42.61269 - diff: 26.42mlTrain batch 4/16 - 178.8ms/batch - loss: 38.74545 - diff: 25.23mlTrain batch 5/16 - 169.8ms/batch - loss: 51.02674 - diff: 27.76mlTrain batch 6/16 - 169.8ms/batch - loss: 49.86719 - diff: 28.37mlTrain batch 7/16 - 169.8ms/batch - loss: 51.20813 - diff: 28.69mlTrain batch 8/16 - 169.8ms/batch - loss: 48.00061 - diff: 28.19mlTrain batch 9/16 - 170.1ms/batch - loss: 46.67888 - diff: 28.00mlTrain batch 10/16 - 169.9ms/batch - loss: 51.49088 - diff: 28.97mlTrain batch 11/16 - 184.2ms/batch - loss: 56.70381 - diff: 30.02mlTrain batch 12/16 - 169.9ms/batch - loss: 54.14132 - diff: 29.51mlTrain batch 13/16 - 172.0ms/batch - loss: 54.24573 - diff: 29.62mlTrain batch 14/16 - 170.1ms/batch - loss: 65.31372 - diff: 30.83mlTrain batch 15/16 - 170.5ms/batch - loss: 63.97388 - diff: 30.92mlTrain batch 16/16 - 56.2ms/batch - loss: 72.24282 - diff: 31.07mlTrain batch 16/16 - 15.7s 56.2ms/batch - loss: 72.24282 - diff: 31.07ml
Test 1.1s: val_loss: 52.48851 - diff: 30.61ml

Epoch 51: current best loss = 29.83492, at epoch 29
Train batch 1/16 - 193.1ms/batch - loss: 53.55726 - diff: 34.60mlTrain batch 2/16 - 172.7ms/batch - loss: 62.25525 - diff: 33.24mlTrain batch 3/16 - 190.8ms/batch - loss: 47.51455 - diff: 28.85mlTrain batch 4/16 - 169.9ms/batch - loss: 43.94427 - diff: 27.97mlTrain batch 5/16 - 184.0ms/batch - loss: 69.66603 - diff: 31.60mlTrain batch 6/16 - 176.2ms/batch - loss: 62.90974 - diff: 30.10mlTrain batch 7/16 - 185.3ms/batch - loss: 60.86613 - diff: 29.80mlTrain batch 8/16 - 170.1ms/batch - loss: 57.07770 - diff: 29.46mlTrain batch 9/16 - 203.6ms/batch - loss: 55.64249 - diff: 29.25mlTrain batch 10/16 - 191.8ms/batch - loss: 56.28526 - diff: 29.73mlTrain batch 11/16 - 186.2ms/batch - loss: 72.11395 - diff: 31.53mlTrain batch 12/16 - 187.9ms/batch - loss: 72.09690 - diff: 32.55mlTrain batch 13/16 - 190.9ms/batch - loss: 70.58084 - diff: 32.65mlTrain batch 14/16 - 169.4ms/batch - loss: 67.54083 - diff: 32.12mlTrain batch 15/16 - 170.1ms/batch - loss: 66.08323 - diff: 31.65mlTrain batch 16/16 - 56.0ms/batch - loss: 67.57430 - diff: 31.53mlTrain batch 16/16 - 18.2s 56.0ms/batch - loss: 67.57430 - diff: 31.53ml
Test 0.6s: val_loss: 68.73955 - diff: 32.91ml
Epoch    52: reducing learning rate of group 0 to 2.5000e-04.

Epoch 52: current best loss = 29.83492, at epoch 29
Train batch 1/16 - 195.6ms/batch - loss: 151.34166 - diff: 45.42mlTrain batch 2/16 - 177.0ms/batch - loss: 125.93361 - diff: 41.28mlTrain batch 3/16 - 180.2ms/batch - loss: 99.01811 - diff: 36.29mlTrain batch 4/16 - 170.0ms/batch - loss: 83.45631 - diff: 33.72mlTrain batch 5/16 - 169.9ms/batch - loss: 84.71998 - diff: 34.13mlTrain batch 6/16 - 170.1ms/batch - loss: 102.04617 - diff: 33.64mlTrain batch 7/16 - 198.1ms/batch - loss: 95.91439 - diff: 33.47mlTrain batch 8/16 - 169.9ms/batch - loss: 93.10698 - diff: 33.98mlTrain batch 9/16 - 197.3ms/batch - loss: 87.47343 - diff: 33.61mlTrain batch 10/16 - 169.4ms/batch - loss: 83.56929 - diff: 33.47mlTrain batch 11/16 - 172.0ms/batch - loss: 81.05360 - diff: 33.74mlTrain batch 12/16 - 169.6ms/batch - loss: 77.54487 - diff: 33.27mlTrain batch 13/16 - 170.1ms/batch - loss: 76.82809 - diff: 33.27mlTrain batch 14/16 - 170.0ms/batch - loss: 75.31669 - diff: 32.77mlTrain batch 15/16 - 170.0ms/batch - loss: 73.28715 - diff: 32.61mlTrain batch 16/16 - 56.1ms/batch - loss: 74.74712 - diff: 32.54mlTrain batch 16/16 - 15.9s 56.1ms/batch - loss: 74.74712 - diff: 32.54ml
Test 0.9s: val_loss: 54.33556 - diff: 25.88ml

Epoch 53: current best loss = 29.83492, at epoch 29
Train batch 1/16 - 188.7ms/batch - loss: 47.59175 - diff: 23.16mlTrain batch 2/16 - 170.0ms/batch - loss: 39.45889 - diff: 23.57mlTrain batch 3/16 - 170.0ms/batch - loss: 40.66509 - diff: 25.10mlTrain batch 4/16 - 169.9ms/batch - loss: 35.88889 - diff: 24.31mlTrain batch 5/16 - 170.0ms/batch - loss: 35.55556 - diff: 24.31mlTrain batch 6/16 - 169.8ms/batch - loss: 40.41394 - diff: 25.43mlTrain batch 7/16 - 169.9ms/batch - loss: 67.41502 - diff: 28.20mlTrain batch 8/16 - 170.1ms/batch - loss: 65.94183 - diff: 29.16mlTrain batch 9/16 - 170.1ms/batch - loss: 62.52351 - diff: 28.91mlTrain batch 10/16 - 170.2ms/batch - loss: 66.67175 - diff: 29.71mlTrain batch 11/16 - 170.0ms/batch - loss: 63.75259 - diff: 29.53mlTrain batch 12/16 - 170.2ms/batch - loss: 62.47750 - diff: 29.57mlTrain batch 13/16 - 180.7ms/batch - loss: 62.75504 - diff: 29.80mlTrain batch 14/16 - 170.0ms/batch - loss: 61.91114 - diff: 29.97mlTrain batch 15/16 - 169.9ms/batch - loss: 61.79807 - diff: 29.94mlTrain batch 16/16 - 56.1ms/batch - loss: 66.28354 - diff: 29.95mlTrain batch 16/16 - 17.4s 56.1ms/batch - loss: 66.28354 - diff: 29.95ml
Test 1.2s: val_loss: 44.47992 - diff: 24.51ml

Epoch 54: current best loss = 29.83492, at epoch 29
Train batch 1/16 - 189.3ms/batch - loss: 61.15454 - diff: 33.35mlTrain batch 2/16 - 173.7ms/batch - loss: 49.54443 - diff: 30.26mlTrain batch 3/16 - 170.0ms/batch - loss: 42.22139 - diff: 27.27mlTrain batch 4/16 - 168.8ms/batch - loss: 35.73252 - diff: 24.90mlTrain batch 5/16 - 170.0ms/batch - loss: 75.67595 - diff: 28.32mlTrain batch 6/16 - 168.7ms/batch - loss: 66.73473 - diff: 27.24mlTrain batch 7/16 - 183.9ms/batch - loss: 64.76757 - diff: 28.52mlTrain batch 8/16 - 190.3ms/batch - loss: 65.50320 - diff: 29.48mlTrain batch 9/16 - 188.9ms/batch - loss: 63.94715 - diff: 29.13mlTrain batch 10/16 - 175.6ms/batch - loss: 65.74845 - diff: 30.18mlTrain batch 11/16 - 170.2ms/batch - loss: 63.87595 - diff: 30.00mlTrain batch 12/16 - 180.3ms/batch - loss: 62.75311 - diff: 30.08mlTrain batch 13/16 - 187.4ms/batch - loss: 65.34649 - diff: 30.08mlTrain batch 14/16 - 173.5ms/batch - loss: 62.95895 - diff: 29.63mlTrain batch 15/16 - 184.3ms/batch - loss: 61.29003 - diff: 29.48mlTrain batch 16/16 - 63.0ms/batch - loss: 61.39363 - diff: 29.27mlTrain batch 16/16 - 17.8s 63.0ms/batch - loss: 61.39363 - diff: 29.27ml
Test 0.9s: val_loss: 42.78139 - diff: 24.38ml

Epoch 55: current best loss = 29.83492, at epoch 29
Train batch 1/16 - 184.3ms/batch - loss: 41.11619 - diff: 23.03mlTrain batch 2/16 - 170.2ms/batch - loss: 57.60835 - diff: 28.76mlTrain batch 3/16 - 170.1ms/batch - loss: 61.60293 - diff: 30.87mlTrain batch 4/16 - 170.1ms/batch - loss: 58.76539 - diff: 31.40mlTrain batch 5/16 - 170.0ms/batch - loss: 50.63826 - diff: 29.11mlTrain batch 6/16 - 169.9ms/batch - loss: 67.35424 - diff: 31.54mlTrain batch 7/16 - 170.2ms/batch - loss: 62.92629 - diff: 31.15mlTrain batch 8/16 - 170.1ms/batch - loss: 63.28813 - diff: 31.96mlTrain batch 9/16 - 189.5ms/batch - loss: 61.09674 - diff: 31.58mlTrain batch 10/16 - 170.0ms/batch - loss: 76.10884 - diff: 32.20mlTrain batch 11/16 - 170.2ms/batch - loss: 72.87214 - diff: 31.41mlTrain batch 12/16 - 169.8ms/batch - loss: 71.84465 - diff: 31.34mlTrain batch 13/16 - 211.7ms/batch - loss: 67.83989 - diff: 30.48mlTrain batch 14/16 - 175.4ms/batch - loss: 64.75752 - diff: 30.03mlTrain batch 15/16 - 169.9ms/batch - loss: 62.14064 - diff: 29.49mlTrain batch 16/16 - 56.1ms/batch - loss: 62.58806 - diff: 29.38mlTrain batch 16/16 - 16.3s 56.1ms/batch - loss: 62.58806 - diff: 29.38ml
Test 1.0s: val_loss: 53.10294 - diff: 24.45ml

Epoch 56: current best loss = 29.83492, at epoch 29
Train batch 1/16 - 188.5ms/batch - loss: 40.71029 - diff: 26.76mlTrain batch 2/16 - 185.3ms/batch - loss: 46.28607 - diff: 26.89mlTrain batch 3/16 - 183.4ms/batch - loss: 56.35710 - diff: 28.68mlTrain batch 4/16 - 189.5ms/batch - loss: 91.22241 - diff: 28.80mlTrain batch 5/16 - 170.0ms/batch - loss: 82.03876 - diff: 28.87mlTrain batch 6/16 - 170.5ms/batch - loss: 72.67855 - diff: 27.94mlTrain batch 7/16 - 181.9ms/batch - loss: 66.09131 - diff: 27.43mlTrain batch 8/16 - 170.2ms/batch - loss: 60.70374 - diff: 26.83mlTrain batch 9/16 - 184.4ms/batch - loss: 59.83438 - diff: 27.08mlTrain batch 10/16 - 176.9ms/batch - loss: 57.56200 - diff: 27.17mlTrain batch 11/16 - 170.2ms/batch - loss: 58.94266 - diff: 27.60mlTrain batch 12/16 - 169.9ms/batch - loss: 64.94214 - diff: 28.57mlTrain batch 13/16 - 188.9ms/batch - loss: 62.90368 - diff: 28.16mlTrain batch 14/16 - 177.6ms/batch - loss: 61.04905 - diff: 27.88mlTrain batch 15/16 - 184.2ms/batch - loss: 59.34055 - diff: 27.83mlTrain batch 16/16 - 71.9ms/batch - loss: 66.16211 - diff: 28.06mlTrain batch 16/16 - 17.2s 71.9ms/batch - loss: 66.16211 - diff: 28.06ml
Test 1.0s: val_loss: 47.81982 - diff: 28.65ml

Epoch 57: current best loss = 29.83492, at epoch 29
Train batch 1/16 - 188.8ms/batch - loss: 27.46415 - diff: 25.33mlTrain batch 2/16 - 173.3ms/batch - loss: 39.12812 - diff: 27.97mlTrain batch 3/16 - 188.2ms/batch - loss: 90.19887 - diff: 31.38mlTrain batch 4/16 - 170.6ms/batch - loss: 80.86006 - diff: 31.46mlTrain batch 5/16 - 170.1ms/batch - loss: 69.31400 - diff: 29.38mlTrain batch 6/16 - 169.2ms/batch - loss: 65.84346 - diff: 29.34mlTrain batch 7/16 - 170.0ms/batch - loss: 61.58918 - diff: 28.56mlTrain batch 8/16 - 172.5ms/batch - loss: 66.56613 - diff: 29.89mlTrain batch 9/16 - 170.1ms/batch - loss: 63.18991 - diff: 29.41mlTrain batch 10/16 - 180.5ms/batch - loss: 64.93236 - diff: 30.01mlTrain batch 11/16 - 170.0ms/batch - loss: 63.92488 - diff: 30.10mlTrain batch 12/16 - 170.1ms/batch - loss: 60.91816 - diff: 29.72mlTrain batch 13/16 - 182.1ms/batch - loss: 58.07716 - diff: 28.95mlTrain batch 14/16 - 170.1ms/batch - loss: 63.80098 - diff: 29.78mlTrain batch 15/16 - 170.3ms/batch - loss: 60.85312 - diff: 29.21mlTrain batch 16/16 - 56.4ms/batch - loss: 61.89441 - diff: 29.16mlTrain batch 16/16 - 15.9s 56.4ms/batch - loss: 61.89441 - diff: 29.16ml
Test 1.0s: val_loss: 40.69714 - diff: 27.19ml

Epoch 58: current best loss = 29.83492, at epoch 29
Train batch 1/16 - 181.9ms/batch - loss: 70.78277 - diff: 35.94mlTrain batch 2/16 - 170.3ms/batch - loss: 65.20113 - diff: 35.41mlTrain batch 3/16 - 170.0ms/batch - loss: 57.26125 - diff: 34.25mlTrain batch 4/16 - 170.0ms/batch - loss: 51.59852 - diff: 32.28mlTrain batch 5/16 - 170.1ms/batch - loss: 44.91480 - diff: 29.82mlTrain batch 6/16 - 168.9ms/batch - loss: 43.99829 - diff: 29.20mlTrain batch 7/16 - 188.5ms/batch - loss: 40.56844 - diff: 27.83mlTrain batch 8/16 - 170.4ms/batch - loss: 52.63958 - diff: 28.73mlTrain batch 9/16 - 170.0ms/batch - loss: 50.58415 - diff: 28.19mlTrain batch 10/16 - 169.9ms/batch - loss: 47.54520 - diff: 27.26mlTrain batch 11/16 - 178.9ms/batch - loss: 62.32496 - diff: 28.21mlTrain batch 12/16 - 169.0ms/batch - loss: 63.14299 - diff: 28.54mlTrain batch 13/16 - 198.1ms/batch - loss: 61.51365 - diff: 28.37mlTrain batch 14/16 - 177.1ms/batch - loss: 60.79584 - diff: 28.78mlTrain batch 15/16 - 170.0ms/batch - loss: 59.96715 - diff: 29.21mlTrain batch 16/16 - 56.2ms/batch - loss: 62.06711 - diff: 29.26mlTrain batch 16/16 - 16.1s 56.2ms/batch - loss: 62.06711 - diff: 29.26ml
Test 1.0s: val_loss: 48.74522 - diff: 26.63ml

Epoch 59: current best loss = 29.83492, at epoch 29
Train batch 1/16 - 190.7ms/batch - loss: 31.65423 - diff: 25.84mlTrain batch 2/16 - 170.2ms/batch - loss: 34.40657 - diff: 25.78mlTrain batch 3/16 - 179.5ms/batch - loss: 28.15985 - diff: 22.47mlTrain batch 4/16 - 169.7ms/batch - loss: 28.02409 - diff: 22.26mlTrain batch 5/16 - 170.7ms/batch - loss: 45.95919 - diff: 25.82mlTrain batch 6/16 - 170.1ms/batch - loss: 45.14859 - diff: 25.59mlTrain batch 7/16 - 170.1ms/batch - loss: 43.50785 - diff: 25.38mlTrain batch 8/16 - 173.6ms/batch - loss: 44.59103 - diff: 25.73mlTrain batch 9/16 - 170.3ms/batch - loss: 44.72890 - diff: 26.04mlTrain batch 10/16 - 169.8ms/batch - loss: 45.11476 - diff: 26.37mlTrain batch 11/16 - 170.1ms/batch - loss: 48.07517 - diff: 27.91mlTrain batch 12/16 - 170.7ms/batch - loss: 47.76661 - diff: 27.98mlTrain batch 13/16 - 170.0ms/batch - loss: 46.72677 - diff: 27.83mlTrain batch 14/16 - 170.1ms/batch - loss: 62.01032 - diff: 29.07mlTrain batch 15/16 - 170.0ms/batch - loss: 63.19122 - diff: 29.48mlTrain batch 16/16 - 64.3ms/batch - loss: 63.66281 - diff: 29.40mlTrain batch 16/16 - 15.4s 64.3ms/batch - loss: 63.66281 - diff: 29.40ml
Test 1.1s: val_loss: 40.88731 - diff: 24.23ml

Epoch 60: current best loss = 29.83492, at epoch 29
Train batch 1/16 - 181.7ms/batch - loss: 56.79596 - diff: 28.94mlTrain batch 2/16 - 176.1ms/batch - loss: 47.55456 - diff: 26.91mlTrain batch 3/16 - 182.0ms/batch - loss: 41.31256 - diff: 26.60mlTrain batch 4/16 - 176.6ms/batch - loss: 79.95700 - diff: 27.78mlTrain batch 5/16 - 171.0ms/batch - loss: 70.96855 - diff: 27.42mlTrain batch 6/16 - 171.0ms/batch - loss: 63.49172 - diff: 26.62mlTrain batch 7/16 - 170.0ms/batch - loss: 59.89105 - diff: 26.29mlTrain batch 8/16 - 173.4ms/batch - loss: 62.63970 - diff: 27.70mlTrain batch 9/16 - 171.3ms/batch - loss: 59.88731 - diff: 27.55mlTrain batch 10/16 - 169.9ms/batch - loss: 62.76405 - diff: 28.37mlTrain batch 11/16 - 170.1ms/batch - loss: 60.22851 - diff: 28.20mlTrain batch 12/16 - 169.8ms/batch - loss: 59.49602 - diff: 28.50mlTrain batch 13/16 - 172.9ms/batch - loss: 62.64727 - diff: 28.85mlTrain batch 14/16 - 170.2ms/batch - loss: 60.59393 - diff: 28.67mlTrain batch 15/16 - 173.0ms/batch - loss: 58.57309 - diff: 28.19mlTrain batch 16/16 - 56.1ms/batch - loss: 59.24057 - diff: 28.06mlTrain batch 16/16 - 16.1s 56.1ms/batch - loss: 59.24057 - diff: 28.06ml
Test 1.0s: val_loss: 56.49909 - diff: 24.43ml

Epoch 61: current best loss = 29.83492, at epoch 29
Train batch 1/16 - 181.0ms/batch - loss: 18.23991 - diff: 19.09mlTrain batch 2/16 - 181.6ms/batch - loss: 25.18062 - diff: 22.77mlTrain batch 3/16 - 184.0ms/batch - loss: 88.37750 - diff: 28.67mlTrain batch 4/16 - 176.2ms/batch - loss: 75.94842 - diff: 28.26mlTrain batch 5/16 - 171.1ms/batch - loss: 67.96609 - diff: 28.30mlTrain batch 6/16 - 178.7ms/batch - loss: 73.41078 - diff: 29.88mlTrain batch 7/16 - 169.0ms/batch - loss: 70.55227 - diff: 29.91mlTrain batch 8/16 - 169.5ms/batch - loss: 70.46432 - diff: 30.31mlTrain batch 9/16 - 188.8ms/batch - loss: 67.71096 - diff: 30.04mlTrain batch 10/16 - 170.6ms/batch - loss: 64.15097 - diff: 29.19mlTrain batch 11/16 - 170.1ms/batch - loss: 62.75424 - diff: 28.85mlTrain batch 12/16 - 170.1ms/batch - loss: 62.59993 - diff: 29.16mlTrain batch 13/16 - 170.2ms/batch - loss: 61.08869 - diff: 28.92mlTrain batch 14/16 - 170.0ms/batch - loss: 59.13316 - diff: 28.59mlTrain batch 15/16 - 170.0ms/batch - loss: 58.48531 - diff: 28.39mlTrain batch 16/16 - 56.1ms/batch - loss: 59.12725 - diff: 28.31mlTrain batch 16/16 - 14.5s 56.1ms/batch - loss: 59.12725 - diff: 28.31ml
Test 1.0s: val_loss: 41.14599 - diff: 24.44ml

Epoch 62: current best loss = 29.83492, at epoch 29
Train batch 1/16 - 169.7ms/batch - loss: 29.76324 - diff: 23.87mlTrain batch 2/16 - 170.4ms/batch - loss: 110.66881 - diff: 29.58mlTrain batch 3/16 - 173.8ms/batch - loss: 82.55169 - diff: 27.21mlTrain batch 4/16 - 170.4ms/batch - loss: 86.96402 - diff: 27.77mlTrain batch 5/16 - 176.0ms/batch - loss: 77.51070 - diff: 27.19mlTrain batch 6/16 - 169.8ms/batch - loss: 78.82098 - diff: 28.82mlTrain batch 7/16 - 169.9ms/batch - loss: 71.15352 - diff: 28.00mlTrain batch 8/16 - 172.8ms/batch - loss: 68.98383 - diff: 28.46mlTrain batch 9/16 - 170.9ms/batch - loss: 68.60136 - diff: 29.57mlTrain batch 10/16 - 178.1ms/batch - loss: 65.70558 - diff: 29.30mlTrain batch 11/16 - 170.1ms/batch - loss: 64.04723 - diff: 29.27mlTrain batch 12/16 - 169.8ms/batch - loss: 63.45496 - diff: 29.69mlTrain batch 13/16 - 170.1ms/batch - loss: 60.27864 - diff: 29.04mlTrain batch 14/16 - 169.9ms/batch - loss: 57.68960 - diff: 28.46mlTrain batch 15/16 - 170.0ms/batch - loss: 57.21409 - diff: 28.37mlTrain batch 16/16 - 56.2ms/batch - loss: 57.02663 - diff: 28.16mlTrain batch 16/16 - 14.7s 56.2ms/batch - loss: 57.02663 - diff: 28.16ml
Test 0.9s: val_loss: 59.86166 - diff: 24.04ml
Epoch    63: reducing learning rate of group 0 to 1.2500e-04.

Epoch 63: current best loss = 29.83492, at epoch 29
Train batch 1/16 - 188.7ms/batch - loss: 18.89260 - diff: 19.39mlTrain batch 2/16 - 171.7ms/batch - loss: 44.93596 - diff: 25.88mlTrain batch 3/16 - 186.6ms/batch - loss: 38.05909 - diff: 24.68mlTrain batch 4/16 - 170.0ms/batch - loss: 34.08427 - diff: 23.53mlTrain batch 5/16 - 169.8ms/batch - loss: 49.13353 - diff: 25.49mlTrain batch 6/16 - 168.7ms/batch - loss: 46.67107 - diff: 25.39mlTrain batch 7/16 - 181.4ms/batch - loss: 49.32786 - diff: 26.30mlTrain batch 8/16 - 170.2ms/batch - loss: 46.29342 - diff: 26.00mlTrain batch 9/16 - 191.1ms/batch - loss: 45.52885 - diff: 26.22mlTrain batch 10/16 - 178.7ms/batch - loss: 49.24602 - diff: 27.24mlTrain batch 11/16 - 190.9ms/batch - loss: 49.81711 - diff: 27.79mlTrain batch 12/16 - 177.0ms/batch - loss: 50.42095 - diff: 28.31mlTrain batch 13/16 - 169.9ms/batch - loss: 48.32294 - diff: 27.89mlTrain batch 14/16 - 170.2ms/batch - loss: 49.46365 - diff: 28.31mlTrain batch 15/16 - 170.0ms/batch - loss: 59.93861 - diff: 29.00mlTrain batch 16/16 - 56.0ms/batch - loss: 62.89225 - diff: 29.14mlTrain batch 16/16 - 17.3s 56.0ms/batch - loss: 62.89225 - diff: 29.14ml
Test 1.1s: val_loss: 42.24418 - diff: 23.70ml

Epoch 64: current best loss = 29.83492, at epoch 29
Train batch 1/16 - 200.2ms/batch - loss: 48.48358 - diff: 27.16mlTrain batch 2/16 - 169.9ms/batch - loss: 75.34886 - diff: 28.39mlTrain batch 3/16 - 170.1ms/batch - loss: 72.65926 - diff: 30.85mlTrain batch 4/16 - 170.3ms/batch - loss: 66.75628 - diff: 31.24mlTrain batch 5/16 - 170.1ms/batch - loss: 61.45009 - diff: 30.70mlTrain batch 6/16 - 176.8ms/batch - loss: 62.10520 - diff: 31.28mlTrain batch 7/16 - 170.0ms/batch - loss: 57.69864 - diff: 30.43mlTrain batch 8/16 - 175.7ms/batch - loss: 57.12351 - diff: 30.52mlTrain batch 9/16 - 170.0ms/batch - loss: 55.90083 - diff: 30.09mlTrain batch 10/16 - 173.3ms/batch - loss: 52.73863 - diff: 29.28mlTrain batch 11/16 - 170.0ms/batch - loss: 51.38219 - diff: 29.10mlTrain batch 12/16 - 184.1ms/batch - loss: 61.74770 - diff: 29.08mlTrain batch 13/16 - 170.2ms/batch - loss: 60.62151 - diff: 28.72mlTrain batch 14/16 - 188.6ms/batch - loss: 61.64043 - diff: 29.00mlTrain batch 15/16 - 180.6ms/batch - loss: 59.16639 - diff: 28.56mlTrain batch 16/16 - 56.1ms/batch - loss: 59.11552 - diff: 28.37mlTrain batch 16/16 - 15.0s 56.1ms/batch - loss: 59.11552 - diff: 28.37ml
Test 1.0s: val_loss: 52.41736 - diff: 25.47ml

Epoch 65: current best loss = 29.83492, at epoch 29
Train batch 1/16 - 203.0ms/batch - loss: 38.49501 - diff: 28.65mlTrain batch 2/16 - 170.0ms/batch - loss: 40.29561 - diff: 27.82mlTrain batch 3/16 - 170.0ms/batch - loss: 60.29979 - diff: 29.97mlTrain batch 4/16 - 175.7ms/batch - loss: 51.96430 - diff: 28.68mlTrain batch 5/16 - 189.0ms/batch - loss: 46.72398 - diff: 27.40mlTrain batch 6/16 - 175.5ms/batch - loss: 44.80775 - diff: 27.16mlTrain batch 7/16 - 170.2ms/batch - loss: 44.32038 - diff: 26.88mlTrain batch 8/16 - 169.6ms/batch - loss: 69.00730 - diff: 29.26mlTrain batch 9/16 - 188.2ms/batch - loss: 65.89450 - diff: 28.79mlTrain batch 10/16 - 170.0ms/batch - loss: 64.17643 - diff: 28.92mlTrain batch 11/16 - 195.7ms/batch - loss: 62.45629 - diff: 29.04mlTrain batch 12/16 - 183.8ms/batch - loss: 61.01913 - diff: 29.47mlTrain batch 13/16 - 177.3ms/batch - loss: 58.81494 - diff: 29.33mlTrain batch 14/16 - 169.7ms/batch - loss: 58.58085 - diff: 29.44mlTrain batch 15/16 - 170.1ms/batch - loss: 56.26220 - diff: 28.82mlTrain batch 16/16 - 56.1ms/batch - loss: 55.71917 - diff: 28.54mlTrain batch 16/16 - 17.1s 56.1ms/batch - loss: 55.71917 - diff: 28.54ml
Test 0.8s: val_loss: 44.02163 - diff: 23.57ml

Epoch 66: current best loss = 29.83492, at epoch 29
Train batch 1/16 - 188.5ms/batch - loss: 200.14125 - diff: 33.19mlTrain batch 2/16 - 170.1ms/batch - loss: 126.07064 - diff: 29.39mlTrain batch 3/16 - 171.9ms/batch - loss: 101.86180 - diff: 28.22mlTrain batch 4/16 - 171.1ms/batch - loss: 81.64862 - diff: 26.10mlTrain batch 5/16 - 188.6ms/batch - loss: 70.30792 - diff: 25.17mlTrain batch 6/16 - 179.9ms/batch - loss: 81.69637 - diff: 27.40mlTrain batch 7/16 - 170.1ms/batch - loss: 75.83204 - diff: 27.22mlTrain batch 8/16 - 169.9ms/batch - loss: 70.70195 - diff: 27.04mlTrain batch 9/16 - 170.1ms/batch - loss: 67.08685 - diff: 26.88mlTrain batch 10/16 - 172.9ms/batch - loss: 64.04401 - diff: 26.70mlTrain batch 11/16 - 170.3ms/batch - loss: 62.52778 - diff: 27.08mlTrain batch 12/16 - 169.8ms/batch - loss: 60.46594 - diff: 27.00mlTrain batch 13/16 - 170.0ms/batch - loss: 60.44579 - diff: 27.45mlTrain batch 14/16 - 176.5ms/batch - loss: 57.55965 - diff: 27.12mlTrain batch 15/16 - 170.1ms/batch - loss: 57.05120 - diff: 27.40mlTrain batch 16/16 - 56.1ms/batch - loss: 57.21892 - diff: 27.22mlTrain batch 16/16 - 16.3s 56.1ms/batch - loss: 57.21892 - diff: 27.22ml
Test 0.9s: val_loss: 39.29529 - diff: 23.34ml

Epoch 67: current best loss = 29.83492, at epoch 29
Train batch 1/16 - 196.8ms/batch - loss: 20.20718 - diff: 20.81mlTrain batch 2/16 - 169.6ms/batch - loss: 41.67300 - diff: 25.38mlTrain batch 3/16 - 170.0ms/batch - loss: 39.17253 - diff: 25.18mlTrain batch 4/16 - 170.5ms/batch - loss: 34.73814 - diff: 23.85mlTrain batch 5/16 - 187.4ms/batch - loss: 32.30786 - diff: 22.86mlTrain batch 6/16 - 170.1ms/batch - loss: 50.57991 - diff: 25.51mlTrain batch 7/16 - 188.9ms/batch - loss: 74.03825 - diff: 27.16mlTrain batch 8/16 - 177.3ms/batch - loss: 71.87927 - diff: 27.54mlTrain batch 9/16 - 176.7ms/batch - loss: 65.67739 - diff: 26.48mlTrain batch 10/16 - 176.0ms/batch - loss: 64.52032 - diff: 26.77mlTrain batch 11/16 - 187.3ms/batch - loss: 61.07515 - diff: 26.60mlTrain batch 12/16 - 172.0ms/batch - loss: 59.93675 - diff: 26.90mlTrain batch 13/16 - 174.3ms/batch - loss: 58.20279 - diff: 26.90mlTrain batch 14/16 - 171.9ms/batch - loss: 56.98063 - diff: 26.93mlTrain batch 15/16 - 169.8ms/batch - loss: 56.91673 - diff: 27.47mlTrain batch 16/16 - 56.1ms/batch - loss: 61.70807 - diff: 27.65mlTrain batch 16/16 - 17.1s 56.1ms/batch - loss: 61.70807 - diff: 27.65ml
Test 1.1s: val_loss: 39.05584 - diff: 24.45ml

Epoch 68: current best loss = 29.83492, at epoch 29
Train batch 1/16 - 188.5ms/batch - loss: 27.14698 - diff: 22.94mlTrain batch 2/16 - 176.4ms/batch - loss: 66.15893 - diff: 29.56mlTrain batch 3/16 - 170.2ms/batch - loss: 51.39597 - diff: 27.16mlTrain batch 4/16 - 170.0ms/batch - loss: 57.87875 - diff: 28.48mlTrain batch 5/16 - 177.9ms/batch - loss: 55.19249 - diff: 28.57mlTrain batch 6/16 - 169.8ms/batch - loss: 54.04315 - diff: 28.47mlTrain batch 7/16 - 169.8ms/batch - loss: 49.41826 - diff: 27.40mlTrain batch 8/16 - 169.7ms/batch - loss: 45.68617 - diff: 26.25mlTrain batch 9/16 - 180.8ms/batch - loss: 48.66179 - diff: 26.90mlTrain batch 10/16 - 188.9ms/batch - loss: 63.97378 - diff: 27.90mlTrain batch 11/16 - 180.6ms/batch - loss: 64.87152 - diff: 28.56mlTrain batch 12/16 - 186.0ms/batch - loss: 62.13506 - diff: 28.48mlTrain batch 13/16 - 169.9ms/batch - loss: 60.92837 - diff: 28.80mlTrain batch 14/16 - 171.0ms/batch - loss: 59.21900 - diff: 28.90mlTrain batch 15/16 - 181.6ms/batch - loss: 60.28488 - diff: 29.48mlTrain batch 16/16 - 66.0ms/batch - loss: 60.31236 - diff: 29.31mlTrain batch 16/16 - 15.9s 66.0ms/batch - loss: 60.31236 - diff: 29.31ml
Test 1.0s: val_loss: 40.69653 - diff: 22.95ml

Epoch 69: current best loss = 29.83492, at epoch 29
Train batch 1/16 - 190.0ms/batch - loss: 29.75298 - diff: 22.98mlTrain batch 2/16 - 170.0ms/batch - loss: 31.45183 - diff: 23.37mlTrain batch 3/16 - 169.9ms/batch - loss: 56.64399 - diff: 25.33mlTrain batch 4/16 - 170.3ms/batch - loss: 58.03898 - diff: 26.73mlTrain batch 5/16 - 170.0ms/batch - loss: 52.68001 - diff: 26.43mlTrain batch 6/16 - 170.1ms/batch - loss: 58.21162 - diff: 27.84mlTrain batch 7/16 - 169.9ms/batch - loss: 57.14854 - diff: 27.31mlTrain batch 8/16 - 170.1ms/batch - loss: 57.09182 - diff: 27.23mlTrain batch 9/16 - 170.0ms/batch - loss: 54.87085 - diff: 27.04mlTrain batch 10/16 - 175.1ms/batch - loss: 52.96356 - diff: 27.18mlTrain batch 11/16 - 170.1ms/batch - loss: 52.10123 - diff: 27.63mlTrain batch 12/16 - 170.1ms/batch - loss: 53.83778 - diff: 28.63mlTrain batch 13/16 - 170.0ms/batch - loss: 53.27336 - diff: 28.98mlTrain batch 14/16 - 169.9ms/batch - loss: 51.43265 - diff: 28.66mlTrain batch 15/16 - 170.0ms/batch - loss: 61.11055 - diff: 29.29mlTrain batch 16/16 - 56.1ms/batch - loss: 68.40077 - diff: 29.49mlTrain batch 16/16 - 16.9s 56.1ms/batch - loss: 68.40077 - diff: 29.49ml
Test 1.0s: val_loss: 39.32924 - diff: 23.39ml

Epoch 70: current best loss = 29.83492, at epoch 29
Train batch 1/16 - 185.6ms/batch - loss: 112.47200 - diff: 38.11mlTrain batch 2/16 - 183.0ms/batch - loss: 78.43610 - diff: 34.21mlTrain batch 3/16 - 183.3ms/batch - loss: 73.15308 - diff: 32.80mlTrain batch 4/16 - 177.0ms/batch - loss: 67.96253 - diff: 32.26mlTrain batch 5/16 - 185.7ms/batch - loss: 64.65330 - diff: 31.74mlTrain batch 6/16 - 171.8ms/batch - loss: 57.34384 - diff: 29.76mlTrain batch 7/16 - 170.0ms/batch - loss: 52.68546 - diff: 28.96mlTrain batch 8/16 - 171.5ms/batch - loss: 49.75487 - diff: 28.30mlTrain batch 9/16 - 170.2ms/batch - loss: 47.03177 - diff: 27.72mlTrain batch 10/16 - 170.2ms/batch - loss: 47.72987 - diff: 28.07mlTrain batch 11/16 - 200.0ms/batch - loss: 45.55348 - diff: 27.36mlTrain batch 12/16 - 177.3ms/batch - loss: 42.96889 - diff: 26.60mlTrain batch 13/16 - 170.1ms/batch - loss: 46.08540 - diff: 27.23mlTrain batch 14/16 - 170.0ms/batch - loss: 56.56940 - diff: 27.67mlTrain batch 15/16 - 175.3ms/batch - loss: 56.91185 - diff: 27.80mlTrain batch 16/16 - 56.1ms/batch - loss: 57.30579 - diff: 27.70mlTrain batch 16/16 - 16.9s 56.1ms/batch - loss: 57.30579 - diff: 27.70ml
Test 1.0s: val_loss: 39.42403 - diff: 26.25ml

Epoch 71: current best loss = 29.83492, at epoch 29
Train batch 1/16 - 192.1ms/batch - loss: 27.76906 - diff: 23.14mlTrain batch 2/16 - 169.8ms/batch - loss: 25.03646 - diff: 22.97mlTrain batch 3/16 - 170.1ms/batch - loss: 35.57961 - diff: 24.50mlTrain batch 4/16 - 170.1ms/batch - loss: 52.16213 - diff: 26.94mlTrain batch 5/16 - 170.2ms/batch - loss: 50.89369 - diff: 27.35mlTrain batch 6/16 - 170.0ms/batch - loss: 49.77574 - diff: 27.11mlTrain batch 7/16 - 170.1ms/batch - loss: 49.70531 - diff: 27.20mlTrain batch 8/16 - 170.2ms/batch - loss: 50.02553 - diff: 27.11mlTrain batch 9/16 - 171.6ms/batch - loss: 50.56007 - diff: 27.36mlTrain batch 10/16 - 169.9ms/batch - loss: 49.47589 - diff: 27.55mlTrain batch 11/16 - 170.1ms/batch - loss: 47.76565 - diff: 27.17mlTrain batch 12/16 - 168.9ms/batch - loss: 58.62105 - diff: 27.64mlTrain batch 13/16 - 188.8ms/batch - loss: 57.09143 - diff: 27.61mlTrain batch 14/16 - 172.8ms/batch - loss: 55.23390 - diff: 27.53mlTrain batch 15/16 - 170.1ms/batch - loss: 54.19551 - diff: 27.58mlTrain batch 16/16 - 56.1ms/batch - loss: 58.33758 - diff: 27.72mlTrain batch 16/16 - 15.4s 56.1ms/batch - loss: 58.33758 - diff: 27.72ml
Test 1.1s: val_loss: 38.01782 - diff: 25.18ml

Epoch 72: current best loss = 29.83492, at epoch 29
Train batch 1/16 - 188.7ms/batch - loss: 50.99518 - diff: 29.96mlTrain batch 2/16 - 183.7ms/batch - loss: 39.71891 - diff: 27.67mlTrain batch 3/16 - 178.5ms/batch - loss: 35.24106 - diff: 26.81mlTrain batch 4/16 - 170.3ms/batch - loss: 42.62291 - diff: 26.82mlTrain batch 5/16 - 170.1ms/batch - loss: 44.66044 - diff: 27.27mlTrain batch 6/16 - 168.7ms/batch - loss: 52.96662 - diff: 28.39mlTrain batch 7/16 - 170.3ms/batch - loss: 73.30421 - diff: 29.68mlTrain batch 8/16 - 170.4ms/batch - loss: 66.70574 - diff: 28.70mlTrain batch 9/16 - 170.2ms/batch - loss: 62.97259 - diff: 28.32mlTrain batch 10/16 - 170.2ms/batch - loss: 60.95930 - diff: 28.55mlTrain batch 11/16 - 170.3ms/batch - loss: 60.31565 - diff: 28.92mlTrain batch 12/16 - 175.1ms/batch - loss: 58.81708 - diff: 29.09mlTrain batch 13/16 - 181.2ms/batch - loss: 58.37767 - diff: 29.28mlTrain batch 14/16 - 177.3ms/batch - loss: 55.84928 - diff: 28.63mlTrain batch 15/16 - 170.1ms/batch - loss: 56.16695 - diff: 28.55mlTrain batch 16/16 - 56.2ms/batch - loss: 55.70723 - diff: 28.30mlTrain batch 16/16 - 14.8s 56.2ms/batch - loss: 55.70723 - diff: 28.30ml
Test 1.0s: val_loss: 51.30741 - diff: 24.96ml

Epoch 73: current best loss = 29.83492, at epoch 29
Train batch 1/16 - 177.1ms/batch - loss: 30.36537 - diff: 20.36mlTrain batch 2/16 - 175.2ms/batch - loss: 22.81576 - diff: 19.37mlTrain batch 3/16 - 170.1ms/batch - loss: 34.00098 - diff: 21.85mlTrain batch 4/16 - 174.6ms/batch - loss: 33.12822 - diff: 22.14mlTrain batch 5/16 - 178.1ms/batch - loss: 30.87964 - diff: 22.20mlTrain batch 6/16 - 177.8ms/batch - loss: 42.05361 - diff: 24.17mlTrain batch 7/16 - 170.0ms/batch - loss: 43.15480 - diff: 24.86mlTrain batch 8/16 - 170.0ms/batch - loss: 41.62717 - diff: 25.25mlTrain batch 9/16 - 170.7ms/batch - loss: 40.94729 - diff: 25.44mlTrain batch 10/16 - 170.0ms/batch - loss: 43.33930 - diff: 26.11mlTrain batch 11/16 - 171.4ms/batch - loss: 56.95301 - diff: 27.31mlTrain batch 12/16 - 169.9ms/batch - loss: 55.32122 - diff: 27.18mlTrain batch 13/16 - 170.1ms/batch - loss: 53.11301 - diff: 27.01mlTrain batch 14/16 - 169.9ms/batch - loss: 55.63902 - diff: 27.79mlTrain batch 15/16 - 170.1ms/batch - loss: 54.36870 - diff: 27.50mlTrain batch 16/16 - 56.2ms/batch - loss: 55.48286 - diff: 27.46mlTrain batch 16/16 - 14.2s 56.2ms/batch - loss: 55.48286 - diff: 27.46ml
Test 1.0s: val_loss: 39.64503 - diff: 23.73ml
Epoch    74: reducing learning rate of group 0 to 6.2500e-05.

Epoch 74: current best loss = 29.83492, at epoch 29
Train batch 1/16 - 194.4ms/batch - loss: 22.61627 - diff: 23.73mlTrain batch 2/16 - 174.5ms/batch - loss: 34.65241 - diff: 25.57mlTrain batch 3/16 - 170.1ms/batch - loss: 30.89569 - diff: 24.16mlTrain batch 4/16 - 170.2ms/batch - loss: 36.30409 - diff: 25.09mlTrain batch 5/16 - 196.0ms/batch - loss: 39.98321 - diff: 26.12mlTrain batch 6/16 - 170.5ms/batch - loss: 69.09558 - diff: 27.85mlTrain batch 7/16 - 179.3ms/batch - loss: 63.04168 - diff: 27.20mlTrain batch 8/16 - 169.7ms/batch - loss: 59.53683 - diff: 27.19mlTrain batch 9/16 - 189.1ms/batch - loss: 56.98432 - diff: 27.04mlTrain batch 10/16 - 178.4ms/batch - loss: 54.62825 - diff: 26.75mlTrain batch 11/16 - 185.6ms/batch - loss: 52.51349 - diff: 26.58mlTrain batch 12/16 - 175.8ms/batch - loss: 58.34541 - diff: 27.37mlTrain batch 13/16 - 174.0ms/batch - loss: 56.64009 - diff: 27.17mlTrain batch 14/16 - 170.2ms/batch - loss: 54.18604 - diff: 26.89mlTrain batch 15/16 - 170.1ms/batch - loss: 52.34015 - diff: 26.67mlTrain batch 16/16 - 56.2ms/batch - loss: 55.45911 - diff: 26.74mlTrain batch 16/16 - 15.1s 56.2ms/batch - loss: 55.45911 - diff: 26.74ml
Test 0.9s: val_loss: 43.51655 - diff: 21.98ml

Epoch 75: current best loss = 29.83492, at epoch 29
Train batch 1/16 - 203.8ms/batch - loss: 128.85599 - diff: 40.62mlTrain batch 2/16 - 170.8ms/batch - loss: 80.71355 - diff: 32.61mlTrain batch 3/16 - 186.4ms/batch - loss: 79.19307 - diff: 32.91mlTrain batch 4/16 - 169.9ms/batch - loss: 64.00366 - diff: 29.55mlTrain batch 5/16 - 177.8ms/batch - loss: 59.78553 - diff: 29.70mlTrain batch 6/16 - 169.9ms/batch - loss: 55.47857 - diff: 29.03mlTrain batch 7/16 - 170.3ms/batch - loss: 50.54738 - diff: 28.07mlTrain batch 8/16 - 182.8ms/batch - loss: 50.75325 - diff: 28.40mlTrain batch 9/16 - 170.1ms/batch - loss: 47.99362 - diff: 27.62mlTrain batch 10/16 - 170.1ms/batch - loss: 45.71081 - diff: 27.23mlTrain batch 11/16 - 170.1ms/batch - loss: 45.22523 - diff: 27.00mlTrain batch 12/16 - 170.0ms/batch - loss: 44.23883 - diff: 26.57mlTrain batch 13/16 - 170.1ms/batch - loss: 44.22712 - diff: 26.67mlTrain batch 14/16 - 178.8ms/batch - loss: 43.13389 - diff: 26.50mlTrain batch 15/16 - 170.1ms/batch - loss: 52.80269 - diff: 26.91mlTrain batch 16/16 - 56.1ms/batch - loss: 53.31855 - diff: 26.80mlTrain batch 16/16 - 15.8s 56.1ms/batch - loss: 53.31855 - diff: 26.80ml
Test 1.0s: val_loss: 43.80365 - diff: 21.94ml

Epoch 76: current best loss = 29.83492, at epoch 29
Train batch 1/16 - 184.3ms/batch - loss: 44.60007 - diff: 28.47mlTrain batch 2/16 - 170.2ms/batch - loss: 44.62825 - diff: 25.11mlTrain batch 3/16 - 199.9ms/batch - loss: 43.48335 - diff: 25.44mlTrain batch 4/16 - 179.4ms/batch - loss: 38.55792 - diff: 24.56mlTrain batch 5/16 - 183.5ms/batch - loss: 35.46497 - diff: 24.24mlTrain batch 6/16 - 170.1ms/batch - loss: 34.65242 - diff: 24.00mlTrain batch 7/16 - 181.6ms/batch - loss: 33.45536 - diff: 23.68mlTrain batch 8/16 - 170.1ms/batch - loss: 42.74127 - diff: 24.96mlTrain batch 9/16 - 185.2ms/batch - loss: 43.28819 - diff: 25.56mlTrain batch 10/16 - 170.1ms/batch - loss: 41.80504 - diff: 25.01mlTrain batch 11/16 - 170.2ms/batch - loss: 51.05707 - diff: 25.61mlTrain batch 12/16 - 170.3ms/batch - loss: 50.34967 - diff: 25.60mlTrain batch 13/16 - 177.7ms/batch - loss: 48.17908 - diff: 25.29mlTrain batch 14/16 - 170.0ms/batch - loss: 47.85286 - diff: 25.32mlTrain batch 15/16 - 170.0ms/batch - loss: 46.40996 - diff: 25.16mlTrain batch 16/16 - 63.9ms/batch - loss: 55.51842 - diff: 25.55mlTrain batch 16/16 - 15.6s 63.9ms/batch - loss: 55.51842 - diff: 25.55ml
Test 1.2s: val_loss: 34.69438 - diff: 21.94ml

Epoch 77: current best loss = 29.83492, at epoch 29
Train batch 1/16 - 182.7ms/batch - loss: 38.84321 - diff: 25.03mlTrain batch 2/16 - 171.1ms/batch - loss: 43.80294 - diff: 25.39mlTrain batch 3/16 - 185.9ms/batch - loss: 41.75988 - diff: 26.30mlTrain batch 4/16 - 174.6ms/batch - loss: 40.97342 - diff: 25.96mlTrain batch 5/16 - 173.2ms/batch - loss: 38.74788 - diff: 25.66mlTrain batch 6/16 - 169.8ms/batch - loss: 39.32248 - diff: 25.78mlTrain batch 7/16 - 183.6ms/batch - loss: 38.48626 - diff: 25.72mlTrain batch 8/16 - 170.0ms/batch - loss: 38.39361 - diff: 25.97mlTrain batch 9/16 - 189.8ms/batch - loss: 39.12289 - diff: 25.99mlTrain batch 10/16 - 170.1ms/batch - loss: 40.50905 - diff: 26.13mlTrain batch 11/16 - 173.9ms/batch - loss: 38.94043 - diff: 25.49mlTrain batch 12/16 - 170.0ms/batch - loss: 37.43021 - diff: 25.17mlTrain batch 13/16 - 169.9ms/batch - loss: 43.29011 - diff: 25.79mlTrain batch 14/16 - 177.7ms/batch - loss: 43.23453 - diff: 25.70mlTrain batch 15/16 - 181.0ms/batch - loss: 51.36843 - diff: 26.33mlTrain batch 16/16 - 56.2ms/batch - loss: 53.28845 - diff: 26.45mlTrain batch 16/16 - 17.0s 56.2ms/batch - loss: 53.28845 - diff: 26.45ml
Test 1.0s: val_loss: 38.05634 - diff: 24.88ml

Epoch 78: current best loss = 29.83492, at epoch 29
Train batch 1/16 - 181.7ms/batch - loss: 42.94410 - diff: 26.01mlTrain batch 2/16 - 183.8ms/batch - loss: 40.36602 - diff: 25.70mlTrain batch 3/16 - 169.9ms/batch - loss: 33.25290 - diff: 24.26mlTrain batch 4/16 - 179.2ms/batch - loss: 34.15619 - diff: 25.33mlTrain batch 5/16 - 170.1ms/batch - loss: 39.54384 - diff: 26.92mlTrain batch 6/16 - 170.4ms/batch - loss: 66.31342 - diff: 28.40mlTrain batch 7/16 - 170.1ms/batch - loss: 64.81820 - diff: 28.54mlTrain batch 8/16 - 170.1ms/batch - loss: 61.26439 - diff: 28.10mlTrain batch 9/16 - 170.2ms/batch - loss: 60.00757 - diff: 28.11mlTrain batch 10/16 - 170.1ms/batch - loss: 55.62520 - diff: 27.21mlTrain batch 11/16 - 169.9ms/batch - loss: 54.19796 - diff: 27.39mlTrain batch 12/16 - 173.6ms/batch - loss: 51.94562 - diff: 27.19mlTrain batch 13/16 - 169.9ms/batch - loss: 50.90893 - diff: 26.81mlTrain batch 14/16 - 175.4ms/batch - loss: 48.42377 - diff: 26.19mlTrain batch 15/16 - 170.0ms/batch - loss: 51.43823 - diff: 26.20mlTrain batch 16/16 - 56.2ms/batch - loss: 52.13833 - diff: 26.13mlTrain batch 16/16 - 14.9s 56.2ms/batch - loss: 52.13833 - diff: 26.13ml
Test 1.0s: val_loss: 36.46037 - diff: 20.76ml

Epoch 79: current best loss = 29.83492, at epoch 29
Train batch 1/16 - 188.7ms/batch - loss: 43.82771 - diff: 26.15mlTrain batch 2/16 - 170.0ms/batch - loss: 39.59985 - diff: 24.83mlTrain batch 3/16 - 169.8ms/batch - loss: 56.02860 - diff: 26.41mlTrain batch 4/16 - 175.6ms/batch - loss: 57.71759 - diff: 26.61mlTrain batch 5/16 - 169.8ms/batch - loss: 77.57564 - diff: 28.29mlTrain batch 6/16 - 189.9ms/batch - loss: 69.11262 - diff: 27.53mlTrain batch 7/16 - 169.9ms/batch - loss: 63.16918 - diff: 27.18mlTrain batch 8/16 - 174.8ms/batch - loss: 59.03349 - diff: 26.76mlTrain batch 9/16 - 170.0ms/batch - loss: 57.30988 - diff: 27.14mlTrain batch 10/16 - 170.2ms/batch - loss: 54.41220 - diff: 26.94mlTrain batch 11/16 - 180.1ms/batch - loss: 52.34521 - diff: 26.69mlTrain batch 12/16 - 170.2ms/batch - loss: 51.61084 - diff: 26.54mlTrain batch 13/16 - 170.1ms/batch - loss: 50.43526 - diff: 26.03mlTrain batch 14/16 - 170.0ms/batch - loss: 49.11928 - diff: 25.71mlTrain batch 15/16 - 176.4ms/batch - loss: 47.58317 - diff: 25.34mlTrain batch 16/16 - 56.2ms/batch - loss: 47.45940 - diff: 25.17mlTrain batch 16/16 - 15.3s 56.2ms/batch - loss: 47.45940 - diff: 25.17ml
Test 1.1s: val_loss: 33.32730 - diff: 20.38ml

Epoch 80: current best loss = 29.83492, at epoch 29
Train batch 1/16 - 194.0ms/batch - loss: 23.64983 - diff: 17.32mlTrain batch 2/16 - 169.8ms/batch - loss: 28.37986 - diff: 20.94mlTrain batch 3/16 - 184.4ms/batch - loss: 25.17963 - diff: 19.95mlTrain batch 4/16 - 170.1ms/batch - loss: 22.44641 - diff: 19.15mlTrain batch 5/16 - 211.8ms/batch - loss: 24.05515 - diff: 20.09mlTrain batch 6/16 - 181.1ms/batch - loss: 26.38840 - diff: 21.01mlTrain batch 7/16 - 170.0ms/batch - loss: 25.24422 - diff: 20.84mlTrain batch 8/16 - 170.1ms/batch - loss: 27.32680 - diff: 21.46mlTrain batch 9/16 - 179.4ms/batch - loss: 27.24867 - diff: 21.48mlTrain batch 10/16 - 170.0ms/batch - loss: 26.25287 - diff: 20.91mlTrain batch 11/16 - 170.1ms/batch - loss: 34.45148 - diff: 22.39mlTrain batch 12/16 - 170.1ms/batch - loss: 34.51095 - diff: 22.58mlTrain batch 13/16 - 170.1ms/batch - loss: 34.38392 - diff: 22.68mlTrain batch 14/16 - 168.9ms/batch - loss: 44.69972 - diff: 24.25mlTrain batch 15/16 - 175.1ms/batch - loss: 46.58649 - diff: 25.46mlTrain batch 16/16 - 56.1ms/batch - loss: 47.18895 - diff: 25.36mlTrain batch 16/16 - 17.1s 56.1ms/batch - loss: 47.18895 - diff: 25.36ml
Test 1.0s: val_loss: 44.63336 - diff: 20.13ml

Epoch 81: current best loss = 29.83492, at epoch 29
Train batch 1/16 - 188.8ms/batch - loss: 31.02294 - diff: 21.50mlTrain batch 2/16 - 194.9ms/batch - loss: 30.24945 - diff: 22.12mlTrain batch 3/16 - 225.9ms/batch - loss: 35.84898 - diff: 23.94mlTrain batch 4/16 - 173.6ms/batch - loss: 55.21038 - diff: 27.71mlTrain batch 5/16 - 170.1ms/batch - loss: 49.27185 - diff: 26.40mlTrain batch 6/16 - 170.2ms/batch - loss: 43.80481 - diff: 24.93mlTrain batch 7/16 - 170.1ms/batch - loss: 40.77767 - diff: 24.32mlTrain batch 8/16 - 176.2ms/batch - loss: 42.85346 - diff: 25.32mlTrain batch 9/16 - 170.1ms/batch - loss: 41.03563 - diff: 25.28mlTrain batch 10/16 - 169.9ms/batch - loss: 40.17930 - diff: 25.62mlTrain batch 11/16 - 172.9ms/batch - loss: 40.08383 - diff: 25.98mlTrain batch 12/16 - 181.9ms/batch - loss: 39.18154 - diff: 25.98mlTrain batch 13/16 - 170.1ms/batch - loss: 57.83123 - diff: 27.92mlTrain batch 14/16 - 186.2ms/batch - loss: 55.86718 - diff: 27.52mlTrain batch 15/16 - 170.1ms/batch - loss: 54.59227 - diff: 27.29mlTrain batch 16/16 - 69.5ms/batch - loss: 59.30760 - diff: 27.30mlTrain batch 16/16 - 15.3s 69.5ms/batch - loss: 59.30760 - diff: 27.30ml
Test 1.0s: val_loss: 34.73606 - diff: 21.90ml

Epoch 82: current best loss = 29.83492, at epoch 29
Train batch 1/16 - 185.2ms/batch - loss: 40.26172 - diff: 27.30mlTrain batch 2/16 - 170.1ms/batch - loss: 27.58043 - diff: 22.40mlTrain batch 3/16 - 173.5ms/batch - loss: 32.97459 - diff: 23.80mlTrain batch 4/16 - 180.3ms/batch - loss: 36.84829 - diff: 24.89mlTrain batch 5/16 - 169.8ms/batch - loss: 46.92899 - diff: 26.30mlTrain batch 6/16 - 170.0ms/batch - loss: 44.34696 - diff: 26.15mlTrain batch 7/16 - 180.1ms/batch - loss: 44.45784 - diff: 26.32mlTrain batch 8/16 - 181.4ms/batch - loss: 41.98979 - diff: 26.11mlTrain batch 9/16 - 170.2ms/batch - loss: 41.67302 - diff: 25.68mlTrain batch 10/16 - 170.0ms/batch - loss: 56.18539 - diff: 26.61mlTrain batch 11/16 - 170.2ms/batch - loss: 52.78503 - diff: 25.70mlTrain batch 12/16 - 170.0ms/batch - loss: 50.58426 - diff: 25.43mlTrain batch 13/16 - 170.0ms/batch - loss: 49.81487 - diff: 25.42mlTrain batch 14/16 - 179.0ms/batch - loss: 48.31486 - diff: 25.42mlTrain batch 15/16 - 174.8ms/batch - loss: 48.24630 - diff: 25.41mlTrain batch 16/16 - 65.5ms/batch - loss: 50.57820 - diff: 25.43mlTrain batch 16/16 - 16.3s 65.5ms/batch - loss: 50.57820 - diff: 25.43ml
Test 1.1s: val_loss: 45.18735 - diff: 21.77ml

Epoch 83: current best loss = 29.83492, at epoch 29
Train batch 1/16 - 186.1ms/batch - loss: 40.73328 - diff: 27.14mlTrain batch 2/16 - 169.9ms/batch - loss: 37.07190 - diff: 26.01mlTrain batch 3/16 - 175.9ms/batch - loss: 40.73523 - diff: 26.28mlTrain batch 4/16 - 170.0ms/batch - loss: 38.36032 - diff: 25.91mlTrain batch 5/16 - 169.8ms/batch - loss: 38.25910 - diff: 26.52mlTrain batch 6/16 - 170.4ms/batch - loss: 35.37603 - diff: 25.65mlTrain batch 7/16 - 170.1ms/batch - loss: 33.73252 - diff: 25.03mlTrain batch 8/16 - 170.4ms/batch - loss: 49.36760 - diff: 25.66mlTrain batch 9/16 - 170.0ms/batch - loss: 46.69163 - diff: 25.12mlTrain batch 10/16 - 170.1ms/batch - loss: 47.37339 - diff: 25.37mlTrain batch 11/16 - 179.5ms/batch - loss: 46.46494 - diff: 25.34mlTrain batch 12/16 - 173.7ms/batch - loss: 44.23439 - diff: 24.87mlTrain batch 13/16 - 179.4ms/batch - loss: 44.70131 - diff: 25.04mlTrain batch 14/16 - 169.1ms/batch - loss: 43.75038 - diff: 25.00mlTrain batch 15/16 - 170.1ms/batch - loss: 46.27265 - diff: 25.10mlTrain batch 16/16 - 56.1ms/batch - loss: 47.64789 - diff: 25.15mlTrain batch 16/16 - 15.1s 56.1ms/batch - loss: 47.64789 - diff: 25.15ml
Test 1.0s: val_loss: 33.42189 - diff: 20.06ml

Epoch 84: current best loss = 29.83492, at epoch 29
Train batch 1/16 - 188.4ms/batch - loss: 11.03127 - diff: 15.74mlTrain batch 2/16 - 169.3ms/batch - loss: 18.99447 - diff: 18.84mlTrain batch 3/16 - 170.2ms/batch - loss: 28.35609 - diff: 21.11mlTrain batch 4/16 - 170.0ms/batch - loss: 34.29952 - diff: 22.84mlTrain batch 5/16 - 170.2ms/batch - loss: 38.73305 - diff: 23.82mlTrain batch 6/16 - 170.2ms/batch - loss: 35.89618 - diff: 23.30mlTrain batch 7/16 - 170.0ms/batch - loss: 34.51706 - diff: 23.14mlTrain batch 8/16 - 169.9ms/batch - loss: 34.00012 - diff: 23.38mlTrain batch 9/16 - 173.1ms/batch - loss: 35.71532 - diff: 24.21mlTrain batch 10/16 - 170.1ms/batch - loss: 37.13817 - diff: 24.98mlTrain batch 11/16 - 172.3ms/batch - loss: 38.11541 - diff: 25.41mlTrain batch 12/16 - 181.7ms/batch - loss: 37.50811 - diff: 25.32mlTrain batch 13/16 - 172.7ms/batch - loss: 36.47464 - diff: 24.80mlTrain batch 14/16 - 170.2ms/batch - loss: 51.08297 - diff: 25.81mlTrain batch 15/16 - 170.0ms/batch - loss: 49.58697 - diff: 25.51mlTrain batch 16/16 - 56.2ms/batch - loss: 49.51446 - diff: 25.36mlTrain batch 16/16 - 15.8s 56.2ms/batch - loss: 49.51446 - diff: 25.36ml
Test 1.0s: val_loss: 31.17077 - diff: 20.19ml
Epoch    85: reducing learning rate of group 0 to 3.1250e-05.

Epoch 85: current best loss = 29.83492, at epoch 29
Train batch 1/16 - 191.8ms/batch - loss: 50.95605 - diff: 27.46mlTrain batch 2/16 - 175.3ms/batch - loss: 46.88060 - diff: 27.63mlTrain batch 3/16 - 170.0ms/batch - loss: 40.25768 - diff: 26.61mlTrain batch 4/16 - 170.1ms/batch - loss: 41.32752 - diff: 26.89mlTrain batch 5/16 - 169.9ms/batch - loss: 36.43795 - diff: 25.59mlTrain batch 6/16 - 170.8ms/batch - loss: 33.76159 - diff: 24.58mlTrain batch 7/16 - 170.1ms/batch - loss: 32.95078 - diff: 24.29mlTrain batch 8/16 - 168.9ms/batch - loss: 32.36625 - diff: 23.92mlTrain batch 9/16 - 184.1ms/batch - loss: 32.56439 - diff: 24.09mlTrain batch 10/16 - 175.8ms/batch - loss: 41.17922 - diff: 25.07mlTrain batch 11/16 - 170.1ms/batch - loss: 39.33790 - diff: 24.81mlTrain batch 12/16 - 170.8ms/batch - loss: 39.16296 - diff: 24.54mlTrain batch 13/16 - 187.6ms/batch - loss: 48.93271 - diff: 25.17mlTrain batch 14/16 - 171.1ms/batch - loss: 47.27070 - diff: 24.72mlTrain batch 15/16 - 170.1ms/batch - loss: 45.11849 - diff: 24.24mlTrain batch 16/16 - 65.4ms/batch - loss: 46.38589 - diff: 24.23mlTrain batch 16/16 - 16.6s 65.4ms/batch - loss: 46.38589 - diff: 24.23ml
Test 1.0s: val_loss: 30.57311 - diff: 21.61ml

Epoch 86: current best loss = 29.83492, at epoch 29
Train batch 1/16 - 185.3ms/batch - loss: 23.92385 - diff: 22.55mlTrain batch 2/16 - 170.0ms/batch - loss: 30.17280 - diff: 24.17mlTrain batch 3/16 - 195.9ms/batch - loss: 29.43572 - diff: 24.24mlTrain batch 4/16 - 170.7ms/batch - loss: 27.63427 - diff: 23.57mlTrain batch 5/16 - 170.1ms/batch - loss: 25.89221 - diff: 22.90mlTrain batch 6/16 - 170.4ms/batch - loss: 26.67812 - diff: 23.06mlTrain batch 7/16 - 183.9ms/batch - loss: 25.82496 - diff: 22.72mlTrain batch 8/16 - 178.1ms/batch - loss: 27.06993 - diff: 22.88mlTrain batch 9/16 - 170.1ms/batch - loss: 25.84514 - diff: 22.40mlTrain batch 10/16 - 170.5ms/batch - loss: 25.74512 - diff: 22.22mlTrain batch 11/16 - 171.5ms/batch - loss: 26.97033 - diff: 22.21mlTrain batch 12/16 - 178.3ms/batch - loss: 30.02427 - diff: 22.69mlTrain batch 13/16 - 171.2ms/batch - loss: 35.45936 - diff: 23.43mlTrain batch 14/16 - 170.1ms/batch - loss: 37.19007 - diff: 23.76mlTrain batch 15/16 - 170.0ms/batch - loss: 44.36514 - diff: 24.52mlTrain batch 16/16 - 56.2ms/batch - loss: 44.60379 - diff: 24.42mlTrain batch 16/16 - 15.9s 56.2ms/batch - loss: 44.60379 - diff: 24.42ml
Test 0.9s: val_loss: 35.98610 - diff: 25.47ml

Epoch 87: current best loss = 29.83492, at epoch 29
Train batch 1/16 - 188.3ms/batch - loss: 28.72066 - diff: 25.59mlTrain batch 2/16 - 170.2ms/batch - loss: 30.53213 - diff: 24.83mlTrain batch 3/16 - 170.1ms/batch - loss: 31.34271 - diff: 23.37mlTrain batch 4/16 - 185.5ms/batch - loss: 31.37756 - diff: 23.67mlTrain batch 5/16 - 170.1ms/batch - loss: 42.65955 - diff: 24.25mlTrain batch 6/16 - 170.2ms/batch - loss: 44.27794 - diff: 24.36mlTrain batch 7/16 - 170.2ms/batch - loss: 42.96179 - diff: 23.99mlTrain batch 8/16 - 173.8ms/batch - loss: 39.86681 - diff: 23.52mlTrain batch 9/16 - 170.2ms/batch - loss: 36.80780 - diff: 22.63mlTrain batch 10/16 - 172.8ms/batch - loss: 35.73531 - diff: 22.62mlTrain batch 11/16 - 170.1ms/batch - loss: 34.08712 - diff: 22.35mlTrain batch 12/16 - 170.3ms/batch - loss: 33.58176 - diff: 22.30mlTrain batch 13/16 - 170.0ms/batch - loss: 34.86616 - diff: 22.56mlTrain batch 14/16 - 170.2ms/batch - loss: 43.02868 - diff: 23.36mlTrain batch 15/16 - 174.2ms/batch - loss: 43.01416 - diff: 23.91mlTrain batch 16/16 - 59.1ms/batch - loss: 45.53397 - diff: 24.03mlTrain batch 16/16 - 15.0s 59.1ms/batch - loss: 45.53397 - diff: 24.03ml
Test 1.0s: val_loss: 36.82420 - diff: 25.46ml

Epoch 88: current best loss = 29.83492, at epoch 29
Train batch 1/16 - 181.7ms/batch - loss: 33.43563 - diff: 27.13mlTrain batch 2/16 - 170.2ms/batch - loss: 36.49518 - diff: 27.22mlTrain batch 3/16 - 183.2ms/batch - loss: 32.73520 - diff: 25.03mlTrain batch 4/16 - 178.1ms/batch - loss: 28.44387 - diff: 22.68mlTrain batch 5/16 - 171.2ms/batch - loss: 27.84586 - diff: 22.35mlTrain batch 6/16 - 170.3ms/batch - loss: 51.92656 - diff: 24.39mlTrain batch 7/16 - 170.1ms/batch - loss: 46.43641 - diff: 23.17mlTrain batch 8/16 - 170.4ms/batch - loss: 44.69525 - diff: 23.04mlTrain batch 9/16 - 182.7ms/batch - loss: 41.54394 - diff: 22.56mlTrain batch 10/16 - 173.1ms/batch - loss: 46.73796 - diff: 23.42mlTrain batch 11/16 - 183.6ms/batch - loss: 44.90307 - diff: 23.46mlTrain batch 12/16 - 182.4ms/batch - loss: 43.45088 - diff: 23.45mlTrain batch 13/16 - 181.0ms/batch - loss: 42.49419 - diff: 23.57mlTrain batch 14/16 - 170.2ms/batch - loss: 42.96870 - diff: 23.76mlTrain batch 15/16 - 176.0ms/batch - loss: 42.22524 - diff: 23.81mlTrain batch 16/16 - 56.2ms/batch - loss: 51.73243 - diff: 24.15mlTrain batch 16/16 - 17.0s 56.2ms/batch - loss: 51.73243 - diff: 24.15ml
Test 0.9s: val_loss: 31.03418 - diff: 20.88ml

Epoch 89: current best loss = 29.83492, at epoch 29
Train batch 1/16 - 189.5ms/batch - loss: 24.64134 - diff: 21.93mlTrain batch 2/16 - 173.6ms/batch - loss: 32.45867 - diff: 22.98mlTrain batch 3/16 - 182.9ms/batch - loss: 69.09956 - diff: 26.42mlTrain batch 4/16 - 170.1ms/batch - loss: 60.11003 - diff: 26.11mlTrain batch 5/16 - 198.1ms/batch - loss: 55.17307 - diff: 25.92mlTrain batch 6/16 - 183.5ms/batch - loss: 54.16668 - diff: 26.99mlTrain batch 7/16 - 188.7ms/batch - loss: 51.60024 - diff: 26.80mlTrain batch 8/16 - 171.6ms/batch - loss: 57.72525 - diff: 27.31mlTrain batch 9/16 - 170.1ms/batch - loss: 53.39490 - diff: 26.11mlTrain batch 10/16 - 175.2ms/batch - loss: 54.19389 - diff: 26.65mlTrain batch 11/16 - 186.8ms/batch - loss: 52.33528 - diff: 26.46mlTrain batch 12/16 - 177.3ms/batch - loss: 49.77118 - diff: 25.99mlTrain batch 13/16 - 194.6ms/batch - loss: 47.14691 - diff: 25.14mlTrain batch 14/16 - 170.1ms/batch - loss: 47.12743 - diff: 25.10mlTrain batch 15/16 - 170.1ms/batch - loss: 44.95414 - diff: 24.57mlTrain batch 16/16 - 56.1ms/batch - loss: 46.15050 - diff: 24.53mlTrain batch 16/16 - 17.5s 56.1ms/batch - loss: 46.15050 - diff: 24.53ml
Test 1.1s: val_loss: 35.21326 - diff: 22.85ml

Epoch 90: current best loss = 29.83492, at epoch 29
Train batch 1/16 - 185.8ms/batch - loss: 15.42074 - diff: 17.59mlTrain batch 2/16 - 170.0ms/batch - loss: 21.42618 - diff: 20.06mlTrain batch 3/16 - 170.0ms/batch - loss: 24.79870 - diff: 20.66mlTrain batch 4/16 - 170.0ms/batch - loss: 21.50480 - diff: 19.33mlTrain batch 5/16 - 170.0ms/batch - loss: 22.26114 - diff: 19.52mlTrain batch 6/16 - 170.2ms/batch - loss: 20.92905 - diff: 18.98mlTrain batch 7/16 - 170.2ms/batch - loss: 21.52863 - diff: 19.12mlTrain batch 8/16 - 175.9ms/batch - loss: 31.79801 - diff: 20.95mlTrain batch 9/16 - 195.9ms/batch - loss: 35.94568 - diff: 21.97mlTrain batch 10/16 - 168.9ms/batch - loss: 48.88837 - diff: 22.92mlTrain batch 11/16 - 188.7ms/batch - loss: 46.74811 - diff: 22.75mlTrain batch 12/16 - 176.8ms/batch - loss: 44.50579 - diff: 22.58mlTrain batch 13/16 - 170.0ms/batch - loss: 44.22200 - diff: 23.31mlTrain batch 14/16 - 176.1ms/batch - loss: 44.03831 - diff: 23.71mlTrain batch 15/16 - 170.1ms/batch - loss: 45.42424 - diff: 24.33mlTrain batch 16/16 - 56.2ms/batch - loss: 45.55534 - diff: 24.20mlTrain batch 16/16 - 17.3s 56.2ms/batch - loss: 45.55534 - diff: 24.20ml
Test 1.0s: val_loss: 32.53766 - diff: 20.58ml

Epoch 91: current best loss = 29.83492, at epoch 29
Train batch 1/16 - 190.5ms/batch - loss: 12.91050 - diff: 16.44mlTrain batch 2/16 - 177.9ms/batch - loss: 20.45081 - diff: 20.32mlTrain batch 3/16 - 170.2ms/batch - loss: 17.94578 - diff: 18.97mlTrain batch 4/16 - 176.1ms/batch - loss: 18.80615 - diff: 19.15mlTrain batch 5/16 - 169.9ms/batch - loss: 34.02678 - diff: 20.88mlTrain batch 6/16 - 184.9ms/batch - loss: 32.67601 - diff: 20.45mlTrain batch 7/16 - 192.7ms/batch - loss: 30.30689 - diff: 20.18mlTrain batch 8/16 - 170.0ms/batch - loss: 29.47025 - diff: 20.21mlTrain batch 9/16 - 170.2ms/batch - loss: 45.25502 - diff: 21.71mlTrain batch 10/16 - 169.1ms/batch - loss: 43.27938 - diff: 21.88mlTrain batch 11/16 - 182.6ms/batch - loss: 44.24804 - diff: 22.25mlTrain batch 12/16 - 178.0ms/batch - loss: 42.66881 - diff: 22.37mlTrain batch 13/16 - 170.0ms/batch - loss: 41.66055 - diff: 22.60mlTrain batch 14/16 - 170.1ms/batch - loss: 42.08666 - diff: 23.12mlTrain batch 15/16 - 170.1ms/batch - loss: 42.95665 - diff: 23.68mlTrain batch 16/16 - 56.0ms/batch - loss: 46.80595 - diff: 23.96mlTrain batch 16/16 - 15.4s 56.0ms/batch - loss: 46.80595 - diff: 23.96ml
Test 0.9s: val_loss: 32.70068 - diff: 21.25ml

Epoch 92: current best loss = 29.83492, at epoch 29
Train batch 1/16 - 188.7ms/batch - loss: 34.81906 - diff: 23.33mlTrain batch 2/16 - 179.2ms/batch - loss: 93.79427 - diff: 28.51mlTrain batch 3/16 - 170.0ms/batch - loss: 69.84520 - diff: 25.87mlTrain batch 4/16 - 170.2ms/batch - loss: 72.97756 - diff: 26.31mlTrain batch 5/16 - 171.0ms/batch - loss: 64.62889 - diff: 25.76mlTrain batch 6/16 - 169.9ms/batch - loss: 57.09081 - diff: 24.71mlTrain batch 7/16 - 170.2ms/batch - loss: 52.53491 - diff: 24.15mlTrain batch 8/16 - 170.1ms/batch - loss: 49.63182 - diff: 23.91mlTrain batch 9/16 - 183.8ms/batch - loss: 48.83328 - diff: 23.71mlTrain batch 10/16 - 170.2ms/batch - loss: 46.53212 - diff: 23.58mlTrain batch 11/16 - 177.8ms/batch - loss: 44.71214 - diff: 23.56mlTrain batch 12/16 - 170.1ms/batch - loss: 43.45968 - diff: 23.42mlTrain batch 13/16 - 170.0ms/batch - loss: 41.46105 - diff: 23.04mlTrain batch 14/16 - 176.2ms/batch - loss: 39.76110 - diff: 22.78mlTrain batch 15/16 - 185.9ms/batch - loss: 38.61725 - diff: 22.72mlTrain batch 16/16 - 56.1ms/batch - loss: 43.07614 - diff: 22.90mlTrain batch 16/16 - 17.0s 56.1ms/batch - loss: 43.07614 - diff: 22.90ml
Test 1.0s: val_loss: 30.93939 - diff: 19.93ml

Epoch 93: current best loss = 29.83492, at epoch 29
Train batch 1/16 - 215.2ms/batch - loss: 12.99078 - diff: 16.75mlTrain batch 2/16 - 170.0ms/batch - loss: 17.79543 - diff: 18.92mlTrain batch 3/16 - 192.1ms/batch - loss: 18.55075 - diff: 19.49mlTrain batch 4/16 - 169.9ms/batch - loss: 25.27180 - diff: 21.03mlTrain batch 5/16 - 190.2ms/batch - loss: 26.87414 - diff: 21.57mlTrain batch 6/16 - 172.3ms/batch - loss: 28.65810 - diff: 22.91mlTrain batch 7/16 - 170.1ms/batch - loss: 28.16150 - diff: 22.55mlTrain batch 8/16 - 170.0ms/batch - loss: 26.42639 - diff: 21.97mlTrain batch 9/16 - 171.2ms/batch - loss: 27.43405 - diff: 22.16mlTrain batch 10/16 - 169.9ms/batch - loss: 26.95557 - diff: 22.03mlTrain batch 11/16 - 169.9ms/batch - loss: 27.03116 - diff: 21.80mlTrain batch 12/16 - 170.0ms/batch - loss: 36.92474 - diff: 22.52mlTrain batch 13/16 - 170.0ms/batch - loss: 38.03659 - diff: 22.90mlTrain batch 14/16 - 170.4ms/batch - loss: 40.98064 - diff: 23.15mlTrain batch 15/16 - 169.8ms/batch - loss: 39.80270 - diff: 23.15mlTrain batch 16/16 - 56.1ms/batch - loss: 40.34043 - diff: 23.11mlTrain batch 16/16 - 16.4s 56.1ms/batch - loss: 40.34043 - diff: 23.11ml
Test 0.6s: val_loss: 39.25943 - diff: 27.72ml

Epoch 94: current best loss = 29.83492, at epoch 29
Train batch 1/16 - 197.4ms/batch - loss: 46.97365 - diff: 27.77mlTrain batch 2/16 - 169.8ms/batch - loss: 46.95138 - diff: 29.86mlTrain batch 3/16 - 174.0ms/batch - loss: 39.63809 - diff: 27.66mlTrain batch 4/16 - 171.8ms/batch - loss: 38.98899 - diff: 26.31mlTrain batch 5/16 - 170.1ms/batch - loss: 36.74768 - diff: 25.60mlTrain batch 6/16 - 170.0ms/batch - loss: 34.11381 - diff: 24.55mlTrain batch 7/16 - 169.7ms/batch - loss: 32.17580 - diff: 23.95mlTrain batch 8/16 - 170.1ms/batch - loss: 30.43843 - diff: 23.19mlTrain batch 9/16 - 170.4ms/batch - loss: 35.99925 - diff: 23.60mlTrain batch 10/16 - 170.0ms/batch - loss: 34.14922 - diff: 23.18mlTrain batch 11/16 - 170.1ms/batch - loss: 34.36821 - diff: 23.22mlTrain batch 12/16 - 170.1ms/batch - loss: 33.27718 - diff: 22.83mlTrain batch 13/16 - 170.2ms/batch - loss: 41.39812 - diff: 23.67mlTrain batch 14/16 - 177.5ms/batch - loss: 42.03877 - diff: 24.02mlTrain batch 15/16 - 170.0ms/batch - loss: 40.99842 - diff: 24.05mlTrain batch 16/16 - 59.0ms/batch - loss: 43.63134 - diff: 24.24mlTrain batch 16/16 - 15.8s 59.0ms/batch - loss: 43.63134 - diff: 24.24ml
Test 1.0s: val_loss: 33.44739 - diff: 22.34ml

Epoch 95: current best loss = 29.83492, at epoch 29
Train batch 1/16 - 184.0ms/batch - loss: 24.03478 - diff: 21.99mlTrain batch 2/16 - 170.0ms/batch - loss: 18.39716 - diff: 18.71mlTrain batch 3/16 - 170.0ms/batch - loss: 24.29609 - diff: 21.31mlTrain batch 4/16 - 170.1ms/batch - loss: 29.79745 - diff: 22.16mlTrain batch 5/16 - 170.0ms/batch - loss: 29.94391 - diff: 22.72mlTrain batch 6/16 - 170.2ms/batch - loss: 38.13665 - diff: 24.47mlTrain batch 7/16 - 170.0ms/batch - loss: 36.42755 - diff: 23.89mlTrain batch 8/16 - 170.2ms/batch - loss: 52.87657 - diff: 25.12mlTrain batch 9/16 - 170.0ms/batch - loss: 57.09021 - diff: 25.58mlTrain batch 10/16 - 169.9ms/batch - loss: 55.17125 - diff: 25.54mlTrain batch 11/16 - 188.9ms/batch - loss: 57.86721 - diff: 27.33mlTrain batch 12/16 - 170.2ms/batch - loss: 57.39829 - diff: 27.77mlTrain batch 13/16 - 177.4ms/batch - loss: 56.05371 - diff: 27.90mlTrain batch 14/16 - 179.3ms/batch - loss: 53.52177 - diff: 27.42mlTrain batch 15/16 - 188.7ms/batch - loss: 52.54772 - diff: 26.90mlTrain batch 16/16 - 66.0ms/batch - loss: 52.27903 - diff: 26.72mlTrain batch 16/16 - 17.6s 66.0ms/batch - loss: 52.27903 - diff: 26.72ml
Test 1.0s: val_loss: 35.42293 - diff: 20.57ml
Epoch    96: reducing learning rate of group 0 to 1.5625e-05.

Epoch 96: current best loss = 29.83492, at epoch 29
Train batch 1/16 - 189.0ms/batch - loss: 52.21069 - diff: 26.77mlTrain batch 2/16 - 173.3ms/batch - loss: 42.12868 - diff: 23.20mlTrain batch 3/16 - 170.2ms/batch - loss: 33.91238 - diff: 21.80mlTrain batch 4/16 - 169.9ms/batch - loss: 30.22849 - diff: 20.73mlTrain batch 5/16 - 179.0ms/batch - loss: 32.49985 - diff: 21.81mlTrain batch 6/16 - 170.2ms/batch - loss: 29.89825 - diff: 21.06mlTrain batch 7/16 - 170.0ms/batch - loss: 38.03980 - diff: 22.25mlTrain batch 8/16 - 170.0ms/batch - loss: 39.11903 - diff: 23.20mlTrain batch 9/16 - 170.1ms/batch - loss: 38.79148 - diff: 23.45mlTrain batch 10/16 - 170.0ms/batch - loss: 37.87547 - diff: 23.38mlTrain batch 11/16 - 177.8ms/batch - loss: 35.66094 - diff: 22.79mlTrain batch 12/16 - 170.1ms/batch - loss: 49.91262 - diff: 24.49mlTrain batch 13/16 - 170.0ms/batch - loss: 47.99045 - diff: 24.32mlTrain batch 14/16 - 170.1ms/batch - loss: 46.97407 - diff: 24.40mlTrain batch 15/16 - 188.8ms/batch - loss: 46.19257 - diff: 24.36mlTrain batch 16/16 - 68.9ms/batch - loss: 48.11814 - diff: 24.40mlTrain batch 16/16 - 15.6s 68.9ms/batch - loss: 48.11814 - diff: 24.40ml
Test 1.0s: val_loss: 32.72004 - diff: 24.97ml

Epoch 97: current best loss = 29.83492, at epoch 29
Train batch 1/16 - 196.7ms/batch - loss: 30.33631 - diff: 27.41mlTrain batch 2/16 - 169.8ms/batch - loss: 37.24678 - diff: 27.33mlTrain batch 3/16 - 170.1ms/batch - loss: 39.84653 - diff: 27.60mlTrain batch 4/16 - 169.7ms/batch - loss: 36.55873 - diff: 26.43mlTrain batch 5/16 - 184.1ms/batch - loss: 33.85985 - diff: 25.62mlTrain batch 6/16 - 175.4ms/batch - loss: 32.23855 - diff: 25.09mlTrain batch 7/16 - 169.9ms/batch - loss: 35.61151 - diff: 25.45mlTrain batch 8/16 - 175.4ms/batch - loss: 32.22362 - diff: 23.91mlTrain batch 9/16 - 183.6ms/batch - loss: 32.52635 - diff: 23.85mlTrain batch 10/16 - 170.2ms/batch - loss: 31.07426 - diff: 23.38mlTrain batch 11/16 - 170.1ms/batch - loss: 30.27699 - diff: 23.09mlTrain batch 12/16 - 170.5ms/batch - loss: 29.41616 - diff: 23.00mlTrain batch 13/16 - 170.0ms/batch - loss: 33.70223 - diff: 23.28mlTrain batch 14/16 - 170.4ms/batch - loss: 42.96317 - diff: 23.83mlTrain batch 15/16 - 170.1ms/batch - loss: 41.10042 - diff: 23.46mlTrain batch 16/16 - 56.3ms/batch - loss: 41.73110 - diff: 23.44mlTrain batch 16/16 - 16.4s 56.3ms/batch - loss: 41.73110 - diff: 23.44ml
Test 0.9s: val_loss: 28.61492 - diff: 19.93ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Systole_VGG19_Adam-0.001_MSE_DA3_best

Epoch 98: current best loss = 28.61492, at epoch 97
Train batch 1/16 - 192.9ms/batch - loss: 143.58904 - diff: 36.43mlTrain batch 2/16 - 180.3ms/batch - loss: 85.17886 - diff: 28.43mlTrain batch 3/16 - 185.7ms/batch - loss: 63.99518 - diff: 25.06mlTrain batch 4/16 - 168.9ms/batch - loss: 59.81894 - diff: 26.04mlTrain batch 5/16 - 175.0ms/batch - loss: 53.43138 - diff: 25.67mlTrain batch 6/16 - 169.9ms/batch - loss: 47.05029 - diff: 24.51mlTrain batch 7/16 - 176.2ms/batch - loss: 46.85420 - diff: 24.69mlTrain batch 8/16 - 175.5ms/batch - loss: 44.50478 - diff: 24.50mlTrain batch 9/16 - 183.7ms/batch - loss: 40.97866 - diff: 23.62mlTrain batch 10/16 - 170.0ms/batch - loss: 40.43599 - diff: 23.85mlTrain batch 11/16 - 197.5ms/batch - loss: 38.31627 - diff: 23.23mlTrain batch 12/16 - 172.5ms/batch - loss: 37.28922 - diff: 22.85mlTrain batch 13/16 - 185.5ms/batch - loss: 41.12232 - diff: 23.20mlTrain batch 14/16 - 177.1ms/batch - loss: 39.21989 - diff: 22.71mlTrain batch 15/16 - 170.2ms/batch - loss: 38.75901 - diff: 22.83mlTrain batch 16/16 - 56.2ms/batch - loss: 41.12729 - diff: 22.93mlTrain batch 16/16 - 17.4s 56.2ms/batch - loss: 41.12729 - diff: 22.93ml
Test 1.1s: val_loss: 38.08805 - diff: 20.56ml

Epoch 99: current best loss = 28.61492, at epoch 97
Train batch 1/16 - 197.8ms/batch - loss: 14.32215 - diff: 16.76mlTrain batch 2/16 - 178.1ms/batch - loss: 23.82513 - diff: 20.10mlTrain batch 3/16 - 172.7ms/batch - loss: 26.02424 - diff: 19.88mlTrain batch 4/16 - 170.3ms/batch - loss: 32.81524 - diff: 22.14mlTrain batch 5/16 - 184.3ms/batch - loss: 29.52050 - diff: 21.55mlTrain batch 6/16 - 173.7ms/batch - loss: 29.04680 - diff: 21.99mlTrain batch 7/16 - 183.2ms/batch - loss: 29.70783 - diff: 22.48mlTrain batch 8/16 - 176.2ms/batch - loss: 29.97731 - diff: 22.86mlTrain batch 9/16 - 187.7ms/batch - loss: 37.32787 - diff: 23.84mlTrain batch 10/16 - 171.3ms/batch - loss: 36.43111 - diff: 23.74mlTrain batch 11/16 - 186.3ms/batch - loss: 37.04727 - diff: 23.99mlTrain batch 12/16 - 185.0ms/batch - loss: 36.07457 - diff: 23.82mlTrain batch 13/16 - 170.1ms/batch - loss: 44.61574 - diff: 24.28mlTrain batch 14/16 - 170.3ms/batch - loss: 43.69885 - diff: 23.83mlTrain batch 15/16 - 174.6ms/batch - loss: 41.81004 - diff: 23.39mlTrain batch 16/16 - 56.2ms/batch - loss: 42.71239 - diff: 23.31mlTrain batch 16/16 - 17.2s 56.2ms/batch - loss: 42.71239 - diff: 23.31ml
Test 0.9s: val_loss: 30.31699 - diff: 21.87ml

Epoch 100: current best loss = 28.61492, at epoch 97
Train batch 1/16 - 181.6ms/batch - loss: 226.34543 - diff: 40.49mlTrain batch 2/16 - 168.7ms/batch - loss: 132.48039 - diff: 32.50mlTrain batch 3/16 - 188.7ms/batch - loss: 94.94247 - diff: 28.60mlTrain batch 4/16 - 170.2ms/batch - loss: 76.81281 - diff: 26.99mlTrain batch 5/16 - 169.8ms/batch - loss: 69.79757 - diff: 27.37mlTrain batch 6/16 - 175.7ms/batch - loss: 61.14386 - diff: 25.93mlTrain batch 7/16 - 176.3ms/batch - loss: 57.27759 - diff: 25.65mlTrain batch 8/16 - 169.9ms/batch - loss: 52.63042 - diff: 24.81mlTrain batch 9/16 - 170.2ms/batch - loss: 48.37963 - diff: 23.77mlTrain batch 10/16 - 170.1ms/batch - loss: 47.87847 - diff: 23.50mlTrain batch 11/16 - 170.2ms/batch - loss: 45.83677 - diff: 23.21mlTrain batch 12/16 - 170.5ms/batch - loss: 45.49598 - diff: 23.44mlTrain batch 13/16 - 170.1ms/batch - loss: 44.33559 - diff: 22.95mlTrain batch 14/16 - 170.1ms/batch - loss: 43.52355 - diff: 23.15mlTrain batch 15/16 - 170.1ms/batch - loss: 42.50509 - diff: 22.87mlTrain batch 16/16 - 56.1ms/batch - loss: 42.65793 - diff: 22.79mlTrain batch 16/16 - 15.2s 56.1ms/batch - loss: 42.65793 - diff: 22.79ml
Test 1.0s: val_loss: 52.14416 - diff: 20.58ml

Epoch 101: current best loss = 28.61492, at epoch 97
Train batch 1/16 - 185.2ms/batch - loss: 22.58872 - diff: 22.41mlTrain batch 2/16 - 169.3ms/batch - loss: 21.35384 - diff: 20.32mlTrain batch 3/16 - 170.7ms/batch - loss: 28.97553 - diff: 21.70mlTrain batch 4/16 - 171.0ms/batch - loss: 31.69954 - diff: 23.37mlTrain batch 5/16 - 203.0ms/batch - loss: 31.40956 - diff: 23.07mlTrain batch 6/16 - 170.2ms/batch - loss: 32.67650 - diff: 23.67mlTrain batch 7/16 - 174.5ms/batch - loss: 31.91184 - diff: 23.62mlTrain batch 8/16 - 197.7ms/batch - loss: 31.32313 - diff: 23.30mlTrain batch 9/16 - 174.9ms/batch - loss: 31.91225 - diff: 22.95mlTrain batch 10/16 - 183.8ms/batch - loss: 30.86625 - diff: 22.81mlTrain batch 11/16 - 188.9ms/batch - loss: 30.37032 - diff: 22.67mlTrain batch 12/16 - 189.5ms/batch - loss: 34.45886 - diff: 22.94mlTrain batch 13/16 - 170.1ms/batch - loss: 33.90894 - diff: 22.98mlTrain batch 14/16 - 169.0ms/batch - loss: 38.25657 - diff: 23.40mlTrain batch 15/16 - 170.3ms/batch - loss: 37.32852 - diff: 23.27mlTrain batch 16/16 - 56.2ms/batch - loss: 37.61131 - diff: 23.18mlTrain batch 16/16 - 17.3s 56.2ms/batch - loss: 37.61131 - diff: 23.18ml
Test 1.1s: val_loss: 33.24272 - diff: 20.22ml

Epoch 102: current best loss = 28.61492, at epoch 97
Train batch 1/16 - 199.2ms/batch - loss: 21.27508 - diff: 21.60mlTrain batch 2/16 - 179.8ms/batch - loss: 20.29415 - diff: 20.84mlTrain batch 3/16 - 178.6ms/batch - loss: 21.10038 - diff: 20.30mlTrain batch 4/16 - 174.1ms/batch - loss: 34.67586 - diff: 21.58mlTrain batch 5/16 - 170.2ms/batch - loss: 37.05798 - diff: 22.14mlTrain batch 6/16 - 170.0ms/batch - loss: 34.92396 - diff: 21.87mlTrain batch 7/16 - 170.0ms/batch - loss: 48.80847 - diff: 22.77mlTrain batch 8/16 - 170.0ms/batch - loss: 45.33353 - diff: 22.45mlTrain batch 9/16 - 170.2ms/batch - loss: 45.39281 - diff: 22.58mlTrain batch 10/16 - 183.8ms/batch - loss: 43.07988 - diff: 22.45mlTrain batch 11/16 - 170.1ms/batch - loss: 44.86708 - diff: 23.36mlTrain batch 12/16 - 188.3ms/batch - loss: 42.27316 - diff: 22.88mlTrain batch 13/16 - 172.9ms/batch - loss: 40.82256 - diff: 22.71mlTrain batch 14/16 - 184.9ms/batch - loss: 39.62054 - diff: 22.75mlTrain batch 15/16 - 175.1ms/batch - loss: 38.35013 - diff: 22.53mlTrain batch 16/16 - 56.1ms/batch - loss: 38.96087 - diff: 22.52mlTrain batch 16/16 - 15.4s 56.1ms/batch - loss: 38.96087 - diff: 22.52ml
Test 0.9s: val_loss: 28.81184 - diff: 19.63ml

Epoch 103: current best loss = 28.61492, at epoch 97
Train batch 1/16 - 187.2ms/batch - loss: 26.81445 - diff: 21.78mlTrain batch 2/16 - 170.0ms/batch - loss: 85.44743 - diff: 29.17mlTrain batch 3/16 - 170.0ms/batch - loss: 63.18192 - diff: 26.24mlTrain batch 4/16 - 170.2ms/batch - loss: 51.70289 - diff: 24.39mlTrain batch 5/16 - 174.4ms/batch - loss: 43.60734 - diff: 22.44mlTrain batch 6/16 - 170.1ms/batch - loss: 40.48973 - diff: 21.97mlTrain batch 7/16 - 169.9ms/batch - loss: 37.39893 - diff: 21.41mlTrain batch 8/16 - 170.1ms/batch - loss: 34.92167 - diff: 21.03mlTrain batch 9/16 - 170.0ms/batch - loss: 33.44668 - diff: 21.11mlTrain batch 10/16 - 170.1ms/batch - loss: 33.70807 - diff: 21.34mlTrain batch 11/16 - 169.5ms/batch - loss: 32.80142 - diff: 21.28mlTrain batch 12/16 - 188.7ms/batch - loss: 33.08005 - diff: 21.23mlTrain batch 13/16 - 170.1ms/batch - loss: 33.44461 - diff: 21.63mlTrain batch 14/16 - 170.2ms/batch - loss: 32.87838 - diff: 21.42mlTrain batch 15/16 - 170.0ms/batch - loss: 32.31562 - diff: 21.32mlTrain batch 16/16 - 56.1ms/batch - loss: 53.11377 - diff: 21.94mlTrain batch 16/16 - 15.6s 56.1ms/batch - loss: 53.11377 - diff: 21.94ml
Test 1.0s: val_loss: 30.70693 - diff: 22.01ml

Epoch 104: current best loss = 28.61492, at epoch 97
Train batch 1/16 - 188.9ms/batch - loss: 20.28883 - diff: 19.35mlTrain batch 2/16 - 173.3ms/batch - loss: 24.58860 - diff: 21.25mlTrain batch 3/16 - 170.3ms/batch - loss: 29.44910 - diff: 22.52mlTrain batch 4/16 - 170.2ms/batch - loss: 26.91071 - diff: 21.73mlTrain batch 5/16 - 188.9ms/batch - loss: 28.95112 - diff: 22.55mlTrain batch 6/16 - 184.6ms/batch - loss: 36.42581 - diff: 22.58mlTrain batch 7/16 - 182.6ms/batch - loss: 35.64173 - diff: 22.44mlTrain batch 8/16 - 170.2ms/batch - loss: 37.53315 - diff: 22.76mlTrain batch 9/16 - 170.1ms/batch - loss: 36.89118 - diff: 22.82mlTrain batch 10/16 - 170.0ms/batch - loss: 38.36104 - diff: 23.50mlTrain batch 11/16 - 170.1ms/batch - loss: 37.02058 - diff: 23.08mlTrain batch 12/16 - 170.1ms/batch - loss: 45.48622 - diff: 23.54mlTrain batch 13/16 - 172.7ms/batch - loss: 43.48739 - diff: 23.31mlTrain batch 14/16 - 184.8ms/batch - loss: 41.91794 - diff: 23.04mlTrain batch 15/16 - 170.2ms/batch - loss: 40.38079 - diff: 22.81mlTrain batch 16/16 - 56.2ms/batch - loss: 40.59115 - diff: 22.73mlTrain batch 16/16 - 16.1s 56.2ms/batch - loss: 40.59115 - diff: 22.73ml
Test 1.0s: val_loss: 32.26436 - diff: 23.72ml

Epoch 105: current best loss = 28.61492, at epoch 97
Train batch 1/16 - 194.7ms/batch - loss: 40.08169 - diff: 27.61mlTrain batch 2/16 - 170.0ms/batch - loss: 34.12709 - diff: 24.65mlTrain batch 3/16 - 181.7ms/batch - loss: 38.77006 - diff: 27.27mlTrain batch 4/16 - 170.0ms/batch - loss: 39.36559 - diff: 27.37mlTrain batch 5/16 - 170.1ms/batch - loss: 39.29078 - diff: 26.62mlTrain batch 6/16 - 169.9ms/batch - loss: 36.10342 - diff: 25.47mlTrain batch 7/16 - 188.8ms/batch - loss: 33.20556 - diff: 24.23mlTrain batch 8/16 - 170.3ms/batch - loss: 31.52462 - diff: 23.57mlTrain batch 9/16 - 188.9ms/batch - loss: 29.63311 - diff: 22.90mlTrain batch 10/16 - 175.8ms/batch - loss: 40.00425 - diff: 23.45mlTrain batch 11/16 - 170.0ms/batch - loss: 39.54198 - diff: 23.33mlTrain batch 12/16 - 176.0ms/batch - loss: 44.35490 - diff: 24.20mlTrain batch 13/16 - 198.7ms/batch - loss: 42.47050 - diff: 23.99mlTrain batch 14/16 - 169.1ms/batch - loss: 41.04354 - diff: 23.69mlTrain batch 15/16 - 169.9ms/batch - loss: 39.31534 - diff: 23.30mlTrain batch 16/16 - 56.1ms/batch - loss: 42.42966 - diff: 23.52mlTrain batch 16/16 - 17.3s 56.1ms/batch - loss: 42.42966 - diff: 23.52ml
Test 1.1s: val_loss: 29.45377 - diff: 21.06ml

Epoch 106: current best loss = 28.61492, at epoch 97
Train batch 1/16 - 183.9ms/batch - loss: 22.35329 - diff: 21.44mlTrain batch 2/16 - 168.7ms/batch - loss: 33.21365 - diff: 22.86mlTrain batch 3/16 - 170.1ms/batch - loss: 33.07867 - diff: 23.39mlTrain batch 4/16 - 170.5ms/batch - loss: 43.97864 - diff: 23.38mlTrain batch 5/16 - 170.1ms/batch - loss: 39.54807 - diff: 22.17mlTrain batch 6/16 - 170.0ms/batch - loss: 44.24926 - diff: 23.68mlTrain batch 7/16 - 170.2ms/batch - loss: 56.14644 - diff: 23.83mlTrain batch 8/16 - 170.0ms/batch - loss: 54.06850 - diff: 23.86mlTrain batch 9/16 - 170.1ms/batch - loss: 49.23986 - diff: 22.84mlTrain batch 10/16 - 170.2ms/batch - loss: 47.19222 - diff: 22.76mlTrain batch 11/16 - 170.1ms/batch - loss: 44.21684 - diff: 22.29mlTrain batch 12/16 - 170.3ms/batch - loss: 42.75024 - diff: 22.42mlTrain batch 13/16 - 170.0ms/batch - loss: 41.29756 - diff: 22.45mlTrain batch 14/16 - 170.2ms/batch - loss: 41.51833 - diff: 22.93mlTrain batch 15/16 - 170.0ms/batch - loss: 40.20782 - diff: 22.84mlTrain batch 16/16 - 56.1ms/batch - loss: 40.17435 - diff: 22.70mlTrain batch 16/16 - 14.5s 56.1ms/batch - loss: 40.17435 - diff: 22.70ml
Test 0.7s: val_loss: 30.12634 - diff: 19.96ml

Epoch 107: current best loss = 28.61492, at epoch 97
Train batch 1/16 - 187.9ms/batch - loss: 22.42788 - diff: 17.43mlTrain batch 2/16 - 170.3ms/batch - loss: 15.86920 - diff: 15.78mlTrain batch 3/16 - 203.0ms/batch - loss: 31.02527 - diff: 20.43mlTrain batch 4/16 - 171.7ms/batch - loss: 33.60957 - diff: 21.83mlTrain batch 5/16 - 185.9ms/batch - loss: 30.83248 - diff: 21.55mlTrain batch 6/16 - 170.3ms/batch - loss: 33.94129 - diff: 22.39mlTrain batch 7/16 - 170.1ms/batch - loss: 36.78105 - diff: 23.39mlTrain batch 8/16 - 170.1ms/batch - loss: 41.16426 - diff: 23.52mlTrain batch 9/16 - 171.7ms/batch - loss: 39.05951 - diff: 23.34mlTrain batch 10/16 - 170.1ms/batch - loss: 40.34080 - diff: 23.54mlTrain batch 11/16 - 170.0ms/batch - loss: 47.21354 - diff: 24.15mlTrain batch 12/16 - 170.1ms/batch - loss: 44.17285 - diff: 23.41mlTrain batch 13/16 - 169.9ms/batch - loss: 42.67870 - diff: 23.35mlTrain batch 14/16 - 170.1ms/batch - loss: 41.28287 - diff: 23.18mlTrain batch 15/16 - 170.1ms/batch - loss: 39.34978 - diff: 22.74mlTrain batch 16/16 - 63.7ms/batch - loss: 41.30250 - diff: 22.83mlTrain batch 16/16 - 16.7s 63.7ms/batch - loss: 41.30250 - diff: 22.83ml
Test 1.0s: val_loss: 27.25434 - diff: 19.03ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Systole_VGG19_Adam-0.001_MSE_DA3_best

Epoch 108: current best loss = 27.25434, at epoch 107
Train batch 1/16 - 192.7ms/batch - loss: 12.75987 - diff: 16.28mlTrain batch 2/16 - 176.6ms/batch - loss: 17.84182 - diff: 18.08mlTrain batch 3/16 - 170.2ms/batch - loss: 19.54551 - diff: 18.39mlTrain batch 4/16 - 171.4ms/batch - loss: 48.61101 - diff: 22.58mlTrain batch 5/16 - 170.0ms/batch - loss: 45.96841 - diff: 23.40mlTrain batch 6/16 - 175.0ms/batch - loss: 41.53746 - diff: 22.97mlTrain batch 7/16 - 170.0ms/batch - loss: 38.33935 - diff: 22.56mlTrain batch 8/16 - 170.0ms/batch - loss: 38.22781 - diff: 22.75mlTrain batch 9/16 - 169.9ms/batch - loss: 36.36842 - diff: 22.49mlTrain batch 10/16 - 170.0ms/batch - loss: 37.93632 - diff: 23.31mlTrain batch 11/16 - 201.8ms/batch - loss: 35.60997 - diff: 22.59mlTrain batch 12/16 - 171.8ms/batch - loss: 33.92831 - diff: 22.07mlTrain batch 13/16 - 179.3ms/batch - loss: 33.50273 - diff: 22.01mlTrain batch 14/16 - 170.2ms/batch - loss: 32.43341 - diff: 21.81mlTrain batch 15/16 - 170.1ms/batch - loss: 37.00419 - diff: 22.39mlTrain batch 16/16 - 56.2ms/batch - loss: 38.11468 - diff: 22.33mlTrain batch 16/16 - 17.1s 56.2ms/batch - loss: 38.11468 - diff: 22.33ml
Test 1.0s: val_loss: 28.91102 - diff: 19.06ml

Epoch 109: current best loss = 27.25434, at epoch 107
Train batch 1/16 - 195.5ms/batch - loss: 35.89433 - diff: 23.85mlTrain batch 2/16 - 169.4ms/batch - loss: 26.24400 - diff: 19.46mlTrain batch 3/16 - 170.1ms/batch - loss: 21.45168 - diff: 17.55mlTrain batch 4/16 - 169.3ms/batch - loss: 49.42662 - diff: 20.47mlTrain batch 5/16 - 170.4ms/batch - loss: 43.17053 - diff: 20.56mlTrain batch 6/16 - 184.0ms/batch - loss: 38.18382 - diff: 19.43mlTrain batch 7/16 - 170.1ms/batch - loss: 33.94271 - diff: 18.56mlTrain batch 8/16 - 169.1ms/batch - loss: 39.98755 - diff: 19.88mlTrain batch 9/16 - 181.7ms/batch - loss: 38.31815 - diff: 20.15mlTrain batch 10/16 - 185.4ms/batch - loss: 37.19773 - diff: 20.54mlTrain batch 11/16 - 188.3ms/batch - loss: 36.53117 - diff: 20.71mlTrain batch 12/16 - 175.4ms/batch - loss: 36.16254 - diff: 20.91mlTrain batch 13/16 - 184.0ms/batch - loss: 36.88477 - diff: 21.33mlTrain batch 14/16 - 170.0ms/batch - loss: 37.45136 - diff: 21.75mlTrain batch 15/16 - 170.1ms/batch - loss: 35.70811 - diff: 21.42mlTrain batch 16/16 - 56.0ms/batch - loss: 36.40875 - diff: 21.42mlTrain batch 16/16 - 17.1s 56.0ms/batch - loss: 36.40875 - diff: 21.42ml
Test 1.0s: val_loss: 31.31003 - diff: 20.73ml

Epoch 110: current best loss = 27.25434, at epoch 107
Train batch 1/16 - 189.0ms/batch - loss: 25.68952 - diff: 22.07mlTrain batch 2/16 - 170.7ms/batch - loss: 25.26960 - diff: 22.38mlTrain batch 3/16 - 169.9ms/batch - loss: 30.90557 - diff: 23.60mlTrain batch 4/16 - 170.1ms/batch - loss: 29.65043 - diff: 23.21mlTrain batch 5/16 - 176.7ms/batch - loss: 62.38956 - diff: 26.72mlTrain batch 6/16 - 169.4ms/batch - loss: 56.04619 - diff: 25.71mlTrain batch 7/16 - 170.2ms/batch - loss: 52.22523 - diff: 25.20mlTrain batch 8/16 - 172.9ms/batch - loss: 47.73582 - diff: 24.30mlTrain batch 9/16 - 169.9ms/batch - loss: 46.57164 - diff: 24.48mlTrain batch 10/16 - 183.6ms/batch - loss: 43.28026 - diff: 23.81mlTrain batch 11/16 - 183.4ms/batch - loss: 40.99662 - diff: 23.31mlTrain batch 12/16 - 174.0ms/batch - loss: 39.13645 - diff: 22.87mlTrain batch 13/16 - 170.2ms/batch - loss: 37.41887 - diff: 22.52mlTrain batch 14/16 - 178.9ms/batch - loss: 35.98267 - diff: 22.23mlTrain batch 15/16 - 170.0ms/batch - loss: 36.94226 - diff: 22.55mlTrain batch 16/16 - 56.1ms/batch - loss: 43.38119 - diff: 22.75mlTrain batch 16/16 - 16.8s 56.1ms/batch - loss: 43.38119 - diff: 22.75ml
Test 1.1s: val_loss: 26.28651 - diff: 19.06ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Systole_VGG19_Adam-0.001_MSE_DA3_best

Epoch 111: current best loss = 26.28651, at epoch 110
Train batch 1/16 - 192.4ms/batch - loss: 75.70938 - diff: 25.43mlTrain batch 2/16 - 177.1ms/batch - loss: 53.57341 - diff: 24.46mlTrain batch 3/16 - 185.9ms/batch - loss: 42.09705 - diff: 22.56mlTrain batch 4/16 - 173.5ms/batch - loss: 39.64974 - diff: 23.81mlTrain batch 5/16 - 169.9ms/batch - loss: 39.67177 - diff: 24.11mlTrain batch 6/16 - 170.2ms/batch - loss: 36.15248 - diff: 23.60mlTrain batch 7/16 - 186.3ms/batch - loss: 37.90250 - diff: 24.36mlTrain batch 8/16 - 175.6ms/batch - loss: 36.86710 - diff: 23.93mlTrain batch 9/16 - 195.9ms/batch - loss: 35.64551 - diff: 23.82mlTrain batch 10/16 - 171.0ms/batch - loss: 35.21988 - diff: 23.82mlTrain batch 11/16 - 184.7ms/batch - loss: 39.68271 - diff: 23.93mlTrain batch 12/16 - 175.3ms/batch - loss: 38.64569 - diff: 23.55mlTrain batch 13/16 - 170.1ms/batch - loss: 36.87097 - diff: 23.08mlTrain batch 14/16 - 168.9ms/batch - loss: 35.25092 - diff: 22.64mlTrain batch 15/16 - 174.0ms/batch - loss: 33.71073 - diff: 22.20mlTrain batch 16/16 - 56.1ms/batch - loss: 33.95679 - diff: 22.11mlTrain batch 16/16 - 17.2s 56.1ms/batch - loss: 33.95679 - diff: 22.11ml
Test 1.0s: val_loss: 28.39388 - diff: 19.16ml

Epoch 112: current best loss = 26.28651, at epoch 110
Train batch 1/16 - 185.3ms/batch - loss: 32.64932 - diff: 21.41mlTrain batch 2/16 - 181.2ms/batch - loss: 38.51617 - diff: 24.78mlTrain batch 3/16 - 178.4ms/batch - loss: 35.00433 - diff: 23.22mlTrain batch 4/16 - 170.2ms/batch - loss: 30.75927 - diff: 21.90mlTrain batch 5/16 - 169.9ms/batch - loss: 35.82453 - diff: 22.73mlTrain batch 6/16 - 175.2ms/batch - loss: 34.07752 - diff: 22.11mlTrain batch 7/16 - 170.1ms/batch - loss: 32.23584 - diff: 21.45mlTrain batch 8/16 - 170.3ms/batch - loss: 31.60663 - diff: 21.49mlTrain batch 9/16 - 182.0ms/batch - loss: 33.49761 - diff: 22.30mlTrain batch 10/16 - 172.6ms/batch - loss: 31.83287 - diff: 21.99mlTrain batch 11/16 - 189.1ms/batch - loss: 36.89512 - diff: 22.64mlTrain batch 12/16 - 201.2ms/batch - loss: 36.23360 - diff: 22.62mlTrain batch 13/16 - 170.2ms/batch - loss: 36.56838 - diff: 22.87mlTrain batch 14/16 - 168.8ms/batch - loss: 35.64553 - diff: 22.47mlTrain batch 15/16 - 174.3ms/batch - loss: 34.37707 - diff: 22.05mlTrain batch 16/16 - 56.2ms/batch - loss: 69.57840 - diff: 22.76mlTrain batch 16/16 - 16.2s 56.2ms/batch - loss: 69.57840 - diff: 22.76ml
Test 0.9s: val_loss: 27.75316 - diff: 18.50ml

Epoch 113: current best loss = 26.28651, at epoch 110
Train batch 1/16 - 182.9ms/batch - loss: 35.74844 - diff: 21.04mlTrain batch 2/16 - 179.7ms/batch - loss: 25.35389 - diff: 19.53mlTrain batch 3/16 - 170.1ms/batch - loss: 29.94957 - diff: 22.32mlTrain batch 4/16 - 183.8ms/batch - loss: 39.29886 - diff: 26.08mlTrain batch 5/16 - 170.1ms/batch - loss: 39.34946 - diff: 26.87mlTrain batch 6/16 - 170.2ms/batch - loss: 45.44873 - diff: 27.42mlTrain batch 7/16 - 183.4ms/batch - loss: 42.09615 - diff: 26.35mlTrain batch 8/16 - 176.9ms/batch - loss: 43.51260 - diff: 26.63mlTrain batch 9/16 - 170.8ms/batch - loss: 42.03787 - diff: 26.24mlTrain batch 10/16 - 168.8ms/batch - loss: 39.80760 - diff: 25.50mlTrain batch 11/16 - 209.8ms/batch - loss: 53.27152 - diff: 27.16mlTrain batch 12/16 - 170.0ms/batch - loss: 49.62821 - diff: 26.06mlTrain batch 13/16 - 170.2ms/batch - loss: 48.02714 - diff: 25.68mlTrain batch 14/16 - 170.4ms/batch - loss: 46.38687 - diff: 25.41mlTrain batch 15/16 - 170.0ms/batch - loss: 44.66328 - diff: 24.96mlTrain batch 16/16 - 56.1ms/batch - loss: 45.07092 - diff: 24.88mlTrain batch 16/16 - 15.7s 56.1ms/batch - loss: 45.07092 - diff: 24.88ml
Test 1.1s: val_loss: 40.41952 - diff: 19.06ml

Epoch 114: current best loss = 26.28651, at epoch 110
Train batch 1/16 - 189.6ms/batch - loss: 13.69229 - diff: 16.65mlTrain batch 2/16 - 183.8ms/batch - loss: 15.77212 - diff: 17.28mlTrain batch 3/16 - 170.0ms/batch - loss: 22.63644 - diff: 18.78mlTrain batch 4/16 - 170.3ms/batch - loss: 19.67378 - diff: 17.74mlTrain batch 5/16 - 170.0ms/batch - loss: 20.74121 - diff: 18.65mlTrain batch 6/16 - 170.5ms/batch - loss: 20.74571 - diff: 18.83mlTrain batch 7/16 - 188.7ms/batch - loss: 21.81485 - diff: 19.23mlTrain batch 8/16 - 177.3ms/batch - loss: 21.44810 - diff: 19.27mlTrain batch 9/16 - 188.7ms/batch - loss: 22.20070 - diff: 19.71mlTrain batch 10/16 - 171.4ms/batch - loss: 21.78367 - diff: 19.61mlTrain batch 11/16 - 170.1ms/batch - loss: 31.07813 - diff: 20.80mlTrain batch 12/16 - 172.1ms/batch - loss: 31.64438 - diff: 21.14mlTrain batch 13/16 - 170.0ms/batch - loss: 31.36049 - diff: 21.20mlTrain batch 14/16 - 170.3ms/batch - loss: 30.73546 - diff: 20.98mlTrain batch 15/16 - 170.3ms/batch - loss: 33.95270 - diff: 21.38mlTrain batch 16/16 - 56.1ms/batch - loss: 42.14155 - diff: 21.79mlTrain batch 16/16 - 16.2s 56.1ms/batch - loss: 42.14155 - diff: 21.79ml
Test 1.1s: val_loss: 30.35516 - diff: 23.21ml

Epoch 115: current best loss = 26.28651, at epoch 110
Train batch 1/16 - 185.4ms/batch - loss: 15.19566 - diff: 17.16mlTrain batch 2/16 - 170.2ms/batch - loss: 19.17278 - diff: 19.24mlTrain batch 3/16 - 169.9ms/batch - loss: 21.04865 - diff: 20.68mlTrain batch 4/16 - 170.2ms/batch - loss: 24.57009 - diff: 22.14mlTrain batch 5/16 - 177.1ms/batch - loss: 24.50325 - diff: 22.07mlTrain batch 6/16 - 170.0ms/batch - loss: 40.96386 - diff: 24.40mlTrain batch 7/16 - 170.1ms/batch - loss: 38.78185 - diff: 23.72mlTrain batch 8/16 - 170.4ms/batch - loss: 37.01378 - diff: 23.09mlTrain batch 9/16 - 170.1ms/batch - loss: 35.20414 - diff: 22.71mlTrain batch 10/16 - 170.1ms/batch - loss: 34.65169 - diff: 22.31mlTrain batch 11/16 - 177.4ms/batch - loss: 34.24634 - diff: 22.44mlTrain batch 12/16 - 174.8ms/batch - loss: 34.94056 - diff: 22.35mlTrain batch 13/16 - 170.1ms/batch - loss: 39.38516 - diff: 22.78mlTrain batch 14/16 - 170.1ms/batch - loss: 37.56694 - diff: 22.39mlTrain batch 15/16 - 176.6ms/batch - loss: 37.16335 - diff: 22.37mlTrain batch 16/16 - 56.1ms/batch - loss: 36.92659 - diff: 22.17mlTrain batch 16/16 - 15.8s 56.1ms/batch - loss: 36.92659 - diff: 22.17ml
Test 1.2s: val_loss: 29.91687 - diff: 22.41ml

Epoch 116: current best loss = 26.28651, at epoch 110
Train batch 1/16 - 192.0ms/batch - loss: 17.16506 - diff: 19.78mlTrain batch 2/16 - 170.6ms/batch - loss: 26.55464 - diff: 22.85mlTrain batch 3/16 - 181.8ms/batch - loss: 22.49439 - diff: 20.63mlTrain batch 4/16 - 176.5ms/batch - loss: 20.34871 - diff: 19.72mlTrain batch 5/16 - 180.2ms/batch - loss: 30.85751 - diff: 20.76mlTrain batch 6/16 - 169.9ms/batch - loss: 28.23822 - diff: 19.93mlTrain batch 7/16 - 182.6ms/batch - loss: 44.92879 - diff: 22.30mlTrain batch 8/16 - 171.7ms/batch - loss: 41.38745 - diff: 21.79mlTrain batch 9/16 - 182.2ms/batch - loss: 39.77729 - diff: 21.91mlTrain batch 10/16 - 181.7ms/batch - loss: 39.03142 - diff: 21.79mlTrain batch 11/16 - 184.4ms/batch - loss: 37.84775 - diff: 21.55mlTrain batch 12/16 - 170.3ms/batch - loss: 36.28178 - diff: 21.27mlTrain batch 13/16 - 169.7ms/batch - loss: 34.92964 - diff: 20.97mlTrain batch 14/16 - 170.2ms/batch - loss: 35.78300 - diff: 21.49mlTrain batch 15/16 - 170.1ms/batch - loss: 35.23970 - diff: 21.75mlTrain batch 16/16 - 56.1ms/batch - loss: 36.65087 - diff: 21.77mlTrain batch 16/16 - 16.5s 56.1ms/batch - loss: 36.65087 - diff: 21.77ml
Test 1.0s: val_loss: 29.99306 - diff: 19.00ml

Epoch 117: current best loss = 26.28651, at epoch 110
Train batch 1/16 - 188.7ms/batch - loss: 17.21283 - diff: 18.29mlTrain batch 2/16 - 170.2ms/batch - loss: 20.98342 - diff: 19.57mlTrain batch 3/16 - 169.9ms/batch - loss: 20.04779 - diff: 19.73mlTrain batch 4/16 - 170.1ms/batch - loss: 50.74718 - diff: 23.31mlTrain batch 5/16 - 170.1ms/batch - loss: 43.96406 - diff: 22.10mlTrain batch 6/16 - 169.9ms/batch - loss: 39.48283 - diff: 21.66mlTrain batch 7/16 - 170.1ms/batch - loss: 37.42330 - diff: 21.50mlTrain batch 8/16 - 175.4ms/batch - loss: 41.46071 - diff: 21.80mlTrain batch 9/16 - 170.1ms/batch - loss: 42.24127 - diff: 22.20mlTrain batch 10/16 - 188.9ms/batch - loss: 40.97221 - diff: 22.17mlTrain batch 11/16 - 170.0ms/batch - loss: 41.07753 - diff: 22.71mlTrain batch 12/16 - 170.1ms/batch - loss: 40.15433 - diff: 22.81mlTrain batch 13/16 - 170.2ms/batch - loss: 38.84202 - diff: 22.74mlTrain batch 14/16 - 170.2ms/batch - loss: 39.14386 - diff: 23.33mlTrain batch 15/16 - 170.0ms/batch - loss: 38.07072 - diff: 23.22mlTrain batch 16/16 - 56.0ms/batch - loss: 37.87452 - diff: 23.00mlTrain batch 16/16 - 15.3s 56.0ms/batch - loss: 37.87452 - diff: 23.00ml
Test 1.0s: val_loss: 33.48046 - diff: 19.57ml

Epoch 118: current best loss = 26.28651, at epoch 110
Train batch 1/16 - 182.9ms/batch - loss: 127.71432 - diff: 32.16mlTrain batch 2/16 - 183.9ms/batch - loss: 69.43495 - diff: 23.17mlTrain batch 3/16 - 170.1ms/batch - loss: 50.81056 - diff: 21.06mlTrain batch 4/16 - 169.1ms/batch - loss: 46.50857 - diff: 22.03mlTrain batch 5/16 - 177.4ms/batch - loss: 48.31756 - diff: 23.30mlTrain batch 6/16 - 170.2ms/batch - loss: 43.12568 - diff: 22.15mlTrain batch 7/16 - 170.1ms/batch - loss: 42.86809 - diff: 22.29mlTrain batch 8/16 - 174.9ms/batch - loss: 39.67238 - diff: 21.88mlTrain batch 9/16 - 206.0ms/batch - loss: 37.72598 - diff: 21.73mlTrain batch 10/16 - 170.2ms/batch - loss: 37.77790 - diff: 21.86mlTrain batch 11/16 - 192.8ms/batch - loss: 35.56095 - diff: 21.39mlTrain batch 12/16 - 170.1ms/batch - loss: 34.37137 - diff: 21.20mlTrain batch 13/16 - 170.4ms/batch - loss: 33.40884 - diff: 21.18mlTrain batch 14/16 - 170.0ms/batch - loss: 32.63561 - diff: 21.21mlTrain batch 15/16 - 170.2ms/batch - loss: 34.95882 - diff: 21.49mlTrain batch 16/16 - 56.3ms/batch - loss: 37.64260 - diff: 21.64mlTrain batch 16/16 - 15.9s 56.3ms/batch - loss: 37.64260 - diff: 21.64ml
Test 0.9s: val_loss: 27.77123 - diff: 20.09ml

Epoch 119: current best loss = 26.28651, at epoch 110
Train batch 1/16 - 188.6ms/batch - loss: 30.13059 - diff: 23.47mlTrain batch 2/16 - 175.3ms/batch - loss: 28.34351 - diff: 23.19mlTrain batch 3/16 - 189.0ms/batch - loss: 24.57807 - diff: 21.93mlTrain batch 4/16 - 179.8ms/batch - loss: 24.80663 - diff: 21.49mlTrain batch 5/16 - 169.9ms/batch - loss: 24.34763 - diff: 20.91mlTrain batch 6/16 - 170.2ms/batch - loss: 23.34740 - diff: 20.30mlTrain batch 7/16 - 170.1ms/batch - loss: 22.63132 - diff: 20.04mlTrain batch 8/16 - 170.2ms/batch - loss: 25.83287 - diff: 20.94mlTrain batch 9/16 - 170.4ms/batch - loss: 24.44723 - diff: 20.42mlTrain batch 10/16 - 169.0ms/batch - loss: 24.61966 - diff: 20.54mlTrain batch 11/16 - 170.2ms/batch - loss: 29.99869 - diff: 21.12mlTrain batch 12/16 - 170.3ms/batch - loss: 29.26408 - diff: 20.95mlTrain batch 13/16 - 189.0ms/batch - loss: 33.93913 - diff: 21.18mlTrain batch 14/16 - 171.4ms/batch - loss: 34.97390 - diff: 21.44mlTrain batch 15/16 - 170.1ms/batch - loss: 34.42478 - diff: 21.29mlTrain batch 16/16 - 56.1ms/batch - loss: 35.09695 - diff: 21.23mlTrain batch 16/16 - 17.2s 56.1ms/batch - loss: 35.09695 - diff: 21.23ml
Test 1.0s: val_loss: 33.72498 - diff: 22.79ml

Epoch 120: current best loss = 26.28651, at epoch 110
Train batch 1/16 - 186.6ms/batch - loss: 28.08189 - diff: 20.83mlTrain batch 2/16 - 171.3ms/batch - loss: 21.08164 - diff: 19.33mlTrain batch 3/16 - 191.8ms/batch - loss: 20.51857 - diff: 19.94mlTrain batch 4/16 - 170.5ms/batch - loss: 17.20550 - diff: 18.31mlTrain batch 5/16 - 170.2ms/batch - loss: 26.55470 - diff: 21.32mlTrain batch 6/16 - 176.3ms/batch - loss: 35.49114 - diff: 22.28mlTrain batch 7/16 - 169.9ms/batch - loss: 33.49997 - diff: 21.64mlTrain batch 8/16 - 169.8ms/batch - loss: 33.78662 - diff: 21.55mlTrain batch 9/16 - 174.1ms/batch - loss: 32.47976 - diff: 21.37mlTrain batch 10/16 - 170.2ms/batch - loss: 31.81866 - diff: 21.30mlTrain batch 11/16 - 170.1ms/batch - loss: 30.65570 - diff: 21.20mlTrain batch 12/16 - 170.3ms/batch - loss: 29.94453 - diff: 21.09mlTrain batch 13/16 - 170.3ms/batch - loss: 33.97232 - diff: 21.36mlTrain batch 14/16 - 169.4ms/batch - loss: 32.59066 - diff: 21.07mlTrain batch 15/16 - 178.8ms/batch - loss: 31.60698 - diff: 20.91mlTrain batch 16/16 - 61.7ms/batch - loss: 33.21499 - diff: 21.02mlTrain batch 16/16 - 16.5s 61.7ms/batch - loss: 33.21499 - diff: 21.02ml
Test 0.9s: val_loss: 34.39824 - diff: 20.89ml

Epoch 121: current best loss = 26.28651, at epoch 110
Train batch 1/16 - 188.6ms/batch - loss: 36.19839 - diff: 25.80mlTrain batch 2/16 - 180.0ms/batch - loss: 27.01622 - diff: 22.43mlTrain batch 3/16 - 184.1ms/batch - loss: 27.67254 - diff: 22.59mlTrain batch 4/16 - 170.3ms/batch - loss: 28.78960 - diff: 21.98mlTrain batch 5/16 - 194.9ms/batch - loss: 30.46009 - diff: 22.67mlTrain batch 6/16 - 168.9ms/batch - loss: 29.70840 - diff: 22.55mlTrain batch 7/16 - 170.0ms/batch - loss: 32.19869 - diff: 22.95mlTrain batch 8/16 - 169.9ms/batch - loss: 30.15322 - diff: 22.42mlTrain batch 9/16 - 169.9ms/batch - loss: 38.51899 - diff: 23.17mlTrain batch 10/16 - 171.4ms/batch - loss: 36.50099 - diff: 22.71mlTrain batch 11/16 - 185.4ms/batch - loss: 34.42955 - diff: 22.15mlTrain batch 12/16 - 170.3ms/batch - loss: 33.72091 - diff: 22.19mlTrain batch 13/16 - 170.0ms/batch - loss: 32.44504 - diff: 21.92mlTrain batch 14/16 - 170.3ms/batch - loss: 31.74025 - diff: 21.81mlTrain batch 15/16 - 170.0ms/batch - loss: 34.39758 - diff: 21.95mlTrain batch 16/16 - 56.1ms/batch - loss: 34.67440 - diff: 21.84mlTrain batch 16/16 - 17.0s 56.1ms/batch - loss: 34.67440 - diff: 21.84ml
Test 0.9s: val_loss: 50.70717 - diff: 18.49ml
Epoch   122: reducing learning rate of group 0 to 7.8125e-06.

Epoch 122: current best loss = 26.28651, at epoch 110
Train batch 1/16 - 187.3ms/batch - loss: 35.18357 - diff: 22.56mlTrain batch 2/16 - 173.6ms/batch - loss: 22.79891 - diff: 18.20mlTrain batch 3/16 - 185.4ms/batch - loss: 20.21460 - diff: 17.42mlTrain batch 4/16 - 170.1ms/batch - loss: 45.15536 - diff: 21.25mlTrain batch 5/16 - 190.1ms/batch - loss: 41.47832 - diff: 21.91mlTrain batch 6/16 - 175.9ms/batch - loss: 36.40714 - diff: 20.58mlTrain batch 7/16 - 169.8ms/batch - loss: 34.56477 - diff: 20.45mlTrain batch 8/16 - 169.2ms/batch - loss: 34.63191 - diff: 20.69mlTrain batch 9/16 - 189.9ms/batch - loss: 34.04595 - diff: 21.06mlTrain batch 10/16 - 172.1ms/batch - loss: 32.37763 - diff: 20.86mlTrain batch 11/16 - 170.2ms/batch - loss: 31.50951 - diff: 20.87mlTrain batch 12/16 - 170.4ms/batch - loss: 30.53300 - diff: 20.76mlTrain batch 13/16 - 182.1ms/batch - loss: 32.40286 - diff: 21.27mlTrain batch 14/16 - 184.8ms/batch - loss: 32.34519 - diff: 21.62mlTrain batch 15/16 - 182.1ms/batch - loss: 35.76014 - diff: 22.00mlTrain batch 16/16 - 56.1ms/batch - loss: 35.53810 - diff: 21.80mlTrain batch 16/16 - 17.2s 56.1ms/batch - loss: 35.53810 - diff: 21.80ml
Test 1.1s: val_loss: 25.21815 - diff: 19.46ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Systole_VGG19_Adam-0.001_MSE_DA3_best

Epoch 123: current best loss = 25.21815, at epoch 122
Train batch 1/16 - 181.5ms/batch - loss: 15.21092 - diff: 17.08mlTrain batch 2/16 - 177.9ms/batch - loss: 17.27399 - diff: 18.56mlTrain batch 3/16 - 175.3ms/batch - loss: 22.84291 - diff: 20.12mlTrain batch 4/16 - 170.5ms/batch - loss: 22.23225 - diff: 20.14mlTrain batch 5/16 - 171.5ms/batch - loss: 23.09246 - diff: 20.09mlTrain batch 6/16 - 170.2ms/batch - loss: 26.89524 - diff: 21.24mlTrain batch 7/16 - 174.1ms/batch - loss: 27.26532 - diff: 21.36mlTrain batch 8/16 - 168.8ms/batch - loss: 25.09048 - diff: 20.42mlTrain batch 9/16 - 170.2ms/batch - loss: 23.67433 - diff: 19.83mlTrain batch 10/16 - 170.4ms/batch - loss: 30.08479 - diff: 20.56mlTrain batch 11/16 - 170.1ms/batch - loss: 37.69635 - diff: 21.48mlTrain batch 12/16 - 182.0ms/batch - loss: 36.16171 - diff: 21.12mlTrain batch 13/16 - 171.8ms/batch - loss: 35.30652 - diff: 21.27mlTrain batch 14/16 - 170.2ms/batch - loss: 34.79913 - diff: 21.35mlTrain batch 15/16 - 170.0ms/batch - loss: 34.51944 - diff: 21.63mlTrain batch 16/16 - 56.1ms/batch - loss: 37.29413 - diff: 21.80mlTrain batch 16/16 - 15.7s 56.1ms/batch - loss: 37.29413 - diff: 21.80ml
Test 1.2s: val_loss: 32.24902 - diff: 19.70ml

Epoch 124: current best loss = 25.21815, at epoch 122
Train batch 1/16 - 184.7ms/batch - loss: 29.32487 - diff: 22.97mlTrain batch 2/16 - 170.2ms/batch - loss: 36.17355 - diff: 23.56mlTrain batch 3/16 - 170.2ms/batch - loss: 30.66933 - diff: 21.90mlTrain batch 4/16 - 170.4ms/batch - loss: 46.65158 - diff: 24.23mlTrain batch 5/16 - 170.1ms/batch - loss: 42.32799 - diff: 23.79mlTrain batch 6/16 - 170.3ms/batch - loss: 38.00982 - diff: 22.43mlTrain batch 7/16 - 176.1ms/batch - loss: 35.19418 - diff: 21.76mlTrain batch 8/16 - 183.2ms/batch - loss: 32.83569 - diff: 21.31mlTrain batch 9/16 - 177.3ms/batch - loss: 31.72605 - diff: 20.98mlTrain batch 10/16 - 170.1ms/batch - loss: 30.97060 - diff: 20.85mlTrain batch 11/16 - 170.1ms/batch - loss: 32.15577 - diff: 21.28mlTrain batch 12/16 - 175.0ms/batch - loss: 31.24137 - diff: 21.03mlTrain batch 13/16 - 181.6ms/batch - loss: 35.54403 - diff: 21.54mlTrain batch 14/16 - 177.7ms/batch - loss: 34.18524 - diff: 21.38mlTrain batch 15/16 - 184.7ms/batch - loss: 32.87305 - diff: 21.11mlTrain batch 16/16 - 56.1ms/batch - loss: 33.36535 - diff: 21.01mlTrain batch 16/16 - 16.5s 56.1ms/batch - loss: 33.36535 - diff: 21.01ml
Test 1.1s: val_loss: 25.13050 - diff: 18.98ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Systole_VGG19_Adam-0.001_MSE_DA3_best

Epoch 125: current best loss = 25.13050, at epoch 124
Train batch 1/16 - 188.6ms/batch - loss: 76.26398 - diff: 23.34mlTrain batch 2/16 - 179.0ms/batch - loss: 46.38809 - diff: 21.09mlTrain batch 3/16 - 170.1ms/batch - loss: 38.99871 - diff: 21.60mlTrain batch 4/16 - 170.1ms/batch - loss: 33.52493 - diff: 20.90mlTrain batch 5/16 - 170.1ms/batch - loss: 29.44405 - diff: 19.99mlTrain batch 6/16 - 170.2ms/batch - loss: 30.06733 - diff: 20.42mlTrain batch 7/16 - 170.2ms/batch - loss: 29.54827 - diff: 20.80mlTrain batch 8/16 - 176.7ms/batch - loss: 34.67187 - diff: 21.16mlTrain batch 9/16 - 170.2ms/batch - loss: 33.47958 - diff: 21.11mlTrain batch 10/16 - 170.1ms/batch - loss: 35.27656 - diff: 21.86mlTrain batch 11/16 - 169.7ms/batch - loss: 33.69800 - diff: 21.44mlTrain batch 12/16 - 172.2ms/batch - loss: 32.15319 - diff: 20.99mlTrain batch 13/16 - 169.9ms/batch - loss: 31.78769 - diff: 21.01mlTrain batch 14/16 - 177.9ms/batch - loss: 32.13598 - diff: 21.47mlTrain batch 15/16 - 170.7ms/batch - loss: 32.15824 - diff: 21.51mlTrain batch 16/16 - 64.0ms/batch - loss: 32.29528 - diff: 21.40mlTrain batch 16/16 - 16.7s 64.0ms/batch - loss: 32.29528 - diff: 21.40ml
Test 1.0s: val_loss: 42.35919 - diff: 20.71ml

Epoch 126: current best loss = 25.13050, at epoch 124
Train batch 1/16 - 188.7ms/batch - loss: 31.62610 - diff: 24.81mlTrain batch 2/16 - 179.1ms/batch - loss: 33.36825 - diff: 24.90mlTrain batch 3/16 - 222.9ms/batch - loss: 29.80650 - diff: 22.93mlTrain batch 4/16 - 178.6ms/batch - loss: 25.61198 - diff: 20.67mlTrain batch 5/16 - 182.7ms/batch - loss: 26.19387 - diff: 21.12mlTrain batch 6/16 - 173.8ms/batch - loss: 25.22415 - diff: 20.74mlTrain batch 7/16 - 186.2ms/batch - loss: 37.64112 - diff: 22.48mlTrain batch 8/16 - 177.1ms/batch - loss: 36.76634 - diff: 22.43mlTrain batch 9/16 - 170.0ms/batch - loss: 35.33998 - diff: 22.33mlTrain batch 10/16 - 170.1ms/batch - loss: 33.10202 - diff: 21.76mlTrain batch 11/16 - 170.0ms/batch - loss: 31.29689 - diff: 21.33mlTrain batch 12/16 - 170.2ms/batch - loss: 29.94741 - diff: 20.96mlTrain batch 13/16 - 183.9ms/batch - loss: 29.92302 - diff: 20.88mlTrain batch 14/16 - 170.1ms/batch - loss: 29.02659 - diff: 20.71mlTrain batch 15/16 - 170.0ms/batch - loss: 33.21053 - diff: 21.53mlTrain batch 16/16 - 56.1ms/batch - loss: 35.65521 - diff: 21.70mlTrain batch 16/16 - 14.9s 56.1ms/batch - loss: 35.65521 - diff: 21.70ml
Test 1.0s: val_loss: 29.23316 - diff: 22.56ml

Epoch 127: current best loss = 25.13050, at epoch 124
Train batch 1/16 - 194.5ms/batch - loss: 29.83360 - diff: 23.20mlTrain batch 2/16 - 173.3ms/batch - loss: 27.91829 - diff: 22.90mlTrain batch 3/16 - 177.2ms/batch - loss: 25.80812 - diff: 21.96mlTrain batch 4/16 - 177.9ms/batch - loss: 25.84324 - diff: 21.89mlTrain batch 5/16 - 170.4ms/batch - loss: 27.80287 - diff: 22.80mlTrain batch 6/16 - 170.3ms/batch - loss: 25.12162 - diff: 21.47mlTrain batch 7/16 - 189.1ms/batch - loss: 24.82948 - diff: 21.18mlTrain batch 8/16 - 172.3ms/batch - loss: 24.68288 - diff: 20.92mlTrain batch 9/16 - 169.8ms/batch - loss: 23.17470 - diff: 20.22mlTrain batch 10/16 - 170.2ms/batch - loss: 23.75718 - diff: 20.45mlTrain batch 11/16 - 188.6ms/batch - loss: 24.79511 - diff: 20.65mlTrain batch 12/16 - 186.2ms/batch - loss: 31.68078 - diff: 20.92mlTrain batch 13/16 - 170.0ms/batch - loss: 31.04067 - diff: 20.87mlTrain batch 14/16 - 174.5ms/batch - loss: 31.40675 - diff: 20.90mlTrain batch 15/16 - 188.8ms/batch - loss: 35.62186 - diff: 21.82mlTrain batch 16/16 - 57.8ms/batch - loss: 37.82110 - diff: 21.89mlTrain batch 16/16 - 16.9s 57.8ms/batch - loss: 37.82110 - diff: 21.89ml
Test 1.1s: val_loss: 24.83481 - diff: 19.18ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Systole_VGG19_Adam-0.001_MSE_DA3_best

Epoch 128: current best loss = 24.83481, at epoch 127
Train batch 1/16 - 188.4ms/batch - loss: 23.71247 - diff: 20.85mlTrain batch 2/16 - 170.1ms/batch - loss: 24.23817 - diff: 20.31mlTrain batch 3/16 - 183.4ms/batch - loss: 23.80910 - diff: 21.39mlTrain batch 4/16 - 177.9ms/batch - loss: 40.36186 - diff: 23.27mlTrain batch 5/16 - 172.8ms/batch - loss: 49.61725 - diff: 24.06mlTrain batch 6/16 - 170.0ms/batch - loss: 47.11480 - diff: 23.98mlTrain batch 7/16 - 174.6ms/batch - loss: 44.07316 - diff: 23.53mlTrain batch 8/16 - 170.8ms/batch - loss: 42.06841 - diff: 23.33mlTrain batch 9/16 - 170.4ms/batch - loss: 39.89186 - diff: 22.98mlTrain batch 10/16 - 170.4ms/batch - loss: 40.50551 - diff: 23.15mlTrain batch 11/16 - 172.0ms/batch - loss: 39.12023 - diff: 22.80mlTrain batch 12/16 - 170.5ms/batch - loss: 38.01014 - diff: 22.73mlTrain batch 13/16 - 186.6ms/batch - loss: 36.64869 - diff: 22.56mlTrain batch 14/16 - 176.0ms/batch - loss: 35.67890 - diff: 22.25mlTrain batch 15/16 - 170.1ms/batch - loss: 33.96869 - diff: 21.69mlTrain batch 16/16 - 56.1ms/batch - loss: 36.02625 - diff: 21.71mlTrain batch 16/16 - 15.7s 56.1ms/batch - loss: 36.02625 - diff: 21.71ml
Test 1.0s: val_loss: 24.45377 - diff: 18.56ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Systole_VGG19_Adam-0.001_MSE_DA3_best

Epoch 129: current best loss = 24.45377, at epoch 128
Train batch 1/16 - 193.9ms/batch - loss: 43.92448 - diff: 26.05mlTrain batch 2/16 - 169.9ms/batch - loss: 33.25458 - diff: 23.87mlTrain batch 3/16 - 170.1ms/batch - loss: 30.01778 - diff: 23.07mlTrain batch 4/16 - 170.0ms/batch - loss: 40.53257 - diff: 23.91mlTrain batch 5/16 - 170.1ms/batch - loss: 36.12086 - diff: 23.10mlTrain batch 6/16 - 177.7ms/batch - loss: 51.77678 - diff: 24.77mlTrain batch 7/16 - 184.1ms/batch - loss: 45.96675 - diff: 23.27mlTrain batch 8/16 - 170.0ms/batch - loss: 41.83556 - diff: 22.21mlTrain batch 9/16 - 193.3ms/batch - loss: 40.97251 - diff: 22.33mlTrain batch 10/16 - 170.2ms/batch - loss: 39.20003 - diff: 22.13mlTrain batch 11/16 - 170.2ms/batch - loss: 38.88483 - diff: 22.45mlTrain batch 12/16 - 170.1ms/batch - loss: 37.64523 - diff: 22.24mlTrain batch 13/16 - 170.1ms/batch - loss: 35.94480 - diff: 22.03mlTrain batch 14/16 - 175.8ms/batch - loss: 35.39636 - diff: 21.96mlTrain batch 15/16 - 170.2ms/batch - loss: 34.48247 - diff: 21.86mlTrain batch 16/16 - 56.1ms/batch - loss: 35.21640 - diff: 21.85mlTrain batch 16/16 - 16.2s 56.1ms/batch - loss: 35.21640 - diff: 21.85ml
Test 0.9s: val_loss: 27.67033 - diff: 19.10ml

Epoch 130: current best loss = 24.45377, at epoch 128
Train batch 1/16 - 188.6ms/batch - loss: 12.77284 - diff: 14.92mlTrain batch 2/16 - 177.6ms/batch - loss: 21.23115 - diff: 17.39mlTrain batch 3/16 - 170.1ms/batch - loss: 21.72991 - diff: 18.11mlTrain batch 4/16 - 169.6ms/batch - loss: 19.83568 - diff: 18.12mlTrain batch 5/16 - 186.1ms/batch - loss: 22.05500 - diff: 18.47mlTrain batch 6/16 - 169.5ms/batch - loss: 22.41897 - diff: 18.80mlTrain batch 7/16 - 170.2ms/batch - loss: 22.95343 - diff: 19.19mlTrain batch 8/16 - 169.4ms/batch - loss: 23.74797 - diff: 19.41mlTrain batch 9/16 - 170.1ms/batch - loss: 23.19895 - diff: 19.45mlTrain batch 10/16 - 170.3ms/batch - loss: 23.90550 - diff: 19.87mlTrain batch 11/16 - 179.9ms/batch - loss: 23.44294 - diff: 19.70mlTrain batch 12/16 - 170.0ms/batch - loss: 35.08587 - diff: 21.31mlTrain batch 13/16 - 186.0ms/batch - loss: 34.00110 - diff: 21.30mlTrain batch 14/16 - 169.4ms/batch - loss: 33.79242 - diff: 21.47mlTrain batch 15/16 - 182.3ms/batch - loss: 32.49541 - diff: 21.22mlTrain batch 16/16 - 67.4ms/batch - loss: 34.71014 - diff: 21.34mlTrain batch 16/16 - 17.0s 67.4ms/batch - loss: 34.71014 - diff: 21.34ml
Test 1.1s: val_loss: 28.08219 - diff: 20.46ml

Epoch 131: current best loss = 24.45377, at epoch 128
Train batch 1/16 - 188.4ms/batch - loss: 21.47874 - diff: 18.15mlTrain batch 2/16 - 175.8ms/batch - loss: 16.47440 - diff: 16.68mlTrain batch 3/16 - 179.7ms/batch - loss: 21.84930 - diff: 18.07mlTrain batch 4/16 - 175.8ms/batch - loss: 21.31107 - diff: 18.58mlTrain batch 5/16 - 170.1ms/batch - loss: 22.93193 - diff: 19.30mlTrain batch 6/16 - 177.7ms/batch - loss: 24.10792 - diff: 19.78mlTrain batch 7/16 - 171.4ms/batch - loss: 21.96950 - diff: 18.91mlTrain batch 8/16 - 182.0ms/batch - loss: 21.85721 - diff: 18.80mlTrain batch 9/16 - 181.1ms/batch - loss: 21.98087 - diff: 19.20mlTrain batch 10/16 - 170.0ms/batch - loss: 21.76351 - diff: 19.25mlTrain batch 11/16 - 170.1ms/batch - loss: 21.57472 - diff: 19.11mlTrain batch 12/16 - 183.5ms/batch - loss: 26.98334 - diff: 19.81mlTrain batch 13/16 - 183.5ms/batch - loss: 26.87115 - diff: 19.75mlTrain batch 14/16 - 170.0ms/batch - loss: 30.45627 - diff: 20.20mlTrain batch 15/16 - 175.8ms/batch - loss: 30.25108 - diff: 20.44mlTrain batch 16/16 - 59.9ms/batch - loss: 31.78081 - diff: 20.50mlTrain batch 16/16 - 16.4s 59.9ms/batch - loss: 31.78081 - diff: 20.50ml
Test 1.0s: val_loss: 27.25523 - diff: 20.74ml

Epoch 132: current best loss = 24.45377, at epoch 128
Train batch 1/16 - 188.5ms/batch - loss: 13.06691 - diff: 17.28mlTrain batch 2/16 - 170.2ms/batch - loss: 18.14059 - diff: 18.61mlTrain batch 3/16 - 170.2ms/batch - loss: 24.29402 - diff: 20.53mlTrain batch 4/16 - 182.1ms/batch - loss: 24.36354 - diff: 21.09mlTrain batch 5/16 - 170.0ms/batch - loss: 28.38802 - diff: 22.51mlTrain batch 6/16 - 184.9ms/batch - loss: 32.60211 - diff: 23.03mlTrain batch 7/16 - 180.9ms/batch - loss: 29.86093 - diff: 22.00mlTrain batch 8/16 - 183.2ms/batch - loss: 37.03148 - diff: 22.71mlTrain batch 9/16 - 180.5ms/batch - loss: 42.50200 - diff: 23.41mlTrain batch 10/16 - 170.1ms/batch - loss: 40.26479 - diff: 22.92mlTrain batch 11/16 - 170.2ms/batch - loss: 39.43022 - diff: 22.81mlTrain batch 12/16 - 170.5ms/batch - loss: 37.09989 - diff: 22.04mlTrain batch 13/16 - 170.1ms/batch - loss: 35.23424 - diff: 21.71mlTrain batch 14/16 - 178.9ms/batch - loss: 33.54884 - diff: 21.36mlTrain batch 15/16 - 170.1ms/batch - loss: 32.60280 - diff: 21.12mlTrain batch 16/16 - 57.0ms/batch - loss: 32.27555 - diff: 20.92mlTrain batch 16/16 - 14.4s 57.0ms/batch - loss: 32.27555 - diff: 20.92ml
Test 1.0s: val_loss: 27.00521 - diff: 20.04ml

Epoch 133: current best loss = 24.45377, at epoch 128
Train batch 1/16 - 196.3ms/batch - loss: 23.15017 - diff: 16.10mlTrain batch 2/16 - 175.1ms/batch - loss: 20.44838 - diff: 17.19mlTrain batch 3/16 - 177.0ms/batch - loss: 19.18923 - diff: 17.14mlTrain batch 4/16 - 170.4ms/batch - loss: 20.39282 - diff: 18.29mlTrain batch 5/16 - 192.9ms/batch - loss: 19.37049 - diff: 18.27mlTrain batch 6/16 - 170.2ms/batch - loss: 19.93863 - diff: 18.57mlTrain batch 7/16 - 170.0ms/batch - loss: 19.68065 - diff: 18.53mlTrain batch 8/16 - 169.3ms/batch - loss: 19.54922 - diff: 18.58mlTrain batch 9/16 - 186.6ms/batch - loss: 20.14286 - diff: 18.67mlTrain batch 10/16 - 174.5ms/batch - loss: 20.59153 - diff: 18.82mlTrain batch 11/16 - 197.2ms/batch - loss: 29.29184 - diff: 20.54mlTrain batch 12/16 - 170.9ms/batch - loss: 28.06921 - diff: 20.22mlTrain batch 13/16 - 177.6ms/batch - loss: 28.59525 - diff: 20.01mlTrain batch 14/16 - 175.9ms/batch - loss: 28.53046 - diff: 20.05mlTrain batch 15/16 - 176.9ms/batch - loss: 29.27608 - diff: 20.44mlTrain batch 16/16 - 56.1ms/batch - loss: 30.78485 - diff: 20.53mlTrain batch 16/16 - 17.3s 56.1ms/batch - loss: 30.78485 - diff: 20.53ml
Test 1.0s: val_loss: 27.18838 - diff: 19.46ml

Epoch 134: current best loss = 24.45377, at epoch 128
Train batch 1/16 - 188.7ms/batch - loss: 15.15992 - diff: 17.21mlTrain batch 2/16 - 170.1ms/batch - loss: 14.31361 - diff: 16.66mlTrain batch 3/16 - 170.2ms/batch - loss: 37.53864 - diff: 20.53mlTrain batch 4/16 - 169.4ms/batch - loss: 43.56985 - diff: 23.49mlTrain batch 5/16 - 173.1ms/batch - loss: 39.29780 - diff: 22.63mlTrain batch 6/16 - 170.2ms/batch - loss: 39.58958 - diff: 23.34mlTrain batch 7/16 - 170.0ms/batch - loss: 43.75151 - diff: 23.30mlTrain batch 8/16 - 170.3ms/batch - loss: 41.26766 - diff: 23.08mlTrain batch 9/16 - 170.1ms/batch - loss: 41.79125 - diff: 23.23mlTrain batch 10/16 - 172.1ms/batch - loss: 40.08663 - diff: 22.97mlTrain batch 11/16 - 170.1ms/batch - loss: 38.16268 - diff: 22.58mlTrain batch 12/16 - 170.4ms/batch - loss: 37.03156 - diff: 22.69mlTrain batch 13/16 - 184.1ms/batch - loss: 35.67870 - diff: 22.47mlTrain batch 14/16 - 176.3ms/batch - loss: 34.56110 - diff: 22.32mlTrain batch 15/16 - 170.2ms/batch - loss: 33.98988 - diff: 22.15mlTrain batch 16/16 - 56.2ms/batch - loss: 34.79751 - diff: 22.11mlTrain batch 16/16 - 16.8s 56.2ms/batch - loss: 34.79751 - diff: 22.11ml
Test 1.0s: val_loss: 24.79648 - diff: 18.73ml

Epoch 135: current best loss = 24.45377, at epoch 128
Train batch 1/16 - 188.7ms/batch - loss: 26.15836 - diff: 21.63mlTrain batch 2/16 - 170.1ms/batch - loss: 50.72059 - diff: 24.76mlTrain batch 3/16 - 169.9ms/batch - loss: 44.74056 - diff: 23.95mlTrain batch 4/16 - 175.0ms/batch - loss: 45.46950 - diff: 23.92mlTrain batch 5/16 - 200.2ms/batch - loss: 40.85701 - diff: 23.14mlTrain batch 6/16 - 170.0ms/batch - loss: 41.49305 - diff: 23.00mlTrain batch 7/16 - 211.1ms/batch - loss: 39.40147 - diff: 22.80mlTrain batch 8/16 - 170.3ms/batch - loss: 36.22873 - diff: 22.22mlTrain batch 9/16 - 182.0ms/batch - loss: 40.94668 - diff: 22.63mlTrain batch 10/16 - 170.5ms/batch - loss: 39.17181 - diff: 22.20mlTrain batch 11/16 - 169.8ms/batch - loss: 36.62187 - diff: 21.47mlTrain batch 12/16 - 169.5ms/batch - loss: 34.87030 - diff: 21.17mlTrain batch 13/16 - 169.9ms/batch - loss: 33.27972 - diff: 20.97mlTrain batch 14/16 - 170.0ms/batch - loss: 33.53172 - diff: 21.38mlTrain batch 15/16 - 170.0ms/batch - loss: 33.81882 - diff: 21.70mlTrain batch 16/16 - 56.2ms/batch - loss: 35.83119 - diff: 21.77mlTrain batch 16/16 - 16.0s 56.2ms/batch - loss: 35.83119 - diff: 21.77ml
Test 1.0s: val_loss: 34.76950 - diff: 19.69ml

Epoch 136: current best loss = 24.45377, at epoch 128
Train batch 1/16 - 188.4ms/batch - loss: 20.63226 - diff: 17.19mlTrain batch 2/16 - 170.1ms/batch - loss: 30.42295 - diff: 22.39mlTrain batch 3/16 - 170.0ms/batch - loss: 24.46308 - diff: 20.52mlTrain batch 4/16 - 170.1ms/batch - loss: 35.91742 - diff: 20.66mlTrain batch 5/16 - 176.7ms/batch - loss: 31.49401 - diff: 19.66mlTrain batch 6/16 - 170.2ms/batch - loss: 30.52126 - diff: 20.05mlTrain batch 7/16 - 170.5ms/batch - loss: 28.86781 - diff: 19.64mlTrain batch 8/16 - 184.1ms/batch - loss: 28.77190 - diff: 20.05mlTrain batch 9/16 - 170.0ms/batch - loss: 28.46223 - diff: 20.01mlTrain batch 10/16 - 176.8ms/batch - loss: 26.96167 - diff: 19.60mlTrain batch 11/16 - 186.8ms/batch - loss: 31.00616 - diff: 19.94mlTrain batch 12/16 - 170.2ms/batch - loss: 30.38989 - diff: 19.92mlTrain batch 13/16 - 188.7ms/batch - loss: 33.01379 - diff: 20.85mlTrain batch 14/16 - 168.7ms/batch - loss: 31.74769 - diff: 20.61mlTrain batch 15/16 - 171.8ms/batch - loss: 30.91794 - diff: 20.36mlTrain batch 16/16 - 57.6ms/batch - loss: 34.60837 - diff: 20.59mlTrain batch 16/16 - 16.7s 57.6ms/batch - loss: 34.60837 - diff: 20.59ml
Test 1.1s: val_loss: 25.51765 - diff: 19.95ml

Epoch 137: current best loss = 24.45377, at epoch 128
Train batch 1/16 - 180.8ms/batch - loss: 19.84022 - diff: 20.58mlTrain batch 2/16 - 170.3ms/batch - loss: 22.33380 - diff: 20.09mlTrain batch 3/16 - 173.5ms/batch - loss: 36.81850 - diff: 21.47mlTrain batch 4/16 - 170.3ms/batch - loss: 30.15035 - diff: 19.82mlTrain batch 5/16 - 170.0ms/batch - loss: 28.69730 - diff: 20.08mlTrain batch 6/16 - 170.2ms/batch - loss: 27.41579 - diff: 20.09mlTrain batch 7/16 - 184.2ms/batch - loss: 30.07521 - diff: 21.18mlTrain batch 8/16 - 179.4ms/batch - loss: 30.01658 - diff: 21.47mlTrain batch 9/16 - 170.0ms/batch - loss: 29.33907 - diff: 21.44mlTrain batch 10/16 - 171.5ms/batch - loss: 27.80231 - diff: 20.78mlTrain batch 11/16 - 186.6ms/batch - loss: 27.66682 - diff: 20.84mlTrain batch 12/16 - 179.8ms/batch - loss: 27.17409 - diff: 20.79mlTrain batch 13/16 - 177.8ms/batch - loss: 27.49642 - diff: 20.99mlTrain batch 14/16 - 180.8ms/batch - loss: 26.50356 - diff: 20.66mlTrain batch 15/16 - 171.2ms/batch - loss: 26.55828 - diff: 20.61mlTrain batch 16/16 - 56.0ms/batch - loss: 50.08392 - diff: 21.14mlTrain batch 16/16 - 16.5s 56.0ms/batch - loss: 50.08392 - diff: 21.14ml
Test 1.0s: val_loss: 26.43316 - diff: 19.34ml

Epoch 138: current best loss = 24.45377, at epoch 128
Train batch 1/16 - 185.2ms/batch - loss: 36.70516 - diff: 23.46mlTrain batch 2/16 - 170.2ms/batch - loss: 56.11537 - diff: 24.77mlTrain batch 3/16 - 170.0ms/batch - loss: 46.20523 - diff: 23.96mlTrain batch 4/16 - 170.1ms/batch - loss: 47.50396 - diff: 26.35mlTrain batch 5/16 - 171.9ms/batch - loss: 50.42353 - diff: 28.06mlTrain batch 6/16 - 170.1ms/batch - loss: 51.24436 - diff: 29.25mlTrain batch 7/16 - 173.6ms/batch - loss: 45.86927 - diff: 27.53mlTrain batch 8/16 - 170.2ms/batch - loss: 42.03806 - diff: 26.18mlTrain batch 9/16 - 170.0ms/batch - loss: 40.16552 - diff: 25.74mlTrain batch 10/16 - 174.0ms/batch - loss: 37.73037 - diff: 24.72mlTrain batch 11/16 - 170.0ms/batch - loss: 42.44307 - diff: 25.15mlTrain batch 12/16 - 180.9ms/batch - loss: 41.93139 - diff: 25.15mlTrain batch 13/16 - 180.2ms/batch - loss: 41.13144 - diff: 25.05mlTrain batch 14/16 - 178.3ms/batch - loss: 40.57526 - diff: 25.00mlTrain batch 15/16 - 170.1ms/batch - loss: 41.72341 - diff: 25.27mlTrain batch 16/16 - 56.3ms/batch - loss: 42.03692 - diff: 25.17mlTrain batch 16/16 - 16.6s 56.3ms/batch - loss: 42.03692 - diff: 25.17ml
Test 1.0s: val_loss: 29.53548 - diff: 19.47ml

Epoch 139: current best loss = 24.45377, at epoch 128
Train batch 1/16 - 187.7ms/batch - loss: 109.32406 - diff: 29.91mlTrain batch 2/16 - 170.4ms/batch - loss: 65.96962 - diff: 24.17mlTrain batch 3/16 - 175.1ms/batch - loss: 49.27870 - diff: 22.43mlTrain batch 4/16 - 174.1ms/batch - loss: 41.26334 - diff: 21.44mlTrain batch 5/16 - 173.5ms/batch - loss: 38.49176 - diff: 21.44mlTrain batch 6/16 - 170.1ms/batch - loss: 37.62600 - diff: 22.37mlTrain batch 7/16 - 170.0ms/batch - loss: 35.70597 - diff: 22.62mlTrain batch 8/16 - 171.4ms/batch - loss: 41.39667 - diff: 23.90mlTrain batch 9/16 - 170.0ms/batch - loss: 40.69615 - diff: 24.14mlTrain batch 10/16 - 175.2ms/batch - loss: 37.77036 - diff: 23.26mlTrain batch 11/16 - 182.6ms/batch - loss: 38.03754 - diff: 23.38mlTrain batch 12/16 - 173.9ms/batch - loss: 37.79370 - diff: 23.45mlTrain batch 13/16 - 170.1ms/batch - loss: 36.32955 - diff: 22.99mlTrain batch 14/16 - 173.8ms/batch - loss: 35.17519 - diff: 22.65mlTrain batch 15/16 - 186.2ms/batch - loss: 34.53804 - diff: 22.36mlTrain batch 16/16 - 63.0ms/batch - loss: 36.45271 - diff: 22.41mlTrain batch 16/16 - 15.9s 63.0ms/batch - loss: 36.45271 - diff: 22.41ml
Test 1.1s: val_loss: 26.54434 - diff: 18.57ml
Epoch   140: reducing learning rate of group 0 to 3.9063e-06.

Epoch 140: current best loss = 24.45377, at epoch 128
Train batch 1/16 - 194.5ms/batch - loss: 19.97799 - diff: 20.29mlTrain batch 2/16 - 169.9ms/batch - loss: 19.74571 - diff: 20.15mlTrain batch 3/16 - 189.0ms/batch - loss: 16.46367 - diff: 18.02mlTrain batch 4/16 - 171.3ms/batch - loss: 20.05807 - diff: 19.06mlTrain batch 5/16 - 169.9ms/batch - loss: 21.34264 - diff: 19.82mlTrain batch 6/16 - 169.9ms/batch - loss: 31.30958 - diff: 21.14mlTrain batch 7/16 - 174.7ms/batch - loss: 29.44353 - diff: 20.93mlTrain batch 8/16 - 170.0ms/batch - loss: 28.00125 - diff: 20.46mlTrain batch 9/16 - 172.0ms/batch - loss: 28.44368 - diff: 20.67mlTrain batch 10/16 - 170.1ms/batch - loss: 28.29752 - diff: 20.74mlTrain batch 11/16 - 171.5ms/batch - loss: 28.33015 - diff: 20.87mlTrain batch 12/16 - 170.0ms/batch - loss: 27.20676 - diff: 20.64mlTrain batch 13/16 - 170.0ms/batch - loss: 28.51389 - diff: 21.32mlTrain batch 14/16 - 170.3ms/batch - loss: 32.91855 - diff: 21.61mlTrain batch 15/16 - 170.1ms/batch - loss: 32.99486 - diff: 21.51mlTrain batch 16/16 - 56.3ms/batch - loss: 33.57089 - diff: 21.45mlTrain batch 16/16 - 18.0s 56.3ms/batch - loss: 33.57089 - diff: 21.45ml
Test 0.9s: val_loss: 29.07680 - diff: 20.67ml

Epoch 141: current best loss = 24.45377, at epoch 128
Train batch 1/16 - 187.4ms/batch - loss: 23.28683 - diff: 23.22mlTrain batch 2/16 - 173.0ms/batch - loss: 34.26324 - diff: 24.76mlTrain batch 3/16 - 170.7ms/batch - loss: 52.37398 - diff: 27.12mlTrain batch 4/16 - 170.0ms/batch - loss: 45.21711 - diff: 25.99mlTrain batch 5/16 - 170.1ms/batch - loss: 41.74375 - diff: 25.31mlTrain batch 6/16 - 170.1ms/batch - loss: 37.92626 - diff: 24.35mlTrain batch 7/16 - 170.2ms/batch - loss: 34.48215 - diff: 23.35mlTrain batch 8/16 - 170.1ms/batch - loss: 35.24474 - diff: 23.47mlTrain batch 9/16 - 170.0ms/batch - loss: 33.75597 - diff: 22.96mlTrain batch 10/16 - 170.1ms/batch - loss: 32.03386 - diff: 22.47mlTrain batch 11/16 - 180.4ms/batch - loss: 35.94821 - diff: 22.90mlTrain batch 12/16 - 170.1ms/batch - loss: 34.60729 - diff: 22.63mlTrain batch 13/16 - 170.3ms/batch - loss: 34.09238 - diff: 22.41mlTrain batch 14/16 - 179.2ms/batch - loss: 32.92101 - diff: 22.09mlTrain batch 15/16 - 170.2ms/batch - loss: 32.46770 - diff: 21.98mlTrain batch 16/16 - 75.9ms/batch - loss: 32.48412 - diff: 21.87mlTrain batch 16/16 - 14.6s 75.9ms/batch - loss: 32.48412 - diff: 21.87ml
Test 1.0s: val_loss: 27.08269 - diff: 18.56ml

Epoch 142: current best loss = 24.45377, at epoch 128
Train batch 1/16 - 188.6ms/batch - loss: 28.62905 - diff: 22.37mlTrain batch 2/16 - 170.1ms/batch - loss: 33.12823 - diff: 23.56mlTrain batch 3/16 - 175.0ms/batch - loss: 34.80098 - diff: 23.96mlTrain batch 4/16 - 170.4ms/batch - loss: 31.89922 - diff: 22.57mlTrain batch 5/16 - 180.2ms/batch - loss: 31.81842 - diff: 22.94mlTrain batch 6/16 - 188.6ms/batch - loss: 33.49475 - diff: 23.16mlTrain batch 7/16 - 170.7ms/batch - loss: 32.65487 - diff: 23.02mlTrain batch 8/16 - 170.2ms/batch - loss: 30.78811 - diff: 22.30mlTrain batch 9/16 - 170.0ms/batch - loss: 28.70444 - diff: 21.46mlTrain batch 10/16 - 170.1ms/batch - loss: 27.87663 - diff: 21.32mlTrain batch 11/16 - 192.5ms/batch - loss: 26.50222 - diff: 20.90mlTrain batch 12/16 - 170.4ms/batch - loss: 26.00681 - diff: 20.86mlTrain batch 13/16 - 186.5ms/batch - loss: 30.61203 - diff: 21.32mlTrain batch 14/16 - 170.1ms/batch - loss: 33.06028 - diff: 21.49mlTrain batch 15/16 - 172.9ms/batch - loss: 32.02342 - diff: 21.23mlTrain batch 16/16 - 58.1ms/batch - loss: 33.57434 - diff: 21.31mlTrain batch 16/16 - 16.7s 58.1ms/batch - loss: 33.57434 - diff: 21.31ml
Test 0.9s: val_loss: 26.35057 - diff: 20.02ml

Epoch 143: current best loss = 24.45377, at epoch 128
Train batch 1/16 - 188.5ms/batch - loss: 23.15020 - diff: 20.29mlTrain batch 2/16 - 170.4ms/batch - loss: 20.17447 - diff: 20.20mlTrain batch 3/16 - 174.7ms/batch - loss: 19.29075 - diff: 19.11mlTrain batch 4/16 - 169.4ms/batch - loss: 18.28113 - diff: 18.90mlTrain batch 5/16 - 187.5ms/batch - loss: 20.75135 - diff: 19.34mlTrain batch 6/16 - 172.6ms/batch - loss: 20.82213 - diff: 19.10mlTrain batch 7/16 - 180.3ms/batch - loss: 28.65252 - diff: 20.48mlTrain batch 8/16 - 170.0ms/batch - loss: 28.65887 - diff: 20.76mlTrain batch 9/16 - 170.2ms/batch - loss: 28.51540 - diff: 21.16mlTrain batch 10/16 - 172.7ms/batch - loss: 27.48510 - diff: 20.75mlTrain batch 11/16 - 181.8ms/batch - loss: 30.31625 - diff: 21.61mlTrain batch 12/16 - 169.2ms/batch - loss: 29.27915 - diff: 21.27mlTrain batch 13/16 - 170.0ms/batch - loss: 28.34718 - diff: 21.17mlTrain batch 14/16 - 170.1ms/batch - loss: 27.21575 - diff: 20.78mlTrain batch 15/16 - 170.0ms/batch - loss: 31.03658 - diff: 21.27mlTrain batch 16/16 - 58.6ms/batch - loss: 32.42771 - diff: 21.35mlTrain batch 16/16 - 15.4s 58.6ms/batch - loss: 32.42771 - diff: 21.35ml
Test 1.0s: val_loss: 25.78413 - diff: 19.14ml

Epoch 144: current best loss = 24.45377, at epoch 128
Train batch 1/16 - 197.0ms/batch - loss: 23.41471 - diff: 17.26mlTrain batch 2/16 - 171.3ms/batch - loss: 20.12948 - diff: 17.71mlTrain batch 3/16 - 182.0ms/batch - loss: 25.32506 - diff: 19.06mlTrain batch 4/16 - 170.2ms/batch - loss: 29.21312 - diff: 20.31mlTrain batch 5/16 - 170.0ms/batch - loss: 26.62777 - diff: 19.50mlTrain batch 6/16 - 170.0ms/batch - loss: 23.22378 - diff: 18.17mlTrain batch 7/16 - 172.8ms/batch - loss: 24.10811 - diff: 18.90mlTrain batch 8/16 - 170.1ms/batch - loss: 23.99145 - diff: 18.77mlTrain batch 9/16 - 188.8ms/batch - loss: 24.33153 - diff: 19.07mlTrain batch 10/16 - 179.5ms/batch - loss: 26.62242 - diff: 19.79mlTrain batch 11/16 - 187.6ms/batch - loss: 25.89383 - diff: 19.69mlTrain batch 12/16 - 172.6ms/batch - loss: 25.39983 - diff: 19.71mlTrain batch 13/16 - 170.1ms/batch - loss: 28.63237 - diff: 20.23mlTrain batch 14/16 - 170.4ms/batch - loss: 28.51657 - diff: 20.28mlTrain batch 15/16 - 170.4ms/batch - loss: 30.70630 - diff: 20.46mlTrain batch 16/16 - 63.9ms/batch - loss: 32.09886 - diff: 20.50mlTrain batch 16/16 - 16.9s 63.9ms/batch - loss: 32.09886 - diff: 20.50ml
Test 1.0s: val_loss: 26.91977 - diff: 20.30ml

Epoch 145: current best loss = 24.45377, at epoch 128
Train batch 1/16 - 188.8ms/batch - loss: 38.79500 - diff: 27.81mlTrain batch 2/16 - 173.9ms/batch - loss: 51.54075 - diff: 24.74mlTrain batch 3/16 - 187.0ms/batch - loss: 57.69320 - diff: 25.51mlTrain batch 4/16 - 172.2ms/batch - loss: 52.94827 - diff: 25.36mlTrain batch 5/16 - 170.0ms/batch - loss: 47.81157 - diff: 24.68mlTrain batch 6/16 - 170.2ms/batch - loss: 43.02979 - diff: 23.82mlTrain batch 7/16 - 173.2ms/batch - loss: 41.57817 - diff: 23.87mlTrain batch 8/16 - 192.1ms/batch - loss: 37.78496 - diff: 22.63mlTrain batch 9/16 - 171.1ms/batch - loss: 36.87451 - diff: 22.56mlTrain batch 10/16 - 170.0ms/batch - loss: 36.85166 - diff: 22.62mlTrain batch 11/16 - 169.9ms/batch - loss: 35.27567 - diff: 22.34mlTrain batch 12/16 - 170.1ms/batch - loss: 33.50466 - diff: 21.94mlTrain batch 13/16 - 201.0ms/batch - loss: 32.47463 - diff: 21.65mlTrain batch 14/16 - 170.1ms/batch - loss: 31.67895 - diff: 21.54mlTrain batch 15/16 - 172.5ms/batch - loss: 31.33809 - diff: 21.34mlTrain batch 16/16 - 56.2ms/batch - loss: 32.19977 - diff: 21.34mlTrain batch 16/16 - 16.8s 56.2ms/batch - loss: 32.19977 - diff: 21.34ml
Test 1.0s: val_loss: 26.98809 - diff: 18.63ml

Epoch 146: current best loss = 24.45377, at epoch 128
Train batch 1/16 - 186.7ms/batch - loss: 66.29970 - diff: 25.04mlTrain batch 2/16 - 177.7ms/batch - loss: 43.33953 - diff: 20.98mlTrain batch 3/16 - 188.3ms/batch - loss: 38.89381 - diff: 20.63mlTrain batch 4/16 - 170.2ms/batch - loss: 36.40885 - diff: 21.23mlTrain batch 5/16 - 170.2ms/batch - loss: 36.92219 - diff: 22.14mlTrain batch 6/16 - 170.2ms/batch - loss: 42.94822 - diff: 23.16mlTrain batch 7/16 - 202.4ms/batch - loss: 40.49047 - diff: 22.79mlTrain batch 8/16 - 170.1ms/batch - loss: 38.10090 - diff: 22.37mlTrain batch 9/16 - 173.6ms/batch - loss: 37.31841 - diff: 22.07mlTrain batch 10/16 - 169.0ms/batch - loss: 36.22137 - diff: 21.62mlTrain batch 11/16 - 170.5ms/batch - loss: 33.97369 - diff: 21.04mlTrain batch 12/16 - 169.8ms/batch - loss: 33.27220 - diff: 21.20mlTrain batch 13/16 - 197.6ms/batch - loss: 32.34406 - diff: 21.22mlTrain batch 14/16 - 170.3ms/batch - loss: 30.94504 - diff: 20.87mlTrain batch 15/16 - 170.1ms/batch - loss: 30.21315 - diff: 20.77mlTrain batch 16/16 - 56.1ms/batch - loss: 32.69881 - diff: 20.85mlTrain batch 16/16 - 16.3s 56.1ms/batch - loss: 32.69881 - diff: 20.85ml
Test 1.0s: val_loss: 24.56119 - diff: 19.28ml

Epoch 147: current best loss = 24.45377, at epoch 128
Train batch 1/16 - 188.7ms/batch - loss: 42.43826 - diff: 25.41mlTrain batch 2/16 - 174.6ms/batch - loss: 38.62293 - diff: 24.17mlTrain batch 3/16 - 169.7ms/batch - loss: 35.59572 - diff: 23.47mlTrain batch 4/16 - 169.3ms/batch - loss: 31.66822 - diff: 22.82mlTrain batch 5/16 - 170.1ms/batch - loss: 31.90380 - diff: 22.85mlTrain batch 6/16 - 170.4ms/batch - loss: 29.50291 - diff: 22.25mlTrain batch 7/16 - 181.3ms/batch - loss: 26.39774 - diff: 20.91mlTrain batch 8/16 - 170.2ms/batch - loss: 26.03254 - diff: 20.35mlTrain batch 9/16 - 170.3ms/batch - loss: 24.95003 - diff: 20.05mlTrain batch 10/16 - 180.8ms/batch - loss: 30.30118 - diff: 20.63mlTrain batch 11/16 - 170.3ms/batch - loss: 29.07826 - diff: 20.43mlTrain batch 12/16 - 170.2ms/batch - loss: 32.16627 - diff: 20.70mlTrain batch 13/16 - 170.2ms/batch - loss: 30.78969 - diff: 20.40mlTrain batch 14/16 - 170.2ms/batch - loss: 30.17958 - diff: 20.36mlTrain batch 15/16 - 170.1ms/batch - loss: 30.27756 - diff: 20.48mlTrain batch 16/16 - 63.8ms/batch - loss: 31.93271 - diff: 20.56mlTrain batch 16/16 - 15.8s 63.8ms/batch - loss: 31.93271 - diff: 20.56ml
Test 1.1s: val_loss: 26.01714 - diff: 18.94ml

Epoch 148: current best loss = 24.45377, at epoch 128
Train batch 1/16 - 185.9ms/batch - loss: 12.64766 - diff: 16.33mlTrain batch 2/16 - 169.1ms/batch - loss: 21.64484 - diff: 19.68mlTrain batch 3/16 - 199.4ms/batch - loss: 20.14545 - diff: 18.84mlTrain batch 4/16 - 170.3ms/batch - loss: 23.19506 - diff: 19.76mlTrain batch 5/16 - 169.8ms/batch - loss: 21.50942 - diff: 19.35mlTrain batch 6/16 - 170.3ms/batch - loss: 30.42663 - diff: 20.45mlTrain batch 7/16 - 170.0ms/batch - loss: 29.59736 - diff: 20.55mlTrain batch 8/16 - 170.2ms/batch - loss: 36.11978 - diff: 21.84mlTrain batch 9/16 - 170.0ms/batch - loss: 34.96147 - diff: 21.92mlTrain batch 10/16 - 171.6ms/batch - loss: 33.20561 - diff: 21.40mlTrain batch 11/16 - 200.4ms/batch - loss: 32.67630 - diff: 21.49mlTrain batch 12/16 - 170.0ms/batch - loss: 31.35830 - diff: 21.25mlTrain batch 13/16 - 170.0ms/batch - loss: 31.10295 - diff: 21.38mlTrain batch 14/16 - 170.3ms/batch - loss: 30.13237 - diff: 21.11mlTrain batch 15/16 - 170.1ms/batch - loss: 30.75763 - diff: 21.27mlTrain batch 16/16 - 56.2ms/batch - loss: 34.21926 - diff: 21.37mlTrain batch 16/16 - 16.2s 56.2ms/batch - loss: 34.21926 - diff: 21.37ml
Test 0.9s: val_loss: 24.59386 - diff: 19.53ml

Epoch 149: current best loss = 24.45377, at epoch 128
Train batch 1/16 - 187.8ms/batch - loss: 30.08423 - diff: 21.46mlTrain batch 2/16 - 174.1ms/batch - loss: 34.82994 - diff: 20.80mlTrain batch 3/16 - 170.0ms/batch - loss: 33.33499 - diff: 21.70mlTrain batch 4/16 - 170.1ms/batch - loss: 33.35199 - diff: 20.97mlTrain batch 5/16 - 188.7ms/batch - loss: 40.70767 - diff: 21.41mlTrain batch 6/16 - 169.7ms/batch - loss: 37.29703 - diff: 21.17mlTrain batch 7/16 - 193.8ms/batch - loss: 37.82954 - diff: 21.81mlTrain batch 8/16 - 170.4ms/batch - loss: 35.19528 - diff: 21.28mlTrain batch 9/16 - 169.9ms/batch - loss: 38.59123 - diff: 21.77mlTrain batch 10/16 - 175.8ms/batch - loss: 37.25788 - diff: 21.60mlTrain batch 11/16 - 189.1ms/batch - loss: 37.08890 - diff: 21.70mlTrain batch 12/16 - 172.9ms/batch - loss: 35.44950 - diff: 21.38mlTrain batch 13/16 - 170.1ms/batch - loss: 34.57720 - diff: 21.41mlTrain batch 14/16 - 172.6ms/batch - loss: 34.74036 - diff: 21.54mlTrain batch 15/16 - 198.3ms/batch - loss: 33.67900 - diff: 21.36mlTrain batch 16/16 - 63.3ms/batch - loss: 33.46137 - diff: 21.18mlTrain batch 16/16 - 17.4s 63.3ms/batch - loss: 33.46137 - diff: 21.18ml
Test 1.0s: val_loss: 29.80974 - diff: 18.72ml

