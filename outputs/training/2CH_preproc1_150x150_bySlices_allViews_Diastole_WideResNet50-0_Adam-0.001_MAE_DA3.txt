nohup: ignoring input
Running experiment 2CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_WideResNet50_0_Adam-0.001_MAE_DA3
Going to train with the GPU in the slot 0 -> device model: GeForce RTX 2080
Model architecture:
 WideResNet50_0(
  (first_conv): Conv2d(30, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (pretrained_block): Sequential(
    (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): ReLU(inplace=True)
    (2): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (3): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (4): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (5): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (4): Bottleneck(
        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (5): Bottleneck(
        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
  )
  (reduction_block): Sequential(
    (0): AdaptiveAvgPool2d(output_size=(1, 1))
    (1): Flatten()
  )
  (dense_block): Sequential(
    (0): Linear(in_features=1024, out_features=512, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.4, inplace=False)
    (3): Linear(in_features=512, out_features=1, bias=True)
  )
) 


############################
# TRAIN PHASE:  150 epochs #
############################

Epoch 0: 
Train batch 1/32 - 212.1ms/batch - loss: 10.75655 - diff: 172.10mlTrain batch 2/32 - 177.2ms/batch - loss: 10.10937 - diff: 161.75mlTrain batch 3/32 - 172.8ms/batch - loss: 9.75370 - diff: 156.06mlTrain batch 4/32 - 170.5ms/batch - loss: 10.11220 - diff: 161.80mlTrain batch 5/32 - 170.5ms/batch - loss: 10.00388 - diff: 160.06mlTrain batch 6/32 - 170.4ms/batch - loss: 9.98844 - diff: 159.81mlTrain batch 7/32 - 172.7ms/batch - loss: 10.14656 - diff: 162.35mlTrain batch 8/32 - 170.9ms/batch - loss: 9.99821 - diff: 159.97mlTrain batch 9/32 - 178.0ms/batch - loss: 10.10832 - diff: 161.73mlTrain batch 10/32 - 170.9ms/batch - loss: 10.08125 - diff: 161.30mlTrain batch 11/32 - 182.0ms/batch - loss: 10.07815 - diff: 161.25mlTrain batch 12/32 - 170.5ms/batch - loss: 10.21490 - diff: 163.44mlTrain batch 13/32 - 171.5ms/batch - loss: 10.31757 - diff: 165.08mlTrain batch 14/32 - 170.4ms/batch - loss: 10.24491 - diff: 163.92mlTrain batch 15/32 - 170.7ms/batch - loss: 10.23882 - diff: 163.82mlTrain batch 16/32 - 170.9ms/batch - loss: 10.21766 - diff: 163.48mlTrain batch 17/32 - 177.1ms/batch - loss: 10.17873 - diff: 162.86mlTrain batch 18/32 - 171.1ms/batch - loss: 10.18410 - diff: 162.95mlTrain batch 19/32 - 174.7ms/batch - loss: 10.14989 - diff: 162.40mlTrain batch 20/32 - 171.1ms/batch - loss: 10.16566 - diff: 162.65mlTrain batch 21/32 - 187.3ms/batch - loss: 10.21003 - diff: 163.36mlTrain batch 22/32 - 171.3ms/batch - loss: 10.19165 - diff: 163.07mlTrain batch 23/32 - 170.9ms/batch - loss: 10.16449 - diff: 162.63mlTrain batch 24/32 - 171.0ms/batch - loss: 10.13800 - diff: 162.21mlTrain batch 25/32 - 171.1ms/batch - loss: 10.01872 - diff: 160.30mlTrain batch 26/32 - 171.1ms/batch - loss: 10.02201 - diff: 160.35mlTrain batch 27/32 - 171.1ms/batch - loss: 10.03407 - diff: 160.55mlTrain batch 28/32 - 171.3ms/batch - loss: 10.06318 - diff: 161.01mlTrain batch 29/32 - 171.1ms/batch - loss: 10.02094 - diff: 160.33mlTrain batch 30/32 - 171.0ms/batch - loss: 9.96348 - diff: 159.42mlTrain batch 31/32 - 181.1ms/batch - loss: 9.95552 - diff: 159.29mlTrain batch 32/32 - 52.1ms/batch - loss: 10.15153 - diff: 159.12mlTrain batch 32/32 - 17.0s 52.1ms/batch - loss: 10.15153 - diff: 159.12ml
Test 1.4s: val_loss: 9.06551 - diff: 139.51ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_WideResNet50_0_Adam-0.001_MAE_DA3_best

Epoch 1: current best loss = 9.06551, at epoch 0
Train batch 1/32 - 171.1ms/batch - loss: 9.18441 - diff: 146.95mlTrain batch 2/32 - 171.4ms/batch - loss: 9.24579 - diff: 147.93mlTrain batch 3/32 - 171.2ms/batch - loss: 8.89103 - diff: 142.26mlTrain batch 4/32 - 174.5ms/batch - loss: 8.99981 - diff: 144.00mlTrain batch 5/32 - 171.3ms/batch - loss: 9.03287 - diff: 144.53mlTrain batch 6/32 - 171.6ms/batch - loss: 8.92444 - diff: 142.79mlTrain batch 7/32 - 171.4ms/batch - loss: 9.02631 - diff: 144.42mlTrain batch 8/32 - 172.9ms/batch - loss: 9.00177 - diff: 144.03mlTrain batch 9/32 - 171.2ms/batch - loss: 8.93339 - diff: 142.93mlTrain batch 10/32 - 172.7ms/batch - loss: 8.96815 - diff: 143.49mlTrain batch 11/32 - 171.3ms/batch - loss: 8.97926 - diff: 143.67mlTrain batch 12/32 - 197.0ms/batch - loss: 9.17168 - diff: 146.75mlTrain batch 13/32 - 171.2ms/batch - loss: 9.15512 - diff: 146.48mlTrain batch 14/32 - 194.9ms/batch - loss: 8.90427 - diff: 142.47mlTrain batch 15/32 - 178.2ms/batch - loss: 8.81211 - diff: 140.99mlTrain batch 16/32 - 171.5ms/batch - loss: 8.76307 - diff: 140.21mlTrain batch 17/32 - 187.4ms/batch - loss: 8.66026 - diff: 138.56mlTrain batch 18/32 - 186.2ms/batch - loss: 8.51982 - diff: 136.32mlTrain batch 19/32 - 176.1ms/batch - loss: 8.50622 - diff: 136.10mlTrain batch 20/32 - 186.0ms/batch - loss: 8.44744 - diff: 135.16mlTrain batch 21/32 - 171.4ms/batch - loss: 8.37177 - diff: 133.95mlTrain batch 22/32 - 173.5ms/batch - loss: 8.28217 - diff: 132.51mlTrain batch 23/32 - 181.3ms/batch - loss: 8.22101 - diff: 131.54mlTrain batch 24/32 - 186.0ms/batch - loss: 8.09799 - diff: 129.57mlTrain batch 25/32 - 172.1ms/batch - loss: 8.03572 - diff: 128.57mlTrain batch 26/32 - 171.4ms/batch - loss: 7.99330 - diff: 127.89mlTrain batch 27/32 - 172.1ms/batch - loss: 7.96165 - diff: 127.39mlTrain batch 28/32 - 171.5ms/batch - loss: 7.87544 - diff: 126.01mlTrain batch 29/32 - 171.2ms/batch - loss: 7.85186 - diff: 125.63mlTrain batch 30/32 - 171.7ms/batch - loss: 7.75435 - diff: 124.07mlTrain batch 31/32 - 171.5ms/batch - loss: 7.69499 - diff: 123.12mlTrain batch 32/32 - 52.4ms/batch - loss: 7.82199 - diff: 122.89mlTrain batch 32/32 - 17.9s 52.4ms/batch - loss: 7.82199 - diff: 122.89ml
Test 1.5s: val_loss: 5.44151 - diff: 83.90ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_WideResNet50_0_Adam-0.001_MAE_DA3_best

Epoch 2: current best loss = 5.44151, at epoch 1
Train batch 1/32 - 181.2ms/batch - loss: 5.41789 - diff: 86.69mlTrain batch 2/32 - 171.6ms/batch - loss: 5.63560 - diff: 90.17mlTrain batch 3/32 - 171.5ms/batch - loss: 5.28602 - diff: 84.58mlTrain batch 4/32 - 171.1ms/batch - loss: 5.11227 - diff: 81.80mlTrain batch 5/32 - 171.8ms/batch - loss: 5.37166 - diff: 85.95mlTrain batch 6/32 - 171.5ms/batch - loss: 5.07271 - diff: 81.16mlTrain batch 7/32 - 173.3ms/batch - loss: 4.80230 - diff: 76.84mlTrain batch 8/32 - 171.9ms/batch - loss: 4.79562 - diff: 76.73mlTrain batch 9/32 - 171.3ms/batch - loss: 4.77588 - diff: 76.41mlTrain batch 10/32 - 177.5ms/batch - loss: 4.80986 - diff: 76.96mlTrain batch 11/32 - 171.4ms/batch - loss: 4.72388 - diff: 75.58mlTrain batch 12/32 - 171.8ms/batch - loss: 4.57527 - diff: 73.20mlTrain batch 13/32 - 186.0ms/batch - loss: 4.52173 - diff: 72.35mlTrain batch 14/32 - 171.5ms/batch - loss: 4.38968 - diff: 70.23mlTrain batch 15/32 - 171.9ms/batch - loss: 4.33681 - diff: 69.39mlTrain batch 16/32 - 180.0ms/batch - loss: 4.30894 - diff: 68.94mlTrain batch 17/32 - 171.6ms/batch - loss: 4.30554 - diff: 68.89mlTrain batch 18/32 - 174.3ms/batch - loss: 4.20994 - diff: 67.36mlTrain batch 19/32 - 171.6ms/batch - loss: 4.20284 - diff: 67.25mlTrain batch 20/32 - 175.9ms/batch - loss: 4.13680 - diff: 66.19mlTrain batch 21/32 - 171.6ms/batch - loss: 4.05484 - diff: 64.88mlTrain batch 22/32 - 171.8ms/batch - loss: 4.00555 - diff: 64.09mlTrain batch 23/32 - 171.7ms/batch - loss: 3.94366 - diff: 63.10mlTrain batch 24/32 - 172.1ms/batch - loss: 3.90557 - diff: 62.49mlTrain batch 25/32 - 182.1ms/batch - loss: 3.97199 - diff: 63.55mlTrain batch 26/32 - 172.0ms/batch - loss: 3.91641 - diff: 62.66mlTrain batch 27/32 - 182.0ms/batch - loss: 3.86751 - diff: 61.88mlTrain batch 28/32 - 184.8ms/batch - loss: 3.83713 - diff: 61.39mlTrain batch 29/32 - 176.7ms/batch - loss: 3.77387 - diff: 60.38mlTrain batch 30/32 - 172.0ms/batch - loss: 3.74548 - diff: 59.93mlTrain batch 31/32 - 172.2ms/batch - loss: 3.70628 - diff: 59.30mlTrain batch 32/32 - 52.6ms/batch - loss: 3.75034 - diff: 59.12mlTrain batch 32/32 - 17.4s 52.6ms/batch - loss: 3.75034 - diff: 59.12ml
Test 1.5s: val_loss: 2.84540 - diff: 43.98ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_WideResNet50_0_Adam-0.001_MAE_DA3_best

Epoch 3: current best loss = 2.84540, at epoch 2
Train batch 1/32 - 184.0ms/batch - loss: 3.78950 - diff: 60.63mlTrain batch 2/32 - 174.8ms/batch - loss: 2.68029 - diff: 42.88mlTrain batch 3/32 - 171.9ms/batch - loss: 2.80274 - diff: 44.84mlTrain batch 4/32 - 171.8ms/batch - loss: 2.74294 - diff: 43.89mlTrain batch 5/32 - 173.6ms/batch - loss: 2.87439 - diff: 45.99mlTrain batch 6/32 - 176.2ms/batch - loss: 2.92294 - diff: 46.77mlTrain batch 7/32 - 172.1ms/batch - loss: 2.81243 - diff: 45.00mlTrain batch 8/32 - 176.0ms/batch - loss: 2.80655 - diff: 44.90mlTrain batch 9/32 - 172.1ms/batch - loss: 2.86642 - diff: 45.86mlTrain batch 10/32 - 172.1ms/batch - loss: 2.89329 - diff: 46.29mlTrain batch 11/32 - 172.4ms/batch - loss: 2.79801 - diff: 44.77mlTrain batch 12/32 - 172.2ms/batch - loss: 2.73968 - diff: 43.83mlTrain batch 13/32 - 172.2ms/batch - loss: 2.65463 - diff: 42.47mlTrain batch 14/32 - 176.4ms/batch - loss: 2.65755 - diff: 42.52mlTrain batch 15/32 - 172.1ms/batch - loss: 2.67064 - diff: 42.73mlTrain batch 16/32 - 172.5ms/batch - loss: 2.72884 - diff: 43.66mlTrain batch 17/32 - 174.1ms/batch - loss: 2.67737 - diff: 42.84mlTrain batch 18/32 - 172.1ms/batch - loss: 2.65576 - diff: 42.49mlTrain batch 19/32 - 193.4ms/batch - loss: 2.66182 - diff: 42.59mlTrain batch 20/32 - 172.2ms/batch - loss: 2.71316 - diff: 43.41mlTrain batch 21/32 - 172.2ms/batch - loss: 2.72860 - diff: 43.66mlTrain batch 22/32 - 172.4ms/batch - loss: 2.70131 - diff: 43.22mlTrain batch 23/32 - 204.3ms/batch - loss: 2.72522 - diff: 43.60mlTrain batch 24/32 - 172.5ms/batch - loss: 2.71147 - diff: 43.38mlTrain batch 25/32 - 172.2ms/batch - loss: 2.73364 - diff: 43.74mlTrain batch 26/32 - 184.1ms/batch - loss: 2.74660 - diff: 43.95mlTrain batch 27/32 - 172.2ms/batch - loss: 2.75360 - diff: 44.06mlTrain batch 28/32 - 172.6ms/batch - loss: 2.76411 - diff: 44.23mlTrain batch 29/32 - 177.2ms/batch - loss: 2.77283 - diff: 44.37mlTrain batch 30/32 - 171.9ms/batch - loss: 2.78156 - diff: 44.51mlTrain batch 31/32 - 172.1ms/batch - loss: 2.77646 - diff: 44.42mlTrain batch 32/32 - 52.8ms/batch - loss: 2.79748 - diff: 44.24mlTrain batch 32/32 - 16.3s 52.8ms/batch - loss: 2.79748 - diff: 44.24ml
Test 1.2s: val_loss: 2.78462 - diff: 42.77ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_WideResNet50_0_Adam-0.001_MAE_DA3_best

Epoch 4: current best loss = 2.78462, at epoch 3
Train batch 1/32 - 188.0ms/batch - loss: 4.17964 - diff: 66.87mlTrain batch 2/32 - 172.5ms/batch - loss: 3.20839 - diff: 51.33mlTrain batch 3/32 - 194.1ms/batch - loss: 3.15313 - diff: 50.45mlTrain batch 4/32 - 172.4ms/batch - loss: 2.99561 - diff: 47.93mlTrain batch 5/32 - 178.4ms/batch - loss: 2.74374 - diff: 43.90mlTrain batch 6/32 - 172.3ms/batch - loss: 2.83837 - diff: 45.41mlTrain batch 7/32 - 172.1ms/batch - loss: 2.88745 - diff: 46.20mlTrain batch 8/32 - 173.2ms/batch - loss: 2.78615 - diff: 44.58mlTrain batch 9/32 - 172.1ms/batch - loss: 2.75770 - diff: 44.12mlTrain batch 10/32 - 172.4ms/batch - loss: 2.72290 - diff: 43.57mlTrain batch 11/32 - 172.4ms/batch - loss: 2.71164 - diff: 43.39mlTrain batch 12/32 - 174.6ms/batch - loss: 2.73671 - diff: 43.79mlTrain batch 13/32 - 175.4ms/batch - loss: 2.67355 - diff: 42.78mlTrain batch 14/32 - 172.3ms/batch - loss: 2.70384 - diff: 43.26mlTrain batch 15/32 - 173.5ms/batch - loss: 2.70832 - diff: 43.33mlTrain batch 16/32 - 175.7ms/batch - loss: 2.71517 - diff: 43.44mlTrain batch 17/32 - 172.0ms/batch - loss: 2.71099 - diff: 43.38mlTrain batch 18/32 - 172.6ms/batch - loss: 2.73572 - diff: 43.77mlTrain batch 19/32 - 171.9ms/batch - loss: 2.69736 - diff: 43.16mlTrain batch 20/32 - 187.5ms/batch - loss: 2.68477 - diff: 42.96mlTrain batch 21/32 - 172.1ms/batch - loss: 2.66754 - diff: 42.68mlTrain batch 22/32 - 172.1ms/batch - loss: 2.68404 - diff: 42.94mlTrain batch 23/32 - 172.2ms/batch - loss: 2.64628 - diff: 42.34mlTrain batch 24/32 - 172.5ms/batch - loss: 2.68898 - diff: 43.02mlTrain batch 25/32 - 179.6ms/batch - loss: 2.67888 - diff: 42.86mlTrain batch 26/32 - 171.9ms/batch - loss: 2.71708 - diff: 43.47mlTrain batch 27/32 - 179.2ms/batch - loss: 2.73649 - diff: 43.78mlTrain batch 28/32 - 171.7ms/batch - loss: 2.72499 - diff: 43.60mlTrain batch 29/32 - 172.3ms/batch - loss: 2.71026 - diff: 43.36mlTrain batch 30/32 - 172.5ms/batch - loss: 2.70982 - diff: 43.36mlTrain batch 31/32 - 172.1ms/batch - loss: 2.68418 - diff: 42.95mlTrain batch 32/32 - 52.7ms/batch - loss: 2.76874 - diff: 43.03mlTrain batch 32/32 - 17.3s 52.7ms/batch - loss: 2.76874 - diff: 43.03ml
Test 1.3s: val_loss: 2.71716 - diff: 42.35ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_WideResNet50_0_Adam-0.001_MAE_DA3_best

Epoch 5: current best loss = 2.71716, at epoch 4
Train batch 1/32 - 188.2ms/batch - loss: 2.96797 - diff: 47.49mlTrain batch 2/32 - 187.5ms/batch - loss: 2.86443 - diff: 45.83mlTrain batch 3/32 - 187.3ms/batch - loss: 2.94787 - diff: 47.17mlTrain batch 4/32 - 172.3ms/batch - loss: 3.00491 - diff: 48.08mlTrain batch 5/32 - 172.1ms/batch - loss: 2.95313 - diff: 47.25mlTrain batch 6/32 - 172.2ms/batch - loss: 2.95506 - diff: 47.28mlTrain batch 7/32 - 191.4ms/batch - loss: 2.77879 - diff: 44.46mlTrain batch 8/32 - 172.8ms/batch - loss: 2.77932 - diff: 44.47mlTrain batch 9/32 - 172.6ms/batch - loss: 2.86382 - diff: 45.82mlTrain batch 10/32 - 172.8ms/batch - loss: 2.87255 - diff: 45.96mlTrain batch 11/32 - 189.5ms/batch - loss: 2.84321 - diff: 45.49mlTrain batch 12/32 - 172.8ms/batch - loss: 2.89569 - diff: 46.33mlTrain batch 13/32 - 172.3ms/batch - loss: 2.84351 - diff: 45.50mlTrain batch 14/32 - 176.8ms/batch - loss: 2.86919 - diff: 45.91mlTrain batch 15/32 - 178.6ms/batch - loss: 2.82539 - diff: 45.21mlTrain batch 16/32 - 172.3ms/batch - loss: 2.79840 - diff: 44.77mlTrain batch 17/32 - 172.7ms/batch - loss: 2.83836 - diff: 45.41mlTrain batch 18/32 - 172.5ms/batch - loss: 2.81388 - diff: 45.02mlTrain batch 19/32 - 172.4ms/batch - loss: 2.79517 - diff: 44.72mlTrain batch 20/32 - 172.8ms/batch - loss: 2.77453 - diff: 44.39mlTrain batch 21/32 - 172.2ms/batch - loss: 2.71498 - diff: 43.44mlTrain batch 22/32 - 172.9ms/batch - loss: 2.68660 - diff: 42.99mlTrain batch 23/32 - 171.8ms/batch - loss: 2.66979 - diff: 42.72mlTrain batch 24/32 - 172.5ms/batch - loss: 2.68197 - diff: 42.91mlTrain batch 25/32 - 179.8ms/batch - loss: 2.69299 - diff: 43.09mlTrain batch 26/32 - 172.5ms/batch - loss: 2.72022 - diff: 43.52mlTrain batch 27/32 - 172.7ms/batch - loss: 2.70548 - diff: 43.29mlTrain batch 28/32 - 172.4ms/batch - loss: 2.67873 - diff: 42.86mlTrain batch 29/32 - 172.4ms/batch - loss: 2.65482 - diff: 42.48mlTrain batch 30/32 - 172.6ms/batch - loss: 2.67341 - diff: 42.77mlTrain batch 31/32 - 172.8ms/batch - loss: 2.67230 - diff: 42.76mlTrain batch 32/32 - 59.7ms/batch - loss: 2.70996 - diff: 42.65mlTrain batch 32/32 - 16.5s 59.7ms/batch - loss: 2.70996 - diff: 42.65ml
Test 1.5s: val_loss: 2.81071 - diff: 42.13ml

Epoch 6: current best loss = 2.71716, at epoch 4
Train batch 1/32 - 172.7ms/batch - loss: 4.08862 - diff: 65.42mlTrain batch 2/32 - 172.8ms/batch - loss: 3.59575 - diff: 57.53mlTrain batch 3/32 - 172.5ms/batch - loss: 3.41759 - diff: 54.68mlTrain batch 4/32 - 174.1ms/batch - loss: 3.18596 - diff: 50.98mlTrain batch 5/32 - 175.2ms/batch - loss: 3.11002 - diff: 49.76mlTrain batch 6/32 - 172.4ms/batch - loss: 2.98052 - diff: 47.69mlTrain batch 7/32 - 172.3ms/batch - loss: 3.00055 - diff: 48.01mlTrain batch 8/32 - 172.4ms/batch - loss: 3.02541 - diff: 48.41mlTrain batch 9/32 - 172.8ms/batch - loss: 3.04137 - diff: 48.66mlTrain batch 10/32 - 179.7ms/batch - loss: 3.15956 - diff: 50.55mlTrain batch 11/32 - 172.3ms/batch - loss: 3.03574 - diff: 48.57mlTrain batch 12/32 - 179.8ms/batch - loss: 3.01977 - diff: 48.32mlTrain batch 13/32 - 172.2ms/batch - loss: 3.05452 - diff: 48.87mlTrain batch 14/32 - 180.6ms/batch - loss: 3.01811 - diff: 48.29mlTrain batch 15/32 - 187.4ms/batch - loss: 3.01356 - diff: 48.22mlTrain batch 16/32 - 177.8ms/batch - loss: 2.97052 - diff: 47.53mlTrain batch 17/32 - 182.1ms/batch - loss: 2.95268 - diff: 47.24mlTrain batch 18/32 - 173.0ms/batch - loss: 2.93231 - diff: 46.92mlTrain batch 19/32 - 172.4ms/batch - loss: 2.89139 - diff: 46.26mlTrain batch 20/32 - 174.3ms/batch - loss: 2.87669 - diff: 46.03mlTrain batch 21/32 - 172.2ms/batch - loss: 2.83737 - diff: 45.40mlTrain batch 22/32 - 173.6ms/batch - loss: 2.82437 - diff: 45.19mlTrain batch 23/32 - 180.0ms/batch - loss: 2.78996 - diff: 44.64mlTrain batch 24/32 - 181.3ms/batch - loss: 2.75629 - diff: 44.10mlTrain batch 25/32 - 172.8ms/batch - loss: 2.71852 - diff: 43.50mlTrain batch 26/32 - 179.5ms/batch - loss: 2.68604 - diff: 42.98mlTrain batch 27/32 - 173.2ms/batch - loss: 2.68842 - diff: 43.01mlTrain batch 28/32 - 172.5ms/batch - loss: 2.71932 - diff: 43.51mlTrain batch 29/32 - 183.9ms/batch - loss: 2.69609 - diff: 43.14mlTrain batch 30/32 - 172.7ms/batch - loss: 2.68893 - diff: 43.02mlTrain batch 31/32 - 172.7ms/batch - loss: 2.67888 - diff: 42.86mlTrain batch 32/32 - 52.9ms/batch - loss: 2.71938 - diff: 42.77mlTrain batch 32/32 - 17.3s 52.9ms/batch - loss: 2.71938 - diff: 42.77ml
Test 1.4s: val_loss: 2.84859 - diff: 42.99ml

Epoch 7: current best loss = 2.71716, at epoch 4
Train batch 1/32 - 172.7ms/batch - loss: 2.04021 - diff: 32.64mlTrain batch 2/32 - 172.7ms/batch - loss: 2.12162 - diff: 33.95mlTrain batch 3/32 - 189.7ms/batch - loss: 2.40336 - diff: 38.45mlTrain batch 4/32 - 181.4ms/batch - loss: 2.48727 - diff: 39.80mlTrain batch 5/32 - 172.6ms/batch - loss: 2.36796 - diff: 37.89mlTrain batch 6/32 - 172.9ms/batch - loss: 2.34892 - diff: 37.58mlTrain batch 7/32 - 172.6ms/batch - loss: 2.32370 - diff: 37.18mlTrain batch 8/32 - 172.8ms/batch - loss: 2.42489 - diff: 38.80mlTrain batch 9/32 - 172.7ms/batch - loss: 2.50506 - diff: 40.08mlTrain batch 10/32 - 172.6ms/batch - loss: 2.49409 - diff: 39.91mlTrain batch 11/32 - 172.6ms/batch - loss: 2.56530 - diff: 41.04mlTrain batch 12/32 - 172.9ms/batch - loss: 2.59584 - diff: 41.53mlTrain batch 13/32 - 176.0ms/batch - loss: 2.56192 - diff: 40.99mlTrain batch 14/32 - 172.9ms/batch - loss: 2.52471 - diff: 40.40mlTrain batch 15/32 - 172.7ms/batch - loss: 2.49739 - diff: 39.96mlTrain batch 16/32 - 177.3ms/batch - loss: 2.54976 - diff: 40.80mlTrain batch 17/32 - 172.8ms/batch - loss: 2.61279 - diff: 41.80mlTrain batch 18/32 - 179.3ms/batch - loss: 2.63047 - diff: 42.09mlTrain batch 19/32 - 172.5ms/batch - loss: 2.64221 - diff: 42.28mlTrain batch 20/32 - 195.8ms/batch - loss: 2.66772 - diff: 42.68mlTrain batch 21/32 - 172.8ms/batch - loss: 2.66455 - diff: 42.63mlTrain batch 22/32 - 188.0ms/batch - loss: 2.65724 - diff: 42.52mlTrain batch 23/32 - 172.8ms/batch - loss: 2.67617 - diff: 42.82mlTrain batch 24/32 - 192.4ms/batch - loss: 2.75071 - diff: 44.01mlTrain batch 25/32 - 172.7ms/batch - loss: 2.72812 - diff: 43.65mlTrain batch 26/32 - 172.0ms/batch - loss: 2.73137 - diff: 43.70mlTrain batch 27/32 - 172.8ms/batch - loss: 2.70603 - diff: 43.30mlTrain batch 28/32 - 173.1ms/batch - loss: 2.70595 - diff: 43.30mlTrain batch 29/32 - 182.0ms/batch - loss: 2.70663 - diff: 43.31mlTrain batch 30/32 - 176.7ms/batch - loss: 2.68500 - diff: 42.96mlTrain batch 31/32 - 175.3ms/batch - loss: 2.66214 - diff: 42.59mlTrain batch 32/32 - 53.2ms/batch - loss: 2.70449 - diff: 42.51mlTrain batch 32/32 - 17.4s 53.2ms/batch - loss: 2.70449 - diff: 42.51ml
Test 1.4s: val_loss: 2.77320 - diff: 41.97ml

Epoch 8: current best loss = 2.71716, at epoch 4
Train batch 1/32 - 180.3ms/batch - loss: 1.94188 - diff: 31.07mlTrain batch 2/32 - 173.2ms/batch - loss: 2.75582 - diff: 44.09mlTrain batch 3/32 - 172.8ms/batch - loss: 2.73708 - diff: 43.79mlTrain batch 4/32 - 182.2ms/batch - loss: 2.77499 - diff: 44.40mlTrain batch 5/32 - 172.6ms/batch - loss: 2.72818 - diff: 43.65mlTrain batch 6/32 - 186.9ms/batch - loss: 2.81903 - diff: 45.10mlTrain batch 7/32 - 172.6ms/batch - loss: 2.84473 - diff: 45.52mlTrain batch 8/32 - 181.8ms/batch - loss: 2.81271 - diff: 45.00mlTrain batch 9/32 - 176.5ms/batch - loss: 2.87535 - diff: 46.01mlTrain batch 10/32 - 181.7ms/batch - loss: 2.76592 - diff: 44.25mlTrain batch 11/32 - 179.7ms/batch - loss: 2.76959 - diff: 44.31mlTrain batch 12/32 - 172.7ms/batch - loss: 2.82874 - diff: 45.26mlTrain batch 13/32 - 173.0ms/batch - loss: 2.77309 - diff: 44.37mlTrain batch 14/32 - 173.3ms/batch - loss: 2.76886 - diff: 44.30mlTrain batch 15/32 - 172.6ms/batch - loss: 2.72358 - diff: 43.58mlTrain batch 16/32 - 172.4ms/batch - loss: 2.73803 - diff: 43.81mlTrain batch 17/32 - 172.6ms/batch - loss: 2.74031 - diff: 43.84mlTrain batch 18/32 - 173.1ms/batch - loss: 2.68409 - diff: 42.95mlTrain batch 19/32 - 179.0ms/batch - loss: 2.72822 - diff: 43.65mlTrain batch 20/32 - 173.1ms/batch - loss: 2.75041 - diff: 44.01mlTrain batch 21/32 - 184.4ms/batch - loss: 2.77238 - diff: 44.36mlTrain batch 22/32 - 172.5ms/batch - loss: 2.74474 - diff: 43.92mlTrain batch 23/32 - 188.5ms/batch - loss: 2.74324 - diff: 43.89mlTrain batch 24/32 - 183.9ms/batch - loss: 2.74109 - diff: 43.86mlTrain batch 25/32 - 172.8ms/batch - loss: 2.73762 - diff: 43.80mlTrain batch 26/32 - 172.4ms/batch - loss: 2.72091 - diff: 43.53mlTrain batch 27/32 - 173.0ms/batch - loss: 2.71546 - diff: 43.45mlTrain batch 28/32 - 187.5ms/batch - loss: 2.69354 - diff: 43.10mlTrain batch 29/32 - 172.8ms/batch - loss: 2.67224 - diff: 42.76mlTrain batch 30/32 - 172.8ms/batch - loss: 2.67797 - diff: 42.85mlTrain batch 31/32 - 172.6ms/batch - loss: 2.66416 - diff: 42.63mlTrain batch 32/32 - 52.9ms/batch - loss: 2.73881 - diff: 42.67mlTrain batch 32/32 - 16.2s 52.9ms/batch - loss: 2.73881 - diff: 42.67ml
Test 1.4s: val_loss: 2.70294 - diff: 40.92ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_WideResNet50_0_Adam-0.001_MAE_DA3_best

Epoch 9: current best loss = 2.70294, at epoch 8
Train batch 1/32 - 188.2ms/batch - loss: 2.36874 - diff: 37.90mlTrain batch 2/32 - 172.7ms/batch - loss: 2.34457 - diff: 37.51mlTrain batch 3/32 - 181.1ms/batch - loss: 2.20178 - diff: 35.23mlTrain batch 4/32 - 173.6ms/batch - loss: 2.39914 - diff: 38.39mlTrain batch 5/32 - 172.8ms/batch - loss: 2.30430 - diff: 36.87mlTrain batch 6/32 - 174.0ms/batch - loss: 2.24443 - diff: 35.91mlTrain batch 7/32 - 172.7ms/batch - loss: 2.23179 - diff: 35.71mlTrain batch 8/32 - 181.9ms/batch - loss: 2.16685 - diff: 34.67mlTrain batch 9/32 - 172.9ms/batch - loss: 2.27566 - diff: 36.41mlTrain batch 10/32 - 172.8ms/batch - loss: 2.24747 - diff: 35.96mlTrain batch 11/32 - 172.8ms/batch - loss: 2.26522 - diff: 36.24mlTrain batch 12/32 - 172.7ms/batch - loss: 2.30709 - diff: 36.91mlTrain batch 13/32 - 172.7ms/batch - loss: 2.33440 - diff: 37.35mlTrain batch 14/32 - 172.8ms/batch - loss: 2.40695 - diff: 38.51mlTrain batch 15/32 - 172.9ms/batch - loss: 2.49634 - diff: 39.94mlTrain batch 16/32 - 175.3ms/batch - loss: 2.50016 - diff: 40.00mlTrain batch 17/32 - 179.4ms/batch - loss: 2.49163 - diff: 39.87mlTrain batch 18/32 - 172.8ms/batch - loss: 2.48938 - diff: 39.83mlTrain batch 19/32 - 172.7ms/batch - loss: 2.52250 - diff: 40.36mlTrain batch 20/32 - 176.5ms/batch - loss: 2.56042 - diff: 40.97mlTrain batch 21/32 - 172.7ms/batch - loss: 2.56663 - diff: 41.07mlTrain batch 22/32 - 184.9ms/batch - loss: 2.58136 - diff: 41.30mlTrain batch 23/32 - 172.6ms/batch - loss: 2.61511 - diff: 41.84mlTrain batch 24/32 - 173.0ms/batch - loss: 2.63538 - diff: 42.17mlTrain batch 25/32 - 172.9ms/batch - loss: 2.67268 - diff: 42.76mlTrain batch 26/32 - 172.5ms/batch - loss: 2.66731 - diff: 42.68mlTrain batch 27/32 - 172.9ms/batch - loss: 2.61764 - diff: 41.88mlTrain batch 28/32 - 180.1ms/batch - loss: 2.60033 - diff: 41.61mlTrain batch 29/32 - 172.8ms/batch - loss: 2.57497 - diff: 41.20mlTrain batch 30/32 - 172.9ms/batch - loss: 2.60891 - diff: 41.74mlTrain batch 31/32 - 172.6ms/batch - loss: 2.59041 - diff: 41.45mlTrain batch 32/32 - 52.9ms/batch - loss: 2.63420 - diff: 41.37mlTrain batch 32/32 - 15.9s 52.9ms/batch - loss: 2.63420 - diff: 41.37ml
Test 1.4s: val_loss: 2.72932 - diff: 42.85ml

Epoch 10: current best loss = 2.70294, at epoch 8
Train batch 1/32 - 172.9ms/batch - loss: 3.08492 - diff: 49.36mlTrain batch 2/32 - 172.8ms/batch - loss: 3.00051 - diff: 48.01mlTrain batch 3/32 - 172.6ms/batch - loss: 2.63921 - diff: 42.23mlTrain batch 4/32 - 173.1ms/batch - loss: 2.59548 - diff: 41.53mlTrain batch 5/32 - 175.4ms/batch - loss: 2.50817 - diff: 40.13mlTrain batch 6/32 - 173.0ms/batch - loss: 2.57183 - diff: 41.15mlTrain batch 7/32 - 189.2ms/batch - loss: 2.60746 - diff: 41.72mlTrain batch 8/32 - 173.0ms/batch - loss: 2.69441 - diff: 43.11mlTrain batch 9/32 - 187.2ms/batch - loss: 2.73185 - diff: 43.71mlTrain batch 10/32 - 173.8ms/batch - loss: 2.67262 - diff: 42.76mlTrain batch 11/32 - 172.8ms/batch - loss: 2.66599 - diff: 42.66mlTrain batch 12/32 - 172.9ms/batch - loss: 2.66146 - diff: 42.58mlTrain batch 13/32 - 172.7ms/batch - loss: 2.77720 - diff: 44.44mlTrain batch 14/32 - 172.5ms/batch - loss: 2.76504 - diff: 44.24mlTrain batch 15/32 - 175.2ms/batch - loss: 2.71967 - diff: 43.51mlTrain batch 16/32 - 173.5ms/batch - loss: 2.68245 - diff: 42.92mlTrain batch 17/32 - 185.7ms/batch - loss: 2.63550 - diff: 42.17mlTrain batch 18/32 - 184.3ms/batch - loss: 2.62362 - diff: 41.98mlTrain batch 19/32 - 174.8ms/batch - loss: 2.65417 - diff: 42.47mlTrain batch 20/32 - 173.7ms/batch - loss: 2.65600 - diff: 42.50mlTrain batch 21/32 - 172.9ms/batch - loss: 2.69659 - diff: 43.15mlTrain batch 22/32 - 173.3ms/batch - loss: 2.65340 - diff: 42.45mlTrain batch 23/32 - 197.3ms/batch - loss: 2.64305 - diff: 42.29mlTrain batch 24/32 - 173.5ms/batch - loss: 2.63386 - diff: 42.14mlTrain batch 25/32 - 173.0ms/batch - loss: 2.60951 - diff: 41.75mlTrain batch 26/32 - 182.9ms/batch - loss: 2.62367 - diff: 41.98mlTrain batch 27/32 - 172.6ms/batch - loss: 2.60994 - diff: 41.76mlTrain batch 28/32 - 173.6ms/batch - loss: 2.64247 - diff: 42.28mlTrain batch 29/32 - 172.9ms/batch - loss: 2.63107 - diff: 42.10mlTrain batch 30/32 - 177.4ms/batch - loss: 2.63716 - diff: 42.19mlTrain batch 31/32 - 173.2ms/batch - loss: 2.64227 - diff: 42.28mlTrain batch 32/32 - 53.4ms/batch - loss: 2.72074 - diff: 42.34mlTrain batch 32/32 - 15.8s 53.4ms/batch - loss: 2.72074 - diff: 42.34ml
Test 1.4s: val_loss: 2.63620 - diff: 40.71ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_WideResNet50_0_Adam-0.001_MAE_DA3_best

Epoch 11: current best loss = 2.63620, at epoch 10
Train batch 1/32 - 188.3ms/batch - loss: 2.00066 - diff: 32.01mlTrain batch 2/32 - 179.7ms/batch - loss: 2.57325 - diff: 41.17mlTrain batch 3/32 - 173.1ms/batch - loss: 2.47638 - diff: 39.62mlTrain batch 4/32 - 179.9ms/batch - loss: 2.72078 - diff: 43.53mlTrain batch 5/32 - 173.1ms/batch - loss: 2.60575 - diff: 41.69mlTrain batch 6/32 - 173.6ms/batch - loss: 2.68382 - diff: 42.94mlTrain batch 7/32 - 177.4ms/batch - loss: 2.77007 - diff: 44.32mlTrain batch 8/32 - 172.7ms/batch - loss: 2.75152 - diff: 44.02mlTrain batch 9/32 - 172.8ms/batch - loss: 2.67555 - diff: 42.81mlTrain batch 10/32 - 173.0ms/batch - loss: 2.84278 - diff: 45.48mlTrain batch 11/32 - 173.1ms/batch - loss: 2.81674 - diff: 45.07mlTrain batch 12/32 - 172.8ms/batch - loss: 2.77006 - diff: 44.32mlTrain batch 13/32 - 172.7ms/batch - loss: 2.68758 - diff: 43.00mlTrain batch 14/32 - 178.2ms/batch - loss: 2.67934 - diff: 42.87mlTrain batch 15/32 - 173.2ms/batch - loss: 2.64644 - diff: 42.34mlTrain batch 16/32 - 173.0ms/batch - loss: 2.61788 - diff: 41.89mlTrain batch 17/32 - 179.4ms/batch - loss: 2.63950 - diff: 42.23mlTrain batch 18/32 - 173.7ms/batch - loss: 2.62258 - diff: 41.96mlTrain batch 19/32 - 172.7ms/batch - loss: 2.64428 - diff: 42.31mlTrain batch 20/32 - 174.9ms/batch - loss: 2.66719 - diff: 42.68mlTrain batch 21/32 - 177.7ms/batch - loss: 2.64788 - diff: 42.37mlTrain batch 22/32 - 179.8ms/batch - loss: 2.62414 - diff: 41.99mlTrain batch 23/32 - 183.4ms/batch - loss: 2.63359 - diff: 42.14mlTrain batch 24/32 - 172.2ms/batch - loss: 2.67083 - diff: 42.73mlTrain batch 25/32 - 172.9ms/batch - loss: 2.68123 - diff: 42.90mlTrain batch 26/32 - 181.2ms/batch - loss: 2.66730 - diff: 42.68mlTrain batch 27/32 - 178.6ms/batch - loss: 2.69165 - diff: 43.07mlTrain batch 28/32 - 172.8ms/batch - loss: 2.68096 - diff: 42.90mlTrain batch 29/32 - 172.7ms/batch - loss: 2.65428 - diff: 42.47mlTrain batch 30/32 - 173.6ms/batch - loss: 2.62732 - diff: 42.04mlTrain batch 31/32 - 172.9ms/batch - loss: 2.62588 - diff: 42.01mlTrain batch 32/32 - 52.9ms/batch - loss: 2.66108 - diff: 41.90mlTrain batch 32/32 - 16.2s 52.9ms/batch - loss: 2.66108 - diff: 41.90ml
Test 1.5s: val_loss: 2.58301 - diff: 39.97ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_WideResNet50_0_Adam-0.001_MAE_DA3_best

Epoch 12: current best loss = 2.58301, at epoch 11
Train batch 1/32 - 181.8ms/batch - loss: 2.21996 - diff: 35.52mlTrain batch 2/32 - 176.5ms/batch - loss: 2.37540 - diff: 38.01mlTrain batch 3/32 - 172.9ms/batch - loss: 2.40127 - diff: 38.42mlTrain batch 4/32 - 173.5ms/batch - loss: 2.29432 - diff: 36.71mlTrain batch 5/32 - 172.9ms/batch - loss: 2.41294 - diff: 38.61mlTrain batch 6/32 - 176.2ms/batch - loss: 2.36192 - diff: 37.79mlTrain batch 7/32 - 173.3ms/batch - loss: 2.40701 - diff: 38.51mlTrain batch 8/32 - 172.7ms/batch - loss: 2.52300 - diff: 40.37mlTrain batch 9/32 - 180.0ms/batch - loss: 2.59498 - diff: 41.52mlTrain batch 10/32 - 182.3ms/batch - loss: 2.58039 - diff: 41.29mlTrain batch 11/32 - 173.0ms/batch - loss: 2.55190 - diff: 40.83mlTrain batch 12/32 - 173.3ms/batch - loss: 2.62334 - diff: 41.97mlTrain batch 13/32 - 183.8ms/batch - loss: 2.57666 - diff: 41.23mlTrain batch 14/32 - 184.0ms/batch - loss: 2.63740 - diff: 42.20mlTrain batch 15/32 - 172.9ms/batch - loss: 2.63385 - diff: 42.14mlTrain batch 16/32 - 173.1ms/batch - loss: 2.68774 - diff: 43.00mlTrain batch 17/32 - 174.0ms/batch - loss: 2.65115 - diff: 42.42mlTrain batch 18/32 - 172.7ms/batch - loss: 2.64438 - diff: 42.31mlTrain batch 19/32 - 172.7ms/batch - loss: 2.65046 - diff: 42.41mlTrain batch 20/32 - 173.3ms/batch - loss: 2.61261 - diff: 41.80mlTrain batch 21/32 - 172.8ms/batch - loss: 2.59434 - diff: 41.51mlTrain batch 22/32 - 173.0ms/batch - loss: 2.59321 - diff: 41.49mlTrain batch 23/32 - 172.7ms/batch - loss: 2.58074 - diff: 41.29mlTrain batch 24/32 - 180.1ms/batch - loss: 2.61452 - diff: 41.83mlTrain batch 25/32 - 173.4ms/batch - loss: 2.60030 - diff: 41.60mlTrain batch 26/32 - 176.2ms/batch - loss: 2.58376 - diff: 41.34mlTrain batch 27/32 - 173.1ms/batch - loss: 2.59051 - diff: 41.45mlTrain batch 28/32 - 173.4ms/batch - loss: 2.61321 - diff: 41.81mlTrain batch 29/32 - 173.0ms/batch - loss: 2.60705 - diff: 41.71mlTrain batch 30/32 - 180.4ms/batch - loss: 2.60688 - diff: 41.71mlTrain batch 31/32 - 173.2ms/batch - loss: 2.60441 - diff: 41.67mlTrain batch 32/32 - 53.2ms/batch - loss: 2.69011 - diff: 41.76mlTrain batch 32/32 - 16.2s 53.2ms/batch - loss: 2.69011 - diff: 41.76ml
Test 1.4s: val_loss: 2.70559 - diff: 41.51ml

Epoch 13: current best loss = 2.58301, at epoch 11
Train batch 1/32 - 172.8ms/batch - loss: 2.11260 - diff: 33.80mlTrain batch 2/32 - 187.2ms/batch - loss: 2.48801 - diff: 39.81mlTrain batch 3/32 - 188.6ms/batch - loss: 2.21975 - diff: 35.52mlTrain batch 4/32 - 180.1ms/batch - loss: 2.30279 - diff: 36.84mlTrain batch 5/32 - 194.8ms/batch - loss: 2.27260 - diff: 36.36mlTrain batch 6/32 - 173.5ms/batch - loss: 2.51035 - diff: 40.17mlTrain batch 7/32 - 172.7ms/batch - loss: 2.44039 - diff: 39.05mlTrain batch 8/32 - 173.1ms/batch - loss: 2.45450 - diff: 39.27mlTrain batch 9/32 - 188.1ms/batch - loss: 2.61436 - diff: 41.83mlTrain batch 10/32 - 173.6ms/batch - loss: 2.64192 - diff: 42.27mlTrain batch 11/32 - 173.2ms/batch - loss: 2.69350 - diff: 43.10mlTrain batch 12/32 - 173.1ms/batch - loss: 2.65716 - diff: 42.51mlTrain batch 13/32 - 174.6ms/batch - loss: 2.69313 - diff: 43.09mlTrain batch 14/32 - 173.0ms/batch - loss: 2.69319 - diff: 43.09mlTrain batch 15/32 - 185.7ms/batch - loss: 2.72486 - diff: 43.60mlTrain batch 16/32 - 178.1ms/batch - loss: 2.66866 - diff: 42.70mlTrain batch 17/32 - 173.1ms/batch - loss: 2.64288 - diff: 42.29mlTrain batch 18/32 - 184.9ms/batch - loss: 2.61034 - diff: 41.77mlTrain batch 19/32 - 173.1ms/batch - loss: 2.66068 - diff: 42.57mlTrain batch 20/32 - 184.7ms/batch - loss: 2.64562 - diff: 42.33mlTrain batch 21/32 - 173.0ms/batch - loss: 2.65457 - diff: 42.47mlTrain batch 22/32 - 179.0ms/batch - loss: 2.65783 - diff: 42.53mlTrain batch 23/32 - 173.0ms/batch - loss: 2.63963 - diff: 42.23mlTrain batch 24/32 - 177.1ms/batch - loss: 2.65346 - diff: 42.46mlTrain batch 25/32 - 173.3ms/batch - loss: 2.62663 - diff: 42.03mlTrain batch 26/32 - 173.2ms/batch - loss: 2.61551 - diff: 41.85mlTrain batch 27/32 - 180.8ms/batch - loss: 2.60089 - diff: 41.61mlTrain batch 28/32 - 173.0ms/batch - loss: 2.58172 - diff: 41.31mlTrain batch 29/32 - 183.2ms/batch - loss: 2.56949 - diff: 41.11mlTrain batch 30/32 - 173.0ms/batch - loss: 2.58675 - diff: 41.39mlTrain batch 31/32 - 172.6ms/batch - loss: 2.58885 - diff: 41.42mlTrain batch 32/32 - 52.8ms/batch - loss: 2.67216 - diff: 41.51mlTrain batch 32/32 - 16.2s 52.8ms/batch - loss: 2.67216 - diff: 41.51ml
Test 1.2s: val_loss: 2.63551 - diff: 40.06ml

Epoch 14: current best loss = 2.58301, at epoch 11
Train batch 1/32 - 172.7ms/batch - loss: 2.97034 - diff: 47.53mlTrain batch 2/32 - 182.5ms/batch - loss: 3.05320 - diff: 48.85mlTrain batch 3/32 - 172.9ms/batch - loss: 2.96014 - diff: 47.36mlTrain batch 4/32 - 173.4ms/batch - loss: 2.93280 - diff: 46.92mlTrain batch 5/32 - 173.2ms/batch - loss: 2.82210 - diff: 45.15mlTrain batch 6/32 - 178.1ms/batch - loss: 2.62350 - diff: 41.98mlTrain batch 7/32 - 173.1ms/batch - loss: 2.68646 - diff: 42.98mlTrain batch 8/32 - 173.2ms/batch - loss: 2.62274 - diff: 41.96mlTrain batch 9/32 - 173.2ms/batch - loss: 2.55283 - diff: 40.85mlTrain batch 10/32 - 173.2ms/batch - loss: 2.73332 - diff: 43.73mlTrain batch 11/32 - 178.2ms/batch - loss: 2.78954 - diff: 44.63mlTrain batch 12/32 - 175.3ms/batch - loss: 2.74070 - diff: 43.85mlTrain batch 13/32 - 173.2ms/batch - loss: 2.75299 - diff: 44.05mlTrain batch 14/32 - 173.2ms/batch - loss: 2.73092 - diff: 43.69mlTrain batch 15/32 - 176.1ms/batch - loss: 2.71909 - diff: 43.51mlTrain batch 16/32 - 173.2ms/batch - loss: 2.66755 - diff: 42.68mlTrain batch 17/32 - 177.0ms/batch - loss: 2.60792 - diff: 41.73mlTrain batch 18/32 - 173.4ms/batch - loss: 2.59205 - diff: 41.47mlTrain batch 19/32 - 173.2ms/batch - loss: 2.58708 - diff: 41.39mlTrain batch 20/32 - 172.9ms/batch - loss: 2.55910 - diff: 40.95mlTrain batch 21/32 - 173.2ms/batch - loss: 2.58462 - diff: 41.35mlTrain batch 22/32 - 176.4ms/batch - loss: 2.58022 - diff: 41.28mlTrain batch 23/32 - 179.8ms/batch - loss: 2.61019 - diff: 41.76mlTrain batch 24/32 - 175.8ms/batch - loss: 2.59594 - diff: 41.54mlTrain batch 25/32 - 176.3ms/batch - loss: 2.62460 - diff: 41.99mlTrain batch 26/32 - 173.3ms/batch - loss: 2.62118 - diff: 41.94mlTrain batch 27/32 - 181.6ms/batch - loss: 2.63888 - diff: 42.22mlTrain batch 28/32 - 172.8ms/batch - loss: 2.61873 - diff: 41.90mlTrain batch 29/32 - 188.9ms/batch - loss: 2.60210 - diff: 41.63mlTrain batch 30/32 - 173.5ms/batch - loss: 2.61399 - diff: 41.82mlTrain batch 31/32 - 173.3ms/batch - loss: 2.61656 - diff: 41.86mlTrain batch 32/32 - 53.2ms/batch - loss: 2.63676 - diff: 41.69mlTrain batch 32/32 - 16.4s 53.2ms/batch - loss: 2.63676 - diff: 41.69ml
Test 1.4s: val_loss: 2.55994 - diff: 39.09ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_WideResNet50_0_Adam-0.001_MAE_DA3_best

Epoch 15: current best loss = 2.55994, at epoch 14
Train batch 1/32 - 183.3ms/batch - loss: 3.15164 - diff: 50.43mlTrain batch 2/32 - 173.4ms/batch - loss: 3.56573 - diff: 57.05mlTrain batch 3/32 - 173.3ms/batch - loss: 2.98659 - diff: 47.79mlTrain batch 4/32 - 181.4ms/batch - loss: 2.87501 - diff: 46.00mlTrain batch 5/32 - 173.0ms/batch - loss: 2.80804 - diff: 44.93mlTrain batch 6/32 - 173.1ms/batch - loss: 2.61426 - diff: 41.83mlTrain batch 7/32 - 173.1ms/batch - loss: 2.66880 - diff: 42.70mlTrain batch 8/32 - 200.0ms/batch - loss: 2.61975 - diff: 41.92mlTrain batch 9/32 - 173.5ms/batch - loss: 2.61099 - diff: 41.78mlTrain batch 10/32 - 173.3ms/batch - loss: 2.55320 - diff: 40.85mlTrain batch 11/32 - 173.6ms/batch - loss: 2.60740 - diff: 41.72mlTrain batch 12/32 - 178.8ms/batch - loss: 2.56074 - diff: 40.97mlTrain batch 13/32 - 173.1ms/batch - loss: 2.60517 - diff: 41.68mlTrain batch 14/32 - 173.0ms/batch - loss: 2.59393 - diff: 41.50mlTrain batch 15/32 - 173.0ms/batch - loss: 2.54487 - diff: 40.72mlTrain batch 16/32 - 173.1ms/batch - loss: 2.54880 - diff: 40.78mlTrain batch 17/32 - 177.9ms/batch - loss: 2.60097 - diff: 41.62mlTrain batch 18/32 - 188.7ms/batch - loss: 2.65804 - diff: 42.53mlTrain batch 19/32 - 173.4ms/batch - loss: 2.63672 - diff: 42.19mlTrain batch 20/32 - 173.5ms/batch - loss: 2.63156 - diff: 42.10mlTrain batch 21/32 - 173.3ms/batch - loss: 2.65577 - diff: 42.49mlTrain batch 22/32 - 172.9ms/batch - loss: 2.61680 - diff: 41.87mlTrain batch 23/32 - 173.5ms/batch - loss: 2.59121 - diff: 41.46mlTrain batch 24/32 - 173.3ms/batch - loss: 2.58206 - diff: 41.31mlTrain batch 25/32 - 173.5ms/batch - loss: 2.56704 - diff: 41.07mlTrain batch 26/32 - 173.2ms/batch - loss: 2.62432 - diff: 41.99mlTrain batch 27/32 - 173.3ms/batch - loss: 2.63076 - diff: 42.09mlTrain batch 28/32 - 180.8ms/batch - loss: 2.61291 - diff: 41.81mlTrain batch 29/32 - 173.8ms/batch - loss: 2.61353 - diff: 41.82mlTrain batch 30/32 - 180.5ms/batch - loss: 2.63005 - diff: 42.08mlTrain batch 31/32 - 177.8ms/batch - loss: 2.60415 - diff: 41.67mlTrain batch 32/32 - 53.2ms/batch - loss: 2.66442 - diff: 41.66mlTrain batch 32/32 - 16.0s 53.2ms/batch - loss: 2.66442 - diff: 41.66ml
Test 1.5s: val_loss: 2.59240 - diff: 39.90ml

Epoch 16: current best loss = 2.55994, at epoch 14
Train batch 1/32 - 172.9ms/batch - loss: 2.02853 - diff: 32.46mlTrain batch 2/32 - 173.5ms/batch - loss: 2.29674 - diff: 36.75mlTrain batch 3/32 - 173.1ms/batch - loss: 2.12235 - diff: 33.96mlTrain batch 4/32 - 173.3ms/batch - loss: 2.09139 - diff: 33.46mlTrain batch 5/32 - 173.3ms/batch - loss: 2.27604 - diff: 36.42mlTrain batch 6/32 - 173.0ms/batch - loss: 2.22031 - diff: 35.53mlTrain batch 7/32 - 173.0ms/batch - loss: 2.38742 - diff: 38.20mlTrain batch 8/32 - 173.4ms/batch - loss: 2.37957 - diff: 38.07mlTrain batch 9/32 - 187.8ms/batch - loss: 2.48098 - diff: 39.70mlTrain batch 10/32 - 175.2ms/batch - loss: 2.58106 - diff: 41.30mlTrain batch 11/32 - 173.4ms/batch - loss: 2.58762 - diff: 41.40mlTrain batch 12/32 - 173.3ms/batch - loss: 2.59017 - diff: 41.44mlTrain batch 13/32 - 179.2ms/batch - loss: 2.66175 - diff: 42.59mlTrain batch 14/32 - 174.7ms/batch - loss: 2.65316 - diff: 42.45mlTrain batch 15/32 - 179.0ms/batch - loss: 2.66941 - diff: 42.71mlTrain batch 16/32 - 173.2ms/batch - loss: 2.67780 - diff: 42.84mlTrain batch 17/32 - 179.2ms/batch - loss: 2.69038 - diff: 43.05mlTrain batch 18/32 - 173.3ms/batch - loss: 2.65956 - diff: 42.55mlTrain batch 19/32 - 185.1ms/batch - loss: 2.62766 - diff: 42.04mlTrain batch 20/32 - 173.4ms/batch - loss: 2.68350 - diff: 42.94mlTrain batch 21/32 - 177.7ms/batch - loss: 2.67475 - diff: 42.80mlTrain batch 22/32 - 173.5ms/batch - loss: 2.63567 - diff: 42.17mlTrain batch 23/32 - 173.3ms/batch - loss: 2.63128 - diff: 42.10mlTrain batch 24/32 - 173.2ms/batch - loss: 2.60019 - diff: 41.60mlTrain batch 25/32 - 182.9ms/batch - loss: 2.60889 - diff: 41.74mlTrain batch 26/32 - 173.1ms/batch - loss: 2.62045 - diff: 41.93mlTrain batch 27/32 - 176.1ms/batch - loss: 2.60277 - diff: 41.64mlTrain batch 28/32 - 173.0ms/batch - loss: 2.59697 - diff: 41.55mlTrain batch 29/32 - 173.2ms/batch - loss: 2.62439 - diff: 41.99mlTrain batch 30/32 - 173.7ms/batch - loss: 2.60519 - diff: 41.68mlTrain batch 31/32 - 173.1ms/batch - loss: 2.60732 - diff: 41.72mlTrain batch 32/32 - 53.2ms/batch - loss: 2.70445 - diff: 41.86mlTrain batch 32/32 - 16.1s 53.2ms/batch - loss: 2.70445 - diff: 41.86ml
Test 1.5s: val_loss: 2.66491 - diff: 40.76ml

Epoch 17: current best loss = 2.55994, at epoch 14
Train batch 1/32 - 173.0ms/batch - loss: 2.72265 - diff: 43.56mlTrain batch 2/32 - 173.5ms/batch - loss: 2.56494 - diff: 41.04mlTrain batch 3/32 - 173.2ms/batch - loss: 2.51250 - diff: 40.20mlTrain batch 4/32 - 176.6ms/batch - loss: 2.73984 - diff: 43.84mlTrain batch 5/32 - 185.3ms/batch - loss: 2.69366 - diff: 43.10mlTrain batch 6/32 - 173.4ms/batch - loss: 2.62864 - diff: 42.06mlTrain batch 7/32 - 180.7ms/batch - loss: 2.57387 - diff: 41.18mlTrain batch 8/32 - 173.8ms/batch - loss: 2.61210 - diff: 41.79mlTrain batch 9/32 - 173.3ms/batch - loss: 2.64081 - diff: 42.25mlTrain batch 10/32 - 173.8ms/batch - loss: 2.75268 - diff: 44.04mlTrain batch 11/32 - 173.1ms/batch - loss: 2.71572 - diff: 43.45mlTrain batch 12/32 - 203.5ms/batch - loss: 2.70383 - diff: 43.26mlTrain batch 13/32 - 173.2ms/batch - loss: 2.67823 - diff: 42.85mlTrain batch 14/32 - 175.6ms/batch - loss: 2.65412 - diff: 42.47mlTrain batch 15/32 - 173.2ms/batch - loss: 2.64401 - diff: 42.30mlTrain batch 16/32 - 173.8ms/batch - loss: 2.69691 - diff: 43.15mlTrain batch 17/32 - 173.1ms/batch - loss: 2.65043 - diff: 42.41mlTrain batch 18/32 - 173.4ms/batch - loss: 2.64990 - diff: 42.40mlTrain batch 19/32 - 180.4ms/batch - loss: 2.60484 - diff: 41.68mlTrain batch 20/32 - 181.5ms/batch - loss: 2.58450 - diff: 41.35mlTrain batch 21/32 - 173.3ms/batch - loss: 2.57450 - diff: 41.19mlTrain batch 22/32 - 181.4ms/batch - loss: 2.52915 - diff: 40.47mlTrain batch 23/32 - 173.4ms/batch - loss: 2.59140 - diff: 41.46mlTrain batch 24/32 - 177.6ms/batch - loss: 2.58543 - diff: 41.37mlTrain batch 25/32 - 173.2ms/batch - loss: 2.56526 - diff: 41.04mlTrain batch 26/32 - 173.4ms/batch - loss: 2.58087 - diff: 41.29mlTrain batch 27/32 - 173.2ms/batch - loss: 2.57984 - diff: 41.28mlTrain batch 28/32 - 173.6ms/batch - loss: 2.58574 - diff: 41.37mlTrain batch 29/32 - 173.4ms/batch - loss: 2.59917 - diff: 41.59mlTrain batch 30/32 - 173.5ms/batch - loss: 2.61168 - diff: 41.79mlTrain batch 31/32 - 173.2ms/batch - loss: 2.58963 - diff: 41.43mlTrain batch 32/32 - 53.2ms/batch - loss: 2.70888 - diff: 41.66mlTrain batch 32/32 - 16.8s 53.2ms/batch - loss: 2.70888 - diff: 41.66ml
Test 1.4s: val_loss: 2.53768 - diff: 39.39ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_WideResNet50_0_Adam-0.001_MAE_DA3_best

Epoch 18: current best loss = 2.53768, at epoch 17
Train batch 1/32 - 193.6ms/batch - loss: 2.46402 - diff: 39.42mlTrain batch 2/32 - 191.4ms/batch - loss: 2.39285 - diff: 38.29mlTrain batch 3/32 - 174.2ms/batch - loss: 2.39646 - diff: 38.34mlTrain batch 4/32 - 179.8ms/batch - loss: 2.31809 - diff: 37.09mlTrain batch 5/32 - 175.8ms/batch - loss: 2.34941 - diff: 37.59mlTrain batch 6/32 - 173.1ms/batch - loss: 2.50679 - diff: 40.11mlTrain batch 7/32 - 173.3ms/batch - loss: 2.55594 - diff: 40.90mlTrain batch 8/32 - 173.3ms/batch - loss: 2.50873 - diff: 40.14mlTrain batch 9/32 - 172.9ms/batch - loss: 2.46122 - diff: 39.38mlTrain batch 10/32 - 175.6ms/batch - loss: 2.47977 - diff: 39.68mlTrain batch 11/32 - 177.5ms/batch - loss: 2.42272 - diff: 38.76mlTrain batch 12/32 - 184.0ms/batch - loss: 2.50738 - diff: 40.12mlTrain batch 13/32 - 173.0ms/batch - loss: 2.45461 - diff: 39.27mlTrain batch 14/32 - 173.2ms/batch - loss: 2.49678 - diff: 39.95mlTrain batch 15/32 - 174.9ms/batch - loss: 2.44760 - diff: 39.16mlTrain batch 16/32 - 173.2ms/batch - loss: 2.54786 - diff: 40.77mlTrain batch 17/32 - 178.2ms/batch - loss: 2.55743 - diff: 40.92mlTrain batch 18/32 - 173.4ms/batch - loss: 2.54842 - diff: 40.77mlTrain batch 19/32 - 173.1ms/batch - loss: 2.56729 - diff: 41.08mlTrain batch 20/32 - 174.8ms/batch - loss: 2.60849 - diff: 41.74mlTrain batch 21/32 - 179.2ms/batch - loss: 2.59543 - diff: 41.53mlTrain batch 22/32 - 173.2ms/batch - loss: 2.67839 - diff: 42.85mlTrain batch 23/32 - 173.1ms/batch - loss: 2.65132 - diff: 42.42mlTrain batch 24/32 - 176.9ms/batch - loss: 2.60982 - diff: 41.76mlTrain batch 25/32 - 173.3ms/batch - loss: 2.65963 - diff: 42.55mlTrain batch 26/32 - 172.9ms/batch - loss: 2.65237 - diff: 42.44mlTrain batch 27/32 - 182.3ms/batch - loss: 2.61917 - diff: 41.91mlTrain batch 28/32 - 173.1ms/batch - loss: 2.60123 - diff: 41.62mlTrain batch 29/32 - 188.2ms/batch - loss: 2.60198 - diff: 41.63mlTrain batch 30/32 - 177.6ms/batch - loss: 2.60107 - diff: 41.62mlTrain batch 31/32 - 173.4ms/batch - loss: 2.58421 - diff: 41.35mlTrain batch 32/32 - 53.2ms/batch - loss: 2.63917 - diff: 41.32mlTrain batch 32/32 - 17.2s 53.2ms/batch - loss: 2.63917 - diff: 41.32ml
Test 1.4s: val_loss: 2.49235 - diff: 38.65ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_WideResNet50_0_Adam-0.001_MAE_DA3_best

Epoch 19: current best loss = 2.49235, at epoch 18
Train batch 1/32 - 187.1ms/batch - loss: 1.96518 - diff: 31.44mlTrain batch 2/32 - 186.1ms/batch - loss: 2.45102 - diff: 39.22mlTrain batch 3/32 - 173.2ms/batch - loss: 2.47101 - diff: 39.54mlTrain batch 4/32 - 173.6ms/batch - loss: 2.54043 - diff: 40.65mlTrain batch 5/32 - 187.4ms/batch - loss: 2.43671 - diff: 38.99mlTrain batch 6/32 - 179.4ms/batch - loss: 2.57385 - diff: 41.18mlTrain batch 7/32 - 172.9ms/batch - loss: 2.44230 - diff: 39.08mlTrain batch 8/32 - 173.4ms/batch - loss: 2.48481 - diff: 39.76mlTrain batch 9/32 - 173.1ms/batch - loss: 2.52538 - diff: 40.41mlTrain batch 10/32 - 173.1ms/batch - loss: 2.47082 - diff: 39.53mlTrain batch 11/32 - 188.1ms/batch - loss: 2.54417 - diff: 40.71mlTrain batch 12/32 - 174.0ms/batch - loss: 2.57267 - diff: 41.16mlTrain batch 13/32 - 173.3ms/batch - loss: 2.61926 - diff: 41.91mlTrain batch 14/32 - 173.2ms/batch - loss: 2.55604 - diff: 40.90mlTrain batch 15/32 - 173.2ms/batch - loss: 2.57063 - diff: 41.13mlTrain batch 16/32 - 173.5ms/batch - loss: 2.61547 - diff: 41.85mlTrain batch 17/32 - 172.9ms/batch - loss: 2.59926 - diff: 41.59mlTrain batch 18/32 - 173.2ms/batch - loss: 2.57567 - diff: 41.21mlTrain batch 19/32 - 175.8ms/batch - loss: 2.55480 - diff: 40.88mlTrain batch 20/32 - 183.8ms/batch - loss: 2.50635 - diff: 40.10mlTrain batch 21/32 - 173.0ms/batch - loss: 2.54463 - diff: 40.71mlTrain batch 22/32 - 177.9ms/batch - loss: 2.55694 - diff: 40.91mlTrain batch 23/32 - 186.5ms/batch - loss: 2.62043 - diff: 41.93mlTrain batch 24/32 - 173.4ms/batch - loss: 2.60546 - diff: 41.69mlTrain batch 25/32 - 173.4ms/batch - loss: 2.58208 - diff: 41.31mlTrain batch 26/32 - 173.7ms/batch - loss: 2.60749 - diff: 41.72mlTrain batch 27/32 - 173.1ms/batch - loss: 2.62238 - diff: 41.96mlTrain batch 28/32 - 186.6ms/batch - loss: 2.59258 - diff: 41.48mlTrain batch 29/32 - 173.4ms/batch - loss: 2.60483 - diff: 41.68mlTrain batch 30/32 - 173.3ms/batch - loss: 2.63652 - diff: 42.18mlTrain batch 31/32 - 173.2ms/batch - loss: 2.60102 - diff: 41.62mlTrain batch 32/32 - 53.3ms/batch - loss: 2.65146 - diff: 41.57mlTrain batch 32/32 - 18.0s 53.3ms/batch - loss: 2.65146 - diff: 41.57ml
Test 1.3s: val_loss: 2.50868 - diff: 38.60ml

Epoch 20: current best loss = 2.49235, at epoch 18
Train batch 1/32 - 172.9ms/batch - loss: 2.93088 - diff: 46.89mlTrain batch 2/32 - 173.5ms/batch - loss: 2.45025 - diff: 39.20mlTrain batch 3/32 - 173.0ms/batch - loss: 2.53542 - diff: 40.57mlTrain batch 4/32 - 177.4ms/batch - loss: 2.48345 - diff: 39.74mlTrain batch 5/32 - 173.0ms/batch - loss: 2.54237 - diff: 40.68mlTrain batch 6/32 - 174.2ms/batch - loss: 2.51869 - diff: 40.30mlTrain batch 7/32 - 186.5ms/batch - loss: 2.58424 - diff: 41.35mlTrain batch 8/32 - 173.3ms/batch - loss: 2.62895 - diff: 42.06mlTrain batch 9/32 - 173.2ms/batch - loss: 2.53604 - diff: 40.58mlTrain batch 10/32 - 187.0ms/batch - loss: 2.59343 - diff: 41.49mlTrain batch 11/32 - 173.2ms/batch - loss: 2.53978 - diff: 40.64mlTrain batch 12/32 - 177.5ms/batch - loss: 2.46990 - diff: 39.52mlTrain batch 13/32 - 173.0ms/batch - loss: 2.59395 - diff: 41.50mlTrain batch 14/32 - 173.4ms/batch - loss: 2.57934 - diff: 41.27mlTrain batch 15/32 - 173.3ms/batch - loss: 2.54736 - diff: 40.76mlTrain batch 16/32 - 191.5ms/batch - loss: 2.58447 - diff: 41.35mlTrain batch 17/32 - 173.1ms/batch - loss: 2.53492 - diff: 40.56mlTrain batch 18/32 - 173.2ms/batch - loss: 2.49499 - diff: 39.92mlTrain batch 19/32 - 173.8ms/batch - loss: 2.48685 - diff: 39.79mlTrain batch 20/32 - 173.6ms/batch - loss: 2.46812 - diff: 39.49mlTrain batch 21/32 - 177.9ms/batch - loss: 2.48282 - diff: 39.73mlTrain batch 22/32 - 173.3ms/batch - loss: 2.50408 - diff: 40.07mlTrain batch 23/32 - 174.8ms/batch - loss: 2.47320 - diff: 39.57mlTrain batch 24/32 - 173.4ms/batch - loss: 2.55002 - diff: 40.80mlTrain batch 25/32 - 173.1ms/batch - loss: 2.60051 - diff: 41.61mlTrain batch 26/32 - 182.7ms/batch - loss: 2.58673 - diff: 41.39mlTrain batch 27/32 - 173.1ms/batch - loss: 2.58365 - diff: 41.34mlTrain batch 28/32 - 173.4ms/batch - loss: 2.55218 - diff: 40.83mlTrain batch 29/32 - 173.1ms/batch - loss: 2.56484 - diff: 41.04mlTrain batch 30/32 - 172.9ms/batch - loss: 2.54548 - diff: 40.73mlTrain batch 31/32 - 179.8ms/batch - loss: 2.54587 - diff: 40.73mlTrain batch 32/32 - 53.1ms/batch - loss: 2.64207 - diff: 40.87mlTrain batch 32/32 - 15.8s 53.1ms/batch - loss: 2.64207 - diff: 40.87ml
Test 1.3s: val_loss: 2.50169 - diff: 38.88ml

Epoch 21: current best loss = 2.49235, at epoch 18
Train batch 1/32 - 178.8ms/batch - loss: 2.52434 - diff: 40.39mlTrain batch 2/32 - 173.6ms/batch - loss: 2.55611 - diff: 40.90mlTrain batch 3/32 - 173.8ms/batch - loss: 2.66892 - diff: 42.70mlTrain batch 4/32 - 173.4ms/batch - loss: 2.63862 - diff: 42.22mlTrain batch 5/32 - 173.0ms/batch - loss: 2.63478 - diff: 42.16mlTrain batch 6/32 - 177.4ms/batch - loss: 2.53270 - diff: 40.52mlTrain batch 7/32 - 173.1ms/batch - loss: 2.49280 - diff: 39.88mlTrain batch 8/32 - 173.0ms/batch - loss: 2.63623 - diff: 42.18mlTrain batch 9/32 - 173.6ms/batch - loss: 2.56270 - diff: 41.00mlTrain batch 10/32 - 199.0ms/batch - loss: 2.47118 - diff: 39.54mlTrain batch 11/32 - 173.2ms/batch - loss: 2.43085 - diff: 38.89mlTrain batch 12/32 - 173.2ms/batch - loss: 2.45952 - diff: 39.35mlTrain batch 13/32 - 173.7ms/batch - loss: 2.45762 - diff: 39.32mlTrain batch 14/32 - 173.2ms/batch - loss: 2.44411 - diff: 39.11mlTrain batch 15/32 - 183.1ms/batch - loss: 2.43769 - diff: 39.00mlTrain batch 16/32 - 174.9ms/batch - loss: 2.47326 - diff: 39.57mlTrain batch 17/32 - 173.0ms/batch - loss: 2.46094 - diff: 39.38mlTrain batch 18/32 - 174.1ms/batch - loss: 2.45295 - diff: 39.25mlTrain batch 19/32 - 173.4ms/batch - loss: 2.51436 - diff: 40.23mlTrain batch 20/32 - 173.0ms/batch - loss: 2.53799 - diff: 40.61mlTrain batch 21/32 - 173.5ms/batch - loss: 2.52940 - diff: 40.47mlTrain batch 22/32 - 173.3ms/batch - loss: 2.54015 - diff: 40.64mlTrain batch 23/32 - 173.4ms/batch - loss: 2.56736 - diff: 41.08mlTrain batch 24/32 - 173.3ms/batch - loss: 2.52861 - diff: 40.46mlTrain batch 25/32 - 173.2ms/batch - loss: 2.48631 - diff: 39.78mlTrain batch 26/32 - 180.4ms/batch - loss: 2.46619 - diff: 39.46mlTrain batch 27/32 - 173.6ms/batch - loss: 2.43820 - diff: 39.01mlTrain batch 28/32 - 173.2ms/batch - loss: 2.42387 - diff: 38.78mlTrain batch 29/32 - 172.9ms/batch - loss: 2.41210 - diff: 38.59mlTrain batch 30/32 - 173.5ms/batch - loss: 2.50967 - diff: 40.15mlTrain batch 31/32 - 177.7ms/batch - loss: 2.50867 - diff: 40.14mlTrain batch 32/32 - 53.2ms/batch - loss: 2.59361 - diff: 40.24mlTrain batch 32/32 - 16.4s 53.2ms/batch - loss: 2.59361 - diff: 40.24ml
Test 1.4s: val_loss: 2.49165 - diff: 38.77ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_WideResNet50_0_Adam-0.001_MAE_DA3_best

Epoch 22: current best loss = 2.49165, at epoch 21
Train batch 1/32 - 181.7ms/batch - loss: 3.18174 - diff: 50.91mlTrain batch 2/32 - 173.7ms/batch - loss: 2.89384 - diff: 46.30mlTrain batch 3/32 - 173.0ms/batch - loss: 2.73452 - diff: 43.75mlTrain batch 4/32 - 173.6ms/batch - loss: 2.60458 - diff: 41.67mlTrain batch 5/32 - 175.6ms/batch - loss: 2.53750 - diff: 40.60mlTrain batch 6/32 - 176.0ms/batch - loss: 2.58265 - diff: 41.32mlTrain batch 7/32 - 175.9ms/batch - loss: 2.53482 - diff: 40.56mlTrain batch 8/32 - 177.7ms/batch - loss: 2.54124 - diff: 40.66mlTrain batch 9/32 - 174.5ms/batch - loss: 2.54837 - diff: 40.77mlTrain batch 10/32 - 173.5ms/batch - loss: 2.54259 - diff: 40.68mlTrain batch 11/32 - 173.2ms/batch - loss: 2.47655 - diff: 39.62mlTrain batch 12/32 - 174.1ms/batch - loss: 2.47249 - diff: 39.56mlTrain batch 13/32 - 173.0ms/batch - loss: 2.50113 - diff: 40.02mlTrain batch 14/32 - 185.9ms/batch - loss: 2.44444 - diff: 39.11mlTrain batch 15/32 - 182.9ms/batch - loss: 2.45386 - diff: 39.26mlTrain batch 16/32 - 175.8ms/batch - loss: 2.48823 - diff: 39.81mlTrain batch 17/32 - 172.9ms/batch - loss: 2.49597 - diff: 39.94mlTrain batch 18/32 - 173.5ms/batch - loss: 2.57244 - diff: 41.16mlTrain batch 19/32 - 173.3ms/batch - loss: 2.56806 - diff: 41.09mlTrain batch 20/32 - 173.5ms/batch - loss: 2.57698 - diff: 41.23mlTrain batch 21/32 - 173.4ms/batch - loss: 2.56056 - diff: 40.97mlTrain batch 22/32 - 179.8ms/batch - loss: 2.55856 - diff: 40.94mlTrain batch 23/32 - 173.2ms/batch - loss: 2.58289 - diff: 41.33mlTrain batch 24/32 - 175.8ms/batch - loss: 2.56221 - diff: 41.00mlTrain batch 25/32 - 173.4ms/batch - loss: 2.57373 - diff: 41.18mlTrain batch 26/32 - 194.5ms/batch - loss: 2.56082 - diff: 40.97mlTrain batch 27/32 - 180.5ms/batch - loss: 2.56100 - diff: 40.98mlTrain batch 28/32 - 173.6ms/batch - loss: 2.60663 - diff: 41.71mlTrain batch 29/32 - 173.4ms/batch - loss: 2.57901 - diff: 41.26mlTrain batch 30/32 - 173.4ms/batch - loss: 2.56652 - diff: 41.06mlTrain batch 31/32 - 173.2ms/batch - loss: 2.57875 - diff: 41.26mlTrain batch 32/32 - 53.2ms/batch - loss: 2.60888 - diff: 41.13mlTrain batch 32/32 - 17.0s 53.2ms/batch - loss: 2.60888 - diff: 41.13ml
Test 1.4s: val_loss: 2.42375 - diff: 37.97ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_WideResNet50_0_Adam-0.001_MAE_DA3_best

Epoch 23: current best loss = 2.42375, at epoch 22
Train batch 1/32 - 192.2ms/batch - loss: 2.29256 - diff: 36.68mlTrain batch 2/32 - 182.8ms/batch - loss: 2.49616 - diff: 39.94mlTrain batch 3/32 - 173.0ms/batch - loss: 2.45057 - diff: 39.21mlTrain batch 4/32 - 173.3ms/batch - loss: 2.24820 - diff: 35.97mlTrain batch 5/32 - 173.0ms/batch - loss: 2.23233 - diff: 35.72mlTrain batch 6/32 - 181.9ms/batch - loss: 2.17146 - diff: 34.74mlTrain batch 7/32 - 187.9ms/batch - loss: 2.38861 - diff: 38.22mlTrain batch 8/32 - 173.7ms/batch - loss: 2.57321 - diff: 41.17mlTrain batch 9/32 - 173.0ms/batch - loss: 2.50177 - diff: 40.03mlTrain batch 10/32 - 188.8ms/batch - loss: 2.54430 - diff: 40.71mlTrain batch 11/32 - 173.2ms/batch - loss: 2.48720 - diff: 39.80mlTrain batch 12/32 - 184.1ms/batch - loss: 2.48932 - diff: 39.83mlTrain batch 13/32 - 172.9ms/batch - loss: 2.55393 - diff: 40.86mlTrain batch 14/32 - 183.7ms/batch - loss: 2.52082 - diff: 40.33mlTrain batch 15/32 - 173.0ms/batch - loss: 2.52451 - diff: 40.39mlTrain batch 16/32 - 173.0ms/batch - loss: 2.47467 - diff: 39.59mlTrain batch 17/32 - 173.4ms/batch - loss: 2.47501 - diff: 39.60mlTrain batch 18/32 - 178.6ms/batch - loss: 2.46260 - diff: 39.40mlTrain batch 19/32 - 173.1ms/batch - loss: 2.45239 - diff: 39.24mlTrain batch 20/32 - 174.7ms/batch - loss: 2.49849 - diff: 39.98mlTrain batch 21/32 - 173.0ms/batch - loss: 2.50860 - diff: 40.14mlTrain batch 22/32 - 173.0ms/batch - loss: 2.52010 - diff: 40.32mlTrain batch 23/32 - 181.7ms/batch - loss: 2.51905 - diff: 40.30mlTrain batch 24/32 - 187.5ms/batch - loss: 2.52499 - diff: 40.40mlTrain batch 25/32 - 181.0ms/batch - loss: 2.53153 - diff: 40.50mlTrain batch 26/32 - 173.3ms/batch - loss: 2.52073 - diff: 40.33mlTrain batch 27/32 - 173.4ms/batch - loss: 2.53443 - diff: 40.55mlTrain batch 28/32 - 180.4ms/batch - loss: 2.55215 - diff: 40.83mlTrain batch 29/32 - 173.2ms/batch - loss: 2.54544 - diff: 40.73mlTrain batch 30/32 - 173.0ms/batch - loss: 2.53099 - diff: 40.50mlTrain batch 31/32 - 173.3ms/batch - loss: 2.52620 - diff: 40.42mlTrain batch 32/32 - 53.2ms/batch - loss: 2.56854 - diff: 40.35mlTrain batch 32/32 - 16.3s 53.2ms/batch - loss: 2.56854 - diff: 40.35ml
Test 1.4s: val_loss: 2.46108 - diff: 38.35ml

Epoch 24: current best loss = 2.42375, at epoch 22
Train batch 1/32 - 173.4ms/batch - loss: 2.56204 - diff: 40.99mlTrain batch 2/32 - 173.5ms/batch - loss: 2.16612 - diff: 34.66mlTrain batch 3/32 - 181.6ms/batch - loss: 2.28053 - diff: 36.49mlTrain batch 4/32 - 186.7ms/batch - loss: 2.26145 - diff: 36.18mlTrain batch 5/32 - 173.3ms/batch - loss: 2.20398 - diff: 35.26mlTrain batch 6/32 - 197.4ms/batch - loss: 2.11874 - diff: 33.90mlTrain batch 7/32 - 178.5ms/batch - loss: 2.27579 - diff: 36.41mlTrain batch 8/32 - 173.1ms/batch - loss: 2.31207 - diff: 36.99mlTrain batch 9/32 - 179.9ms/batch - loss: 2.27265 - diff: 36.36mlTrain batch 10/32 - 188.6ms/batch - loss: 2.31365 - diff: 37.02mlTrain batch 11/32 - 177.5ms/batch - loss: 2.45189 - diff: 39.23mlTrain batch 12/32 - 184.4ms/batch - loss: 2.43828 - diff: 39.01mlTrain batch 13/32 - 173.1ms/batch - loss: 2.38572 - diff: 38.17mlTrain batch 14/32 - 180.1ms/batch - loss: 2.38561 - diff: 38.17mlTrain batch 15/32 - 182.2ms/batch - loss: 2.37345 - diff: 37.98mlTrain batch 16/32 - 179.7ms/batch - loss: 2.47268 - diff: 39.56mlTrain batch 17/32 - 173.0ms/batch - loss: 2.53693 - diff: 40.59mlTrain batch 18/32 - 173.1ms/batch - loss: 2.54722 - diff: 40.76mlTrain batch 19/32 - 187.8ms/batch - loss: 2.55413 - diff: 40.87mlTrain batch 20/32 - 191.9ms/batch - loss: 2.54354 - diff: 40.70mlTrain batch 21/32 - 173.4ms/batch - loss: 2.54005 - diff: 40.64mlTrain batch 22/32 - 173.2ms/batch - loss: 2.58733 - diff: 41.40mlTrain batch 23/32 - 188.7ms/batch - loss: 2.56189 - diff: 40.99mlTrain batch 24/32 - 173.1ms/batch - loss: 2.57491 - diff: 41.20mlTrain batch 25/32 - 180.2ms/batch - loss: 2.57010 - diff: 41.12mlTrain batch 26/32 - 186.5ms/batch - loss: 2.58370 - diff: 41.34mlTrain batch 27/32 - 174.2ms/batch - loss: 2.58646 - diff: 41.38mlTrain batch 28/32 - 174.2ms/batch - loss: 2.60310 - diff: 41.65mlTrain batch 29/32 - 174.6ms/batch - loss: 2.58098 - diff: 41.30mlTrain batch 30/32 - 173.4ms/batch - loss: 2.57262 - diff: 41.16mlTrain batch 31/32 - 173.6ms/batch - loss: 2.57942 - diff: 41.27mlTrain batch 32/32 - 53.3ms/batch - loss: 2.64933 - diff: 41.30mlTrain batch 32/32 - 16.3s 53.3ms/batch - loss: 2.64933 - diff: 41.30ml
Test 1.4s: val_loss: 2.46883 - diff: 37.99ml

Epoch 25: current best loss = 2.42375, at epoch 22
Train batch 1/32 - 176.5ms/batch - loss: 3.13214 - diff: 50.11mlTrain batch 2/32 - 183.8ms/batch - loss: 2.44125 - diff: 39.06mlTrain batch 3/32 - 173.4ms/batch - loss: 2.44430 - diff: 39.11mlTrain batch 4/32 - 173.5ms/batch - loss: 2.54325 - diff: 40.69mlTrain batch 5/32 - 173.4ms/batch - loss: 2.44968 - diff: 39.19mlTrain batch 6/32 - 173.8ms/batch - loss: 2.41225 - diff: 38.60mlTrain batch 7/32 - 173.2ms/batch - loss: 2.44274 - diff: 39.08mlTrain batch 8/32 - 173.6ms/batch - loss: 2.48145 - diff: 39.70mlTrain batch 9/32 - 176.1ms/batch - loss: 2.37522 - diff: 38.00mlTrain batch 10/32 - 173.4ms/batch - loss: 2.42229 - diff: 38.76mlTrain batch 11/32 - 173.5ms/batch - loss: 2.44900 - diff: 39.18mlTrain batch 12/32 - 173.2ms/batch - loss: 2.59218 - diff: 41.47mlTrain batch 13/32 - 173.3ms/batch - loss: 2.50934 - diff: 40.15mlTrain batch 14/32 - 173.2ms/batch - loss: 2.51713 - diff: 40.27mlTrain batch 15/32 - 189.1ms/batch - loss: 2.49157 - diff: 39.87mlTrain batch 16/32 - 174.5ms/batch - loss: 2.42619 - diff: 38.82mlTrain batch 17/32 - 173.4ms/batch - loss: 2.39736 - diff: 38.36mlTrain batch 18/32 - 187.2ms/batch - loss: 2.40025 - diff: 38.40mlTrain batch 19/32 - 173.4ms/batch - loss: 2.36148 - diff: 37.78mlTrain batch 20/32 - 173.9ms/batch - loss: 2.43699 - diff: 38.99mlTrain batch 21/32 - 173.3ms/batch - loss: 2.42195 - diff: 38.75mlTrain batch 22/32 - 173.9ms/batch - loss: 2.43469 - diff: 38.95mlTrain batch 23/32 - 173.3ms/batch - loss: 2.42675 - diff: 38.83mlTrain batch 24/32 - 173.5ms/batch - loss: 2.42601 - diff: 38.82mlTrain batch 25/32 - 173.1ms/batch - loss: 2.41291 - diff: 38.61mlTrain batch 26/32 - 173.5ms/batch - loss: 2.43485 - diff: 38.96mlTrain batch 27/32 - 187.6ms/batch - loss: 2.45032 - diff: 39.21mlTrain batch 28/32 - 175.9ms/batch - loss: 2.47061 - diff: 39.53mlTrain batch 29/32 - 177.4ms/batch - loss: 2.47767 - diff: 39.64mlTrain batch 30/32 - 173.7ms/batch - loss: 2.47521 - diff: 39.60mlTrain batch 31/32 - 173.5ms/batch - loss: 2.50065 - diff: 40.01mlTrain batch 32/32 - 53.2ms/batch - loss: 2.59384 - diff: 40.14mlTrain batch 32/32 - 16.9s 53.2ms/batch - loss: 2.59384 - diff: 40.14ml
Test 1.3s: val_loss: 2.49843 - diff: 38.36ml

Epoch 26: current best loss = 2.42375, at epoch 22
Train batch 1/32 - 173.3ms/batch - loss: 2.56453 - diff: 41.03mlTrain batch 2/32 - 182.3ms/batch - loss: 2.36996 - diff: 37.92mlTrain batch 3/32 - 185.2ms/batch - loss: 2.18014 - diff: 34.88mlTrain batch 4/32 - 173.5ms/batch - loss: 2.08526 - diff: 33.36mlTrain batch 5/32 - 187.4ms/batch - loss: 2.36467 - diff: 37.83mlTrain batch 6/32 - 177.5ms/batch - loss: 2.33830 - diff: 37.41mlTrain batch 7/32 - 173.3ms/batch - loss: 2.27318 - diff: 36.37mlTrain batch 8/32 - 177.1ms/batch - loss: 2.51684 - diff: 40.27mlTrain batch 9/32 - 172.9ms/batch - loss: 2.45185 - diff: 39.23mlTrain batch 10/32 - 173.6ms/batch - loss: 2.49464 - diff: 39.91mlTrain batch 11/32 - 179.0ms/batch - loss: 2.55625 - diff: 40.90mlTrain batch 12/32 - 173.6ms/batch - loss: 2.54954 - diff: 40.79mlTrain batch 13/32 - 173.3ms/batch - loss: 2.54371 - diff: 40.70mlTrain batch 14/32 - 173.7ms/batch - loss: 2.58484 - diff: 41.36mlTrain batch 15/32 - 173.4ms/batch - loss: 2.56085 - diff: 40.97mlTrain batch 16/32 - 173.8ms/batch - loss: 2.55007 - diff: 40.80mlTrain batch 17/32 - 173.8ms/batch - loss: 2.51954 - diff: 40.31mlTrain batch 18/32 - 173.5ms/batch - loss: 2.50460 - diff: 40.07mlTrain batch 19/32 - 173.4ms/batch - loss: 2.49390 - diff: 39.90mlTrain batch 20/32 - 176.7ms/batch - loss: 2.52865 - diff: 40.46mlTrain batch 21/32 - 173.3ms/batch - loss: 2.53021 - diff: 40.48mlTrain batch 22/32 - 173.2ms/batch - loss: 2.57418 - diff: 41.19mlTrain batch 23/32 - 176.1ms/batch - loss: 2.55677 - diff: 40.91mlTrain batch 24/32 - 179.0ms/batch - loss: 2.54385 - diff: 40.70mlTrain batch 25/32 - 174.1ms/batch - loss: 2.55679 - diff: 40.91mlTrain batch 26/32 - 178.2ms/batch - loss: 2.53508 - diff: 40.56mlTrain batch 27/32 - 173.3ms/batch - loss: 2.51383 - diff: 40.22mlTrain batch 28/32 - 173.4ms/batch - loss: 2.52798 - diff: 40.45mlTrain batch 29/32 - 182.0ms/batch - loss: 2.52208 - diff: 40.35mlTrain batch 30/32 - 175.9ms/batch - loss: 2.50874 - diff: 40.14mlTrain batch 31/32 - 173.4ms/batch - loss: 2.50136 - diff: 40.02mlTrain batch 32/32 - 53.2ms/batch - loss: 2.55402 - diff: 39.99mlTrain batch 32/32 - 15.6s 53.2ms/batch - loss: 2.55402 - diff: 39.99ml
Test 1.5s: val_loss: 2.49627 - diff: 37.71ml

Epoch 27: current best loss = 2.42375, at epoch 22
Train batch 1/32 - 181.8ms/batch - loss: 1.72591 - diff: 27.61mlTrain batch 2/32 - 173.8ms/batch - loss: 1.76516 - diff: 28.24mlTrain batch 3/32 - 173.4ms/batch - loss: 2.16175 - diff: 34.59mlTrain batch 4/32 - 173.5ms/batch - loss: 2.14903 - diff: 34.38mlTrain batch 5/32 - 181.5ms/batch - loss: 2.01897 - diff: 32.30mlTrain batch 6/32 - 173.2ms/batch - loss: 2.07881 - diff: 33.26mlTrain batch 7/32 - 173.3ms/batch - loss: 2.25523 - diff: 36.08mlTrain batch 8/32 - 173.6ms/batch - loss: 2.29211 - diff: 36.67mlTrain batch 9/32 - 173.3ms/batch - loss: 2.35545 - diff: 37.69mlTrain batch 10/32 - 173.8ms/batch - loss: 2.37096 - diff: 37.94mlTrain batch 11/32 - 173.3ms/batch - loss: 2.49317 - diff: 39.89mlTrain batch 12/32 - 173.7ms/batch - loss: 2.47273 - diff: 39.56mlTrain batch 13/32 - 177.0ms/batch - loss: 2.47090 - diff: 39.53mlTrain batch 14/32 - 173.5ms/batch - loss: 2.43095 - diff: 38.90mlTrain batch 15/32 - 189.4ms/batch - loss: 2.40102 - diff: 38.42mlTrain batch 16/32 - 173.5ms/batch - loss: 2.42010 - diff: 38.72mlTrain batch 17/32 - 176.6ms/batch - loss: 2.40965 - diff: 38.55mlTrain batch 18/32 - 179.8ms/batch - loss: 2.36703 - diff: 37.87mlTrain batch 19/32 - 173.4ms/batch - loss: 2.40530 - diff: 38.48mlTrain batch 20/32 - 174.6ms/batch - loss: 2.35603 - diff: 37.70mlTrain batch 21/32 - 173.2ms/batch - loss: 2.37914 - diff: 38.07mlTrain batch 22/32 - 187.5ms/batch - loss: 2.36429 - diff: 37.83mlTrain batch 23/32 - 189.9ms/batch - loss: 2.39916 - diff: 38.39mlTrain batch 24/32 - 173.8ms/batch - loss: 2.39177 - diff: 38.27mlTrain batch 25/32 - 173.3ms/batch - loss: 2.39387 - diff: 38.30mlTrain batch 26/32 - 173.6ms/batch - loss: 2.38215 - diff: 38.11mlTrain batch 27/32 - 173.1ms/batch - loss: 2.36696 - diff: 37.87mlTrain batch 28/32 - 174.0ms/batch - loss: 2.38419 - diff: 38.15mlTrain batch 29/32 - 173.7ms/batch - loss: 2.40015 - diff: 38.40mlTrain batch 30/32 - 173.7ms/batch - loss: 2.40339 - diff: 38.45mlTrain batch 31/32 - 183.3ms/batch - loss: 2.46244 - diff: 39.40mlTrain batch 32/32 - 53.6ms/batch - loss: 2.52239 - diff: 39.40mlTrain batch 32/32 - 16.3s 53.6ms/batch - loss: 2.52239 - diff: 39.40ml
Test 1.3s: val_loss: 2.45540 - diff: 37.15ml

Epoch 28: current best loss = 2.42375, at epoch 22
Train batch 1/32 - 173.4ms/batch - loss: 1.96690 - diff: 31.47mlTrain batch 2/32 - 173.8ms/batch - loss: 1.77103 - diff: 28.34mlTrain batch 3/32 - 204.6ms/batch - loss: 2.30522 - diff: 36.88mlTrain batch 4/32 - 173.9ms/batch - loss: 2.35960 - diff: 37.75mlTrain batch 5/32 - 196.1ms/batch - loss: 2.32573 - diff: 37.21mlTrain batch 6/32 - 173.5ms/batch - loss: 2.27941 - diff: 36.47mlTrain batch 7/32 - 173.4ms/batch - loss: 2.33216 - diff: 37.31mlTrain batch 8/32 - 188.8ms/batch - loss: 2.24783 - diff: 35.97mlTrain batch 9/32 - 173.4ms/batch - loss: 2.26304 - diff: 36.21mlTrain batch 10/32 - 193.3ms/batch - loss: 2.27230 - diff: 36.36mlTrain batch 11/32 - 173.5ms/batch - loss: 2.28662 - diff: 36.59mlTrain batch 12/32 - 173.6ms/batch - loss: 2.26299 - diff: 36.21mlTrain batch 13/32 - 173.4ms/batch - loss: 2.32239 - diff: 37.16mlTrain batch 14/32 - 173.2ms/batch - loss: 2.57114 - diff: 41.14mlTrain batch 15/32 - 173.2ms/batch - loss: 2.54035 - diff: 40.65mlTrain batch 16/32 - 173.4ms/batch - loss: 2.51018 - diff: 40.16mlTrain batch 17/32 - 173.2ms/batch - loss: 2.52779 - diff: 40.44mlTrain batch 18/32 - 173.6ms/batch - loss: 2.51192 - diff: 40.19mlTrain batch 19/32 - 173.3ms/batch - loss: 2.49630 - diff: 39.94mlTrain batch 20/32 - 176.9ms/batch - loss: 2.50192 - diff: 40.03mlTrain batch 21/32 - 188.9ms/batch - loss: 2.51711 - diff: 40.27mlTrain batch 22/32 - 179.6ms/batch - loss: 2.52149 - diff: 40.34mlTrain batch 23/32 - 173.3ms/batch - loss: 2.49584 - diff: 39.93mlTrain batch 24/32 - 173.8ms/batch - loss: 2.53932 - diff: 40.63mlTrain batch 25/32 - 178.7ms/batch - loss: 2.52925 - diff: 40.47mlTrain batch 26/32 - 173.6ms/batch - loss: 2.52641 - diff: 40.42mlTrain batch 27/32 - 177.1ms/batch - loss: 2.53328 - diff: 40.53mlTrain batch 28/32 - 173.2ms/batch - loss: 2.51613 - diff: 40.26mlTrain batch 29/32 - 182.1ms/batch - loss: 2.53352 - diff: 40.54mlTrain batch 30/32 - 181.9ms/batch - loss: 2.52981 - diff: 40.48mlTrain batch 31/32 - 173.2ms/batch - loss: 2.50943 - diff: 40.15mlTrain batch 32/32 - 62.7ms/batch - loss: 2.54345 - diff: 40.05mlTrain batch 32/32 - 17.0s 62.7ms/batch - loss: 2.54345 - diff: 40.05ml
Test 1.4s: val_loss: 2.46232 - diff: 37.08ml

Epoch 29: current best loss = 2.42375, at epoch 22
Train batch 1/32 - 173.2ms/batch - loss: 2.83529 - diff: 45.36mlTrain batch 2/32 - 173.4ms/batch - loss: 3.44872 - diff: 55.18mlTrain batch 3/32 - 173.4ms/batch - loss: 3.60974 - diff: 57.76mlTrain batch 4/32 - 185.0ms/batch - loss: 3.35258 - diff: 53.64mlTrain batch 5/32 - 173.3ms/batch - loss: 3.07498 - diff: 49.20mlTrain batch 6/32 - 173.4ms/batch - loss: 2.91481 - diff: 46.64mlTrain batch 7/32 - 173.3ms/batch - loss: 2.82447 - diff: 45.19mlTrain batch 8/32 - 174.8ms/batch - loss: 2.85216 - diff: 45.63mlTrain batch 9/32 - 187.0ms/batch - loss: 2.91342 - diff: 46.61mlTrain batch 10/32 - 183.6ms/batch - loss: 2.83319 - diff: 45.33mlTrain batch 11/32 - 173.4ms/batch - loss: 2.77765 - diff: 44.44mlTrain batch 12/32 - 173.7ms/batch - loss: 2.86487 - diff: 45.84mlTrain batch 13/32 - 174.2ms/batch - loss: 2.82111 - diff: 45.14mlTrain batch 14/32 - 173.7ms/batch - loss: 2.81299 - diff: 45.01mlTrain batch 15/32 - 173.4ms/batch - loss: 2.74846 - diff: 43.98mlTrain batch 16/32 - 179.7ms/batch - loss: 2.69716 - diff: 43.15mlTrain batch 17/32 - 173.3ms/batch - loss: 2.68181 - diff: 42.91mlTrain batch 18/32 - 188.6ms/batch - loss: 2.65209 - diff: 42.43mlTrain batch 19/32 - 181.7ms/batch - loss: 2.65748 - diff: 42.52mlTrain batch 20/32 - 173.3ms/batch - loss: 2.66168 - diff: 42.59mlTrain batch 21/32 - 179.7ms/batch - loss: 2.61915 - diff: 41.91mlTrain batch 22/32 - 173.4ms/batch - loss: 2.58562 - diff: 41.37mlTrain batch 23/32 - 173.3ms/batch - loss: 2.58666 - diff: 41.39mlTrain batch 24/32 - 173.3ms/batch - loss: 2.58196 - diff: 41.31mlTrain batch 25/32 - 173.4ms/batch - loss: 2.55273 - diff: 40.84mlTrain batch 26/32 - 185.3ms/batch - loss: 2.53568 - diff: 40.57mlTrain batch 27/32 - 173.4ms/batch - loss: 2.54000 - diff: 40.64mlTrain batch 28/32 - 173.6ms/batch - loss: 2.52434 - diff: 40.39mlTrain batch 29/32 - 173.1ms/batch - loss: 2.49927 - diff: 39.99mlTrain batch 30/32 - 175.6ms/batch - loss: 2.49171 - diff: 39.87mlTrain batch 31/32 - 173.2ms/batch - loss: 2.46780 - diff: 39.48mlTrain batch 32/32 - 53.2ms/batch - loss: 2.53496 - diff: 39.52mlTrain batch 32/32 - 17.0s 53.2ms/batch - loss: 2.53496 - diff: 39.52ml
Test 1.2s: val_loss: 2.33541 - diff: 36.23ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_WideResNet50_0_Adam-0.001_MAE_DA3_best

Epoch 30: current best loss = 2.33541, at epoch 29
Train batch 1/32 - 186.9ms/batch - loss: 2.06071 - diff: 32.97mlTrain batch 2/32 - 178.9ms/batch - loss: 2.05960 - diff: 32.95mlTrain batch 3/32 - 181.2ms/batch - loss: 2.27528 - diff: 36.40mlTrain batch 4/32 - 173.5ms/batch - loss: 2.39262 - diff: 38.28mlTrain batch 5/32 - 175.9ms/batch - loss: 2.36574 - diff: 37.85mlTrain batch 6/32 - 173.1ms/batch - loss: 2.54342 - diff: 40.69mlTrain batch 7/32 - 177.6ms/batch - loss: 2.51192 - diff: 40.19mlTrain batch 8/32 - 176.1ms/batch - loss: 2.52496 - diff: 40.40mlTrain batch 9/32 - 173.2ms/batch - loss: 2.52301 - diff: 40.37mlTrain batch 10/32 - 173.4ms/batch - loss: 2.52633 - diff: 40.42mlTrain batch 11/32 - 173.0ms/batch - loss: 2.52974 - diff: 40.48mlTrain batch 12/32 - 184.0ms/batch - loss: 2.51339 - diff: 40.21mlTrain batch 13/32 - 180.4ms/batch - loss: 2.49702 - diff: 39.95mlTrain batch 14/32 - 173.6ms/batch - loss: 2.49688 - diff: 39.95mlTrain batch 15/32 - 173.2ms/batch - loss: 2.45702 - diff: 39.31mlTrain batch 16/32 - 173.6ms/batch - loss: 2.44936 - diff: 39.19mlTrain batch 17/32 - 173.2ms/batch - loss: 2.43781 - diff: 39.01mlTrain batch 18/32 - 174.8ms/batch - loss: 2.41453 - diff: 38.63mlTrain batch 19/32 - 172.9ms/batch - loss: 2.42036 - diff: 38.73mlTrain batch 20/32 - 186.7ms/batch - loss: 2.48105 - diff: 39.70mlTrain batch 21/32 - 173.4ms/batch - loss: 2.45955 - diff: 39.35mlTrain batch 22/32 - 173.7ms/batch - loss: 2.44757 - diff: 39.16mlTrain batch 23/32 - 186.4ms/batch - loss: 2.47650 - diff: 39.62mlTrain batch 24/32 - 173.2ms/batch - loss: 2.48958 - diff: 39.83mlTrain batch 25/32 - 186.0ms/batch - loss: 2.52727 - diff: 40.44mlTrain batch 26/32 - 186.6ms/batch - loss: 2.49866 - diff: 39.98mlTrain batch 27/32 - 186.5ms/batch - loss: 2.48884 - diff: 39.82mlTrain batch 28/32 - 198.2ms/batch - loss: 2.47801 - diff: 39.65mlTrain batch 29/32 - 173.3ms/batch - loss: 2.48731 - diff: 39.80mlTrain batch 30/32 - 173.6ms/batch - loss: 2.46670 - diff: 39.47mlTrain batch 31/32 - 173.3ms/batch - loss: 2.45038 - diff: 39.21mlTrain batch 32/32 - 53.2ms/batch - loss: 2.52549 - diff: 39.27mlTrain batch 32/32 - 16.8s 53.2ms/batch - loss: 2.52549 - diff: 39.27ml
Test 1.3s: val_loss: 2.50295 - diff: 37.23ml

Epoch 31: current best loss = 2.33541, at epoch 29
Train batch 1/32 - 173.4ms/batch - loss: 1.97769 - diff: 31.64mlTrain batch 2/32 - 173.8ms/batch - loss: 2.28494 - diff: 36.56mlTrain batch 3/32 - 188.8ms/batch - loss: 2.65913 - diff: 42.55mlTrain batch 4/32 - 173.6ms/batch - loss: 2.69753 - diff: 43.16mlTrain batch 5/32 - 173.3ms/batch - loss: 2.67742 - diff: 42.84mlTrain batch 6/32 - 173.6ms/batch - loss: 2.62831 - diff: 42.05mlTrain batch 7/32 - 173.6ms/batch - loss: 2.59127 - diff: 41.46mlTrain batch 8/32 - 173.4ms/batch - loss: 2.66271 - diff: 42.60mlTrain batch 9/32 - 180.6ms/batch - loss: 2.62299 - diff: 41.97mlTrain batch 10/32 - 173.5ms/batch - loss: 2.59002 - diff: 41.44mlTrain batch 11/32 - 173.1ms/batch - loss: 2.60646 - diff: 41.70mlTrain batch 12/32 - 173.7ms/batch - loss: 2.56111 - diff: 40.98mlTrain batch 13/32 - 183.4ms/batch - loss: 2.53108 - diff: 40.50mlTrain batch 14/32 - 185.6ms/batch - loss: 2.51750 - diff: 40.28mlTrain batch 15/32 - 180.0ms/batch - loss: 2.45231 - diff: 39.24mlTrain batch 16/32 - 173.4ms/batch - loss: 2.43468 - diff: 38.95mlTrain batch 17/32 - 173.3ms/batch - loss: 2.45759 - diff: 39.32mlTrain batch 18/32 - 181.0ms/batch - loss: 2.49608 - diff: 39.94mlTrain batch 19/32 - 180.4ms/batch - loss: 2.51027 - diff: 40.16mlTrain batch 20/32 - 173.2ms/batch - loss: 2.49491 - diff: 39.92mlTrain batch 21/32 - 173.3ms/batch - loss: 2.50949 - diff: 40.15mlTrain batch 22/32 - 173.7ms/batch - loss: 2.51526 - diff: 40.24mlTrain batch 23/32 - 173.3ms/batch - loss: 2.50851 - diff: 40.14mlTrain batch 24/32 - 178.7ms/batch - loss: 2.51975 - diff: 40.32mlTrain batch 25/32 - 173.1ms/batch - loss: 2.51265 - diff: 40.20mlTrain batch 26/32 - 204.6ms/batch - loss: 2.53657 - diff: 40.59mlTrain batch 27/32 - 173.5ms/batch - loss: 2.52726 - diff: 40.44mlTrain batch 28/32 - 173.4ms/batch - loss: 2.48729 - diff: 39.80mlTrain batch 29/32 - 173.2ms/batch - loss: 2.48371 - diff: 39.74mlTrain batch 30/32 - 179.5ms/batch - loss: 2.45955 - diff: 39.35mlTrain batch 31/32 - 173.4ms/batch - loss: 2.47137 - diff: 39.54mlTrain batch 32/32 - 53.3ms/batch - loss: 2.52709 - diff: 39.53mlTrain batch 32/32 - 17.1s 53.3ms/batch - loss: 2.52709 - diff: 39.53ml
Test 1.5s: val_loss: 2.40629 - diff: 36.85ml

Epoch 32: current best loss = 2.33541, at epoch 29
Train batch 1/32 - 173.2ms/batch - loss: 2.36662 - diff: 37.87mlTrain batch 2/32 - 184.6ms/batch - loss: 2.38739 - diff: 38.20mlTrain batch 3/32 - 179.0ms/batch - loss: 2.14815 - diff: 34.37mlTrain batch 4/32 - 183.2ms/batch - loss: 2.40201 - diff: 38.43mlTrain batch 5/32 - 173.1ms/batch - loss: 2.33425 - diff: 37.35mlTrain batch 6/32 - 181.2ms/batch - loss: 2.43369 - diff: 38.94mlTrain batch 7/32 - 173.3ms/batch - loss: 2.56041 - diff: 40.97mlTrain batch 8/32 - 176.5ms/batch - loss: 2.41822 - diff: 38.69mlTrain batch 9/32 - 173.0ms/batch - loss: 2.45937 - diff: 39.35mlTrain batch 10/32 - 192.3ms/batch - loss: 2.45813 - diff: 39.33mlTrain batch 11/32 - 173.2ms/batch - loss: 2.54348 - diff: 40.70mlTrain batch 12/32 - 173.8ms/batch - loss: 2.55895 - diff: 40.94mlTrain batch 13/32 - 173.7ms/batch - loss: 2.54978 - diff: 40.80mlTrain batch 14/32 - 189.6ms/batch - loss: 2.50991 - diff: 40.16mlTrain batch 15/32 - 173.4ms/batch - loss: 2.50661 - diff: 40.11mlTrain batch 16/32 - 183.9ms/batch - loss: 2.48729 - diff: 39.80mlTrain batch 17/32 - 177.8ms/batch - loss: 2.47747 - diff: 39.64mlTrain batch 18/32 - 174.6ms/batch - loss: 2.45732 - diff: 39.32mlTrain batch 19/32 - 183.7ms/batch - loss: 2.45251 - diff: 39.24mlTrain batch 20/32 - 173.3ms/batch - loss: 2.42166 - diff: 38.75mlTrain batch 21/32 - 173.0ms/batch - loss: 2.41352 - diff: 38.62mlTrain batch 22/32 - 173.8ms/batch - loss: 2.40284 - diff: 38.45mlTrain batch 23/32 - 187.9ms/batch - loss: 2.37826 - diff: 38.05mlTrain batch 24/32 - 183.8ms/batch - loss: 2.36831 - diff: 37.89mlTrain batch 25/32 - 175.7ms/batch - loss: 2.38340 - diff: 38.13mlTrain batch 26/32 - 173.4ms/batch - loss: 2.39270 - diff: 38.28mlTrain batch 27/32 - 173.5ms/batch - loss: 2.41040 - diff: 38.57mlTrain batch 28/32 - 173.2ms/batch - loss: 2.40992 - diff: 38.56mlTrain batch 29/32 - 173.0ms/batch - loss: 2.40778 - diff: 38.52mlTrain batch 30/32 - 181.5ms/batch - loss: 2.44904 - diff: 39.18mlTrain batch 31/32 - 173.2ms/batch - loss: 2.46418 - diff: 39.43mlTrain batch 32/32 - 53.1ms/batch - loss: 2.48326 - diff: 39.27mlTrain batch 32/32 - 16.2s 53.1ms/batch - loss: 2.48326 - diff: 39.27ml
Test 1.4s: val_loss: 2.40038 - diff: 37.04ml

Epoch 33: current best loss = 2.33541, at epoch 29
Train batch 1/32 - 173.2ms/batch - loss: 3.31860 - diff: 53.10mlTrain batch 2/32 - 173.4ms/batch - loss: 3.34834 - diff: 53.57mlTrain batch 3/32 - 173.5ms/batch - loss: 3.29142 - diff: 52.66mlTrain batch 4/32 - 173.6ms/batch - loss: 3.23664 - diff: 51.79mlTrain batch 5/32 - 176.2ms/batch - loss: 2.89692 - diff: 46.35mlTrain batch 6/32 - 181.1ms/batch - loss: 2.77094 - diff: 44.33mlTrain batch 7/32 - 180.1ms/batch - loss: 2.69041 - diff: 43.05mlTrain batch 8/32 - 182.5ms/batch - loss: 2.59947 - diff: 41.59mlTrain batch 9/32 - 183.1ms/batch - loss: 2.53576 - diff: 40.57mlTrain batch 10/32 - 172.8ms/batch - loss: 2.46757 - diff: 39.48mlTrain batch 11/32 - 173.2ms/batch - loss: 2.42881 - diff: 38.86mlTrain batch 12/32 - 173.7ms/batch - loss: 2.40896 - diff: 38.54mlTrain batch 13/32 - 179.3ms/batch - loss: 2.42883 - diff: 38.86mlTrain batch 14/32 - 173.1ms/batch - loss: 2.42860 - diff: 38.86mlTrain batch 15/32 - 187.1ms/batch - loss: 2.39299 - diff: 38.29mlTrain batch 16/32 - 173.5ms/batch - loss: 2.42771 - diff: 38.84mlTrain batch 17/32 - 200.1ms/batch - loss: 2.43423 - diff: 38.95mlTrain batch 18/32 - 178.5ms/batch - loss: 2.41049 - diff: 38.57mlTrain batch 19/32 - 173.4ms/batch - loss: 2.40630 - diff: 38.50mlTrain batch 20/32 - 173.5ms/batch - loss: 2.39688 - diff: 38.35mlTrain batch 21/32 - 173.3ms/batch - loss: 2.36813 - diff: 37.89mlTrain batch 22/32 - 173.5ms/batch - loss: 2.39189 - diff: 38.27mlTrain batch 23/32 - 175.8ms/batch - loss: 2.37465 - diff: 37.99mlTrain batch 24/32 - 173.3ms/batch - loss: 2.35179 - diff: 37.63mlTrain batch 25/32 - 173.2ms/batch - loss: 2.34859 - diff: 37.58mlTrain batch 26/32 - 173.5ms/batch - loss: 2.39939 - diff: 38.39mlTrain batch 27/32 - 173.3ms/batch - loss: 2.42828 - diff: 38.85mlTrain batch 28/32 - 173.8ms/batch - loss: 2.42799 - diff: 38.85mlTrain batch 29/32 - 173.2ms/batch - loss: 2.41591 - diff: 38.65mlTrain batch 30/32 - 173.1ms/batch - loss: 2.42952 - diff: 38.87mlTrain batch 31/32 - 173.2ms/batch - loss: 2.46172 - diff: 39.39mlTrain batch 32/32 - 53.3ms/batch - loss: 2.48484 - diff: 39.24mlTrain batch 32/32 - 17.8s 53.3ms/batch - loss: 2.48484 - diff: 39.24ml
Test 1.1s: val_loss: 2.39700 - diff: 36.85ml

Epoch 34: current best loss = 2.33541, at epoch 29
Train batch 1/32 - 185.7ms/batch - loss: 2.33794 - diff: 37.41mlTrain batch 2/32 - 178.4ms/batch - loss: 2.84143 - diff: 45.46mlTrain batch 3/32 - 173.6ms/batch - loss: 2.70414 - diff: 43.27mlTrain batch 4/32 - 173.5ms/batch - loss: 2.57003 - diff: 41.12mlTrain batch 5/32 - 179.8ms/batch - loss: 2.58577 - diff: 41.37mlTrain batch 6/32 - 173.5ms/batch - loss: 2.53305 - diff: 40.53mlTrain batch 7/32 - 173.3ms/batch - loss: 2.53560 - diff: 40.57mlTrain batch 8/32 - 173.4ms/batch - loss: 2.44035 - diff: 39.05mlTrain batch 9/32 - 173.4ms/batch - loss: 2.44371 - diff: 39.10mlTrain batch 10/32 - 175.6ms/batch - loss: 2.53809 - diff: 40.61mlTrain batch 11/32 - 188.9ms/batch - loss: 2.44968 - diff: 39.19mlTrain batch 12/32 - 173.4ms/batch - loss: 2.44636 - diff: 39.14mlTrain batch 13/32 - 176.9ms/batch - loss: 2.48070 - diff: 39.69mlTrain batch 14/32 - 173.4ms/batch - loss: 2.51820 - diff: 40.29mlTrain batch 15/32 - 184.5ms/batch - loss: 2.54572 - diff: 40.73mlTrain batch 16/32 - 174.6ms/batch - loss: 2.58196 - diff: 41.31mlTrain batch 17/32 - 179.2ms/batch - loss: 2.58553 - diff: 41.37mlTrain batch 18/32 - 173.5ms/batch - loss: 2.54139 - diff: 40.66mlTrain batch 19/32 - 173.5ms/batch - loss: 2.48241 - diff: 39.72mlTrain batch 20/32 - 189.9ms/batch - loss: 2.45175 - diff: 39.23mlTrain batch 21/32 - 172.5ms/batch - loss: 2.42956 - diff: 38.87mlTrain batch 22/32 - 181.1ms/batch - loss: 2.43453 - diff: 38.95mlTrain batch 23/32 - 173.6ms/batch - loss: 2.42662 - diff: 38.83mlTrain batch 24/32 - 173.3ms/batch - loss: 2.42401 - diff: 38.78mlTrain batch 25/32 - 175.9ms/batch - loss: 2.42253 - diff: 38.76mlTrain batch 26/32 - 173.5ms/batch - loss: 2.43774 - diff: 39.00mlTrain batch 27/32 - 173.5ms/batch - loss: 2.40788 - diff: 38.53mlTrain batch 28/32 - 174.3ms/batch - loss: 2.40439 - diff: 38.47mlTrain batch 29/32 - 177.8ms/batch - loss: 2.42786 - diff: 38.85mlTrain batch 30/32 - 188.7ms/batch - loss: 2.41757 - diff: 38.68mlTrain batch 31/32 - 177.8ms/batch - loss: 2.43025 - diff: 38.88mlTrain batch 32/32 - 53.2ms/batch - loss: 2.48524 - diff: 38.87mlTrain batch 32/32 - 16.6s 53.2ms/batch - loss: 2.48524 - diff: 38.87ml
Test 1.5s: val_loss: 2.38070 - diff: 37.01ml

Epoch 35: current best loss = 2.33541, at epoch 29
Train batch 1/32 - 173.3ms/batch - loss: 2.44711 - diff: 39.15mlTrain batch 2/32 - 172.9ms/batch - loss: 2.15228 - diff: 34.44mlTrain batch 3/32 - 173.5ms/batch - loss: 2.19663 - diff: 35.15mlTrain batch 4/32 - 173.5ms/batch - loss: 2.22879 - diff: 35.66mlTrain batch 5/32 - 173.3ms/batch - loss: 2.36120 - diff: 37.78mlTrain batch 6/32 - 178.1ms/batch - loss: 2.55670 - diff: 40.91mlTrain batch 7/32 - 173.4ms/batch - loss: 2.52131 - diff: 40.34mlTrain batch 8/32 - 178.6ms/batch - loss: 2.40315 - diff: 38.45mlTrain batch 9/32 - 173.3ms/batch - loss: 2.35887 - diff: 37.74mlTrain batch 10/32 - 173.3ms/batch - loss: 2.33241 - diff: 37.32mlTrain batch 11/32 - 173.4ms/batch - loss: 2.35817 - diff: 37.73mlTrain batch 12/32 - 180.6ms/batch - loss: 2.38573 - diff: 38.17mlTrain batch 13/32 - 173.2ms/batch - loss: 2.39686 - diff: 38.35mlTrain batch 14/32 - 180.8ms/batch - loss: 2.35873 - diff: 37.74mlTrain batch 15/32 - 173.4ms/batch - loss: 2.32073 - diff: 37.13mlTrain batch 16/32 - 187.8ms/batch - loss: 2.31507 - diff: 37.04mlTrain batch 17/32 - 173.1ms/batch - loss: 2.27900 - diff: 36.46mlTrain batch 18/32 - 173.4ms/batch - loss: 2.28406 - diff: 36.54mlTrain batch 19/32 - 173.4ms/batch - loss: 2.26353 - diff: 36.22mlTrain batch 20/32 - 188.9ms/batch - loss: 2.33617 - diff: 37.38mlTrain batch 21/32 - 176.6ms/batch - loss: 2.35274 - diff: 37.64mlTrain batch 22/32 - 173.6ms/batch - loss: 2.35342 - diff: 37.65mlTrain batch 23/32 - 173.3ms/batch - loss: 2.33247 - diff: 37.32mlTrain batch 24/32 - 197.3ms/batch - loss: 2.34014 - diff: 37.44mlTrain batch 25/32 - 173.5ms/batch - loss: 2.36887 - diff: 37.90mlTrain batch 26/32 - 175.5ms/batch - loss: 2.39113 - diff: 38.26mlTrain batch 27/32 - 181.3ms/batch - loss: 2.41870 - diff: 38.70mlTrain batch 28/32 - 173.3ms/batch - loss: 2.39959 - diff: 38.39mlTrain batch 29/32 - 173.2ms/batch - loss: 2.40889 - diff: 38.54mlTrain batch 30/32 - 173.4ms/batch - loss: 2.40856 - diff: 38.54mlTrain batch 31/32 - 173.3ms/batch - loss: 2.41128 - diff: 38.58mlTrain batch 32/32 - 53.1ms/batch - loss: 2.51471 - diff: 38.76mlTrain batch 32/32 - 17.7s 53.1ms/batch - loss: 2.51471 - diff: 38.76ml
Test 1.4s: val_loss: 2.30207 - diff: 35.58ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_WideResNet50_0_Adam-0.001_MAE_DA3_best

Epoch 36: current best loss = 2.30207, at epoch 35
Train batch 1/32 - 188.1ms/batch - loss: 3.63244 - diff: 58.12mlTrain batch 2/32 - 176.8ms/batch - loss: 3.56798 - diff: 57.09mlTrain batch 3/32 - 173.2ms/batch - loss: 3.01909 - diff: 48.31mlTrain batch 4/32 - 179.8ms/batch - loss: 2.72712 - diff: 43.63mlTrain batch 5/32 - 176.2ms/batch - loss: 2.48031 - diff: 39.69mlTrain batch 6/32 - 180.3ms/batch - loss: 2.44632 - diff: 39.14mlTrain batch 7/32 - 173.4ms/batch - loss: 2.62003 - diff: 41.92mlTrain batch 8/32 - 180.9ms/batch - loss: 2.54074 - diff: 40.65mlTrain batch 9/32 - 180.0ms/batch - loss: 2.56042 - diff: 40.97mlTrain batch 10/32 - 178.5ms/batch - loss: 2.61011 - diff: 41.76mlTrain batch 11/32 - 179.9ms/batch - loss: 2.64348 - diff: 42.30mlTrain batch 12/32 - 188.5ms/batch - loss: 2.64874 - diff: 42.38mlTrain batch 13/32 - 173.2ms/batch - loss: 2.61230 - diff: 41.80mlTrain batch 14/32 - 173.5ms/batch - loss: 2.61125 - diff: 41.78mlTrain batch 15/32 - 173.5ms/batch - loss: 2.57655 - diff: 41.22mlTrain batch 16/32 - 178.1ms/batch - loss: 2.57230 - diff: 41.16mlTrain batch 17/32 - 173.4ms/batch - loss: 2.51972 - diff: 40.32mlTrain batch 18/32 - 174.1ms/batch - loss: 2.54011 - diff: 40.64mlTrain batch 19/32 - 173.1ms/batch - loss: 2.50530 - diff: 40.08mlTrain batch 20/32 - 178.2ms/batch - loss: 2.47484 - diff: 39.60mlTrain batch 21/32 - 179.8ms/batch - loss: 2.49271 - diff: 39.88mlTrain batch 22/32 - 172.9ms/batch - loss: 2.55585 - diff: 40.89mlTrain batch 23/32 - 180.9ms/batch - loss: 2.54152 - diff: 40.66mlTrain batch 24/32 - 179.3ms/batch - loss: 2.49869 - diff: 39.98mlTrain batch 25/32 - 173.2ms/batch - loss: 2.49066 - diff: 39.85mlTrain batch 26/32 - 173.8ms/batch - loss: 2.50608 - diff: 40.10mlTrain batch 27/32 - 173.4ms/batch - loss: 2.51659 - diff: 40.27mlTrain batch 28/32 - 187.1ms/batch - loss: 2.49282 - diff: 39.89mlTrain batch 29/32 - 173.5ms/batch - loss: 2.46348 - diff: 39.42mlTrain batch 30/32 - 173.6ms/batch - loss: 2.42450 - diff: 38.79mlTrain batch 31/32 - 173.4ms/batch - loss: 2.45768 - diff: 39.32mlTrain batch 32/32 - 56.2ms/batch - loss: 2.56999 - diff: 39.54mlTrain batch 32/32 - 17.4s 56.2ms/batch - loss: 2.56999 - diff: 39.54ml
Test 1.3s: val_loss: 2.41744 - diff: 37.02ml

Epoch 37: current best loss = 2.30207, at epoch 35
Train batch 1/32 - 188.1ms/batch - loss: 2.23048 - diff: 35.69mlTrain batch 2/32 - 174.1ms/batch - loss: 2.44530 - diff: 39.12mlTrain batch 3/32 - 173.4ms/batch - loss: 2.25340 - diff: 36.05mlTrain batch 4/32 - 173.7ms/batch - loss: 2.25544 - diff: 36.09mlTrain batch 5/32 - 186.1ms/batch - loss: 2.23402 - diff: 35.74mlTrain batch 6/32 - 199.7ms/batch - loss: 2.36710 - diff: 37.87mlTrain batch 7/32 - 173.3ms/batch - loss: 2.29243 - diff: 36.68mlTrain batch 8/32 - 173.1ms/batch - loss: 2.27892 - diff: 36.46mlTrain batch 9/32 - 173.3ms/batch - loss: 2.38438 - diff: 38.15mlTrain batch 10/32 - 179.4ms/batch - loss: 2.44133 - diff: 39.06mlTrain batch 11/32 - 173.4ms/batch - loss: 2.47172 - diff: 39.55mlTrain batch 12/32 - 173.0ms/batch - loss: 2.49551 - diff: 39.93mlTrain batch 13/32 - 173.3ms/batch - loss: 2.40859 - diff: 38.54mlTrain batch 14/32 - 188.0ms/batch - loss: 2.40271 - diff: 38.44mlTrain batch 15/32 - 173.4ms/batch - loss: 2.35033 - diff: 37.61mlTrain batch 16/32 - 181.4ms/batch - loss: 2.36544 - diff: 37.85mlTrain batch 17/32 - 180.5ms/batch - loss: 2.33537 - diff: 37.37mlTrain batch 18/32 - 176.2ms/batch - loss: 2.36481 - diff: 37.84mlTrain batch 19/32 - 173.4ms/batch - loss: 2.34427 - diff: 37.51mlTrain batch 20/32 - 173.7ms/batch - loss: 2.34370 - diff: 37.50mlTrain batch 21/32 - 173.3ms/batch - loss: 2.33042 - diff: 37.29mlTrain batch 22/32 - 176.9ms/batch - loss: 2.32279 - diff: 37.16mlTrain batch 23/32 - 182.9ms/batch - loss: 2.40435 - diff: 38.47mlTrain batch 24/32 - 188.2ms/batch - loss: 2.38690 - diff: 38.19mlTrain batch 25/32 - 187.2ms/batch - loss: 2.36296 - diff: 37.81mlTrain batch 26/32 - 173.2ms/batch - loss: 2.41154 - diff: 38.58mlTrain batch 27/32 - 187.8ms/batch - loss: 2.40518 - diff: 38.48mlTrain batch 28/32 - 173.2ms/batch - loss: 2.42033 - diff: 38.73mlTrain batch 29/32 - 176.2ms/batch - loss: 2.41679 - diff: 38.67mlTrain batch 30/32 - 173.4ms/batch - loss: 2.40321 - diff: 38.45mlTrain batch 31/32 - 173.3ms/batch - loss: 2.41158 - diff: 38.59mlTrain batch 32/32 - 53.1ms/batch - loss: 2.48521 - diff: 38.65mlTrain batch 32/32 - 17.7s 53.1ms/batch - loss: 2.48521 - diff: 38.65ml
Test 1.3s: val_loss: 2.29248 - diff: 35.45ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_WideResNet50_0_Adam-0.001_MAE_DA3_best

Epoch 38: current best loss = 2.29248, at epoch 37
Train batch 1/32 - 188.1ms/batch - loss: 2.51942 - diff: 40.31mlTrain batch 2/32 - 188.6ms/batch - loss: 2.05299 - diff: 32.85mlTrain batch 3/32 - 172.8ms/batch - loss: 2.53466 - diff: 40.55mlTrain batch 4/32 - 173.5ms/batch - loss: 2.36611 - diff: 37.86mlTrain batch 5/32 - 173.3ms/batch - loss: 2.33329 - diff: 37.33mlTrain batch 6/32 - 173.4ms/batch - loss: 2.51088 - diff: 40.17mlTrain batch 7/32 - 174.0ms/batch - loss: 2.55574 - diff: 40.89mlTrain batch 8/32 - 173.7ms/batch - loss: 2.59343 - diff: 41.49mlTrain batch 9/32 - 175.6ms/batch - loss: 2.45044 - diff: 39.21mlTrain batch 10/32 - 173.9ms/batch - loss: 2.40261 - diff: 38.44mlTrain batch 11/32 - 173.3ms/batch - loss: 2.37834 - diff: 38.05mlTrain batch 12/32 - 184.6ms/batch - loss: 2.36559 - diff: 37.85mlTrain batch 13/32 - 173.3ms/batch - loss: 2.38208 - diff: 38.11mlTrain batch 14/32 - 189.2ms/batch - loss: 2.42287 - diff: 38.77mlTrain batch 15/32 - 180.0ms/batch - loss: 2.41304 - diff: 38.61mlTrain batch 16/32 - 175.5ms/batch - loss: 2.37111 - diff: 37.94mlTrain batch 17/32 - 173.3ms/batch - loss: 2.38716 - diff: 38.19mlTrain batch 18/32 - 173.0ms/batch - loss: 2.44933 - diff: 39.19mlTrain batch 19/32 - 173.6ms/batch - loss: 2.44821 - diff: 39.17mlTrain batch 20/32 - 186.2ms/batch - loss: 2.47767 - diff: 39.64mlTrain batch 21/32 - 183.2ms/batch - loss: 2.43791 - diff: 39.01mlTrain batch 22/32 - 183.4ms/batch - loss: 2.40304 - diff: 38.45mlTrain batch 23/32 - 173.3ms/batch - loss: 2.41220 - diff: 38.60mlTrain batch 24/32 - 173.5ms/batch - loss: 2.40157 - diff: 38.43mlTrain batch 25/32 - 173.1ms/batch - loss: 2.42055 - diff: 38.73mlTrain batch 26/32 - 173.8ms/batch - loss: 2.43115 - diff: 38.90mlTrain batch 27/32 - 173.3ms/batch - loss: 2.44536 - diff: 39.13mlTrain batch 28/32 - 173.3ms/batch - loss: 2.41802 - diff: 38.69mlTrain batch 29/32 - 173.2ms/batch - loss: 2.40333 - diff: 38.45mlTrain batch 30/32 - 173.6ms/batch - loss: 2.37923 - diff: 38.07mlTrain batch 31/32 - 173.4ms/batch - loss: 2.37884 - diff: 38.06mlTrain batch 32/32 - 53.3ms/batch - loss: 2.44605 - diff: 38.10mlTrain batch 32/32 - 17.7s 53.3ms/batch - loss: 2.44605 - diff: 38.10ml
Test 1.4s: val_loss: 2.35605 - diff: 36.33ml

Epoch 39: current best loss = 2.29248, at epoch 37
Train batch 1/32 - 173.1ms/batch - loss: 1.76009 - diff: 28.16mlTrain batch 2/32 - 173.8ms/batch - loss: 2.78214 - diff: 44.51mlTrain batch 3/32 - 183.5ms/batch - loss: 2.79689 - diff: 44.75mlTrain batch 4/32 - 175.7ms/batch - loss: 3.03993 - diff: 48.64mlTrain batch 5/32 - 173.2ms/batch - loss: 2.75401 - diff: 44.06mlTrain batch 6/32 - 173.4ms/batch - loss: 2.73809 - diff: 43.81mlTrain batch 7/32 - 188.4ms/batch - loss: 2.65401 - diff: 42.46mlTrain batch 8/32 - 173.6ms/batch - loss: 2.57725 - diff: 41.24mlTrain batch 9/32 - 187.9ms/batch - loss: 2.54155 - diff: 40.66mlTrain batch 10/32 - 173.3ms/batch - loss: 2.47426 - diff: 39.59mlTrain batch 11/32 - 173.4ms/batch - loss: 2.45995 - diff: 39.36mlTrain batch 12/32 - 176.6ms/batch - loss: 2.48722 - diff: 39.80mlTrain batch 13/32 - 173.2ms/batch - loss: 2.50654 - diff: 40.10mlTrain batch 14/32 - 173.2ms/batch - loss: 2.50806 - diff: 40.13mlTrain batch 15/32 - 195.2ms/batch - loss: 2.49110 - diff: 39.86mlTrain batch 16/32 - 173.6ms/batch - loss: 2.53437 - diff: 40.55mlTrain batch 17/32 - 173.2ms/batch - loss: 2.52169 - diff: 40.35mlTrain batch 18/32 - 173.4ms/batch - loss: 2.55717 - diff: 40.91mlTrain batch 19/32 - 173.3ms/batch - loss: 2.53464 - diff: 40.55mlTrain batch 20/32 - 173.8ms/batch - loss: 2.53628 - diff: 40.58mlTrain batch 21/32 - 183.0ms/batch - loss: 2.52627 - diff: 40.42mlTrain batch 22/32 - 173.5ms/batch - loss: 2.51162 - diff: 40.19mlTrain batch 23/32 - 186.9ms/batch - loss: 2.48092 - diff: 39.69mlTrain batch 24/32 - 173.7ms/batch - loss: 2.45737 - diff: 39.32mlTrain batch 25/32 - 178.8ms/batch - loss: 2.43679 - diff: 38.99mlTrain batch 26/32 - 177.8ms/batch - loss: 2.43045 - diff: 38.89mlTrain batch 27/32 - 173.5ms/batch - loss: 2.43536 - diff: 38.97mlTrain batch 28/32 - 173.5ms/batch - loss: 2.40882 - diff: 38.54mlTrain batch 29/32 - 178.1ms/batch - loss: 2.39958 - diff: 38.39mlTrain batch 30/32 - 173.4ms/batch - loss: 2.37071 - diff: 37.93mlTrain batch 31/32 - 179.4ms/batch - loss: 2.37777 - diff: 38.04mlTrain batch 32/32 - 53.4ms/batch - loss: 2.41804 - diff: 37.98mlTrain batch 32/32 - 16.8s 53.4ms/batch - loss: 2.41804 - diff: 37.98ml
Test 1.3s: val_loss: 2.28546 - diff: 35.41ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_WideResNet50_0_Adam-0.001_MAE_DA3_best

Epoch 40: current best loss = 2.28546, at epoch 39
Train batch 1/32 - 193.0ms/batch - loss: 2.51831 - diff: 40.29mlTrain batch 2/32 - 183.0ms/batch - loss: 2.49653 - diff: 39.94mlTrain batch 3/32 - 190.8ms/batch - loss: 2.31213 - diff: 36.99mlTrain batch 4/32 - 173.5ms/batch - loss: 2.34738 - diff: 37.56mlTrain batch 5/32 - 182.7ms/batch - loss: 2.41880 - diff: 38.70mlTrain batch 6/32 - 176.0ms/batch - loss: 2.39516 - diff: 38.32mlTrain batch 7/32 - 186.5ms/batch - loss: 2.44145 - diff: 39.06mlTrain batch 8/32 - 173.3ms/batch - loss: 2.48762 - diff: 39.80mlTrain batch 9/32 - 179.9ms/batch - loss: 2.48958 - diff: 39.83mlTrain batch 10/32 - 173.4ms/batch - loss: 2.52219 - diff: 40.36mlTrain batch 11/32 - 173.4ms/batch - loss: 2.45506 - diff: 39.28mlTrain batch 12/32 - 173.2ms/batch - loss: 2.47453 - diff: 39.59mlTrain batch 13/32 - 173.3ms/batch - loss: 2.44387 - diff: 39.10mlTrain batch 14/32 - 173.1ms/batch - loss: 2.42095 - diff: 38.74mlTrain batch 15/32 - 173.5ms/batch - loss: 2.40459 - diff: 38.47mlTrain batch 16/32 - 177.6ms/batch - loss: 2.40829 - diff: 38.53mlTrain batch 17/32 - 173.1ms/batch - loss: 2.37845 - diff: 38.06mlTrain batch 18/32 - 173.7ms/batch - loss: 2.35901 - diff: 37.74mlTrain batch 19/32 - 188.7ms/batch - loss: 2.34112 - diff: 37.46mlTrain batch 20/32 - 173.3ms/batch - loss: 2.35152 - diff: 37.62mlTrain batch 21/32 - 173.4ms/batch - loss: 2.33396 - diff: 37.34mlTrain batch 22/32 - 173.5ms/batch - loss: 2.31963 - diff: 37.11mlTrain batch 23/32 - 173.4ms/batch - loss: 2.29745 - diff: 36.76mlTrain batch 24/32 - 173.5ms/batch - loss: 2.30020 - diff: 36.80mlTrain batch 25/32 - 173.2ms/batch - loss: 2.39529 - diff: 38.32mlTrain batch 26/32 - 173.3ms/batch - loss: 2.38513 - diff: 38.16mlTrain batch 27/32 - 173.6ms/batch - loss: 2.38095 - diff: 38.10mlTrain batch 28/32 - 173.3ms/batch - loss: 2.37022 - diff: 37.92mlTrain batch 29/32 - 175.0ms/batch - loss: 2.38210 - diff: 38.11mlTrain batch 30/32 - 190.4ms/batch - loss: 2.36925 - diff: 37.91mlTrain batch 31/32 - 173.4ms/batch - loss: 2.36235 - diff: 37.80mlTrain batch 32/32 - 54.6ms/batch - loss: 2.37894 - diff: 37.64mlTrain batch 32/32 - 16.3s 54.6ms/batch - loss: 2.37894 - diff: 37.64ml
Test 1.4s: val_loss: 2.27774 - diff: 35.21ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_WideResNet50_0_Adam-0.001_MAE_DA3_best

Epoch 41: current best loss = 2.27774, at epoch 40
Train batch 1/32 - 186.2ms/batch - loss: 1.74837 - diff: 27.97mlTrain batch 2/32 - 173.4ms/batch - loss: 1.96437 - diff: 31.43mlTrain batch 3/32 - 178.8ms/batch - loss: 2.09691 - diff: 33.55mlTrain batch 4/32 - 178.4ms/batch - loss: 2.03924 - diff: 32.63mlTrain batch 5/32 - 173.3ms/batch - loss: 2.08239 - diff: 33.32mlTrain batch 6/32 - 180.2ms/batch - loss: 2.04216 - diff: 32.67mlTrain batch 7/32 - 173.3ms/batch - loss: 2.15822 - diff: 34.53mlTrain batch 8/32 - 173.6ms/batch - loss: 2.29010 - diff: 36.64mlTrain batch 9/32 - 182.0ms/batch - loss: 2.28434 - diff: 36.55mlTrain batch 10/32 - 173.5ms/batch - loss: 2.28134 - diff: 36.50mlTrain batch 11/32 - 173.3ms/batch - loss: 2.30203 - diff: 36.83mlTrain batch 12/32 - 173.6ms/batch - loss: 2.26526 - diff: 36.24mlTrain batch 13/32 - 173.2ms/batch - loss: 2.20177 - diff: 35.23mlTrain batch 14/32 - 188.2ms/batch - loss: 2.20623 - diff: 35.30mlTrain batch 15/32 - 173.2ms/batch - loss: 2.25101 - diff: 36.02mlTrain batch 16/32 - 173.5ms/batch - loss: 2.27606 - diff: 36.42mlTrain batch 17/32 - 173.2ms/batch - loss: 2.28266 - diff: 36.52mlTrain batch 18/32 - 173.4ms/batch - loss: 2.29432 - diff: 36.71mlTrain batch 19/32 - 173.3ms/batch - loss: 2.37632 - diff: 38.02mlTrain batch 20/32 - 173.5ms/batch - loss: 2.34814 - diff: 37.57mlTrain batch 21/32 - 173.3ms/batch - loss: 2.40331 - diff: 38.45mlTrain batch 22/32 - 173.7ms/batch - loss: 2.38729 - diff: 38.20mlTrain batch 23/32 - 173.3ms/batch - loss: 2.40226 - diff: 38.44mlTrain batch 24/32 - 173.7ms/batch - loss: 2.41995 - diff: 38.72mlTrain batch 25/32 - 178.9ms/batch - loss: 2.47747 - diff: 39.64mlTrain batch 26/32 - 173.5ms/batch - loss: 2.44233 - diff: 39.08mlTrain batch 27/32 - 173.3ms/batch - loss: 2.43792 - diff: 39.01mlTrain batch 28/32 - 178.0ms/batch - loss: 2.42980 - diff: 38.88mlTrain batch 29/32 - 178.2ms/batch - loss: 2.40383 - diff: 38.46mlTrain batch 30/32 - 178.4ms/batch - loss: 2.39461 - diff: 38.31mlTrain batch 31/32 - 176.3ms/batch - loss: 2.37553 - diff: 38.01mlTrain batch 32/32 - 54.4ms/batch - loss: 2.42617 - diff: 37.98mlTrain batch 32/32 - 18.4s 54.4ms/batch - loss: 2.42617 - diff: 37.98ml
Test 1.4s: val_loss: 2.42020 - diff: 37.39ml

Epoch 42: current best loss = 2.27774, at epoch 40
Train batch 1/32 - 173.4ms/batch - loss: 2.29590 - diff: 36.73mlTrain batch 2/32 - 178.1ms/batch - loss: 2.02599 - diff: 32.42mlTrain batch 3/32 - 173.3ms/batch - loss: 2.31958 - diff: 37.11mlTrain batch 4/32 - 180.8ms/batch - loss: 2.33966 - diff: 37.43mlTrain batch 5/32 - 173.1ms/batch - loss: 2.38615 - diff: 38.18mlTrain batch 6/32 - 173.6ms/batch - loss: 2.64996 - diff: 42.40mlTrain batch 7/32 - 173.4ms/batch - loss: 2.71318 - diff: 43.41mlTrain batch 8/32 - 173.7ms/batch - loss: 2.79958 - diff: 44.79mlTrain batch 9/32 - 184.0ms/batch - loss: 2.75466 - diff: 44.07mlTrain batch 10/32 - 172.7ms/batch - loss: 2.70058 - diff: 43.21mlTrain batch 11/32 - 175.5ms/batch - loss: 2.65007 - diff: 42.40mlTrain batch 12/32 - 183.8ms/batch - loss: 2.60815 - diff: 41.73mlTrain batch 13/32 - 173.2ms/batch - loss: 2.53616 - diff: 40.58mlTrain batch 14/32 - 173.5ms/batch - loss: 2.50611 - diff: 40.10mlTrain batch 15/32 - 173.4ms/batch - loss: 2.45587 - diff: 39.29mlTrain batch 16/32 - 173.6ms/batch - loss: 2.43248 - diff: 38.92mlTrain batch 17/32 - 173.2ms/batch - loss: 2.45167 - diff: 39.23mlTrain batch 18/32 - 174.5ms/batch - loss: 2.41443 - diff: 38.63mlTrain batch 19/32 - 173.4ms/batch - loss: 2.43487 - diff: 38.96mlTrain batch 20/32 - 173.2ms/batch - loss: 2.45899 - diff: 39.34mlTrain batch 21/32 - 217.9ms/batch - loss: 2.48032 - diff: 39.69mlTrain batch 22/32 - 182.4ms/batch - loss: 2.45459 - diff: 39.27mlTrain batch 23/32 - 173.4ms/batch - loss: 2.45752 - diff: 39.32mlTrain batch 24/32 - 172.9ms/batch - loss: 2.45569 - diff: 39.29mlTrain batch 25/32 - 173.3ms/batch - loss: 2.40810 - diff: 38.53mlTrain batch 26/32 - 173.2ms/batch - loss: 2.40778 - diff: 38.52mlTrain batch 27/32 - 173.2ms/batch - loss: 2.41957 - diff: 38.71mlTrain batch 28/32 - 182.1ms/batch - loss: 2.41770 - diff: 38.68mlTrain batch 29/32 - 173.4ms/batch - loss: 2.42229 - diff: 38.76mlTrain batch 30/32 - 173.5ms/batch - loss: 2.43140 - diff: 38.90mlTrain batch 31/32 - 173.3ms/batch - loss: 2.40169 - diff: 38.43mlTrain batch 32/32 - 53.1ms/batch - loss: 2.43961 - diff: 38.35mlTrain batch 32/32 - 18.4s 53.1ms/batch - loss: 2.43961 - diff: 38.35ml
Test 1.4s: val_loss: 2.28956 - diff: 35.32ml

Epoch 43: current best loss = 2.27774, at epoch 40
Train batch 1/32 - 173.1ms/batch - loss: 2.52226 - diff: 40.36mlTrain batch 2/32 - 173.2ms/batch - loss: 2.40585 - diff: 38.49mlTrain batch 3/32 - 173.2ms/batch - loss: 2.62587 - diff: 42.01mlTrain batch 4/32 - 173.7ms/batch - loss: 2.48893 - diff: 39.82mlTrain batch 5/32 - 173.3ms/batch - loss: 2.33728 - diff: 37.40mlTrain batch 6/32 - 173.7ms/batch - loss: 2.31905 - diff: 37.10mlTrain batch 7/32 - 180.8ms/batch - loss: 2.38345 - diff: 38.14mlTrain batch 8/32 - 177.0ms/batch - loss: 2.45409 - diff: 39.27mlTrain batch 9/32 - 173.3ms/batch - loss: 2.51085 - diff: 40.17mlTrain batch 10/32 - 173.4ms/batch - loss: 2.50503 - diff: 40.08mlTrain batch 11/32 - 173.4ms/batch - loss: 2.55409 - diff: 40.87mlTrain batch 12/32 - 179.8ms/batch - loss: 2.50292 - diff: 40.05mlTrain batch 13/32 - 179.5ms/batch - loss: 2.47766 - diff: 39.64mlTrain batch 14/32 - 173.3ms/batch - loss: 2.52520 - diff: 40.40mlTrain batch 15/32 - 195.5ms/batch - loss: 2.51924 - diff: 40.31mlTrain batch 16/32 - 173.5ms/batch - loss: 2.48044 - diff: 39.69mlTrain batch 17/32 - 206.2ms/batch - loss: 2.42959 - diff: 38.87mlTrain batch 18/32 - 178.1ms/batch - loss: 2.44594 - diff: 39.13mlTrain batch 19/32 - 173.2ms/batch - loss: 2.43974 - diff: 39.04mlTrain batch 20/32 - 181.3ms/batch - loss: 2.42832 - diff: 38.85mlTrain batch 21/32 - 173.4ms/batch - loss: 2.36776 - diff: 37.88mlTrain batch 22/32 - 190.8ms/batch - loss: 2.37239 - diff: 37.96mlTrain batch 23/32 - 173.2ms/batch - loss: 2.37207 - diff: 37.95mlTrain batch 24/32 - 173.7ms/batch - loss: 2.36222 - diff: 37.80mlTrain batch 25/32 - 178.4ms/batch - loss: 2.37025 - diff: 37.92mlTrain batch 26/32 - 177.1ms/batch - loss: 2.33324 - diff: 37.33mlTrain batch 27/32 - 173.1ms/batch - loss: 2.35229 - diff: 37.64mlTrain batch 28/32 - 173.3ms/batch - loss: 2.32717 - diff: 37.23mlTrain batch 29/32 - 173.0ms/batch - loss: 2.37396 - diff: 37.98mlTrain batch 30/32 - 173.9ms/batch - loss: 2.34392 - diff: 37.50mlTrain batch 31/32 - 178.9ms/batch - loss: 2.32764 - diff: 37.24mlTrain batch 32/32 - 53.2ms/batch - loss: 2.37170 - diff: 37.20mlTrain batch 32/32 - 17.3s 53.2ms/batch - loss: 2.37170 - diff: 37.20ml
Test 1.5s: val_loss: 2.15241 - diff: 33.53ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_WideResNet50_0_Adam-0.001_MAE_DA3_best

Epoch 44: current best loss = 2.15241, at epoch 43
Train batch 1/32 - 188.4ms/batch - loss: 2.32330 - diff: 37.17mlTrain batch 2/32 - 183.3ms/batch - loss: 2.04111 - diff: 32.66mlTrain batch 3/32 - 173.0ms/batch - loss: 2.20396 - diff: 35.26mlTrain batch 4/32 - 180.8ms/batch - loss: 2.10305 - diff: 33.65mlTrain batch 5/32 - 173.0ms/batch - loss: 2.38966 - diff: 38.23mlTrain batch 6/32 - 173.5ms/batch - loss: 2.38574 - diff: 38.17mlTrain batch 7/32 - 179.2ms/batch - loss: 2.30452 - diff: 36.87mlTrain batch 8/32 - 173.4ms/batch - loss: 2.31445 - diff: 37.03mlTrain batch 9/32 - 173.2ms/batch - loss: 2.26205 - diff: 36.19mlTrain batch 10/32 - 173.3ms/batch - loss: 2.22355 - diff: 35.58mlTrain batch 11/32 - 173.3ms/batch - loss: 2.30231 - diff: 36.84mlTrain batch 12/32 - 177.9ms/batch - loss: 2.29827 - diff: 36.77mlTrain batch 13/32 - 173.1ms/batch - loss: 2.29316 - diff: 36.69mlTrain batch 14/32 - 173.4ms/batch - loss: 2.26890 - diff: 36.30mlTrain batch 15/32 - 180.2ms/batch - loss: 2.23958 - diff: 35.83mlTrain batch 16/32 - 179.8ms/batch - loss: 2.20962 - diff: 35.35mlTrain batch 17/32 - 173.1ms/batch - loss: 2.24174 - diff: 35.87mlTrain batch 18/32 - 173.1ms/batch - loss: 2.24333 - diff: 35.89mlTrain batch 19/32 - 173.3ms/batch - loss: 2.22253 - diff: 35.56mlTrain batch 20/32 - 173.6ms/batch - loss: 2.24909 - diff: 35.99mlTrain batch 21/32 - 188.3ms/batch - loss: 2.30392 - diff: 36.86mlTrain batch 22/32 - 173.4ms/batch - loss: 2.36840 - diff: 37.89mlTrain batch 23/32 - 173.3ms/batch - loss: 2.35445 - diff: 37.67mlTrain batch 24/32 - 173.2ms/batch - loss: 2.37573 - diff: 38.01mlTrain batch 25/32 - 173.2ms/batch - loss: 2.40999 - diff: 38.56mlTrain batch 26/32 - 173.6ms/batch - loss: 2.39530 - diff: 38.32mlTrain batch 27/32 - 173.1ms/batch - loss: 2.40034 - diff: 38.41mlTrain batch 28/32 - 173.1ms/batch - loss: 2.39102 - diff: 38.26mlTrain batch 29/32 - 172.9ms/batch - loss: 2.37564 - diff: 38.01mlTrain batch 30/32 - 173.3ms/batch - loss: 2.36638 - diff: 37.86mlTrain batch 31/32 - 173.3ms/batch - loss: 2.36072 - diff: 37.77mlTrain batch 32/32 - 53.2ms/batch - loss: 2.37191 - diff: 37.59mlTrain batch 32/32 - 17.6s 53.2ms/batch - loss: 2.37191 - diff: 37.59ml
Test 1.4s: val_loss: 2.24936 - diff: 34.37ml

Epoch 45: current best loss = 2.15241, at epoch 43
Going to unfreeze the pretrained weights
Train batch 1/32 - 257.5ms/batch - loss: 2.42732 - diff: 38.84mlTrain batch 2/32 - 235.3ms/batch - loss: 1.99489 - diff: 31.92mlTrain batch 3/32 - 235.1ms/batch - loss: 2.85611 - diff: 45.70mlTrain batch 4/32 - 234.9ms/batch - loss: 2.98543 - diff: 47.77mlTrain batch 5/32 - 235.5ms/batch - loss: 3.19933 - diff: 51.19mlTrain batch 6/32 - 235.5ms/batch - loss: 3.21000 - diff: 51.36mlTrain batch 7/32 - 234.9ms/batch - loss: 3.23390 - diff: 51.74mlTrain batch 8/32 - 235.4ms/batch - loss: 3.03050 - diff: 48.49mlTrain batch 9/32 - 235.2ms/batch - loss: 2.92841 - diff: 46.85mlTrain batch 10/32 - 237.2ms/batch - loss: 2.92769 - diff: 46.84mlTrain batch 11/32 - 235.0ms/batch - loss: 2.83664 - diff: 45.39mlTrain batch 12/32 - 235.1ms/batch - loss: 2.79301 - diff: 44.69mlTrain batch 13/32 - 240.8ms/batch - loss: 2.80008 - diff: 44.80mlTrain batch 14/32 - 235.5ms/batch - loss: 2.78324 - diff: 44.53mlTrain batch 15/32 - 234.6ms/batch - loss: 2.76452 - diff: 44.23mlTrain batch 16/32 - 236.4ms/batch - loss: 2.71824 - diff: 43.49mlTrain batch 17/32 - 235.2ms/batch - loss: 2.72015 - diff: 43.52mlTrain batch 18/32 - 235.6ms/batch - loss: 2.72778 - diff: 43.64mlTrain batch 19/32 - 235.2ms/batch - loss: 2.70410 - diff: 43.27mlTrain batch 20/32 - 235.9ms/batch - loss: 2.65471 - diff: 42.48mlTrain batch 21/32 - 234.8ms/batch - loss: 2.63477 - diff: 42.16mlTrain batch 22/32 - 235.8ms/batch - loss: 2.58707 - diff: 41.39mlTrain batch 23/32 - 234.9ms/batch - loss: 2.56454 - diff: 41.03mlTrain batch 24/32 - 235.4ms/batch - loss: 2.54502 - diff: 40.72mlTrain batch 25/32 - 235.2ms/batch - loss: 2.56217 - diff: 40.99mlTrain batch 26/32 - 236.1ms/batch - loss: 2.57919 - diff: 41.27mlTrain batch 27/32 - 234.9ms/batch - loss: 2.58474 - diff: 41.36mlTrain batch 28/32 - 236.0ms/batch - loss: 2.56790 - diff: 41.09mlTrain batch 29/32 - 235.3ms/batch - loss: 2.53823 - diff: 40.61mlTrain batch 30/32 - 235.3ms/batch - loss: 2.54220 - diff: 40.68mlTrain batch 31/32 - 235.5ms/batch - loss: 2.52126 - diff: 40.34mlTrain batch 32/32 - 79.6ms/batch - loss: 2.52773 - diff: 40.12mlTrain batch 32/32 - 17.0s 79.6ms/batch - loss: 2.52773 - diff: 40.12ml
Test 1.3s: val_loss: 29.46211 - diff: 451.99ml

Epoch 46: current best loss = 2.15241, at epoch 43
Train batch 1/32 - 234.7ms/batch - loss: 1.73218 - diff: 27.71mlTrain batch 2/32 - 235.4ms/batch - loss: 2.40249 - diff: 38.44mlTrain batch 3/32 - 235.5ms/batch - loss: 2.49359 - diff: 39.90mlTrain batch 4/32 - 235.4ms/batch - loss: 2.39097 - diff: 38.26mlTrain batch 5/32 - 236.7ms/batch - loss: 2.39977 - diff: 38.40mlTrain batch 6/32 - 249.8ms/batch - loss: 2.31218 - diff: 36.99mlTrain batch 7/32 - 235.1ms/batch - loss: 2.38414 - diff: 38.15mlTrain batch 8/32 - 235.5ms/batch - loss: 2.31636 - diff: 37.06mlTrain batch 9/32 - 235.3ms/batch - loss: 2.26639 - diff: 36.26mlTrain batch 10/32 - 235.0ms/batch - loss: 2.28077 - diff: 36.49mlTrain batch 11/32 - 235.2ms/batch - loss: 2.35656 - diff: 37.70mlTrain batch 12/32 - 235.3ms/batch - loss: 2.33941 - diff: 37.43mlTrain batch 13/32 - 235.2ms/batch - loss: 2.32238 - diff: 37.16mlTrain batch 14/32 - 235.6ms/batch - loss: 2.38321 - diff: 38.13mlTrain batch 15/32 - 240.6ms/batch - loss: 2.33706 - diff: 37.39mlTrain batch 16/32 - 236.1ms/batch - loss: 2.31439 - diff: 37.03mlTrain batch 17/32 - 235.5ms/batch - loss: 2.28451 - diff: 36.55mlTrain batch 18/32 - 235.3ms/batch - loss: 2.23515 - diff: 35.76mlTrain batch 19/32 - 235.8ms/batch - loss: 2.21923 - diff: 35.51mlTrain batch 20/32 - 235.0ms/batch - loss: 2.17421 - diff: 34.79mlTrain batch 21/32 - 235.5ms/batch - loss: 2.15375 - diff: 34.46mlTrain batch 22/32 - 235.6ms/batch - loss: 2.13389 - diff: 34.14mlTrain batch 23/32 - 236.0ms/batch - loss: 2.15053 - diff: 34.41mlTrain batch 24/32 - 235.3ms/batch - loss: 2.14657 - diff: 34.35mlTrain batch 25/32 - 236.6ms/batch - loss: 2.14405 - diff: 34.30mlTrain batch 26/32 - 235.5ms/batch - loss: 2.15547 - diff: 34.49mlTrain batch 27/32 - 235.9ms/batch - loss: 2.15857 - diff: 34.54mlTrain batch 28/32 - 235.5ms/batch - loss: 2.15761 - diff: 34.52mlTrain batch 29/32 - 235.9ms/batch - loss: 2.15128 - diff: 34.42mlTrain batch 30/32 - 235.0ms/batch - loss: 2.14110 - diff: 34.26mlTrain batch 31/32 - 234.4ms/batch - loss: 2.13734 - diff: 34.20mlTrain batch 32/32 - 84.2ms/batch - loss: 2.21062 - diff: 34.29mlTrain batch 32/32 - 15.8s 84.2ms/batch - loss: 2.21062 - diff: 34.29ml
Test 1.4s: val_loss: 2.12978 - diff: 32.85ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_WideResNet50_0_Adam-0.001_MAE_DA3_best

Epoch 47: current best loss = 2.12978, at epoch 46
Train batch 1/32 - 255.1ms/batch - loss: 1.54685 - diff: 24.75mlTrain batch 2/32 - 235.9ms/batch - loss: 1.67459 - diff: 26.79mlTrain batch 3/32 - 235.3ms/batch - loss: 1.74123 - diff: 27.86mlTrain batch 4/32 - 235.4ms/batch - loss: 1.78818 - diff: 28.61mlTrain batch 5/32 - 235.5ms/batch - loss: 1.76354 - diff: 28.22mlTrain batch 6/32 - 235.3ms/batch - loss: 1.76825 - diff: 28.29mlTrain batch 7/32 - 235.0ms/batch - loss: 1.69658 - diff: 27.15mlTrain batch 8/32 - 236.4ms/batch - loss: 1.63556 - diff: 26.17mlTrain batch 9/32 - 235.5ms/batch - loss: 1.60792 - diff: 25.73mlTrain batch 10/32 - 236.3ms/batch - loss: 1.62847 - diff: 26.06mlTrain batch 11/32 - 235.4ms/batch - loss: 1.68589 - diff: 26.97mlTrain batch 12/32 - 236.0ms/batch - loss: 1.65814 - diff: 26.53mlTrain batch 13/32 - 235.4ms/batch - loss: 1.79722 - diff: 28.76mlTrain batch 14/32 - 236.3ms/batch - loss: 1.79558 - diff: 28.73mlTrain batch 15/32 - 235.1ms/batch - loss: 1.77710 - diff: 28.43mlTrain batch 16/32 - 235.4ms/batch - loss: 1.82036 - diff: 29.13mlTrain batch 17/32 - 235.6ms/batch - loss: 1.82626 - diff: 29.22mlTrain batch 18/32 - 235.4ms/batch - loss: 1.81786 - diff: 29.09mlTrain batch 19/32 - 236.1ms/batch - loss: 1.86010 - diff: 29.76mlTrain batch 20/32 - 235.6ms/batch - loss: 1.84063 - diff: 29.45mlTrain batch 21/32 - 236.0ms/batch - loss: 1.82369 - diff: 29.18mlTrain batch 22/32 - 235.7ms/batch - loss: 1.84452 - diff: 29.51mlTrain batch 23/32 - 235.5ms/batch - loss: 1.83768 - diff: 29.40mlTrain batch 24/32 - 235.1ms/batch - loss: 1.83780 - diff: 29.40mlTrain batch 25/32 - 235.2ms/batch - loss: 1.83526 - diff: 29.36mlTrain batch 26/32 - 235.4ms/batch - loss: 1.88031 - diff: 30.08mlTrain batch 27/32 - 235.8ms/batch - loss: 1.87979 - diff: 30.08mlTrain batch 28/32 - 255.6ms/batch - loss: 1.88959 - diff: 30.23mlTrain batch 29/32 - 235.4ms/batch - loss: 1.89617 - diff: 30.34mlTrain batch 30/32 - 236.2ms/batch - loss: 1.90711 - diff: 30.51mlTrain batch 31/32 - 235.6ms/batch - loss: 1.93028 - diff: 30.88mlTrain batch 32/32 - 76.4ms/batch - loss: 1.95451 - diff: 30.80mlTrain batch 32/32 - 16.3s 76.4ms/batch - loss: 1.95451 - diff: 30.80ml
Test 1.4s: val_loss: 1.67858 - diff: 25.74ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_WideResNet50_0_Adam-0.001_MAE_DA3_best

Epoch 48: current best loss = 1.67858, at epoch 47
Train batch 1/32 - 251.9ms/batch - loss: 1.65349 - diff: 26.46mlTrain batch 2/32 - 235.4ms/batch - loss: 2.02486 - diff: 32.40mlTrain batch 3/32 - 235.2ms/batch - loss: 2.01432 - diff: 32.23mlTrain batch 4/32 - 235.5ms/batch - loss: 2.07693 - diff: 33.23mlTrain batch 5/32 - 235.3ms/batch - loss: 1.94499 - diff: 31.12mlTrain batch 6/32 - 236.1ms/batch - loss: 1.85723 - diff: 29.72mlTrain batch 7/32 - 235.2ms/batch - loss: 1.88079 - diff: 30.09mlTrain batch 8/32 - 235.9ms/batch - loss: 1.82017 - diff: 29.12mlTrain batch 9/32 - 235.1ms/batch - loss: 1.90168 - diff: 30.43mlTrain batch 10/32 - 238.0ms/batch - loss: 1.81480 - diff: 29.04mlTrain batch 11/32 - 235.2ms/batch - loss: 1.85511 - diff: 29.68mlTrain batch 12/32 - 235.9ms/batch - loss: 1.84733 - diff: 29.56mlTrain batch 13/32 - 240.6ms/batch - loss: 1.82528 - diff: 29.20mlTrain batch 14/32 - 235.8ms/batch - loss: 1.80270 - diff: 28.84mlTrain batch 15/32 - 236.0ms/batch - loss: 1.81664 - diff: 29.07mlTrain batch 16/32 - 245.2ms/batch - loss: 1.93289 - diff: 30.93mlTrain batch 17/32 - 235.8ms/batch - loss: 1.94293 - diff: 31.09mlTrain batch 18/32 - 235.4ms/batch - loss: 1.96344 - diff: 31.41mlTrain batch 19/32 - 235.1ms/batch - loss: 1.96032 - diff: 31.37mlTrain batch 20/32 - 235.9ms/batch - loss: 1.96823 - diff: 31.49mlTrain batch 21/32 - 235.9ms/batch - loss: 1.97224 - diff: 31.56mlTrain batch 22/32 - 236.0ms/batch - loss: 1.98801 - diff: 31.81mlTrain batch 23/32 - 236.0ms/batch - loss: 1.96309 - diff: 31.41mlTrain batch 24/32 - 236.0ms/batch - loss: 2.00165 - diff: 32.03mlTrain batch 25/32 - 240.8ms/batch - loss: 1.98198 - diff: 31.71mlTrain batch 26/32 - 235.9ms/batch - loss: 1.97633 - diff: 31.62mlTrain batch 27/32 - 236.0ms/batch - loss: 1.97263 - diff: 31.56mlTrain batch 28/32 - 236.2ms/batch - loss: 1.96707 - diff: 31.47mlTrain batch 29/32 - 236.1ms/batch - loss: 2.02964 - diff: 32.47mlTrain batch 30/32 - 235.1ms/batch - loss: 2.01501 - diff: 32.24mlTrain batch 31/32 - 236.2ms/batch - loss: 2.01509 - diff: 32.24mlTrain batch 32/32 - 76.4ms/batch - loss: 2.05376 - diff: 32.20mlTrain batch 32/32 - 15.8s 76.4ms/batch - loss: 2.05376 - diff: 32.20ml
Test 1.4s: val_loss: 2.28811 - diff: 35.03ml

Epoch 49: current best loss = 1.67858, at epoch 47
Train batch 1/32 - 235.3ms/batch - loss: 2.32740 - diff: 37.24mlTrain batch 2/32 - 235.7ms/batch - loss: 1.99709 - diff: 31.95mlTrain batch 3/32 - 236.0ms/batch - loss: 2.06604 - diff: 33.06mlTrain batch 4/32 - 235.5ms/batch - loss: 1.89099 - diff: 30.26mlTrain batch 5/32 - 236.1ms/batch - loss: 1.90102 - diff: 30.42mlTrain batch 6/32 - 236.0ms/batch - loss: 2.02101 - diff: 32.34mlTrain batch 7/32 - 236.1ms/batch - loss: 2.00903 - diff: 32.14mlTrain batch 8/32 - 235.9ms/batch - loss: 2.12553 - diff: 34.01mlTrain batch 9/32 - 235.3ms/batch - loss: 2.15820 - diff: 34.53mlTrain batch 10/32 - 235.9ms/batch - loss: 2.10651 - diff: 33.70mlTrain batch 11/32 - 235.9ms/batch - loss: 2.05156 - diff: 32.82mlTrain batch 12/32 - 235.1ms/batch - loss: 2.05214 - diff: 32.83mlTrain batch 13/32 - 235.4ms/batch - loss: 2.06353 - diff: 33.02mlTrain batch 14/32 - 235.0ms/batch - loss: 2.05804 - diff: 32.93mlTrain batch 15/32 - 235.6ms/batch - loss: 2.02287 - diff: 32.37mlTrain batch 16/32 - 235.9ms/batch - loss: 2.02085 - diff: 32.33mlTrain batch 17/32 - 235.7ms/batch - loss: 1.98609 - diff: 31.78mlTrain batch 18/32 - 236.8ms/batch - loss: 1.99502 - diff: 31.92mlTrain batch 19/32 - 235.5ms/batch - loss: 2.01009 - diff: 32.16mlTrain batch 20/32 - 242.2ms/batch - loss: 2.04648 - diff: 32.74mlTrain batch 21/32 - 236.3ms/batch - loss: 2.01952 - diff: 32.31mlTrain batch 22/32 - 236.2ms/batch - loss: 2.00096 - diff: 32.02mlTrain batch 23/32 - 236.7ms/batch - loss: 2.04959 - diff: 32.79mlTrain batch 24/32 - 235.8ms/batch - loss: 2.08490 - diff: 33.36mlTrain batch 25/32 - 236.1ms/batch - loss: 2.07386 - diff: 33.18mlTrain batch 26/32 - 235.8ms/batch - loss: 2.08013 - diff: 33.28mlTrain batch 27/32 - 238.7ms/batch - loss: 2.04247 - diff: 32.68mlTrain batch 28/32 - 236.4ms/batch - loss: 2.05043 - diff: 32.81mlTrain batch 29/32 - 235.9ms/batch - loss: 2.05374 - diff: 32.86mlTrain batch 30/32 - 236.3ms/batch - loss: 2.07776 - diff: 33.24mlTrain batch 31/32 - 236.7ms/batch - loss: 2.10081 - diff: 33.61mlTrain batch 32/32 - 87.0ms/batch - loss: 2.13534 - diff: 33.55mlTrain batch 32/32 - 16.5s 87.0ms/batch - loss: 2.13534 - diff: 33.55ml
Test 1.5s: val_loss: 3.70896 - diff: 57.65ml

Epoch 50: current best loss = 1.67858, at epoch 47
Train batch 1/32 - 238.2ms/batch - loss: 1.72342 - diff: 27.57mlTrain batch 2/32 - 236.4ms/batch - loss: 1.74229 - diff: 27.88mlTrain batch 3/32 - 235.4ms/batch - loss: 2.25378 - diff: 36.06mlTrain batch 4/32 - 236.5ms/batch - loss: 1.95003 - diff: 31.20mlTrain batch 5/32 - 235.8ms/batch - loss: 2.01988 - diff: 32.32mlTrain batch 6/32 - 258.0ms/batch - loss: 1.95895 - diff: 31.34mlTrain batch 7/32 - 235.6ms/batch - loss: 1.93938 - diff: 31.03mlTrain batch 8/32 - 236.6ms/batch - loss: 1.96477 - diff: 31.44mlTrain batch 9/32 - 235.9ms/batch - loss: 2.03949 - diff: 32.63mlTrain batch 10/32 - 242.5ms/batch - loss: 2.05248 - diff: 32.84mlTrain batch 11/32 - 235.8ms/batch - loss: 2.06876 - diff: 33.10mlTrain batch 12/32 - 250.1ms/batch - loss: 2.03760 - diff: 32.60mlTrain batch 13/32 - 235.6ms/batch - loss: 1.98776 - diff: 31.80mlTrain batch 14/32 - 236.0ms/batch - loss: 1.98036 - diff: 31.69mlTrain batch 15/32 - 235.9ms/batch - loss: 1.98484 - diff: 31.76mlTrain batch 16/32 - 236.3ms/batch - loss: 1.97351 - diff: 31.58mlTrain batch 17/32 - 235.5ms/batch - loss: 2.00473 - diff: 32.08mlTrain batch 18/32 - 235.8ms/batch - loss: 2.04962 - diff: 32.79mlTrain batch 19/32 - 236.0ms/batch - loss: 2.10733 - diff: 33.72mlTrain batch 20/32 - 236.1ms/batch - loss: 2.09343 - diff: 33.49mlTrain batch 21/32 - 235.3ms/batch - loss: 2.16154 - diff: 34.58mlTrain batch 22/32 - 236.2ms/batch - loss: 2.16211 - diff: 34.59mlTrain batch 23/32 - 235.4ms/batch - loss: 2.16693 - diff: 34.67mlTrain batch 24/32 - 237.0ms/batch - loss: 2.17376 - diff: 34.78mlTrain batch 25/32 - 235.7ms/batch - loss: 2.22607 - diff: 35.62mlTrain batch 26/32 - 237.2ms/batch - loss: 2.20646 - diff: 35.30mlTrain batch 27/32 - 235.4ms/batch - loss: 2.23421 - diff: 35.75mlTrain batch 28/32 - 236.6ms/batch - loss: 2.21502 - diff: 35.44mlTrain batch 29/32 - 235.5ms/batch - loss: 2.20379 - diff: 35.26mlTrain batch 30/32 - 236.6ms/batch - loss: 2.18173 - diff: 34.91mlTrain batch 31/32 - 235.4ms/batch - loss: 2.15475 - diff: 34.48mlTrain batch 32/32 - 76.0ms/batch - loss: 2.22322 - diff: 34.54mlTrain batch 32/32 - 17.9s 76.0ms/batch - loss: 2.22322 - diff: 34.54ml
Test 1.4s: val_loss: 1.72560 - diff: 26.63ml

Epoch 51: current best loss = 1.67858, at epoch 47
Train batch 1/32 - 235.4ms/batch - loss: 1.39121 - diff: 22.26mlTrain batch 2/32 - 236.1ms/batch - loss: 2.09686 - diff: 33.55mlTrain batch 3/32 - 240.4ms/batch - loss: 2.01991 - diff: 32.32mlTrain batch 4/32 - 235.6ms/batch - loss: 2.18451 - diff: 34.95mlTrain batch 5/32 - 236.1ms/batch - loss: 2.24490 - diff: 35.92mlTrain batch 6/32 - 236.5ms/batch - loss: 2.11138 - diff: 33.78mlTrain batch 7/32 - 235.5ms/batch - loss: 2.02256 - diff: 32.36mlTrain batch 8/32 - 235.4ms/batch - loss: 1.89226 - diff: 30.28mlTrain batch 9/32 - 235.9ms/batch - loss: 1.87289 - diff: 29.97mlTrain batch 10/32 - 239.8ms/batch - loss: 1.91138 - diff: 30.58mlTrain batch 11/32 - 235.5ms/batch - loss: 1.87000 - diff: 29.92mlTrain batch 12/32 - 235.8ms/batch - loss: 1.91428 - diff: 30.63mlTrain batch 13/32 - 235.6ms/batch - loss: 1.95561 - diff: 31.29mlTrain batch 14/32 - 243.9ms/batch - loss: 1.98763 - diff: 31.80mlTrain batch 15/32 - 235.4ms/batch - loss: 1.94896 - diff: 31.18mlTrain batch 16/32 - 236.2ms/batch - loss: 1.91690 - diff: 30.67mlTrain batch 17/32 - 236.6ms/batch - loss: 1.86811 - diff: 29.89mlTrain batch 18/32 - 236.2ms/batch - loss: 1.82951 - diff: 29.27mlTrain batch 19/32 - 235.6ms/batch - loss: 1.86210 - diff: 29.79mlTrain batch 20/32 - 235.7ms/batch - loss: 1.84271 - diff: 29.48mlTrain batch 21/32 - 235.4ms/batch - loss: 1.82691 - diff: 29.23mlTrain batch 22/32 - 235.9ms/batch - loss: 1.82712 - diff: 29.23mlTrain batch 23/32 - 236.6ms/batch - loss: 1.84867 - diff: 29.58mlTrain batch 24/32 - 236.5ms/batch - loss: 1.83404 - diff: 29.34mlTrain batch 25/32 - 236.4ms/batch - loss: 1.82157 - diff: 29.15mlTrain batch 26/32 - 236.5ms/batch - loss: 1.81551 - diff: 29.05mlTrain batch 27/32 - 240.7ms/batch - loss: 1.83249 - diff: 29.32mlTrain batch 28/32 - 236.5ms/batch - loss: 1.84004 - diff: 29.44mlTrain batch 29/32 - 236.2ms/batch - loss: 1.83573 - diff: 29.37mlTrain batch 30/32 - 235.5ms/batch - loss: 1.85833 - diff: 29.73mlTrain batch 31/32 - 235.9ms/batch - loss: 1.83947 - diff: 29.43mlTrain batch 32/32 - 76.3ms/batch - loss: 2.05590 - diff: 30.12mlTrain batch 32/32 - 16.9s 76.3ms/batch - loss: 2.05590 - diff: 30.12ml
Test 1.4s: val_loss: 2.87171 - diff: 43.51ml

Epoch 52: current best loss = 1.67858, at epoch 47
Train batch 1/32 - 235.8ms/batch - loss: 2.57234 - diff: 41.16mlTrain batch 2/32 - 235.6ms/batch - loss: 2.07657 - diff: 33.23mlTrain batch 3/32 - 235.6ms/batch - loss: 2.34096 - diff: 37.46mlTrain batch 4/32 - 245.9ms/batch - loss: 2.28166 - diff: 36.51mlTrain batch 5/32 - 235.7ms/batch - loss: 2.08836 - diff: 33.41mlTrain batch 6/32 - 236.0ms/batch - loss: 1.99903 - diff: 31.98mlTrain batch 7/32 - 235.2ms/batch - loss: 2.08736 - diff: 33.40mlTrain batch 8/32 - 235.9ms/batch - loss: 2.08910 - diff: 33.43mlTrain batch 9/32 - 235.8ms/batch - loss: 2.07609 - diff: 33.22mlTrain batch 10/32 - 235.3ms/batch - loss: 2.09503 - diff: 33.52mlTrain batch 11/32 - 241.0ms/batch - loss: 2.09725 - diff: 33.56mlTrain batch 12/32 - 236.4ms/batch - loss: 2.05802 - diff: 32.93mlTrain batch 13/32 - 235.7ms/batch - loss: 2.01997 - diff: 32.32mlTrain batch 14/32 - 236.3ms/batch - loss: 1.99617 - diff: 31.94mlTrain batch 15/32 - 235.8ms/batch - loss: 1.97315 - diff: 31.57mlTrain batch 16/32 - 235.1ms/batch - loss: 1.97024 - diff: 31.52mlTrain batch 17/32 - 235.5ms/batch - loss: 1.95294 - diff: 31.25mlTrain batch 18/32 - 235.2ms/batch - loss: 1.93899 - diff: 31.02mlTrain batch 19/32 - 235.9ms/batch - loss: 1.95113 - diff: 31.22mlTrain batch 20/32 - 236.5ms/batch - loss: 1.94657 - diff: 31.15mlTrain batch 21/32 - 235.7ms/batch - loss: 1.95041 - diff: 31.21mlTrain batch 22/32 - 235.6ms/batch - loss: 1.97426 - diff: 31.59mlTrain batch 23/32 - 235.5ms/batch - loss: 1.95222 - diff: 31.24mlTrain batch 24/32 - 236.1ms/batch - loss: 1.94029 - diff: 31.04mlTrain batch 25/32 - 235.7ms/batch - loss: 1.93160 - diff: 30.91mlTrain batch 26/32 - 235.6ms/batch - loss: 1.93078 - diff: 30.89mlTrain batch 27/32 - 235.6ms/batch - loss: 1.95183 - diff: 31.23mlTrain batch 28/32 - 236.3ms/batch - loss: 1.94873 - diff: 31.18mlTrain batch 29/32 - 235.4ms/batch - loss: 1.95609 - diff: 31.30mlTrain batch 30/32 - 236.3ms/batch - loss: 1.94008 - diff: 31.04mlTrain batch 31/32 - 236.0ms/batch - loss: 1.93109 - diff: 30.90mlTrain batch 32/32 - 76.8ms/batch - loss: 1.96465 - diff: 30.85mlTrain batch 32/32 - 17.5s 76.8ms/batch - loss: 1.96465 - diff: 30.85ml
Test 1.5s: val_loss: 1.79656 - diff: 28.22ml

Epoch 53: current best loss = 1.67858, at epoch 47
Train batch 1/32 - 235.4ms/batch - loss: 1.52970 - diff: 24.48mlTrain batch 2/32 - 236.3ms/batch - loss: 1.60921 - diff: 25.75mlTrain batch 3/32 - 236.1ms/batch - loss: 1.82125 - diff: 29.14mlTrain batch 4/32 - 236.3ms/batch - loss: 1.94669 - diff: 31.15mlTrain batch 5/32 - 236.1ms/batch - loss: 2.00279 - diff: 32.04mlTrain batch 6/32 - 237.6ms/batch - loss: 2.00253 - diff: 32.04mlTrain batch 7/32 - 235.7ms/batch - loss: 1.99364 - diff: 31.90mlTrain batch 8/32 - 236.2ms/batch - loss: 2.02277 - diff: 32.36mlTrain batch 9/32 - 236.0ms/batch - loss: 1.95944 - diff: 31.35mlTrain batch 10/32 - 236.3ms/batch - loss: 1.99042 - diff: 31.85mlTrain batch 11/32 - 235.7ms/batch - loss: 2.08825 - diff: 33.41mlTrain batch 12/32 - 236.0ms/batch - loss: 2.09197 - diff: 33.47mlTrain batch 13/32 - 235.3ms/batch - loss: 2.03334 - diff: 32.53mlTrain batch 14/32 - 236.1ms/batch - loss: 1.99535 - diff: 31.93mlTrain batch 15/32 - 235.6ms/batch - loss: 2.03749 - diff: 32.60mlTrain batch 16/32 - 236.8ms/batch - loss: 2.00047 - diff: 32.01mlTrain batch 17/32 - 236.0ms/batch - loss: 2.01673 - diff: 32.27mlTrain batch 18/32 - 245.1ms/batch - loss: 2.02576 - diff: 32.41mlTrain batch 19/32 - 236.3ms/batch - loss: 1.99459 - diff: 31.91mlTrain batch 20/32 - 236.8ms/batch - loss: 2.01386 - diff: 32.22mlTrain batch 21/32 - 235.8ms/batch - loss: 1.99851 - diff: 31.98mlTrain batch 22/32 - 250.2ms/batch - loss: 1.97126 - diff: 31.54mlTrain batch 23/32 - 236.4ms/batch - loss: 1.97518 - diff: 31.60mlTrain batch 24/32 - 236.7ms/batch - loss: 1.96832 - diff: 31.49mlTrain batch 25/32 - 242.2ms/batch - loss: 1.95850 - diff: 31.34mlTrain batch 26/32 - 236.3ms/batch - loss: 1.94100 - diff: 31.06mlTrain batch 27/32 - 236.5ms/batch - loss: 1.93039 - diff: 30.89mlTrain batch 28/32 - 236.9ms/batch - loss: 1.92846 - diff: 30.86mlTrain batch 29/32 - 236.4ms/batch - loss: 1.92646 - diff: 30.82mlTrain batch 30/32 - 236.2ms/batch - loss: 1.92516 - diff: 30.80mlTrain batch 31/32 - 236.5ms/batch - loss: 1.92924 - diff: 30.87mlTrain batch 32/32 - 76.3ms/batch - loss: 2.01760 - diff: 31.04mlTrain batch 32/32 - 16.8s 76.3ms/batch - loss: 2.01760 - diff: 31.04ml
Test 1.5s: val_loss: 2.75480 - diff: 42.77ml

Epoch 54: current best loss = 1.67858, at epoch 47
Train batch 1/32 - 236.1ms/batch - loss: 2.65743 - diff: 42.52mlTrain batch 2/32 - 235.7ms/batch - loss: 2.19227 - diff: 35.08mlTrain batch 3/32 - 235.9ms/batch - loss: 2.10301 - diff: 33.65mlTrain batch 4/32 - 236.3ms/batch - loss: 1.94168 - diff: 31.07mlTrain batch 5/32 - 240.0ms/batch - loss: 1.88075 - diff: 30.09mlTrain batch 6/32 - 236.3ms/batch - loss: 1.77353 - diff: 28.38mlTrain batch 7/32 - 235.9ms/batch - loss: 1.79162 - diff: 28.67mlTrain batch 8/32 - 236.5ms/batch - loss: 1.72641 - diff: 27.62mlTrain batch 9/32 - 235.5ms/batch - loss: 1.87255 - diff: 29.96mlTrain batch 10/32 - 235.5ms/batch - loss: 1.86231 - diff: 29.80mlTrain batch 11/32 - 235.4ms/batch - loss: 1.83237 - diff: 29.32mlTrain batch 12/32 - 236.3ms/batch - loss: 1.77946 - diff: 28.47mlTrain batch 13/32 - 235.9ms/batch - loss: 1.79151 - diff: 28.66mlTrain batch 14/32 - 251.1ms/batch - loss: 1.77614 - diff: 28.42mlTrain batch 15/32 - 236.1ms/batch - loss: 1.78420 - diff: 28.55mlTrain batch 16/32 - 240.7ms/batch - loss: 1.78292 - diff: 28.53mlTrain batch 17/32 - 235.4ms/batch - loss: 1.78052 - diff: 28.49mlTrain batch 18/32 - 235.9ms/batch - loss: 1.76983 - diff: 28.32mlTrain batch 19/32 - 235.7ms/batch - loss: 1.80231 - diff: 28.84mlTrain batch 20/32 - 239.8ms/batch - loss: 1.82637 - diff: 29.22mlTrain batch 21/32 - 236.2ms/batch - loss: 1.82935 - diff: 29.27mlTrain batch 22/32 - 236.1ms/batch - loss: 1.81784 - diff: 29.09mlTrain batch 23/32 - 239.7ms/batch - loss: 1.81135 - diff: 28.98mlTrain batch 24/32 - 235.9ms/batch - loss: 1.79604 - diff: 28.74mlTrain batch 25/32 - 235.8ms/batch - loss: 1.80336 - diff: 28.85mlTrain batch 26/32 - 235.8ms/batch - loss: 1.82670 - diff: 29.23mlTrain batch 27/32 - 236.3ms/batch - loss: 1.81884 - diff: 29.10mlTrain batch 28/32 - 236.6ms/batch - loss: 1.82242 - diff: 29.16mlTrain batch 29/32 - 235.7ms/batch - loss: 1.86764 - diff: 29.88mlTrain batch 30/32 - 235.7ms/batch - loss: 1.84356 - diff: 29.50mlTrain batch 31/32 - 236.5ms/batch - loss: 1.83398 - diff: 29.34mlTrain batch 32/32 - 92.7ms/batch - loss: 1.88564 - diff: 29.37mlTrain batch 32/32 - 16.8s 92.7ms/batch - loss: 1.88564 - diff: 29.37ml
Test 1.5s: val_loss: 1.65696 - diff: 25.31ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_WideResNet50_0_Adam-0.001_MAE_DA3_best

Epoch 55: current best loss = 1.65696, at epoch 54
Train batch 1/32 - 255.0ms/batch - loss: 1.32488 - diff: 21.20mlTrain batch 2/32 - 235.7ms/batch - loss: 1.78736 - diff: 28.60mlTrain batch 3/32 - 235.6ms/batch - loss: 1.55400 - diff: 24.86mlTrain batch 4/32 - 236.4ms/batch - loss: 1.60823 - diff: 25.73mlTrain batch 5/32 - 235.5ms/batch - loss: 1.63985 - diff: 26.24mlTrain batch 6/32 - 237.1ms/batch - loss: 1.64809 - diff: 26.37mlTrain batch 7/32 - 235.7ms/batch - loss: 1.61211 - diff: 25.79mlTrain batch 8/32 - 235.9ms/batch - loss: 1.60733 - diff: 25.72mlTrain batch 9/32 - 235.7ms/batch - loss: 1.62075 - diff: 25.93mlTrain batch 10/32 - 235.8ms/batch - loss: 1.60480 - diff: 25.68mlTrain batch 11/32 - 235.5ms/batch - loss: 1.62162 - diff: 25.95mlTrain batch 12/32 - 236.3ms/batch - loss: 1.66765 - diff: 26.68mlTrain batch 13/32 - 243.5ms/batch - loss: 1.63236 - diff: 26.12mlTrain batch 14/32 - 236.0ms/batch - loss: 1.66763 - diff: 26.68mlTrain batch 15/32 - 236.3ms/batch - loss: 1.64444 - diff: 26.31mlTrain batch 16/32 - 237.6ms/batch - loss: 1.64698 - diff: 26.35mlTrain batch 17/32 - 239.7ms/batch - loss: 1.64621 - diff: 26.34mlTrain batch 18/32 - 235.2ms/batch - loss: 1.70155 - diff: 27.22mlTrain batch 19/32 - 236.1ms/batch - loss: 1.73872 - diff: 27.82mlTrain batch 20/32 - 236.3ms/batch - loss: 1.74781 - diff: 27.97mlTrain batch 21/32 - 235.9ms/batch - loss: 1.76203 - diff: 28.19mlTrain batch 22/32 - 243.6ms/batch - loss: 1.75477 - diff: 28.08mlTrain batch 23/32 - 235.6ms/batch - loss: 1.75888 - diff: 28.14mlTrain batch 24/32 - 236.0ms/batch - loss: 1.74655 - diff: 27.94mlTrain batch 25/32 - 240.6ms/batch - loss: 1.74428 - diff: 27.91mlTrain batch 26/32 - 235.5ms/batch - loss: 1.76191 - diff: 28.19mlTrain batch 27/32 - 235.6ms/batch - loss: 1.74843 - diff: 27.97mlTrain batch 28/32 - 235.6ms/batch - loss: 1.72486 - diff: 27.60mlTrain batch 29/32 - 235.9ms/batch - loss: 1.72624 - diff: 27.62mlTrain batch 30/32 - 236.2ms/batch - loss: 1.71689 - diff: 27.47mlTrain batch 31/32 - 236.1ms/batch - loss: 1.73139 - diff: 27.70mlTrain batch 32/32 - 76.4ms/batch - loss: 1.76925 - diff: 27.69mlTrain batch 32/32 - 17.4s 76.4ms/batch - loss: 1.76925 - diff: 27.69ml
Test 1.5s: val_loss: 1.66067 - diff: 25.11ml

Epoch 56: current best loss = 1.65696, at epoch 54
Train batch 1/32 - 235.6ms/batch - loss: 1.95276 - diff: 31.24mlTrain batch 2/32 - 239.8ms/batch - loss: 1.64491 - diff: 26.32mlTrain batch 3/32 - 235.2ms/batch - loss: 1.71976 - diff: 27.52mlTrain batch 4/32 - 238.1ms/batch - loss: 1.69078 - diff: 27.05mlTrain batch 5/32 - 235.6ms/batch - loss: 1.83767 - diff: 29.40mlTrain batch 6/32 - 236.1ms/batch - loss: 2.10877 - diff: 33.74mlTrain batch 7/32 - 235.5ms/batch - loss: 2.11157 - diff: 33.79mlTrain batch 8/32 - 235.9ms/batch - loss: 2.04832 - diff: 32.77mlTrain batch 9/32 - 235.7ms/batch - loss: 2.00383 - diff: 32.06mlTrain batch 10/32 - 241.5ms/batch - loss: 2.00825 - diff: 32.13mlTrain batch 11/32 - 235.4ms/batch - loss: 1.96675 - diff: 31.47mlTrain batch 12/32 - 235.5ms/batch - loss: 1.95169 - diff: 31.23mlTrain batch 13/32 - 237.5ms/batch - loss: 1.92178 - diff: 30.75mlTrain batch 14/32 - 236.1ms/batch - loss: 1.90582 - diff: 30.49mlTrain batch 15/32 - 235.7ms/batch - loss: 1.86703 - diff: 29.87mlTrain batch 16/32 - 235.4ms/batch - loss: 1.87075 - diff: 29.93mlTrain batch 17/32 - 238.9ms/batch - loss: 1.84610 - diff: 29.54mlTrain batch 18/32 - 235.8ms/batch - loss: 1.85240 - diff: 29.64mlTrain batch 19/32 - 235.9ms/batch - loss: 1.84905 - diff: 29.58mlTrain batch 20/32 - 235.1ms/batch - loss: 1.84201 - diff: 29.47mlTrain batch 21/32 - 236.0ms/batch - loss: 1.86124 - diff: 29.78mlTrain batch 22/32 - 255.4ms/batch - loss: 1.83820 - diff: 29.41mlTrain batch 23/32 - 238.8ms/batch - loss: 1.83248 - diff: 29.32mlTrain batch 24/32 - 235.9ms/batch - loss: 1.79684 - diff: 28.75mlTrain batch 25/32 - 235.8ms/batch - loss: 1.77158 - diff: 28.35mlTrain batch 26/32 - 237.7ms/batch - loss: 1.82832 - diff: 29.25mlTrain batch 27/32 - 235.3ms/batch - loss: 1.80089 - diff: 28.81mlTrain batch 28/32 - 236.3ms/batch - loss: 1.82724 - diff: 29.24mlTrain batch 29/32 - 235.6ms/batch - loss: 1.81098 - diff: 28.98mlTrain batch 30/32 - 246.8ms/batch - loss: 1.80995 - diff: 28.96mlTrain batch 31/32 - 236.1ms/batch - loss: 1.82624 - diff: 29.22mlTrain batch 32/32 - 76.5ms/batch - loss: 1.90675 - diff: 29.37mlTrain batch 32/32 - 17.3s 76.5ms/batch - loss: 1.90675 - diff: 29.37ml
Test 1.5s: val_loss: 1.98477 - diff: 30.03ml

Epoch 57: current best loss = 1.65696, at epoch 54
Train batch 1/32 - 235.6ms/batch - loss: 2.14810 - diff: 34.37mlTrain batch 2/32 - 235.7ms/batch - loss: 1.86061 - diff: 29.77mlTrain batch 3/32 - 235.9ms/batch - loss: 1.86520 - diff: 29.84mlTrain batch 4/32 - 236.0ms/batch - loss: 1.82876 - diff: 29.26mlTrain batch 5/32 - 235.3ms/batch - loss: 1.89830 - diff: 30.37mlTrain batch 6/32 - 235.6ms/batch - loss: 1.81478 - diff: 29.04mlTrain batch 7/32 - 235.4ms/batch - loss: 1.77176 - diff: 28.35mlTrain batch 8/32 - 235.3ms/batch - loss: 1.71117 - diff: 27.38mlTrain batch 9/32 - 235.7ms/batch - loss: 1.65110 - diff: 26.42mlTrain batch 10/32 - 236.2ms/batch - loss: 1.64177 - diff: 26.27mlTrain batch 11/32 - 235.8ms/batch - loss: 1.61719 - diff: 25.87mlTrain batch 12/32 - 235.5ms/batch - loss: 1.62856 - diff: 26.06mlTrain batch 13/32 - 235.9ms/batch - loss: 1.60920 - diff: 25.75mlTrain batch 14/32 - 236.5ms/batch - loss: 1.62596 - diff: 26.02mlTrain batch 15/32 - 239.3ms/batch - loss: 1.61621 - diff: 25.86mlTrain batch 16/32 - 236.5ms/batch - loss: 1.58757 - diff: 25.40mlTrain batch 17/32 - 235.8ms/batch - loss: 1.63149 - diff: 26.10mlTrain batch 18/32 - 236.6ms/batch - loss: 1.64031 - diff: 26.24mlTrain batch 19/32 - 235.6ms/batch - loss: 1.65024 - diff: 26.40mlTrain batch 20/32 - 236.6ms/batch - loss: 1.63180 - diff: 26.11mlTrain batch 21/32 - 235.5ms/batch - loss: 1.65100 - diff: 26.42mlTrain batch 22/32 - 236.6ms/batch - loss: 1.64799 - diff: 26.37mlTrain batch 23/32 - 235.6ms/batch - loss: 1.64897 - diff: 26.38mlTrain batch 24/32 - 236.6ms/batch - loss: 1.63748 - diff: 26.20mlTrain batch 25/32 - 235.7ms/batch - loss: 1.62995 - diff: 26.08mlTrain batch 26/32 - 236.7ms/batch - loss: 1.67226 - diff: 26.76mlTrain batch 27/32 - 235.8ms/batch - loss: 1.66783 - diff: 26.69mlTrain batch 28/32 - 235.8ms/batch - loss: 1.67485 - diff: 26.80mlTrain batch 29/32 - 236.4ms/batch - loss: 1.66714 - diff: 26.67mlTrain batch 30/32 - 236.1ms/batch - loss: 1.71500 - diff: 27.44mlTrain batch 31/32 - 236.5ms/batch - loss: 1.70925 - diff: 27.35mlTrain batch 32/32 - 76.4ms/batch - loss: 1.75298 - diff: 27.36mlTrain batch 32/32 - 17.5s 76.4ms/batch - loss: 1.75298 - diff: 27.36ml
Test 1.4s: val_loss: 1.59414 - diff: 24.63ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_WideResNet50_0_Adam-0.001_MAE_DA3_best

Epoch 58: current best loss = 1.59414, at epoch 57
Train batch 1/32 - 248.3ms/batch - loss: 2.27368 - diff: 36.38mlTrain batch 2/32 - 236.0ms/batch - loss: 1.73515 - diff: 27.76mlTrain batch 3/32 - 235.7ms/batch - loss: 1.60871 - diff: 25.74mlTrain batch 4/32 - 237.0ms/batch - loss: 1.62072 - diff: 25.93mlTrain batch 5/32 - 236.2ms/batch - loss: 1.77612 - diff: 28.42mlTrain batch 6/32 - 237.1ms/batch - loss: 1.64584 - diff: 26.33mlTrain batch 7/32 - 235.9ms/batch - loss: 1.60118 - diff: 25.62mlTrain batch 8/32 - 236.3ms/batch - loss: 1.56973 - diff: 25.12mlTrain batch 9/32 - 235.6ms/batch - loss: 1.69020 - diff: 27.04mlTrain batch 10/32 - 236.0ms/batch - loss: 1.68816 - diff: 27.01mlTrain batch 11/32 - 235.8ms/batch - loss: 1.71431 - diff: 27.43mlTrain batch 12/32 - 237.2ms/batch - loss: 1.77415 - diff: 28.39mlTrain batch 13/32 - 239.3ms/batch - loss: 1.74931 - diff: 27.99mlTrain batch 14/32 - 235.7ms/batch - loss: 1.71031 - diff: 27.36mlTrain batch 15/32 - 236.1ms/batch - loss: 1.71043 - diff: 27.37mlTrain batch 16/32 - 235.7ms/batch - loss: 1.72042 - diff: 27.53mlTrain batch 17/32 - 236.0ms/batch - loss: 1.70891 - diff: 27.34mlTrain batch 18/32 - 237.4ms/batch - loss: 1.69858 - diff: 27.18mlTrain batch 19/32 - 235.3ms/batch - loss: 1.68003 - diff: 26.88mlTrain batch 20/32 - 235.3ms/batch - loss: 1.69623 - diff: 27.14mlTrain batch 21/32 - 236.6ms/batch - loss: 1.75916 - diff: 28.15mlTrain batch 22/32 - 236.1ms/batch - loss: 1.77139 - diff: 28.34mlTrain batch 23/32 - 235.7ms/batch - loss: 1.77670 - diff: 28.43mlTrain batch 24/32 - 236.0ms/batch - loss: 1.76191 - diff: 28.19mlTrain batch 25/32 - 235.9ms/batch - loss: 1.78142 - diff: 28.50mlTrain batch 26/32 - 235.8ms/batch - loss: 1.78046 - diff: 28.49mlTrain batch 27/32 - 236.6ms/batch - loss: 1.76490 - diff: 28.24mlTrain batch 28/32 - 235.7ms/batch - loss: 1.75662 - diff: 28.11mlTrain batch 29/32 - 236.8ms/batch - loss: 1.77217 - diff: 28.35mlTrain batch 30/32 - 235.5ms/batch - loss: 1.77763 - diff: 28.44mlTrain batch 31/32 - 236.2ms/batch - loss: 1.78335 - diff: 28.53mlTrain batch 32/32 - 76.8ms/batch - loss: 1.88585 - diff: 28.77mlTrain batch 32/32 - 16.6s 76.8ms/batch - loss: 1.88585 - diff: 28.77ml
Test 1.5s: val_loss: 1.67010 - diff: 25.56ml

Epoch 59: current best loss = 1.59414, at epoch 57
Train batch 1/32 - 254.0ms/batch - loss: 1.55183 - diff: 24.83mlTrain batch 2/32 - 235.9ms/batch - loss: 1.57036 - diff: 25.13mlTrain batch 3/32 - 235.7ms/batch - loss: 1.57609 - diff: 25.22mlTrain batch 4/32 - 250.9ms/batch - loss: 1.57379 - diff: 25.18mlTrain batch 5/32 - 236.1ms/batch - loss: 1.52837 - diff: 24.45mlTrain batch 6/32 - 241.7ms/batch - loss: 1.52096 - diff: 24.34mlTrain batch 7/32 - 235.8ms/batch - loss: 1.51140 - diff: 24.18mlTrain batch 8/32 - 236.9ms/batch - loss: 1.51095 - diff: 24.18mlTrain batch 9/32 - 239.6ms/batch - loss: 1.53917 - diff: 24.63mlTrain batch 10/32 - 235.1ms/batch - loss: 1.60311 - diff: 25.65mlTrain batch 11/32 - 236.4ms/batch - loss: 1.69408 - diff: 27.11mlTrain batch 12/32 - 236.2ms/batch - loss: 1.68296 - diff: 26.93mlTrain batch 13/32 - 235.1ms/batch - loss: 1.67728 - diff: 26.84mlTrain batch 14/32 - 236.3ms/batch - loss: 1.68323 - diff: 26.93mlTrain batch 15/32 - 235.9ms/batch - loss: 1.68646 - diff: 26.98mlTrain batch 16/32 - 236.5ms/batch - loss: 1.67809 - diff: 26.85mlTrain batch 17/32 - 236.0ms/batch - loss: 1.67408 - diff: 26.79mlTrain batch 18/32 - 240.9ms/batch - loss: 1.68243 - diff: 26.92mlTrain batch 19/32 - 235.8ms/batch - loss: 1.65873 - diff: 26.54mlTrain batch 20/32 - 241.8ms/batch - loss: 1.65193 - diff: 26.43mlTrain batch 21/32 - 235.4ms/batch - loss: 1.67671 - diff: 26.83mlTrain batch 22/32 - 236.3ms/batch - loss: 1.67555 - diff: 26.81mlTrain batch 23/32 - 236.1ms/batch - loss: 1.66375 - diff: 26.62mlTrain batch 24/32 - 236.4ms/batch - loss: 1.64386 - diff: 26.30mlTrain batch 25/32 - 235.4ms/batch - loss: 1.62850 - diff: 26.06mlTrain batch 26/32 - 236.0ms/batch - loss: 1.65759 - diff: 26.52mlTrain batch 27/32 - 236.3ms/batch - loss: 1.67588 - diff: 26.81mlTrain batch 28/32 - 236.2ms/batch - loss: 1.67977 - diff: 26.88mlTrain batch 29/32 - 235.7ms/batch - loss: 1.67265 - diff: 26.76mlTrain batch 30/32 - 236.0ms/batch - loss: 1.67687 - diff: 26.83mlTrain batch 31/32 - 236.3ms/batch - loss: 1.68431 - diff: 26.95mlTrain batch 32/32 - 76.5ms/batch - loss: 1.82958 - diff: 27.37mlTrain batch 32/32 - 17.0s 76.5ms/batch - loss: 1.82958 - diff: 27.37ml
Test 1.4s: val_loss: 2.34104 - diff: 36.42ml

Epoch 60: current best loss = 1.59414, at epoch 57
Train batch 1/32 - 235.7ms/batch - loss: 1.87006 - diff: 29.92mlTrain batch 2/32 - 236.7ms/batch - loss: 1.63129 - diff: 26.10mlTrain batch 3/32 - 235.8ms/batch - loss: 1.51807 - diff: 24.29mlTrain batch 4/32 - 235.7ms/batch - loss: 1.68176 - diff: 26.91mlTrain batch 5/32 - 236.0ms/batch - loss: 1.72863 - diff: 27.66mlTrain batch 6/32 - 236.2ms/batch - loss: 1.73734 - diff: 27.80mlTrain batch 7/32 - 236.1ms/batch - loss: 1.72965 - diff: 27.67mlTrain batch 8/32 - 236.7ms/batch - loss: 1.73901 - diff: 27.82mlTrain batch 9/32 - 236.8ms/batch - loss: 1.71439 - diff: 27.43mlTrain batch 10/32 - 236.3ms/batch - loss: 1.67379 - diff: 26.78mlTrain batch 11/32 - 236.1ms/batch - loss: 1.67282 - diff: 26.77mlTrain batch 12/32 - 235.6ms/batch - loss: 1.67335 - diff: 26.77mlTrain batch 13/32 - 235.7ms/batch - loss: 1.66723 - diff: 26.68mlTrain batch 14/32 - 236.6ms/batch - loss: 1.66144 - diff: 26.58mlTrain batch 15/32 - 235.4ms/batch - loss: 1.65791 - diff: 26.53mlTrain batch 16/32 - 236.5ms/batch - loss: 1.71051 - diff: 27.37mlTrain batch 17/32 - 249.8ms/batch - loss: 1.71591 - diff: 27.45mlTrain batch 18/32 - 236.3ms/batch - loss: 1.69935 - diff: 27.19mlTrain batch 19/32 - 235.8ms/batch - loss: 1.68596 - diff: 26.98mlTrain batch 20/32 - 235.9ms/batch - loss: 1.67598 - diff: 26.82mlTrain batch 21/32 - 235.9ms/batch - loss: 1.69746 - diff: 27.16mlTrain batch 22/32 - 235.8ms/batch - loss: 1.70309 - diff: 27.25mlTrain batch 23/32 - 236.8ms/batch - loss: 1.70896 - diff: 27.34mlTrain batch 24/32 - 235.5ms/batch - loss: 1.70009 - diff: 27.20mlTrain batch 25/32 - 235.9ms/batch - loss: 1.68630 - diff: 26.98mlTrain batch 26/32 - 248.3ms/batch - loss: 1.68165 - diff: 26.91mlTrain batch 27/32 - 236.6ms/batch - loss: 1.71361 - diff: 27.42mlTrain batch 28/32 - 236.4ms/batch - loss: 1.72748 - diff: 27.64mlTrain batch 29/32 - 236.9ms/batch - loss: 1.72306 - diff: 27.57mlTrain batch 30/32 - 236.5ms/batch - loss: 1.71288 - diff: 27.41mlTrain batch 31/32 - 236.7ms/batch - loss: 1.70146 - diff: 27.22mlTrain batch 32/32 - 76.7ms/batch - loss: 1.74512 - diff: 27.23mlTrain batch 32/32 - 16.3s 76.7ms/batch - loss: 1.74512 - diff: 27.23ml
Test 1.4s: val_loss: 1.76860 - diff: 27.16ml

Epoch 61: current best loss = 1.59414, at epoch 57
Train batch 1/32 - 235.8ms/batch - loss: 1.42086 - diff: 22.73mlTrain batch 2/32 - 236.1ms/batch - loss: 1.32015 - diff: 21.12mlTrain batch 3/32 - 235.5ms/batch - loss: 1.74717 - diff: 27.95mlTrain batch 4/32 - 236.2ms/batch - loss: 1.78404 - diff: 28.54mlTrain batch 5/32 - 235.5ms/batch - loss: 1.67837 - diff: 26.85mlTrain batch 6/32 - 238.5ms/batch - loss: 1.75996 - diff: 28.16mlTrain batch 7/32 - 235.9ms/batch - loss: 1.75030 - diff: 28.00mlTrain batch 8/32 - 236.1ms/batch - loss: 1.70337 - diff: 27.25mlTrain batch 9/32 - 235.2ms/batch - loss: 1.68066 - diff: 26.89mlTrain batch 10/32 - 236.4ms/batch - loss: 1.64390 - diff: 26.30mlTrain batch 11/32 - 235.6ms/batch - loss: 1.63237 - diff: 26.12mlTrain batch 12/32 - 242.0ms/batch - loss: 1.63263 - diff: 26.12mlTrain batch 13/32 - 236.0ms/batch - loss: 1.63011 - diff: 26.08mlTrain batch 14/32 - 236.6ms/batch - loss: 1.66919 - diff: 26.71mlTrain batch 15/32 - 235.6ms/batch - loss: 1.67294 - diff: 26.77mlTrain batch 16/32 - 235.7ms/batch - loss: 1.65816 - diff: 26.53mlTrain batch 17/32 - 236.3ms/batch - loss: 1.68421 - diff: 26.95mlTrain batch 18/32 - 235.6ms/batch - loss: 1.69682 - diff: 27.15mlTrain batch 19/32 - 235.7ms/batch - loss: 1.71992 - diff: 27.52mlTrain batch 20/32 - 235.8ms/batch - loss: 1.74064 - diff: 27.85mlTrain batch 21/32 - 235.8ms/batch - loss: 1.78476 - diff: 28.56mlTrain batch 22/32 - 235.7ms/batch - loss: 1.76067 - diff: 28.17mlTrain batch 23/32 - 235.8ms/batch - loss: 1.78772 - diff: 28.60mlTrain batch 24/32 - 236.1ms/batch - loss: 1.85298 - diff: 29.65mlTrain batch 25/32 - 236.4ms/batch - loss: 1.83664 - diff: 29.39mlTrain batch 26/32 - 236.4ms/batch - loss: 1.85627 - diff: 29.70mlTrain batch 27/32 - 236.8ms/batch - loss: 1.83467 - diff: 29.35mlTrain batch 28/32 - 236.1ms/batch - loss: 1.84212 - diff: 29.47mlTrain batch 29/32 - 242.0ms/batch - loss: 1.83866 - diff: 29.42mlTrain batch 30/32 - 235.5ms/batch - loss: 1.83408 - diff: 29.35mlTrain batch 31/32 - 236.5ms/batch - loss: 1.83486 - diff: 29.36mlTrain batch 32/32 - 85.2ms/batch - loss: 1.88914 - diff: 29.40mlTrain batch 32/32 - 17.3s 85.2ms/batch - loss: 1.88914 - diff: 29.40ml
Test 1.4s: val_loss: 2.02230 - diff: 30.64ml

Epoch 62: current best loss = 1.59414, at epoch 57
Train batch 1/32 - 235.8ms/batch - loss: 1.37400 - diff: 21.98mlTrain batch 2/32 - 238.2ms/batch - loss: 2.12693 - diff: 34.03mlTrain batch 3/32 - 236.0ms/batch - loss: 1.86427 - diff: 29.83mlTrain batch 4/32 - 236.2ms/batch - loss: 1.78213 - diff: 28.51mlTrain batch 5/32 - 235.8ms/batch - loss: 1.78892 - diff: 28.62mlTrain batch 6/32 - 236.5ms/batch - loss: 1.85665 - diff: 29.71mlTrain batch 7/32 - 236.1ms/batch - loss: 1.76788 - diff: 28.29mlTrain batch 8/32 - 238.8ms/batch - loss: 1.81831 - diff: 29.09mlTrain batch 9/32 - 235.6ms/batch - loss: 1.75381 - diff: 28.06mlTrain batch 10/32 - 235.7ms/batch - loss: 1.74245 - diff: 27.88mlTrain batch 11/32 - 236.7ms/batch - loss: 1.71744 - diff: 27.48mlTrain batch 12/32 - 236.3ms/batch - loss: 1.71176 - diff: 27.39mlTrain batch 13/32 - 235.7ms/batch - loss: 1.72333 - diff: 27.57mlTrain batch 14/32 - 236.1ms/batch - loss: 1.75495 - diff: 28.08mlTrain batch 15/32 - 235.9ms/batch - loss: 1.73753 - diff: 27.80mlTrain batch 16/32 - 240.1ms/batch - loss: 1.69219 - diff: 27.08mlTrain batch 17/32 - 235.8ms/batch - loss: 1.68575 - diff: 26.97mlTrain batch 18/32 - 236.5ms/batch - loss: 1.66382 - diff: 26.62mlTrain batch 19/32 - 236.2ms/batch - loss: 1.68532 - diff: 26.97mlTrain batch 20/32 - 236.7ms/batch - loss: 1.67807 - diff: 26.85mlTrain batch 21/32 - 235.6ms/batch - loss: 1.69207 - diff: 27.07mlTrain batch 22/32 - 244.4ms/batch - loss: 1.66226 - diff: 26.60mlTrain batch 23/32 - 235.9ms/batch - loss: 1.63071 - diff: 26.09mlTrain batch 24/32 - 236.9ms/batch - loss: 1.59915 - diff: 25.59mlTrain batch 25/32 - 236.5ms/batch - loss: 1.59605 - diff: 25.54mlTrain batch 26/32 - 241.5ms/batch - loss: 1.59901 - diff: 25.58mlTrain batch 27/32 - 235.4ms/batch - loss: 1.60732 - diff: 25.72mlTrain batch 28/32 - 236.1ms/batch - loss: 1.60578 - diff: 25.69mlTrain batch 29/32 - 239.6ms/batch - loss: 1.63380 - diff: 26.14mlTrain batch 30/32 - 236.5ms/batch - loss: 1.64862 - diff: 26.38mlTrain batch 31/32 - 235.9ms/batch - loss: 1.69309 - diff: 27.09mlTrain batch 32/32 - 76.4ms/batch - loss: 1.70047 - diff: 26.96mlTrain batch 32/32 - 16.9s 76.4ms/batch - loss: 1.70047 - diff: 26.96ml
Test 1.4s: val_loss: 1.67012 - diff: 25.39ml

Epoch 63: current best loss = 1.59414, at epoch 57
Train batch 1/32 - 236.0ms/batch - loss: 1.46366 - diff: 23.42mlTrain batch 2/32 - 236.8ms/batch - loss: 1.55554 - diff: 24.89mlTrain batch 3/32 - 235.7ms/batch - loss: 1.76203 - diff: 28.19mlTrain batch 4/32 - 236.3ms/batch - loss: 1.85237 - diff: 29.64mlTrain batch 5/32 - 241.7ms/batch - loss: 1.76142 - diff: 28.18mlTrain batch 6/32 - 252.3ms/batch - loss: 1.70694 - diff: 27.31mlTrain batch 7/32 - 235.9ms/batch - loss: 1.73561 - diff: 27.77mlTrain batch 8/32 - 235.5ms/batch - loss: 1.69612 - diff: 27.14mlTrain batch 9/32 - 235.5ms/batch - loss: 1.63463 - diff: 26.15mlTrain batch 10/32 - 237.1ms/batch - loss: 1.64105 - diff: 26.26mlTrain batch 11/32 - 235.5ms/batch - loss: 1.61934 - diff: 25.91mlTrain batch 12/32 - 243.0ms/batch - loss: 1.62841 - diff: 26.05mlTrain batch 13/32 - 235.4ms/batch - loss: 1.59450 - diff: 25.51mlTrain batch 14/32 - 236.9ms/batch - loss: 1.56874 - diff: 25.10mlTrain batch 15/32 - 235.7ms/batch - loss: 1.56369 - diff: 25.02mlTrain batch 16/32 - 237.1ms/batch - loss: 1.60595 - diff: 25.70mlTrain batch 17/32 - 235.9ms/batch - loss: 1.61734 - diff: 25.88mlTrain batch 18/32 - 236.1ms/batch - loss: 1.60600 - diff: 25.70mlTrain batch 19/32 - 236.1ms/batch - loss: 1.62626 - diff: 26.02mlTrain batch 20/32 - 235.6ms/batch - loss: 1.61895 - diff: 25.90mlTrain batch 21/32 - 236.0ms/batch - loss: 1.63045 - diff: 26.09mlTrain batch 22/32 - 236.1ms/batch - loss: 1.64082 - diff: 26.25mlTrain batch 23/32 - 235.8ms/batch - loss: 1.64290 - diff: 26.29mlTrain batch 24/32 - 236.3ms/batch - loss: 1.67328 - diff: 26.77mlTrain batch 25/32 - 235.7ms/batch - loss: 1.69345 - diff: 27.10mlTrain batch 26/32 - 236.4ms/batch - loss: 1.68603 - diff: 26.98mlTrain batch 27/32 - 235.9ms/batch - loss: 1.70955 - diff: 27.35mlTrain batch 28/32 - 236.0ms/batch - loss: 1.72552 - diff: 27.61mlTrain batch 29/32 - 235.5ms/batch - loss: 1.71828 - diff: 27.49mlTrain batch 30/32 - 235.2ms/batch - loss: 1.72949 - diff: 27.67mlTrain batch 31/32 - 235.8ms/batch - loss: 1.73370 - diff: 27.74mlTrain batch 32/32 - 84.0ms/batch - loss: 1.77068 - diff: 27.72mlTrain batch 32/32 - 18.1s 84.0ms/batch - loss: 1.77068 - diff: 27.72ml
Test 1.4s: val_loss: 1.53898 - diff: 23.85ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_WideResNet50_0_Adam-0.001_MAE_DA3_best

Epoch 64: current best loss = 1.53898, at epoch 63
Train batch 1/32 - 253.2ms/batch - loss: 1.85232 - diff: 29.64mlTrain batch 2/32 - 237.2ms/batch - loss: 1.61444 - diff: 25.83mlTrain batch 3/32 - 235.6ms/batch - loss: 1.42998 - diff: 22.88mlTrain batch 4/32 - 235.3ms/batch - loss: 1.31642 - diff: 21.06mlTrain batch 5/32 - 235.6ms/batch - loss: 1.37538 - diff: 22.01mlTrain batch 6/32 - 236.3ms/batch - loss: 1.33739 - diff: 21.40mlTrain batch 7/32 - 236.0ms/batch - loss: 1.36516 - diff: 21.84mlTrain batch 8/32 - 244.4ms/batch - loss: 1.40030 - diff: 22.40mlTrain batch 9/32 - 235.5ms/batch - loss: 1.45695 - diff: 23.31mlTrain batch 10/32 - 235.8ms/batch - loss: 1.40680 - diff: 22.51mlTrain batch 11/32 - 235.9ms/batch - loss: 1.51643 - diff: 24.26mlTrain batch 12/32 - 237.6ms/batch - loss: 1.56023 - diff: 24.96mlTrain batch 13/32 - 236.6ms/batch - loss: 1.60664 - diff: 25.71mlTrain batch 14/32 - 236.0ms/batch - loss: 1.61039 - diff: 25.77mlTrain batch 15/32 - 235.6ms/batch - loss: 1.59997 - diff: 25.60mlTrain batch 16/32 - 236.1ms/batch - loss: 1.60493 - diff: 25.68mlTrain batch 17/32 - 235.6ms/batch - loss: 1.60775 - diff: 25.72mlTrain batch 18/32 - 235.5ms/batch - loss: 1.60388 - diff: 25.66mlTrain batch 19/32 - 235.2ms/batch - loss: 1.64227 - diff: 26.28mlTrain batch 20/32 - 236.6ms/batch - loss: 1.64754 - diff: 26.36mlTrain batch 21/32 - 236.4ms/batch - loss: 1.63956 - diff: 26.23mlTrain batch 22/32 - 236.1ms/batch - loss: 1.63589 - diff: 26.17mlTrain batch 23/32 - 235.9ms/batch - loss: 1.62365 - diff: 25.98mlTrain batch 24/32 - 236.4ms/batch - loss: 1.61504 - diff: 25.84mlTrain batch 25/32 - 236.4ms/batch - loss: 1.61629 - diff: 25.86mlTrain batch 26/32 - 236.4ms/batch - loss: 1.60996 - diff: 25.76mlTrain batch 27/32 - 236.5ms/batch - loss: 1.61409 - diff: 25.83mlTrain batch 28/32 - 236.4ms/batch - loss: 1.62129 - diff: 25.94mlTrain batch 29/32 - 235.9ms/batch - loss: 1.62625 - diff: 26.02mlTrain batch 30/32 - 236.4ms/batch - loss: 1.65342 - diff: 26.45mlTrain batch 31/32 - 236.1ms/batch - loss: 1.64501 - diff: 26.32mlTrain batch 32/32 - 97.7ms/batch - loss: 1.68789 - diff: 26.33mlTrain batch 32/32 - 16.2s 97.7ms/batch - loss: 1.68789 - diff: 26.33ml
Test 1.4s: val_loss: 2.04886 - diff: 31.57ml

Epoch 65: current best loss = 1.53898, at epoch 63
Train batch 1/32 - 235.5ms/batch - loss: 1.21032 - diff: 19.37mlTrain batch 2/32 - 242.1ms/batch - loss: 1.81558 - diff: 29.05mlTrain batch 3/32 - 236.0ms/batch - loss: 1.66806 - diff: 26.69mlTrain batch 4/32 - 236.5ms/batch - loss: 1.69661 - diff: 27.15mlTrain batch 5/32 - 236.3ms/batch - loss: 1.78589 - diff: 28.57mlTrain batch 6/32 - 236.4ms/batch - loss: 1.78936 - diff: 28.63mlTrain batch 7/32 - 236.6ms/batch - loss: 1.77656 - diff: 28.42mlTrain batch 8/32 - 236.2ms/batch - loss: 1.74713 - diff: 27.95mlTrain batch 9/32 - 236.5ms/batch - loss: 1.76456 - diff: 28.23mlTrain batch 10/32 - 236.2ms/batch - loss: 1.77844 - diff: 28.46mlTrain batch 11/32 - 236.5ms/batch - loss: 1.85433 - diff: 29.67mlTrain batch 12/32 - 236.5ms/batch - loss: 1.85486 - diff: 29.68mlTrain batch 13/32 - 236.6ms/batch - loss: 1.85914 - diff: 29.75mlTrain batch 14/32 - 236.7ms/batch - loss: 1.82315 - diff: 29.17mlTrain batch 15/32 - 236.6ms/batch - loss: 1.78236 - diff: 28.52mlTrain batch 16/32 - 237.5ms/batch - loss: 1.77126 - diff: 28.34mlTrain batch 17/32 - 236.4ms/batch - loss: 1.74373 - diff: 27.90mlTrain batch 18/32 - 236.7ms/batch - loss: 1.73703 - diff: 27.79mlTrain batch 19/32 - 236.5ms/batch - loss: 1.74200 - diff: 27.87mlTrain batch 20/32 - 236.9ms/batch - loss: 1.74483 - diff: 27.92mlTrain batch 21/32 - 236.0ms/batch - loss: 1.77341 - diff: 28.37mlTrain batch 22/32 - 236.4ms/batch - loss: 1.76303 - diff: 28.21mlTrain batch 23/32 - 235.9ms/batch - loss: 1.75334 - diff: 28.05mlTrain batch 24/32 - 236.9ms/batch - loss: 1.78053 - diff: 28.49mlTrain batch 25/32 - 235.9ms/batch - loss: 1.81660 - diff: 29.07mlTrain batch 26/32 - 236.5ms/batch - loss: 1.83457 - diff: 29.35mlTrain batch 27/32 - 236.5ms/batch - loss: 1.87313 - diff: 29.97mlTrain batch 28/32 - 236.1ms/batch - loss: 1.87284 - diff: 29.97mlTrain batch 29/32 - 235.4ms/batch - loss: 1.85573 - diff: 29.69mlTrain batch 30/32 - 236.1ms/batch - loss: 1.85038 - diff: 29.61mlTrain batch 31/32 - 236.2ms/batch - loss: 1.85910 - diff: 29.75mlTrain batch 32/32 - 83.1ms/batch - loss: 1.87827 - diff: 29.64mlTrain batch 32/32 - 16.3s 83.1ms/batch - loss: 1.87827 - diff: 29.64ml
Test 1.4s: val_loss: 1.59507 - diff: 24.64ml

Epoch 66: current best loss = 1.53898, at epoch 63
Train batch 1/32 - 235.7ms/batch - loss: 1.65963 - diff: 26.55mlTrain batch 2/32 - 235.6ms/batch - loss: 1.58099 - diff: 25.30mlTrain batch 3/32 - 235.5ms/batch - loss: 1.49595 - diff: 23.94mlTrain batch 4/32 - 236.4ms/batch - loss: 1.53397 - diff: 24.54mlTrain batch 5/32 - 235.8ms/batch - loss: 1.53729 - diff: 24.60mlTrain batch 6/32 - 236.0ms/batch - loss: 1.62040 - diff: 25.93mlTrain batch 7/32 - 238.1ms/batch - loss: 1.59460 - diff: 25.51mlTrain batch 8/32 - 235.7ms/batch - loss: 1.64860 - diff: 26.38mlTrain batch 9/32 - 236.3ms/batch - loss: 1.60253 - diff: 25.64mlTrain batch 10/32 - 237.8ms/batch - loss: 1.55013 - diff: 24.80mlTrain batch 11/32 - 235.8ms/batch - loss: 1.51705 - diff: 24.27mlTrain batch 12/32 - 236.1ms/batch - loss: 1.48183 - diff: 23.71mlTrain batch 13/32 - 235.8ms/batch - loss: 1.53030 - diff: 24.48mlTrain batch 14/32 - 236.2ms/batch - loss: 1.57758 - diff: 25.24mlTrain batch 15/32 - 236.3ms/batch - loss: 1.59804 - diff: 25.57mlTrain batch 16/32 - 236.2ms/batch - loss: 1.57724 - diff: 25.24mlTrain batch 17/32 - 237.0ms/batch - loss: 1.61180 - diff: 25.79mlTrain batch 18/32 - 236.8ms/batch - loss: 1.62838 - diff: 26.05mlTrain batch 19/32 - 236.3ms/batch - loss: 1.64742 - diff: 26.36mlTrain batch 20/32 - 236.8ms/batch - loss: 1.64873 - diff: 26.38mlTrain batch 21/32 - 235.6ms/batch - loss: 1.65323 - diff: 26.45mlTrain batch 22/32 - 236.1ms/batch - loss: 1.64103 - diff: 26.26mlTrain batch 23/32 - 235.7ms/batch - loss: 1.64141 - diff: 26.26mlTrain batch 24/32 - 236.1ms/batch - loss: 1.61697 - diff: 25.87mlTrain batch 25/32 - 236.4ms/batch - loss: 1.63285 - diff: 26.13mlTrain batch 26/32 - 236.7ms/batch - loss: 1.63743 - diff: 26.20mlTrain batch 27/32 - 235.9ms/batch - loss: 1.62996 - diff: 26.08mlTrain batch 28/32 - 236.2ms/batch - loss: 1.65266 - diff: 26.44mlTrain batch 29/32 - 235.6ms/batch - loss: 1.65941 - diff: 26.55mlTrain batch 30/32 - 236.3ms/batch - loss: 1.66127 - diff: 26.58mlTrain batch 31/32 - 235.8ms/batch - loss: 1.63734 - diff: 26.20mlTrain batch 32/32 - 76.9ms/batch - loss: 1.64245 - diff: 26.06mlTrain batch 32/32 - 17.0s 76.9ms/batch - loss: 1.64245 - diff: 26.06ml
Test 1.5s: val_loss: 1.52386 - diff: 23.59ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_WideResNet50_0_Adam-0.001_MAE_DA3_best

Epoch 67: current best loss = 1.52386, at epoch 66
Train batch 1/32 - 256.6ms/batch - loss: 2.03566 - diff: 32.57mlTrain batch 2/32 - 236.2ms/batch - loss: 1.75751 - diff: 28.12mlTrain batch 3/32 - 235.7ms/batch - loss: 1.88594 - diff: 30.18mlTrain batch 4/32 - 235.9ms/batch - loss: 1.90432 - diff: 30.47mlTrain batch 5/32 - 236.8ms/batch - loss: 1.81472 - diff: 29.04mlTrain batch 6/32 - 236.5ms/batch - loss: 1.76470 - diff: 28.24mlTrain batch 7/32 - 238.1ms/batch - loss: 1.73880 - diff: 27.82mlTrain batch 8/32 - 236.1ms/batch - loss: 1.75242 - diff: 28.04mlTrain batch 9/32 - 236.5ms/batch - loss: 1.72017 - diff: 27.52mlTrain batch 10/32 - 236.0ms/batch - loss: 1.70295 - diff: 27.25mlTrain batch 11/32 - 236.0ms/batch - loss: 1.71778 - diff: 27.48mlTrain batch 12/32 - 236.1ms/batch - loss: 1.71095 - diff: 27.38mlTrain batch 13/32 - 236.1ms/batch - loss: 1.68780 - diff: 27.00mlTrain batch 14/32 - 236.0ms/batch - loss: 1.74038 - diff: 27.85mlTrain batch 15/32 - 236.0ms/batch - loss: 1.77131 - diff: 28.34mlTrain batch 16/32 - 235.6ms/batch - loss: 1.78732 - diff: 28.60mlTrain batch 17/32 - 236.0ms/batch - loss: 1.78430 - diff: 28.55mlTrain batch 18/32 - 239.9ms/batch - loss: 1.73512 - diff: 27.76mlTrain batch 19/32 - 235.9ms/batch - loss: 1.76682 - diff: 28.27mlTrain batch 20/32 - 235.6ms/batch - loss: 1.81633 - diff: 29.06mlTrain batch 21/32 - 236.4ms/batch - loss: 1.80315 - diff: 28.85mlTrain batch 22/32 - 235.7ms/batch - loss: 1.76619 - diff: 28.26mlTrain batch 23/32 - 235.8ms/batch - loss: 1.77292 - diff: 28.37mlTrain batch 24/32 - 235.5ms/batch - loss: 1.75985 - diff: 28.16mlTrain batch 25/32 - 235.7ms/batch - loss: 1.76897 - diff: 28.30mlTrain batch 26/32 - 235.3ms/batch - loss: 1.76261 - diff: 28.20mlTrain batch 27/32 - 237.1ms/batch - loss: 1.75837 - diff: 28.13mlTrain batch 28/32 - 236.1ms/batch - loss: 1.74793 - diff: 27.97mlTrain batch 29/32 - 236.2ms/batch - loss: 1.72559 - diff: 27.61mlTrain batch 30/32 - 236.1ms/batch - loss: 1.71026 - diff: 27.36mlTrain batch 31/32 - 236.0ms/batch - loss: 1.69619 - diff: 27.14mlTrain batch 32/32 - 76.5ms/batch - loss: 1.82501 - diff: 27.49mlTrain batch 32/32 - 16.8s 76.5ms/batch - loss: 1.82501 - diff: 27.49ml
Test 1.4s: val_loss: 3.50496 - diff: 53.83ml

Epoch 68: current best loss = 1.52386, at epoch 66
Train batch 1/32 - 235.6ms/batch - loss: 1.32426 - diff: 21.19mlTrain batch 2/32 - 236.5ms/batch - loss: 1.52197 - diff: 24.35mlTrain batch 3/32 - 235.9ms/batch - loss: 1.58355 - diff: 25.34mlTrain batch 4/32 - 242.9ms/batch - loss: 1.52423 - diff: 24.39mlTrain batch 5/32 - 236.0ms/batch - loss: 1.69749 - diff: 27.16mlTrain batch 6/32 - 237.4ms/batch - loss: 1.82402 - diff: 29.18mlTrain batch 7/32 - 236.8ms/batch - loss: 1.85950 - diff: 29.75mlTrain batch 8/32 - 237.1ms/batch - loss: 1.78222 - diff: 28.52mlTrain batch 9/32 - 236.2ms/batch - loss: 1.77163 - diff: 28.35mlTrain batch 10/32 - 236.6ms/batch - loss: 1.74475 - diff: 27.92mlTrain batch 11/32 - 251.6ms/batch - loss: 1.73459 - diff: 27.75mlTrain batch 12/32 - 236.3ms/batch - loss: 1.73346 - diff: 27.74mlTrain batch 13/32 - 236.0ms/batch - loss: 1.69975 - diff: 27.20mlTrain batch 14/32 - 236.1ms/batch - loss: 1.75975 - diff: 28.16mlTrain batch 15/32 - 236.4ms/batch - loss: 1.72872 - diff: 27.66mlTrain batch 16/32 - 236.8ms/batch - loss: 1.72449 - diff: 27.59mlTrain batch 17/32 - 236.2ms/batch - loss: 1.73076 - diff: 27.69mlTrain batch 18/32 - 236.6ms/batch - loss: 1.69734 - diff: 27.16mlTrain batch 19/32 - 235.8ms/batch - loss: 1.69018 - diff: 27.04mlTrain batch 20/32 - 236.9ms/batch - loss: 1.68318 - diff: 26.93mlTrain batch 21/32 - 235.7ms/batch - loss: 1.69169 - diff: 27.07mlTrain batch 22/32 - 237.5ms/batch - loss: 1.73582 - diff: 27.77mlTrain batch 23/32 - 236.1ms/batch - loss: 1.72806 - diff: 27.65mlTrain batch 24/32 - 237.2ms/batch - loss: 1.72887 - diff: 27.66mlTrain batch 25/32 - 236.5ms/batch - loss: 1.70813 - diff: 27.33mlTrain batch 26/32 - 236.7ms/batch - loss: 1.69971 - diff: 27.20mlTrain batch 27/32 - 235.8ms/batch - loss: 1.72436 - diff: 27.59mlTrain batch 28/32 - 236.2ms/batch - loss: 1.71370 - diff: 27.42mlTrain batch 29/32 - 235.5ms/batch - loss: 1.70868 - diff: 27.34mlTrain batch 30/32 - 235.4ms/batch - loss: 1.70499 - diff: 27.28mlTrain batch 31/32 - 235.7ms/batch - loss: 1.71285 - diff: 27.41mlTrain batch 32/32 - 83.7ms/batch - loss: 1.78272 - diff: 27.52mlTrain batch 32/32 - 16.5s 83.7ms/batch - loss: 1.78272 - diff: 27.52ml
Test 1.4s: val_loss: 1.54184 - diff: 23.55ml

Epoch 69: current best loss = 1.52386, at epoch 66
Train batch 1/32 - 236.3ms/batch - loss: 1.39790 - diff: 22.37mlTrain batch 2/32 - 236.3ms/batch - loss: 1.46504 - diff: 23.44mlTrain batch 3/32 - 236.1ms/batch - loss: 1.42317 - diff: 22.77mlTrain batch 4/32 - 235.9ms/batch - loss: 1.61099 - diff: 25.78mlTrain batch 5/32 - 235.7ms/batch - loss: 1.64405 - diff: 26.30mlTrain batch 6/32 - 236.5ms/batch - loss: 1.66908 - diff: 26.71mlTrain batch 7/32 - 235.8ms/batch - loss: 1.74848 - diff: 27.98mlTrain batch 8/32 - 236.3ms/batch - loss: 1.67542 - diff: 26.81mlTrain batch 9/32 - 235.4ms/batch - loss: 1.63226 - diff: 26.12mlTrain batch 10/32 - 236.7ms/batch - loss: 1.64785 - diff: 26.37mlTrain batch 11/32 - 236.0ms/batch - loss: 1.64814 - diff: 26.37mlTrain batch 12/32 - 249.7ms/batch - loss: 1.64290 - diff: 26.29mlTrain batch 13/32 - 247.8ms/batch - loss: 1.68031 - diff: 26.88mlTrain batch 14/32 - 240.4ms/batch - loss: 1.68795 - diff: 27.01mlTrain batch 15/32 - 235.7ms/batch - loss: 1.68105 - diff: 26.90mlTrain batch 16/32 - 245.9ms/batch - loss: 1.65291 - diff: 26.45mlTrain batch 17/32 - 235.9ms/batch - loss: 1.64796 - diff: 26.37mlTrain batch 18/32 - 237.0ms/batch - loss: 1.64408 - diff: 26.31mlTrain batch 19/32 - 240.8ms/batch - loss: 1.64742 - diff: 26.36mlTrain batch 20/32 - 236.0ms/batch - loss: 1.63965 - diff: 26.23mlTrain batch 21/32 - 235.7ms/batch - loss: 1.62474 - diff: 26.00mlTrain batch 22/32 - 246.2ms/batch - loss: 1.65175 - diff: 26.43mlTrain batch 23/32 - 235.7ms/batch - loss: 1.64043 - diff: 26.25mlTrain batch 24/32 - 235.4ms/batch - loss: 1.63349 - diff: 26.14mlTrain batch 25/32 - 236.2ms/batch - loss: 1.61997 - diff: 25.92mlTrain batch 26/32 - 235.9ms/batch - loss: 1.62864 - diff: 26.06mlTrain batch 27/32 - 238.6ms/batch - loss: 1.60623 - diff: 25.70mlTrain batch 28/32 - 235.4ms/batch - loss: 1.60059 - diff: 25.61mlTrain batch 29/32 - 236.9ms/batch - loss: 1.62565 - diff: 26.01mlTrain batch 30/32 - 235.5ms/batch - loss: 1.61999 - diff: 25.92mlTrain batch 31/32 - 235.7ms/batch - loss: 1.64960 - diff: 26.39mlTrain batch 32/32 - 76.5ms/batch - loss: 1.67328 - diff: 26.33mlTrain batch 32/32 - 17.3s 76.5ms/batch - loss: 1.67328 - diff: 26.33ml
Test 1.4s: val_loss: 1.55354 - diff: 23.23ml

Epoch 70: current best loss = 1.52386, at epoch 66
Train batch 1/32 - 236.1ms/batch - loss: 2.03980 - diff: 32.64mlTrain batch 2/32 - 236.2ms/batch - loss: 1.86784 - diff: 29.89mlTrain batch 3/32 - 235.5ms/batch - loss: 2.09457 - diff: 33.51mlTrain batch 4/32 - 235.9ms/batch - loss: 2.02712 - diff: 32.43mlTrain batch 5/32 - 236.0ms/batch - loss: 1.90977 - diff: 30.56mlTrain batch 6/32 - 236.6ms/batch - loss: 1.74059 - diff: 27.85mlTrain batch 7/32 - 241.7ms/batch - loss: 1.70538 - diff: 27.29mlTrain batch 8/32 - 236.9ms/batch - loss: 1.70231 - diff: 27.24mlTrain batch 9/32 - 235.3ms/batch - loss: 1.62412 - diff: 25.99mlTrain batch 10/32 - 236.4ms/batch - loss: 1.61901 - diff: 25.90mlTrain batch 11/32 - 237.0ms/batch - loss: 1.64719 - diff: 26.36mlTrain batch 12/32 - 236.6ms/batch - loss: 1.63536 - diff: 26.17mlTrain batch 13/32 - 235.8ms/batch - loss: 1.61607 - diff: 25.86mlTrain batch 14/32 - 236.1ms/batch - loss: 1.65257 - diff: 26.44mlTrain batch 15/32 - 236.0ms/batch - loss: 1.67716 - diff: 26.83mlTrain batch 16/32 - 236.7ms/batch - loss: 1.73870 - diff: 27.82mlTrain batch 17/32 - 235.9ms/batch - loss: 1.80429 - diff: 28.87mlTrain batch 18/32 - 235.9ms/batch - loss: 1.80298 - diff: 28.85mlTrain batch 19/32 - 236.2ms/batch - loss: 1.80497 - diff: 28.88mlTrain batch 20/32 - 239.6ms/batch - loss: 1.78707 - diff: 28.59mlTrain batch 21/32 - 235.5ms/batch - loss: 1.77318 - diff: 28.37mlTrain batch 22/32 - 235.7ms/batch - loss: 1.74977 - diff: 28.00mlTrain batch 23/32 - 235.9ms/batch - loss: 1.72335 - diff: 27.57mlTrain batch 24/32 - 236.4ms/batch - loss: 1.73390 - diff: 27.74mlTrain batch 25/32 - 239.5ms/batch - loss: 1.71290 - diff: 27.41mlTrain batch 26/32 - 236.6ms/batch - loss: 1.68868 - diff: 27.02mlTrain batch 27/32 - 236.0ms/batch - loss: 1.69854 - diff: 27.18mlTrain batch 28/32 - 236.4ms/batch - loss: 1.69287 - diff: 27.09mlTrain batch 29/32 - 235.2ms/batch - loss: 1.68732 - diff: 27.00mlTrain batch 30/32 - 236.5ms/batch - loss: 1.69234 - diff: 27.08mlTrain batch 31/32 - 236.1ms/batch - loss: 1.67014 - diff: 26.72mlTrain batch 32/32 - 76.4ms/batch - loss: 1.71897 - diff: 26.76mlTrain batch 32/32 - 18.3s 76.4ms/batch - loss: 1.71897 - diff: 26.76ml
Test 1.4s: val_loss: 1.64881 - diff: 25.36ml

Epoch 71: current best loss = 1.52386, at epoch 66
Train batch 1/32 - 235.5ms/batch - loss: 1.30372 - diff: 20.86mlTrain batch 2/32 - 235.4ms/batch - loss: 1.56683 - diff: 25.07mlTrain batch 3/32 - 235.5ms/batch - loss: 1.64814 - diff: 26.37mlTrain batch 4/32 - 235.0ms/batch - loss: 1.87967 - diff: 30.07mlTrain batch 5/32 - 235.4ms/batch - loss: 1.79319 - diff: 28.69mlTrain batch 6/32 - 236.3ms/batch - loss: 1.74180 - diff: 27.87mlTrain batch 7/32 - 235.7ms/batch - loss: 1.71997 - diff: 27.52mlTrain batch 8/32 - 245.5ms/batch - loss: 1.74062 - diff: 27.85mlTrain batch 9/32 - 235.8ms/batch - loss: 1.91020 - diff: 30.56mlTrain batch 10/32 - 236.5ms/batch - loss: 1.84417 - diff: 29.51mlTrain batch 11/32 - 235.3ms/batch - loss: 1.82383 - diff: 29.18mlTrain batch 12/32 - 236.4ms/batch - loss: 1.83408 - diff: 29.35mlTrain batch 13/32 - 236.2ms/batch - loss: 1.78783 - diff: 28.61mlTrain batch 14/32 - 236.1ms/batch - loss: 1.79093 - diff: 28.65mlTrain batch 15/32 - 235.7ms/batch - loss: 1.76800 - diff: 28.29mlTrain batch 16/32 - 236.4ms/batch - loss: 1.73805 - diff: 27.81mlTrain batch 17/32 - 234.7ms/batch - loss: 1.74183 - diff: 27.87mlTrain batch 18/32 - 235.9ms/batch - loss: 1.70370 - diff: 27.26mlTrain batch 19/32 - 236.0ms/batch - loss: 1.69165 - diff: 27.07mlTrain batch 20/32 - 241.5ms/batch - loss: 1.72023 - diff: 27.52mlTrain batch 21/32 - 237.8ms/batch - loss: 1.70832 - diff: 27.33mlTrain batch 22/32 - 235.8ms/batch - loss: 1.70317 - diff: 27.25mlTrain batch 23/32 - 236.4ms/batch - loss: 1.67098 - diff: 26.74mlTrain batch 24/32 - 236.2ms/batch - loss: 1.64817 - diff: 26.37mlTrain batch 25/32 - 235.7ms/batch - loss: 1.64417 - diff: 26.31mlTrain batch 26/32 - 235.5ms/batch - loss: 1.64827 - diff: 26.37mlTrain batch 27/32 - 235.4ms/batch - loss: 1.64508 - diff: 26.32mlTrain batch 28/32 - 235.1ms/batch - loss: 1.62269 - diff: 25.96mlTrain batch 29/32 - 238.8ms/batch - loss: 1.62292 - diff: 25.97mlTrain batch 30/32 - 240.1ms/batch - loss: 1.62167 - diff: 25.95mlTrain batch 31/32 - 238.7ms/batch - loss: 1.61502 - diff: 25.84mlTrain batch 32/32 - 76.3ms/batch - loss: 1.66105 - diff: 25.87mlTrain batch 32/32 - 18.4s 76.3ms/batch - loss: 1.66105 - diff: 25.87ml
Test 1.5s: val_loss: 1.71762 - diff: 26.45ml

Epoch 72: current best loss = 1.52386, at epoch 66
Train batch 1/32 - 235.8ms/batch - loss: 2.88394 - diff: 46.14mlTrain batch 2/32 - 235.6ms/batch - loss: 2.44650 - diff: 39.14mlTrain batch 3/32 - 236.2ms/batch - loss: 2.01041 - diff: 32.17mlTrain batch 4/32 - 236.4ms/batch - loss: 1.86379 - diff: 29.82mlTrain batch 5/32 - 235.4ms/batch - loss: 1.94558 - diff: 31.13mlTrain batch 6/32 - 236.5ms/batch - loss: 1.83469 - diff: 29.35mlTrain batch 7/32 - 235.5ms/batch - loss: 1.81167 - diff: 28.99mlTrain batch 8/32 - 235.9ms/batch - loss: 1.76846 - diff: 28.30mlTrain batch 9/32 - 235.4ms/batch - loss: 1.73086 - diff: 27.69mlTrain batch 10/32 - 236.8ms/batch - loss: 1.73961 - diff: 27.83mlTrain batch 11/32 - 236.6ms/batch - loss: 1.72756 - diff: 27.64mlTrain batch 12/32 - 236.4ms/batch - loss: 1.69616 - diff: 27.14mlTrain batch 13/32 - 235.8ms/batch - loss: 1.66628 - diff: 26.66mlTrain batch 14/32 - 236.4ms/batch - loss: 1.61360 - diff: 25.82mlTrain batch 15/32 - 235.6ms/batch - loss: 1.58958 - diff: 25.43mlTrain batch 16/32 - 236.4ms/batch - loss: 1.63511 - diff: 26.16mlTrain batch 17/32 - 235.8ms/batch - loss: 1.68552 - diff: 26.97mlTrain batch 18/32 - 236.4ms/batch - loss: 1.66091 - diff: 26.57mlTrain batch 19/32 - 235.6ms/batch - loss: 1.64220 - diff: 26.28mlTrain batch 20/32 - 236.3ms/batch - loss: 1.65123 - diff: 26.42mlTrain batch 21/32 - 235.5ms/batch - loss: 1.61387 - diff: 25.82mlTrain batch 22/32 - 235.9ms/batch - loss: 1.62088 - diff: 25.93mlTrain batch 23/32 - 235.5ms/batch - loss: 1.63398 - diff: 26.14mlTrain batch 24/32 - 244.0ms/batch - loss: 1.62022 - diff: 25.92mlTrain batch 25/32 - 235.8ms/batch - loss: 1.62389 - diff: 25.98mlTrain batch 26/32 - 236.1ms/batch - loss: 1.64544 - diff: 26.33mlTrain batch 27/32 - 235.8ms/batch - loss: 1.62767 - diff: 26.04mlTrain batch 28/32 - 236.0ms/batch - loss: 1.62841 - diff: 26.05mlTrain batch 29/32 - 235.8ms/batch - loss: 1.60549 - diff: 25.69mlTrain batch 30/32 - 235.9ms/batch - loss: 1.63284 - diff: 26.13mlTrain batch 31/32 - 236.4ms/batch - loss: 1.64620 - diff: 26.34mlTrain batch 32/32 - 76.6ms/batch - loss: 1.72210 - diff: 26.48mlTrain batch 32/32 - 17.0s 76.6ms/batch - loss: 1.72210 - diff: 26.48ml
Test 1.5s: val_loss: 1.53829 - diff: 24.12ml

Epoch 73: current best loss = 1.52386, at epoch 66
Train batch 1/32 - 235.8ms/batch - loss: 2.06986 - diff: 33.12mlTrain batch 2/32 - 236.4ms/batch - loss: 1.59220 - diff: 25.48mlTrain batch 3/32 - 235.9ms/batch - loss: 1.57529 - diff: 25.20mlTrain batch 4/32 - 236.0ms/batch - loss: 1.41971 - diff: 22.72mlTrain batch 5/32 - 235.9ms/batch - loss: 1.57042 - diff: 25.13mlTrain batch 6/32 - 235.8ms/batch - loss: 1.57126 - diff: 25.14mlTrain batch 7/32 - 235.5ms/batch - loss: 1.69075 - diff: 27.05mlTrain batch 8/32 - 235.5ms/batch - loss: 1.67073 - diff: 26.73mlTrain batch 9/32 - 235.7ms/batch - loss: 1.62755 - diff: 26.04mlTrain batch 10/32 - 236.4ms/batch - loss: 1.64218 - diff: 26.27mlTrain batch 11/32 - 236.2ms/batch - loss: 1.59422 - diff: 25.51mlTrain batch 12/32 - 235.6ms/batch - loss: 1.58838 - diff: 25.41mlTrain batch 13/32 - 234.7ms/batch - loss: 1.63220 - diff: 26.12mlTrain batch 14/32 - 235.7ms/batch - loss: 1.65233 - diff: 26.44mlTrain batch 15/32 - 235.9ms/batch - loss: 1.68960 - diff: 27.03mlTrain batch 16/32 - 242.7ms/batch - loss: 1.68527 - diff: 26.96mlTrain batch 17/32 - 236.0ms/batch - loss: 1.64298 - diff: 26.29mlTrain batch 18/32 - 235.5ms/batch - loss: 1.67078 - diff: 26.73mlTrain batch 19/32 - 235.8ms/batch - loss: 1.67340 - diff: 26.77mlTrain batch 20/32 - 236.6ms/batch - loss: 1.65493 - diff: 26.48mlTrain batch 21/32 - 235.4ms/batch - loss: 1.64570 - diff: 26.33mlTrain batch 22/32 - 236.3ms/batch - loss: 1.65450 - diff: 26.47mlTrain batch 23/32 - 235.7ms/batch - loss: 1.66424 - diff: 26.63mlTrain batch 24/32 - 235.2ms/batch - loss: 1.64904 - diff: 26.38mlTrain batch 25/32 - 235.7ms/batch - loss: 1.66536 - diff: 26.65mlTrain batch 26/32 - 236.3ms/batch - loss: 1.66360 - diff: 26.62mlTrain batch 27/32 - 238.4ms/batch - loss: 1.66192 - diff: 26.59mlTrain batch 28/32 - 236.3ms/batch - loss: 1.64540 - diff: 26.33mlTrain batch 29/32 - 235.7ms/batch - loss: 1.64043 - diff: 26.25mlTrain batch 30/32 - 235.3ms/batch - loss: 1.67048 - diff: 26.73mlTrain batch 31/32 - 235.3ms/batch - loss: 1.67423 - diff: 26.79mlTrain batch 32/32 - 82.1ms/batch - loss: 1.72582 - diff: 26.83mlTrain batch 32/32 - 16.8s 82.1ms/batch - loss: 1.72582 - diff: 26.83ml
Test 1.4s: val_loss: 2.18152 - diff: 33.24ml

Epoch 74: current best loss = 1.52386, at epoch 66
Train batch 1/32 - 235.4ms/batch - loss: 3.02264 - diff: 48.36mlTrain batch 2/32 - 235.8ms/batch - loss: 1.95482 - diff: 31.28mlTrain batch 3/32 - 235.8ms/batch - loss: 1.86617 - diff: 29.86mlTrain batch 4/32 - 242.2ms/batch - loss: 1.73237 - diff: 27.72mlTrain batch 5/32 - 235.8ms/batch - loss: 1.75379 - diff: 28.06mlTrain batch 6/32 - 235.9ms/batch - loss: 1.73022 - diff: 27.68mlTrain batch 7/32 - 235.4ms/batch - loss: 1.66498 - diff: 26.64mlTrain batch 8/32 - 246.8ms/batch - loss: 1.64150 - diff: 26.26mlTrain batch 9/32 - 235.6ms/batch - loss: 1.64559 - diff: 26.33mlTrain batch 10/32 - 236.3ms/batch - loss: 1.66184 - diff: 26.59mlTrain batch 11/32 - 236.0ms/batch - loss: 1.70949 - diff: 27.35mlTrain batch 12/32 - 236.4ms/batch - loss: 1.77787 - diff: 28.45mlTrain batch 13/32 - 236.6ms/batch - loss: 1.76486 - diff: 28.24mlTrain batch 14/32 - 236.3ms/batch - loss: 1.74901 - diff: 27.98mlTrain batch 15/32 - 235.9ms/batch - loss: 1.74419 - diff: 27.91mlTrain batch 16/32 - 236.3ms/batch - loss: 1.74881 - diff: 27.98mlTrain batch 17/32 - 236.2ms/batch - loss: 1.73957 - diff: 27.83mlTrain batch 18/32 - 241.1ms/batch - loss: 1.70758 - diff: 27.32mlTrain batch 19/32 - 237.2ms/batch - loss: 1.68594 - diff: 26.98mlTrain batch 20/32 - 236.5ms/batch - loss: 1.67412 - diff: 26.79mlTrain batch 21/32 - 237.0ms/batch - loss: 1.68077 - diff: 26.89mlTrain batch 22/32 - 240.4ms/batch - loss: 1.69264 - diff: 27.08mlTrain batch 23/32 - 236.6ms/batch - loss: 1.69715 - diff: 27.15mlTrain batch 24/32 - 238.1ms/batch - loss: 1.72357 - diff: 27.58mlTrain batch 25/32 - 235.4ms/batch - loss: 1.72127 - diff: 27.54mlTrain batch 26/32 - 236.6ms/batch - loss: 1.72422 - diff: 27.59mlTrain batch 27/32 - 251.0ms/batch - loss: 1.71878 - diff: 27.50mlTrain batch 28/32 - 236.5ms/batch - loss: 1.72867 - diff: 27.66mlTrain batch 29/32 - 235.8ms/batch - loss: 1.72011 - diff: 27.52mlTrain batch 30/32 - 235.9ms/batch - loss: 1.73254 - diff: 27.72mlTrain batch 31/32 - 236.4ms/batch - loss: 1.72946 - diff: 27.67mlTrain batch 32/32 - 90.7ms/batch - loss: 1.77623 - diff: 27.69mlTrain batch 32/32 - 16.9s 90.7ms/batch - loss: 1.77623 - diff: 27.69ml
Test 1.3s: val_loss: 1.46259 - diff: 22.15ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_WideResNet50_0_Adam-0.001_MAE_DA3_best

Epoch 75: current best loss = 1.46259, at epoch 74
Train batch 1/32 - 255.7ms/batch - loss: 1.76653 - diff: 28.26mlTrain batch 2/32 - 236.0ms/batch - loss: 1.60013 - diff: 25.60mlTrain batch 3/32 - 235.7ms/batch - loss: 1.58376 - diff: 25.34mlTrain batch 4/32 - 235.6ms/batch - loss: 1.63106 - diff: 26.10mlTrain batch 5/32 - 235.6ms/batch - loss: 1.70072 - diff: 27.21mlTrain batch 6/32 - 236.8ms/batch - loss: 1.95298 - diff: 31.25mlTrain batch 7/32 - 235.4ms/batch - loss: 1.86954 - diff: 29.91mlTrain batch 8/32 - 236.7ms/batch - loss: 1.83344 - diff: 29.34mlTrain batch 9/32 - 236.6ms/batch - loss: 1.78502 - diff: 28.56mlTrain batch 10/32 - 236.7ms/batch - loss: 1.77776 - diff: 28.44mlTrain batch 11/32 - 236.7ms/batch - loss: 1.81583 - diff: 29.05mlTrain batch 12/32 - 237.3ms/batch - loss: 1.81674 - diff: 29.07mlTrain batch 13/32 - 236.4ms/batch - loss: 1.75162 - diff: 28.03mlTrain batch 14/32 - 236.6ms/batch - loss: 1.79795 - diff: 28.77mlTrain batch 15/32 - 235.9ms/batch - loss: 1.82173 - diff: 29.15mlTrain batch 16/32 - 236.5ms/batch - loss: 1.78652 - diff: 28.58mlTrain batch 17/32 - 236.1ms/batch - loss: 1.77930 - diff: 28.47mlTrain batch 18/32 - 236.7ms/batch - loss: 1.73480 - diff: 27.76mlTrain batch 19/32 - 240.3ms/batch - loss: 1.72934 - diff: 27.67mlTrain batch 20/32 - 236.0ms/batch - loss: 1.71123 - diff: 27.38mlTrain batch 21/32 - 236.3ms/batch - loss: 1.68523 - diff: 26.96mlTrain batch 22/32 - 242.3ms/batch - loss: 1.66035 - diff: 26.57mlTrain batch 23/32 - 236.4ms/batch - loss: 1.67831 - diff: 26.85mlTrain batch 24/32 - 246.7ms/batch - loss: 1.67885 - diff: 26.86mlTrain batch 25/32 - 236.3ms/batch - loss: 1.67775 - diff: 26.84mlTrain batch 26/32 - 236.7ms/batch - loss: 1.66241 - diff: 26.60mlTrain batch 27/32 - 242.8ms/batch - loss: 1.67981 - diff: 26.88mlTrain batch 28/32 - 236.9ms/batch - loss: 1.65869 - diff: 26.54mlTrain batch 29/32 - 238.5ms/batch - loss: 1.68061 - diff: 26.89mlTrain batch 30/32 - 236.1ms/batch - loss: 1.66223 - diff: 26.60mlTrain batch 31/32 - 236.6ms/batch - loss: 1.64820 - diff: 26.37mlTrain batch 32/32 - 84.2ms/batch - loss: 1.76379 - diff: 26.68mlTrain batch 32/32 - 15.2s 84.2ms/batch - loss: 1.76379 - diff: 26.68ml
Test 1.4s: val_loss: 1.54162 - diff: 23.36ml

Epoch 76: current best loss = 1.46259, at epoch 74
Train batch 1/32 - 235.5ms/batch - loss: 1.53969 - diff: 24.64mlTrain batch 2/32 - 235.9ms/batch - loss: 1.60133 - diff: 25.62mlTrain batch 3/32 - 235.6ms/batch - loss: 1.61241 - diff: 25.80mlTrain batch 4/32 - 236.6ms/batch - loss: 1.72382 - diff: 27.58mlTrain batch 5/32 - 235.6ms/batch - loss: 1.76528 - diff: 28.24mlTrain batch 6/32 - 235.8ms/batch - loss: 1.69105 - diff: 27.06mlTrain batch 7/32 - 235.7ms/batch - loss: 1.69083 - diff: 27.05mlTrain batch 8/32 - 235.9ms/batch - loss: 1.68708 - diff: 26.99mlTrain batch 9/32 - 237.2ms/batch - loss: 1.67968 - diff: 26.87mlTrain batch 10/32 - 235.3ms/batch - loss: 1.73595 - diff: 27.78mlTrain batch 11/32 - 235.4ms/batch - loss: 1.71099 - diff: 27.38mlTrain batch 12/32 - 235.7ms/batch - loss: 1.68310 - diff: 26.93mlTrain batch 13/32 - 235.6ms/batch - loss: 1.63502 - diff: 26.16mlTrain batch 14/32 - 235.3ms/batch - loss: 1.62036 - diff: 25.93mlTrain batch 15/32 - 251.9ms/batch - loss: 1.56485 - diff: 25.04mlTrain batch 16/32 - 235.6ms/batch - loss: 1.55220 - diff: 24.84mlTrain batch 17/32 - 235.7ms/batch - loss: 1.59353 - diff: 25.50mlTrain batch 18/32 - 235.1ms/batch - loss: 1.62328 - diff: 25.97mlTrain batch 19/32 - 235.6ms/batch - loss: 1.64223 - diff: 26.28mlTrain batch 20/32 - 235.8ms/batch - loss: 1.61205 - diff: 25.79mlTrain batch 21/32 - 236.5ms/batch - loss: 1.67071 - diff: 26.73mlTrain batch 22/32 - 235.3ms/batch - loss: 1.65242 - diff: 26.44mlTrain batch 23/32 - 236.4ms/batch - loss: 1.64315 - diff: 26.29mlTrain batch 24/32 - 235.9ms/batch - loss: 1.63341 - diff: 26.13mlTrain batch 25/32 - 236.5ms/batch - loss: 1.62641 - diff: 26.02mlTrain batch 26/32 - 235.8ms/batch - loss: 1.61834 - diff: 25.89mlTrain batch 27/32 - 235.4ms/batch - loss: 1.65920 - diff: 26.55mlTrain batch 28/32 - 241.9ms/batch - loss: 1.64723 - diff: 26.36mlTrain batch 29/32 - 236.6ms/batch - loss: 1.63351 - diff: 26.14mlTrain batch 30/32 - 235.3ms/batch - loss: 1.61160 - diff: 25.79mlTrain batch 31/32 - 236.3ms/batch - loss: 1.61109 - diff: 25.78mlTrain batch 32/32 - 78.4ms/batch - loss: 1.64514 - diff: 25.76mlTrain batch 32/32 - 17.2s 78.4ms/batch - loss: 1.64514 - diff: 25.76ml
Test 1.5s: val_loss: 1.55507 - diff: 23.62ml

Epoch 77: current best loss = 1.46259, at epoch 74
Train batch 1/32 - 235.8ms/batch - loss: 2.00325 - diff: 32.05mlTrain batch 2/32 - 251.2ms/batch - loss: 2.03696 - diff: 32.59mlTrain batch 3/32 - 235.5ms/batch - loss: 2.07022 - diff: 33.12mlTrain batch 4/32 - 235.7ms/batch - loss: 1.89967 - diff: 30.39mlTrain batch 5/32 - 235.8ms/batch - loss: 1.73529 - diff: 27.76mlTrain batch 6/32 - 236.1ms/batch - loss: 1.62688 - diff: 26.03mlTrain batch 7/32 - 235.2ms/batch - loss: 1.65766 - diff: 26.52mlTrain batch 8/32 - 235.6ms/batch - loss: 1.61347 - diff: 25.82mlTrain batch 9/32 - 236.1ms/batch - loss: 1.61638 - diff: 25.86mlTrain batch 10/32 - 239.8ms/batch - loss: 1.62451 - diff: 25.99mlTrain batch 11/32 - 244.1ms/batch - loss: 1.60409 - diff: 25.67mlTrain batch 12/32 - 237.0ms/batch - loss: 1.62957 - diff: 26.07mlTrain batch 13/32 - 235.7ms/batch - loss: 1.67115 - diff: 26.74mlTrain batch 14/32 - 235.7ms/batch - loss: 1.63979 - diff: 26.24mlTrain batch 15/32 - 235.4ms/batch - loss: 1.62350 - diff: 25.98mlTrain batch 16/32 - 236.4ms/batch - loss: 1.60073 - diff: 25.61mlTrain batch 17/32 - 235.6ms/batch - loss: 1.60105 - diff: 25.62mlTrain batch 18/32 - 235.9ms/batch - loss: 1.57919 - diff: 25.27mlTrain batch 19/32 - 238.6ms/batch - loss: 1.57192 - diff: 25.15mlTrain batch 20/32 - 236.1ms/batch - loss: 1.55310 - diff: 24.85mlTrain batch 21/32 - 235.8ms/batch - loss: 1.59014 - diff: 25.44mlTrain batch 22/32 - 235.5ms/batch - loss: 1.57388 - diff: 25.18mlTrain batch 23/32 - 235.5ms/batch - loss: 1.60751 - diff: 25.72mlTrain batch 24/32 - 236.3ms/batch - loss: 1.63816 - diff: 26.21mlTrain batch 25/32 - 236.3ms/batch - loss: 1.62890 - diff: 26.06mlTrain batch 26/32 - 236.0ms/batch - loss: 1.65211 - diff: 26.43mlTrain batch 27/32 - 239.8ms/batch - loss: 1.66342 - diff: 26.61mlTrain batch 28/32 - 236.1ms/batch - loss: 1.66126 - diff: 26.58mlTrain batch 29/32 - 259.9ms/batch - loss: 1.65556 - diff: 26.49mlTrain batch 30/32 - 236.1ms/batch - loss: 1.64185 - diff: 26.27mlTrain batch 31/32 - 235.4ms/batch - loss: 1.63223 - diff: 26.12mlTrain batch 32/32 - 84.7ms/batch - loss: 1.64657 - diff: 26.02mlTrain batch 32/32 - 17.4s 84.7ms/batch - loss: 1.64657 - diff: 26.02ml
Test 1.4s: val_loss: 2.24608 - diff: 34.38ml

Epoch 78: current best loss = 1.46259, at epoch 74
Train batch 1/32 - 235.7ms/batch - loss: 1.79078 - diff: 28.65mlTrain batch 2/32 - 239.0ms/batch - loss: 1.99890 - diff: 31.98mlTrain batch 3/32 - 235.9ms/batch - loss: 1.79634 - diff: 28.74mlTrain batch 4/32 - 235.3ms/batch - loss: 1.83072 - diff: 29.29mlTrain batch 5/32 - 236.5ms/batch - loss: 1.81144 - diff: 28.98mlTrain batch 6/32 - 235.8ms/batch - loss: 1.79144 - diff: 28.66mlTrain batch 7/32 - 236.1ms/batch - loss: 1.71387 - diff: 27.42mlTrain batch 8/32 - 235.8ms/batch - loss: 1.72180 - diff: 27.55mlTrain batch 9/32 - 235.7ms/batch - loss: 1.70158 - diff: 27.23mlTrain batch 10/32 - 235.9ms/batch - loss: 1.73525 - diff: 27.76mlTrain batch 11/32 - 246.0ms/batch - loss: 1.67849 - diff: 26.86mlTrain batch 12/32 - 235.8ms/batch - loss: 1.64577 - diff: 26.33mlTrain batch 13/32 - 236.7ms/batch - loss: 1.63530 - diff: 26.16mlTrain batch 14/32 - 236.0ms/batch - loss: 1.68525 - diff: 26.96mlTrain batch 15/32 - 236.2ms/batch - loss: 1.69141 - diff: 27.06mlTrain batch 16/32 - 236.3ms/batch - loss: 1.66780 - diff: 26.68mlTrain batch 17/32 - 239.2ms/batch - loss: 1.66059 - diff: 26.57mlTrain batch 18/32 - 235.9ms/batch - loss: 1.63795 - diff: 26.21mlTrain batch 19/32 - 235.8ms/batch - loss: 1.63739 - diff: 26.20mlTrain batch 20/32 - 235.7ms/batch - loss: 1.66493 - diff: 26.64mlTrain batch 21/32 - 236.0ms/batch - loss: 1.64524 - diff: 26.32mlTrain batch 22/32 - 236.1ms/batch - loss: 1.64979 - diff: 26.40mlTrain batch 23/32 - 236.4ms/batch - loss: 1.63934 - diff: 26.23mlTrain batch 24/32 - 236.3ms/batch - loss: 1.63481 - diff: 26.16mlTrain batch 25/32 - 237.0ms/batch - loss: 1.63073 - diff: 26.09mlTrain batch 26/32 - 235.4ms/batch - loss: 1.63599 - diff: 26.18mlTrain batch 27/32 - 237.8ms/batch - loss: 1.64986 - diff: 26.40mlTrain batch 28/32 - 236.1ms/batch - loss: 1.64563 - diff: 26.33mlTrain batch 29/32 - 235.9ms/batch - loss: 1.62669 - diff: 26.03mlTrain batch 30/32 - 235.6ms/batch - loss: 1.61771 - diff: 25.88mlTrain batch 31/32 - 236.0ms/batch - loss: 1.60651 - diff: 25.70mlTrain batch 32/32 - 76.3ms/batch - loss: 1.64085 - diff: 25.69mlTrain batch 32/32 - 16.4s 76.3ms/batch - loss: 1.64085 - diff: 25.69ml
Test 1.5s: val_loss: 1.37943 - diff: 21.18ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_WideResNet50_0_Adam-0.001_MAE_DA3_best

Epoch 79: current best loss = 1.37943, at epoch 78
Train batch 1/32 - 261.7ms/batch - loss: 1.24966 - diff: 19.99mlTrain batch 2/32 - 235.7ms/batch - loss: 1.13745 - diff: 18.20mlTrain batch 3/32 - 247.2ms/batch - loss: 1.63210 - diff: 26.11mlTrain batch 4/32 - 236.5ms/batch - loss: 1.66033 - diff: 26.57mlTrain batch 5/32 - 236.0ms/batch - loss: 1.84380 - diff: 29.50mlTrain batch 6/32 - 237.2ms/batch - loss: 1.70788 - diff: 27.33mlTrain batch 7/32 - 236.1ms/batch - loss: 1.74614 - diff: 27.94mlTrain batch 8/32 - 235.8ms/batch - loss: 1.71869 - diff: 27.50mlTrain batch 9/32 - 235.7ms/batch - loss: 1.76190 - diff: 28.19mlTrain batch 10/32 - 236.2ms/batch - loss: 1.69007 - diff: 27.04mlTrain batch 11/32 - 235.9ms/batch - loss: 1.65980 - diff: 26.56mlTrain batch 12/32 - 236.6ms/batch - loss: 1.68464 - diff: 26.95mlTrain batch 13/32 - 236.0ms/batch - loss: 1.68226 - diff: 26.92mlTrain batch 14/32 - 235.8ms/batch - loss: 1.65156 - diff: 26.42mlTrain batch 15/32 - 236.0ms/batch - loss: 1.66714 - diff: 26.67mlTrain batch 16/32 - 235.5ms/batch - loss: 1.67086 - diff: 26.73mlTrain batch 17/32 - 235.8ms/batch - loss: 1.70489 - diff: 27.28mlTrain batch 18/32 - 236.3ms/batch - loss: 1.67352 - diff: 26.78mlTrain batch 19/32 - 235.8ms/batch - loss: 1.68414 - diff: 26.95mlTrain batch 20/32 - 236.7ms/batch - loss: 1.66812 - diff: 26.69mlTrain batch 21/32 - 235.5ms/batch - loss: 1.66821 - diff: 26.69mlTrain batch 22/32 - 236.2ms/batch - loss: 1.65311 - diff: 26.45mlTrain batch 23/32 - 235.4ms/batch - loss: 1.67733 - diff: 26.84mlTrain batch 24/32 - 236.4ms/batch - loss: 1.65756 - diff: 26.52mlTrain batch 25/32 - 235.9ms/batch - loss: 1.65909 - diff: 26.55mlTrain batch 26/32 - 236.1ms/batch - loss: 1.64910 - diff: 26.39mlTrain batch 27/32 - 235.7ms/batch - loss: 1.65773 - diff: 26.52mlTrain batch 28/32 - 236.4ms/batch - loss: 1.63864 - diff: 26.22mlTrain batch 29/32 - 235.7ms/batch - loss: 1.62332 - diff: 25.97mlTrain batch 30/32 - 235.8ms/batch - loss: 1.63849 - diff: 26.22mlTrain batch 31/32 - 235.5ms/batch - loss: 1.62610 - diff: 26.02mlTrain batch 32/32 - 76.5ms/batch - loss: 1.71629 - diff: 26.22mlTrain batch 32/32 - 17.7s 76.5ms/batch - loss: 1.71629 - diff: 26.22ml
Test 1.4s: val_loss: 1.65457 - diff: 25.33ml

Epoch 80: current best loss = 1.37943, at epoch 78
Train batch 1/32 - 235.5ms/batch - loss: 1.43105 - diff: 22.90mlTrain batch 2/32 - 236.5ms/batch - loss: 1.43205 - diff: 22.91mlTrain batch 3/32 - 235.7ms/batch - loss: 1.30117 - diff: 20.82mlTrain batch 4/32 - 235.6ms/batch - loss: 1.44135 - diff: 23.06mlTrain batch 5/32 - 235.8ms/batch - loss: 1.71644 - diff: 27.46mlTrain batch 6/32 - 235.4ms/batch - loss: 1.85395 - diff: 29.66mlTrain batch 7/32 - 235.6ms/batch - loss: 1.82300 - diff: 29.17mlTrain batch 8/32 - 236.2ms/batch - loss: 1.76507 - diff: 28.24mlTrain batch 9/32 - 235.6ms/batch - loss: 1.73439 - diff: 27.75mlTrain batch 10/32 - 236.2ms/batch - loss: 1.75314 - diff: 28.05mlTrain batch 11/32 - 235.9ms/batch - loss: 1.74160 - diff: 27.87mlTrain batch 12/32 - 237.0ms/batch - loss: 1.75514 - diff: 28.08mlTrain batch 13/32 - 235.7ms/batch - loss: 1.77246 - diff: 28.36mlTrain batch 14/32 - 236.3ms/batch - loss: 1.73993 - diff: 27.84mlTrain batch 15/32 - 237.0ms/batch - loss: 1.68837 - diff: 27.01mlTrain batch 16/32 - 236.1ms/batch - loss: 1.65892 - diff: 26.54mlTrain batch 17/32 - 236.0ms/batch - loss: 1.62932 - diff: 26.07mlTrain batch 18/32 - 236.4ms/batch - loss: 1.62296 - diff: 25.97mlTrain batch 19/32 - 235.0ms/batch - loss: 1.61370 - diff: 25.82mlTrain batch 20/32 - 235.8ms/batch - loss: 1.58661 - diff: 25.39mlTrain batch 21/32 - 236.0ms/batch - loss: 1.56425 - diff: 25.03mlTrain batch 22/32 - 235.5ms/batch - loss: 1.56025 - diff: 24.96mlTrain batch 23/32 - 236.7ms/batch - loss: 1.55680 - diff: 24.91mlTrain batch 24/32 - 235.8ms/batch - loss: 1.58683 - diff: 25.39mlTrain batch 25/32 - 236.5ms/batch - loss: 1.59015 - diff: 25.44mlTrain batch 26/32 - 235.6ms/batch - loss: 1.57164 - diff: 25.15mlTrain batch 27/32 - 236.2ms/batch - loss: 1.60111 - diff: 25.62mlTrain batch 28/32 - 236.1ms/batch - loss: 1.60846 - diff: 25.74mlTrain batch 29/32 - 238.8ms/batch - loss: 1.62433 - diff: 25.99mlTrain batch 30/32 - 235.3ms/batch - loss: 1.60638 - diff: 25.70mlTrain batch 31/32 - 235.8ms/batch - loss: 1.61000 - diff: 25.76mlTrain batch 32/32 - 76.5ms/batch - loss: 1.70233 - diff: 25.97mlTrain batch 32/32 - 17.6s 76.5ms/batch - loss: 1.70233 - diff: 25.97ml
Test 1.4s: val_loss: 1.57319 - diff: 24.13ml

Epoch 81: current best loss = 1.37943, at epoch 78
Train batch 1/32 - 235.9ms/batch - loss: 1.24277 - diff: 19.88mlTrain batch 2/32 - 236.3ms/batch - loss: 1.70933 - diff: 27.35mlTrain batch 3/32 - 235.5ms/batch - loss: 1.92092 - diff: 30.73mlTrain batch 4/32 - 236.4ms/batch - loss: 1.90884 - diff: 30.54mlTrain batch 5/32 - 235.5ms/batch - loss: 1.83910 - diff: 29.43mlTrain batch 6/32 - 236.1ms/batch - loss: 1.79777 - diff: 28.76mlTrain batch 7/32 - 240.0ms/batch - loss: 1.78181 - diff: 28.51mlTrain batch 8/32 - 236.7ms/batch - loss: 1.76379 - diff: 28.22mlTrain batch 9/32 - 236.2ms/batch - loss: 1.69946 - diff: 27.19mlTrain batch 10/32 - 236.4ms/batch - loss: 1.68174 - diff: 26.91mlTrain batch 11/32 - 236.1ms/batch - loss: 1.62961 - diff: 26.07mlTrain batch 12/32 - 235.9ms/batch - loss: 1.60843 - diff: 25.73mlTrain batch 13/32 - 236.0ms/batch - loss: 1.57427 - diff: 25.19mlTrain batch 14/32 - 235.8ms/batch - loss: 1.55421 - diff: 24.87mlTrain batch 15/32 - 242.1ms/batch - loss: 1.57293 - diff: 25.17mlTrain batch 16/32 - 236.1ms/batch - loss: 1.56647 - diff: 25.06mlTrain batch 17/32 - 239.5ms/batch - loss: 1.55347 - diff: 24.86mlTrain batch 18/32 - 236.1ms/batch - loss: 1.57073 - diff: 25.13mlTrain batch 19/32 - 236.4ms/batch - loss: 1.55302 - diff: 24.85mlTrain batch 20/32 - 235.7ms/batch - loss: 1.54910 - diff: 24.79mlTrain batch 21/32 - 235.1ms/batch - loss: 1.54390 - diff: 24.70mlTrain batch 22/32 - 235.8ms/batch - loss: 1.54126 - diff: 24.66mlTrain batch 23/32 - 236.2ms/batch - loss: 1.54633 - diff: 24.74mlTrain batch 24/32 - 235.6ms/batch - loss: 1.52471 - diff: 24.40mlTrain batch 25/32 - 235.8ms/batch - loss: 1.55548 - diff: 24.89mlTrain batch 26/32 - 235.5ms/batch - loss: 1.55399 - diff: 24.86mlTrain batch 27/32 - 235.8ms/batch - loss: 1.54696 - diff: 24.75mlTrain batch 28/32 - 235.8ms/batch - loss: 1.55677 - diff: 24.91mlTrain batch 29/32 - 235.6ms/batch - loss: 1.55043 - diff: 24.81mlTrain batch 30/32 - 235.3ms/batch - loss: 1.58368 - diff: 25.34mlTrain batch 31/32 - 235.5ms/batch - loss: 1.57402 - diff: 25.18mlTrain batch 32/32 - 76.4ms/batch - loss: 1.70940 - diff: 25.57mlTrain batch 32/32 - 16.8s 76.4ms/batch - loss: 1.70940 - diff: 25.57ml
Test 1.4s: val_loss: 1.43210 - diff: 21.85ml

Epoch 82: current best loss = 1.37943, at epoch 78
Train batch 1/32 - 236.1ms/batch - loss: 1.27432 - diff: 20.39mlTrain batch 2/32 - 235.5ms/batch - loss: 1.38887 - diff: 22.22mlTrain batch 3/32 - 236.1ms/batch - loss: 1.34038 - diff: 21.45mlTrain batch 4/32 - 236.5ms/batch - loss: 1.32366 - diff: 21.18mlTrain batch 5/32 - 236.1ms/batch - loss: 1.47989 - diff: 23.68mlTrain batch 6/32 - 235.7ms/batch - loss: 1.54600 - diff: 24.74mlTrain batch 7/32 - 235.4ms/batch - loss: 1.49519 - diff: 23.92mlTrain batch 8/32 - 235.9ms/batch - loss: 1.50141 - diff: 24.02mlTrain batch 9/32 - 241.6ms/batch - loss: 1.48075 - diff: 23.69mlTrain batch 10/32 - 235.8ms/batch - loss: 1.45483 - diff: 23.28mlTrain batch 11/32 - 235.4ms/batch - loss: 1.51009 - diff: 24.16mlTrain batch 12/32 - 236.3ms/batch - loss: 1.49899 - diff: 23.98mlTrain batch 13/32 - 235.9ms/batch - loss: 1.50868 - diff: 24.14mlTrain batch 14/32 - 235.9ms/batch - loss: 1.51505 - diff: 24.24mlTrain batch 15/32 - 236.7ms/batch - loss: 1.52053 - diff: 24.33mlTrain batch 16/32 - 235.6ms/batch - loss: 1.53588 - diff: 24.57mlTrain batch 17/32 - 235.5ms/batch - loss: 1.54516 - diff: 24.72mlTrain batch 18/32 - 235.9ms/batch - loss: 1.60512 - diff: 25.68mlTrain batch 19/32 - 238.3ms/batch - loss: 1.59765 - diff: 25.56mlTrain batch 20/32 - 235.6ms/batch - loss: 1.65006 - diff: 26.40mlTrain batch 21/32 - 235.3ms/batch - loss: 1.66332 - diff: 26.61mlTrain batch 22/32 - 236.8ms/batch - loss: 1.64750 - diff: 26.36mlTrain batch 23/32 - 236.3ms/batch - loss: 1.61585 - diff: 25.85mlTrain batch 24/32 - 235.7ms/batch - loss: 1.59683 - diff: 25.55mlTrain batch 25/32 - 237.1ms/batch - loss: 1.58368 - diff: 25.34mlTrain batch 26/32 - 235.7ms/batch - loss: 1.58285 - diff: 25.33mlTrain batch 27/32 - 236.0ms/batch - loss: 1.56996 - diff: 25.12mlTrain batch 28/32 - 235.9ms/batch - loss: 1.61249 - diff: 25.80mlTrain batch 29/32 - 236.7ms/batch - loss: 1.58980 - diff: 25.44mlTrain batch 30/32 - 235.7ms/batch - loss: 1.58306 - diff: 25.33mlTrain batch 31/32 - 236.1ms/batch - loss: 1.58005 - diff: 25.28mlTrain batch 32/32 - 76.9ms/batch - loss: 1.62820 - diff: 25.32mlTrain batch 32/32 - 16.6s 76.9ms/batch - loss: 1.62820 - diff: 25.32ml
Test 1.4s: val_loss: 2.11463 - diff: 32.50ml

Epoch 83: current best loss = 1.37943, at epoch 78
Train batch 1/32 - 240.6ms/batch - loss: 1.33515 - diff: 21.36mlTrain batch 2/32 - 235.3ms/batch - loss: 1.77076 - diff: 28.33mlTrain batch 3/32 - 237.0ms/batch - loss: 1.48896 - diff: 23.82mlTrain batch 4/32 - 236.2ms/batch - loss: 1.47553 - diff: 23.61mlTrain batch 5/32 - 236.2ms/batch - loss: 1.56633 - diff: 25.06mlTrain batch 6/32 - 236.6ms/batch - loss: 1.46698 - diff: 23.47mlTrain batch 7/32 - 236.1ms/batch - loss: 1.48312 - diff: 23.73mlTrain batch 8/32 - 249.2ms/batch - loss: 1.44005 - diff: 23.04mlTrain batch 9/32 - 235.4ms/batch - loss: 1.39811 - diff: 22.37mlTrain batch 10/32 - 236.2ms/batch - loss: 1.42890 - diff: 22.86mlTrain batch 11/32 - 236.4ms/batch - loss: 1.44510 - diff: 23.12mlTrain batch 12/32 - 236.6ms/batch - loss: 1.48769 - diff: 23.80mlTrain batch 13/32 - 235.5ms/batch - loss: 1.56249 - diff: 25.00mlTrain batch 14/32 - 239.5ms/batch - loss: 1.54860 - diff: 24.78mlTrain batch 15/32 - 235.8ms/batch - loss: 1.55802 - diff: 24.93mlTrain batch 16/32 - 235.6ms/batch - loss: 1.56108 - diff: 24.98mlTrain batch 17/32 - 245.7ms/batch - loss: 1.56539 - diff: 25.05mlTrain batch 18/32 - 236.2ms/batch - loss: 1.56503 - diff: 25.04mlTrain batch 19/32 - 235.9ms/batch - loss: 1.56077 - diff: 24.97mlTrain batch 20/32 - 235.5ms/batch - loss: 1.55759 - diff: 24.92mlTrain batch 21/32 - 236.5ms/batch - loss: 1.57208 - diff: 25.15mlTrain batch 22/32 - 235.9ms/batch - loss: 1.57061 - diff: 25.13mlTrain batch 23/32 - 236.0ms/batch - loss: 1.56890 - diff: 25.10mlTrain batch 24/32 - 235.7ms/batch - loss: 1.57907 - diff: 25.27mlTrain batch 25/32 - 235.5ms/batch - loss: 1.57472 - diff: 25.20mlTrain batch 26/32 - 236.4ms/batch - loss: 1.56148 - diff: 24.98mlTrain batch 27/32 - 236.4ms/batch - loss: 1.58087 - diff: 25.29mlTrain batch 28/32 - 235.9ms/batch - loss: 1.58226 - diff: 25.32mlTrain batch 29/32 - 236.1ms/batch - loss: 1.58967 - diff: 25.43mlTrain batch 30/32 - 236.6ms/batch - loss: 1.61515 - diff: 25.84mlTrain batch 31/32 - 236.5ms/batch - loss: 1.63789 - diff: 26.21mlTrain batch 32/32 - 76.5ms/batch - loss: 1.64967 - diff: 26.10mlTrain batch 32/32 - 16.4s 76.5ms/batch - loss: 1.64967 - diff: 26.10ml
Test 1.5s: val_loss: 4.02419 - diff: 62.53ml

Epoch 84: current best loss = 1.37943, at epoch 78
Train batch 1/32 - 235.8ms/batch - loss: 1.92615 - diff: 30.82mlTrain batch 2/32 - 242.6ms/batch - loss: 1.57976 - diff: 25.28mlTrain batch 3/32 - 235.9ms/batch - loss: 1.65499 - diff: 26.48mlTrain batch 4/32 - 236.6ms/batch - loss: 1.58060 - diff: 25.29mlTrain batch 5/32 - 235.6ms/batch - loss: 1.59084 - diff: 25.45mlTrain batch 6/32 - 236.1ms/batch - loss: 1.56415 - diff: 25.03mlTrain batch 7/32 - 235.4ms/batch - loss: 1.53838 - diff: 24.61mlTrain batch 8/32 - 237.3ms/batch - loss: 1.52503 - diff: 24.40mlTrain batch 9/32 - 236.2ms/batch - loss: 1.54232 - diff: 24.68mlTrain batch 10/32 - 236.1ms/batch - loss: 1.54090 - diff: 24.65mlTrain batch 11/32 - 235.6ms/batch - loss: 1.53125 - diff: 24.50mlTrain batch 12/32 - 236.1ms/batch - loss: 1.53677 - diff: 24.59mlTrain batch 13/32 - 235.2ms/batch - loss: 1.52564 - diff: 24.41mlTrain batch 14/32 - 236.7ms/batch - loss: 1.60613 - diff: 25.70mlTrain batch 15/32 - 235.5ms/batch - loss: 1.63160 - diff: 26.11mlTrain batch 16/32 - 236.6ms/batch - loss: 1.64310 - diff: 26.29mlTrain batch 17/32 - 237.9ms/batch - loss: 1.64616 - diff: 26.34mlTrain batch 18/32 - 235.6ms/batch - loss: 1.61928 - diff: 25.91mlTrain batch 19/32 - 236.1ms/batch - loss: 1.59374 - diff: 25.50mlTrain batch 20/32 - 257.1ms/batch - loss: 1.59728 - diff: 25.56mlTrain batch 21/32 - 235.7ms/batch - loss: 1.60010 - diff: 25.60mlTrain batch 22/32 - 235.7ms/batch - loss: 1.59865 - diff: 25.58mlTrain batch 23/32 - 235.7ms/batch - loss: 1.60041 - diff: 25.61mlTrain batch 24/32 - 236.3ms/batch - loss: 1.62624 - diff: 26.02mlTrain batch 25/32 - 236.1ms/batch - loss: 1.62128 - diff: 25.94mlTrain batch 26/32 - 235.9ms/batch - loss: 1.60782 - diff: 25.73mlTrain batch 27/32 - 235.4ms/batch - loss: 1.61237 - diff: 25.80mlTrain batch 28/32 - 236.5ms/batch - loss: 1.61334 - diff: 25.81mlTrain batch 29/32 - 236.2ms/batch - loss: 1.59973 - diff: 25.60mlTrain batch 30/32 - 237.1ms/batch - loss: 1.58666 - diff: 25.39mlTrain batch 31/32 - 235.5ms/batch - loss: 1.59005 - diff: 25.44mlTrain batch 32/32 - 76.5ms/batch - loss: 1.64249 - diff: 25.50mlTrain batch 32/32 - 17.1s 76.5ms/batch - loss: 1.64249 - diff: 25.50ml
Test 1.5s: val_loss: 2.62788 - diff: 40.61ml

Epoch 85: current best loss = 1.37943, at epoch 78
Train batch 1/32 - 235.5ms/batch - loss: 0.74162 - diff: 11.87mlTrain batch 2/32 - 236.0ms/batch - loss: 0.87779 - diff: 14.04mlTrain batch 3/32 - 235.7ms/batch - loss: 1.09453 - diff: 17.51mlTrain batch 4/32 - 236.2ms/batch - loss: 1.25437 - diff: 20.07mlTrain batch 5/32 - 235.4ms/batch - loss: 1.27478 - diff: 20.40mlTrain batch 6/32 - 236.5ms/batch - loss: 1.30393 - diff: 20.86mlTrain batch 7/32 - 238.8ms/batch - loss: 1.33612 - diff: 21.38mlTrain batch 8/32 - 235.6ms/batch - loss: 1.35273 - diff: 21.64mlTrain batch 9/32 - 235.5ms/batch - loss: 1.32963 - diff: 21.27mlTrain batch 10/32 - 236.7ms/batch - loss: 1.44609 - diff: 23.14mlTrain batch 11/32 - 235.8ms/batch - loss: 1.44643 - diff: 23.14mlTrain batch 12/32 - 236.8ms/batch - loss: 1.43974 - diff: 23.04mlTrain batch 13/32 - 236.1ms/batch - loss: 1.44755 - diff: 23.16mlTrain batch 14/32 - 235.8ms/batch - loss: 1.44201 - diff: 23.07mlTrain batch 15/32 - 235.7ms/batch - loss: 1.44044 - diff: 23.05mlTrain batch 16/32 - 235.7ms/batch - loss: 1.42103 - diff: 22.74mlTrain batch 17/32 - 235.5ms/batch - loss: 1.42702 - diff: 22.83mlTrain batch 18/32 - 236.4ms/batch - loss: 1.41829 - diff: 22.69mlTrain batch 19/32 - 236.3ms/batch - loss: 1.49459 - diff: 23.91mlTrain batch 20/32 - 236.4ms/batch - loss: 1.49090 - diff: 23.85mlTrain batch 21/32 - 235.1ms/batch - loss: 1.49153 - diff: 23.86mlTrain batch 22/32 - 236.1ms/batch - loss: 1.48901 - diff: 23.82mlTrain batch 23/32 - 236.1ms/batch - loss: 1.47122 - diff: 23.54mlTrain batch 24/32 - 236.7ms/batch - loss: 1.47621 - diff: 23.62mlTrain batch 25/32 - 236.1ms/batch - loss: 1.48285 - diff: 23.73mlTrain batch 26/32 - 236.5ms/batch - loss: 1.51769 - diff: 24.28mlTrain batch 27/32 - 236.1ms/batch - loss: 1.52932 - diff: 24.47mlTrain batch 28/32 - 236.4ms/batch - loss: 1.55228 - diff: 24.84mlTrain batch 29/32 - 236.2ms/batch - loss: 1.55296 - diff: 24.85mlTrain batch 30/32 - 236.3ms/batch - loss: 1.55088 - diff: 24.81mlTrain batch 31/32 - 236.4ms/batch - loss: 1.54655 - diff: 24.74mlTrain batch 32/32 - 83.8ms/batch - loss: 1.55795 - diff: 24.64mlTrain batch 32/32 - 16.6s 83.8ms/batch - loss: 1.55795 - diff: 24.64ml
Test 1.5s: val_loss: 1.52410 - diff: 23.42ml

Epoch 86: current best loss = 1.37943, at epoch 78
Train batch 1/32 - 235.5ms/batch - loss: 1.08513 - diff: 17.36mlTrain batch 2/32 - 236.9ms/batch - loss: 1.26703 - diff: 20.27mlTrain batch 3/32 - 235.9ms/batch - loss: 1.29657 - diff: 20.75mlTrain batch 4/32 - 236.3ms/batch - loss: 1.40562 - diff: 22.49mlTrain batch 5/32 - 236.0ms/batch - loss: 1.48685 - diff: 23.79mlTrain batch 6/32 - 236.5ms/batch - loss: 1.51084 - diff: 24.17mlTrain batch 7/32 - 237.2ms/batch - loss: 1.46019 - diff: 23.36mlTrain batch 8/32 - 236.4ms/batch - loss: 1.44226 - diff: 23.08mlTrain batch 9/32 - 235.8ms/batch - loss: 1.43086 - diff: 22.89mlTrain batch 10/32 - 235.7ms/batch - loss: 1.43014 - diff: 22.88mlTrain batch 11/32 - 235.6ms/batch - loss: 1.52038 - diff: 24.33mlTrain batch 12/32 - 237.1ms/batch - loss: 1.50604 - diff: 24.10mlTrain batch 13/32 - 235.4ms/batch - loss: 1.49527 - diff: 23.92mlTrain batch 14/32 - 236.1ms/batch - loss: 1.45111 - diff: 23.22mlTrain batch 15/32 - 236.6ms/batch - loss: 1.46972 - diff: 23.52mlTrain batch 16/32 - 236.3ms/batch - loss: 1.48972 - diff: 23.84mlTrain batch 17/32 - 235.9ms/batch - loss: 1.49304 - diff: 23.89mlTrain batch 18/32 - 236.6ms/batch - loss: 1.50494 - diff: 24.08mlTrain batch 19/32 - 237.4ms/batch - loss: 1.49196 - diff: 23.87mlTrain batch 20/32 - 236.5ms/batch - loss: 1.52638 - diff: 24.42mlTrain batch 21/32 - 235.9ms/batch - loss: 1.49838 - diff: 23.97mlTrain batch 22/32 - 235.6ms/batch - loss: 1.48417 - diff: 23.75mlTrain batch 23/32 - 235.9ms/batch - loss: 1.46497 - diff: 23.44mlTrain batch 24/32 - 236.5ms/batch - loss: 1.49538 - diff: 23.93mlTrain batch 25/32 - 235.6ms/batch - loss: 1.47731 - diff: 23.64mlTrain batch 26/32 - 236.5ms/batch - loss: 1.51040 - diff: 24.17mlTrain batch 27/32 - 235.5ms/batch - loss: 1.51479 - diff: 24.24mlTrain batch 28/32 - 235.9ms/batch - loss: 1.50940 - diff: 24.15mlTrain batch 29/32 - 235.7ms/batch - loss: 1.51213 - diff: 24.19mlTrain batch 30/32 - 235.9ms/batch - loss: 1.54489 - diff: 24.72mlTrain batch 31/32 - 236.3ms/batch - loss: 1.55309 - diff: 24.85mlTrain batch 32/32 - 76.8ms/batch - loss: 1.69770 - diff: 25.28mlTrain batch 32/32 - 18.1s 76.8ms/batch - loss: 1.69770 - diff: 25.28ml
Test 1.4s: val_loss: 2.09801 - diff: 31.90ml

Epoch 87: current best loss = 1.37943, at epoch 78
Train batch 1/32 - 235.7ms/batch - loss: 1.39257 - diff: 22.28mlTrain batch 2/32 - 236.7ms/batch - loss: 1.13876 - diff: 18.22mlTrain batch 3/32 - 235.9ms/batch - loss: 1.21511 - diff: 19.44mlTrain batch 4/32 - 235.7ms/batch - loss: 1.37982 - diff: 22.08mlTrain batch 5/32 - 257.0ms/batch - loss: 1.41419 - diff: 22.63mlTrain batch 6/32 - 236.1ms/batch - loss: 1.35648 - diff: 21.70mlTrain batch 7/32 - 235.5ms/batch - loss: 1.47448 - diff: 23.59mlTrain batch 8/32 - 240.6ms/batch - loss: 1.44980 - diff: 23.20mlTrain batch 9/32 - 239.4ms/batch - loss: 1.46326 - diff: 23.41mlTrain batch 10/32 - 236.2ms/batch - loss: 1.41215 - diff: 22.59mlTrain batch 11/32 - 235.5ms/batch - loss: 1.41729 - diff: 22.68mlTrain batch 12/32 - 236.6ms/batch - loss: 1.41292 - diff: 22.61mlTrain batch 13/32 - 235.9ms/batch - loss: 1.49581 - diff: 23.93mlTrain batch 14/32 - 236.2ms/batch - loss: 1.51582 - diff: 24.25mlTrain batch 15/32 - 235.5ms/batch - loss: 1.57080 - diff: 25.13mlTrain batch 16/32 - 235.9ms/batch - loss: 1.57702 - diff: 25.23mlTrain batch 17/32 - 235.7ms/batch - loss: 1.57617 - diff: 25.22mlTrain batch 18/32 - 246.8ms/batch - loss: 1.54168 - diff: 24.67mlTrain batch 19/32 - 235.9ms/batch - loss: 1.56226 - diff: 25.00mlTrain batch 20/32 - 237.5ms/batch - loss: 1.53236 - diff: 24.52mlTrain batch 21/32 - 235.1ms/batch - loss: 1.56122 - diff: 24.98mlTrain batch 22/32 - 236.6ms/batch - loss: 1.55865 - diff: 24.94mlTrain batch 23/32 - 235.6ms/batch - loss: 1.55224 - diff: 24.84mlTrain batch 24/32 - 236.3ms/batch - loss: 1.54891 - diff: 24.78mlTrain batch 25/32 - 235.5ms/batch - loss: 1.53327 - diff: 24.53mlTrain batch 26/32 - 236.1ms/batch - loss: 1.55267 - diff: 24.84mlTrain batch 27/32 - 235.6ms/batch - loss: 1.54694 - diff: 24.75mlTrain batch 28/32 - 240.4ms/batch - loss: 1.53497 - diff: 24.56mlTrain batch 29/32 - 235.9ms/batch - loss: 1.53260 - diff: 24.52mlTrain batch 30/32 - 236.6ms/batch - loss: 1.50582 - diff: 24.09mlTrain batch 31/32 - 235.8ms/batch - loss: 1.51068 - diff: 24.17mlTrain batch 32/32 - 92.3ms/batch - loss: 1.54563 - diff: 24.17mlTrain batch 32/32 - 17.2s 92.3ms/batch - loss: 1.54563 - diff: 24.17ml
Test 1.4s: val_loss: 1.48997 - diff: 23.18ml

Epoch 88: current best loss = 1.37943, at epoch 78
Train batch 1/32 - 235.8ms/batch - loss: 2.01628 - diff: 32.26mlTrain batch 2/32 - 240.0ms/batch - loss: 1.51088 - diff: 24.17mlTrain batch 3/32 - 235.7ms/batch - loss: 1.47419 - diff: 23.59mlTrain batch 4/32 - 235.6ms/batch - loss: 1.44414 - diff: 23.11mlTrain batch 5/32 - 235.5ms/batch - loss: 1.53278 - diff: 24.52mlTrain batch 6/32 - 235.6ms/batch - loss: 1.46319 - diff: 23.41mlTrain batch 7/32 - 236.8ms/batch - loss: 1.43812 - diff: 23.01mlTrain batch 8/32 - 235.8ms/batch - loss: 1.44773 - diff: 23.16mlTrain batch 9/32 - 235.5ms/batch - loss: 1.43319 - diff: 22.93mlTrain batch 10/32 - 235.7ms/batch - loss: 1.48796 - diff: 23.81mlTrain batch 11/32 - 236.8ms/batch - loss: 1.49199 - diff: 23.87mlTrain batch 12/32 - 235.5ms/batch - loss: 1.44466 - diff: 23.11mlTrain batch 13/32 - 235.8ms/batch - loss: 1.44383 - diff: 23.10mlTrain batch 14/32 - 235.6ms/batch - loss: 1.45319 - diff: 23.25mlTrain batch 15/32 - 236.8ms/batch - loss: 1.43840 - diff: 23.01mlTrain batch 16/32 - 235.5ms/batch - loss: 1.43315 - diff: 22.93mlTrain batch 17/32 - 236.3ms/batch - loss: 1.42927 - diff: 22.87mlTrain batch 18/32 - 239.7ms/batch - loss: 1.41941 - diff: 22.71mlTrain batch 19/32 - 235.8ms/batch - loss: 1.52352 - diff: 24.38mlTrain batch 20/32 - 235.7ms/batch - loss: 1.50562 - diff: 24.09mlTrain batch 21/32 - 236.7ms/batch - loss: 1.49286 - diff: 23.89mlTrain batch 22/32 - 235.5ms/batch - loss: 1.51099 - diff: 24.18mlTrain batch 23/32 - 236.3ms/batch - loss: 1.53798 - diff: 24.61mlTrain batch 24/32 - 235.8ms/batch - loss: 1.51172 - diff: 24.19mlTrain batch 25/32 - 236.3ms/batch - loss: 1.53008 - diff: 24.48mlTrain batch 26/32 - 235.8ms/batch - loss: 1.51775 - diff: 24.28mlTrain batch 27/32 - 235.9ms/batch - loss: 1.50780 - diff: 24.12mlTrain batch 28/32 - 235.5ms/batch - loss: 1.50005 - diff: 24.00mlTrain batch 29/32 - 235.6ms/batch - loss: 1.49429 - diff: 23.91mlTrain batch 30/32 - 235.8ms/batch - loss: 1.48885 - diff: 23.82mlTrain batch 31/32 - 236.5ms/batch - loss: 1.47827 - diff: 23.65mlTrain batch 32/32 - 76.9ms/batch - loss: 1.48335 - diff: 23.53mlTrain batch 32/32 - 17.1s 76.9ms/batch - loss: 1.48335 - diff: 23.53ml
Test 1.5s: val_loss: 1.67367 - diff: 25.46ml

Epoch 89: current best loss = 1.37943, at epoch 78
Train batch 1/32 - 235.6ms/batch - loss: 2.83090 - diff: 45.29mlTrain batch 2/32 - 236.0ms/batch - loss: 2.06091 - diff: 32.97mlTrain batch 3/32 - 236.2ms/batch - loss: 1.84956 - diff: 29.59mlTrain batch 4/32 - 235.9ms/batch - loss: 1.82339 - diff: 29.17mlTrain batch 5/32 - 235.7ms/batch - loss: 1.72165 - diff: 27.55mlTrain batch 6/32 - 235.6ms/batch - loss: 1.70587 - diff: 27.29mlTrain batch 7/32 - 235.8ms/batch - loss: 1.69305 - diff: 27.09mlTrain batch 8/32 - 236.1ms/batch - loss: 1.67567 - diff: 26.81mlTrain batch 9/32 - 235.6ms/batch - loss: 1.70566 - diff: 27.29mlTrain batch 10/32 - 235.8ms/batch - loss: 1.68349 - diff: 26.94mlTrain batch 11/32 - 236.8ms/batch - loss: 1.62947 - diff: 26.07mlTrain batch 12/32 - 235.9ms/batch - loss: 1.62422 - diff: 25.99mlTrain batch 13/32 - 236.3ms/batch - loss: 1.64066 - diff: 26.25mlTrain batch 14/32 - 235.7ms/batch - loss: 1.60854 - diff: 25.74mlTrain batch 15/32 - 236.0ms/batch - loss: 1.57710 - diff: 25.23mlTrain batch 16/32 - 235.5ms/batch - loss: 1.59369 - diff: 25.50mlTrain batch 17/32 - 236.3ms/batch - loss: 1.62673 - diff: 26.03mlTrain batch 18/32 - 236.7ms/batch - loss: 1.61834 - diff: 25.89mlTrain batch 19/32 - 236.1ms/batch - loss: 1.59844 - diff: 25.57mlTrain batch 20/32 - 236.3ms/batch - loss: 1.57237 - diff: 25.16mlTrain batch 21/32 - 236.5ms/batch - loss: 1.56822 - diff: 25.09mlTrain batch 22/32 - 235.8ms/batch - loss: 1.54565 - diff: 24.73mlTrain batch 23/32 - 236.1ms/batch - loss: 1.55336 - diff: 24.85mlTrain batch 24/32 - 242.7ms/batch - loss: 1.55397 - diff: 24.86mlTrain batch 25/32 - 236.7ms/batch - loss: 1.53507 - diff: 24.56mlTrain batch 26/32 - 236.3ms/batch - loss: 1.56249 - diff: 25.00mlTrain batch 27/32 - 242.2ms/batch - loss: 1.57136 - diff: 25.14mlTrain batch 28/32 - 235.6ms/batch - loss: 1.56774 - diff: 25.08mlTrain batch 29/32 - 236.3ms/batch - loss: 1.57542 - diff: 25.21mlTrain batch 30/32 - 235.9ms/batch - loss: 1.56645 - diff: 25.06mlTrain batch 31/32 - 236.7ms/batch - loss: 1.54151 - diff: 24.66mlTrain batch 32/32 - 83.9ms/batch - loss: 1.58227 - diff: 24.68mlTrain batch 32/32 - 15.8s 83.9ms/batch - loss: 1.58227 - diff: 24.68ml
Test 1.5s: val_loss: 1.81350 - diff: 27.83ml
Epoch    90: reducing learning rate of group 0 to 5.0000e-04.

Epoch 90: current best loss = 1.37943, at epoch 78
Train batch 1/32 - 235.9ms/batch - loss: 1.91946 - diff: 30.71mlTrain batch 2/32 - 236.3ms/batch - loss: 1.62334 - diff: 25.97mlTrain batch 3/32 - 235.7ms/batch - loss: 1.66534 - diff: 26.65mlTrain batch 4/32 - 236.2ms/batch - loss: 1.71666 - diff: 27.47mlTrain batch 5/32 - 236.4ms/batch - loss: 1.60700 - diff: 25.71mlTrain batch 6/32 - 236.9ms/batch - loss: 1.62503 - diff: 26.00mlTrain batch 7/32 - 238.4ms/batch - loss: 1.60041 - diff: 25.61mlTrain batch 8/32 - 235.9ms/batch - loss: 1.59279 - diff: 25.48mlTrain batch 9/32 - 236.0ms/batch - loss: 1.66049 - diff: 26.57mlTrain batch 10/32 - 235.7ms/batch - loss: 1.65027 - diff: 26.40mlTrain batch 11/32 - 235.4ms/batch - loss: 1.67369 - diff: 26.78mlTrain batch 12/32 - 235.7ms/batch - loss: 1.65904 - diff: 26.54mlTrain batch 13/32 - 236.3ms/batch - loss: 1.66631 - diff: 26.66mlTrain batch 14/32 - 236.0ms/batch - loss: 1.64045 - diff: 26.25mlTrain batch 15/32 - 272.1ms/batch - loss: 1.65293 - diff: 26.45mlTrain batch 16/32 - 238.6ms/batch - loss: 1.61120 - diff: 25.78mlTrain batch 17/32 - 235.7ms/batch - loss: 1.56918 - diff: 25.11mlTrain batch 18/32 - 236.9ms/batch - loss: 1.57521 - diff: 25.20mlTrain batch 19/32 - 235.5ms/batch - loss: 1.55409 - diff: 24.87mlTrain batch 20/32 - 235.8ms/batch - loss: 1.52308 - diff: 24.37mlTrain batch 21/32 - 236.5ms/batch - loss: 1.56368 - diff: 25.02mlTrain batch 22/32 - 236.2ms/batch - loss: 1.52818 - diff: 24.45mlTrain batch 23/32 - 240.1ms/batch - loss: 1.52366 - diff: 24.38mlTrain batch 24/32 - 236.1ms/batch - loss: 1.51651 - diff: 24.26mlTrain batch 25/32 - 236.4ms/batch - loss: 1.51520 - diff: 24.24mlTrain batch 26/32 - 235.3ms/batch - loss: 1.49660 - diff: 23.95mlTrain batch 27/32 - 236.4ms/batch - loss: 1.48385 - diff: 23.74mlTrain batch 28/32 - 235.4ms/batch - loss: 1.47958 - diff: 23.67mlTrain batch 29/32 - 238.5ms/batch - loss: 1.46211 - diff: 23.39mlTrain batch 30/32 - 235.9ms/batch - loss: 1.47397 - diff: 23.58mlTrain batch 31/32 - 235.3ms/batch - loss: 1.46537 - diff: 23.45mlTrain batch 32/32 - 76.7ms/batch - loss: 1.47798 - diff: 23.36mlTrain batch 32/32 - 17.2s 76.7ms/batch - loss: 1.47798 - diff: 23.36ml
Test 1.5s: val_loss: 1.59213 - diff: 24.47ml

Epoch 91: current best loss = 1.37943, at epoch 78
Train batch 1/32 - 235.5ms/batch - loss: 1.56143 - diff: 24.98mlTrain batch 2/32 - 235.8ms/batch - loss: 1.83260 - diff: 29.32mlTrain batch 3/32 - 236.0ms/batch - loss: 1.72652 - diff: 27.62mlTrain batch 4/32 - 238.1ms/batch - loss: 1.82219 - diff: 29.16mlTrain batch 5/32 - 236.4ms/batch - loss: 1.65099 - diff: 26.42mlTrain batch 6/32 - 236.7ms/batch - loss: 1.58585 - diff: 25.37mlTrain batch 7/32 - 236.1ms/batch - loss: 1.55521 - diff: 24.88mlTrain batch 8/32 - 243.1ms/batch - loss: 1.52510 - diff: 24.40mlTrain batch 9/32 - 235.7ms/batch - loss: 1.58349 - diff: 25.34mlTrain batch 10/32 - 236.5ms/batch - loss: 1.52430 - diff: 24.39mlTrain batch 11/32 - 235.7ms/batch - loss: 1.52402 - diff: 24.38mlTrain batch 12/32 - 236.2ms/batch - loss: 1.51694 - diff: 24.27mlTrain batch 13/32 - 236.1ms/batch - loss: 1.49320 - diff: 23.89mlTrain batch 14/32 - 236.4ms/batch - loss: 1.48601 - diff: 23.78mlTrain batch 15/32 - 239.0ms/batch - loss: 1.46840 - diff: 23.49mlTrain batch 16/32 - 236.4ms/batch - loss: 1.46888 - diff: 23.50mlTrain batch 17/32 - 236.0ms/batch - loss: 1.44640 - diff: 23.14mlTrain batch 18/32 - 236.2ms/batch - loss: 1.43914 - diff: 23.03mlTrain batch 19/32 - 235.9ms/batch - loss: 1.47156 - diff: 23.54mlTrain batch 20/32 - 243.5ms/batch - loss: 1.47398 - diff: 23.58mlTrain batch 21/32 - 235.6ms/batch - loss: 1.44207 - diff: 23.07mlTrain batch 22/32 - 236.1ms/batch - loss: 1.43470 - diff: 22.96mlTrain batch 23/32 - 235.7ms/batch - loss: 1.44635 - diff: 23.14mlTrain batch 24/32 - 245.4ms/batch - loss: 1.44861 - diff: 23.18mlTrain batch 25/32 - 236.4ms/batch - loss: 1.46611 - diff: 23.46mlTrain batch 26/32 - 236.2ms/batch - loss: 1.46434 - diff: 23.43mlTrain batch 27/32 - 236.9ms/batch - loss: 1.45934 - diff: 23.35mlTrain batch 28/32 - 238.4ms/batch - loss: 1.45207 - diff: 23.23mlTrain batch 29/32 - 235.7ms/batch - loss: 1.45894 - diff: 23.34mlTrain batch 30/32 - 235.7ms/batch - loss: 1.44179 - diff: 23.07mlTrain batch 31/32 - 236.0ms/batch - loss: 1.44094 - diff: 23.06mlTrain batch 32/32 - 82.6ms/batch - loss: 1.47656 - diff: 23.06mlTrain batch 32/32 - 17.5s 82.6ms/batch - loss: 1.47656 - diff: 23.06ml
Test 1.4s: val_loss: 2.00313 - diff: 30.79ml

Epoch 92: current best loss = 1.37943, at epoch 78
Train batch 1/32 - 235.9ms/batch - loss: 2.07042 - diff: 33.13mlTrain batch 2/32 - 236.3ms/batch - loss: 1.68225 - diff: 26.92mlTrain batch 3/32 - 236.1ms/batch - loss: 1.75115 - diff: 28.02mlTrain batch 4/32 - 235.4ms/batch - loss: 1.57792 - diff: 25.25mlTrain batch 5/32 - 235.7ms/batch - loss: 1.47958 - diff: 23.67mlTrain batch 6/32 - 235.4ms/batch - loss: 1.48060 - diff: 23.69mlTrain batch 7/32 - 235.9ms/batch - loss: 1.42849 - diff: 22.86mlTrain batch 8/32 - 236.0ms/batch - loss: 1.45706 - diff: 23.31mlTrain batch 9/32 - 236.6ms/batch - loss: 1.51024 - diff: 24.16mlTrain batch 10/32 - 239.9ms/batch - loss: 1.46232 - diff: 23.40mlTrain batch 11/32 - 235.8ms/batch - loss: 1.43575 - diff: 22.97mlTrain batch 12/32 - 236.0ms/batch - loss: 1.47061 - diff: 23.53mlTrain batch 13/32 - 236.0ms/batch - loss: 1.44714 - diff: 23.15mlTrain batch 14/32 - 235.9ms/batch - loss: 1.45639 - diff: 23.30mlTrain batch 15/32 - 235.9ms/batch - loss: 1.48447 - diff: 23.75mlTrain batch 16/32 - 241.8ms/batch - loss: 1.48288 - diff: 23.73mlTrain batch 17/32 - 236.5ms/batch - loss: 1.48918 - diff: 23.83mlTrain batch 18/32 - 235.9ms/batch - loss: 1.50488 - diff: 24.08mlTrain batch 19/32 - 236.5ms/batch - loss: 1.49485 - diff: 23.92mlTrain batch 20/32 - 235.4ms/batch - loss: 1.47279 - diff: 23.56mlTrain batch 21/32 - 235.4ms/batch - loss: 1.48458 - diff: 23.75mlTrain batch 22/32 - 235.4ms/batch - loss: 1.47433 - diff: 23.59mlTrain batch 23/32 - 236.0ms/batch - loss: 1.46837 - diff: 23.49mlTrain batch 24/32 - 235.5ms/batch - loss: 1.49445 - diff: 23.91mlTrain batch 25/32 - 235.6ms/batch - loss: 1.47237 - diff: 23.56mlTrain batch 26/32 - 235.9ms/batch - loss: 1.46468 - diff: 23.43mlTrain batch 27/32 - 236.7ms/batch - loss: 1.44200 - diff: 23.07mlTrain batch 28/32 - 235.8ms/batch - loss: 1.43209 - diff: 22.91mlTrain batch 29/32 - 236.0ms/batch - loss: 1.42746 - diff: 22.84mlTrain batch 30/32 - 237.0ms/batch - loss: 1.43808 - diff: 23.01mlTrain batch 31/32 - 236.8ms/batch - loss: 1.44091 - diff: 23.05mlTrain batch 32/32 - 77.8ms/batch - loss: 1.51094 - diff: 23.20mlTrain batch 32/32 - 17.5s 77.8ms/batch - loss: 1.51094 - diff: 23.20ml
Test 1.3s: val_loss: 1.44001 - diff: 22.21ml

Epoch 93: current best loss = 1.37943, at epoch 78
Train batch 1/32 - 235.8ms/batch - loss: 1.30532 - diff: 20.89mlTrain batch 2/32 - 247.7ms/batch - loss: 1.41434 - diff: 22.63mlTrain batch 3/32 - 238.1ms/batch - loss: 1.28081 - diff: 20.49mlTrain batch 4/32 - 235.6ms/batch - loss: 1.29184 - diff: 20.67mlTrain batch 5/32 - 235.5ms/batch - loss: 1.32000 - diff: 21.12mlTrain batch 6/32 - 236.3ms/batch - loss: 1.31258 - diff: 21.00mlTrain batch 7/32 - 235.5ms/batch - loss: 1.29065 - diff: 20.65mlTrain batch 8/32 - 236.5ms/batch - loss: 1.32049 - diff: 21.13mlTrain batch 9/32 - 235.7ms/batch - loss: 1.31904 - diff: 21.10mlTrain batch 10/32 - 236.8ms/batch - loss: 1.33273 - diff: 21.32mlTrain batch 11/32 - 235.8ms/batch - loss: 1.35727 - diff: 21.72mlTrain batch 12/32 - 236.7ms/batch - loss: 1.37642 - diff: 22.02mlTrain batch 13/32 - 235.5ms/batch - loss: 1.35455 - diff: 21.67mlTrain batch 14/32 - 235.9ms/batch - loss: 1.38153 - diff: 22.10mlTrain batch 15/32 - 235.9ms/batch - loss: 1.39843 - diff: 22.37mlTrain batch 16/32 - 235.8ms/batch - loss: 1.37902 - diff: 22.06mlTrain batch 17/32 - 236.1ms/batch - loss: 1.37082 - diff: 21.93mlTrain batch 18/32 - 235.5ms/batch - loss: 1.36074 - diff: 21.77mlTrain batch 19/32 - 235.8ms/batch - loss: 1.37339 - diff: 21.97mlTrain batch 20/32 - 236.3ms/batch - loss: 1.38205 - diff: 22.11mlTrain batch 21/32 - 240.2ms/batch - loss: 1.44807 - diff: 23.17mlTrain batch 22/32 - 236.8ms/batch - loss: 1.43167 - diff: 22.91mlTrain batch 23/32 - 236.0ms/batch - loss: 1.43892 - diff: 23.02mlTrain batch 24/32 - 237.2ms/batch - loss: 1.43339 - diff: 22.93mlTrain batch 25/32 - 236.2ms/batch - loss: 1.42040 - diff: 22.73mlTrain batch 26/32 - 236.4ms/batch - loss: 1.40464 - diff: 22.47mlTrain batch 27/32 - 235.8ms/batch - loss: 1.40167 - diff: 22.43mlTrain batch 28/32 - 235.8ms/batch - loss: 1.40707 - diff: 22.51mlTrain batch 29/32 - 235.9ms/batch - loss: 1.39993 - diff: 22.40mlTrain batch 30/32 - 235.9ms/batch - loss: 1.41285 - diff: 22.61mlTrain batch 31/32 - 235.7ms/batch - loss: 1.39632 - diff: 22.34mlTrain batch 32/32 - 79.2ms/batch - loss: 1.44648 - diff: 22.41mlTrain batch 32/32 - 17.1s 79.2ms/batch - loss: 1.44648 - diff: 22.41ml
Test 1.4s: val_loss: 1.56865 - diff: 24.65ml

Epoch 94: current best loss = 1.37943, at epoch 78
Train batch 1/32 - 235.9ms/batch - loss: 1.31096 - diff: 20.98mlTrain batch 2/32 - 253.9ms/batch - loss: 1.55258 - diff: 24.84mlTrain batch 3/32 - 236.0ms/batch - loss: 1.41619 - diff: 22.66mlTrain batch 4/32 - 235.8ms/batch - loss: 1.36765 - diff: 21.88mlTrain batch 5/32 - 236.4ms/batch - loss: 1.39054 - diff: 22.25mlTrain batch 6/32 - 236.2ms/batch - loss: 1.43973 - diff: 23.04mlTrain batch 7/32 - 236.0ms/batch - loss: 1.34042 - diff: 21.45mlTrain batch 8/32 - 236.7ms/batch - loss: 1.39497 - diff: 22.32mlTrain batch 9/32 - 244.9ms/batch - loss: 1.38238 - diff: 22.12mlTrain batch 10/32 - 235.9ms/batch - loss: 1.49077 - diff: 23.85mlTrain batch 11/32 - 236.0ms/batch - loss: 1.46929 - diff: 23.51mlTrain batch 12/32 - 236.3ms/batch - loss: 1.52275 - diff: 24.36mlTrain batch 13/32 - 236.0ms/batch - loss: 1.48190 - diff: 23.71mlTrain batch 14/32 - 237.0ms/batch - loss: 1.51239 - diff: 24.20mlTrain batch 15/32 - 240.8ms/batch - loss: 1.50042 - diff: 24.01mlTrain batch 16/32 - 236.8ms/batch - loss: 1.48731 - diff: 23.80mlTrain batch 17/32 - 236.2ms/batch - loss: 1.47002 - diff: 23.52mlTrain batch 18/32 - 236.1ms/batch - loss: 1.44793 - diff: 23.17mlTrain batch 19/32 - 235.8ms/batch - loss: 1.43837 - diff: 23.01mlTrain batch 20/32 - 236.8ms/batch - loss: 1.44698 - diff: 23.15mlTrain batch 21/32 - 235.4ms/batch - loss: 1.43026 - diff: 22.88mlTrain batch 22/32 - 241.8ms/batch - loss: 1.42719 - diff: 22.83mlTrain batch 23/32 - 236.2ms/batch - loss: 1.41033 - diff: 22.57mlTrain batch 24/32 - 236.3ms/batch - loss: 1.40605 - diff: 22.50mlTrain batch 25/32 - 236.0ms/batch - loss: 1.41816 - diff: 22.69mlTrain batch 26/32 - 235.9ms/batch - loss: 1.40825 - diff: 22.53mlTrain batch 27/32 - 235.8ms/batch - loss: 1.42361 - diff: 22.78mlTrain batch 28/32 - 235.9ms/batch - loss: 1.42145 - diff: 22.74mlTrain batch 29/32 - 236.1ms/batch - loss: 1.42729 - diff: 22.84mlTrain batch 30/32 - 235.9ms/batch - loss: 1.42736 - diff: 22.84mlTrain batch 31/32 - 236.3ms/batch - loss: 1.41758 - diff: 22.68mlTrain batch 32/32 - 76.9ms/batch - loss: 1.45027 - diff: 22.68mlTrain batch 32/32 - 16.5s 76.9ms/batch - loss: 1.45027 - diff: 22.68ml
Test 1.5s: val_loss: 1.56553 - diff: 24.03ml

Epoch 95: current best loss = 1.37943, at epoch 78
Train batch 1/32 - 235.9ms/batch - loss: 1.27282 - diff: 20.37mlTrain batch 2/32 - 236.3ms/batch - loss: 1.80722 - diff: 28.92mlTrain batch 3/32 - 236.1ms/batch - loss: 1.59210 - diff: 25.47mlTrain batch 4/32 - 236.4ms/batch - loss: 1.74561 - diff: 27.93mlTrain batch 5/32 - 235.7ms/batch - loss: 1.55512 - diff: 24.88mlTrain batch 6/32 - 237.6ms/batch - loss: 1.56567 - diff: 25.05mlTrain batch 7/32 - 236.2ms/batch - loss: 1.52434 - diff: 24.39mlTrain batch 8/32 - 236.8ms/batch - loss: 1.48439 - diff: 23.75mlTrain batch 9/32 - 235.7ms/batch - loss: 1.49259 - diff: 23.88mlTrain batch 10/32 - 235.6ms/batch - loss: 1.48237 - diff: 23.72mlTrain batch 11/32 - 235.9ms/batch - loss: 1.46852 - diff: 23.50mlTrain batch 12/32 - 236.2ms/batch - loss: 1.41427 - diff: 22.63mlTrain batch 13/32 - 236.2ms/batch - loss: 1.39045 - diff: 22.25mlTrain batch 14/32 - 235.8ms/batch - loss: 1.39186 - diff: 22.27mlTrain batch 15/32 - 236.0ms/batch - loss: 1.38145 - diff: 22.10mlTrain batch 16/32 - 236.5ms/batch - loss: 1.38627 - diff: 22.18mlTrain batch 17/32 - 236.4ms/batch - loss: 1.40121 - diff: 22.42mlTrain batch 18/32 - 236.7ms/batch - loss: 1.42091 - diff: 22.73mlTrain batch 19/32 - 236.3ms/batch - loss: 1.46478 - diff: 23.44mlTrain batch 20/32 - 236.7ms/batch - loss: 1.44928 - diff: 23.19mlTrain batch 21/32 - 235.8ms/batch - loss: 1.46789 - diff: 23.49mlTrain batch 22/32 - 236.5ms/batch - loss: 1.45387 - diff: 23.26mlTrain batch 23/32 - 246.9ms/batch - loss: 1.46047 - diff: 23.37mlTrain batch 24/32 - 236.2ms/batch - loss: 1.44463 - diff: 23.11mlTrain batch 25/32 - 236.0ms/batch - loss: 1.41834 - diff: 22.69mlTrain batch 26/32 - 235.5ms/batch - loss: 1.41429 - diff: 22.63mlTrain batch 27/32 - 239.0ms/batch - loss: 1.42083 - diff: 22.73mlTrain batch 28/32 - 236.4ms/batch - loss: 1.40394 - diff: 22.46mlTrain batch 29/32 - 235.7ms/batch - loss: 1.39085 - diff: 22.25mlTrain batch 30/32 - 236.0ms/batch - loss: 1.39295 - diff: 22.29mlTrain batch 31/32 - 235.7ms/batch - loss: 1.41035 - diff: 22.57mlTrain batch 32/32 - 76.4ms/batch - loss: 1.45499 - diff: 22.61mlTrain batch 32/32 - 16.5s 76.4ms/batch - loss: 1.45499 - diff: 22.61ml
Test 1.5s: val_loss: 1.49890 - diff: 23.11ml

Epoch 96: current best loss = 1.37943, at epoch 78
Train batch 1/32 - 236.0ms/batch - loss: 1.27303 - diff: 20.37mlTrain batch 2/32 - 238.0ms/batch - loss: 1.27307 - diff: 20.37mlTrain batch 3/32 - 235.6ms/batch - loss: 1.31494 - diff: 21.04mlTrain batch 4/32 - 236.1ms/batch - loss: 1.32179 - diff: 21.15mlTrain batch 5/32 - 236.4ms/batch - loss: 1.31588 - diff: 21.05mlTrain batch 6/32 - 238.8ms/batch - loss: 1.30841 - diff: 20.93mlTrain batch 7/32 - 235.8ms/batch - loss: 1.37369 - diff: 21.98mlTrain batch 8/32 - 236.3ms/batch - loss: 1.39548 - diff: 22.33mlTrain batch 9/32 - 236.0ms/batch - loss: 1.42267 - diff: 22.76mlTrain batch 10/32 - 236.1ms/batch - loss: 1.43751 - diff: 23.00mlTrain batch 11/32 - 236.0ms/batch - loss: 1.42696 - diff: 22.83mlTrain batch 12/32 - 236.0ms/batch - loss: 1.40644 - diff: 22.50mlTrain batch 13/32 - 235.7ms/batch - loss: 1.51489 - diff: 24.24mlTrain batch 14/32 - 236.0ms/batch - loss: 1.54755 - diff: 24.76mlTrain batch 15/32 - 236.3ms/batch - loss: 1.50617 - diff: 24.10mlTrain batch 16/32 - 236.1ms/batch - loss: 1.50133 - diff: 24.02mlTrain batch 17/32 - 236.1ms/batch - loss: 1.49870 - diff: 23.98mlTrain batch 18/32 - 236.7ms/batch - loss: 1.47856 - diff: 23.66mlTrain batch 19/32 - 236.0ms/batch - loss: 1.44869 - diff: 23.18mlTrain batch 20/32 - 236.3ms/batch - loss: 1.43641 - diff: 22.98mlTrain batch 21/32 - 236.3ms/batch - loss: 1.42488 - diff: 22.80mlTrain batch 22/32 - 237.0ms/batch - loss: 1.42202 - diff: 22.75mlTrain batch 23/32 - 237.0ms/batch - loss: 1.42131 - diff: 22.74mlTrain batch 24/32 - 236.5ms/batch - loss: 1.39416 - diff: 22.31mlTrain batch 25/32 - 238.3ms/batch - loss: 1.37889 - diff: 22.06mlTrain batch 26/32 - 245.1ms/batch - loss: 1.36888 - diff: 21.90mlTrain batch 27/32 - 235.8ms/batch - loss: 1.36352 - diff: 21.82mlTrain batch 28/32 - 236.1ms/batch - loss: 1.38099 - diff: 22.10mlTrain batch 29/32 - 236.5ms/batch - loss: 1.38739 - diff: 22.20mlTrain batch 30/32 - 236.0ms/batch - loss: 1.37237 - diff: 21.96mlTrain batch 31/32 - 240.7ms/batch - loss: 1.38568 - diff: 22.17mlTrain batch 32/32 - 76.7ms/batch - loss: 1.43294 - diff: 22.23mlTrain batch 32/32 - 17.0s 76.7ms/batch - loss: 1.43294 - diff: 22.23ml
Test 1.3s: val_loss: 1.60016 - diff: 24.60ml

Epoch 97: current best loss = 1.37943, at epoch 78
Train batch 1/32 - 235.5ms/batch - loss: 1.23375 - diff: 19.74mlTrain batch 2/32 - 236.4ms/batch - loss: 1.15533 - diff: 18.49mlTrain batch 3/32 - 235.5ms/batch - loss: 1.21869 - diff: 19.50mlTrain batch 4/32 - 235.9ms/batch - loss: 1.32833 - diff: 21.25mlTrain batch 5/32 - 235.4ms/batch - loss: 1.42030 - diff: 22.72mlTrain batch 6/32 - 235.8ms/batch - loss: 1.44419 - diff: 23.11mlTrain batch 7/32 - 235.8ms/batch - loss: 1.54424 - diff: 24.71mlTrain batch 8/32 - 236.6ms/batch - loss: 1.51177 - diff: 24.19mlTrain batch 9/32 - 236.2ms/batch - loss: 1.51482 - diff: 24.24mlTrain batch 10/32 - 236.9ms/batch - loss: 1.53118 - diff: 24.50mlTrain batch 11/32 - 235.5ms/batch - loss: 1.53034 - diff: 24.49mlTrain batch 12/32 - 236.1ms/batch - loss: 1.53852 - diff: 24.62mlTrain batch 13/32 - 236.2ms/batch - loss: 1.52356 - diff: 24.38mlTrain batch 14/32 - 236.7ms/batch - loss: 1.54116 - diff: 24.66mlTrain batch 15/32 - 236.3ms/batch - loss: 1.52815 - diff: 24.45mlTrain batch 16/32 - 236.4ms/batch - loss: 1.48727 - diff: 23.80mlTrain batch 17/32 - 235.9ms/batch - loss: 1.47478 - diff: 23.60mlTrain batch 18/32 - 236.6ms/batch - loss: 1.48470 - diff: 23.76mlTrain batch 19/32 - 236.2ms/batch - loss: 1.45207 - diff: 23.23mlTrain batch 20/32 - 236.8ms/batch - loss: 1.44200 - diff: 23.07mlTrain batch 21/32 - 235.8ms/batch - loss: 1.44323 - diff: 23.09mlTrain batch 22/32 - 236.2ms/batch - loss: 1.42654 - diff: 22.82mlTrain batch 23/32 - 235.5ms/batch - loss: 1.44545 - diff: 23.13mlTrain batch 24/32 - 236.4ms/batch - loss: 1.43098 - diff: 22.90mlTrain batch 25/32 - 236.3ms/batch - loss: 1.45913 - diff: 23.35mlTrain batch 26/32 - 236.5ms/batch - loss: 1.46634 - diff: 23.46mlTrain batch 27/32 - 235.4ms/batch - loss: 1.45798 - diff: 23.33mlTrain batch 28/32 - 236.0ms/batch - loss: 1.45939 - diff: 23.35mlTrain batch 29/32 - 236.1ms/batch - loss: 1.45010 - diff: 23.20mlTrain batch 30/32 - 236.4ms/batch - loss: 1.43559 - diff: 22.97mlTrain batch 31/32 - 236.3ms/batch - loss: 1.41816 - diff: 22.69mlTrain batch 32/32 - 80.3ms/batch - loss: 1.52465 - diff: 22.98mlTrain batch 32/32 - 16.4s 80.3ms/batch - loss: 1.52465 - diff: 22.98ml
Test 1.5s: val_loss: 1.43878 - diff: 22.26ml

Epoch 98: current best loss = 1.37943, at epoch 78
Train batch 1/32 - 235.6ms/batch - loss: 1.35935 - diff: 21.75mlTrain batch 2/32 - 236.2ms/batch - loss: 1.46666 - diff: 23.47mlTrain batch 3/32 - 235.7ms/batch - loss: 1.29930 - diff: 20.79mlTrain batch 4/32 - 237.0ms/batch - loss: 1.28675 - diff: 20.59mlTrain batch 5/32 - 236.1ms/batch - loss: 1.15022 - diff: 18.40mlTrain batch 6/32 - 236.2ms/batch - loss: 1.24034 - diff: 19.85mlTrain batch 7/32 - 235.8ms/batch - loss: 1.35373 - diff: 21.66mlTrain batch 8/32 - 235.8ms/batch - loss: 1.39727 - diff: 22.36mlTrain batch 9/32 - 240.0ms/batch - loss: 1.35544 - diff: 21.69mlTrain batch 10/32 - 237.0ms/batch - loss: 1.36058 - diff: 21.77mlTrain batch 11/32 - 236.9ms/batch - loss: 1.31235 - diff: 21.00mlTrain batch 12/32 - 235.5ms/batch - loss: 1.28283 - diff: 20.53mlTrain batch 13/32 - 235.9ms/batch - loss: 1.32298 - diff: 21.17mlTrain batch 14/32 - 241.1ms/batch - loss: 1.32904 - diff: 21.26mlTrain batch 15/32 - 239.2ms/batch - loss: 1.32850 - diff: 21.26mlTrain batch 16/32 - 235.5ms/batch - loss: 1.33389 - diff: 21.34mlTrain batch 17/32 - 237.0ms/batch - loss: 1.34901 - diff: 21.58mlTrain batch 18/32 - 235.9ms/batch - loss: 1.33310 - diff: 21.33mlTrain batch 19/32 - 235.5ms/batch - loss: 1.32713 - diff: 21.23mlTrain batch 20/32 - 236.5ms/batch - loss: 1.31706 - diff: 21.07mlTrain batch 21/32 - 236.4ms/batch - loss: 1.31328 - diff: 21.01mlTrain batch 22/32 - 236.1ms/batch - loss: 1.33105 - diff: 21.30mlTrain batch 23/32 - 236.5ms/batch - loss: 1.32909 - diff: 21.27mlTrain batch 24/32 - 236.0ms/batch - loss: 1.32908 - diff: 21.27mlTrain batch 25/32 - 237.1ms/batch - loss: 1.36840 - diff: 21.89mlTrain batch 26/32 - 236.3ms/batch - loss: 1.35811 - diff: 21.73mlTrain batch 27/32 - 236.2ms/batch - loss: 1.37487 - diff: 22.00mlTrain batch 28/32 - 236.4ms/batch - loss: 1.37101 - diff: 21.94mlTrain batch 29/32 - 236.5ms/batch - loss: 1.38578 - diff: 22.17mlTrain batch 30/32 - 236.3ms/batch - loss: 1.42345 - diff: 22.78mlTrain batch 31/32 - 236.2ms/batch - loss: 1.40869 - diff: 22.54mlTrain batch 32/32 - 77.0ms/batch - loss: 1.42611 - diff: 22.47mlTrain batch 32/32 - 17.3s 77.0ms/batch - loss: 1.42611 - diff: 22.47ml
Test 1.5s: val_loss: 2.16969 - diff: 33.29ml

Epoch 99: current best loss = 1.37943, at epoch 78
Train batch 1/32 - 235.9ms/batch - loss: 0.98100 - diff: 15.70mlTrain batch 2/32 - 235.5ms/batch - loss: 1.17191 - diff: 18.75mlTrain batch 3/32 - 235.8ms/batch - loss: 1.23831 - diff: 19.81mlTrain batch 4/32 - 236.5ms/batch - loss: 1.22476 - diff: 19.60mlTrain batch 5/32 - 236.2ms/batch - loss: 1.23163 - diff: 19.71mlTrain batch 6/32 - 236.1ms/batch - loss: 1.18752 - diff: 19.00mlTrain batch 7/32 - 235.2ms/batch - loss: 1.16145 - diff: 18.58mlTrain batch 8/32 - 235.9ms/batch - loss: 1.21296 - diff: 19.41mlTrain batch 9/32 - 235.9ms/batch - loss: 1.20396 - diff: 19.26mlTrain batch 10/32 - 237.0ms/batch - loss: 1.25817 - diff: 20.13mlTrain batch 11/32 - 241.1ms/batch - loss: 1.28640 - diff: 20.58mlTrain batch 12/32 - 236.1ms/batch - loss: 1.31629 - diff: 21.06mlTrain batch 13/32 - 235.8ms/batch - loss: 1.29885 - diff: 20.78mlTrain batch 14/32 - 236.8ms/batch - loss: 1.35537 - diff: 21.69mlTrain batch 15/32 - 235.8ms/batch - loss: 1.33235 - diff: 21.32mlTrain batch 16/32 - 241.2ms/batch - loss: 1.32033 - diff: 21.13mlTrain batch 17/32 - 236.6ms/batch - loss: 1.28083 - diff: 20.49mlTrain batch 18/32 - 236.2ms/batch - loss: 1.31964 - diff: 21.11mlTrain batch 19/32 - 240.6ms/batch - loss: 1.34236 - diff: 21.48mlTrain batch 20/32 - 249.5ms/batch - loss: 1.34879 - diff: 21.58mlTrain batch 21/32 - 235.9ms/batch - loss: 1.37588 - diff: 22.01mlTrain batch 22/32 - 236.4ms/batch - loss: 1.38239 - diff: 22.12mlTrain batch 23/32 - 235.4ms/batch - loss: 1.37534 - diff: 22.01mlTrain batch 24/32 - 236.0ms/batch - loss: 1.37146 - diff: 21.94mlTrain batch 25/32 - 236.4ms/batch - loss: 1.36538 - diff: 21.85mlTrain batch 26/32 - 236.9ms/batch - loss: 1.35799 - diff: 21.73mlTrain batch 27/32 - 236.3ms/batch - loss: 1.35727 - diff: 21.72mlTrain batch 28/32 - 236.8ms/batch - loss: 1.35421 - diff: 21.67mlTrain batch 29/32 - 235.7ms/batch - loss: 1.34956 - diff: 21.59mlTrain batch 30/32 - 236.7ms/batch - loss: 1.34690 - diff: 21.55mlTrain batch 31/32 - 235.9ms/batch - loss: 1.35773 - diff: 21.72mlTrain batch 32/32 - 76.1ms/batch - loss: 1.39228 - diff: 21.73mlTrain batch 32/32 - 17.5s 76.1ms/batch - loss: 1.39228 - diff: 21.73ml
Test 1.4s: val_loss: 1.68277 - diff: 26.03ml

Epoch 100: current best loss = 1.37943, at epoch 78
Train batch 1/32 - 240.9ms/batch - loss: 2.50917 - diff: 40.15mlTrain batch 2/32 - 236.4ms/batch - loss: 1.73010 - diff: 27.68mlTrain batch 3/32 - 235.6ms/batch - loss: 1.55965 - diff: 24.95mlTrain batch 4/32 - 236.0ms/batch - loss: 1.42992 - diff: 22.88mlTrain batch 5/32 - 236.0ms/batch - loss: 1.42996 - diff: 22.88mlTrain batch 6/32 - 235.8ms/batch - loss: 1.34511 - diff: 21.52mlTrain batch 7/32 - 236.2ms/batch - loss: 1.41645 - diff: 22.66mlTrain batch 8/32 - 236.6ms/batch - loss: 1.41225 - diff: 22.60mlTrain batch 9/32 - 236.6ms/batch - loss: 1.45875 - diff: 23.34mlTrain batch 10/32 - 236.2ms/batch - loss: 1.46640 - diff: 23.46mlTrain batch 11/32 - 236.8ms/batch - loss: 1.45270 - diff: 23.24mlTrain batch 12/32 - 236.3ms/batch - loss: 1.45131 - diff: 23.22mlTrain batch 13/32 - 237.9ms/batch - loss: 1.42179 - diff: 22.75mlTrain batch 14/32 - 236.7ms/batch - loss: 1.42179 - diff: 22.75mlTrain batch 15/32 - 236.3ms/batch - loss: 1.42435 - diff: 22.79mlTrain batch 16/32 - 236.3ms/batch - loss: 1.40239 - diff: 22.44mlTrain batch 17/32 - 244.8ms/batch - loss: 1.41039 - diff: 22.57mlTrain batch 18/32 - 236.6ms/batch - loss: 1.40148 - diff: 22.42mlTrain batch 19/32 - 236.3ms/batch - loss: 1.40615 - diff: 22.50mlTrain batch 20/32 - 236.8ms/batch - loss: 1.42380 - diff: 22.78mlTrain batch 21/32 - 236.4ms/batch - loss: 1.51951 - diff: 24.31mlTrain batch 22/32 - 236.4ms/batch - loss: 1.53228 - diff: 24.52mlTrain batch 23/32 - 236.3ms/batch - loss: 1.50725 - diff: 24.12mlTrain batch 24/32 - 236.1ms/batch - loss: 1.49092 - diff: 23.85mlTrain batch 25/32 - 237.6ms/batch - loss: 1.49739 - diff: 23.96mlTrain batch 26/32 - 236.7ms/batch - loss: 1.48507 - diff: 23.76mlTrain batch 27/32 - 236.8ms/batch - loss: 1.48147 - diff: 23.70mlTrain batch 28/32 - 235.6ms/batch - loss: 1.48212 - diff: 23.71mlTrain batch 29/32 - 236.0ms/batch - loss: 1.48795 - diff: 23.81mlTrain batch 30/32 - 236.0ms/batch - loss: 1.48984 - diff: 23.84mlTrain batch 31/32 - 235.5ms/batch - loss: 1.48802 - diff: 23.81mlTrain batch 32/32 - 83.7ms/batch - loss: 1.56116 - diff: 23.96mlTrain batch 32/32 - 17.2s 83.7ms/batch - loss: 1.56116 - diff: 23.96ml
Test 1.4s: val_loss: 1.41575 - diff: 21.76ml
Epoch   101: reducing learning rate of group 0 to 2.5000e-04.

Epoch 101: current best loss = 1.37943, at epoch 78
Train batch 1/32 - 236.3ms/batch - loss: 0.96513 - diff: 15.44mlTrain batch 2/32 - 236.2ms/batch - loss: 1.29399 - diff: 20.70mlTrain batch 3/32 - 235.5ms/batch - loss: 1.33724 - diff: 21.40mlTrain batch 4/32 - 236.0ms/batch - loss: 1.35626 - diff: 21.70mlTrain batch 5/32 - 238.0ms/batch - loss: 1.33215 - diff: 21.31mlTrain batch 6/32 - 236.0ms/batch - loss: 1.26625 - diff: 20.26mlTrain batch 7/32 - 235.6ms/batch - loss: 1.31075 - diff: 20.97mlTrain batch 8/32 - 236.2ms/batch - loss: 1.40060 - diff: 22.41mlTrain batch 9/32 - 235.8ms/batch - loss: 1.38802 - diff: 22.21mlTrain batch 10/32 - 236.0ms/batch - loss: 1.36528 - diff: 21.84mlTrain batch 11/32 - 236.2ms/batch - loss: 1.37881 - diff: 22.06mlTrain batch 12/32 - 245.3ms/batch - loss: 1.36121 - diff: 21.78mlTrain batch 13/32 - 235.8ms/batch - loss: 1.39180 - diff: 22.27mlTrain batch 14/32 - 236.6ms/batch - loss: 1.38414 - diff: 22.15mlTrain batch 15/32 - 235.9ms/batch - loss: 1.36965 - diff: 21.91mlTrain batch 16/32 - 235.7ms/batch - loss: 1.37148 - diff: 21.94mlTrain batch 17/32 - 235.8ms/batch - loss: 1.34894 - diff: 21.58mlTrain batch 18/32 - 235.8ms/batch - loss: 1.30503 - diff: 20.88mlTrain batch 19/32 - 235.9ms/batch - loss: 1.30552 - diff: 20.89mlTrain batch 20/32 - 237.3ms/batch - loss: 1.29309 - diff: 20.69mlTrain batch 21/32 - 235.3ms/batch - loss: 1.30371 - diff: 20.86mlTrain batch 22/32 - 236.4ms/batch - loss: 1.30737 - diff: 20.92mlTrain batch 23/32 - 236.6ms/batch - loss: 1.31461 - diff: 21.03mlTrain batch 24/32 - 236.5ms/batch - loss: 1.31550 - diff: 21.05mlTrain batch 25/32 - 236.2ms/batch - loss: 1.31172 - diff: 20.99mlTrain batch 26/32 - 236.3ms/batch - loss: 1.31563 - diff: 21.05mlTrain batch 27/32 - 235.8ms/batch - loss: 1.31021 - diff: 20.96mlTrain batch 28/32 - 236.3ms/batch - loss: 1.30652 - diff: 20.90mlTrain batch 29/32 - 238.9ms/batch - loss: 1.31120 - diff: 20.98mlTrain batch 30/32 - 235.9ms/batch - loss: 1.30847 - diff: 20.94mlTrain batch 31/32 - 236.3ms/batch - loss: 1.31399 - diff: 21.02mlTrain batch 32/32 - 83.9ms/batch - loss: 1.33106 - diff: 20.97mlTrain batch 32/32 - 17.9s 83.9ms/batch - loss: 1.33106 - diff: 20.97ml
Test 1.4s: val_loss: 1.38605 - diff: 21.18ml

Epoch 102: current best loss = 1.37943, at epoch 78
Train batch 1/32 - 235.7ms/batch - loss: 0.93076 - diff: 14.89mlTrain batch 2/32 - 236.6ms/batch - loss: 1.01785 - diff: 16.29mlTrain batch 3/32 - 235.6ms/batch - loss: 1.16584 - diff: 18.65mlTrain batch 4/32 - 254.8ms/batch - loss: 1.26905 - diff: 20.30mlTrain batch 5/32 - 235.6ms/batch - loss: 1.28700 - diff: 20.59mlTrain batch 6/32 - 236.8ms/batch - loss: 1.32325 - diff: 21.17mlTrain batch 7/32 - 236.1ms/batch - loss: 1.34704 - diff: 21.55mlTrain batch 8/32 - 236.7ms/batch - loss: 1.34220 - diff: 21.48mlTrain batch 9/32 - 235.6ms/batch - loss: 1.29531 - diff: 20.72mlTrain batch 10/32 - 236.2ms/batch - loss: 1.31360 - diff: 21.02mlTrain batch 11/32 - 235.6ms/batch - loss: 1.34942 - diff: 21.59mlTrain batch 12/32 - 252.7ms/batch - loss: 1.32890 - diff: 21.26mlTrain batch 13/32 - 236.3ms/batch - loss: 1.34960 - diff: 21.59mlTrain batch 14/32 - 236.6ms/batch - loss: 1.33647 - diff: 21.38mlTrain batch 15/32 - 235.5ms/batch - loss: 1.35952 - diff: 21.75mlTrain batch 16/32 - 241.4ms/batch - loss: 1.35577 - diff: 21.69mlTrain batch 17/32 - 235.7ms/batch - loss: 1.35936 - diff: 21.75mlTrain batch 18/32 - 235.5ms/batch - loss: 1.41984 - diff: 22.72mlTrain batch 19/32 - 236.0ms/batch - loss: 1.40207 - diff: 22.43mlTrain batch 20/32 - 236.9ms/batch - loss: 1.38761 - diff: 22.20mlTrain batch 21/32 - 235.7ms/batch - loss: 1.39356 - diff: 22.30mlTrain batch 22/32 - 235.3ms/batch - loss: 1.39685 - diff: 22.35mlTrain batch 23/32 - 235.8ms/batch - loss: 1.37898 - diff: 22.06mlTrain batch 24/32 - 236.7ms/batch - loss: 1.38258 - diff: 22.12mlTrain batch 25/32 - 235.8ms/batch - loss: 1.39329 - diff: 22.29mlTrain batch 26/32 - 235.9ms/batch - loss: 1.37305 - diff: 21.97mlTrain batch 27/32 - 235.9ms/batch - loss: 1.35191 - diff: 21.63mlTrain batch 28/32 - 236.5ms/batch - loss: 1.36028 - diff: 21.76mlTrain batch 29/32 - 235.7ms/batch - loss: 1.35506 - diff: 21.68mlTrain batch 30/32 - 236.1ms/batch - loss: 1.35165 - diff: 21.63mlTrain batch 31/32 - 235.4ms/batch - loss: 1.34647 - diff: 21.54mlTrain batch 32/32 - 76.2ms/batch - loss: 1.38425 - diff: 21.57mlTrain batch 32/32 - 17.7s 76.2ms/batch - loss: 1.38425 - diff: 21.57ml
Test 1.3s: val_loss: 1.45115 - diff: 22.42ml

Epoch 103: current best loss = 1.37943, at epoch 78
Train batch 1/32 - 236.1ms/batch - loss: 1.08079 - diff: 17.29mlTrain batch 2/32 - 235.4ms/batch - loss: 1.04094 - diff: 16.66mlTrain batch 3/32 - 235.8ms/batch - loss: 0.99988 - diff: 16.00mlTrain batch 4/32 - 242.9ms/batch - loss: 1.08147 - diff: 17.30mlTrain batch 5/32 - 235.8ms/batch - loss: 1.40127 - diff: 22.42mlTrain batch 6/32 - 235.7ms/batch - loss: 1.40106 - diff: 22.42mlTrain batch 7/32 - 236.0ms/batch - loss: 1.58823 - diff: 25.41mlTrain batch 8/32 - 236.1ms/batch - loss: 1.56458 - diff: 25.03mlTrain batch 9/32 - 236.0ms/batch - loss: 1.57880 - diff: 25.26mlTrain batch 10/32 - 236.0ms/batch - loss: 1.59842 - diff: 25.57mlTrain batch 11/32 - 236.1ms/batch - loss: 1.56907 - diff: 25.11mlTrain batch 12/32 - 236.6ms/batch - loss: 1.53615 - diff: 24.58mlTrain batch 13/32 - 235.8ms/batch - loss: 1.55666 - diff: 24.91mlTrain batch 14/32 - 236.8ms/batch - loss: 1.56854 - diff: 25.10mlTrain batch 15/32 - 235.5ms/batch - loss: 1.53142 - diff: 24.50mlTrain batch 16/32 - 235.9ms/batch - loss: 1.50755 - diff: 24.12mlTrain batch 17/32 - 235.7ms/batch - loss: 1.48388 - diff: 23.74mlTrain batch 18/32 - 235.8ms/batch - loss: 1.46123 - diff: 23.38mlTrain batch 19/32 - 235.7ms/batch - loss: 1.44815 - diff: 23.17mlTrain batch 20/32 - 253.5ms/batch - loss: 1.42878 - diff: 22.86mlTrain batch 21/32 - 235.7ms/batch - loss: 1.41447 - diff: 22.63mlTrain batch 22/32 - 236.1ms/batch - loss: 1.39804 - diff: 22.37mlTrain batch 23/32 - 235.6ms/batch - loss: 1.38561 - diff: 22.17mlTrain batch 24/32 - 236.9ms/batch - loss: 1.42245 - diff: 22.76mlTrain batch 25/32 - 235.8ms/batch - loss: 1.40734 - diff: 22.52mlTrain batch 26/32 - 236.7ms/batch - loss: 1.39621 - diff: 22.34mlTrain batch 27/32 - 235.6ms/batch - loss: 1.39042 - diff: 22.25mlTrain batch 28/32 - 236.4ms/batch - loss: 1.38269 - diff: 22.12mlTrain batch 29/32 - 235.9ms/batch - loss: 1.37996 - diff: 22.08mlTrain batch 30/32 - 235.8ms/batch - loss: 1.37427 - diff: 21.99mlTrain batch 31/32 - 235.4ms/batch - loss: 1.37240 - diff: 21.96mlTrain batch 32/32 - 81.8ms/batch - loss: 1.44388 - diff: 22.11mlTrain batch 32/32 - 17.7s 81.8ms/batch - loss: 1.44388 - diff: 22.11ml
Test 1.6s: val_loss: 1.80830 - diff: 27.12ml

Epoch 104: current best loss = 1.37943, at epoch 78
Train batch 1/32 - 235.8ms/batch - loss: 1.36211 - diff: 21.79mlTrain batch 2/32 - 237.0ms/batch - loss: 1.50464 - diff: 24.07mlTrain batch 3/32 - 236.7ms/batch - loss: 1.40031 - diff: 22.40mlTrain batch 4/32 - 236.2ms/batch - loss: 1.28981 - diff: 20.64mlTrain batch 5/32 - 235.4ms/batch - loss: 1.25902 - diff: 20.14mlTrain batch 6/32 - 236.5ms/batch - loss: 1.23296 - diff: 19.73mlTrain batch 7/32 - 235.7ms/batch - loss: 1.30153 - diff: 20.82mlTrain batch 8/32 - 236.9ms/batch - loss: 1.31511 - diff: 21.04mlTrain batch 9/32 - 235.9ms/batch - loss: 1.30108 - diff: 20.82mlTrain batch 10/32 - 239.5ms/batch - loss: 1.28415 - diff: 20.55mlTrain batch 11/32 - 236.5ms/batch - loss: 1.28326 - diff: 20.53mlTrain batch 12/32 - 235.5ms/batch - loss: 1.29008 - diff: 20.64mlTrain batch 13/32 - 235.7ms/batch - loss: 1.32896 - diff: 21.26mlTrain batch 14/32 - 238.3ms/batch - loss: 1.31084 - diff: 20.97mlTrain batch 15/32 - 236.8ms/batch - loss: 1.34425 - diff: 21.51mlTrain batch 16/32 - 235.9ms/batch - loss: 1.32414 - diff: 21.19mlTrain batch 17/32 - 236.3ms/batch - loss: 1.33203 - diff: 21.31mlTrain batch 18/32 - 235.8ms/batch - loss: 1.35833 - diff: 21.73mlTrain batch 19/32 - 236.8ms/batch - loss: 1.34216 - diff: 21.47mlTrain batch 20/32 - 236.0ms/batch - loss: 1.35493 - diff: 21.68mlTrain batch 21/32 - 236.0ms/batch - loss: 1.36817 - diff: 21.89mlTrain batch 22/32 - 235.8ms/batch - loss: 1.35779 - diff: 21.72mlTrain batch 23/32 - 236.6ms/batch - loss: 1.33961 - diff: 21.43mlTrain batch 24/32 - 236.7ms/batch - loss: 1.34042 - diff: 21.45mlTrain batch 25/32 - 236.4ms/batch - loss: 1.34061 - diff: 21.45mlTrain batch 26/32 - 236.3ms/batch - loss: 1.34045 - diff: 21.45mlTrain batch 27/32 - 236.0ms/batch - loss: 1.33605 - diff: 21.38mlTrain batch 28/32 - 236.5ms/batch - loss: 1.33991 - diff: 21.44mlTrain batch 29/32 - 236.1ms/batch - loss: 1.33491 - diff: 21.36mlTrain batch 30/32 - 241.2ms/batch - loss: 1.32896 - diff: 21.26mlTrain batch 31/32 - 236.9ms/batch - loss: 1.34236 - diff: 21.48mlTrain batch 32/32 - 92.9ms/batch - loss: 1.35435 - diff: 21.40mlTrain batch 32/32 - 16.6s 92.9ms/batch - loss: 1.35435 - diff: 21.40ml
Test 1.4s: val_loss: 1.43697 - diff: 22.18ml

Epoch 105: current best loss = 1.37943, at epoch 78
Train batch 1/32 - 235.5ms/batch - loss: 1.39623 - diff: 22.34mlTrain batch 2/32 - 236.4ms/batch - loss: 1.73924 - diff: 27.83mlTrain batch 3/32 - 238.2ms/batch - loss: 1.92511 - diff: 30.80mlTrain batch 4/32 - 236.0ms/batch - loss: 1.80124 - diff: 28.82mlTrain batch 5/32 - 235.8ms/batch - loss: 1.67414 - diff: 26.79mlTrain batch 6/32 - 236.4ms/batch - loss: 1.60182 - diff: 25.63mlTrain batch 7/32 - 235.9ms/batch - loss: 1.60115 - diff: 25.62mlTrain batch 8/32 - 237.1ms/batch - loss: 1.69320 - diff: 27.09mlTrain batch 9/32 - 235.8ms/batch - loss: 1.66835 - diff: 26.69mlTrain batch 10/32 - 236.7ms/batch - loss: 1.61921 - diff: 25.91mlTrain batch 11/32 - 235.8ms/batch - loss: 1.57007 - diff: 25.12mlTrain batch 12/32 - 236.8ms/batch - loss: 1.55434 - diff: 24.87mlTrain batch 13/32 - 236.6ms/batch - loss: 1.64066 - diff: 26.25mlTrain batch 14/32 - 236.8ms/batch - loss: 1.61611 - diff: 25.86mlTrain batch 15/32 - 236.0ms/batch - loss: 1.58784 - diff: 25.41mlTrain batch 16/32 - 238.8ms/batch - loss: 1.54122 - diff: 24.66mlTrain batch 17/32 - 235.8ms/batch - loss: 1.55496 - diff: 24.88mlTrain batch 18/32 - 236.9ms/batch - loss: 1.53048 - diff: 24.49mlTrain batch 19/32 - 236.4ms/batch - loss: 1.50052 - diff: 24.01mlTrain batch 20/32 - 236.4ms/batch - loss: 1.52128 - diff: 24.34mlTrain batch 21/32 - 235.8ms/batch - loss: 1.52817 - diff: 24.45mlTrain batch 22/32 - 241.6ms/batch - loss: 1.50130 - diff: 24.02mlTrain batch 23/32 - 236.1ms/batch - loss: 1.48361 - diff: 23.74mlTrain batch 24/32 - 235.8ms/batch - loss: 1.49868 - diff: 23.98mlTrain batch 25/32 - 236.3ms/batch - loss: 1.48412 - diff: 23.75mlTrain batch 26/32 - 236.6ms/batch - loss: 1.46953 - diff: 23.51mlTrain batch 27/32 - 236.3ms/batch - loss: 1.46956 - diff: 23.51mlTrain batch 28/32 - 236.4ms/batch - loss: 1.45505 - diff: 23.28mlTrain batch 29/32 - 236.3ms/batch - loss: 1.44433 - diff: 23.11mlTrain batch 30/32 - 236.5ms/batch - loss: 1.45098 - diff: 23.22mlTrain batch 31/32 - 236.1ms/batch - loss: 1.46130 - diff: 23.38mlTrain batch 32/32 - 76.4ms/batch - loss: 1.50222 - diff: 23.40mlTrain batch 32/32 - 16.9s 76.4ms/batch - loss: 1.50222 - diff: 23.40ml
Test 1.4s: val_loss: 1.51643 - diff: 23.48ml

Epoch 106: current best loss = 1.37943, at epoch 78
Train batch 1/32 - 235.6ms/batch - loss: 1.07255 - diff: 17.16mlTrain batch 2/32 - 236.6ms/batch - loss: 1.19246 - diff: 19.08mlTrain batch 3/32 - 235.8ms/batch - loss: 1.20767 - diff: 19.32mlTrain batch 4/32 - 236.4ms/batch - loss: 1.52962 - diff: 24.47mlTrain batch 5/32 - 239.8ms/batch - loss: 1.43666 - diff: 22.99mlTrain batch 6/32 - 236.7ms/batch - loss: 1.37780 - diff: 22.04mlTrain batch 7/32 - 235.5ms/batch - loss: 1.37489 - diff: 22.00mlTrain batch 8/32 - 236.8ms/batch - loss: 1.31520 - diff: 21.04mlTrain batch 9/32 - 235.8ms/batch - loss: 1.42256 - diff: 22.76mlTrain batch 10/32 - 241.8ms/batch - loss: 1.44471 - diff: 23.12mlTrain batch 11/32 - 236.2ms/batch - loss: 1.50637 - diff: 24.10mlTrain batch 12/32 - 235.8ms/batch - loss: 1.49032 - diff: 23.85mlTrain batch 13/32 - 236.4ms/batch - loss: 1.48083 - diff: 23.69mlTrain batch 14/32 - 236.4ms/batch - loss: 1.44806 - diff: 23.17mlTrain batch 15/32 - 235.8ms/batch - loss: 1.41978 - diff: 22.72mlTrain batch 16/32 - 236.4ms/batch - loss: 1.45504 - diff: 23.28mlTrain batch 17/32 - 235.8ms/batch - loss: 1.44755 - diff: 23.16mlTrain batch 18/32 - 236.4ms/batch - loss: 1.41304 - diff: 22.61mlTrain batch 19/32 - 237.1ms/batch - loss: 1.40183 - diff: 22.43mlTrain batch 20/32 - 236.4ms/batch - loss: 1.41915 - diff: 22.71mlTrain batch 21/32 - 236.0ms/batch - loss: 1.41430 - diff: 22.63mlTrain batch 22/32 - 236.5ms/batch - loss: 1.41370 - diff: 22.62mlTrain batch 23/32 - 235.7ms/batch - loss: 1.39341 - diff: 22.29mlTrain batch 24/32 - 236.8ms/batch - loss: 1.39897 - diff: 22.38mlTrain batch 25/32 - 235.8ms/batch - loss: 1.39604 - diff: 22.34mlTrain batch 26/32 - 236.9ms/batch - loss: 1.39122 - diff: 22.26mlTrain batch 27/32 - 236.0ms/batch - loss: 1.39053 - diff: 22.25mlTrain batch 28/32 - 236.1ms/batch - loss: 1.37114 - diff: 21.94mlTrain batch 29/32 - 236.0ms/batch - loss: 1.36970 - diff: 21.92mlTrain batch 30/32 - 235.6ms/batch - loss: 1.36501 - diff: 21.84mlTrain batch 31/32 - 236.4ms/batch - loss: 1.34493 - diff: 21.52mlTrain batch 32/32 - 83.2ms/batch - loss: 1.36078 - diff: 21.45mlTrain batch 32/32 - 17.5s 83.2ms/batch - loss: 1.36078 - diff: 21.45ml
Test 1.6s: val_loss: 1.49056 - diff: 22.61ml

Epoch 107: current best loss = 1.37943, at epoch 78
Train batch 1/32 - 235.3ms/batch - loss: 1.67497 - diff: 26.80mlTrain batch 2/32 - 235.7ms/batch - loss: 1.30792 - diff: 20.93mlTrain batch 3/32 - 235.7ms/batch - loss: 1.44878 - diff: 23.18mlTrain batch 4/32 - 235.9ms/batch - loss: 1.26142 - diff: 20.18mlTrain batch 5/32 - 263.2ms/batch - loss: 1.24269 - diff: 19.88mlTrain batch 6/32 - 235.5ms/batch - loss: 1.24665 - diff: 19.95mlTrain batch 7/32 - 235.6ms/batch - loss: 1.32296 - diff: 21.17mlTrain batch 8/32 - 236.4ms/batch - loss: 1.31061 - diff: 20.97mlTrain batch 9/32 - 235.4ms/batch - loss: 1.37144 - diff: 21.94mlTrain batch 10/32 - 237.1ms/batch - loss: 1.34060 - diff: 21.45mlTrain batch 11/32 - 235.5ms/batch - loss: 1.37201 - diff: 21.95mlTrain batch 12/32 - 237.0ms/batch - loss: 1.38397 - diff: 22.14mlTrain batch 13/32 - 235.8ms/batch - loss: 1.35229 - diff: 21.64mlTrain batch 14/32 - 236.4ms/batch - loss: 1.33144 - diff: 21.30mlTrain batch 15/32 - 235.9ms/batch - loss: 1.36729 - diff: 21.88mlTrain batch 16/32 - 236.8ms/batch - loss: 1.33341 - diff: 21.33mlTrain batch 17/32 - 236.0ms/batch - loss: 1.34057 - diff: 21.45mlTrain batch 18/32 - 236.7ms/batch - loss: 1.30833 - diff: 20.93mlTrain batch 19/32 - 235.6ms/batch - loss: 1.33798 - diff: 21.41mlTrain batch 20/32 - 236.8ms/batch - loss: 1.34010 - diff: 21.44mlTrain batch 21/32 - 236.0ms/batch - loss: 1.34531 - diff: 21.52mlTrain batch 22/32 - 236.7ms/batch - loss: 1.32489 - diff: 21.20mlTrain batch 23/32 - 235.5ms/batch - loss: 1.32478 - diff: 21.20mlTrain batch 24/32 - 235.8ms/batch - loss: 1.30352 - diff: 20.86mlTrain batch 25/32 - 235.9ms/batch - loss: 1.34150 - diff: 21.46mlTrain batch 26/32 - 236.7ms/batch - loss: 1.33487 - diff: 21.36mlTrain batch 27/32 - 236.0ms/batch - loss: 1.33269 - diff: 21.32mlTrain batch 28/32 - 236.0ms/batch - loss: 1.33091 - diff: 21.29mlTrain batch 29/32 - 235.4ms/batch - loss: 1.34110 - diff: 21.46mlTrain batch 30/32 - 236.7ms/batch - loss: 1.35533 - diff: 21.69mlTrain batch 31/32 - 235.9ms/batch - loss: 1.36253 - diff: 21.80mlTrain batch 32/32 - 83.3ms/batch - loss: 1.38347 - diff: 21.75mlTrain batch 32/32 - 17.5s 83.3ms/batch - loss: 1.38347 - diff: 21.75ml
Test 1.5s: val_loss: 1.54335 - diff: 23.75ml

Epoch 108: current best loss = 1.37943, at epoch 78
Train batch 1/32 - 236.2ms/batch - loss: 1.38119 - diff: 22.10mlTrain batch 2/32 - 242.7ms/batch - loss: 1.12556 - diff: 18.01mlTrain batch 3/32 - 235.6ms/batch - loss: 1.38199 - diff: 22.11mlTrain batch 4/32 - 236.5ms/batch - loss: 1.29813 - diff: 20.77mlTrain batch 5/32 - 235.9ms/batch - loss: 1.49379 - diff: 23.90mlTrain batch 6/32 - 237.6ms/batch - loss: 1.44762 - diff: 23.16mlTrain batch 7/32 - 235.6ms/batch - loss: 1.39587 - diff: 22.33mlTrain batch 8/32 - 239.8ms/batch - loss: 1.38313 - diff: 22.13mlTrain batch 9/32 - 235.8ms/batch - loss: 1.33299 - diff: 21.33mlTrain batch 10/32 - 236.2ms/batch - loss: 1.35233 - diff: 21.64mlTrain batch 11/32 - 235.6ms/batch - loss: 1.38158 - diff: 22.11mlTrain batch 12/32 - 236.0ms/batch - loss: 1.37765 - diff: 22.04mlTrain batch 13/32 - 235.8ms/batch - loss: 1.34598 - diff: 21.54mlTrain batch 14/32 - 235.7ms/batch - loss: 1.34547 - diff: 21.53mlTrain batch 15/32 - 236.3ms/batch - loss: 1.33596 - diff: 21.38mlTrain batch 16/32 - 236.3ms/batch - loss: 1.31237 - diff: 21.00mlTrain batch 17/32 - 237.1ms/batch - loss: 1.31997 - diff: 21.12mlTrain batch 18/32 - 236.6ms/batch - loss: 1.31124 - diff: 20.98mlTrain batch 19/32 - 236.3ms/batch - loss: 1.30530 - diff: 20.88mlTrain batch 20/32 - 236.7ms/batch - loss: 1.30339 - diff: 20.85mlTrain batch 21/32 - 239.2ms/batch - loss: 1.32303 - diff: 21.17mlTrain batch 22/32 - 252.3ms/batch - loss: 1.30898 - diff: 20.94mlTrain batch 23/32 - 239.3ms/batch - loss: 1.33121 - diff: 21.30mlTrain batch 24/32 - 236.2ms/batch - loss: 1.31992 - diff: 21.12mlTrain batch 25/32 - 235.8ms/batch - loss: 1.31607 - diff: 21.06mlTrain batch 26/32 - 238.2ms/batch - loss: 1.33775 - diff: 21.40mlTrain batch 27/32 - 238.4ms/batch - loss: 1.32906 - diff: 21.27mlTrain batch 28/32 - 236.8ms/batch - loss: 1.31823 - diff: 21.09mlTrain batch 29/32 - 235.8ms/batch - loss: 1.29953 - diff: 20.79mlTrain batch 30/32 - 236.7ms/batch - loss: 1.30719 - diff: 20.92mlTrain batch 31/32 - 236.0ms/batch - loss: 1.29179 - diff: 20.67mlTrain batch 32/32 - 77.7ms/batch - loss: 1.31091 - diff: 20.62mlTrain batch 32/32 - 17.7s 77.7ms/batch - loss: 1.31091 - diff: 20.62ml
Test 1.4s: val_loss: 1.40201 - diff: 21.35ml

Epoch 109: current best loss = 1.37943, at epoch 78
Train batch 1/32 - 235.8ms/batch - loss: 1.09671 - diff: 17.55mlTrain batch 2/32 - 235.1ms/batch - loss: 1.23474 - diff: 19.76mlTrain batch 3/32 - 235.9ms/batch - loss: 1.16457 - diff: 18.63mlTrain batch 4/32 - 236.2ms/batch - loss: 1.10878 - diff: 17.74mlTrain batch 5/32 - 235.8ms/batch - loss: 1.20036 - diff: 19.21mlTrain batch 6/32 - 236.4ms/batch - loss: 1.18819 - diff: 19.01mlTrain batch 7/32 - 236.1ms/batch - loss: 1.32172 - diff: 21.15mlTrain batch 8/32 - 235.5ms/batch - loss: 1.31032 - diff: 20.97mlTrain batch 9/32 - 235.9ms/batch - loss: 1.31195 - diff: 20.99mlTrain batch 10/32 - 235.3ms/batch - loss: 1.42209 - diff: 22.75mlTrain batch 11/32 - 237.0ms/batch - loss: 1.56338 - diff: 25.01mlTrain batch 12/32 - 236.3ms/batch - loss: 1.54821 - diff: 24.77mlTrain batch 13/32 - 235.8ms/batch - loss: 1.54520 - diff: 24.72mlTrain batch 14/32 - 236.7ms/batch - loss: 1.52136 - diff: 24.34mlTrain batch 15/32 - 236.5ms/batch - loss: 1.48128 - diff: 23.70mlTrain batch 16/32 - 236.4ms/batch - loss: 1.47690 - diff: 23.63mlTrain batch 17/32 - 236.8ms/batch - loss: 1.47055 - diff: 23.53mlTrain batch 18/32 - 236.5ms/batch - loss: 1.49099 - diff: 23.86mlTrain batch 19/32 - 236.6ms/batch - loss: 1.46477 - diff: 23.44mlTrain batch 20/32 - 236.2ms/batch - loss: 1.44889 - diff: 23.18mlTrain batch 21/32 - 236.4ms/batch - loss: 1.43990 - diff: 23.04mlTrain batch 22/32 - 235.6ms/batch - loss: 1.45232 - diff: 23.24mlTrain batch 23/32 - 236.0ms/batch - loss: 1.48195 - diff: 23.71mlTrain batch 24/32 - 251.6ms/batch - loss: 1.48445 - diff: 23.75mlTrain batch 25/32 - 235.4ms/batch - loss: 1.47415 - diff: 23.59mlTrain batch 26/32 - 249.6ms/batch - loss: 1.45711 - diff: 23.31mlTrain batch 27/32 - 235.6ms/batch - loss: 1.46628 - diff: 23.46mlTrain batch 28/32 - 237.0ms/batch - loss: 1.45812 - diff: 23.33mlTrain batch 29/32 - 236.7ms/batch - loss: 1.43849 - diff: 23.02mlTrain batch 30/32 - 235.7ms/batch - loss: 1.43656 - diff: 22.98mlTrain batch 31/32 - 235.9ms/batch - loss: 1.44021 - diff: 23.04mlTrain batch 32/32 - 77.2ms/batch - loss: 1.47930 - diff: 23.06mlTrain batch 32/32 - 16.3s 77.2ms/batch - loss: 1.47930 - diff: 23.06ml
Test 1.4s: val_loss: 1.51471 - diff: 23.53ml

Epoch 110: current best loss = 1.37943, at epoch 78
Train batch 1/32 - 235.4ms/batch - loss: 1.49027 - diff: 23.84mlTrain batch 2/32 - 236.5ms/batch - loss: 1.36790 - diff: 21.89mlTrain batch 3/32 - 235.5ms/batch - loss: 1.24091 - diff: 19.85mlTrain batch 4/32 - 235.7ms/batch - loss: 1.26191 - diff: 20.19mlTrain batch 5/32 - 235.9ms/batch - loss: 1.20664 - diff: 19.31mlTrain batch 6/32 - 236.5ms/batch - loss: 1.19451 - diff: 19.11mlTrain batch 7/32 - 236.8ms/batch - loss: 1.15533 - diff: 18.49mlTrain batch 8/32 - 235.6ms/batch - loss: 1.14087 - diff: 18.25mlTrain batch 9/32 - 236.1ms/batch - loss: 1.13889 - diff: 18.22mlTrain batch 10/32 - 236.8ms/batch - loss: 1.18040 - diff: 18.89mlTrain batch 11/32 - 235.3ms/batch - loss: 1.21310 - diff: 19.41mlTrain batch 12/32 - 236.2ms/batch - loss: 1.23764 - diff: 19.80mlTrain batch 13/32 - 236.3ms/batch - loss: 1.32814 - diff: 21.25mlTrain batch 14/32 - 236.5ms/batch - loss: 1.33826 - diff: 21.41mlTrain batch 15/32 - 237.0ms/batch - loss: 1.31793 - diff: 21.09mlTrain batch 16/32 - 236.2ms/batch - loss: 1.30248 - diff: 20.84mlTrain batch 17/32 - 236.1ms/batch - loss: 1.29558 - diff: 20.73mlTrain batch 18/32 - 236.5ms/batch - loss: 1.28698 - diff: 20.59mlTrain batch 19/32 - 236.6ms/batch - loss: 1.28493 - diff: 20.56mlTrain batch 20/32 - 236.3ms/batch - loss: 1.28182 - diff: 20.51mlTrain batch 21/32 - 236.8ms/batch - loss: 1.31886 - diff: 21.10mlTrain batch 22/32 - 236.5ms/batch - loss: 1.31030 - diff: 20.96mlTrain batch 23/32 - 236.2ms/batch - loss: 1.32262 - diff: 21.16mlTrain batch 24/32 - 236.6ms/batch - loss: 1.31639 - diff: 21.06mlTrain batch 25/32 - 236.5ms/batch - loss: 1.29184 - diff: 20.67mlTrain batch 26/32 - 235.9ms/batch - loss: 1.29575 - diff: 20.73mlTrain batch 27/32 - 236.6ms/batch - loss: 1.29189 - diff: 20.67mlTrain batch 28/32 - 236.2ms/batch - loss: 1.30274 - diff: 20.84mlTrain batch 29/32 - 236.0ms/batch - loss: 1.31484 - diff: 21.04mlTrain batch 30/32 - 236.5ms/batch - loss: 1.30450 - diff: 20.87mlTrain batch 31/32 - 235.8ms/batch - loss: 1.29212 - diff: 20.67mlTrain batch 32/32 - 82.5ms/batch - loss: 1.33377 - diff: 20.72mlTrain batch 32/32 - 16.9s 82.5ms/batch - loss: 1.33377 - diff: 20.72ml
Test 1.4s: val_loss: 1.43741 - diff: 21.70ml

Epoch 111: current best loss = 1.37943, at epoch 78
Train batch 1/32 - 235.9ms/batch - loss: 1.53298 - diff: 24.53mlTrain batch 2/32 - 235.7ms/batch - loss: 1.33089 - diff: 21.29mlTrain batch 3/32 - 235.6ms/batch - loss: 1.27163 - diff: 20.35mlTrain batch 4/32 - 236.4ms/batch - loss: 1.19231 - diff: 19.08mlTrain batch 5/32 - 235.7ms/batch - loss: 1.30456 - diff: 20.87mlTrain batch 6/32 - 235.6ms/batch - loss: 1.26494 - diff: 20.24mlTrain batch 7/32 - 235.3ms/batch - loss: 1.23086 - diff: 19.69mlTrain batch 8/32 - 236.5ms/batch - loss: 1.17816 - diff: 18.85mlTrain batch 9/32 - 235.7ms/batch - loss: 1.15645 - diff: 18.50mlTrain batch 10/32 - 236.6ms/batch - loss: 1.15482 - diff: 18.48mlTrain batch 11/32 - 236.4ms/batch - loss: 1.23014 - diff: 19.68mlTrain batch 12/32 - 236.3ms/batch - loss: 1.21370 - diff: 19.42mlTrain batch 13/32 - 236.0ms/batch - loss: 1.19087 - diff: 19.05mlTrain batch 14/32 - 236.5ms/batch - loss: 1.29687 - diff: 20.75mlTrain batch 15/32 - 239.8ms/batch - loss: 1.30632 - diff: 20.90mlTrain batch 16/32 - 236.7ms/batch - loss: 1.31309 - diff: 21.01mlTrain batch 17/32 - 235.9ms/batch - loss: 1.31393 - diff: 21.02mlTrain batch 18/32 - 236.8ms/batch - loss: 1.34052 - diff: 21.45mlTrain batch 19/32 - 238.9ms/batch - loss: 1.30787 - diff: 20.93mlTrain batch 20/32 - 236.3ms/batch - loss: 1.29028 - diff: 20.64mlTrain batch 21/32 - 236.4ms/batch - loss: 1.29673 - diff: 20.75mlTrain batch 22/32 - 236.8ms/batch - loss: 1.26856 - diff: 20.30mlTrain batch 23/32 - 236.6ms/batch - loss: 1.27162 - diff: 20.35mlTrain batch 24/32 - 242.3ms/batch - loss: 1.29408 - diff: 20.71mlTrain batch 25/32 - 236.8ms/batch - loss: 1.28354 - diff: 20.54mlTrain batch 26/32 - 235.8ms/batch - loss: 1.28672 - diff: 20.59mlTrain batch 27/32 - 235.9ms/batch - loss: 1.28060 - diff: 20.49mlTrain batch 28/32 - 236.3ms/batch - loss: 1.28299 - diff: 20.53mlTrain batch 29/32 - 236.7ms/batch - loss: 1.28754 - diff: 20.60mlTrain batch 30/32 - 236.9ms/batch - loss: 1.29412 - diff: 20.71mlTrain batch 31/32 - 236.5ms/batch - loss: 1.28591 - diff: 20.57mlTrain batch 32/32 - 76.7ms/batch - loss: 1.32341 - diff: 20.60mlTrain batch 32/32 - 16.6s 76.7ms/batch - loss: 1.32341 - diff: 20.60ml
Test 1.5s: val_loss: 1.32748 - diff: 20.47ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_WideResNet50_0_Adam-0.001_MAE_DA3_best

Epoch 112: current best loss = 1.32748, at epoch 111
Train batch 1/32 - 256.5ms/batch - loss: 2.18292 - diff: 34.93mlTrain batch 2/32 - 237.4ms/batch - loss: 1.68840 - diff: 27.01mlTrain batch 3/32 - 235.5ms/batch - loss: 1.56531 - diff: 25.04mlTrain batch 4/32 - 235.8ms/batch - loss: 1.63329 - diff: 26.13mlTrain batch 5/32 - 235.9ms/batch - loss: 1.62538 - diff: 26.01mlTrain batch 6/32 - 236.5ms/batch - loss: 1.54260 - diff: 24.68mlTrain batch 7/32 - 235.9ms/batch - loss: 1.44573 - diff: 23.13mlTrain batch 8/32 - 237.0ms/batch - loss: 1.41593 - diff: 22.65mlTrain batch 9/32 - 235.8ms/batch - loss: 1.45441 - diff: 23.27mlTrain batch 10/32 - 236.6ms/batch - loss: 1.37314 - diff: 21.97mlTrain batch 11/32 - 235.8ms/batch - loss: 1.38385 - diff: 22.14mlTrain batch 12/32 - 235.5ms/batch - loss: 1.36610 - diff: 21.86mlTrain batch 13/32 - 235.7ms/batch - loss: 1.33369 - diff: 21.34mlTrain batch 14/32 - 236.0ms/batch - loss: 1.31069 - diff: 20.97mlTrain batch 15/32 - 235.7ms/batch - loss: 1.31108 - diff: 20.98mlTrain batch 16/32 - 236.2ms/batch - loss: 1.32338 - diff: 21.17mlTrain batch 17/32 - 235.8ms/batch - loss: 1.32063 - diff: 21.13mlTrain batch 18/32 - 236.3ms/batch - loss: 1.39864 - diff: 22.38mlTrain batch 19/32 - 235.6ms/batch - loss: 1.37924 - diff: 22.07mlTrain batch 20/32 - 244.3ms/batch - loss: 1.36290 - diff: 21.81mlTrain batch 21/32 - 235.7ms/batch - loss: 1.36065 - diff: 21.77mlTrain batch 22/32 - 236.2ms/batch - loss: 1.34411 - diff: 21.51mlTrain batch 23/32 - 240.3ms/batch - loss: 1.34615 - diff: 21.54mlTrain batch 24/32 - 239.9ms/batch - loss: 1.32279 - diff: 21.16mlTrain batch 25/32 - 236.0ms/batch - loss: 1.33628 - diff: 21.38mlTrain batch 26/32 - 235.7ms/batch - loss: 1.34403 - diff: 21.50mlTrain batch 27/32 - 235.7ms/batch - loss: 1.34236 - diff: 21.48mlTrain batch 28/32 - 236.8ms/batch - loss: 1.35713 - diff: 21.71mlTrain batch 29/32 - 235.4ms/batch - loss: 1.34924 - diff: 21.59mlTrain batch 30/32 - 234.8ms/batch - loss: 1.34320 - diff: 21.49mlTrain batch 31/32 - 235.3ms/batch - loss: 1.33051 - diff: 21.29mlTrain batch 32/32 - 89.8ms/batch - loss: 1.35930 - diff: 21.28mlTrain batch 32/32 - 18.2s 89.8ms/batch - loss: 1.35930 - diff: 21.28ml
Test 1.6s: val_loss: 1.59954 - diff: 24.94ml

Epoch 113: current best loss = 1.32748, at epoch 111
Train batch 1/32 - 235.9ms/batch - loss: 0.74175 - diff: 11.87mlTrain batch 2/32 - 243.0ms/batch - loss: 1.11360 - diff: 17.82mlTrain batch 3/32 - 235.5ms/batch - loss: 1.29624 - diff: 20.74mlTrain batch 4/32 - 235.8ms/batch - loss: 1.32320 - diff: 21.17mlTrain batch 5/32 - 235.6ms/batch - loss: 1.28759 - diff: 20.60mlTrain batch 6/32 - 236.0ms/batch - loss: 1.24761 - diff: 19.96mlTrain batch 7/32 - 235.5ms/batch - loss: 1.22953 - diff: 19.67mlTrain batch 8/32 - 236.0ms/batch - loss: 1.23587 - diff: 19.77mlTrain batch 9/32 - 235.6ms/batch - loss: 1.21893 - diff: 19.50mlTrain batch 10/32 - 236.2ms/batch - loss: 1.23336 - diff: 19.73mlTrain batch 11/32 - 235.7ms/batch - loss: 1.28513 - diff: 20.56mlTrain batch 12/32 - 235.8ms/batch - loss: 1.30464 - diff: 20.87mlTrain batch 13/32 - 235.5ms/batch - loss: 1.32982 - diff: 21.28mlTrain batch 14/32 - 242.7ms/batch - loss: 1.28696 - diff: 20.59mlTrain batch 15/32 - 236.0ms/batch - loss: 1.28968 - diff: 20.63mlTrain batch 16/32 - 242.4ms/batch - loss: 1.26759 - diff: 20.28mlTrain batch 17/32 - 235.6ms/batch - loss: 1.33841 - diff: 21.41mlTrain batch 18/32 - 236.3ms/batch - loss: 1.36419 - diff: 21.83mlTrain batch 19/32 - 235.8ms/batch - loss: 1.38341 - diff: 22.13mlTrain batch 20/32 - 235.7ms/batch - loss: 1.42561 - diff: 22.81mlTrain batch 21/32 - 235.9ms/batch - loss: 1.42859 - diff: 22.86mlTrain batch 22/32 - 235.4ms/batch - loss: 1.41512 - diff: 22.64mlTrain batch 23/32 - 247.3ms/batch - loss: 1.40380 - diff: 22.46mlTrain batch 24/32 - 235.2ms/batch - loss: 1.36363 - diff: 21.82mlTrain batch 25/32 - 236.3ms/batch - loss: 1.34768 - diff: 21.56mlTrain batch 26/32 - 235.6ms/batch - loss: 1.34957 - diff: 21.59mlTrain batch 27/32 - 235.9ms/batch - loss: 1.35830 - diff: 21.73mlTrain batch 28/32 - 236.0ms/batch - loss: 1.35970 - diff: 21.76mlTrain batch 29/32 - 235.8ms/batch - loss: 1.35298 - diff: 21.65mlTrain batch 30/32 - 235.6ms/batch - loss: 1.33779 - diff: 21.40mlTrain batch 31/32 - 235.9ms/batch - loss: 1.34130 - diff: 21.46mlTrain batch 32/32 - 77.0ms/batch - loss: 1.35721 - diff: 21.40mlTrain batch 32/32 - 17.4s 77.0ms/batch - loss: 1.35721 - diff: 21.40ml
Test 1.5s: val_loss: 1.43791 - diff: 21.54ml

Epoch 114: current best loss = 1.32748, at epoch 111
Train batch 1/32 - 235.7ms/batch - loss: 1.92880 - diff: 30.86mlTrain batch 2/32 - 235.7ms/batch - loss: 1.49736 - diff: 23.96mlTrain batch 3/32 - 235.9ms/batch - loss: 1.56493 - diff: 25.04mlTrain batch 4/32 - 236.0ms/batch - loss: 1.39282 - diff: 22.29mlTrain batch 5/32 - 236.3ms/batch - loss: 1.38689 - diff: 22.19mlTrain batch 6/32 - 236.3ms/batch - loss: 1.35592 - diff: 21.69mlTrain batch 7/32 - 235.5ms/batch - loss: 1.31396 - diff: 21.02mlTrain batch 8/32 - 235.9ms/batch - loss: 1.28334 - diff: 20.53mlTrain batch 9/32 - 235.6ms/batch - loss: 1.26044 - diff: 20.17mlTrain batch 10/32 - 238.6ms/batch - loss: 1.29075 - diff: 20.65mlTrain batch 11/32 - 235.8ms/batch - loss: 1.27678 - diff: 20.43mlTrain batch 12/32 - 236.1ms/batch - loss: 1.31883 - diff: 21.10mlTrain batch 13/32 - 240.2ms/batch - loss: 1.32758 - diff: 21.24mlTrain batch 14/32 - 236.5ms/batch - loss: 1.30450 - diff: 20.87mlTrain batch 15/32 - 236.3ms/batch - loss: 1.25167 - diff: 20.03mlTrain batch 16/32 - 235.7ms/batch - loss: 1.23000 - diff: 19.68mlTrain batch 17/32 - 236.6ms/batch - loss: 1.24391 - diff: 19.90mlTrain batch 18/32 - 236.9ms/batch - loss: 1.23026 - diff: 19.68mlTrain batch 19/32 - 236.7ms/batch - loss: 1.23936 - diff: 19.83mlTrain batch 20/32 - 239.4ms/batch - loss: 1.24520 - diff: 19.92mlTrain batch 21/32 - 236.0ms/batch - loss: 1.23304 - diff: 19.73mlTrain batch 22/32 - 236.1ms/batch - loss: 1.21519 - diff: 19.44mlTrain batch 23/32 - 236.4ms/batch - loss: 1.20735 - diff: 19.32mlTrain batch 24/32 - 236.3ms/batch - loss: 1.19810 - diff: 19.17mlTrain batch 25/32 - 235.7ms/batch - loss: 1.19753 - diff: 19.16mlTrain batch 26/32 - 236.7ms/batch - loss: 1.18542 - diff: 18.97mlTrain batch 27/32 - 235.3ms/batch - loss: 1.20474 - diff: 19.28mlTrain batch 28/32 - 245.3ms/batch - loss: 1.26671 - diff: 20.27mlTrain batch 29/32 - 236.3ms/batch - loss: 1.29412 - diff: 20.71mlTrain batch 30/32 - 236.0ms/batch - loss: 1.29283 - diff: 20.69mlTrain batch 31/32 - 235.8ms/batch - loss: 1.29692 - diff: 20.75mlTrain batch 32/32 - 84.8ms/batch - loss: 1.31088 - diff: 20.68mlTrain batch 32/32 - 16.1s 84.8ms/batch - loss: 1.31088 - diff: 20.68ml
Test 1.4s: val_loss: 1.74249 - diff: 26.80ml

Epoch 115: current best loss = 1.32748, at epoch 111
Train batch 1/32 - 235.1ms/batch - loss: 1.08052 - diff: 17.29mlTrain batch 2/32 - 236.3ms/batch - loss: 1.46181 - diff: 23.39mlTrain batch 3/32 - 237.9ms/batch - loss: 1.24042 - diff: 19.85mlTrain batch 4/32 - 236.1ms/batch - loss: 1.31331 - diff: 21.01mlTrain batch 5/32 - 235.7ms/batch - loss: 1.42705 - diff: 22.83mlTrain batch 6/32 - 236.0ms/batch - loss: 1.37407 - diff: 21.99mlTrain batch 7/32 - 248.0ms/batch - loss: 1.35979 - diff: 21.76mlTrain batch 8/32 - 235.7ms/batch - loss: 1.31138 - diff: 20.98mlTrain batch 9/32 - 236.0ms/batch - loss: 1.39078 - diff: 22.25mlTrain batch 10/32 - 236.4ms/batch - loss: 1.45760 - diff: 23.32mlTrain batch 11/32 - 253.0ms/batch - loss: 1.45949 - diff: 23.35mlTrain batch 12/32 - 235.6ms/batch - loss: 1.48515 - diff: 23.76mlTrain batch 13/32 - 236.6ms/batch - loss: 1.49198 - diff: 23.87mlTrain batch 14/32 - 235.5ms/batch - loss: 1.44021 - diff: 23.04mlTrain batch 15/32 - 235.1ms/batch - loss: 1.40960 - diff: 22.55mlTrain batch 16/32 - 235.9ms/batch - loss: 1.41081 - diff: 22.57mlTrain batch 17/32 - 236.7ms/batch - loss: 1.38533 - diff: 22.17mlTrain batch 18/32 - 235.9ms/batch - loss: 1.36454 - diff: 21.83mlTrain batch 19/32 - 235.9ms/batch - loss: 1.35925 - diff: 21.75mlTrain batch 20/32 - 236.6ms/batch - loss: 1.35182 - diff: 21.63mlTrain batch 21/32 - 235.6ms/batch - loss: 1.34427 - diff: 21.51mlTrain batch 22/32 - 235.7ms/batch - loss: 1.33300 - diff: 21.33mlTrain batch 23/32 - 235.8ms/batch - loss: 1.33836 - diff: 21.41mlTrain batch 24/32 - 236.1ms/batch - loss: 1.34017 - diff: 21.44mlTrain batch 25/32 - 235.7ms/batch - loss: 1.31554 - diff: 21.05mlTrain batch 26/32 - 236.4ms/batch - loss: 1.33128 - diff: 21.30mlTrain batch 27/32 - 235.9ms/batch - loss: 1.34390 - diff: 21.50mlTrain batch 28/32 - 235.5ms/batch - loss: 1.35835 - diff: 21.73mlTrain batch 29/32 - 238.6ms/batch - loss: 1.35547 - diff: 21.69mlTrain batch 30/32 - 235.8ms/batch - loss: 1.35133 - diff: 21.62mlTrain batch 31/32 - 235.9ms/batch - loss: 1.35321 - diff: 21.65mlTrain batch 32/32 - 81.1ms/batch - loss: 1.44644 - diff: 21.89mlTrain batch 32/32 - 17.5s 81.1ms/batch - loss: 1.44644 - diff: 21.89ml
Test 1.6s: val_loss: 1.37212 - diff: 21.16ml

Epoch 116: current best loss = 1.32748, at epoch 111
Train batch 1/32 - 235.5ms/batch - loss: 1.70676 - diff: 27.31mlTrain batch 2/32 - 236.5ms/batch - loss: 1.43290 - diff: 22.93mlTrain batch 3/32 - 235.8ms/batch - loss: 1.23978 - diff: 19.84mlTrain batch 4/32 - 236.8ms/batch - loss: 1.21402 - diff: 19.42mlTrain batch 5/32 - 235.9ms/batch - loss: 1.15984 - diff: 18.56mlTrain batch 6/32 - 236.2ms/batch - loss: 1.16684 - diff: 18.67mlTrain batch 7/32 - 235.7ms/batch - loss: 1.17361 - diff: 18.78mlTrain batch 8/32 - 235.3ms/batch - loss: 1.20884 - diff: 19.34mlTrain batch 9/32 - 235.9ms/batch - loss: 1.21930 - diff: 19.51mlTrain batch 10/32 - 236.5ms/batch - loss: 1.17784 - diff: 18.85mlTrain batch 11/32 - 235.5ms/batch - loss: 1.22673 - diff: 19.63mlTrain batch 12/32 - 238.9ms/batch - loss: 1.22690 - diff: 19.63mlTrain batch 13/32 - 235.6ms/batch - loss: 1.26917 - diff: 20.31mlTrain batch 14/32 - 236.1ms/batch - loss: 1.27094 - diff: 20.34mlTrain batch 15/32 - 235.8ms/batch - loss: 1.26705 - diff: 20.27mlTrain batch 16/32 - 236.1ms/batch - loss: 1.25007 - diff: 20.00mlTrain batch 17/32 - 235.9ms/batch - loss: 1.24701 - diff: 19.95mlTrain batch 18/32 - 235.9ms/batch - loss: 1.24461 - diff: 19.91mlTrain batch 19/32 - 236.1ms/batch - loss: 1.25229 - diff: 20.04mlTrain batch 20/32 - 236.6ms/batch - loss: 1.25943 - diff: 20.15mlTrain batch 21/32 - 236.3ms/batch - loss: 1.24978 - diff: 20.00mlTrain batch 22/32 - 236.7ms/batch - loss: 1.24906 - diff: 19.99mlTrain batch 23/32 - 246.7ms/batch - loss: 1.25657 - diff: 20.11mlTrain batch 24/32 - 236.6ms/batch - loss: 1.24918 - diff: 19.99mlTrain batch 25/32 - 235.8ms/batch - loss: 1.25213 - diff: 20.03mlTrain batch 26/32 - 236.8ms/batch - loss: 1.26314 - diff: 20.21mlTrain batch 27/32 - 235.5ms/batch - loss: 1.25715 - diff: 20.11mlTrain batch 28/32 - 236.1ms/batch - loss: 1.25067 - diff: 20.01mlTrain batch 29/32 - 235.7ms/batch - loss: 1.25030 - diff: 20.00mlTrain batch 30/32 - 236.8ms/batch - loss: 1.25336 - diff: 20.05mlTrain batch 31/32 - 235.3ms/batch - loss: 1.25880 - diff: 20.14mlTrain batch 32/32 - 83.4ms/batch - loss: 1.29976 - diff: 20.18mlTrain batch 32/32 - 18.3s 83.4ms/batch - loss: 1.29976 - diff: 20.18ml
Test 1.5s: val_loss: 1.52373 - diff: 23.29ml

Epoch 117: current best loss = 1.32748, at epoch 111
Train batch 1/32 - 237.1ms/batch - loss: 1.38528 - diff: 22.16mlTrain batch 2/32 - 236.1ms/batch - loss: 1.15752 - diff: 18.52mlTrain batch 3/32 - 235.9ms/batch - loss: 1.49227 - diff: 23.88mlTrain batch 4/32 - 236.1ms/batch - loss: 1.40276 - diff: 22.44mlTrain batch 5/32 - 236.2ms/batch - loss: 1.28014 - diff: 20.48mlTrain batch 6/32 - 236.4ms/batch - loss: 1.19071 - diff: 19.05mlTrain batch 7/32 - 238.2ms/batch - loss: 1.23318 - diff: 19.73mlTrain batch 8/32 - 236.0ms/batch - loss: 1.21825 - diff: 19.49mlTrain batch 9/32 - 235.5ms/batch - loss: 1.21674 - diff: 19.47mlTrain batch 10/32 - 237.0ms/batch - loss: 1.16512 - diff: 18.64mlTrain batch 11/32 - 235.7ms/batch - loss: 1.11509 - diff: 17.84mlTrain batch 12/32 - 237.1ms/batch - loss: 1.17383 - diff: 18.78mlTrain batch 13/32 - 235.9ms/batch - loss: 1.16874 - diff: 18.70mlTrain batch 14/32 - 235.4ms/batch - loss: 1.28093 - diff: 20.49mlTrain batch 15/32 - 234.8ms/batch - loss: 1.26501 - diff: 20.24mlTrain batch 16/32 - 237.1ms/batch - loss: 1.24156 - diff: 19.86mlTrain batch 17/32 - 236.0ms/batch - loss: 1.26825 - diff: 20.29mlTrain batch 18/32 - 234.9ms/batch - loss: 1.27647 - diff: 20.42mlTrain batch 19/32 - 235.8ms/batch - loss: 1.24072 - diff: 19.85mlTrain batch 20/32 - 236.1ms/batch - loss: 1.20949 - diff: 19.35mlTrain batch 21/32 - 235.7ms/batch - loss: 1.22769 - diff: 19.64mlTrain batch 22/32 - 236.2ms/batch - loss: 1.22624 - diff: 19.62mlTrain batch 23/32 - 235.7ms/batch - loss: 1.24358 - diff: 19.90mlTrain batch 24/32 - 237.0ms/batch - loss: 1.25125 - diff: 20.02mlTrain batch 25/32 - 235.6ms/batch - loss: 1.24685 - diff: 19.95mlTrain batch 26/32 - 235.9ms/batch - loss: 1.25353 - diff: 20.06mlTrain batch 27/32 - 235.9ms/batch - loss: 1.25349 - diff: 20.06mlTrain batch 28/32 - 235.3ms/batch - loss: 1.25871 - diff: 20.14mlTrain batch 29/32 - 242.5ms/batch - loss: 1.25948 - diff: 20.15mlTrain batch 30/32 - 236.0ms/batch - loss: 1.25709 - diff: 20.11mlTrain batch 31/32 - 235.8ms/batch - loss: 1.26156 - diff: 20.18mlTrain batch 32/32 - 82.6ms/batch - loss: 1.31852 - diff: 20.29mlTrain batch 32/32 - 16.7s 82.6ms/batch - loss: 1.31852 - diff: 20.29ml
Test 1.5s: val_loss: 1.48436 - diff: 22.53ml

Epoch 118: current best loss = 1.32748, at epoch 111
Train batch 1/32 - 238.3ms/batch - loss: 1.07821 - diff: 17.25mlTrain batch 2/32 - 235.6ms/batch - loss: 1.20571 - diff: 19.29mlTrain batch 3/32 - 235.7ms/batch - loss: 1.54143 - diff: 24.66mlTrain batch 4/32 - 237.8ms/batch - loss: 1.54945 - diff: 24.79mlTrain batch 5/32 - 236.0ms/batch - loss: 1.45457 - diff: 23.27mlTrain batch 6/32 - 236.5ms/batch - loss: 1.45123 - diff: 23.22mlTrain batch 7/32 - 235.9ms/batch - loss: 1.42219 - diff: 22.76mlTrain batch 8/32 - 251.1ms/batch - loss: 1.39728 - diff: 22.36mlTrain batch 9/32 - 236.5ms/batch - loss: 1.44471 - diff: 23.12mlTrain batch 10/32 - 239.9ms/batch - loss: 1.43640 - diff: 22.98mlTrain batch 11/32 - 236.4ms/batch - loss: 1.50211 - diff: 24.03mlTrain batch 12/32 - 236.0ms/batch - loss: 1.48745 - diff: 23.80mlTrain batch 13/32 - 236.4ms/batch - loss: 1.48917 - diff: 23.83mlTrain batch 14/32 - 236.4ms/batch - loss: 1.48240 - diff: 23.72mlTrain batch 15/32 - 236.6ms/batch - loss: 1.44001 - diff: 23.04mlTrain batch 16/32 - 236.0ms/batch - loss: 1.42072 - diff: 22.73mlTrain batch 17/32 - 236.1ms/batch - loss: 1.44014 - diff: 23.04mlTrain batch 18/32 - 236.7ms/batch - loss: 1.43236 - diff: 22.92mlTrain batch 19/32 - 241.9ms/batch - loss: 1.43678 - diff: 22.99mlTrain batch 20/32 - 235.9ms/batch - loss: 1.44435 - diff: 23.11mlTrain batch 21/32 - 235.6ms/batch - loss: 1.43590 - diff: 22.97mlTrain batch 22/32 - 236.4ms/batch - loss: 1.41249 - diff: 22.60mlTrain batch 23/32 - 235.4ms/batch - loss: 1.42634 - diff: 22.82mlTrain batch 24/32 - 235.9ms/batch - loss: 1.40837 - diff: 22.53mlTrain batch 25/32 - 247.3ms/batch - loss: 1.39804 - diff: 22.37mlTrain batch 26/32 - 235.5ms/batch - loss: 1.39304 - diff: 22.29mlTrain batch 27/32 - 236.1ms/batch - loss: 1.38110 - diff: 22.10mlTrain batch 28/32 - 236.1ms/batch - loss: 1.38282 - diff: 22.13mlTrain batch 29/32 - 235.8ms/batch - loss: 1.37374 - diff: 21.98mlTrain batch 30/32 - 235.8ms/batch - loss: 1.38199 - diff: 22.11mlTrain batch 31/32 - 236.0ms/batch - loss: 1.37379 - diff: 21.98mlTrain batch 32/32 - 83.4ms/batch - loss: 1.37839 - diff: 21.87mlTrain batch 32/32 - 17.1s 83.4ms/batch - loss: 1.37839 - diff: 21.87ml
Test 1.5s: val_loss: 1.55163 - diff: 23.97ml

Epoch 119: current best loss = 1.32748, at epoch 111
Train batch 1/32 - 235.7ms/batch - loss: 0.73544 - diff: 11.77mlTrain batch 2/32 - 236.0ms/batch - loss: 0.96177 - diff: 15.39mlTrain batch 3/32 - 235.6ms/batch - loss: 0.97641 - diff: 15.62mlTrain batch 4/32 - 236.8ms/batch - loss: 1.02123 - diff: 16.34mlTrain batch 5/32 - 236.1ms/batch - loss: 1.07998 - diff: 17.28mlTrain batch 6/32 - 236.5ms/batch - loss: 1.11063 - diff: 17.77mlTrain batch 7/32 - 236.2ms/batch - loss: 1.08627 - diff: 17.38mlTrain batch 8/32 - 236.2ms/batch - loss: 1.07759 - diff: 17.24mlTrain batch 9/32 - 235.6ms/batch - loss: 1.07999 - diff: 17.28mlTrain batch 10/32 - 235.5ms/batch - loss: 1.09480 - diff: 17.52mlTrain batch 11/32 - 235.7ms/batch - loss: 1.10606 - diff: 17.70mlTrain batch 12/32 - 236.0ms/batch - loss: 1.10513 - diff: 17.68mlTrain batch 13/32 - 236.2ms/batch - loss: 1.19765 - diff: 19.16mlTrain batch 14/32 - 235.8ms/batch - loss: 1.19343 - diff: 19.09mlTrain batch 15/32 - 236.5ms/batch - loss: 1.18540 - diff: 18.97mlTrain batch 16/32 - 236.0ms/batch - loss: 1.15971 - diff: 18.56mlTrain batch 17/32 - 236.3ms/batch - loss: 1.21268 - diff: 19.40mlTrain batch 18/32 - 236.1ms/batch - loss: 1.20561 - diff: 19.29mlTrain batch 19/32 - 235.6ms/batch - loss: 1.21420 - diff: 19.43mlTrain batch 20/32 - 237.1ms/batch - loss: 1.21701 - diff: 19.47mlTrain batch 21/32 - 236.1ms/batch - loss: 1.20202 - diff: 19.23mlTrain batch 22/32 - 236.3ms/batch - loss: 1.20559 - diff: 19.29mlTrain batch 23/32 - 235.2ms/batch - loss: 1.21564 - diff: 19.45mlTrain batch 24/32 - 236.2ms/batch - loss: 1.24260 - diff: 19.88mlTrain batch 25/32 - 236.1ms/batch - loss: 1.24525 - diff: 19.92mlTrain batch 26/32 - 236.1ms/batch - loss: 1.25656 - diff: 20.10mlTrain batch 27/32 - 236.0ms/batch - loss: 1.24527 - diff: 19.92mlTrain batch 28/32 - 236.7ms/batch - loss: 1.24701 - diff: 19.95mlTrain batch 29/32 - 235.9ms/batch - loss: 1.26562 - diff: 20.25mlTrain batch 30/32 - 235.9ms/batch - loss: 1.26725 - diff: 20.28mlTrain batch 31/32 - 235.8ms/batch - loss: 1.25781 - diff: 20.12mlTrain batch 32/32 - 76.5ms/batch - loss: 1.32640 - diff: 20.28mlTrain batch 32/32 - 17.0s 76.5ms/batch - loss: 1.32640 - diff: 20.28ml
Test 1.5s: val_loss: 1.44497 - diff: 22.31ml

Epoch 120: current best loss = 1.32748, at epoch 111
Train batch 1/32 - 235.2ms/batch - loss: 1.60742 - diff: 25.72mlTrain batch 2/32 - 239.0ms/batch - loss: 1.34774 - diff: 21.56mlTrain batch 3/32 - 236.8ms/batch - loss: 1.26896 - diff: 20.30mlTrain batch 4/32 - 235.6ms/batch - loss: 1.24243 - diff: 19.88mlTrain batch 5/32 - 235.9ms/batch - loss: 1.34080 - diff: 21.45mlTrain batch 6/32 - 236.0ms/batch - loss: 1.26610 - diff: 20.26mlTrain batch 7/32 - 235.3ms/batch - loss: 1.28683 - diff: 20.59mlTrain batch 8/32 - 236.3ms/batch - loss: 1.23271 - diff: 19.72mlTrain batch 9/32 - 236.1ms/batch - loss: 1.28179 - diff: 20.51mlTrain batch 10/32 - 236.5ms/batch - loss: 1.32160 - diff: 21.15mlTrain batch 11/32 - 235.5ms/batch - loss: 1.34799 - diff: 21.57mlTrain batch 12/32 - 235.8ms/batch - loss: 1.33251 - diff: 21.32mlTrain batch 13/32 - 236.2ms/batch - loss: 1.29666 - diff: 20.75mlTrain batch 14/32 - 236.1ms/batch - loss: 1.30139 - diff: 20.82mlTrain batch 15/32 - 235.7ms/batch - loss: 1.27435 - diff: 20.39mlTrain batch 16/32 - 236.0ms/batch - loss: 1.26204 - diff: 20.19mlTrain batch 17/32 - 236.4ms/batch - loss: 1.26854 - diff: 20.30mlTrain batch 18/32 - 236.1ms/batch - loss: 1.26731 - diff: 20.28mlTrain batch 19/32 - 236.1ms/batch - loss: 1.25530 - diff: 20.08mlTrain batch 20/32 - 235.6ms/batch - loss: 1.27808 - diff: 20.45mlTrain batch 21/32 - 236.0ms/batch - loss: 1.29049 - diff: 20.65mlTrain batch 22/32 - 236.8ms/batch - loss: 1.29746 - diff: 20.76mlTrain batch 23/32 - 235.9ms/batch - loss: 1.30564 - diff: 20.89mlTrain batch 24/32 - 236.5ms/batch - loss: 1.32050 - diff: 21.13mlTrain batch 25/32 - 236.1ms/batch - loss: 1.33323 - diff: 21.33mlTrain batch 26/32 - 236.5ms/batch - loss: 1.31931 - diff: 21.11mlTrain batch 27/32 - 235.7ms/batch - loss: 1.37051 - diff: 21.93mlTrain batch 28/32 - 236.1ms/batch - loss: 1.33974 - diff: 21.44mlTrain batch 29/32 - 236.2ms/batch - loss: 1.32940 - diff: 21.27mlTrain batch 30/32 - 236.4ms/batch - loss: 1.30856 - diff: 20.94mlTrain batch 31/32 - 236.2ms/batch - loss: 1.31261 - diff: 21.00mlTrain batch 32/32 - 76.4ms/batch - loss: 1.37264 - diff: 21.12mlTrain batch 32/32 - 16.9s 76.4ms/batch - loss: 1.37264 - diff: 21.12ml
Test 1.4s: val_loss: 1.44226 - diff: 22.13ml

Epoch 121: current best loss = 1.32748, at epoch 111
Train batch 1/32 - 235.7ms/batch - loss: 1.32884 - diff: 21.26mlTrain batch 2/32 - 236.2ms/batch - loss: 1.25008 - diff: 20.00mlTrain batch 3/32 - 235.8ms/batch - loss: 1.19049 - diff: 19.05mlTrain batch 4/32 - 237.0ms/batch - loss: 1.39176 - diff: 22.27mlTrain batch 5/32 - 236.5ms/batch - loss: 1.25268 - diff: 20.04mlTrain batch 6/32 - 235.8ms/batch - loss: 1.21350 - diff: 19.42mlTrain batch 7/32 - 235.7ms/batch - loss: 1.22797 - diff: 19.65mlTrain batch 8/32 - 235.8ms/batch - loss: 1.22623 - diff: 19.62mlTrain batch 9/32 - 236.1ms/batch - loss: 1.21524 - diff: 19.44mlTrain batch 10/32 - 236.0ms/batch - loss: 1.18379 - diff: 18.94mlTrain batch 11/32 - 235.8ms/batch - loss: 1.20144 - diff: 19.22mlTrain batch 12/32 - 236.0ms/batch - loss: 1.20911 - diff: 19.35mlTrain batch 13/32 - 240.2ms/batch - loss: 1.17661 - diff: 18.83mlTrain batch 14/32 - 236.3ms/batch - loss: 1.17750 - diff: 18.84mlTrain batch 15/32 - 235.6ms/batch - loss: 1.22729 - diff: 19.64mlTrain batch 16/32 - 236.8ms/batch - loss: 1.23061 - diff: 19.69mlTrain batch 17/32 - 235.8ms/batch - loss: 1.22217 - diff: 19.55mlTrain batch 18/32 - 236.4ms/batch - loss: 1.22888 - diff: 19.66mlTrain batch 19/32 - 235.8ms/batch - loss: 1.21818 - diff: 19.49mlTrain batch 20/32 - 236.4ms/batch - loss: 1.22824 - diff: 19.65mlTrain batch 21/32 - 236.2ms/batch - loss: 1.24515 - diff: 19.92mlTrain batch 22/32 - 236.5ms/batch - loss: 1.26230 - diff: 20.20mlTrain batch 23/32 - 236.0ms/batch - loss: 1.25826 - diff: 20.13mlTrain batch 24/32 - 235.3ms/batch - loss: 1.24506 - diff: 19.92mlTrain batch 25/32 - 235.9ms/batch - loss: 1.24061 - diff: 19.85mlTrain batch 26/32 - 236.0ms/batch - loss: 1.24786 - diff: 19.97mlTrain batch 27/32 - 236.1ms/batch - loss: 1.25155 - diff: 20.02mlTrain batch 28/32 - 236.0ms/batch - loss: 1.24059 - diff: 19.85mlTrain batch 29/32 - 235.9ms/batch - loss: 1.23268 - diff: 19.72mlTrain batch 30/32 - 235.6ms/batch - loss: 1.24069 - diff: 19.85mlTrain batch 31/32 - 236.0ms/batch - loss: 1.22558 - diff: 19.61mlTrain batch 32/32 - 83.0ms/batch - loss: 1.26247 - diff: 19.64mlTrain batch 32/32 - 17.0s 83.0ms/batch - loss: 1.26247 - diff: 19.64ml
Test 1.5s: val_loss: 1.44130 - diff: 22.25ml

Epoch 122: current best loss = 1.32748, at epoch 111
Train batch 1/32 - 236.1ms/batch - loss: 1.91802 - diff: 30.69mlTrain batch 2/32 - 236.6ms/batch - loss: 1.41849 - diff: 22.70mlTrain batch 3/32 - 235.7ms/batch - loss: 1.46736 - diff: 23.48mlTrain batch 4/32 - 236.4ms/batch - loss: 1.40328 - diff: 22.45mlTrain batch 5/32 - 236.1ms/batch - loss: 1.57078 - diff: 25.13mlTrain batch 6/32 - 244.4ms/batch - loss: 1.55451 - diff: 24.87mlTrain batch 7/32 - 236.1ms/batch - loss: 1.61605 - diff: 25.86mlTrain batch 8/32 - 235.9ms/batch - loss: 1.55164 - diff: 24.83mlTrain batch 9/32 - 236.1ms/batch - loss: 1.56931 - diff: 25.11mlTrain batch 10/32 - 236.7ms/batch - loss: 1.52022 - diff: 24.32mlTrain batch 11/32 - 235.8ms/batch - loss: 1.51464 - diff: 24.23mlTrain batch 12/32 - 236.4ms/batch - loss: 1.51607 - diff: 24.26mlTrain batch 13/32 - 236.0ms/batch - loss: 1.52755 - diff: 24.44mlTrain batch 14/32 - 236.3ms/batch - loss: 1.52253 - diff: 24.36mlTrain batch 15/32 - 235.8ms/batch - loss: 1.49616 - diff: 23.94mlTrain batch 16/32 - 235.4ms/batch - loss: 1.49925 - diff: 23.99mlTrain batch 17/32 - 236.1ms/batch - loss: 1.48759 - diff: 23.80mlTrain batch 18/32 - 236.1ms/batch - loss: 1.47708 - diff: 23.63mlTrain batch 19/32 - 236.0ms/batch - loss: 1.48580 - diff: 23.77mlTrain batch 20/32 - 235.7ms/batch - loss: 1.46190 - diff: 23.39mlTrain batch 21/32 - 236.2ms/batch - loss: 1.45175 - diff: 23.23mlTrain batch 22/32 - 236.2ms/batch - loss: 1.45405 - diff: 23.26mlTrain batch 23/32 - 235.7ms/batch - loss: 1.46540 - diff: 23.45mlTrain batch 24/32 - 237.9ms/batch - loss: 1.44350 - diff: 23.10mlTrain batch 25/32 - 236.3ms/batch - loss: 1.44713 - diff: 23.15mlTrain batch 26/32 - 236.2ms/batch - loss: 1.43559 - diff: 22.97mlTrain batch 27/32 - 236.0ms/batch - loss: 1.42854 - diff: 22.86mlTrain batch 28/32 - 235.5ms/batch - loss: 1.44026 - diff: 23.04mlTrain batch 29/32 - 236.4ms/batch - loss: 1.46854 - diff: 23.50mlTrain batch 30/32 - 236.0ms/batch - loss: 1.46023 - diff: 23.36mlTrain batch 31/32 - 235.6ms/batch - loss: 1.44474 - diff: 23.12mlTrain batch 32/32 - 76.4ms/batch - loss: 1.48888 - diff: 23.15mlTrain batch 32/32 - 16.6s 76.4ms/batch - loss: 1.48888 - diff: 23.15ml
Test 1.4s: val_loss: 1.64230 - diff: 25.58ml
Epoch   123: reducing learning rate of group 0 to 1.2500e-04.

Epoch 123: current best loss = 1.32748, at epoch 111
Train batch 1/32 - 235.9ms/batch - loss: 1.01675 - diff: 16.27mlTrain batch 2/32 - 244.6ms/batch - loss: 0.96747 - diff: 15.48mlTrain batch 3/32 - 236.1ms/batch - loss: 1.02374 - diff: 16.38mlTrain batch 4/32 - 236.7ms/batch - loss: 1.13087 - diff: 18.09mlTrain batch 5/32 - 236.5ms/batch - loss: 1.09339 - diff: 17.49mlTrain batch 6/32 - 236.7ms/batch - loss: 1.09942 - diff: 17.59mlTrain batch 7/32 - 236.4ms/batch - loss: 1.11807 - diff: 17.89mlTrain batch 8/32 - 236.5ms/batch - loss: 1.11482 - diff: 17.84mlTrain batch 9/32 - 236.9ms/batch - loss: 1.11062 - diff: 17.77mlTrain batch 10/32 - 236.1ms/batch - loss: 1.15758 - diff: 18.52mlTrain batch 11/32 - 236.4ms/batch - loss: 1.19633 - diff: 19.14mlTrain batch 12/32 - 235.8ms/batch - loss: 1.20285 - diff: 19.25mlTrain batch 13/32 - 236.5ms/batch - loss: 1.20498 - diff: 19.28mlTrain batch 14/32 - 236.5ms/batch - loss: 1.20002 - diff: 19.20mlTrain batch 15/32 - 236.2ms/batch - loss: 1.31506 - diff: 21.04mlTrain batch 16/32 - 236.9ms/batch - loss: 1.30672 - diff: 20.91mlTrain batch 17/32 - 236.4ms/batch - loss: 1.29303 - diff: 20.69mlTrain batch 18/32 - 236.3ms/batch - loss: 1.27051 - diff: 20.33mlTrain batch 19/32 - 236.5ms/batch - loss: 1.26916 - diff: 20.31mlTrain batch 20/32 - 236.3ms/batch - loss: 1.27847 - diff: 20.46mlTrain batch 21/32 - 237.0ms/batch - loss: 1.26729 - diff: 20.28mlTrain batch 22/32 - 236.3ms/batch - loss: 1.27396 - diff: 20.38mlTrain batch 23/32 - 235.7ms/batch - loss: 1.28379 - diff: 20.54mlTrain batch 24/32 - 236.0ms/batch - loss: 1.28883 - diff: 20.62mlTrain batch 25/32 - 236.5ms/batch - loss: 1.27591 - diff: 20.41mlTrain batch 26/32 - 235.9ms/batch - loss: 1.28336 - diff: 20.53mlTrain batch 27/32 - 236.0ms/batch - loss: 1.30468 - diff: 20.87mlTrain batch 28/32 - 236.2ms/batch - loss: 1.30471 - diff: 20.88mlTrain batch 29/32 - 236.7ms/batch - loss: 1.29429 - diff: 20.71mlTrain batch 30/32 - 236.0ms/batch - loss: 1.29109 - diff: 20.66mlTrain batch 31/32 - 235.7ms/batch - loss: 1.28333 - diff: 20.53mlTrain batch 32/32 - 83.0ms/batch - loss: 1.29454 - diff: 20.45mlTrain batch 32/32 - 16.5s 83.0ms/batch - loss: 1.29454 - diff: 20.45ml
Test 1.5s: val_loss: 1.60713 - diff: 24.44ml

Epoch 124: current best loss = 1.32748, at epoch 111
Train batch 1/32 - 235.8ms/batch - loss: 0.91433 - diff: 14.63mlTrain batch 2/32 - 235.1ms/batch - loss: 1.00509 - diff: 16.08mlTrain batch 3/32 - 236.2ms/batch - loss: 1.19777 - diff: 19.16mlTrain batch 4/32 - 235.3ms/batch - loss: 1.28437 - diff: 20.55mlTrain batch 5/32 - 235.7ms/batch - loss: 1.24854 - diff: 19.98mlTrain batch 6/32 - 235.7ms/batch - loss: 1.32116 - diff: 21.14mlTrain batch 7/32 - 244.4ms/batch - loss: 1.30245 - diff: 20.84mlTrain batch 8/32 - 235.8ms/batch - loss: 1.36183 - diff: 21.79mlTrain batch 9/32 - 235.6ms/batch - loss: 1.34516 - diff: 21.52mlTrain batch 10/32 - 235.6ms/batch - loss: 1.30459 - diff: 20.87mlTrain batch 11/32 - 236.1ms/batch - loss: 1.31588 - diff: 21.05mlTrain batch 12/32 - 236.2ms/batch - loss: 1.30222 - diff: 20.84mlTrain batch 13/32 - 260.6ms/batch - loss: 1.28211 - diff: 20.51mlTrain batch 14/32 - 235.9ms/batch - loss: 1.27342 - diff: 20.37mlTrain batch 15/32 - 236.2ms/batch - loss: 1.22423 - diff: 19.59mlTrain batch 16/32 - 235.8ms/batch - loss: 1.19477 - diff: 19.12mlTrain batch 17/32 - 236.7ms/batch - loss: 1.20386 - diff: 19.26mlTrain batch 18/32 - 235.8ms/batch - loss: 1.20989 - diff: 19.36mlTrain batch 19/32 - 235.6ms/batch - loss: 1.21070 - diff: 19.37mlTrain batch 20/32 - 239.0ms/batch - loss: 1.20379 - diff: 19.26mlTrain batch 21/32 - 235.5ms/batch - loss: 1.21266 - diff: 19.40mlTrain batch 22/32 - 236.0ms/batch - loss: 1.19922 - diff: 19.19mlTrain batch 23/32 - 236.8ms/batch - loss: 1.18922 - diff: 19.03mlTrain batch 24/32 - 235.8ms/batch - loss: 1.18599 - diff: 18.98mlTrain batch 25/32 - 236.5ms/batch - loss: 1.18499 - diff: 18.96mlTrain batch 26/32 - 236.7ms/batch - loss: 1.18471 - diff: 18.96mlTrain batch 27/32 - 236.6ms/batch - loss: 1.17991 - diff: 18.88mlTrain batch 28/32 - 236.6ms/batch - loss: 1.17545 - diff: 18.81mlTrain batch 29/32 - 236.8ms/batch - loss: 1.17469 - diff: 18.79mlTrain batch 30/32 - 236.1ms/batch - loss: 1.17222 - diff: 18.76mlTrain batch 31/32 - 236.5ms/batch - loss: 1.18158 - diff: 18.91mlTrain batch 32/32 - 76.4ms/batch - loss: 1.21671 - diff: 18.93mlTrain batch 32/32 - 17.5s 76.4ms/batch - loss: 1.21671 - diff: 18.93ml
Test 1.5s: val_loss: 1.46315 - diff: 22.45ml

Epoch 125: current best loss = 1.32748, at epoch 111
Train batch 1/32 - 236.6ms/batch - loss: 0.97855 - diff: 15.66mlTrain batch 2/32 - 236.4ms/batch - loss: 1.69267 - diff: 27.08mlTrain batch 3/32 - 236.0ms/batch - loss: 1.39564 - diff: 22.33mlTrain batch 4/32 - 236.3ms/batch - loss: 1.47400 - diff: 23.58mlTrain batch 5/32 - 237.0ms/batch - loss: 1.33612 - diff: 21.38mlTrain batch 6/32 - 235.7ms/batch - loss: 1.31240 - diff: 21.00mlTrain batch 7/32 - 235.5ms/batch - loss: 1.32254 - diff: 21.16mlTrain batch 8/32 - 236.8ms/batch - loss: 1.26033 - diff: 20.17mlTrain batch 9/32 - 235.9ms/batch - loss: 1.28747 - diff: 20.60mlTrain batch 10/32 - 235.9ms/batch - loss: 1.31059 - diff: 20.97mlTrain batch 11/32 - 235.9ms/batch - loss: 1.31483 - diff: 21.04mlTrain batch 12/32 - 236.5ms/batch - loss: 1.32832 - diff: 21.25mlTrain batch 13/32 - 235.7ms/batch - loss: 1.32319 - diff: 21.17mlTrain batch 14/32 - 236.2ms/batch - loss: 1.33314 - diff: 21.33mlTrain batch 15/32 - 236.2ms/batch - loss: 1.32323 - diff: 21.17mlTrain batch 16/32 - 236.4ms/batch - loss: 1.30012 - diff: 20.80mlTrain batch 17/32 - 235.7ms/batch - loss: 1.28718 - diff: 20.59mlTrain batch 18/32 - 236.0ms/batch - loss: 1.27468 - diff: 20.39mlTrain batch 19/32 - 236.1ms/batch - loss: 1.26717 - diff: 20.27mlTrain batch 20/32 - 237.1ms/batch - loss: 1.28705 - diff: 20.59mlTrain batch 21/32 - 236.5ms/batch - loss: 1.29876 - diff: 20.78mlTrain batch 22/32 - 236.4ms/batch - loss: 1.28752 - diff: 20.60mlTrain batch 23/32 - 235.7ms/batch - loss: 1.28867 - diff: 20.62mlTrain batch 24/32 - 240.0ms/batch - loss: 1.27079 - diff: 20.33mlTrain batch 25/32 - 235.9ms/batch - loss: 1.26342 - diff: 20.21mlTrain batch 26/32 - 238.5ms/batch - loss: 1.25529 - diff: 20.08mlTrain batch 27/32 - 236.3ms/batch - loss: 1.25777 - diff: 20.12mlTrain batch 28/32 - 240.1ms/batch - loss: 1.25319 - diff: 20.05mlTrain batch 29/32 - 236.2ms/batch - loss: 1.24105 - diff: 19.86mlTrain batch 30/32 - 236.0ms/batch - loss: 1.24420 - diff: 19.91mlTrain batch 31/32 - 235.6ms/batch - loss: 1.24144 - diff: 19.86mlTrain batch 32/32 - 76.3ms/batch - loss: 1.24760 - diff: 19.77mlTrain batch 32/32 - 18.2s 76.3ms/batch - loss: 1.24760 - diff: 19.77ml
Test 1.5s: val_loss: 1.39919 - diff: 21.76ml

Epoch 126: current best loss = 1.32748, at epoch 111
Train batch 1/32 - 235.8ms/batch - loss: 1.05262 - diff: 16.84mlTrain batch 2/32 - 234.9ms/batch - loss: 0.94514 - diff: 15.12mlTrain batch 3/32 - 237.1ms/batch - loss: 1.00732 - diff: 16.12mlTrain batch 4/32 - 236.4ms/batch - loss: 1.29376 - diff: 20.70mlTrain batch 5/32 - 235.6ms/batch - loss: 1.27833 - diff: 20.45mlTrain batch 6/32 - 236.4ms/batch - loss: 1.27871 - diff: 20.46mlTrain batch 7/32 - 235.6ms/batch - loss: 1.22520 - diff: 19.60mlTrain batch 8/32 - 236.3ms/batch - loss: 1.21709 - diff: 19.47mlTrain batch 9/32 - 235.4ms/batch - loss: 1.24796 - diff: 19.97mlTrain batch 10/32 - 236.2ms/batch - loss: 1.22486 - diff: 19.60mlTrain batch 11/32 - 239.5ms/batch - loss: 1.25647 - diff: 20.10mlTrain batch 12/32 - 247.0ms/batch - loss: 1.26827 - diff: 20.29mlTrain batch 13/32 - 236.1ms/batch - loss: 1.27545 - diff: 20.41mlTrain batch 14/32 - 236.3ms/batch - loss: 1.25377 - diff: 20.06mlTrain batch 15/32 - 235.6ms/batch - loss: 1.22564 - diff: 19.61mlTrain batch 16/32 - 236.4ms/batch - loss: 1.20338 - diff: 19.25mlTrain batch 17/32 - 236.2ms/batch - loss: 1.18385 - diff: 18.94mlTrain batch 18/32 - 236.7ms/batch - loss: 1.21423 - diff: 19.43mlTrain batch 19/32 - 235.5ms/batch - loss: 1.23554 - diff: 19.77mlTrain batch 20/32 - 236.2ms/batch - loss: 1.22632 - diff: 19.62mlTrain batch 21/32 - 235.8ms/batch - loss: 1.22880 - diff: 19.66mlTrain batch 22/32 - 236.4ms/batch - loss: 1.26590 - diff: 20.25mlTrain batch 23/32 - 236.5ms/batch - loss: 1.28293 - diff: 20.53mlTrain batch 24/32 - 236.6ms/batch - loss: 1.29557 - diff: 20.73mlTrain batch 25/32 - 236.2ms/batch - loss: 1.30340 - diff: 20.85mlTrain batch 26/32 - 236.2ms/batch - loss: 1.28660 - diff: 20.59mlTrain batch 27/32 - 237.3ms/batch - loss: 1.28248 - diff: 20.52mlTrain batch 28/32 - 237.0ms/batch - loss: 1.27684 - diff: 20.43mlTrain batch 29/32 - 236.5ms/batch - loss: 1.29234 - diff: 20.68mlTrain batch 30/32 - 236.5ms/batch - loss: 1.27214 - diff: 20.35mlTrain batch 31/32 - 236.2ms/batch - loss: 1.25650 - diff: 20.10mlTrain batch 32/32 - 78.9ms/batch - loss: 1.27227 - diff: 20.05mlTrain batch 32/32 - 17.0s 78.9ms/batch - loss: 1.27227 - diff: 20.05ml
Test 1.5s: val_loss: 1.44740 - diff: 21.90ml

Epoch 127: current best loss = 1.32748, at epoch 111
Train batch 1/32 - 235.5ms/batch - loss: 1.09375 - diff: 17.50mlTrain batch 2/32 - 236.6ms/batch - loss: 1.37461 - diff: 21.99mlTrain batch 3/32 - 235.8ms/batch - loss: 1.19868 - diff: 19.18mlTrain batch 4/32 - 236.5ms/batch - loss: 1.13660 - diff: 18.19mlTrain batch 5/32 - 235.3ms/batch - loss: 1.16248 - diff: 18.60mlTrain batch 6/32 - 235.9ms/batch - loss: 1.15968 - diff: 18.55mlTrain batch 7/32 - 236.1ms/batch - loss: 1.18106 - diff: 18.90mlTrain batch 8/32 - 235.8ms/batch - loss: 1.28859 - diff: 20.62mlTrain batch 9/32 - 235.7ms/batch - loss: 1.28640 - diff: 20.58mlTrain batch 10/32 - 235.2ms/batch - loss: 1.24592 - diff: 19.93mlTrain batch 11/32 - 244.8ms/batch - loss: 1.22924 - diff: 19.67mlTrain batch 12/32 - 247.4ms/batch - loss: 1.21225 - diff: 19.40mlTrain batch 13/32 - 235.8ms/batch - loss: 1.20759 - diff: 19.32mlTrain batch 14/32 - 241.3ms/batch - loss: 1.18146 - diff: 18.90mlTrain batch 15/32 - 235.9ms/batch - loss: 1.18799 - diff: 19.01mlTrain batch 16/32 - 236.1ms/batch - loss: 1.21116 - diff: 19.38mlTrain batch 17/32 - 236.2ms/batch - loss: 1.25386 - diff: 20.06mlTrain batch 18/32 - 236.4ms/batch - loss: 1.23124 - diff: 19.70mlTrain batch 19/32 - 235.8ms/batch - loss: 1.23933 - diff: 19.83mlTrain batch 20/32 - 244.2ms/batch - loss: 1.21143 - diff: 19.38mlTrain batch 21/32 - 235.6ms/batch - loss: 1.22808 - diff: 19.65mlTrain batch 22/32 - 246.3ms/batch - loss: 1.22464 - diff: 19.59mlTrain batch 23/32 - 235.7ms/batch - loss: 1.23055 - diff: 19.69mlTrain batch 24/32 - 236.1ms/batch - loss: 1.22420 - diff: 19.59mlTrain batch 25/32 - 272.0ms/batch - loss: 1.24851 - diff: 19.98mlTrain batch 26/32 - 236.7ms/batch - loss: 1.26032 - diff: 20.17mlTrain batch 27/32 - 236.9ms/batch - loss: 1.24401 - diff: 19.90mlTrain batch 28/32 - 236.0ms/batch - loss: 1.22762 - diff: 19.64mlTrain batch 29/32 - 235.6ms/batch - loss: 1.22505 - diff: 19.60mlTrain batch 30/32 - 235.9ms/batch - loss: 1.21565 - diff: 19.45mlTrain batch 31/32 - 235.9ms/batch - loss: 1.20552 - diff: 19.29mlTrain batch 32/32 - 76.2ms/batch - loss: 1.22057 - diff: 19.23mlTrain batch 32/32 - 17.9s 76.2ms/batch - loss: 1.22057 - diff: 19.23ml
Test 1.4s: val_loss: 1.41803 - diff: 21.96ml

Epoch 128: current best loss = 1.32748, at epoch 111
Train batch 1/32 - 235.6ms/batch - loss: 1.64492 - diff: 26.32mlTrain batch 2/32 - 244.4ms/batch - loss: 1.39873 - diff: 22.38mlTrain batch 3/32 - 235.8ms/batch - loss: 1.29242 - diff: 20.68mlTrain batch 4/32 - 236.0ms/batch - loss: 1.42034 - diff: 22.73mlTrain batch 5/32 - 240.1ms/batch - loss: 1.39640 - diff: 22.34mlTrain batch 6/32 - 236.1ms/batch - loss: 1.51011 - diff: 24.16mlTrain batch 7/32 - 235.5ms/batch - loss: 1.42056 - diff: 22.73mlTrain batch 8/32 - 236.1ms/batch - loss: 1.35445 - diff: 21.67mlTrain batch 9/32 - 237.8ms/batch - loss: 1.28035 - diff: 20.49mlTrain batch 10/32 - 236.0ms/batch - loss: 1.27144 - diff: 20.34mlTrain batch 11/32 - 235.7ms/batch - loss: 1.30874 - diff: 20.94mlTrain batch 12/32 - 235.3ms/batch - loss: 1.29797 - diff: 20.77mlTrain batch 13/32 - 236.2ms/batch - loss: 1.32702 - diff: 21.23mlTrain batch 14/32 - 236.6ms/batch - loss: 1.30778 - diff: 20.92mlTrain batch 15/32 - 235.7ms/batch - loss: 1.27881 - diff: 20.46mlTrain batch 16/32 - 236.5ms/batch - loss: 1.25813 - diff: 20.13mlTrain batch 17/32 - 235.5ms/batch - loss: 1.22176 - diff: 19.55mlTrain batch 18/32 - 236.2ms/batch - loss: 1.20399 - diff: 19.26mlTrain batch 19/32 - 236.1ms/batch - loss: 1.19278 - diff: 19.08mlTrain batch 20/32 - 236.2ms/batch - loss: 1.16729 - diff: 18.68mlTrain batch 21/32 - 236.6ms/batch - loss: 1.17595 - diff: 18.82mlTrain batch 22/32 - 236.2ms/batch - loss: 1.16586 - diff: 18.65mlTrain batch 23/32 - 236.0ms/batch - loss: 1.15306 - diff: 18.45mlTrain batch 24/32 - 242.8ms/batch - loss: 1.16490 - diff: 18.64mlTrain batch 25/32 - 235.9ms/batch - loss: 1.16428 - diff: 18.63mlTrain batch 26/32 - 236.2ms/batch - loss: 1.15468 - diff: 18.47mlTrain batch 27/32 - 236.4ms/batch - loss: 1.16372 - diff: 18.62mlTrain batch 28/32 - 236.1ms/batch - loss: 1.17599 - diff: 18.82mlTrain batch 29/32 - 236.5ms/batch - loss: 1.16653 - diff: 18.66mlTrain batch 30/32 - 236.4ms/batch - loss: 1.15663 - diff: 18.51mlTrain batch 31/32 - 236.0ms/batch - loss: 1.13882 - diff: 18.22mlTrain batch 32/32 - 76.3ms/batch - loss: 1.19390 - diff: 18.33mlTrain batch 32/32 - 17.2s 76.3ms/batch - loss: 1.19390 - diff: 18.33ml
Test 1.5s: val_loss: 1.33274 - diff: 20.81ml

Epoch 129: current best loss = 1.32748, at epoch 111
Train batch 1/32 - 245.6ms/batch - loss: 1.38327 - diff: 22.13mlTrain batch 2/32 - 259.0ms/batch - loss: 1.36651 - diff: 21.86mlTrain batch 3/32 - 235.5ms/batch - loss: 1.27647 - diff: 20.42mlTrain batch 4/32 - 236.8ms/batch - loss: 1.21541 - diff: 19.45mlTrain batch 5/32 - 235.9ms/batch - loss: 1.18588 - diff: 18.97mlTrain batch 6/32 - 235.7ms/batch - loss: 1.16061 - diff: 18.57mlTrain batch 7/32 - 235.8ms/batch - loss: 1.10079 - diff: 17.61mlTrain batch 8/32 - 260.1ms/batch - loss: 1.25105 - diff: 20.02mlTrain batch 9/32 - 236.1ms/batch - loss: 1.27308 - diff: 20.37mlTrain batch 10/32 - 237.0ms/batch - loss: 1.27721 - diff: 20.44mlTrain batch 11/32 - 235.2ms/batch - loss: 1.25025 - diff: 20.00mlTrain batch 12/32 - 236.8ms/batch - loss: 1.23610 - diff: 19.78mlTrain batch 13/32 - 235.8ms/batch - loss: 1.23704 - diff: 19.79mlTrain batch 14/32 - 237.8ms/batch - loss: 1.24793 - diff: 19.97mlTrain batch 15/32 - 235.5ms/batch - loss: 1.24973 - diff: 20.00mlTrain batch 16/32 - 239.0ms/batch - loss: 1.26205 - diff: 20.19mlTrain batch 17/32 - 235.6ms/batch - loss: 1.23509 - diff: 19.76mlTrain batch 18/32 - 236.1ms/batch - loss: 1.22067 - diff: 19.53mlTrain batch 19/32 - 235.7ms/batch - loss: 1.21884 - diff: 19.50mlTrain batch 20/32 - 236.1ms/batch - loss: 1.22116 - diff: 19.54mlTrain batch 21/32 - 235.9ms/batch - loss: 1.23120 - diff: 19.70mlTrain batch 22/32 - 236.4ms/batch - loss: 1.25624 - diff: 20.10mlTrain batch 23/32 - 235.7ms/batch - loss: 1.30704 - diff: 20.91mlTrain batch 24/32 - 237.4ms/batch - loss: 1.31059 - diff: 20.97mlTrain batch 25/32 - 235.7ms/batch - loss: 1.31076 - diff: 20.97mlTrain batch 26/32 - 236.8ms/batch - loss: 1.31353 - diff: 21.02mlTrain batch 27/32 - 236.0ms/batch - loss: 1.31295 - diff: 21.01mlTrain batch 28/32 - 235.8ms/batch - loss: 1.31959 - diff: 21.11mlTrain batch 29/32 - 235.9ms/batch - loss: 1.32562 - diff: 21.21mlTrain batch 30/32 - 236.0ms/batch - loss: 1.32881 - diff: 21.26mlTrain batch 31/32 - 240.7ms/batch - loss: 1.32741 - diff: 21.24mlTrain batch 32/32 - 76.1ms/batch - loss: 1.37816 - diff: 21.31mlTrain batch 32/32 - 17.7s 76.1ms/batch - loss: 1.37816 - diff: 21.31ml
Test 1.6s: val_loss: 1.58255 - diff: 24.19ml

Epoch 130: current best loss = 1.32748, at epoch 111
Train batch 1/32 - 235.6ms/batch - loss: 1.14296 - diff: 18.29mlTrain batch 2/32 - 235.9ms/batch - loss: 1.00299 - diff: 16.05mlTrain batch 3/32 - 235.8ms/batch - loss: 1.28102 - diff: 20.50mlTrain batch 4/32 - 236.0ms/batch - loss: 1.33832 - diff: 21.41mlTrain batch 5/32 - 235.6ms/batch - loss: 1.59332 - diff: 25.49mlTrain batch 6/32 - 237.6ms/batch - loss: 1.51852 - diff: 24.30mlTrain batch 7/32 - 236.2ms/batch - loss: 1.41455 - diff: 22.63mlTrain batch 8/32 - 236.2ms/batch - loss: 1.37967 - diff: 22.07mlTrain batch 9/32 - 235.9ms/batch - loss: 1.34500 - diff: 21.52mlTrain batch 10/32 - 236.0ms/batch - loss: 1.28463 - diff: 20.55mlTrain batch 11/32 - 235.6ms/batch - loss: 1.24860 - diff: 19.98mlTrain batch 12/32 - 257.3ms/batch - loss: 1.23857 - diff: 19.82mlTrain batch 13/32 - 236.0ms/batch - loss: 1.23870 - diff: 19.82mlTrain batch 14/32 - 235.7ms/batch - loss: 1.22366 - diff: 19.58mlTrain batch 15/32 - 236.1ms/batch - loss: 1.21967 - diff: 19.51mlTrain batch 16/32 - 236.7ms/batch - loss: 1.23302 - diff: 19.73mlTrain batch 17/32 - 235.6ms/batch - loss: 1.21476 - diff: 19.44mlTrain batch 18/32 - 241.9ms/batch - loss: 1.21079 - diff: 19.37mlTrain batch 19/32 - 235.6ms/batch - loss: 1.18740 - diff: 19.00mlTrain batch 20/32 - 236.3ms/batch - loss: 1.17232 - diff: 18.76mlTrain batch 21/32 - 236.3ms/batch - loss: 1.16084 - diff: 18.57mlTrain batch 22/32 - 236.0ms/batch - loss: 1.16741 - diff: 18.68mlTrain batch 23/32 - 236.1ms/batch - loss: 1.16167 - diff: 18.59mlTrain batch 24/32 - 236.6ms/batch - loss: 1.15563 - diff: 18.49mlTrain batch 25/32 - 240.3ms/batch - loss: 1.16706 - diff: 18.67mlTrain batch 26/32 - 236.1ms/batch - loss: 1.17521 - diff: 18.80mlTrain batch 27/32 - 235.6ms/batch - loss: 1.17153 - diff: 18.74mlTrain batch 28/32 - 235.4ms/batch - loss: 1.18676 - diff: 18.99mlTrain batch 29/32 - 236.1ms/batch - loss: 1.18510 - diff: 18.96mlTrain batch 30/32 - 236.3ms/batch - loss: 1.19722 - diff: 19.16mlTrain batch 31/32 - 235.6ms/batch - loss: 1.18194 - diff: 18.91mlTrain batch 32/32 - 80.9ms/batch - loss: 1.19599 - diff: 18.85mlTrain batch 32/32 - 17.3s 80.9ms/batch - loss: 1.19599 - diff: 18.85ml
Test 1.5s: val_loss: 1.41266 - diff: 22.09ml

Epoch 131: current best loss = 1.32748, at epoch 111
Train batch 1/32 - 235.8ms/batch - loss: 1.00886 - diff: 16.14mlTrain batch 2/32 - 236.4ms/batch - loss: 0.99061 - diff: 15.85mlTrain batch 3/32 - 235.6ms/batch - loss: 1.01861 - diff: 16.30mlTrain batch 4/32 - 259.5ms/batch - loss: 1.02252 - diff: 16.36mlTrain batch 5/32 - 235.8ms/batch - loss: 1.12845 - diff: 18.06mlTrain batch 6/32 - 235.8ms/batch - loss: 1.24906 - diff: 19.98mlTrain batch 7/32 - 235.6ms/batch - loss: 1.26092 - diff: 20.17mlTrain batch 8/32 - 238.8ms/batch - loss: 1.30220 - diff: 20.84mlTrain batch 9/32 - 235.6ms/batch - loss: 1.28917 - diff: 20.63mlTrain batch 10/32 - 235.4ms/batch - loss: 1.30385 - diff: 20.86mlTrain batch 11/32 - 235.8ms/batch - loss: 1.29082 - diff: 20.65mlTrain batch 12/32 - 258.8ms/batch - loss: 1.31413 - diff: 21.03mlTrain batch 13/32 - 235.5ms/batch - loss: 1.28039 - diff: 20.49mlTrain batch 14/32 - 237.0ms/batch - loss: 1.25031 - diff: 20.00mlTrain batch 15/32 - 235.6ms/batch - loss: 1.25665 - diff: 20.11mlTrain batch 16/32 - 236.6ms/batch - loss: 1.22110 - diff: 19.54mlTrain batch 17/32 - 235.7ms/batch - loss: 1.22998 - diff: 19.68mlTrain batch 18/32 - 237.4ms/batch - loss: 1.22822 - diff: 19.65mlTrain batch 19/32 - 235.9ms/batch - loss: 1.20846 - diff: 19.34mlTrain batch 20/32 - 236.3ms/batch - loss: 1.20781 - diff: 19.32mlTrain batch 21/32 - 236.2ms/batch - loss: 1.19255 - diff: 19.08mlTrain batch 22/32 - 236.4ms/batch - loss: 1.17613 - diff: 18.82mlTrain batch 23/32 - 239.4ms/batch - loss: 1.17073 - diff: 18.73mlTrain batch 24/32 - 236.5ms/batch - loss: 1.18281 - diff: 18.93mlTrain batch 25/32 - 236.7ms/batch - loss: 1.19027 - diff: 19.04mlTrain batch 26/32 - 236.3ms/batch - loss: 1.19418 - diff: 19.11mlTrain batch 27/32 - 236.0ms/batch - loss: 1.18083 - diff: 18.89mlTrain batch 28/32 - 236.5ms/batch - loss: 1.16739 - diff: 18.68mlTrain batch 29/32 - 236.6ms/batch - loss: 1.17280 - diff: 18.76mlTrain batch 30/32 - 235.5ms/batch - loss: 1.19406 - diff: 19.11mlTrain batch 31/32 - 236.5ms/batch - loss: 1.17781 - diff: 18.84mlTrain batch 32/32 - 76.4ms/batch - loss: 1.19729 - diff: 18.81mlTrain batch 32/32 - 17.5s 76.4ms/batch - loss: 1.19729 - diff: 18.81ml
Test 1.5s: val_loss: 1.35405 - diff: 20.97ml

Epoch 132: current best loss = 1.32748, at epoch 111
Train batch 1/32 - 235.5ms/batch - loss: 0.96807 - diff: 15.49mlTrain batch 2/32 - 242.4ms/batch - loss: 1.63096 - diff: 26.10mlTrain batch 3/32 - 235.4ms/batch - loss: 1.51876 - diff: 24.30mlTrain batch 4/32 - 235.9ms/batch - loss: 1.36222 - diff: 21.80mlTrain batch 5/32 - 240.4ms/batch - loss: 1.30607 - diff: 20.90mlTrain batch 6/32 - 235.9ms/batch - loss: 1.26507 - diff: 20.24mlTrain batch 7/32 - 235.8ms/batch - loss: 1.23895 - diff: 19.82mlTrain batch 8/32 - 237.2ms/batch - loss: 1.21780 - diff: 19.48mlTrain batch 9/32 - 236.4ms/batch - loss: 1.20421 - diff: 19.27mlTrain batch 10/32 - 236.3ms/batch - loss: 1.18133 - diff: 18.90mlTrain batch 11/32 - 235.6ms/batch - loss: 1.20286 - diff: 19.25mlTrain batch 12/32 - 235.9ms/batch - loss: 1.18738 - diff: 19.00mlTrain batch 13/32 - 235.2ms/batch - loss: 1.17822 - diff: 18.85mlTrain batch 14/32 - 235.6ms/batch - loss: 1.16251 - diff: 18.60mlTrain batch 15/32 - 235.9ms/batch - loss: 1.13222 - diff: 18.12mlTrain batch 16/32 - 236.3ms/batch - loss: 1.14273 - diff: 18.28mlTrain batch 17/32 - 235.6ms/batch - loss: 1.15478 - diff: 18.48mlTrain batch 18/32 - 244.5ms/batch - loss: 1.16542 - diff: 18.65mlTrain batch 19/32 - 235.9ms/batch - loss: 1.15005 - diff: 18.40mlTrain batch 20/32 - 236.1ms/batch - loss: 1.14822 - diff: 18.37mlTrain batch 21/32 - 236.1ms/batch - loss: 1.12415 - diff: 17.99mlTrain batch 22/32 - 235.9ms/batch - loss: 1.10793 - diff: 17.73mlTrain batch 23/32 - 235.9ms/batch - loss: 1.14836 - diff: 18.37mlTrain batch 24/32 - 236.1ms/batch - loss: 1.14389 - diff: 18.30mlTrain batch 25/32 - 236.0ms/batch - loss: 1.14789 - diff: 18.37mlTrain batch 26/32 - 236.1ms/batch - loss: 1.13267 - diff: 18.12mlTrain batch 27/32 - 236.0ms/batch - loss: 1.12872 - diff: 18.06mlTrain batch 28/32 - 236.3ms/batch - loss: 1.13706 - diff: 18.19mlTrain batch 29/32 - 235.9ms/batch - loss: 1.13175 - diff: 18.11mlTrain batch 30/32 - 236.9ms/batch - loss: 1.11737 - diff: 17.88mlTrain batch 31/32 - 235.8ms/batch - loss: 1.12976 - diff: 18.08mlTrain batch 32/32 - 76.1ms/batch - loss: 1.16221 - diff: 18.10mlTrain batch 32/32 - 17.4s 76.1ms/batch - loss: 1.16221 - diff: 18.10ml
Test 1.4s: val_loss: 1.40730 - diff: 21.70ml

Epoch 133: current best loss = 1.32748, at epoch 111
Train batch 1/32 - 235.7ms/batch - loss: 1.15826 - diff: 18.53mlTrain batch 2/32 - 241.9ms/batch - loss: 1.17475 - diff: 18.80mlTrain batch 3/32 - 238.9ms/batch - loss: 1.25578 - diff: 20.09mlTrain batch 4/32 - 240.9ms/batch - loss: 1.17195 - diff: 18.75mlTrain batch 5/32 - 235.6ms/batch - loss: 1.18994 - diff: 19.04mlTrain batch 6/32 - 235.6ms/batch - loss: 1.12195 - diff: 17.95mlTrain batch 7/32 - 235.4ms/batch - loss: 1.13735 - diff: 18.20mlTrain batch 8/32 - 266.4ms/batch - loss: 1.11471 - diff: 17.84mlTrain batch 9/32 - 236.2ms/batch - loss: 1.13457 - diff: 18.15mlTrain batch 10/32 - 236.5ms/batch - loss: 1.15807 - diff: 18.53mlTrain batch 11/32 - 235.7ms/batch - loss: 1.15573 - diff: 18.49mlTrain batch 12/32 - 235.5ms/batch - loss: 1.13964 - diff: 18.23mlTrain batch 13/32 - 235.5ms/batch - loss: 1.18197 - diff: 18.91mlTrain batch 14/32 - 236.3ms/batch - loss: 1.17100 - diff: 18.74mlTrain batch 15/32 - 235.6ms/batch - loss: 1.16101 - diff: 18.58mlTrain batch 16/32 - 237.3ms/batch - loss: 1.16841 - diff: 18.69mlTrain batch 17/32 - 235.6ms/batch - loss: 1.15881 - diff: 18.54mlTrain batch 18/32 - 236.4ms/batch - loss: 1.15712 - diff: 18.51mlTrain batch 19/32 - 235.8ms/batch - loss: 1.19590 - diff: 19.13mlTrain batch 20/32 - 236.5ms/batch - loss: 1.19043 - diff: 19.05mlTrain batch 21/32 - 236.1ms/batch - loss: 1.18932 - diff: 19.03mlTrain batch 22/32 - 236.5ms/batch - loss: 1.18678 - diff: 18.99mlTrain batch 23/32 - 235.8ms/batch - loss: 1.18584 - diff: 18.97mlTrain batch 24/32 - 235.8ms/batch - loss: 1.19710 - diff: 19.15mlTrain batch 25/32 - 237.0ms/batch - loss: 1.18507 - diff: 18.96mlTrain batch 26/32 - 236.7ms/batch - loss: 1.19323 - diff: 19.09mlTrain batch 27/32 - 235.7ms/batch - loss: 1.19615 - diff: 19.14mlTrain batch 28/32 - 236.6ms/batch - loss: 1.19446 - diff: 19.11mlTrain batch 29/32 - 235.8ms/batch - loss: 1.18926 - diff: 19.03mlTrain batch 30/32 - 235.3ms/batch - loss: 1.17533 - diff: 18.81mlTrain batch 31/32 - 235.7ms/batch - loss: 1.17448 - diff: 18.79mlTrain batch 32/32 - 84.0ms/batch - loss: 1.18807 - diff: 18.73mlTrain batch 32/32 - 17.9s 84.0ms/batch - loss: 1.18807 - diff: 18.73ml
Test 1.5s: val_loss: 1.52355 - diff: 23.25ml
Epoch   134: reducing learning rate of group 0 to 6.2500e-05.

Epoch 134: current best loss = 1.32748, at epoch 111
Train batch 1/32 - 235.4ms/batch - loss: 1.06462 - diff: 17.03mlTrain batch 2/32 - 238.3ms/batch - loss: 1.06554 - diff: 17.05mlTrain batch 3/32 - 235.4ms/batch - loss: 1.45937 - diff: 23.35mlTrain batch 4/32 - 244.1ms/batch - loss: 1.41552 - diff: 22.65mlTrain batch 5/32 - 235.6ms/batch - loss: 1.34187 - diff: 21.47mlTrain batch 6/32 - 236.2ms/batch - loss: 1.29646 - diff: 20.74mlTrain batch 7/32 - 235.5ms/batch - loss: 1.34581 - diff: 21.53mlTrain batch 8/32 - 251.3ms/batch - loss: 1.31761 - diff: 21.08mlTrain batch 9/32 - 235.3ms/batch - loss: 1.28794 - diff: 20.61mlTrain batch 10/32 - 236.7ms/batch - loss: 1.25295 - diff: 20.05mlTrain batch 11/32 - 235.5ms/batch - loss: 1.24567 - diff: 19.93mlTrain batch 12/32 - 236.0ms/batch - loss: 1.22237 - diff: 19.56mlTrain batch 13/32 - 235.3ms/batch - loss: 1.22592 - diff: 19.61mlTrain batch 14/32 - 236.4ms/batch - loss: 1.23814 - diff: 19.81mlTrain batch 15/32 - 236.1ms/batch - loss: 1.21215 - diff: 19.39mlTrain batch 16/32 - 235.6ms/batch - loss: 1.18068 - diff: 18.89mlTrain batch 17/32 - 235.4ms/batch - loss: 1.17389 - diff: 18.78mlTrain batch 18/32 - 235.8ms/batch - loss: 1.16816 - diff: 18.69mlTrain batch 19/32 - 235.6ms/batch - loss: 1.16451 - diff: 18.63mlTrain batch 20/32 - 235.9ms/batch - loss: 1.16903 - diff: 18.70mlTrain batch 21/32 - 235.7ms/batch - loss: 1.18238 - diff: 18.92mlTrain batch 22/32 - 236.1ms/batch - loss: 1.16072 - diff: 18.57mlTrain batch 23/32 - 235.9ms/batch - loss: 1.13663 - diff: 18.19mlTrain batch 24/32 - 242.3ms/batch - loss: 1.13018 - diff: 18.08mlTrain batch 25/32 - 255.9ms/batch - loss: 1.10538 - diff: 17.69mlTrain batch 26/32 - 236.0ms/batch - loss: 1.10548 - diff: 17.69mlTrain batch 27/32 - 235.6ms/batch - loss: 1.10451 - diff: 17.67mlTrain batch 28/32 - 237.5ms/batch - loss: 1.12471 - diff: 18.00mlTrain batch 29/32 - 235.9ms/batch - loss: 1.14383 - diff: 18.30mlTrain batch 30/32 - 235.8ms/batch - loss: 1.15666 - diff: 18.51mlTrain batch 31/32 - 236.4ms/batch - loss: 1.15424 - diff: 18.47mlTrain batch 32/32 - 82.8ms/batch - loss: 1.23221 - diff: 18.67mlTrain batch 32/32 - 18.4s 82.8ms/batch - loss: 1.23221 - diff: 18.67ml
Test 1.5s: val_loss: 1.41681 - diff: 22.01ml

Epoch 135: current best loss = 1.32748, at epoch 111
Train batch 1/32 - 235.6ms/batch - loss: 1.26682 - diff: 20.27mlTrain batch 2/32 - 242.4ms/batch - loss: 1.49795 - diff: 23.97mlTrain batch 3/32 - 235.4ms/batch - loss: 1.37593 - diff: 22.01mlTrain batch 4/32 - 235.3ms/batch - loss: 1.30927 - diff: 20.95mlTrain batch 5/32 - 235.7ms/batch - loss: 1.19330 - diff: 19.09mlTrain batch 6/32 - 235.9ms/batch - loss: 1.20647 - diff: 19.30mlTrain batch 7/32 - 235.7ms/batch - loss: 1.28489 - diff: 20.56mlTrain batch 8/32 - 245.3ms/batch - loss: 1.28985 - diff: 20.64mlTrain batch 9/32 - 235.6ms/batch - loss: 1.26122 - diff: 20.18mlTrain batch 10/32 - 235.3ms/batch - loss: 1.25844 - diff: 20.14mlTrain batch 11/32 - 241.6ms/batch - loss: 1.21159 - diff: 19.39mlTrain batch 12/32 - 236.5ms/batch - loss: 1.17949 - diff: 18.87mlTrain batch 13/32 - 235.5ms/batch - loss: 1.14647 - diff: 18.34mlTrain batch 14/32 - 235.9ms/batch - loss: 1.14850 - diff: 18.38mlTrain batch 15/32 - 235.8ms/batch - loss: 1.16756 - diff: 18.68mlTrain batch 16/32 - 254.4ms/batch - loss: 1.14954 - diff: 18.39mlTrain batch 17/32 - 235.6ms/batch - loss: 1.14501 - diff: 18.32mlTrain batch 18/32 - 235.2ms/batch - loss: 1.15743 - diff: 18.52mlTrain batch 19/32 - 241.2ms/batch - loss: 1.18812 - diff: 19.01mlTrain batch 20/32 - 236.5ms/batch - loss: 1.17787 - diff: 18.85mlTrain batch 21/32 - 235.8ms/batch - loss: 1.16319 - diff: 18.61mlTrain batch 22/32 - 235.7ms/batch - loss: 1.15342 - diff: 18.45mlTrain batch 23/32 - 236.3ms/batch - loss: 1.21400 - diff: 19.42mlTrain batch 24/32 - 236.1ms/batch - loss: 1.20780 - diff: 19.32mlTrain batch 25/32 - 236.1ms/batch - loss: 1.21441 - diff: 19.43mlTrain batch 26/32 - 236.2ms/batch - loss: 1.21734 - diff: 19.48mlTrain batch 27/32 - 236.3ms/batch - loss: 1.20803 - diff: 19.33mlTrain batch 28/32 - 252.6ms/batch - loss: 1.22469 - diff: 19.59mlTrain batch 29/32 - 235.5ms/batch - loss: 1.22053 - diff: 19.53mlTrain batch 30/32 - 235.6ms/batch - loss: 1.22794 - diff: 19.65mlTrain batch 31/32 - 235.9ms/batch - loss: 1.25298 - diff: 20.05mlTrain batch 32/32 - 76.2ms/batch - loss: 1.31747 - diff: 20.19mlTrain batch 32/32 - 17.4s 76.2ms/batch - loss: 1.31747 - diff: 20.19ml
Test 1.4s: val_loss: 1.42436 - diff: 21.77ml

Epoch 136: current best loss = 1.32748, at epoch 111
Train batch 1/32 - 238.1ms/batch - loss: 0.93360 - diff: 14.94mlTrain batch 2/32 - 235.8ms/batch - loss: 1.23907 - diff: 19.83mlTrain batch 3/32 - 235.8ms/batch - loss: 1.20360 - diff: 19.26mlTrain batch 4/32 - 235.7ms/batch - loss: 1.20334 - diff: 19.25mlTrain batch 5/32 - 236.2ms/batch - loss: 1.13289 - diff: 18.13mlTrain batch 6/32 - 236.1ms/batch - loss: 1.10565 - diff: 17.69mlTrain batch 7/32 - 257.1ms/batch - loss: 1.08838 - diff: 17.41mlTrain batch 8/32 - 236.2ms/batch - loss: 1.11359 - diff: 17.82mlTrain batch 9/32 - 236.1ms/batch - loss: 1.07400 - diff: 17.18mlTrain batch 10/32 - 235.8ms/batch - loss: 1.08093 - diff: 17.29mlTrain batch 11/32 - 236.4ms/batch - loss: 1.17204 - diff: 18.75mlTrain batch 12/32 - 236.3ms/batch - loss: 1.20124 - diff: 19.22mlTrain batch 13/32 - 236.7ms/batch - loss: 1.19094 - diff: 19.06mlTrain batch 14/32 - 235.9ms/batch - loss: 1.24288 - diff: 19.89mlTrain batch 15/32 - 236.1ms/batch - loss: 1.25465 - diff: 20.07mlTrain batch 16/32 - 236.0ms/batch - loss: 1.22046 - diff: 19.53mlTrain batch 17/32 - 237.4ms/batch - loss: 1.23905 - diff: 19.82mlTrain batch 18/32 - 235.3ms/batch - loss: 1.24160 - diff: 19.87mlTrain batch 19/32 - 236.5ms/batch - loss: 1.23604 - diff: 19.78mlTrain batch 20/32 - 235.9ms/batch - loss: 1.25488 - diff: 20.08mlTrain batch 21/32 - 236.5ms/batch - loss: 1.24784 - diff: 19.97mlTrain batch 22/32 - 235.5ms/batch - loss: 1.30085 - diff: 20.81mlTrain batch 23/32 - 235.0ms/batch - loss: 1.28535 - diff: 20.57mlTrain batch 24/32 - 235.6ms/batch - loss: 1.27131 - diff: 20.34mlTrain batch 25/32 - 236.2ms/batch - loss: 1.27835 - diff: 20.45mlTrain batch 26/32 - 236.5ms/batch - loss: 1.29173 - diff: 20.67mlTrain batch 27/32 - 236.5ms/batch - loss: 1.28135 - diff: 20.50mlTrain batch 28/32 - 236.1ms/batch - loss: 1.28492 - diff: 20.56mlTrain batch 29/32 - 236.8ms/batch - loss: 1.27502 - diff: 20.40mlTrain batch 30/32 - 236.4ms/batch - loss: 1.26013 - diff: 20.16mlTrain batch 31/32 - 236.6ms/batch - loss: 1.24238 - diff: 19.88mlTrain batch 32/32 - 76.5ms/batch - loss: 1.27372 - diff: 19.88mlTrain batch 32/32 - 16.3s 76.5ms/batch - loss: 1.27372 - diff: 19.88ml
Test 1.3s: val_loss: 1.40832 - diff: 21.63ml

Epoch 137: current best loss = 1.32748, at epoch 111
Train batch 1/32 - 253.7ms/batch - loss: 0.90792 - diff: 14.53mlTrain batch 2/32 - 236.5ms/batch - loss: 0.99899 - diff: 15.98mlTrain batch 3/32 - 235.8ms/batch - loss: 1.05185 - diff: 16.83mlTrain batch 4/32 - 236.8ms/batch - loss: 1.09933 - diff: 17.59mlTrain batch 5/32 - 240.6ms/batch - loss: 1.09573 - diff: 17.53mlTrain batch 6/32 - 236.1ms/batch - loss: 1.10402 - diff: 17.66mlTrain batch 7/32 - 238.3ms/batch - loss: 1.13177 - diff: 18.11mlTrain batch 8/32 - 236.2ms/batch - loss: 1.08615 - diff: 17.38mlTrain batch 9/32 - 236.6ms/batch - loss: 1.14423 - diff: 18.31mlTrain batch 10/32 - 239.1ms/batch - loss: 1.12959 - diff: 18.07mlTrain batch 11/32 - 235.6ms/batch - loss: 1.15275 - diff: 18.44mlTrain batch 12/32 - 236.7ms/batch - loss: 1.13391 - diff: 18.14mlTrain batch 13/32 - 235.9ms/batch - loss: 1.15721 - diff: 18.52mlTrain batch 14/32 - 236.0ms/batch - loss: 1.16395 - diff: 18.62mlTrain batch 15/32 - 239.1ms/batch - loss: 1.16038 - diff: 18.57mlTrain batch 16/32 - 236.0ms/batch - loss: 1.16331 - diff: 18.61mlTrain batch 17/32 - 235.8ms/batch - loss: 1.17731 - diff: 18.84mlTrain batch 18/32 - 236.7ms/batch - loss: 1.14430 - diff: 18.31mlTrain batch 19/32 - 236.2ms/batch - loss: 1.13345 - diff: 18.14mlTrain batch 20/32 - 236.5ms/batch - loss: 1.11425 - diff: 17.83mlTrain batch 21/32 - 235.9ms/batch - loss: 1.13344 - diff: 18.14mlTrain batch 22/32 - 235.7ms/batch - loss: 1.12117 - diff: 17.94mlTrain batch 23/32 - 236.2ms/batch - loss: 1.11252 - diff: 17.80mlTrain batch 24/32 - 236.3ms/batch - loss: 1.10976 - diff: 17.76mlTrain batch 25/32 - 235.6ms/batch - loss: 1.11056 - diff: 17.77mlTrain batch 26/32 - 236.6ms/batch - loss: 1.12205 - diff: 17.95mlTrain batch 27/32 - 235.9ms/batch - loss: 1.11640 - diff: 17.86mlTrain batch 28/32 - 236.0ms/batch - loss: 1.11016 - diff: 17.76mlTrain batch 29/32 - 235.5ms/batch - loss: 1.13934 - diff: 18.23mlTrain batch 30/32 - 235.4ms/batch - loss: 1.12474 - diff: 18.00mlTrain batch 31/32 - 235.6ms/batch - loss: 1.11497 - diff: 17.84mlTrain batch 32/32 - 76.6ms/batch - loss: 1.13442 - diff: 17.81mlTrain batch 32/32 - 18.1s 76.6ms/batch - loss: 1.13442 - diff: 17.81ml
Test 1.5s: val_loss: 1.45238 - diff: 22.21ml

Epoch 138: current best loss = 1.32748, at epoch 111
Train batch 1/32 - 236.2ms/batch - loss: 0.71199 - diff: 11.39mlTrain batch 2/32 - 236.6ms/batch - loss: 0.90101 - diff: 14.42mlTrain batch 3/32 - 235.4ms/batch - loss: 1.02965 - diff: 16.47mlTrain batch 4/32 - 236.1ms/batch - loss: 1.01389 - diff: 16.22mlTrain batch 5/32 - 235.2ms/batch - loss: 1.04149 - diff: 16.66mlTrain batch 6/32 - 235.6ms/batch - loss: 1.03752 - diff: 16.60mlTrain batch 7/32 - 235.6ms/batch - loss: 1.12408 - diff: 17.99mlTrain batch 8/32 - 235.8ms/batch - loss: 1.13484 - diff: 18.16mlTrain batch 9/32 - 236.3ms/batch - loss: 1.11188 - diff: 17.79mlTrain batch 10/32 - 236.0ms/batch - loss: 1.09514 - diff: 17.52mlTrain batch 11/32 - 239.2ms/batch - loss: 1.12593 - diff: 18.01mlTrain batch 12/32 - 235.4ms/batch - loss: 1.13086 - diff: 18.09mlTrain batch 13/32 - 236.0ms/batch - loss: 1.13237 - diff: 18.12mlTrain batch 14/32 - 245.7ms/batch - loss: 1.13878 - diff: 18.22mlTrain batch 15/32 - 235.5ms/batch - loss: 1.13179 - diff: 18.11mlTrain batch 16/32 - 235.5ms/batch - loss: 1.15940 - diff: 18.55mlTrain batch 17/32 - 235.5ms/batch - loss: 1.15588 - diff: 18.49mlTrain batch 18/32 - 235.6ms/batch - loss: 1.17086 - diff: 18.73mlTrain batch 19/32 - 251.4ms/batch - loss: 1.15231 - diff: 18.44mlTrain batch 20/32 - 255.9ms/batch - loss: 1.16472 - diff: 18.64mlTrain batch 21/32 - 237.3ms/batch - loss: 1.16984 - diff: 18.72mlTrain batch 22/32 - 238.9ms/batch - loss: 1.16438 - diff: 18.63mlTrain batch 23/32 - 240.8ms/batch - loss: 1.16362 - diff: 18.62mlTrain batch 24/32 - 236.1ms/batch - loss: 1.15984 - diff: 18.56mlTrain batch 25/32 - 236.2ms/batch - loss: 1.14845 - diff: 18.38mlTrain batch 26/32 - 235.9ms/batch - loss: 1.14535 - diff: 18.33mlTrain batch 27/32 - 235.8ms/batch - loss: 1.13473 - diff: 18.16mlTrain batch 28/32 - 236.0ms/batch - loss: 1.14314 - diff: 18.29mlTrain batch 29/32 - 235.7ms/batch - loss: 1.13889 - diff: 18.22mlTrain batch 30/32 - 236.5ms/batch - loss: 1.13981 - diff: 18.24mlTrain batch 31/32 - 236.0ms/batch - loss: 1.14342 - diff: 18.29mlTrain batch 32/32 - 85.7ms/batch - loss: 1.30706 - diff: 18.84mlTrain batch 32/32 - 16.5s 85.7ms/batch - loss: 1.30706 - diff: 18.84ml
Test 1.4s: val_loss: 1.34112 - diff: 20.79ml

Epoch 139: current best loss = 1.32748, at epoch 111
Train batch 1/32 - 239.4ms/batch - loss: 1.02965 - diff: 16.47mlTrain batch 2/32 - 236.5ms/batch - loss: 1.12044 - diff: 17.93mlTrain batch 3/32 - 235.7ms/batch - loss: 1.08815 - diff: 17.41mlTrain batch 4/32 - 239.5ms/batch - loss: 1.15494 - diff: 18.48mlTrain batch 5/32 - 237.3ms/batch - loss: 1.16682 - diff: 18.67mlTrain batch 6/32 - 235.7ms/batch - loss: 1.21705 - diff: 19.47mlTrain batch 7/32 - 235.5ms/batch - loss: 1.13773 - diff: 18.20mlTrain batch 8/32 - 235.9ms/batch - loss: 1.24707 - diff: 19.95mlTrain batch 9/32 - 235.4ms/batch - loss: 1.27664 - diff: 20.43mlTrain batch 10/32 - 236.3ms/batch - loss: 1.28465 - diff: 20.55mlTrain batch 11/32 - 236.0ms/batch - loss: 1.25640 - diff: 20.10mlTrain batch 12/32 - 237.0ms/batch - loss: 1.23039 - diff: 19.69mlTrain batch 13/32 - 235.9ms/batch - loss: 1.21912 - diff: 19.51mlTrain batch 14/32 - 236.5ms/batch - loss: 1.20061 - diff: 19.21mlTrain batch 15/32 - 236.0ms/batch - loss: 1.19798 - diff: 19.17mlTrain batch 16/32 - 235.6ms/batch - loss: 1.25819 - diff: 20.13mlTrain batch 17/32 - 235.9ms/batch - loss: 1.25952 - diff: 20.15mlTrain batch 18/32 - 236.7ms/batch - loss: 1.26197 - diff: 20.19mlTrain batch 19/32 - 235.7ms/batch - loss: 1.23760 - diff: 19.80mlTrain batch 20/32 - 236.1ms/batch - loss: 1.23519 - diff: 19.76mlTrain batch 21/32 - 236.2ms/batch - loss: 1.23868 - diff: 19.82mlTrain batch 22/32 - 236.3ms/batch - loss: 1.23982 - diff: 19.84mlTrain batch 23/32 - 235.9ms/batch - loss: 1.23013 - diff: 19.68mlTrain batch 24/32 - 236.4ms/batch - loss: 1.21938 - diff: 19.51mlTrain batch 25/32 - 235.8ms/batch - loss: 1.20818 - diff: 19.33mlTrain batch 26/32 - 237.1ms/batch - loss: 1.19281 - diff: 19.08mlTrain batch 27/32 - 240.2ms/batch - loss: 1.20783 - diff: 19.33mlTrain batch 28/32 - 236.1ms/batch - loss: 1.20110 - diff: 19.22mlTrain batch 29/32 - 235.8ms/batch - loss: 1.19346 - diff: 19.10mlTrain batch 30/32 - 236.1ms/batch - loss: 1.18749 - diff: 19.00mlTrain batch 31/32 - 235.7ms/batch - loss: 1.17928 - diff: 18.87mlTrain batch 32/32 - 86.3ms/batch - loss: 1.19299 - diff: 18.81mlTrain batch 32/32 - 18.7s 86.3ms/batch - loss: 1.19299 - diff: 18.81ml
Test 1.5s: val_loss: 1.43622 - diff: 22.26ml

Epoch 140: current best loss = 1.32748, at epoch 111
Train batch 1/32 - 236.1ms/batch - loss: 1.72347 - diff: 27.58mlTrain batch 2/32 - 239.8ms/batch - loss: 1.31036 - diff: 20.97mlTrain batch 3/32 - 235.4ms/batch - loss: 1.62634 - diff: 26.02mlTrain batch 4/32 - 236.4ms/batch - loss: 1.50945 - diff: 24.15mlTrain batch 5/32 - 236.0ms/batch - loss: 1.47717 - diff: 23.63mlTrain batch 6/32 - 236.7ms/batch - loss: 1.41048 - diff: 22.57mlTrain batch 7/32 - 235.7ms/batch - loss: 1.40337 - diff: 22.45mlTrain batch 8/32 - 235.9ms/batch - loss: 1.35133 - diff: 21.62mlTrain batch 9/32 - 235.3ms/batch - loss: 1.30371 - diff: 20.86mlTrain batch 10/32 - 236.1ms/batch - loss: 1.26142 - diff: 20.18mlTrain batch 11/32 - 235.9ms/batch - loss: 1.22548 - diff: 19.61mlTrain batch 12/32 - 237.0ms/batch - loss: 1.24179 - diff: 19.87mlTrain batch 13/32 - 236.1ms/batch - loss: 1.22702 - diff: 19.63mlTrain batch 14/32 - 235.3ms/batch - loss: 1.22532 - diff: 19.61mlTrain batch 15/32 - 235.9ms/batch - loss: 1.20400 - diff: 19.26mlTrain batch 16/32 - 236.5ms/batch - loss: 1.17639 - diff: 18.82mlTrain batch 17/32 - 235.9ms/batch - loss: 1.17053 - diff: 18.73mlTrain batch 18/32 - 245.8ms/batch - loss: 1.16581 - diff: 18.65mlTrain batch 19/32 - 236.0ms/batch - loss: 1.15768 - diff: 18.52mlTrain batch 20/32 - 237.4ms/batch - loss: 1.14271 - diff: 18.28mlTrain batch 21/32 - 235.6ms/batch - loss: 1.14488 - diff: 18.32mlTrain batch 22/32 - 236.8ms/batch - loss: 1.13852 - diff: 18.22mlTrain batch 23/32 - 235.7ms/batch - loss: 1.22066 - diff: 19.53mlTrain batch 24/32 - 236.0ms/batch - loss: 1.20216 - diff: 19.23mlTrain batch 25/32 - 235.5ms/batch - loss: 1.18830 - diff: 19.01mlTrain batch 26/32 - 235.5ms/batch - loss: 1.18452 - diff: 18.95mlTrain batch 27/32 - 235.8ms/batch - loss: 1.19278 - diff: 19.08mlTrain batch 28/32 - 235.1ms/batch - loss: 1.18697 - diff: 18.99mlTrain batch 29/32 - 236.2ms/batch - loss: 1.18296 - diff: 18.93mlTrain batch 30/32 - 236.9ms/batch - loss: 1.17508 - diff: 18.80mlTrain batch 31/32 - 235.9ms/batch - loss: 1.18525 - diff: 18.96mlTrain batch 32/32 - 77.1ms/batch - loss: 1.22321 - diff: 19.00mlTrain batch 32/32 - 17.3s 77.1ms/batch - loss: 1.22321 - diff: 19.00ml
Test 1.5s: val_loss: 1.36156 - diff: 21.49ml

Epoch 141: current best loss = 1.32748, at epoch 111
Train batch 1/32 - 235.7ms/batch - loss: 1.18707 - diff: 18.99mlTrain batch 2/32 - 236.3ms/batch - loss: 1.06121 - diff: 16.98mlTrain batch 3/32 - 236.4ms/batch - loss: 1.18523 - diff: 18.96mlTrain batch 4/32 - 235.9ms/batch - loss: 1.21109 - diff: 19.38mlTrain batch 5/32 - 235.9ms/batch - loss: 1.05515 - diff: 16.88mlTrain batch 6/32 - 236.4ms/batch - loss: 1.10578 - diff: 17.69mlTrain batch 7/32 - 242.1ms/batch - loss: 1.04488 - diff: 16.72mlTrain batch 8/32 - 236.1ms/batch - loss: 1.06334 - diff: 17.01mlTrain batch 9/32 - 236.3ms/batch - loss: 1.02711 - diff: 16.43mlTrain batch 10/32 - 236.5ms/batch - loss: 0.99520 - diff: 15.92mlTrain batch 11/32 - 235.4ms/batch - loss: 1.02169 - diff: 16.35mlTrain batch 12/32 - 245.2ms/batch - loss: 1.01093 - diff: 16.17mlTrain batch 13/32 - 235.8ms/batch - loss: 1.02215 - diff: 16.35mlTrain batch 14/32 - 236.5ms/batch - loss: 1.01341 - diff: 16.21mlTrain batch 15/32 - 239.3ms/batch - loss: 1.05020 - diff: 16.80mlTrain batch 16/32 - 236.2ms/batch - loss: 1.07226 - diff: 17.16mlTrain batch 17/32 - 239.1ms/batch - loss: 1.10001 - diff: 17.60mlTrain batch 18/32 - 235.7ms/batch - loss: 1.16466 - diff: 18.63mlTrain batch 19/32 - 238.9ms/batch - loss: 1.16163 - diff: 18.59mlTrain batch 20/32 - 236.3ms/batch - loss: 1.19515 - diff: 19.12mlTrain batch 21/32 - 236.6ms/batch - loss: 1.19426 - diff: 19.11mlTrain batch 22/32 - 235.9ms/batch - loss: 1.18003 - diff: 18.88mlTrain batch 23/32 - 236.1ms/batch - loss: 1.19037 - diff: 19.05mlTrain batch 24/32 - 236.3ms/batch - loss: 1.20927 - diff: 19.35mlTrain batch 25/32 - 239.4ms/batch - loss: 1.19420 - diff: 19.11mlTrain batch 26/32 - 236.2ms/batch - loss: 1.18380 - diff: 18.94mlTrain batch 27/32 - 236.0ms/batch - loss: 1.19346 - diff: 19.10mlTrain batch 28/32 - 236.6ms/batch - loss: 1.19473 - diff: 19.12mlTrain batch 29/32 - 235.8ms/batch - loss: 1.20773 - diff: 19.32mlTrain batch 30/32 - 235.9ms/batch - loss: 1.20745 - diff: 19.32mlTrain batch 31/32 - 236.1ms/batch - loss: 1.19656 - diff: 19.15mlTrain batch 32/32 - 77.0ms/batch - loss: 1.24109 - diff: 19.21mlTrain batch 32/32 - 17.4s 77.0ms/batch - loss: 1.24109 - diff: 19.21ml
Test 1.4s: val_loss: 1.51338 - diff: 23.23ml

Epoch 142: current best loss = 1.32748, at epoch 111
Train batch 1/32 - 235.7ms/batch - loss: 1.04509 - diff: 16.72mlTrain batch 2/32 - 258.6ms/batch - loss: 0.96339 - diff: 15.41mlTrain batch 3/32 - 235.3ms/batch - loss: 0.86370 - diff: 13.82mlTrain batch 4/32 - 236.0ms/batch - loss: 1.08415 - diff: 17.35mlTrain batch 5/32 - 236.3ms/batch - loss: 1.09905 - diff: 17.58mlTrain batch 6/32 - 236.0ms/batch - loss: 1.02277 - diff: 16.36mlTrain batch 7/32 - 236.0ms/batch - loss: 1.10892 - diff: 17.74mlTrain batch 8/32 - 236.7ms/batch - loss: 1.20455 - diff: 19.27mlTrain batch 9/32 - 235.7ms/batch - loss: 1.14796 - diff: 18.37mlTrain batch 10/32 - 235.7ms/batch - loss: 1.11293 - diff: 17.81mlTrain batch 11/32 - 235.8ms/batch - loss: 1.09124 - diff: 17.46mlTrain batch 12/32 - 235.8ms/batch - loss: 1.11092 - diff: 17.77mlTrain batch 13/32 - 235.9ms/batch - loss: 1.06231 - diff: 17.00mlTrain batch 14/32 - 236.1ms/batch - loss: 1.05719 - diff: 16.92mlTrain batch 15/32 - 236.5ms/batch - loss: 1.08008 - diff: 17.28mlTrain batch 16/32 - 236.0ms/batch - loss: 1.06726 - diff: 17.08mlTrain batch 17/32 - 235.6ms/batch - loss: 1.08718 - diff: 17.39mlTrain batch 18/32 - 236.8ms/batch - loss: 1.07584 - diff: 17.21mlTrain batch 19/32 - 235.4ms/batch - loss: 1.07823 - diff: 17.25mlTrain batch 20/32 - 236.6ms/batch - loss: 1.12135 - diff: 17.94mlTrain batch 21/32 - 247.0ms/batch - loss: 1.12551 - diff: 18.01mlTrain batch 22/32 - 236.5ms/batch - loss: 1.11463 - diff: 17.83mlTrain batch 23/32 - 236.4ms/batch - loss: 1.11033 - diff: 17.77mlTrain batch 24/32 - 236.6ms/batch - loss: 1.10661 - diff: 17.71mlTrain batch 25/32 - 236.1ms/batch - loss: 1.10289 - diff: 17.65mlTrain batch 26/32 - 236.3ms/batch - loss: 1.10391 - diff: 17.66mlTrain batch 27/32 - 235.6ms/batch - loss: 1.11205 - diff: 17.79mlTrain batch 28/32 - 238.9ms/batch - loss: 1.10427 - diff: 17.67mlTrain batch 29/32 - 236.0ms/batch - loss: 1.09505 - diff: 17.52mlTrain batch 30/32 - 236.6ms/batch - loss: 1.08375 - diff: 17.34mlTrain batch 31/32 - 236.0ms/batch - loss: 1.09927 - diff: 17.59mlTrain batch 32/32 - 76.7ms/batch - loss: 1.18036 - diff: 17.81mlTrain batch 32/32 - 17.6s 76.7ms/batch - loss: 1.18036 - diff: 17.81ml
Test 1.4s: val_loss: 1.46501 - diff: 22.40ml

Epoch 143: current best loss = 1.32748, at epoch 111
Train batch 1/32 - 235.8ms/batch - loss: 0.93578 - diff: 14.97mlTrain batch 2/32 - 242.4ms/batch - loss: 0.86848 - diff: 13.90mlTrain batch 3/32 - 236.3ms/batch - loss: 1.08700 - diff: 17.39mlTrain batch 4/32 - 236.9ms/batch - loss: 1.09499 - diff: 17.52mlTrain batch 5/32 - 236.0ms/batch - loss: 1.07516 - diff: 17.20mlTrain batch 6/32 - 236.4ms/batch - loss: 1.10268 - diff: 17.64mlTrain batch 7/32 - 236.3ms/batch - loss: 1.16100 - diff: 18.58mlTrain batch 8/32 - 236.2ms/batch - loss: 1.14532 - diff: 18.33mlTrain batch 9/32 - 236.5ms/batch - loss: 1.18370 - diff: 18.94mlTrain batch 10/32 - 238.5ms/batch - loss: 1.20613 - diff: 19.30mlTrain batch 11/32 - 236.7ms/batch - loss: 1.19168 - diff: 19.07mlTrain batch 12/32 - 236.6ms/batch - loss: 1.19440 - diff: 19.11mlTrain batch 13/32 - 236.1ms/batch - loss: 1.19528 - diff: 19.12mlTrain batch 14/32 - 236.4ms/batch - loss: 1.18152 - diff: 18.90mlTrain batch 15/32 - 236.3ms/batch - loss: 1.17292 - diff: 18.77mlTrain batch 16/32 - 236.2ms/batch - loss: 1.15276 - diff: 18.44mlTrain batch 17/32 - 239.4ms/batch - loss: 1.12441 - diff: 17.99mlTrain batch 18/32 - 236.0ms/batch - loss: 1.13902 - diff: 18.22mlTrain batch 19/32 - 236.7ms/batch - loss: 1.13543 - diff: 18.17mlTrain batch 20/32 - 236.6ms/batch - loss: 1.15435 - diff: 18.47mlTrain batch 21/32 - 235.7ms/batch - loss: 1.14811 - diff: 18.37mlTrain batch 22/32 - 236.8ms/batch - loss: 1.15328 - diff: 18.45mlTrain batch 23/32 - 235.9ms/batch - loss: 1.17145 - diff: 18.74mlTrain batch 24/32 - 241.6ms/batch - loss: 1.17382 - diff: 18.78mlTrain batch 25/32 - 240.4ms/batch - loss: 1.17060 - diff: 18.73mlTrain batch 26/32 - 236.3ms/batch - loss: 1.15178 - diff: 18.43mlTrain batch 27/32 - 236.0ms/batch - loss: 1.14282 - diff: 18.29mlTrain batch 28/32 - 236.4ms/batch - loss: 1.16228 - diff: 18.60mlTrain batch 29/32 - 235.8ms/batch - loss: 1.15709 - diff: 18.51mlTrain batch 30/32 - 236.2ms/batch - loss: 1.15438 - diff: 18.47mlTrain batch 31/32 - 235.2ms/batch - loss: 1.15808 - diff: 18.53mlTrain batch 32/32 - 83.2ms/batch - loss: 1.27639 - diff: 18.89mlTrain batch 32/32 - 17.7s 83.2ms/batch - loss: 1.27639 - diff: 18.89ml
Test 1.5s: val_loss: 1.41249 - diff: 22.15ml

Epoch 144: current best loss = 1.32748, at epoch 111
Train batch 1/32 - 236.2ms/batch - loss: 1.17268 - diff: 18.76mlTrain batch 2/32 - 236.0ms/batch - loss: 1.21789 - diff: 19.49mlTrain batch 3/32 - 240.7ms/batch - loss: 1.12324 - diff: 17.97mlTrain batch 4/32 - 235.6ms/batch - loss: 1.19364 - diff: 19.10mlTrain batch 5/32 - 236.2ms/batch - loss: 1.27059 - diff: 20.33mlTrain batch 6/32 - 250.7ms/batch - loss: 1.33781 - diff: 21.40mlTrain batch 7/32 - 236.4ms/batch - loss: 1.23209 - diff: 19.71mlTrain batch 8/32 - 236.2ms/batch - loss: 1.23734 - diff: 19.80mlTrain batch 9/32 - 236.3ms/batch - loss: 1.23518 - diff: 19.76mlTrain batch 10/32 - 235.9ms/batch - loss: 1.22354 - diff: 19.58mlTrain batch 11/32 - 236.7ms/batch - loss: 1.22079 - diff: 19.53mlTrain batch 12/32 - 235.7ms/batch - loss: 1.18446 - diff: 18.95mlTrain batch 13/32 - 236.7ms/batch - loss: 1.18057 - diff: 18.89mlTrain batch 14/32 - 235.5ms/batch - loss: 1.18131 - diff: 18.90mlTrain batch 15/32 - 235.7ms/batch - loss: 1.23360 - diff: 19.74mlTrain batch 16/32 - 235.6ms/batch - loss: 1.20748 - diff: 19.32mlTrain batch 17/32 - 235.7ms/batch - loss: 1.20646 - diff: 19.30mlTrain batch 18/32 - 236.0ms/batch - loss: 1.22590 - diff: 19.61mlTrain batch 19/32 - 238.3ms/batch - loss: 1.23144 - diff: 19.70mlTrain batch 20/32 - 235.6ms/batch - loss: 1.24899 - diff: 19.98mlTrain batch 21/32 - 236.7ms/batch - loss: 1.27592 - diff: 20.41mlTrain batch 22/32 - 236.5ms/batch - loss: 1.27629 - diff: 20.42mlTrain batch 23/32 - 236.2ms/batch - loss: 1.26444 - diff: 20.23mlTrain batch 24/32 - 236.1ms/batch - loss: 1.26085 - diff: 20.17mlTrain batch 25/32 - 236.3ms/batch - loss: 1.25403 - diff: 20.06mlTrain batch 26/32 - 235.9ms/batch - loss: 1.23934 - diff: 19.83mlTrain batch 27/32 - 236.2ms/batch - loss: 1.22566 - diff: 19.61mlTrain batch 28/32 - 236.1ms/batch - loss: 1.21543 - diff: 19.45mlTrain batch 29/32 - 236.6ms/batch - loss: 1.20515 - diff: 19.28mlTrain batch 30/32 - 236.2ms/batch - loss: 1.20326 - diff: 19.25mlTrain batch 31/32 - 236.6ms/batch - loss: 1.22862 - diff: 19.66mlTrain batch 32/32 - 84.3ms/batch - loss: 1.25823 - diff: 19.66mlTrain batch 32/32 - 17.0s 84.3ms/batch - loss: 1.25823 - diff: 19.66ml
Test 1.6s: val_loss: 1.44078 - diff: 22.08ml
Epoch   145: reducing learning rate of group 0 to 3.1250e-05.

Epoch 145: current best loss = 1.32748, at epoch 111
Train batch 1/32 - 236.0ms/batch - loss: 0.95920 - diff: 15.35mlTrain batch 2/32 - 236.3ms/batch - loss: 1.11778 - diff: 17.88mlTrain batch 3/32 - 236.1ms/batch - loss: 1.13876 - diff: 18.22mlTrain batch 4/32 - 236.0ms/batch - loss: 1.08367 - diff: 17.34mlTrain batch 5/32 - 235.5ms/batch - loss: 1.08148 - diff: 17.30mlTrain batch 6/32 - 236.6ms/batch - loss: 1.12745 - diff: 18.04mlTrain batch 7/32 - 236.0ms/batch - loss: 1.12144 - diff: 17.94mlTrain batch 8/32 - 236.0ms/batch - loss: 1.09251 - diff: 17.48mlTrain batch 9/32 - 236.2ms/batch - loss: 1.13128 - diff: 18.10mlTrain batch 10/32 - 241.0ms/batch - loss: 1.11822 - diff: 17.89mlTrain batch 11/32 - 235.6ms/batch - loss: 1.11532 - diff: 17.85mlTrain batch 12/32 - 236.5ms/batch - loss: 1.10060 - diff: 17.61mlTrain batch 13/32 - 240.2ms/batch - loss: 1.12438 - diff: 17.99mlTrain batch 14/32 - 235.5ms/batch - loss: 1.11093 - diff: 17.77mlTrain batch 15/32 - 236.2ms/batch - loss: 1.11557 - diff: 17.85mlTrain batch 16/32 - 235.6ms/batch - loss: 1.08757 - diff: 17.40mlTrain batch 17/32 - 236.4ms/batch - loss: 1.09257 - diff: 17.48mlTrain batch 18/32 - 235.0ms/batch - loss: 1.08272 - diff: 17.32mlTrain batch 19/32 - 235.5ms/batch - loss: 1.08489 - diff: 17.36mlTrain batch 20/32 - 235.7ms/batch - loss: 1.07350 - diff: 17.18mlTrain batch 21/32 - 236.9ms/batch - loss: 1.06829 - diff: 17.09mlTrain batch 22/32 - 236.2ms/batch - loss: 1.06696 - diff: 17.07mlTrain batch 23/32 - 235.4ms/batch - loss: 1.05783 - diff: 16.93mlTrain batch 24/32 - 235.9ms/batch - loss: 1.05749 - diff: 16.92mlTrain batch 25/32 - 236.0ms/batch - loss: 1.06996 - diff: 17.12mlTrain batch 26/32 - 235.7ms/batch - loss: 1.06792 - diff: 17.09mlTrain batch 27/32 - 236.6ms/batch - loss: 1.07721 - diff: 17.24mlTrain batch 28/32 - 235.8ms/batch - loss: 1.09146 - diff: 17.46mlTrain batch 29/32 - 236.1ms/batch - loss: 1.10258 - diff: 17.64mlTrain batch 30/32 - 235.5ms/batch - loss: 1.11966 - diff: 17.91mlTrain batch 31/32 - 236.3ms/batch - loss: 1.12294 - diff: 17.97mlTrain batch 32/32 - 76.6ms/batch - loss: 1.16430 - diff: 18.02mlTrain batch 32/32 - 16.1s 76.6ms/batch - loss: 1.16430 - diff: 18.02ml
Test 1.4s: val_loss: 1.43992 - diff: 21.52ml

Epoch 146: current best loss = 1.32748, at epoch 111
Train batch 1/32 - 236.1ms/batch - loss: 1.04957 - diff: 16.79mlTrain batch 2/32 - 242.6ms/batch - loss: 1.92869 - diff: 30.86mlTrain batch 3/32 - 235.7ms/batch - loss: 1.74700 - diff: 27.95mlTrain batch 4/32 - 236.5ms/batch - loss: 1.62443 - diff: 25.99mlTrain batch 5/32 - 235.4ms/batch - loss: 1.54246 - diff: 24.68mlTrain batch 6/32 - 248.5ms/batch - loss: 1.44011 - diff: 23.04mlTrain batch 7/32 - 235.9ms/batch - loss: 1.44792 - diff: 23.17mlTrain batch 8/32 - 236.5ms/batch - loss: 1.40041 - diff: 22.41mlTrain batch 9/32 - 236.2ms/batch - loss: 1.38145 - diff: 22.10mlTrain batch 10/32 - 239.1ms/batch - loss: 1.34782 - diff: 21.57mlTrain batch 11/32 - 236.2ms/batch - loss: 1.30470 - diff: 20.88mlTrain batch 12/32 - 236.6ms/batch - loss: 1.30032 - diff: 20.81mlTrain batch 13/32 - 236.2ms/batch - loss: 1.24368 - diff: 19.90mlTrain batch 14/32 - 236.6ms/batch - loss: 1.21185 - diff: 19.39mlTrain batch 15/32 - 236.6ms/batch - loss: 1.17269 - diff: 18.76mlTrain batch 16/32 - 236.8ms/batch - loss: 1.17087 - diff: 18.73mlTrain batch 17/32 - 236.3ms/batch - loss: 1.16856 - diff: 18.70mlTrain batch 18/32 - 236.5ms/batch - loss: 1.16350 - diff: 18.62mlTrain batch 19/32 - 238.9ms/batch - loss: 1.14968 - diff: 18.39mlTrain batch 20/32 - 236.8ms/batch - loss: 1.12650 - diff: 18.02mlTrain batch 21/32 - 237.0ms/batch - loss: 1.11472 - diff: 17.84mlTrain batch 22/32 - 236.2ms/batch - loss: 1.11292 - diff: 17.81mlTrain batch 23/32 - 236.7ms/batch - loss: 1.18575 - diff: 18.97mlTrain batch 24/32 - 236.7ms/batch - loss: 1.18682 - diff: 18.99mlTrain batch 25/32 - 236.5ms/batch - loss: 1.17018 - diff: 18.72mlTrain batch 26/32 - 236.9ms/batch - loss: 1.17020 - diff: 18.72mlTrain batch 27/32 - 236.7ms/batch - loss: 1.15149 - diff: 18.42mlTrain batch 28/32 - 236.3ms/batch - loss: 1.15497 - diff: 18.48mlTrain batch 29/32 - 236.6ms/batch - loss: 1.15911 - diff: 18.55mlTrain batch 30/32 - 236.7ms/batch - loss: 1.16973 - diff: 18.72mlTrain batch 31/32 - 236.9ms/batch - loss: 1.16379 - diff: 18.62mlTrain batch 32/32 - 76.7ms/batch - loss: 1.17936 - diff: 18.57mlTrain batch 32/32 - 15.1s 76.7ms/batch - loss: 1.17936 - diff: 18.57ml
Test 1.4s: val_loss: 1.44381 - diff: 22.15ml

Epoch 147: current best loss = 1.32748, at epoch 111
Train batch 1/32 - 236.5ms/batch - loss: 0.92420 - diff: 14.79mlTrain batch 2/32 - 236.2ms/batch - loss: 0.88683 - diff: 14.19mlTrain batch 3/32 - 236.9ms/batch - loss: 0.99530 - diff: 15.92mlTrain batch 4/32 - 236.5ms/batch - loss: 0.91461 - diff: 14.63mlTrain batch 5/32 - 236.9ms/batch - loss: 1.08402 - diff: 17.34mlTrain batch 6/32 - 236.6ms/batch - loss: 1.17007 - diff: 18.72mlTrain batch 7/32 - 236.7ms/batch - loss: 1.14903 - diff: 18.38mlTrain batch 8/32 - 236.2ms/batch - loss: 1.16211 - diff: 18.59mlTrain batch 9/32 - 236.8ms/batch - loss: 1.10747 - diff: 17.72mlTrain batch 10/32 - 236.7ms/batch - loss: 1.17019 - diff: 18.72mlTrain batch 11/32 - 236.8ms/batch - loss: 1.17449 - diff: 18.79mlTrain batch 12/32 - 236.4ms/batch - loss: 1.16953 - diff: 18.71mlTrain batch 13/32 - 236.7ms/batch - loss: 1.16064 - diff: 18.57mlTrain batch 14/32 - 236.4ms/batch - loss: 1.19157 - diff: 19.07mlTrain batch 15/32 - 236.8ms/batch - loss: 1.19506 - diff: 19.12mlTrain batch 16/32 - 236.9ms/batch - loss: 1.18577 - diff: 18.97mlTrain batch 17/32 - 236.2ms/batch - loss: 1.19279 - diff: 19.08mlTrain batch 18/32 - 236.4ms/batch - loss: 1.21299 - diff: 19.41mlTrain batch 19/32 - 236.2ms/batch - loss: 1.20196 - diff: 19.23mlTrain batch 20/32 - 236.5ms/batch - loss: 1.18209 - diff: 18.91mlTrain batch 21/32 - 236.7ms/batch - loss: 1.17742 - diff: 18.84mlTrain batch 22/32 - 236.9ms/batch - loss: 1.17125 - diff: 18.74mlTrain batch 23/32 - 236.4ms/batch - loss: 1.16520 - diff: 18.64mlTrain batch 24/32 - 236.4ms/batch - loss: 1.15455 - diff: 18.47mlTrain batch 25/32 - 236.5ms/batch - loss: 1.14852 - diff: 18.38mlTrain batch 26/32 - 236.2ms/batch - loss: 1.13470 - diff: 18.16mlTrain batch 27/32 - 237.0ms/batch - loss: 1.14413 - diff: 18.31mlTrain batch 28/32 - 237.0ms/batch - loss: 1.14084 - diff: 18.25mlTrain batch 29/32 - 236.5ms/batch - loss: 1.13723 - diff: 18.20mlTrain batch 30/32 - 236.4ms/batch - loss: 1.13338 - diff: 18.13mlTrain batch 31/32 - 236.3ms/batch - loss: 1.14637 - diff: 18.34mlTrain batch 32/32 - 76.6ms/batch - loss: 1.15813 - diff: 18.28mlTrain batch 32/32 - 15.2s 76.6ms/batch - loss: 1.15813 - diff: 18.28ml
Test 1.5s: val_loss: 1.47085 - diff: 22.43ml

Epoch 148: current best loss = 1.32748, at epoch 111
Train batch 1/32 - 236.3ms/batch - loss: 0.87735 - diff: 14.04mlTrain batch 2/32 - 236.5ms/batch - loss: 1.44062 - diff: 23.05mlTrain batch 3/32 - 236.1ms/batch - loss: 1.33694 - diff: 21.39mlTrain batch 4/32 - 251.9ms/batch - loss: 1.18449 - diff: 18.95mlTrain batch 5/32 - 236.6ms/batch - loss: 1.10368 - diff: 17.66mlTrain batch 6/32 - 243.7ms/batch - loss: 1.09454 - diff: 17.51mlTrain batch 7/32 - 236.7ms/batch - loss: 1.11212 - diff: 17.79mlTrain batch 8/32 - 235.9ms/batch - loss: 1.08950 - diff: 17.43mlTrain batch 9/32 - 236.5ms/batch - loss: 1.07025 - diff: 17.12mlTrain batch 10/32 - 236.5ms/batch - loss: 1.06679 - diff: 17.07mlTrain batch 11/32 - 236.2ms/batch - loss: 1.05660 - diff: 16.91mlTrain batch 12/32 - 236.6ms/batch - loss: 1.10902 - diff: 17.74mlTrain batch 13/32 - 236.2ms/batch - loss: 1.10672 - diff: 17.71mlTrain batch 14/32 - 236.3ms/batch - loss: 1.10060 - diff: 17.61mlTrain batch 15/32 - 236.5ms/batch - loss: 1.11830 - diff: 17.89mlTrain batch 16/32 - 236.4ms/batch - loss: 1.10360 - diff: 17.66mlTrain batch 17/32 - 236.5ms/batch - loss: 1.10617 - diff: 17.70mlTrain batch 18/32 - 236.8ms/batch - loss: 1.10485 - diff: 17.68mlTrain batch 19/32 - 236.3ms/batch - loss: 1.08790 - diff: 17.41mlTrain batch 20/32 - 236.7ms/batch - loss: 1.11160 - diff: 17.79mlTrain batch 21/32 - 236.4ms/batch - loss: 1.12437 - diff: 17.99mlTrain batch 22/32 - 236.7ms/batch - loss: 1.11549 - diff: 17.85mlTrain batch 23/32 - 236.6ms/batch - loss: 1.13074 - diff: 18.09mlTrain batch 24/32 - 236.4ms/batch - loss: 1.14969 - diff: 18.39mlTrain batch 25/32 - 236.9ms/batch - loss: 1.15294 - diff: 18.45mlTrain batch 26/32 - 236.4ms/batch - loss: 1.15460 - diff: 18.47mlTrain batch 27/32 - 236.5ms/batch - loss: 1.15991 - diff: 18.56mlTrain batch 28/32 - 236.9ms/batch - loss: 1.16316 - diff: 18.61mlTrain batch 29/32 - 236.3ms/batch - loss: 1.15137 - diff: 18.42mlTrain batch 30/32 - 236.2ms/batch - loss: 1.13468 - diff: 18.15mlTrain batch 31/32 - 236.4ms/batch - loss: 1.13525 - diff: 18.16mlTrain batch 32/32 - 76.5ms/batch - loss: 1.15173 - diff: 18.12mlTrain batch 32/32 - 15.2s 76.5ms/batch - loss: 1.15173 - diff: 18.12ml
Test 1.5s: val_loss: 1.40072 - diff: 21.85ml

Epoch 149: current best loss = 1.32748, at epoch 111
Train batch 1/32 - 236.4ms/batch - loss: 0.91265 - diff: 14.60mlTrain batch 2/32 - 236.3ms/batch - loss: 0.88338 - diff: 14.13mlTrain batch 3/32 - 236.7ms/batch - loss: 0.91601 - diff: 14.66mlTrain batch 4/32 - 236.7ms/batch - loss: 0.87170 - diff: 13.95mlTrain batch 5/32 - 236.9ms/batch - loss: 0.96723 - diff: 15.48mlTrain batch 6/32 - 236.8ms/batch - loss: 0.99714 - diff: 15.95mlTrain batch 7/32 - 236.4ms/batch - loss: 1.00472 - diff: 16.08mlTrain batch 8/32 - 236.3ms/batch - loss: 1.04518 - diff: 16.72mlTrain batch 9/32 - 236.6ms/batch - loss: 1.01230 - diff: 16.20mlTrain batch 10/32 - 237.0ms/batch - loss: 1.02184 - diff: 16.35mlTrain batch 11/32 - 236.2ms/batch - loss: 1.04223 - diff: 16.68mlTrain batch 12/32 - 236.4ms/batch - loss: 1.04033 - diff: 16.65mlTrain batch 13/32 - 236.3ms/batch - loss: 1.06551 - diff: 17.05mlTrain batch 14/32 - 236.1ms/batch - loss: 1.04974 - diff: 16.80mlTrain batch 15/32 - 236.2ms/batch - loss: 1.05256 - diff: 16.84mlTrain batch 16/32 - 236.5ms/batch - loss: 1.06649 - diff: 17.06mlTrain batch 17/32 - 236.9ms/batch - loss: 1.08305 - diff: 17.33mlTrain batch 18/32 - 236.9ms/batch - loss: 1.15771 - diff: 18.52mlTrain batch 19/32 - 237.0ms/batch - loss: 1.16124 - diff: 18.58mlTrain batch 20/32 - 236.3ms/batch - loss: 1.15957 - diff: 18.55mlTrain batch 21/32 - 237.0ms/batch - loss: 1.16873 - diff: 18.70mlTrain batch 22/32 - 236.4ms/batch - loss: 1.18525 - diff: 18.96mlTrain batch 23/32 - 236.4ms/batch - loss: 1.17261 - diff: 18.76mlTrain batch 24/32 - 236.2ms/batch - loss: 1.16326 - diff: 18.61mlTrain batch 25/32 - 236.4ms/batch - loss: 1.15429 - diff: 18.47mlTrain batch 26/32 - 236.4ms/batch - loss: 1.14817 - diff: 18.37mlTrain batch 27/32 - 236.9ms/batch - loss: 1.14409 - diff: 18.31mlTrain batch 28/32 - 236.5ms/batch - loss: 1.13329 - diff: 18.13mlTrain batch 29/32 - 236.6ms/batch - loss: 1.11848 - diff: 17.90mlTrain batch 30/32 - 236.5ms/batch - loss: 1.12440 - diff: 17.99mlTrain batch 31/32 - 236.5ms/batch - loss: 1.13500 - diff: 18.16mlTrain batch 32/32 - 82.3ms/batch - loss: 1.22506 - diff: 18.41mlTrain batch 32/32 - 15.6s 82.3ms/batch - loss: 1.22506 - diff: 18.41ml
Test 1.4s: val_loss: 1.40538 - diff: 21.78ml

