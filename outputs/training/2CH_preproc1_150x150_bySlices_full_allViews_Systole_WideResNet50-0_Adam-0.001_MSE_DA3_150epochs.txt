nohup: ignoring input
Running experiment 2CH_preproc1_150x150_bySlices_dataset_allViews_Systole_WideResNet50_0_Adam-0.001_MSE_DA3
Going to train with the GPU in the slot 0 -> device model: GeForce RTX 2080
Model architecture:
 WideResNet50_0(
  (first_conv): Conv2d(30, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (pretrained_block): Sequential(
    (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): ReLU(inplace=True)
    (2): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (3): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (4): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (5): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (4): Bottleneck(
        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (5): Bottleneck(
        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
  )
  (reduction_block): Sequential(
    (0): AdaptiveAvgPool2d(output_size=(1, 1))
    (1): Flatten()
  )
  (dense_block): Sequential(
    (0): Linear(in_features=1024, out_features=512, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.4, inplace=False)
    (3): Linear(in_features=512, out_features=1, bias=True)
  )
) 


############################
# TRAIN PHASE:  150 epochs #
############################

Epoch 0: 
Train batch 1/32 - 189.2ms/batch - loss: 230.86697 - diff: 57.17mlTrain batch 2/32 - 170.3ms/batch - loss: 365.91164 - diff: 66.15mlTrain batch 3/32 - 179.2ms/batch - loss: 333.69100 - diff: 64.27mlTrain batch 4/32 - 171.0ms/batch - loss: 308.65370 - diff: 62.21mlTrain batch 5/32 - 170.9ms/batch - loss: 315.41311 - diff: 63.01mlTrain batch 6/32 - 170.9ms/batch - loss: 296.02207 - diff: 61.15mlTrain batch 7/32 - 171.0ms/batch - loss: 300.58509 - diff: 61.94mlTrain batch 8/32 - 171.1ms/batch - loss: 295.61967 - diff: 61.75mlTrain batch 9/32 - 171.0ms/batch - loss: 325.11006 - diff: 64.18mlTrain batch 10/32 - 171.3ms/batch - loss: 375.46039 - diff: 67.06mlTrain batch 11/32 - 171.0ms/batch - loss: 385.66146 - diff: 68.06mlTrain batch 12/32 - 171.3ms/batch - loss: 394.31574 - diff: 68.71mlTrain batch 13/32 - 171.1ms/batch - loss: 386.59944 - diff: 67.95mlTrain batch 14/32 - 171.1ms/batch - loss: 381.64306 - diff: 67.59mlTrain batch 15/32 - 171.2ms/batch - loss: 386.19139 - diff: 67.81mlTrain batch 16/32 - 170.9ms/batch - loss: 433.36686 - diff: 68.79mlTrain batch 17/32 - 171.0ms/batch - loss: 426.64045 - diff: 68.29mlTrain batch 18/32 - 171.2ms/batch - loss: 423.87329 - diff: 68.43mlTrain batch 19/32 - 171.0ms/batch - loss: 414.59728 - diff: 67.89mlTrain batch 20/32 - 171.2ms/batch - loss: 401.97854 - diff: 66.70mlTrain batch 21/32 - 170.9ms/batch - loss: 399.10354 - diff: 66.75mlTrain batch 22/32 - 171.3ms/batch - loss: 398.65621 - diff: 66.88mlTrain batch 23/32 - 171.3ms/batch - loss: 410.62643 - diff: 67.66mlTrain batch 24/32 - 171.1ms/batch - loss: 409.98831 - diff: 67.52mlTrain batch 25/32 - 171.3ms/batch - loss: 413.77150 - diff: 67.63mlTrain batch 26/32 - 171.2ms/batch - loss: 409.12843 - diff: 67.35mlTrain batch 27/32 - 171.0ms/batch - loss: 401.42762 - diff: 66.51mlTrain batch 28/32 - 171.3ms/batch - loss: 395.28387 - diff: 65.92mlTrain batch 29/32 - 171.3ms/batch - loss: 392.32254 - diff: 65.91mlTrain batch 30/32 - 171.3ms/batch - loss: 387.46538 - diff: 65.52mlTrain batch 31/32 - 171.2ms/batch - loss: 382.10989 - diff: 65.09mlTrain batch 32/32 - 52.0ms/batch - loss: 381.52982 - diff: 64.77mlTrain batch 32/32 - 10.4s 52.0ms/batch - loss: 381.52982 - diff: 64.77ml
Test 1.1s: val_loss: 245.49689 - diff: 49.29ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Systole_WideResNet50_0_Adam-0.001_MSE_DA3_best

Epoch 1: current best loss = 245.49689, at epoch 0
Train batch 1/32 - 171.3ms/batch - loss: 252.20662 - diff: 53.46mlTrain batch 2/32 - 170.8ms/batch - loss: 284.32941 - diff: 56.58mlTrain batch 3/32 - 171.6ms/batch - loss: 255.57900 - diff: 52.51mlTrain batch 4/32 - 171.3ms/batch - loss: 251.50419 - diff: 52.58mlTrain batch 5/32 - 171.1ms/batch - loss: 233.99538 - diff: 50.40mlTrain batch 6/32 - 171.6ms/batch - loss: 211.37398 - diff: 47.54mlTrain batch 7/32 - 171.4ms/batch - loss: 196.52740 - diff: 45.76mlTrain batch 8/32 - 171.8ms/batch - loss: 206.14171 - diff: 46.67mlTrain batch 9/32 - 171.4ms/batch - loss: 219.31646 - diff: 47.43mlTrain batch 10/32 - 171.8ms/batch - loss: 201.95124 - diff: 44.89mlTrain batch 11/32 - 171.7ms/batch - loss: 189.61994 - diff: 43.39mlTrain batch 12/32 - 171.9ms/batch - loss: 192.94103 - diff: 43.37mlTrain batch 13/32 - 171.4ms/batch - loss: 193.26316 - diff: 43.35mlTrain batch 14/32 - 173.9ms/batch - loss: 190.45511 - diff: 43.16mlTrain batch 15/32 - 194.9ms/batch - loss: 184.63840 - diff: 42.05mlTrain batch 16/32 - 189.9ms/batch - loss: 175.41168 - diff: 40.73mlTrain batch 17/32 - 187.7ms/batch - loss: 168.24665 - diff: 39.59mlTrain batch 18/32 - 188.5ms/batch - loss: 167.30588 - diff: 38.96mlTrain batch 19/32 - 189.8ms/batch - loss: 167.29949 - diff: 38.91mlTrain batch 20/32 - 185.4ms/batch - loss: 168.39295 - diff: 38.65mlTrain batch 21/32 - 189.7ms/batch - loss: 165.96959 - diff: 38.06mlTrain batch 22/32 - 187.3ms/batch - loss: 161.04154 - diff: 37.36mlTrain batch 23/32 - 190.4ms/batch - loss: 160.95207 - diff: 37.30mlTrain batch 24/32 - 186.2ms/batch - loss: 161.41694 - diff: 37.28mlTrain batch 25/32 - 172.0ms/batch - loss: 159.29322 - diff: 36.98mlTrain batch 26/32 - 171.8ms/batch - loss: 187.76008 - diff: 37.97mlTrain batch 27/32 - 172.0ms/batch - loss: 189.05689 - diff: 38.06mlTrain batch 28/32 - 171.8ms/batch - loss: 193.54145 - diff: 38.21mlTrain batch 29/32 - 171.6ms/batch - loss: 191.81231 - diff: 37.97mlTrain batch 30/32 - 171.7ms/batch - loss: 187.89337 - diff: 37.48mlTrain batch 31/32 - 171.7ms/batch - loss: 183.38670 - diff: 36.97mlTrain batch 32/32 - 52.3ms/batch - loss: 182.36118 - diff: 36.79mlTrain batch 32/32 - 10.7s 52.3ms/batch - loss: 182.36118 - diff: 36.79ml
Test 1.1s: val_loss: 94.23166 - diff: 25.85ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Systole_WideResNet50_0_Adam-0.001_MSE_DA3_best

Epoch 2: current best loss = 94.23166, at epoch 1
Train batch 1/32 - 171.9ms/batch - loss: 71.02946 - diff: 24.83mlTrain batch 2/32 - 171.8ms/batch - loss: 112.78762 - diff: 29.70mlTrain batch 3/32 - 171.6ms/batch - loss: 119.34049 - diff: 30.64mlTrain batch 4/32 - 171.9ms/batch - loss: 109.83834 - diff: 29.22mlTrain batch 5/32 - 171.6ms/batch - loss: 101.33802 - diff: 28.72mlTrain batch 6/32 - 171.8ms/batch - loss: 101.42797 - diff: 28.20mlTrain batch 7/32 - 171.5ms/batch - loss: 96.92153 - diff: 28.17mlTrain batch 8/32 - 171.9ms/batch - loss: 174.50499 - diff: 30.73mlTrain batch 9/32 - 171.8ms/batch - loss: 170.68997 - diff: 31.06mlTrain batch 10/32 - 172.0ms/batch - loss: 159.45197 - diff: 30.37mlTrain batch 11/32 - 171.5ms/batch - loss: 150.29274 - diff: 29.90mlTrain batch 12/32 - 171.8ms/batch - loss: 143.44486 - diff: 29.70mlTrain batch 13/32 - 171.9ms/batch - loss: 136.37427 - diff: 29.27mlTrain batch 14/32 - 171.6ms/batch - loss: 132.33681 - diff: 29.17mlTrain batch 15/32 - 171.8ms/batch - loss: 127.93308 - diff: 28.99mlTrain batch 16/32 - 172.0ms/batch - loss: 121.67022 - diff: 28.19mlTrain batch 17/32 - 172.1ms/batch - loss: 117.95196 - diff: 27.93mlTrain batch 18/32 - 172.1ms/batch - loss: 115.41712 - diff: 27.81mlTrain batch 19/32 - 172.1ms/batch - loss: 118.74483 - diff: 28.27mlTrain batch 20/32 - 172.1ms/batch - loss: 117.58565 - diff: 28.40mlTrain batch 21/32 - 171.6ms/batch - loss: 127.33724 - diff: 29.29mlTrain batch 22/32 - 172.0ms/batch - loss: 124.67503 - diff: 29.15mlTrain batch 23/32 - 171.6ms/batch - loss: 121.83701 - diff: 29.04mlTrain batch 24/32 - 172.1ms/batch - loss: 120.34878 - diff: 29.08mlTrain batch 25/32 - 171.8ms/batch - loss: 117.58215 - diff: 28.90mlTrain batch 26/32 - 172.1ms/batch - loss: 115.62133 - diff: 28.91mlTrain batch 27/32 - 172.3ms/batch - loss: 115.31973 - diff: 28.91mlTrain batch 28/32 - 172.1ms/batch - loss: 115.64873 - diff: 29.07mlTrain batch 29/32 - 172.1ms/batch - loss: 115.88515 - diff: 28.97mlTrain batch 30/32 - 172.2ms/batch - loss: 116.19600 - diff: 29.11mlTrain batch 31/32 - 172.0ms/batch - loss: 116.49638 - diff: 29.25mlTrain batch 32/32 - 52.5ms/batch - loss: 120.24703 - diff: 29.29mlTrain batch 32/32 - 10.5s 52.5ms/batch - loss: 120.24703 - diff: 29.29ml
Test 1.1s: val_loss: 93.67937 - diff: 27.35ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Systole_WideResNet50_0_Adam-0.001_MSE_DA3_best

Epoch 3: current best loss = 93.67937, at epoch 2
Train batch 1/32 - 187.8ms/batch - loss: 144.81377 - diff: 32.79mlTrain batch 2/32 - 172.1ms/batch - loss: 436.96233 - diff: 40.88mlTrain batch 3/32 - 171.6ms/batch - loss: 349.32339 - diff: 39.75mlTrain batch 4/32 - 172.3ms/batch - loss: 273.42705 - diff: 35.03mlTrain batch 5/32 - 172.3ms/batch - loss: 248.60092 - diff: 35.33mlTrain batch 6/32 - 172.3ms/batch - loss: 217.25743 - diff: 33.34mlTrain batch 7/32 - 172.2ms/batch - loss: 192.15041 - diff: 31.43mlTrain batch 8/32 - 172.1ms/batch - loss: 177.25240 - diff: 30.95mlTrain batch 9/32 - 172.1ms/batch - loss: 169.31099 - diff: 31.14mlTrain batch 10/32 - 172.3ms/batch - loss: 156.44737 - diff: 30.27mlTrain batch 11/32 - 172.2ms/batch - loss: 148.75294 - diff: 30.02mlTrain batch 12/32 - 172.2ms/batch - loss: 142.11941 - diff: 29.89mlTrain batch 13/32 - 172.3ms/batch - loss: 137.26530 - diff: 29.57mlTrain batch 14/32 - 172.4ms/batch - loss: 132.09428 - diff: 29.62mlTrain batch 15/32 - 172.2ms/batch - loss: 125.76831 - diff: 29.03mlTrain batch 16/32 - 172.3ms/batch - loss: 124.09984 - diff: 28.79mlTrain batch 17/32 - 172.1ms/batch - loss: 122.04568 - diff: 28.84mlTrain batch 18/32 - 172.3ms/batch - loss: 121.60978 - diff: 28.92mlTrain batch 19/32 - 172.5ms/batch - loss: 119.46580 - diff: 28.86mlTrain batch 20/32 - 172.3ms/batch - loss: 123.77975 - diff: 29.61mlTrain batch 21/32 - 172.4ms/batch - loss: 122.77971 - diff: 29.82mlTrain batch 22/32 - 172.2ms/batch - loss: 118.49296 - diff: 29.37mlTrain batch 23/32 - 172.3ms/batch - loss: 114.66902 - diff: 28.90mlTrain batch 24/32 - 172.3ms/batch - loss: 111.64599 - diff: 28.63mlTrain batch 25/32 - 172.4ms/batch - loss: 110.27293 - diff: 28.51mlTrain batch 26/32 - 172.4ms/batch - loss: 114.64133 - diff: 28.63mlTrain batch 27/32 - 172.5ms/batch - loss: 113.92827 - diff: 28.63mlTrain batch 28/32 - 172.3ms/batch - loss: 118.77796 - diff: 29.13mlTrain batch 29/32 - 172.6ms/batch - loss: 115.67100 - diff: 28.70mlTrain batch 30/32 - 172.2ms/batch - loss: 113.31730 - diff: 28.50mlTrain batch 31/32 - 172.3ms/batch - loss: 111.53915 - diff: 28.37mlTrain batch 32/32 - 52.6ms/batch - loss: 123.83169 - diff: 28.71mlTrain batch 32/32 - 10.4s 52.6ms/batch - loss: 123.83169 - diff: 28.71ml
Test 1.1s: val_loss: 94.58687 - diff: 27.79ml

Epoch 4: current best loss = 93.67937, at epoch 2
Train batch 1/32 - 172.3ms/batch - loss: 138.71091 - diff: 33.73mlTrain batch 2/32 - 172.4ms/batch - loss: 93.58916 - diff: 28.87mlTrain batch 3/32 - 172.1ms/batch - loss: 304.34983 - diff: 36.43mlTrain batch 4/32 - 172.2ms/batch - loss: 240.47560 - diff: 33.30mlTrain batch 5/32 - 172.3ms/batch - loss: 197.21692 - diff: 29.79mlTrain batch 6/32 - 172.2ms/batch - loss: 173.44612 - diff: 29.07mlTrain batch 7/32 - 172.3ms/batch - loss: 156.25188 - diff: 28.02mlTrain batch 8/32 - 172.4ms/batch - loss: 143.48312 - diff: 26.99mlTrain batch 9/32 - 172.2ms/batch - loss: 151.77841 - diff: 29.11mlTrain batch 10/32 - 172.3ms/batch - loss: 166.52169 - diff: 30.45mlTrain batch 11/32 - 172.4ms/batch - loss: 161.83885 - diff: 30.42mlTrain batch 12/32 - 172.5ms/batch - loss: 154.60466 - diff: 30.41mlTrain batch 13/32 - 172.2ms/batch - loss: 162.36771 - diff: 31.22mlTrain batch 14/32 - 172.6ms/batch - loss: 155.54093 - diff: 30.79mlTrain batch 15/32 - 172.3ms/batch - loss: 148.49869 - diff: 30.38mlTrain batch 16/32 - 172.3ms/batch - loss: 143.44009 - diff: 30.10mlTrain batch 17/32 - 172.2ms/batch - loss: 139.91030 - diff: 29.85mlTrain batch 18/32 - 172.2ms/batch - loss: 137.64154 - diff: 29.90mlTrain batch 19/32 - 172.3ms/batch - loss: 137.28305 - diff: 30.02mlTrain batch 20/32 - 172.3ms/batch - loss: 135.19693 - diff: 30.19mlTrain batch 21/32 - 172.3ms/batch - loss: 132.33599 - diff: 30.14mlTrain batch 22/32 - 172.4ms/batch - loss: 129.24813 - diff: 29.89mlTrain batch 23/32 - 172.2ms/batch - loss: 127.94020 - diff: 29.94mlTrain batch 24/32 - 172.3ms/batch - loss: 123.32297 - diff: 29.28mlTrain batch 25/32 - 172.5ms/batch - loss: 120.57248 - diff: 29.15mlTrain batch 26/32 - 172.2ms/batch - loss: 120.41610 - diff: 29.17mlTrain batch 27/32 - 172.4ms/batch - loss: 119.57334 - diff: 29.06mlTrain batch 28/32 - 172.6ms/batch - loss: 116.64340 - diff: 28.75mlTrain batch 29/32 - 172.4ms/batch - loss: 114.84952 - diff: 28.58mlTrain batch 30/32 - 172.6ms/batch - loss: 117.06013 - diff: 28.93mlTrain batch 31/32 - 172.4ms/batch - loss: 115.82245 - diff: 29.00mlTrain batch 32/32 - 52.9ms/batch - loss: 116.05059 - diff: 28.93mlTrain batch 32/32 - 10.5s 52.9ms/batch - loss: 116.05059 - diff: 28.93ml
Test 1.1s: val_loss: 92.67726 - diff: 26.99ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Systole_WideResNet50_0_Adam-0.001_MSE_DA3_best

Epoch 5: current best loss = 92.67726, at epoch 4
Train batch 1/32 - 172.4ms/batch - loss: 56.90374 - diff: 25.46mlTrain batch 2/32 - 172.2ms/batch - loss: 40.81876 - diff: 21.39mlTrain batch 3/32 - 172.3ms/batch - loss: 64.19248 - diff: 23.77mlTrain batch 4/32 - 172.5ms/batch - loss: 59.74140 - diff: 23.41mlTrain batch 5/32 - 172.4ms/batch - loss: 73.57365 - diff: 25.61mlTrain batch 6/32 - 172.2ms/batch - loss: 70.52750 - diff: 25.47mlTrain batch 7/32 - 172.6ms/batch - loss: 71.65671 - diff: 25.92mlTrain batch 8/32 - 172.8ms/batch - loss: 83.16497 - diff: 26.36mlTrain batch 9/32 - 172.6ms/batch - loss: 79.52172 - diff: 26.11mlTrain batch 10/32 - 172.6ms/batch - loss: 154.33456 - diff: 29.41mlTrain batch 11/32 - 172.3ms/batch - loss: 148.00043 - diff: 29.17mlTrain batch 12/32 - 172.8ms/batch - loss: 138.77016 - diff: 28.57mlTrain batch 13/32 - 172.3ms/batch - loss: 132.83315 - diff: 28.29mlTrain batch 14/32 - 172.9ms/batch - loss: 135.03817 - diff: 28.57mlTrain batch 15/32 - 172.6ms/batch - loss: 127.75978 - diff: 27.71mlTrain batch 16/32 - 172.8ms/batch - loss: 123.95574 - diff: 27.63mlTrain batch 17/32 - 172.6ms/batch - loss: 123.16033 - diff: 27.91mlTrain batch 18/32 - 172.5ms/batch - loss: 120.83785 - diff: 27.97mlTrain batch 19/32 - 172.6ms/batch - loss: 116.90435 - diff: 27.68mlTrain batch 20/32 - 172.7ms/batch - loss: 114.41643 - diff: 27.60mlTrain batch 21/32 - 172.8ms/batch - loss: 114.39659 - diff: 27.74mlTrain batch 22/32 - 172.7ms/batch - loss: 110.59373 - diff: 27.38mlTrain batch 23/32 - 172.7ms/batch - loss: 108.94761 - diff: 27.37mlTrain batch 24/32 - 172.9ms/batch - loss: 108.55491 - diff: 27.52mlTrain batch 25/32 - 172.7ms/batch - loss: 114.41268 - diff: 27.82mlTrain batch 26/32 - 172.8ms/batch - loss: 114.98217 - diff: 27.90mlTrain batch 27/32 - 172.7ms/batch - loss: 116.49633 - diff: 28.33mlTrain batch 28/32 - 172.8ms/batch - loss: 115.39894 - diff: 28.19mlTrain batch 29/32 - 172.7ms/batch - loss: 116.41473 - diff: 28.37mlTrain batch 30/32 - 172.7ms/batch - loss: 114.88129 - diff: 28.24mlTrain batch 31/32 - 172.7ms/batch - loss: 112.82076 - diff: 28.03mlTrain batch 32/32 - 52.9ms/batch - loss: 114.06467 - diff: 28.04mlTrain batch 32/32 - 10.5s 52.9ms/batch - loss: 114.06467 - diff: 28.04ml
Test 1.1s: val_loss: 98.22161 - diff: 27.26ml

Epoch 6: current best loss = 92.67726, at epoch 4
Train batch 1/32 - 172.8ms/batch - loss: 76.72963 - diff: 29.23mlTrain batch 2/32 - 172.8ms/batch - loss: 389.85905 - diff: 37.26mlTrain batch 3/32 - 172.6ms/batch - loss: 266.76081 - diff: 29.94mlTrain batch 4/32 - 172.9ms/batch - loss: 209.41780 - diff: 27.76mlTrain batch 5/32 - 172.8ms/batch - loss: 185.73697 - diff: 28.70mlTrain batch 6/32 - 172.7ms/batch - loss: 163.87905 - diff: 27.49mlTrain batch 7/32 - 172.7ms/batch - loss: 164.66300 - diff: 29.16mlTrain batch 8/32 - 172.8ms/batch - loss: 159.08646 - diff: 29.33mlTrain batch 9/32 - 172.7ms/batch - loss: 147.92135 - diff: 28.99mlTrain batch 10/32 - 172.8ms/batch - loss: 141.27044 - diff: 28.69mlTrain batch 11/32 - 172.6ms/batch - loss: 132.26274 - diff: 27.84mlTrain batch 12/32 - 172.8ms/batch - loss: 129.48122 - diff: 28.22mlTrain batch 13/32 - 172.6ms/batch - loss: 130.34086 - diff: 28.46mlTrain batch 14/32 - 172.8ms/batch - loss: 125.65427 - diff: 28.45mlTrain batch 15/32 - 172.7ms/batch - loss: 119.83532 - diff: 27.97mlTrain batch 16/32 - 172.8ms/batch - loss: 115.12954 - diff: 27.46mlTrain batch 17/32 - 172.6ms/batch - loss: 112.00140 - diff: 27.40mlTrain batch 18/32 - 172.7ms/batch - loss: 109.95067 - diff: 27.45mlTrain batch 19/32 - 172.6ms/batch - loss: 108.12718 - diff: 27.47mlTrain batch 20/32 - 172.9ms/batch - loss: 103.64623 - diff: 26.75mlTrain batch 21/32 - 172.7ms/batch - loss: 102.31820 - diff: 26.71mlTrain batch 22/32 - 173.0ms/batch - loss: 113.11218 - diff: 27.36mlTrain batch 23/32 - 172.9ms/batch - loss: 114.65077 - diff: 27.89mlTrain batch 24/32 - 172.7ms/batch - loss: 113.47165 - diff: 27.91mlTrain batch 25/32 - 172.8ms/batch - loss: 119.17310 - diff: 28.26mlTrain batch 26/32 - 173.0ms/batch - loss: 122.26037 - diff: 28.70mlTrain batch 27/32 - 172.7ms/batch - loss: 120.53828 - diff: 28.42mlTrain batch 28/32 - 173.1ms/batch - loss: 118.52413 - diff: 28.32mlTrain batch 29/32 - 172.9ms/batch - loss: 117.09369 - diff: 28.32mlTrain batch 30/32 - 173.0ms/batch - loss: 116.83571 - diff: 28.51mlTrain batch 31/32 - 172.7ms/batch - loss: 115.22541 - diff: 28.48mlTrain batch 32/32 - 52.8ms/batch - loss: 116.96511 - diff: 28.50mlTrain batch 32/32 - 10.5s 52.8ms/batch - loss: 116.96511 - diff: 28.50ml
Test 1.1s: val_loss: 94.91832 - diff: 27.66ml

Epoch 7: current best loss = 92.67726, at epoch 4
Train batch 1/32 - 172.9ms/batch - loss: 32.11583 - diff: 17.52mlTrain batch 2/32 - 172.9ms/batch - loss: 36.84515 - diff: 19.69mlTrain batch 3/32 - 172.5ms/batch - loss: 39.30463 - diff: 20.11mlTrain batch 4/32 - 172.7ms/batch - loss: 56.09600 - diff: 23.20mlTrain batch 5/32 - 172.8ms/batch - loss: 67.25527 - diff: 25.27mlTrain batch 6/32 - 172.7ms/batch - loss: 64.36333 - diff: 24.37mlTrain batch 7/32 - 172.7ms/batch - loss: 63.42276 - diff: 24.53mlTrain batch 8/32 - 172.7ms/batch - loss: 61.65207 - diff: 24.34mlTrain batch 9/32 - 173.1ms/batch - loss: 64.34685 - diff: 24.86mlTrain batch 10/32 - 172.8ms/batch - loss: 70.83408 - diff: 25.43mlTrain batch 11/32 - 172.5ms/batch - loss: 102.67135 - diff: 28.06mlTrain batch 12/32 - 172.7ms/batch - loss: 100.57632 - diff: 28.13mlTrain batch 13/32 - 172.8ms/batch - loss: 101.16605 - diff: 28.34mlTrain batch 14/32 - 172.7ms/batch - loss: 96.43761 - diff: 27.80mlTrain batch 15/32 - 172.9ms/batch - loss: 99.50434 - diff: 28.15mlTrain batch 16/32 - 172.9ms/batch - loss: 99.85050 - diff: 28.38mlTrain batch 17/32 - 172.7ms/batch - loss: 102.44261 - diff: 28.62mlTrain batch 18/32 - 172.8ms/batch - loss: 105.85351 - diff: 28.72mlTrain batch 19/32 - 172.8ms/batch - loss: 138.79438 - diff: 29.70mlTrain batch 20/32 - 173.0ms/batch - loss: 135.57204 - diff: 29.32mlTrain batch 21/32 - 172.7ms/batch - loss: 131.76119 - diff: 28.94mlTrain batch 22/32 - 172.9ms/batch - loss: 130.27520 - diff: 28.97mlTrain batch 23/32 - 172.9ms/batch - loss: 131.84688 - diff: 29.28mlTrain batch 24/32 - 173.1ms/batch - loss: 128.48033 - diff: 29.07mlTrain batch 25/32 - 172.9ms/batch - loss: 124.65283 - diff: 28.69mlTrain batch 26/32 - 173.0ms/batch - loss: 121.88306 - diff: 28.48mlTrain batch 27/32 - 172.8ms/batch - loss: 119.16663 - diff: 28.29mlTrain batch 28/32 - 172.9ms/batch - loss: 116.78482 - diff: 28.20mlTrain batch 29/32 - 172.9ms/batch - loss: 115.70943 - diff: 28.22mlTrain batch 30/32 - 173.1ms/batch - loss: 113.90903 - diff: 28.19mlTrain batch 31/32 - 172.9ms/batch - loss: 115.24371 - diff: 28.42mlTrain batch 32/32 - 52.9ms/batch - loss: 117.93549 - diff: 28.49mlTrain batch 32/32 - 10.5s 52.9ms/batch - loss: 117.93549 - diff: 28.49ml
Test 1.1s: val_loss: 92.38853 - diff: 27.55ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Systole_WideResNet50_0_Adam-0.001_MSE_DA3_best

Epoch 8: current best loss = 92.38853, at epoch 7
Train batch 1/32 - 172.5ms/batch - loss: 219.40314 - diff: 46.26mlTrain batch 2/32 - 173.0ms/batch - loss: 146.50342 - diff: 37.07mlTrain batch 3/32 - 172.8ms/batch - loss: 132.90523 - diff: 34.76mlTrain batch 4/32 - 173.0ms/batch - loss: 108.88166 - diff: 30.26mlTrain batch 5/32 - 172.6ms/batch - loss: 94.28447 - diff: 28.24mlTrain batch 6/32 - 173.0ms/batch - loss: 91.80165 - diff: 28.44mlTrain batch 7/32 - 172.9ms/batch - loss: 111.73036 - diff: 28.79mlTrain batch 8/32 - 172.9ms/batch - loss: 101.87198 - diff: 27.61mlTrain batch 9/32 - 172.7ms/batch - loss: 97.88353 - diff: 27.40mlTrain batch 10/32 - 173.3ms/batch - loss: 107.04723 - diff: 28.32mlTrain batch 11/32 - 172.8ms/batch - loss: 102.56221 - diff: 28.03mlTrain batch 12/32 - 173.5ms/batch - loss: 100.28232 - diff: 27.69mlTrain batch 13/32 - 172.9ms/batch - loss: 97.48881 - diff: 27.26mlTrain batch 14/32 - 173.0ms/batch - loss: 98.72073 - diff: 27.63mlTrain batch 15/32 - 173.3ms/batch - loss: 102.29755 - diff: 27.95mlTrain batch 16/32 - 173.3ms/batch - loss: 100.29299 - diff: 27.87mlTrain batch 17/32 - 173.1ms/batch - loss: 96.29280 - diff: 27.36mlTrain batch 18/32 - 173.4ms/batch - loss: 94.34964 - diff: 27.14mlTrain batch 19/32 - 173.0ms/batch - loss: 91.04509 - diff: 26.71mlTrain batch 20/32 - 172.8ms/batch - loss: 89.48178 - diff: 26.55mlTrain batch 21/32 - 172.7ms/batch - loss: 92.59453 - diff: 26.94mlTrain batch 22/32 - 173.2ms/batch - loss: 90.97227 - diff: 26.85mlTrain batch 23/32 - 172.9ms/batch - loss: 93.10463 - diff: 27.22mlTrain batch 24/32 - 173.3ms/batch - loss: 92.79367 - diff: 27.37mlTrain batch 25/32 - 173.1ms/batch - loss: 95.06472 - diff: 27.47mlTrain batch 26/32 - 173.4ms/batch - loss: 120.73329 - diff: 28.67mlTrain batch 27/32 - 173.2ms/batch - loss: 119.15164 - diff: 28.61mlTrain batch 28/32 - 173.5ms/batch - loss: 118.06908 - diff: 28.65mlTrain batch 29/32 - 173.2ms/batch - loss: 115.73510 - diff: 28.48mlTrain batch 30/32 - 173.5ms/batch - loss: 112.91554 - diff: 28.07mlTrain batch 31/32 - 173.5ms/batch - loss: 112.20448 - diff: 28.11mlTrain batch 32/32 - 53.1ms/batch - loss: 112.47880 - diff: 28.07mlTrain batch 32/32 - 10.5s 53.1ms/batch - loss: 112.47880 - diff: 28.07ml
Test 1.1s: val_loss: 101.40739 - diff: 27.49ml

Epoch 9: current best loss = 92.38853, at epoch 7
Train batch 1/32 - 172.9ms/batch - loss: 184.80482 - diff: 30.63mlTrain batch 2/32 - 173.3ms/batch - loss: 119.24274 - diff: 27.81mlTrain batch 3/32 - 173.4ms/batch - loss: 119.79908 - diff: 28.37mlTrain batch 4/32 - 173.6ms/batch - loss: 104.17354 - diff: 27.95mlTrain batch 5/32 - 173.0ms/batch - loss: 99.71175 - diff: 27.53mlTrain batch 6/32 - 173.5ms/batch - loss: 133.10281 - diff: 30.18mlTrain batch 7/32 - 173.3ms/batch - loss: 121.93672 - diff: 29.38mlTrain batch 8/32 - 173.3ms/batch - loss: 116.37009 - diff: 29.09mlTrain batch 9/32 - 173.0ms/batch - loss: 116.49836 - diff: 29.83mlTrain batch 10/32 - 173.2ms/batch - loss: 117.28646 - diff: 30.07mlTrain batch 11/32 - 173.3ms/batch - loss: 125.31155 - diff: 31.00mlTrain batch 12/32 - 173.1ms/batch - loss: 121.01460 - diff: 30.63mlTrain batch 13/32 - 173.3ms/batch - loss: 116.94416 - diff: 30.42mlTrain batch 14/32 - 173.5ms/batch - loss: 164.75499 - diff: 32.29mlTrain batch 15/32 - 173.3ms/batch - loss: 162.53816 - diff: 32.38mlTrain batch 16/32 - 173.3ms/batch - loss: 158.60141 - diff: 32.04mlTrain batch 17/32 - 173.6ms/batch - loss: 158.21489 - diff: 32.39mlTrain batch 18/32 - 173.3ms/batch - loss: 152.67522 - diff: 31.89mlTrain batch 19/32 - 173.2ms/batch - loss: 147.94898 - diff: 31.79mlTrain batch 20/32 - 173.4ms/batch - loss: 142.22526 - diff: 31.17mlTrain batch 21/32 - 173.3ms/batch - loss: 139.11227 - diff: 31.07mlTrain batch 22/32 - 173.3ms/batch - loss: 135.91533 - diff: 30.96mlTrain batch 23/32 - 173.4ms/batch - loss: 131.61986 - diff: 30.49mlTrain batch 24/32 - 173.3ms/batch - loss: 127.60733 - diff: 30.00mlTrain batch 25/32 - 173.3ms/batch - loss: 124.69560 - diff: 29.81mlTrain batch 26/32 - 173.4ms/batch - loss: 123.69539 - diff: 29.82mlTrain batch 27/32 - 173.4ms/batch - loss: 120.07786 - diff: 29.38mlTrain batch 28/32 - 173.6ms/batch - loss: 117.27690 - diff: 29.06mlTrain batch 29/32 - 173.4ms/batch - loss: 117.06987 - diff: 29.06mlTrain batch 30/32 - 173.4ms/batch - loss: 114.05744 - diff: 28.67mlTrain batch 31/32 - 173.4ms/batch - loss: 112.15434 - diff: 28.57mlTrain batch 32/32 - 53.1ms/batch - loss: 118.19515 - diff: 28.75mlTrain batch 32/32 - 10.6s 53.1ms/batch - loss: 118.19515 - diff: 28.75ml
Test 1.1s: val_loss: 94.92587 - diff: 27.41ml

Epoch 10: current best loss = 92.38853, at epoch 7
Train batch 1/32 - 173.2ms/batch - loss: 43.14075 - diff: 21.12mlTrain batch 2/32 - 173.2ms/batch - loss: 101.90496 - diff: 29.25mlTrain batch 3/32 - 173.2ms/batch - loss: 104.91200 - diff: 30.59mlTrain batch 4/32 - 173.6ms/batch - loss: 94.08580 - diff: 29.61mlTrain batch 5/32 - 173.3ms/batch - loss: 92.80596 - diff: 29.95mlTrain batch 6/32 - 173.4ms/batch - loss: 84.67779 - diff: 28.53mlTrain batch 7/32 - 173.4ms/batch - loss: 92.01328 - diff: 28.77mlTrain batch 8/32 - 173.5ms/batch - loss: 109.96319 - diff: 29.53mlTrain batch 9/32 - 173.4ms/batch - loss: 100.41623 - diff: 28.18mlTrain batch 10/32 - 173.4ms/batch - loss: 92.50890 - diff: 26.87mlTrain batch 11/32 - 173.4ms/batch - loss: 88.90774 - diff: 26.69mlTrain batch 12/32 - 173.6ms/batch - loss: 86.60581 - diff: 26.72mlTrain batch 13/32 - 173.3ms/batch - loss: 89.26554 - diff: 26.98mlTrain batch 14/32 - 173.7ms/batch - loss: 86.85942 - diff: 26.70mlTrain batch 15/32 - 173.1ms/batch - loss: 86.30075 - diff: 26.67mlTrain batch 16/32 - 173.1ms/batch - loss: 83.48110 - diff: 26.30mlTrain batch 17/32 - 173.7ms/batch - loss: 85.96110 - diff: 26.66mlTrain batch 18/32 - 173.4ms/batch - loss: 83.84711 - diff: 26.35mlTrain batch 19/32 - 173.4ms/batch - loss: 87.32087 - diff: 26.91mlTrain batch 20/32 - 173.5ms/batch - loss: 88.20807 - diff: 27.02mlTrain batch 21/32 - 173.5ms/batch - loss: 86.51439 - diff: 26.80mlTrain batch 22/32 - 173.4ms/batch - loss: 84.41675 - diff: 26.54mlTrain batch 23/32 - 173.3ms/batch - loss: 81.98837 - diff: 26.21mlTrain batch 24/32 - 173.3ms/batch - loss: 81.81682 - diff: 26.16mlTrain batch 25/32 - 173.0ms/batch - loss: 80.03213 - diff: 25.87mlTrain batch 26/32 - 173.5ms/batch - loss: 86.77453 - diff: 26.30mlTrain batch 27/32 - 173.1ms/batch - loss: 88.58367 - diff: 26.57mlTrain batch 28/32 - 173.4ms/batch - loss: 90.25993 - diff: 26.96mlTrain batch 29/32 - 173.5ms/batch - loss: 113.77165 - diff: 27.91mlTrain batch 30/32 - 173.2ms/batch - loss: 111.90076 - diff: 27.88mlTrain batch 31/32 - 173.3ms/batch - loss: 113.12883 - diff: 28.08mlTrain batch 32/32 - 53.1ms/batch - loss: 113.93236 - diff: 28.07mlTrain batch 32/32 - 10.5s 53.1ms/batch - loss: 113.93236 - diff: 28.07ml
Test 1.1s: val_loss: 90.29966 - diff: 27.74ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Systole_WideResNet50_0_Adam-0.001_MSE_DA3_best

Epoch 11: current best loss = 90.29966, at epoch 10
Train batch 1/32 - 173.4ms/batch - loss: 59.31168 - diff: 27.45mlTrain batch 2/32 - 173.4ms/batch - loss: 48.28439 - diff: 23.33mlTrain batch 3/32 - 173.2ms/batch - loss: 39.13135 - diff: 20.54mlTrain batch 4/32 - 173.6ms/batch - loss: 52.49087 - diff: 22.95mlTrain batch 5/32 - 173.3ms/batch - loss: 57.12856 - diff: 24.36mlTrain batch 6/32 - 173.5ms/batch - loss: 68.65610 - diff: 24.93mlTrain batch 7/32 - 173.4ms/batch - loss: 79.52216 - diff: 25.92mlTrain batch 8/32 - 173.5ms/batch - loss: 72.00320 - diff: 24.22mlTrain batch 9/32 - 173.4ms/batch - loss: 70.83101 - diff: 24.17mlTrain batch 10/32 - 173.4ms/batch - loss: 77.49924 - diff: 25.90mlTrain batch 11/32 - 173.2ms/batch - loss: 137.43034 - diff: 28.15mlTrain batch 12/32 - 173.1ms/batch - loss: 129.72319 - diff: 27.67mlTrain batch 13/32 - 173.3ms/batch - loss: 126.01088 - diff: 27.76mlTrain batch 14/32 - 173.7ms/batch - loss: 120.42905 - diff: 27.43mlTrain batch 15/32 - 173.5ms/batch - loss: 124.15840 - diff: 28.33mlTrain batch 16/32 - 173.6ms/batch - loss: 118.40687 - diff: 27.66mlTrain batch 17/32 - 173.5ms/batch - loss: 115.92852 - diff: 27.73mlTrain batch 18/32 - 173.6ms/batch - loss: 118.01048 - diff: 28.17mlTrain batch 19/32 - 173.2ms/batch - loss: 115.38595 - diff: 28.20mlTrain batch 20/32 - 173.9ms/batch - loss: 111.98912 - diff: 27.93mlTrain batch 21/32 - 173.5ms/batch - loss: 108.28866 - diff: 27.57mlTrain batch 22/32 - 173.5ms/batch - loss: 105.33689 - diff: 27.30mlTrain batch 23/32 - 173.5ms/batch - loss: 103.43706 - diff: 27.14mlTrain batch 24/32 - 173.4ms/batch - loss: 100.73301 - diff: 26.82mlTrain batch 25/32 - 173.3ms/batch - loss: 100.88268 - diff: 26.94mlTrain batch 26/32 - 173.5ms/batch - loss: 103.49702 - diff: 27.09mlTrain batch 27/32 - 173.5ms/batch - loss: 101.91879 - diff: 27.01mlTrain batch 28/32 - 173.3ms/batch - loss: 99.67214 - diff: 26.84mlTrain batch 29/32 - 173.3ms/batch - loss: 111.00082 - diff: 27.93mlTrain batch 30/32 - 173.4ms/batch - loss: 110.25771 - diff: 27.96mlTrain batch 31/32 - 173.5ms/batch - loss: 109.95915 - diff: 27.98mlTrain batch 32/32 - 53.1ms/batch - loss: 119.96109 - diff: 28.14mlTrain batch 32/32 - 10.5s 53.1ms/batch - loss: 119.96109 - diff: 28.14ml
Test 1.1s: val_loss: 90.04869 - diff: 26.87ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Systole_WideResNet50_0_Adam-0.001_MSE_DA3_best

Epoch 12: current best loss = 90.04869, at epoch 11
Train batch 1/32 - 173.1ms/batch - loss: 50.96179 - diff: 21.26mlTrain batch 2/32 - 173.6ms/batch - loss: 513.23969 - diff: 43.55mlTrain batch 3/32 - 173.3ms/batch - loss: 368.06627 - diff: 38.96mlTrain batch 4/32 - 174.0ms/batch - loss: 288.00266 - diff: 34.50mlTrain batch 5/32 - 173.4ms/batch - loss: 244.31387 - diff: 32.51mlTrain batch 6/32 - 173.4ms/batch - loss: 231.94902 - diff: 33.04mlTrain batch 7/32 - 173.2ms/batch - loss: 204.90050 - diff: 31.53mlTrain batch 8/32 - 173.4ms/batch - loss: 197.89075 - diff: 31.87mlTrain batch 9/32 - 173.0ms/batch - loss: 187.08910 - diff: 32.19mlTrain batch 10/32 - 173.4ms/batch - loss: 177.53583 - diff: 32.20mlTrain batch 11/32 - 173.4ms/batch - loss: 167.96007 - diff: 31.90mlTrain batch 12/32 - 173.4ms/batch - loss: 158.90873 - diff: 31.48mlTrain batch 13/32 - 173.1ms/batch - loss: 150.78614 - diff: 30.75mlTrain batch 14/32 - 173.8ms/batch - loss: 148.69203 - diff: 30.85mlTrain batch 15/32 - 173.3ms/batch - loss: 145.00116 - diff: 31.02mlTrain batch 16/32 - 173.7ms/batch - loss: 143.36597 - diff: 31.11mlTrain batch 17/32 - 173.1ms/batch - loss: 138.41405 - diff: 30.57mlTrain batch 18/32 - 173.5ms/batch - loss: 134.73825 - diff: 30.34mlTrain batch 19/32 - 173.5ms/batch - loss: 130.50883 - diff: 30.14mlTrain batch 20/32 - 173.4ms/batch - loss: 127.64387 - diff: 30.24mlTrain batch 21/32 - 173.2ms/batch - loss: 122.96319 - diff: 29.67mlTrain batch 22/32 - 172.8ms/batch - loss: 128.86068 - diff: 30.22mlTrain batch 23/32 - 173.0ms/batch - loss: 127.15226 - diff: 30.11mlTrain batch 24/32 - 173.1ms/batch - loss: 126.84804 - diff: 30.12mlTrain batch 25/32 - 173.5ms/batch - loss: 123.89834 - diff: 29.82mlTrain batch 26/32 - 173.3ms/batch - loss: 121.55467 - diff: 29.72mlTrain batch 27/32 - 173.6ms/batch - loss: 119.37964 - diff: 29.63mlTrain batch 28/32 - 173.7ms/batch - loss: 119.04092 - diff: 29.75mlTrain batch 29/32 - 173.2ms/batch - loss: 116.45417 - diff: 29.41mlTrain batch 30/32 - 173.9ms/batch - loss: 117.00673 - diff: 29.37mlTrain batch 31/32 - 173.7ms/batch - loss: 114.42320 - diff: 29.12mlTrain batch 32/32 - 53.1ms/batch - loss: 116.20191 - diff: 29.16mlTrain batch 32/32 - 10.5s 53.1ms/batch - loss: 116.20191 - diff: 29.16ml
Test 1.1s: val_loss: 91.11754 - diff: 27.94ml

Epoch 13: current best loss = 90.04869, at epoch 11
Train batch 1/32 - 173.5ms/batch - loss: 94.55809 - diff: 27.20mlTrain batch 2/32 - 173.3ms/batch - loss: 85.92267 - diff: 29.37mlTrain batch 3/32 - 173.6ms/batch - loss: 74.97104 - diff: 27.63mlTrain batch 4/32 - 173.5ms/batch - loss: 97.84923 - diff: 30.63mlTrain batch 5/32 - 173.4ms/batch - loss: 85.79341 - diff: 28.28mlTrain batch 6/32 - 173.9ms/batch - loss: 77.45431 - diff: 26.76mlTrain batch 7/32 - 173.3ms/batch - loss: 75.85350 - diff: 26.76mlTrain batch 8/32 - 173.6ms/batch - loss: 78.90095 - diff: 26.95mlTrain batch 9/32 - 173.5ms/batch - loss: 96.15503 - diff: 28.21mlTrain batch 10/32 - 174.1ms/batch - loss: 91.16187 - diff: 27.64mlTrain batch 11/32 - 173.3ms/batch - loss: 85.84647 - diff: 26.94mlTrain batch 12/32 - 174.0ms/batch - loss: 86.23428 - diff: 27.15mlTrain batch 13/32 - 173.4ms/batch - loss: 81.70856 - diff: 26.25mlTrain batch 14/32 - 172.9ms/batch - loss: 124.52930 - diff: 27.26mlTrain batch 15/32 - 173.4ms/batch - loss: 118.69862 - diff: 26.80mlTrain batch 16/32 - 173.7ms/batch - loss: 112.98663 - diff: 26.24mlTrain batch 17/32 - 173.7ms/batch - loss: 113.18775 - diff: 26.39mlTrain batch 18/32 - 173.5ms/batch - loss: 110.19958 - diff: 26.07mlTrain batch 19/32 - 173.3ms/batch - loss: 107.58616 - diff: 26.14mlTrain batch 20/32 - 173.5ms/batch - loss: 105.56350 - diff: 26.22mlTrain batch 21/32 - 173.7ms/batch - loss: 102.67645 - diff: 26.03mlTrain batch 22/32 - 173.6ms/batch - loss: 101.14475 - diff: 26.04mlTrain batch 23/32 - 173.5ms/batch - loss: 104.51843 - diff: 26.51mlTrain batch 24/32 - 173.7ms/batch - loss: 102.64246 - diff: 26.47mlTrain batch 25/32 - 173.4ms/batch - loss: 100.44289 - diff: 26.37mlTrain batch 26/32 - 173.6ms/batch - loss: 98.64868 - diff: 26.26mlTrain batch 27/32 - 173.6ms/batch - loss: 104.44386 - diff: 26.68mlTrain batch 28/32 - 173.9ms/batch - loss: 108.55180 - diff: 27.29mlTrain batch 29/32 - 173.7ms/batch - loss: 105.50579 - diff: 26.87mlTrain batch 30/32 - 173.9ms/batch - loss: 108.57633 - diff: 27.15mlTrain batch 31/32 - 173.4ms/batch - loss: 110.21098 - diff: 27.60mlTrain batch 32/32 - 53.1ms/batch - loss: 121.91433 - diff: 27.87mlTrain batch 32/32 - 10.5s 53.1ms/batch - loss: 121.91433 - diff: 27.87ml
Test 1.1s: val_loss: 96.34007 - diff: 28.20ml

Epoch 14: current best loss = 90.04869, at epoch 11
Train batch 1/32 - 173.7ms/batch - loss: 118.05284 - diff: 34.97mlTrain batch 2/32 - 173.7ms/batch - loss: 186.76060 - diff: 40.95mlTrain batch 3/32 - 173.6ms/batch - loss: 144.08170 - diff: 35.45mlTrain batch 4/32 - 173.8ms/batch - loss: 149.56741 - diff: 34.30mlTrain batch 5/32 - 173.6ms/batch - loss: 129.92390 - diff: 32.34mlTrain batch 6/32 - 173.9ms/batch - loss: 126.00647 - diff: 31.84mlTrain batch 7/32 - 173.5ms/batch - loss: 112.44419 - diff: 30.11mlTrain batch 8/32 - 173.7ms/batch - loss: 110.19448 - diff: 29.83mlTrain batch 9/32 - 173.3ms/batch - loss: 111.67264 - diff: 30.04mlTrain batch 10/32 - 173.0ms/batch - loss: 106.00546 - diff: 29.72mlTrain batch 11/32 - 173.5ms/batch - loss: 101.43533 - diff: 29.29mlTrain batch 12/32 - 174.0ms/batch - loss: 96.70285 - diff: 28.71mlTrain batch 13/32 - 173.5ms/batch - loss: 99.60573 - diff: 29.01mlTrain batch 14/32 - 173.7ms/batch - loss: 97.66229 - diff: 28.54mlTrain batch 15/32 - 173.5ms/batch - loss: 141.05647 - diff: 30.18mlTrain batch 16/32 - 173.8ms/batch - loss: 136.23372 - diff: 29.93mlTrain batch 17/32 - 173.6ms/batch - loss: 130.44792 - diff: 29.34mlTrain batch 18/32 - 173.8ms/batch - loss: 128.39992 - diff: 29.38mlTrain batch 19/32 - 173.7ms/batch - loss: 124.10846 - diff: 29.06mlTrain batch 20/32 - 173.4ms/batch - loss: 132.25307 - diff: 29.84mlTrain batch 21/32 - 173.6ms/batch - loss: 129.49327 - diff: 29.86mlTrain batch 22/32 - 172.9ms/batch - loss: 125.77177 - diff: 29.44mlTrain batch 23/32 - 173.6ms/batch - loss: 124.41053 - diff: 29.44mlTrain batch 24/32 - 173.1ms/batch - loss: 124.74284 - diff: 29.72mlTrain batch 25/32 - 173.7ms/batch - loss: 124.32990 - diff: 30.01mlTrain batch 26/32 - 173.7ms/batch - loss: 122.62402 - diff: 30.10mlTrain batch 27/32 - 173.6ms/batch - loss: 120.56221 - diff: 29.90mlTrain batch 28/32 - 173.9ms/batch - loss: 117.05505 - diff: 29.33mlTrain batch 29/32 - 173.7ms/batch - loss: 114.73459 - diff: 29.12mlTrain batch 30/32 - 173.7ms/batch - loss: 114.59661 - diff: 29.14mlTrain batch 31/32 - 173.8ms/batch - loss: 111.64986 - diff: 28.73mlTrain batch 32/32 - 53.3ms/batch - loss: 111.76253 - diff: 28.66mlTrain batch 32/32 - 10.5s 53.3ms/batch - loss: 111.76253 - diff: 28.66ml
Test 1.1s: val_loss: 92.52826 - diff: 27.38ml

Epoch 15: current best loss = 90.04869, at epoch 11
Train batch 1/32 - 173.7ms/batch - loss: 80.71648 - diff: 29.23mlTrain batch 2/32 - 173.1ms/batch - loss: 109.38459 - diff: 29.41mlTrain batch 3/32 - 173.6ms/batch - loss: 98.53298 - diff: 27.99mlTrain batch 4/32 - 173.1ms/batch - loss: 86.06784 - diff: 27.13mlTrain batch 5/32 - 173.5ms/batch - loss: 74.01911 - diff: 25.25mlTrain batch 6/32 - 173.7ms/batch - loss: 185.10336 - diff: 29.97mlTrain batch 7/32 - 173.5ms/batch - loss: 166.76749 - diff: 28.94mlTrain batch 8/32 - 173.5ms/batch - loss: 151.16727 - diff: 27.41mlTrain batch 9/32 - 173.5ms/batch - loss: 144.74604 - diff: 27.63mlTrain batch 10/32 - 173.8ms/batch - loss: 135.85104 - diff: 27.30mlTrain batch 11/32 - 173.6ms/batch - loss: 126.58202 - diff: 26.40mlTrain batch 12/32 - 173.7ms/batch - loss: 125.76258 - diff: 27.13mlTrain batch 13/32 - 173.6ms/batch - loss: 135.65068 - diff: 28.41mlTrain batch 14/32 - 173.8ms/batch - loss: 137.57579 - diff: 28.96mlTrain batch 15/32 - 173.5ms/batch - loss: 134.10162 - diff: 28.95mlTrain batch 16/32 - 173.6ms/batch - loss: 135.02885 - diff: 29.30mlTrain batch 17/32 - 174.1ms/batch - loss: 128.84533 - diff: 28.69mlTrain batch 18/32 - 173.9ms/batch - loss: 126.11800 - diff: 28.67mlTrain batch 19/32 - 173.6ms/batch - loss: 123.08970 - diff: 28.49mlTrain batch 20/32 - 173.8ms/batch - loss: 122.05172 - diff: 28.32mlTrain batch 21/32 - 173.5ms/batch - loss: 118.87934 - diff: 28.20mlTrain batch 22/32 - 173.7ms/batch - loss: 115.30452 - diff: 27.80mlTrain batch 23/32 - 173.3ms/batch - loss: 119.20692 - diff: 28.37mlTrain batch 24/32 - 173.9ms/batch - loss: 118.17972 - diff: 28.51mlTrain batch 25/32 - 173.8ms/batch - loss: 123.89892 - diff: 28.97mlTrain batch 26/32 - 173.8ms/batch - loss: 120.90774 - diff: 28.79mlTrain batch 27/32 - 173.8ms/batch - loss: 117.90432 - diff: 28.44mlTrain batch 28/32 - 173.9ms/batch - loss: 115.11459 - diff: 28.15mlTrain batch 29/32 - 173.6ms/batch - loss: 113.23835 - diff: 28.05mlTrain batch 30/32 - 173.9ms/batch - loss: 112.81419 - diff: 28.15mlTrain batch 31/32 - 173.9ms/batch - loss: 110.38992 - diff: 27.87mlTrain batch 32/32 - 53.3ms/batch - loss: 116.81192 - diff: 28.02mlTrain batch 32/32 - 10.5s 53.3ms/batch - loss: 116.81192 - diff: 28.02ml
Test 1.1s: val_loss: 87.56194 - diff: 26.58ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Systole_WideResNet50_0_Adam-0.001_MSE_DA3_best

Epoch 16: current best loss = 87.56194, at epoch 15
Train batch 1/32 - 173.3ms/batch - loss: 76.32500 - diff: 26.60mlTrain batch 2/32 - 173.7ms/batch - loss: 59.72020 - diff: 24.41mlTrain batch 3/32 - 173.3ms/batch - loss: 54.65007 - diff: 23.57mlTrain batch 4/32 - 173.9ms/batch - loss: 85.60364 - diff: 25.69mlTrain batch 5/32 - 173.6ms/batch - loss: 76.62881 - diff: 25.05mlTrain batch 6/32 - 173.5ms/batch - loss: 95.07407 - diff: 27.07mlTrain batch 7/32 - 173.6ms/batch - loss: 124.03719 - diff: 29.25mlTrain batch 8/32 - 173.8ms/batch - loss: 122.34968 - diff: 29.84mlTrain batch 9/32 - 173.7ms/batch - loss: 129.91626 - diff: 30.83mlTrain batch 10/32 - 174.1ms/batch - loss: 118.57550 - diff: 29.09mlTrain batch 11/32 - 174.0ms/batch - loss: 112.97001 - diff: 28.36mlTrain batch 12/32 - 174.1ms/batch - loss: 106.13782 - diff: 27.52mlTrain batch 13/32 - 173.9ms/batch - loss: 100.84522 - diff: 26.95mlTrain batch 14/32 - 174.3ms/batch - loss: 96.95255 - diff: 26.57mlTrain batch 15/32 - 173.7ms/batch - loss: 93.48422 - diff: 25.95mlTrain batch 16/32 - 173.2ms/batch - loss: 91.63697 - diff: 25.86mlTrain batch 17/32 - 173.9ms/batch - loss: 90.62193 - diff: 25.72mlTrain batch 18/32 - 174.0ms/batch - loss: 91.17049 - diff: 26.11mlTrain batch 19/32 - 173.8ms/batch - loss: 88.42745 - diff: 25.84mlTrain batch 20/32 - 174.0ms/batch - loss: 87.10675 - diff: 25.94mlTrain batch 21/32 - 174.0ms/batch - loss: 86.56733 - diff: 26.09mlTrain batch 22/32 - 174.0ms/batch - loss: 87.53953 - diff: 26.13mlTrain batch 23/32 - 173.8ms/batch - loss: 89.09510 - diff: 26.46mlTrain batch 24/32 - 174.1ms/batch - loss: 113.35825 - diff: 27.37mlTrain batch 25/32 - 173.7ms/batch - loss: 113.65194 - diff: 27.57mlTrain batch 26/32 - 174.2ms/batch - loss: 110.94943 - diff: 27.39mlTrain batch 27/32 - 173.7ms/batch - loss: 109.00773 - diff: 27.43mlTrain batch 28/32 - 174.0ms/batch - loss: 110.74364 - diff: 27.69mlTrain batch 29/32 - 173.8ms/batch - loss: 111.23613 - diff: 27.92mlTrain batch 30/32 - 174.0ms/batch - loss: 109.59674 - diff: 27.81mlTrain batch 31/32 - 173.5ms/batch - loss: 109.63314 - diff: 27.79mlTrain batch 32/32 - 53.3ms/batch - loss: 110.97717 - diff: 27.77mlTrain batch 32/32 - 10.5s 53.3ms/batch - loss: 110.97717 - diff: 27.77ml
Test 1.1s: val_loss: 104.87641 - diff: 28.49ml

Epoch 17: current best loss = 87.56194, at epoch 15
Train batch 1/32 - 173.2ms/batch - loss: 67.81915 - diff: 29.09mlTrain batch 2/32 - 173.8ms/batch - loss: 72.02123 - diff: 28.30mlTrain batch 3/32 - 174.0ms/batch - loss: 65.57787 - diff: 27.47mlTrain batch 4/32 - 174.3ms/batch - loss: 64.35923 - diff: 27.08mlTrain batch 5/32 - 174.1ms/batch - loss: 72.07861 - diff: 28.62mlTrain batch 6/32 - 173.7ms/batch - loss: 86.50172 - diff: 29.74mlTrain batch 7/32 - 173.9ms/batch - loss: 81.09998 - diff: 28.78mlTrain batch 8/32 - 173.4ms/batch - loss: 82.09937 - diff: 28.88mlTrain batch 9/32 - 173.3ms/batch - loss: 83.23948 - diff: 28.92mlTrain batch 10/32 - 173.1ms/batch - loss: 89.09466 - diff: 29.66mlTrain batch 11/32 - 173.6ms/batch - loss: 83.69330 - diff: 28.57mlTrain batch 12/32 - 173.7ms/batch - loss: 92.38262 - diff: 29.22mlTrain batch 13/32 - 173.5ms/batch - loss: 86.95080 - diff: 28.24mlTrain batch 14/32 - 173.7ms/batch - loss: 87.52033 - diff: 28.41mlTrain batch 15/32 - 173.9ms/batch - loss: 84.75263 - diff: 27.87mlTrain batch 16/32 - 174.3ms/batch - loss: 80.79364 - diff: 27.10mlTrain batch 17/32 - 173.9ms/batch - loss: 94.84740 - diff: 27.75mlTrain batch 18/32 - 174.1ms/batch - loss: 91.71143 - diff: 27.37mlTrain batch 19/32 - 173.9ms/batch - loss: 96.82116 - diff: 28.00mlTrain batch 20/32 - 174.3ms/batch - loss: 94.27747 - diff: 27.59mlTrain batch 21/32 - 173.9ms/batch - loss: 91.79514 - diff: 27.36mlTrain batch 22/32 - 174.1ms/batch - loss: 90.32736 - diff: 27.11mlTrain batch 23/32 - 173.6ms/batch - loss: 116.09208 - diff: 27.87mlTrain batch 24/32 - 173.3ms/batch - loss: 112.08920 - diff: 27.34mlTrain batch 25/32 - 173.6ms/batch - loss: 113.18808 - diff: 27.56mlTrain batch 26/32 - 174.2ms/batch - loss: 109.96270 - diff: 27.19mlTrain batch 27/32 - 173.7ms/batch - loss: 111.85221 - diff: 27.22mlTrain batch 28/32 - 173.9ms/batch - loss: 111.78123 - diff: 27.39mlTrain batch 29/32 - 174.0ms/batch - loss: 108.67851 - diff: 26.99mlTrain batch 30/32 - 174.2ms/batch - loss: 110.23031 - diff: 27.37mlTrain batch 31/32 - 174.1ms/batch - loss: 109.50346 - diff: 27.33mlTrain batch 32/32 - 53.4ms/batch - loss: 114.66765 - diff: 27.52mlTrain batch 32/32 - 10.5s 53.4ms/batch - loss: 114.66765 - diff: 27.52ml
Test 1.1s: val_loss: 87.05357 - diff: 27.24ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Systole_WideResNet50_0_Adam-0.001_MSE_DA3_best

Epoch 18: current best loss = 87.05357, at epoch 17
Train batch 1/32 - 173.7ms/batch - loss: 131.98946 - diff: 35.08mlTrain batch 2/32 - 173.8ms/batch - loss: 84.61532 - diff: 28.36mlTrain batch 3/32 - 173.4ms/batch - loss: 89.03658 - diff: 29.85mlTrain batch 4/32 - 173.8ms/batch - loss: 121.30645 - diff: 29.95mlTrain batch 5/32 - 173.6ms/batch - loss: 111.64259 - diff: 28.47mlTrain batch 6/32 - 173.8ms/batch - loss: 102.48112 - diff: 27.55mlTrain batch 7/32 - 174.1ms/batch - loss: 100.74399 - diff: 27.30mlTrain batch 8/32 - 174.3ms/batch - loss: 101.67538 - diff: 27.53mlTrain batch 9/32 - 174.1ms/batch - loss: 98.43726 - diff: 27.66mlTrain batch 10/32 - 174.4ms/batch - loss: 98.93445 - diff: 27.83mlTrain batch 11/32 - 174.0ms/batch - loss: 97.27564 - diff: 28.01mlTrain batch 12/32 - 174.2ms/batch - loss: 93.62565 - diff: 27.54mlTrain batch 13/32 - 174.1ms/batch - loss: 89.07958 - diff: 26.91mlTrain batch 14/32 - 173.7ms/batch - loss: 86.11948 - diff: 26.69mlTrain batch 15/32 - 174.0ms/batch - loss: 82.87483 - diff: 26.22mlTrain batch 16/32 - 173.7ms/batch - loss: 81.27560 - diff: 26.00mlTrain batch 17/32 - 174.2ms/batch - loss: 80.53965 - diff: 25.98mlTrain batch 18/32 - 174.2ms/batch - loss: 126.33465 - diff: 28.11mlTrain batch 19/32 - 174.0ms/batch - loss: 122.87867 - diff: 28.07mlTrain batch 20/32 - 174.2ms/batch - loss: 123.45344 - diff: 28.49mlTrain batch 21/32 - 173.9ms/batch - loss: 120.21296 - diff: 28.20mlTrain batch 22/32 - 174.1ms/batch - loss: 123.04519 - diff: 28.72mlTrain batch 23/32 - 173.8ms/batch - loss: 122.21118 - diff: 28.72mlTrain batch 24/32 - 174.1ms/batch - loss: 120.17789 - diff: 28.49mlTrain batch 25/32 - 174.0ms/batch - loss: 117.12329 - diff: 28.21mlTrain batch 26/32 - 174.1ms/batch - loss: 114.99518 - diff: 28.02mlTrain batch 27/32 - 173.9ms/batch - loss: 115.42253 - diff: 28.22mlTrain batch 28/32 - 174.3ms/batch - loss: 113.73390 - diff: 28.21mlTrain batch 29/32 - 174.1ms/batch - loss: 112.55709 - diff: 28.32mlTrain batch 30/32 - 174.2ms/batch - loss: 111.44419 - diff: 28.27mlTrain batch 31/32 - 174.2ms/batch - loss: 110.48966 - diff: 28.32mlTrain batch 32/32 - 53.4ms/batch - loss: 109.89600 - diff: 28.19mlTrain batch 32/32 - 10.5s 53.4ms/batch - loss: 109.89600 - diff: 28.19ml
Test 1.1s: val_loss: 87.71934 - diff: 28.30ml

Epoch 19: current best loss = 87.05357, at epoch 17
Train batch 1/32 - 173.9ms/batch - loss: 101.41619 - diff: 30.78mlTrain batch 2/32 - 174.1ms/batch - loss: 91.00363 - diff: 26.63mlTrain batch 3/32 - 174.2ms/batch - loss: 109.50763 - diff: 28.51mlTrain batch 4/32 - 174.1ms/batch - loss: 151.07339 - diff: 32.22mlTrain batch 5/32 - 174.0ms/batch - loss: 129.29410 - diff: 30.35mlTrain batch 6/32 - 174.5ms/batch - loss: 118.83618 - diff: 30.20mlTrain batch 7/32 - 173.9ms/batch - loss: 114.57728 - diff: 30.06mlTrain batch 8/32 - 173.8ms/batch - loss: 104.35767 - diff: 28.56mlTrain batch 9/32 - 173.7ms/batch - loss: 100.69053 - diff: 27.98mlTrain batch 10/32 - 173.9ms/batch - loss: 98.69283 - diff: 28.01mlTrain batch 11/32 - 173.8ms/batch - loss: 95.57792 - diff: 27.70mlTrain batch 12/32 - 173.8ms/batch - loss: 89.58144 - diff: 26.79mlTrain batch 13/32 - 173.9ms/batch - loss: 89.07669 - diff: 26.75mlTrain batch 14/32 - 173.7ms/batch - loss: 92.50495 - diff: 27.29mlTrain batch 15/32 - 173.5ms/batch - loss: 89.93344 - diff: 26.91mlTrain batch 16/32 - 173.9ms/batch - loss: 87.27728 - diff: 26.72mlTrain batch 17/32 - 174.2ms/batch - loss: 84.27292 - diff: 26.36mlTrain batch 18/32 - 173.9ms/batch - loss: 83.90024 - diff: 26.55mlTrain batch 19/32 - 174.0ms/batch - loss: 84.53251 - diff: 26.70mlTrain batch 20/32 - 174.3ms/batch - loss: 82.99924 - diff: 26.60mlTrain batch 21/32 - 173.6ms/batch - loss: 87.97402 - diff: 26.96mlTrain batch 22/32 - 173.8ms/batch - loss: 87.66457 - diff: 26.91mlTrain batch 23/32 - 173.7ms/batch - loss: 88.77029 - diff: 27.04mlTrain batch 24/32 - 173.9ms/batch - loss: 86.58574 - diff: 26.72mlTrain batch 25/32 - 173.7ms/batch - loss: 87.01316 - diff: 26.86mlTrain batch 26/32 - 174.0ms/batch - loss: 85.00623 - diff: 26.57mlTrain batch 27/32 - 173.6ms/batch - loss: 83.61928 - diff: 26.46mlTrain batch 28/32 - 173.8ms/batch - loss: 83.04834 - diff: 26.41mlTrain batch 29/32 - 174.0ms/batch - loss: 109.50683 - diff: 27.60mlTrain batch 30/32 - 174.4ms/batch - loss: 109.97948 - diff: 27.70mlTrain batch 31/32 - 174.1ms/batch - loss: 108.41374 - diff: 27.59mlTrain batch 32/32 - 53.4ms/batch - loss: 107.71231 - diff: 27.44mlTrain batch 32/32 - 10.5s 53.4ms/batch - loss: 107.71231 - diff: 27.44ml
Test 1.1s: val_loss: 89.53555 - diff: 27.14ml

Epoch 20: current best loss = 87.05357, at epoch 17
Train batch 1/32 - 173.7ms/batch - loss: 53.08109 - diff: 24.18mlTrain batch 2/32 - 173.7ms/batch - loss: 87.38017 - diff: 26.51mlTrain batch 3/32 - 173.7ms/batch - loss: 74.96562 - diff: 25.42mlTrain batch 4/32 - 173.9ms/batch - loss: 66.18202 - diff: 24.04mlTrain batch 5/32 - 173.7ms/batch - loss: 61.00079 - diff: 23.40mlTrain batch 6/32 - 174.1ms/batch - loss: 60.49110 - diff: 24.08mlTrain batch 7/32 - 173.8ms/batch - loss: 58.63376 - diff: 23.93mlTrain batch 8/32 - 173.9ms/batch - loss: 66.95901 - diff: 25.42mlTrain batch 9/32 - 174.0ms/batch - loss: 69.84711 - diff: 25.30mlTrain batch 10/32 - 174.5ms/batch - loss: 76.08577 - diff: 25.83mlTrain batch 11/32 - 173.9ms/batch - loss: 76.05224 - diff: 26.13mlTrain batch 12/32 - 174.6ms/batch - loss: 73.18067 - diff: 25.68mlTrain batch 13/32 - 174.0ms/batch - loss: 74.79402 - diff: 25.83mlTrain batch 14/32 - 174.7ms/batch - loss: 73.83111 - diff: 25.45mlTrain batch 15/32 - 174.1ms/batch - loss: 87.19201 - diff: 26.40mlTrain batch 16/32 - 174.6ms/batch - loss: 86.18145 - diff: 26.16mlTrain batch 17/32 - 174.0ms/batch - loss: 86.09831 - diff: 26.35mlTrain batch 18/32 - 174.4ms/batch - loss: 85.10573 - diff: 26.45mlTrain batch 19/32 - 173.6ms/batch - loss: 86.77560 - diff: 26.47mlTrain batch 20/32 - 173.4ms/batch - loss: 84.11557 - diff: 26.14mlTrain batch 21/32 - 174.2ms/batch - loss: 91.39900 - diff: 26.94mlTrain batch 22/32 - 174.1ms/batch - loss: 95.77510 - diff: 27.30mlTrain batch 23/32 - 174.3ms/batch - loss: 96.14060 - diff: 27.26mlTrain batch 24/32 - 173.9ms/batch - loss: 96.13356 - diff: 27.42mlTrain batch 25/32 - 173.9ms/batch - loss: 121.20575 - diff: 28.41mlTrain batch 26/32 - 174.2ms/batch - loss: 120.61723 - diff: 28.42mlTrain batch 27/32 - 173.9ms/batch - loss: 118.42662 - diff: 28.31mlTrain batch 28/32 - 174.4ms/batch - loss: 115.78222 - diff: 28.04mlTrain batch 29/32 - 174.0ms/batch - loss: 113.98791 - diff: 27.94mlTrain batch 30/32 - 174.5ms/batch - loss: 112.52855 - diff: 27.94mlTrain batch 31/32 - 174.3ms/batch - loss: 110.96445 - diff: 27.92mlTrain batch 32/32 - 53.4ms/batch - loss: 111.89495 - diff: 27.91mlTrain batch 32/32 - 10.5s 53.4ms/batch - loss: 111.89495 - diff: 27.91ml
Test 1.1s: val_loss: 99.47105 - diff: 27.42ml

Epoch 21: current best loss = 87.05357, at epoch 17
Train batch 1/32 - 173.7ms/batch - loss: 121.04552 - diff: 29.22mlTrain batch 2/32 - 174.0ms/batch - loss: 95.88653 - diff: 28.12mlTrain batch 3/32 - 173.5ms/batch - loss: 86.55693 - diff: 28.08mlTrain batch 4/32 - 174.0ms/batch - loss: 127.18551 - diff: 30.44mlTrain batch 5/32 - 174.0ms/batch - loss: 131.73177 - diff: 31.75mlTrain batch 6/32 - 174.3ms/batch - loss: 115.28620 - diff: 29.68mlTrain batch 7/32 - 174.1ms/batch - loss: 110.88715 - diff: 29.86mlTrain batch 8/32 - 174.4ms/batch - loss: 105.72733 - diff: 28.84mlTrain batch 9/32 - 173.8ms/batch - loss: 97.72813 - diff: 27.78mlTrain batch 10/32 - 174.4ms/batch - loss: 97.78980 - diff: 27.95mlTrain batch 11/32 - 174.1ms/batch - loss: 93.06068 - diff: 27.23mlTrain batch 12/32 - 174.5ms/batch - loss: 89.74195 - diff: 26.86mlTrain batch 13/32 - 173.6ms/batch - loss: 85.14396 - diff: 26.05mlTrain batch 14/32 - 173.3ms/batch - loss: 88.86695 - diff: 26.61mlTrain batch 15/32 - 173.8ms/batch - loss: 134.26604 - diff: 28.62mlTrain batch 16/32 - 174.1ms/batch - loss: 134.57828 - diff: 28.86mlTrain batch 17/32 - 173.8ms/batch - loss: 135.13697 - diff: 29.20mlTrain batch 18/32 - 174.2ms/batch - loss: 133.24908 - diff: 29.30mlTrain batch 19/32 - 174.4ms/batch - loss: 132.44287 - diff: 29.31mlTrain batch 20/32 - 174.6ms/batch - loss: 127.20802 - diff: 28.76mlTrain batch 21/32 - 174.3ms/batch - loss: 129.04726 - diff: 28.97mlTrain batch 22/32 - 174.4ms/batch - loss: 126.34072 - diff: 28.83mlTrain batch 23/32 - 174.3ms/batch - loss: 126.98753 - diff: 29.06mlTrain batch 24/32 - 174.2ms/batch - loss: 123.29540 - diff: 28.68mlTrain batch 25/32 - 173.9ms/batch - loss: 120.27894 - diff: 28.50mlTrain batch 26/32 - 174.2ms/batch - loss: 118.54982 - diff: 28.44mlTrain batch 27/32 - 173.3ms/batch - loss: 116.09946 - diff: 28.30mlTrain batch 28/32 - 173.5ms/batch - loss: 114.33083 - diff: 28.28mlTrain batch 29/32 - 173.9ms/batch - loss: 113.22795 - diff: 28.27mlTrain batch 30/32 - 174.0ms/batch - loss: 111.08140 - diff: 28.08mlTrain batch 31/32 - 173.8ms/batch - loss: 109.93761 - diff: 27.97mlTrain batch 32/32 - 53.7ms/batch - loss: 109.76492 - diff: 27.90mlTrain batch 32/32 - 10.5s 53.7ms/batch - loss: 109.76492 - diff: 27.90ml
Test 1.1s: val_loss: 95.13548 - diff: 26.51ml

Epoch 22: current best loss = 87.05357, at epoch 17
Train batch 1/32 - 173.7ms/batch - loss: 46.25094 - diff: 23.30mlTrain batch 2/32 - 174.5ms/batch - loss: 41.91356 - diff: 21.45mlTrain batch 3/32 - 174.0ms/batch - loss: 47.16813 - diff: 22.25mlTrain batch 4/32 - 174.2ms/batch - loss: 55.60041 - diff: 23.45mlTrain batch 5/32 - 173.7ms/batch - loss: 82.76329 - diff: 26.09mlTrain batch 6/32 - 174.0ms/batch - loss: 136.57257 - diff: 29.76mlTrain batch 7/32 - 173.7ms/batch - loss: 138.96514 - diff: 30.17mlTrain batch 8/32 - 173.9ms/batch - loss: 130.72588 - diff: 29.49mlTrain batch 9/32 - 173.8ms/batch - loss: 122.87412 - diff: 29.16mlTrain batch 10/32 - 173.9ms/batch - loss: 124.03748 - diff: 29.54mlTrain batch 11/32 - 173.7ms/batch - loss: 116.97031 - diff: 28.87mlTrain batch 12/32 - 174.0ms/batch - loss: 110.64440 - diff: 28.36mlTrain batch 13/32 - 174.1ms/batch - loss: 104.27511 - diff: 27.62mlTrain batch 14/32 - 174.6ms/batch - loss: 99.32179 - diff: 26.89mlTrain batch 15/32 - 174.4ms/batch - loss: 94.83696 - diff: 26.26mlTrain batch 16/32 - 173.8ms/batch - loss: 95.13774 - diff: 26.63mlTrain batch 17/32 - 174.3ms/batch - loss: 94.68126 - diff: 26.91mlTrain batch 18/32 - 174.2ms/batch - loss: 90.23995 - diff: 26.14mlTrain batch 19/32 - 173.9ms/batch - loss: 87.23262 - diff: 25.73mlTrain batch 20/32 - 173.9ms/batch - loss: 86.00611 - diff: 25.75mlTrain batch 21/32 - 173.9ms/batch - loss: 115.00311 - diff: 26.61mlTrain batch 22/32 - 173.9ms/batch - loss: 114.91664 - diff: 26.88mlTrain batch 23/32 - 174.3ms/batch - loss: 115.38365 - diff: 27.00mlTrain batch 24/32 - 174.6ms/batch - loss: 115.86791 - diff: 27.07mlTrain batch 25/32 - 173.9ms/batch - loss: 114.34823 - diff: 27.08mlTrain batch 26/32 - 174.5ms/batch - loss: 111.95229 - diff: 26.91mlTrain batch 27/32 - 174.0ms/batch - loss: 110.13471 - diff: 26.82mlTrain batch 28/32 - 174.0ms/batch - loss: 109.94528 - diff: 26.85mlTrain batch 29/32 - 173.9ms/batch - loss: 109.21804 - diff: 26.96mlTrain batch 30/32 - 173.5ms/batch - loss: 108.19899 - diff: 26.90mlTrain batch 31/32 - 173.9ms/batch - loss: 107.61721 - diff: 27.04mlTrain batch 32/32 - 53.4ms/batch - loss: 107.99552 - diff: 27.02mlTrain batch 32/32 - 10.6s 53.4ms/batch - loss: 107.99552 - diff: 27.02ml
Test 1.1s: val_loss: 84.73580 - diff: 27.32ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Systole_WideResNet50_0_Adam-0.001_MSE_DA3_best

Epoch 23: current best loss = 84.73580, at epoch 22
Train batch 1/32 - 173.8ms/batch - loss: 26.03395 - diff: 15.53mlTrain batch 2/32 - 174.1ms/batch - loss: 93.31457 - diff: 25.36mlTrain batch 3/32 - 174.0ms/batch - loss: 110.85511 - diff: 27.29mlTrain batch 4/32 - 174.0ms/batch - loss: 93.36068 - diff: 25.98mlTrain batch 5/32 - 173.7ms/batch - loss: 91.65010 - diff: 26.64mlTrain batch 6/32 - 173.5ms/batch - loss: 96.85771 - diff: 27.92mlTrain batch 7/32 - 174.4ms/batch - loss: 90.34356 - diff: 27.33mlTrain batch 8/32 - 174.3ms/batch - loss: 82.70594 - diff: 26.11mlTrain batch 9/32 - 173.8ms/batch - loss: 80.35329 - diff: 25.62mlTrain batch 10/32 - 174.1ms/batch - loss: 85.72206 - diff: 26.50mlTrain batch 11/32 - 173.9ms/batch - loss: 86.58532 - diff: 26.51mlTrain batch 12/32 - 174.1ms/batch - loss: 88.39166 - diff: 26.74mlTrain batch 13/32 - 174.0ms/batch - loss: 88.41530 - diff: 26.97mlTrain batch 14/32 - 174.0ms/batch - loss: 86.89411 - diff: 26.89mlTrain batch 15/32 - 173.9ms/batch - loss: 84.14435 - diff: 26.62mlTrain batch 16/32 - 174.0ms/batch - loss: 83.26481 - diff: 26.57mlTrain batch 17/32 - 174.0ms/batch - loss: 82.45203 - diff: 26.75mlTrain batch 18/32 - 174.1ms/batch - loss: 82.40633 - diff: 26.84mlTrain batch 19/32 - 174.0ms/batch - loss: 81.28301 - diff: 26.76mlTrain batch 20/32 - 174.0ms/batch - loss: 81.48644 - diff: 26.85mlTrain batch 21/32 - 174.6ms/batch - loss: 81.57002 - diff: 26.94mlTrain batch 22/32 - 174.2ms/batch - loss: 80.38421 - diff: 26.83mlTrain batch 23/32 - 174.5ms/batch - loss: 78.80546 - diff: 26.59mlTrain batch 24/32 - 174.2ms/batch - loss: 78.83673 - diff: 26.71mlTrain batch 25/32 - 174.1ms/batch - loss: 77.15322 - diff: 26.50mlTrain batch 26/32 - 173.9ms/batch - loss: 101.06383 - diff: 27.20mlTrain batch 27/32 - 173.8ms/batch - loss: 106.14402 - diff: 27.41mlTrain batch 28/32 - 173.9ms/batch - loss: 105.52707 - diff: 27.40mlTrain batch 29/32 - 173.9ms/batch - loss: 105.94819 - diff: 27.43mlTrain batch 30/32 - 174.2ms/batch - loss: 104.33022 - diff: 27.32mlTrain batch 31/32 - 173.9ms/batch - loss: 102.69138 - diff: 27.22mlTrain batch 32/32 - 53.2ms/batch - loss: 118.59841 - diff: 27.57mlTrain batch 32/32 - 10.4s 53.2ms/batch - loss: 118.59841 - diff: 27.57ml
Test 1.1s: val_loss: 84.87052 - diff: 26.23ml

Epoch 24: current best loss = 84.73580, at epoch 22
Train batch 1/32 - 173.9ms/batch - loss: 323.42429 - diff: 46.67mlTrain batch 2/32 - 174.0ms/batch - loss: 210.05310 - diff: 37.12mlTrain batch 3/32 - 174.0ms/batch - loss: 194.39151 - diff: 36.05mlTrain batch 4/32 - 174.5ms/batch - loss: 157.01560 - diff: 32.61mlTrain batch 5/32 - 173.9ms/batch - loss: 131.53547 - diff: 29.10mlTrain batch 6/32 - 173.3ms/batch - loss: 131.01982 - diff: 29.56mlTrain batch 7/32 - 174.0ms/batch - loss: 118.05929 - diff: 28.52mlTrain batch 8/32 - 173.9ms/batch - loss: 121.71661 - diff: 29.05mlTrain batch 9/32 - 173.8ms/batch - loss: 118.45466 - diff: 28.97mlTrain batch 10/32 - 174.0ms/batch - loss: 112.81694 - diff: 28.64mlTrain batch 11/32 - 174.3ms/batch - loss: 109.13874 - diff: 28.45mlTrain batch 12/32 - 174.5ms/batch - loss: 108.95347 - diff: 28.64mlTrain batch 13/32 - 174.1ms/batch - loss: 106.25441 - diff: 28.38mlTrain batch 14/32 - 174.6ms/batch - loss: 102.73356 - diff: 28.12mlTrain batch 15/32 - 174.3ms/batch - loss: 98.10782 - diff: 27.56mlTrain batch 16/32 - 174.3ms/batch - loss: 94.81584 - diff: 27.28mlTrain batch 17/32 - 174.4ms/batch - loss: 91.97921 - diff: 26.97mlTrain batch 18/32 - 174.6ms/batch - loss: 88.16751 - diff: 26.38mlTrain batch 19/32 - 174.3ms/batch - loss: 86.69996 - diff: 26.28mlTrain batch 20/32 - 174.6ms/batch - loss: 88.30752 - diff: 26.64mlTrain batch 21/32 - 173.6ms/batch - loss: 86.36932 - diff: 26.44mlTrain batch 22/32 - 173.5ms/batch - loss: 84.75242 - diff: 26.26mlTrain batch 23/32 - 173.8ms/batch - loss: 86.37929 - diff: 26.69mlTrain batch 24/32 - 174.2ms/batch - loss: 86.32263 - diff: 26.84mlTrain batch 25/32 - 174.4ms/batch - loss: 90.50076 - diff: 27.35mlTrain batch 26/32 - 174.5ms/batch - loss: 93.96903 - diff: 27.49mlTrain batch 27/32 - 174.2ms/batch - loss: 93.35551 - diff: 27.55mlTrain batch 28/32 - 174.4ms/batch - loss: 91.59299 - diff: 27.39mlTrain batch 29/32 - 174.2ms/batch - loss: 89.88007 - diff: 27.18mlTrain batch 30/32 - 174.5ms/batch - loss: 110.11885 - diff: 27.65mlTrain batch 31/32 - 174.2ms/batch - loss: 108.61753 - diff: 27.58mlTrain batch 32/32 - 53.5ms/batch - loss: 109.25119 - diff: 27.57mlTrain batch 32/32 - 10.5s 53.5ms/batch - loss: 109.25119 - diff: 27.57ml
Test 1.1s: val_loss: 83.10572 - diff: 26.12ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Systole_WideResNet50_0_Adam-0.001_MSE_DA3_best

Epoch 25: current best loss = 83.10572, at epoch 24
Train batch 1/32 - 173.9ms/batch - loss: 44.55940 - diff: 19.37mlTrain batch 2/32 - 174.1ms/batch - loss: 409.97935 - diff: 36.86mlTrain batch 3/32 - 174.1ms/batch - loss: 307.77717 - diff: 34.30mlTrain batch 4/32 - 174.3ms/batch - loss: 239.85774 - diff: 30.97mlTrain batch 5/32 - 173.9ms/batch - loss: 217.25844 - diff: 31.09mlTrain batch 6/32 - 174.6ms/batch - loss: 192.11788 - diff: 30.52mlTrain batch 7/32 - 174.3ms/batch - loss: 171.20136 - diff: 29.44mlTrain batch 8/32 - 174.7ms/batch - loss: 155.28119 - diff: 28.56mlTrain batch 9/32 - 174.0ms/batch - loss: 143.23919 - diff: 27.88mlTrain batch 10/32 - 174.7ms/batch - loss: 135.97043 - diff: 27.83mlTrain batch 11/32 - 174.1ms/batch - loss: 130.72052 - diff: 27.76mlTrain batch 12/32 - 173.8ms/batch - loss: 121.18083 - diff: 26.48mlTrain batch 13/32 - 174.3ms/batch - loss: 117.58552 - diff: 26.34mlTrain batch 14/32 - 174.5ms/batch - loss: 112.87926 - diff: 26.30mlTrain batch 15/32 - 173.6ms/batch - loss: 108.90666 - diff: 26.21mlTrain batch 16/32 - 174.0ms/batch - loss: 104.43223 - diff: 25.82mlTrain batch 17/32 - 173.9ms/batch - loss: 102.57379 - diff: 25.83mlTrain batch 18/32 - 173.9ms/batch - loss: 100.05884 - diff: 25.69mlTrain batch 19/32 - 173.9ms/batch - loss: 96.79401 - diff: 25.49mlTrain batch 20/32 - 174.0ms/batch - loss: 93.89843 - diff: 25.29mlTrain batch 21/32 - 174.2ms/batch - loss: 94.27915 - diff: 25.54mlTrain batch 22/32 - 174.6ms/batch - loss: 94.95366 - diff: 25.67mlTrain batch 23/32 - 174.3ms/batch - loss: 92.10485 - diff: 25.30mlTrain batch 24/32 - 174.4ms/batch - loss: 94.05855 - diff: 25.77mlTrain batch 25/32 - 174.2ms/batch - loss: 100.85455 - diff: 26.45mlTrain batch 26/32 - 174.2ms/batch - loss: 98.45330 - diff: 26.28mlTrain batch 27/32 - 174.4ms/batch - loss: 97.57514 - diff: 26.24mlTrain batch 28/32 - 173.6ms/batch - loss: 95.83699 - diff: 26.12mlTrain batch 29/32 - 174.0ms/batch - loss: 98.14120 - diff: 26.27mlTrain batch 30/32 - 174.0ms/batch - loss: 97.23091 - diff: 26.23mlTrain batch 31/32 - 174.0ms/batch - loss: 102.24889 - diff: 26.47mlTrain batch 32/32 - 53.1ms/batch - loss: 118.85929 - diff: 26.80mlTrain batch 32/32 - 10.5s 53.1ms/batch - loss: 118.85929 - diff: 26.80ml
Test 1.1s: val_loss: 95.77168 - diff: 25.78ml

Epoch 26: current best loss = 83.10572, at epoch 24
Train batch 1/32 - 174.0ms/batch - loss: 106.91032 - diff: 32.39mlTrain batch 2/32 - 174.5ms/batch - loss: 123.76763 - diff: 31.02mlTrain batch 3/32 - 174.2ms/batch - loss: 104.83025 - diff: 28.72mlTrain batch 4/32 - 174.3ms/batch - loss: 117.98913 - diff: 29.80mlTrain batch 5/32 - 174.2ms/batch - loss: 141.93026 - diff: 31.45mlTrain batch 6/32 - 174.5ms/batch - loss: 231.36980 - diff: 34.81mlTrain batch 7/32 - 174.3ms/batch - loss: 209.14920 - diff: 33.93mlTrain batch 8/32 - 174.6ms/batch - loss: 190.63447 - diff: 33.02mlTrain batch 9/32 - 174.3ms/batch - loss: 184.37997 - diff: 33.16mlTrain batch 10/32 - 174.2ms/batch - loss: 179.37277 - diff: 33.49mlTrain batch 11/32 - 173.7ms/batch - loss: 169.71039 - diff: 33.08mlTrain batch 12/32 - 174.1ms/batch - loss: 159.21143 - diff: 32.25mlTrain batch 13/32 - 174.1ms/batch - loss: 151.21978 - diff: 31.83mlTrain batch 14/32 - 174.4ms/batch - loss: 144.11145 - diff: 31.16mlTrain batch 15/32 - 174.3ms/batch - loss: 137.47980 - diff: 30.71mlTrain batch 16/32 - 174.5ms/batch - loss: 133.37840 - diff: 30.42mlTrain batch 17/32 - 174.6ms/batch - loss: 139.18173 - diff: 30.87mlTrain batch 18/32 - 174.7ms/batch - loss: 133.49355 - diff: 30.28mlTrain batch 19/32 - 174.1ms/batch - loss: 129.17207 - diff: 30.00mlTrain batch 20/32 - 173.9ms/batch - loss: 126.98617 - diff: 29.77mlTrain batch 21/32 - 174.1ms/batch - loss: 124.52313 - diff: 29.73mlTrain batch 22/32 - 174.5ms/batch - loss: 120.21719 - diff: 29.20mlTrain batch 23/32 - 173.4ms/batch - loss: 118.36391 - diff: 29.19mlTrain batch 24/32 - 174.1ms/batch - loss: 116.27840 - diff: 29.08mlTrain batch 25/32 - 173.9ms/batch - loss: 113.71541 - diff: 28.91mlTrain batch 26/32 - 174.5ms/batch - loss: 113.44233 - diff: 28.92mlTrain batch 27/32 - 173.9ms/batch - loss: 110.69509 - diff: 28.63mlTrain batch 28/32 - 174.0ms/batch - loss: 110.96350 - diff: 28.78mlTrain batch 29/32 - 174.1ms/batch - loss: 109.32065 - diff: 28.68mlTrain batch 30/32 - 174.1ms/batch - loss: 108.66777 - diff: 28.66mlTrain batch 31/32 - 174.4ms/batch - loss: 106.33113 - diff: 28.40mlTrain batch 32/32 - 53.4ms/batch - loss: 108.33925 - diff: 28.43mlTrain batch 32/32 - 10.5s 53.4ms/batch - loss: 108.33925 - diff: 28.43ml
Test 1.1s: val_loss: 84.55944 - diff: 25.19ml

Epoch 27: current best loss = 83.10572, at epoch 24
Train batch 1/32 - 174.2ms/batch - loss: 66.40466 - diff: 26.24mlTrain batch 2/32 - 174.1ms/batch - loss: 87.96994 - diff: 27.14mlTrain batch 3/32 - 173.9ms/batch - loss: 74.36112 - diff: 24.81mlTrain batch 4/32 - 174.1ms/batch - loss: 71.31007 - diff: 25.40mlTrain batch 5/32 - 173.9ms/batch - loss: 62.63304 - diff: 24.03mlTrain batch 6/32 - 174.0ms/batch - loss: 76.88348 - diff: 25.98mlTrain batch 7/32 - 174.0ms/batch - loss: 78.18238 - diff: 26.04mlTrain batch 8/32 - 174.1ms/batch - loss: 86.10662 - diff: 26.99mlTrain batch 9/32 - 174.2ms/batch - loss: 89.24703 - diff: 27.43mlTrain batch 10/32 - 174.5ms/batch - loss: 93.20056 - diff: 27.64mlTrain batch 11/32 - 174.2ms/batch - loss: 88.44734 - diff: 26.90mlTrain batch 12/32 - 174.5ms/batch - loss: 83.59868 - diff: 26.16mlTrain batch 13/32 - 174.3ms/batch - loss: 79.92687 - diff: 25.71mlTrain batch 14/32 - 174.6ms/batch - loss: 83.02874 - diff: 25.83mlTrain batch 15/32 - 174.3ms/batch - loss: 121.11305 - diff: 27.22mlTrain batch 16/32 - 174.0ms/batch - loss: 116.78654 - diff: 26.80mlTrain batch 17/32 - 173.7ms/batch - loss: 115.31910 - diff: 26.92mlTrain batch 18/32 - 173.6ms/batch - loss: 119.02643 - diff: 27.09mlTrain batch 19/32 - 173.7ms/batch - loss: 115.78190 - diff: 26.99mlTrain batch 20/32 - 173.5ms/batch - loss: 117.08397 - diff: 27.40mlTrain batch 21/32 - 174.1ms/batch - loss: 113.79373 - diff: 27.10mlTrain batch 22/32 - 173.9ms/batch - loss: 120.87879 - diff: 27.63mlTrain batch 23/32 - 174.0ms/batch - loss: 118.80431 - diff: 27.62mlTrain batch 24/32 - 173.9ms/batch - loss: 118.56435 - diff: 27.77mlTrain batch 25/32 - 174.4ms/batch - loss: 117.51536 - diff: 27.85mlTrain batch 26/32 - 174.6ms/batch - loss: 114.73072 - diff: 27.67mlTrain batch 27/32 - 174.5ms/batch - loss: 112.41916 - diff: 27.59mlTrain batch 28/32 - 175.0ms/batch - loss: 110.03702 - diff: 27.41mlTrain batch 29/32 - 174.3ms/batch - loss: 108.20354 - diff: 27.33mlTrain batch 30/32 - 174.7ms/batch - loss: 106.24490 - diff: 27.20mlTrain batch 31/32 - 174.2ms/batch - loss: 104.62505 - diff: 27.11mlTrain batch 32/32 - 53.4ms/batch - loss: 105.58774 - diff: 27.10mlTrain batch 32/32 - 10.5s 53.4ms/batch - loss: 105.58774 - diff: 27.10ml
Test 1.1s: val_loss: 84.98662 - diff: 25.53ml

Epoch 28: current best loss = 83.10572, at epoch 24
Train batch 1/32 - 173.8ms/batch - loss: 72.41277 - diff: 25.79mlTrain batch 2/32 - 174.0ms/batch - loss: 62.85650 - diff: 24.93mlTrain batch 3/32 - 173.8ms/batch - loss: 85.11720 - diff: 28.16mlTrain batch 4/32 - 174.2ms/batch - loss: 73.39216 - diff: 26.34mlTrain batch 5/32 - 174.1ms/batch - loss: 70.38615 - diff: 26.22mlTrain batch 6/32 - 174.3ms/batch - loss: 70.58685 - diff: 26.07mlTrain batch 7/32 - 174.4ms/batch - loss: 64.62180 - diff: 25.04mlTrain batch 8/32 - 174.7ms/batch - loss: 72.88095 - diff: 25.30mlTrain batch 9/32 - 174.6ms/batch - loss: 81.66616 - diff: 27.05mlTrain batch 10/32 - 174.2ms/batch - loss: 78.66522 - diff: 26.70mlTrain batch 11/32 - 173.5ms/batch - loss: 76.06145 - diff: 26.21mlTrain batch 12/32 - 173.5ms/batch - loss: 80.69654 - diff: 26.49mlTrain batch 13/32 - 174.2ms/batch - loss: 130.15654 - diff: 28.07mlTrain batch 14/32 - 174.0ms/batch - loss: 123.76310 - diff: 27.53mlTrain batch 15/32 - 173.9ms/batch - loss: 120.23292 - diff: 27.35mlTrain batch 16/32 - 174.5ms/batch - loss: 121.47416 - diff: 28.04mlTrain batch 17/32 - 173.9ms/batch - loss: 122.52655 - diff: 28.39mlTrain batch 18/32 - 174.0ms/batch - loss: 118.98928 - diff: 28.07mlTrain batch 19/32 - 173.9ms/batch - loss: 123.17134 - diff: 28.26mlTrain batch 20/32 - 174.6ms/batch - loss: 128.49456 - diff: 28.63mlTrain batch 21/32 - 173.7ms/batch - loss: 124.78715 - diff: 28.43mlTrain batch 22/32 - 174.6ms/batch - loss: 120.76313 - diff: 28.10mlTrain batch 23/32 - 174.3ms/batch - loss: 118.73347 - diff: 28.21mlTrain batch 24/32 - 173.8ms/batch - loss: 117.30678 - diff: 28.18mlTrain batch 25/32 - 174.3ms/batch - loss: 114.74847 - diff: 28.12mlTrain batch 26/32 - 174.5ms/batch - loss: 112.80004 - diff: 28.00mlTrain batch 27/32 - 173.6ms/batch - loss: 111.30861 - diff: 27.79mlTrain batch 28/32 - 174.0ms/batch - loss: 110.05115 - diff: 27.55mlTrain batch 29/32 - 174.0ms/batch - loss: 108.55093 - diff: 27.61mlTrain batch 30/32 - 174.1ms/batch - loss: 105.96988 - diff: 27.36mlTrain batch 31/32 - 173.9ms/batch - loss: 105.35645 - diff: 27.34mlTrain batch 32/32 - 53.1ms/batch - loss: 106.33166 - diff: 27.33mlTrain batch 32/32 - 10.5s 53.1ms/batch - loss: 106.33166 - diff: 27.33ml
Test 1.1s: val_loss: 78.18402 - diff: 24.32ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Systole_WideResNet50_0_Adam-0.001_MSE_DA3_best

Epoch 29: current best loss = 78.18402, at epoch 28
Train batch 1/32 - 188.2ms/batch - loss: 66.56088 - diff: 22.13mlTrain batch 2/32 - 174.5ms/batch - loss: 43.68706 - diff: 18.25mlTrain batch 3/32 - 173.9ms/batch - loss: 56.47140 - diff: 21.54mlTrain batch 4/32 - 174.3ms/batch - loss: 72.21826 - diff: 25.20mlTrain batch 5/32 - 174.0ms/batch - loss: 74.75285 - diff: 26.04mlTrain batch 6/32 - 174.1ms/batch - loss: 105.46382 - diff: 28.29mlTrain batch 7/32 - 174.0ms/batch - loss: 119.38659 - diff: 29.65mlTrain batch 8/32 - 174.2ms/batch - loss: 119.62006 - diff: 29.55mlTrain batch 9/32 - 173.9ms/batch - loss: 122.74842 - diff: 30.13mlTrain batch 10/32 - 173.8ms/batch - loss: 114.81608 - diff: 29.03mlTrain batch 11/32 - 174.0ms/batch - loss: 106.86965 - diff: 28.02mlTrain batch 12/32 - 174.1ms/batch - loss: 100.75544 - diff: 27.18mlTrain batch 13/32 - 173.8ms/batch - loss: 96.64835 - diff: 26.86mlTrain batch 14/32 - 174.3ms/batch - loss: 96.81796 - diff: 26.83mlTrain batch 15/32 - 174.2ms/batch - loss: 97.92968 - diff: 26.78mlTrain batch 16/32 - 174.1ms/batch - loss: 96.39376 - diff: 26.99mlTrain batch 17/32 - 173.9ms/batch - loss: 92.89357 - diff: 26.69mlTrain batch 18/32 - 174.2ms/batch - loss: 91.54022 - diff: 26.51mlTrain batch 19/32 - 174.0ms/batch - loss: 94.64795 - diff: 26.87mlTrain batch 20/32 - 174.3ms/batch - loss: 92.54036 - diff: 26.74mlTrain batch 21/32 - 173.8ms/batch - loss: 91.46097 - diff: 26.56mlTrain batch 22/32 - 174.1ms/batch - loss: 90.69508 - diff: 26.59mlTrain batch 23/32 - 173.9ms/batch - loss: 89.74196 - diff: 26.71mlTrain batch 24/32 - 174.2ms/batch - loss: 89.02804 - diff: 26.62mlTrain batch 25/32 - 173.9ms/batch - loss: 89.81323 - diff: 26.77mlTrain batch 26/32 - 174.2ms/batch - loss: 89.94271 - diff: 26.71mlTrain batch 27/32 - 174.0ms/batch - loss: 87.77613 - diff: 26.45mlTrain batch 28/32 - 174.5ms/batch - loss: 87.76119 - diff: 26.46mlTrain batch 29/32 - 174.1ms/batch - loss: 85.78715 - diff: 26.16mlTrain batch 30/32 - 173.8ms/batch - loss: 105.04765 - diff: 26.81mlTrain batch 31/32 - 174.0ms/batch - loss: 103.03398 - diff: 26.60mlTrain batch 32/32 - 53.3ms/batch - loss: 102.63512 - diff: 26.47mlTrain batch 32/32 - 10.5s 53.3ms/batch - loss: 102.63512 - diff: 26.47ml
Test 1.1s: val_loss: 81.00116 - diff: 26.53ml

Epoch 30: current best loss = 78.18402, at epoch 28
Train batch 1/32 - 174.2ms/batch - loss: 110.80964 - diff: 26.25mlTrain batch 2/32 - 173.7ms/batch - loss: 144.65422 - diff: 29.71mlTrain batch 3/32 - 173.8ms/batch - loss: 103.73918 - diff: 25.36mlTrain batch 4/32 - 174.3ms/batch - loss: 111.14462 - diff: 27.27mlTrain batch 5/32 - 174.0ms/batch - loss: 103.22909 - diff: 27.02mlTrain batch 6/32 - 174.1ms/batch - loss: 95.08630 - diff: 26.31mlTrain batch 7/32 - 173.9ms/batch - loss: 94.68971 - diff: 26.45mlTrain batch 8/32 - 174.2ms/batch - loss: 87.74532 - diff: 25.92mlTrain batch 9/32 - 173.9ms/batch - loss: 86.35919 - diff: 25.85mlTrain batch 10/32 - 174.2ms/batch - loss: 85.86506 - diff: 26.46mlTrain batch 11/32 - 173.8ms/batch - loss: 81.86823 - diff: 25.88mlTrain batch 12/32 - 174.2ms/batch - loss: 82.16644 - diff: 26.31mlTrain batch 13/32 - 174.0ms/batch - loss: 94.50381 - diff: 26.98mlTrain batch 14/32 - 174.0ms/batch - loss: 94.12043 - diff: 27.14mlTrain batch 15/32 - 174.1ms/batch - loss: 91.45465 - diff: 26.94mlTrain batch 16/32 - 173.6ms/batch - loss: 90.35196 - diff: 26.83mlTrain batch 17/32 - 174.0ms/batch - loss: 89.75295 - diff: 26.98mlTrain batch 18/32 - 174.1ms/batch - loss: 88.16979 - diff: 26.74mlTrain batch 19/32 - 174.2ms/batch - loss: 93.29403 - diff: 27.32mlTrain batch 20/32 - 174.1ms/batch - loss: 122.94675 - diff: 28.49mlTrain batch 21/32 - 174.1ms/batch - loss: 121.45601 - diff: 28.50mlTrain batch 22/32 - 174.2ms/batch - loss: 117.59364 - diff: 28.07mlTrain batch 23/32 - 173.9ms/batch - loss: 113.84193 - diff: 27.70mlTrain batch 24/32 - 174.2ms/batch - loss: 111.83174 - diff: 27.78mlTrain batch 25/32 - 173.9ms/batch - loss: 108.55908 - diff: 27.35mlTrain batch 26/32 - 174.0ms/batch - loss: 106.70885 - diff: 27.21mlTrain batch 27/32 - 173.8ms/batch - loss: 106.77754 - diff: 27.36mlTrain batch 28/32 - 174.0ms/batch - loss: 106.71750 - diff: 27.53mlTrain batch 29/32 - 173.9ms/batch - loss: 107.07344 - diff: 27.62mlTrain batch 30/32 - 173.9ms/batch - loss: 104.68762 - diff: 27.34mlTrain batch 31/32 - 174.0ms/batch - loss: 102.18606 - diff: 27.00mlTrain batch 32/32 - 53.4ms/batch - loss: 101.66557 - diff: 26.86mlTrain batch 32/32 - 10.5s 53.4ms/batch - loss: 101.66557 - diff: 26.86ml
Test 1.1s: val_loss: 82.76126 - diff: 25.46ml

Epoch 31: current best loss = 78.18402, at epoch 28
Train batch 1/32 - 174.0ms/batch - loss: 221.74678 - diff: 34.41mlTrain batch 2/32 - 174.1ms/batch - loss: 133.71121 - diff: 27.92mlTrain batch 3/32 - 174.0ms/batch - loss: 129.31008 - diff: 28.31mlTrain batch 4/32 - 174.1ms/batch - loss: 115.46091 - diff: 27.88mlTrain batch 5/32 - 174.2ms/batch - loss: 108.76436 - diff: 27.01mlTrain batch 6/32 - 174.6ms/batch - loss: 121.23902 - diff: 28.37mlTrain batch 7/32 - 174.1ms/batch - loss: 108.23974 - diff: 26.99mlTrain batch 8/32 - 174.7ms/batch - loss: 114.96098 - diff: 28.52mlTrain batch 9/32 - 174.5ms/batch - loss: 105.62105 - diff: 27.35mlTrain batch 10/32 - 174.7ms/batch - loss: 101.20275 - diff: 27.22mlTrain batch 11/32 - 174.2ms/batch - loss: 100.47893 - diff: 26.84mlTrain batch 12/32 - 174.2ms/batch - loss: 96.92773 - diff: 26.65mlTrain batch 13/32 - 173.7ms/batch - loss: 93.99915 - diff: 26.67mlTrain batch 14/32 - 173.2ms/batch - loss: 92.42682 - diff: 26.62mlTrain batch 15/32 - 174.0ms/batch - loss: 91.60392 - diff: 26.76mlTrain batch 16/32 - 174.0ms/batch - loss: 91.19147 - diff: 27.03mlTrain batch 17/32 - 173.9ms/batch - loss: 89.30211 - diff: 26.75mlTrain batch 18/32 - 174.6ms/batch - loss: 86.76637 - diff: 26.55mlTrain batch 19/32 - 173.8ms/batch - loss: 85.23628 - diff: 26.38mlTrain batch 20/32 - 174.0ms/batch - loss: 88.93023 - diff: 26.67mlTrain batch 21/32 - 174.3ms/batch - loss: 87.14127 - diff: 26.66mlTrain batch 22/32 - 174.6ms/batch - loss: 85.89406 - diff: 26.58mlTrain batch 23/32 - 174.6ms/batch - loss: 113.56890 - diff: 27.69mlTrain batch 24/32 - 174.5ms/batch - loss: 109.65401 - diff: 27.13mlTrain batch 25/32 - 174.4ms/batch - loss: 107.82178 - diff: 27.10mlTrain batch 26/32 - 174.5ms/batch - loss: 106.98312 - diff: 27.21mlTrain batch 27/32 - 174.5ms/batch - loss: 105.03878 - diff: 27.17mlTrain batch 28/32 - 174.5ms/batch - loss: 103.26022 - diff: 27.01mlTrain batch 29/32 - 173.7ms/batch - loss: 101.40402 - diff: 26.83mlTrain batch 30/32 - 174.2ms/batch - loss: 103.99211 - diff: 27.28mlTrain batch 31/32 - 173.9ms/batch - loss: 101.92954 - diff: 27.07mlTrain batch 32/32 - 53.2ms/batch - loss: 102.96091 - diff: 27.03mlTrain batch 32/32 - 10.5s 53.2ms/batch - loss: 102.96091 - diff: 27.03ml
Test 1.1s: val_loss: 82.49183 - diff: 27.02ml

Epoch 32: current best loss = 78.18402, at epoch 28
Train batch 1/32 - 174.1ms/batch - loss: 92.48439 - diff: 26.51mlTrain batch 2/32 - 174.2ms/batch - loss: 166.00755 - diff: 33.77mlTrain batch 3/32 - 174.3ms/batch - loss: 135.40930 - diff: 31.70mlTrain batch 4/32 - 174.2ms/batch - loss: 118.40116 - diff: 30.36mlTrain batch 5/32 - 174.2ms/batch - loss: 99.17002 - diff: 27.04mlTrain batch 6/32 - 174.0ms/batch - loss: 91.43076 - diff: 26.19mlTrain batch 7/32 - 174.2ms/batch - loss: 86.43681 - diff: 26.18mlTrain batch 8/32 - 174.5ms/batch - loss: 91.23343 - diff: 27.39mlTrain batch 9/32 - 174.0ms/batch - loss: 92.39827 - diff: 27.95mlTrain batch 10/32 - 174.0ms/batch - loss: 85.86983 - diff: 26.99mlTrain batch 11/32 - 174.0ms/batch - loss: 83.94502 - diff: 26.89mlTrain batch 12/32 - 174.0ms/batch - loss: 80.07011 - diff: 26.56mlTrain batch 13/32 - 173.9ms/batch - loss: 75.44569 - diff: 25.57mlTrain batch 14/32 - 174.1ms/batch - loss: 78.29554 - diff: 25.45mlTrain batch 15/32 - 174.3ms/batch - loss: 76.99718 - diff: 25.33mlTrain batch 16/32 - 174.7ms/batch - loss: 80.26684 - diff: 25.73mlTrain batch 17/32 - 174.2ms/batch - loss: 77.88031 - diff: 25.52mlTrain batch 18/32 - 174.6ms/batch - loss: 77.77257 - diff: 25.46mlTrain batch 19/32 - 174.4ms/batch - loss: 87.13299 - diff: 26.08mlTrain batch 20/32 - 173.9ms/batch - loss: 86.09707 - diff: 26.14mlTrain batch 21/32 - 173.6ms/batch - loss: 89.41882 - diff: 26.66mlTrain batch 22/32 - 173.2ms/batch - loss: 86.78246 - diff: 26.24mlTrain batch 23/32 - 174.2ms/batch - loss: 86.89330 - diff: 26.25mlTrain batch 24/32 - 174.0ms/batch - loss: 85.14621 - diff: 26.13mlTrain batch 25/32 - 174.1ms/batch - loss: 83.33743 - diff: 25.94mlTrain batch 26/32 - 174.3ms/batch - loss: 82.21801 - diff: 25.89mlTrain batch 27/32 - 173.9ms/batch - loss: 81.74556 - diff: 25.93mlTrain batch 28/32 - 174.7ms/batch - loss: 80.48376 - diff: 25.77mlTrain batch 29/32 - 173.9ms/batch - loss: 78.87808 - diff: 25.54mlTrain batch 30/32 - 174.2ms/batch - loss: 80.77354 - diff: 25.90mlTrain batch 31/32 - 174.2ms/batch - loss: 82.17852 - diff: 26.04mlTrain batch 32/32 - 53.4ms/batch - loss: 161.25322 - diff: 26.74mlTrain batch 32/32 - 10.5s 53.4ms/batch - loss: 161.25322 - diff: 26.74ml
Test 1.1s: val_loss: 89.57836 - diff: 24.76ml

Epoch 33: current best loss = 78.18402, at epoch 28
Train batch 1/32 - 174.0ms/batch - loss: 53.34307 - diff: 23.15mlTrain batch 2/32 - 174.3ms/batch - loss: 355.81314 - diff: 32.97mlTrain batch 3/32 - 174.2ms/batch - loss: 243.27615 - diff: 26.29mlTrain batch 4/32 - 174.3ms/batch - loss: 198.01970 - diff: 25.96mlTrain batch 5/32 - 174.0ms/batch - loss: 165.97028 - diff: 24.98mlTrain batch 6/32 - 174.5ms/batch - loss: 150.84071 - diff: 25.58mlTrain batch 7/32 - 174.0ms/batch - loss: 136.69656 - diff: 25.22mlTrain batch 8/32 - 174.2ms/batch - loss: 128.85605 - diff: 25.33mlTrain batch 9/32 - 174.2ms/batch - loss: 128.90093 - diff: 25.65mlTrain batch 10/32 - 174.0ms/batch - loss: 128.66268 - diff: 26.42mlTrain batch 11/32 - 174.1ms/batch - loss: 139.83153 - diff: 27.38mlTrain batch 12/32 - 174.2ms/batch - loss: 138.38361 - diff: 27.46mlTrain batch 13/32 - 174.0ms/batch - loss: 132.18481 - diff: 27.32mlTrain batch 14/32 - 173.8ms/batch - loss: 127.83720 - diff: 27.12mlTrain batch 15/32 - 173.9ms/batch - loss: 121.70165 - diff: 26.61mlTrain batch 16/32 - 174.4ms/batch - loss: 123.48703 - diff: 27.47mlTrain batch 17/32 - 174.3ms/batch - loss: 120.90183 - diff: 27.72mlTrain batch 18/32 - 174.4ms/batch - loss: 118.41620 - diff: 27.73mlTrain batch 19/32 - 174.4ms/batch - loss: 117.52710 - diff: 27.88mlTrain batch 20/32 - 174.1ms/batch - loss: 113.94258 - diff: 27.56mlTrain batch 21/32 - 173.9ms/batch - loss: 111.26049 - diff: 27.53mlTrain batch 22/32 - 174.3ms/batch - loss: 110.90012 - diff: 27.68mlTrain batch 23/32 - 174.0ms/batch - loss: 109.12399 - diff: 27.58mlTrain batch 24/32 - 174.4ms/batch - loss: 108.68240 - diff: 27.74mlTrain batch 25/32 - 174.2ms/batch - loss: 110.96446 - diff: 28.04mlTrain batch 26/32 - 174.1ms/batch - loss: 109.33733 - diff: 28.05mlTrain batch 27/32 - 174.0ms/batch - loss: 106.86576 - diff: 27.82mlTrain batch 28/32 - 174.0ms/batch - loss: 108.41800 - diff: 28.07mlTrain batch 29/32 - 173.9ms/batch - loss: 106.62006 - diff: 28.03mlTrain batch 30/32 - 174.5ms/batch - loss: 104.33175 - diff: 27.75mlTrain batch 31/32 - 174.0ms/batch - loss: 104.33156 - diff: 27.82mlTrain batch 32/32 - 53.8ms/batch - loss: 107.82662 - diff: 27.89mlTrain batch 32/32 - 10.5s 53.8ms/batch - loss: 107.82662 - diff: 27.89ml
Test 1.1s: val_loss: 81.18052 - diff: 23.85ml

Epoch 34: current best loss = 78.18402, at epoch 28
Train batch 1/32 - 174.1ms/batch - loss: 655.19659 - diff: 46.88mlTrain batch 2/32 - 173.7ms/batch - loss: 366.96265 - diff: 36.19mlTrain batch 3/32 - 174.0ms/batch - loss: 327.07321 - diff: 37.47mlTrain batch 4/32 - 174.0ms/batch - loss: 260.15288 - diff: 33.37mlTrain batch 5/32 - 174.2ms/batch - loss: 244.42344 - diff: 33.60mlTrain batch 6/32 - 174.3ms/batch - loss: 221.55371 - diff: 32.22mlTrain batch 7/32 - 173.9ms/batch - loss: 198.35135 - diff: 31.20mlTrain batch 8/32 - 174.6ms/batch - loss: 183.33551 - diff: 30.90mlTrain batch 9/32 - 174.1ms/batch - loss: 169.09753 - diff: 30.18mlTrain batch 10/32 - 174.2ms/batch - loss: 157.41588 - diff: 29.72mlTrain batch 11/32 - 174.1ms/batch - loss: 147.61866 - diff: 28.96mlTrain batch 12/32 - 174.0ms/batch - loss: 143.42889 - diff: 28.86mlTrain batch 13/32 - 173.9ms/batch - loss: 142.38465 - diff: 29.59mlTrain batch 14/32 - 174.2ms/batch - loss: 135.73258 - diff: 29.21mlTrain batch 15/32 - 173.9ms/batch - loss: 134.30705 - diff: 29.36mlTrain batch 16/32 - 174.5ms/batch - loss: 127.70464 - diff: 28.73mlTrain batch 17/32 - 173.8ms/batch - loss: 123.35157 - diff: 28.26mlTrain batch 18/32 - 174.2ms/batch - loss: 127.61494 - diff: 29.11mlTrain batch 19/32 - 173.9ms/batch - loss: 123.19863 - diff: 28.76mlTrain batch 20/32 - 174.4ms/batch - loss: 119.10139 - diff: 28.42mlTrain batch 21/32 - 174.1ms/batch - loss: 115.23348 - diff: 28.04mlTrain batch 22/32 - 174.3ms/batch - loss: 115.08752 - diff: 28.24mlTrain batch 23/32 - 174.0ms/batch - loss: 113.31646 - diff: 28.23mlTrain batch 24/32 - 174.2ms/batch - loss: 110.00356 - diff: 27.82mlTrain batch 25/32 - 174.1ms/batch - loss: 107.63764 - diff: 27.59mlTrain batch 26/32 - 174.7ms/batch - loss: 105.89967 - diff: 27.40mlTrain batch 27/32 - 173.8ms/batch - loss: 112.45080 - diff: 27.75mlTrain batch 28/32 - 173.9ms/batch - loss: 109.56639 - diff: 27.40mlTrain batch 29/32 - 173.9ms/batch - loss: 107.45180 - diff: 27.24mlTrain batch 30/32 - 173.8ms/batch - loss: 104.93348 - diff: 26.93mlTrain batch 31/32 - 173.9ms/batch - loss: 102.25386 - diff: 26.57mlTrain batch 32/32 - 53.4ms/batch - loss: 109.85069 - diff: 26.79mlTrain batch 32/32 - 10.5s 53.4ms/batch - loss: 109.85069 - diff: 26.79ml
Test 1.1s: val_loss: 80.19800 - diff: 23.46ml

Epoch 35: current best loss = 78.18402, at epoch 28
Train batch 1/32 - 174.2ms/batch - loss: 35.35393 - diff: 19.34mlTrain batch 2/32 - 174.2ms/batch - loss: 46.03813 - diff: 21.44mlTrain batch 3/32 - 174.2ms/batch - loss: 49.58211 - diff: 20.94mlTrain batch 4/32 - 173.8ms/batch - loss: 54.90531 - diff: 21.31mlTrain batch 5/32 - 173.7ms/batch - loss: 60.81508 - diff: 23.37mlTrain batch 6/32 - 173.6ms/batch - loss: 96.21609 - diff: 27.06mlTrain batch 7/32 - 173.8ms/batch - loss: 99.59346 - diff: 27.45mlTrain batch 8/32 - 174.2ms/batch - loss: 114.74305 - diff: 27.70mlTrain batch 9/32 - 174.1ms/batch - loss: 105.41212 - diff: 26.58mlTrain batch 10/32 - 174.1ms/batch - loss: 96.85089 - diff: 25.33mlTrain batch 11/32 - 173.9ms/batch - loss: 96.34436 - diff: 25.36mlTrain batch 12/32 - 174.3ms/batch - loss: 91.22884 - diff: 24.82mlTrain batch 13/32 - 174.3ms/batch - loss: 88.94856 - diff: 24.85mlTrain batch 14/32 - 174.4ms/batch - loss: 86.93750 - diff: 24.63mlTrain batch 15/32 - 174.6ms/batch - loss: 85.03379 - diff: 24.55mlTrain batch 16/32 - 174.7ms/batch - loss: 82.06790 - diff: 24.31mlTrain batch 17/32 - 174.5ms/batch - loss: 123.97278 - diff: 26.68mlTrain batch 18/32 - 174.6ms/batch - loss: 124.06765 - diff: 26.98mlTrain batch 19/32 - 174.4ms/batch - loss: 122.09695 - diff: 26.80mlTrain batch 20/32 - 174.4ms/batch - loss: 121.81212 - diff: 26.93mlTrain batch 21/32 - 174.5ms/batch - loss: 117.50417 - diff: 26.55mlTrain batch 22/32 - 174.5ms/batch - loss: 114.53017 - diff: 26.49mlTrain batch 23/32 - 173.7ms/batch - loss: 112.17953 - diff: 26.48mlTrain batch 24/32 - 174.2ms/batch - loss: 109.57249 - diff: 26.39mlTrain batch 25/32 - 174.1ms/batch - loss: 106.65634 - diff: 26.08mlTrain batch 26/32 - 174.1ms/batch - loss: 103.64063 - diff: 25.71mlTrain batch 27/32 - 174.2ms/batch - loss: 103.53024 - diff: 26.02mlTrain batch 28/32 - 174.4ms/batch - loss: 103.42472 - diff: 26.18mlTrain batch 29/32 - 174.1ms/batch - loss: 102.58597 - diff: 26.27mlTrain batch 30/32 - 174.3ms/batch - loss: 100.60762 - diff: 26.13mlTrain batch 31/32 - 173.9ms/batch - loss: 99.29166 - diff: 26.11mlTrain batch 32/32 - 53.4ms/batch - loss: 100.65865 - diff: 26.13mlTrain batch 32/32 - 10.5s 53.4ms/batch - loss: 100.65865 - diff: 26.13ml
Test 1.1s: val_loss: 81.46240 - diff: 27.36ml

Epoch 36: current best loss = 78.18402, at epoch 28
Train batch 1/32 - 174.0ms/batch - loss: 100.17280 - diff: 31.69mlTrain batch 2/32 - 173.9ms/batch - loss: 63.35382 - diff: 24.28mlTrain batch 3/32 - 174.0ms/batch - loss: 66.60790 - diff: 25.56mlTrain batch 4/32 - 174.0ms/batch - loss: 61.34438 - diff: 24.34mlTrain batch 5/32 - 173.9ms/batch - loss: 177.88853 - diff: 27.57mlTrain batch 6/32 - 174.4ms/batch - loss: 151.87288 - diff: 25.47mlTrain batch 7/32 - 174.0ms/batch - loss: 137.39736 - diff: 25.05mlTrain batch 8/32 - 174.5ms/batch - loss: 127.74701 - diff: 25.10mlTrain batch 9/32 - 174.1ms/batch - loss: 118.51247 - diff: 24.55mlTrain batch 10/32 - 174.4ms/batch - loss: 123.13337 - diff: 25.65mlTrain batch 11/32 - 174.2ms/batch - loss: 115.96769 - diff: 25.29mlTrain batch 12/32 - 174.8ms/batch - loss: 111.33312 - diff: 25.16mlTrain batch 13/32 - 174.4ms/batch - loss: 111.27135 - diff: 25.40mlTrain batch 14/32 - 174.3ms/batch - loss: 107.12372 - diff: 25.05mlTrain batch 15/32 - 174.4ms/batch - loss: 103.60134 - diff: 24.94mlTrain batch 16/32 - 173.9ms/batch - loss: 102.80460 - diff: 25.01mlTrain batch 17/32 - 174.2ms/batch - loss: 99.79403 - diff: 24.84mlTrain batch 18/32 - 174.6ms/batch - loss: 98.65773 - diff: 25.15mlTrain batch 19/32 - 174.0ms/batch - loss: 95.33562 - diff: 24.97mlTrain batch 20/32 - 174.1ms/batch - loss: 95.42774 - diff: 25.23mlTrain batch 21/32 - 174.0ms/batch - loss: 94.41957 - diff: 25.35mlTrain batch 22/32 - 174.6ms/batch - loss: 91.50013 - diff: 25.08mlTrain batch 23/32 - 173.7ms/batch - loss: 99.34637 - diff: 25.71mlTrain batch 24/32 - 174.1ms/batch - loss: 96.17834 - diff: 25.24mlTrain batch 25/32 - 173.9ms/batch - loss: 99.25386 - diff: 25.65mlTrain batch 26/32 - 174.2ms/batch - loss: 96.83897 - diff: 25.44mlTrain batch 27/32 - 174.0ms/batch - loss: 96.56254 - diff: 25.53mlTrain batch 28/32 - 174.4ms/batch - loss: 97.38892 - diff: 25.83mlTrain batch 29/32 - 174.0ms/batch - loss: 96.16861 - diff: 25.76mlTrain batch 30/32 - 174.3ms/batch - loss: 97.74100 - diff: 26.06mlTrain batch 31/32 - 174.3ms/batch - loss: 96.48142 - diff: 26.00mlTrain batch 32/32 - 53.5ms/batch - loss: 97.66273 - diff: 26.00mlTrain batch 32/32 - 10.5s 53.5ms/batch - loss: 97.66273 - diff: 26.00ml
Test 1.1s: val_loss: 76.38424 - diff: 25.36ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Systole_WideResNet50_0_Adam-0.001_MSE_DA3_best

Epoch 37: current best loss = 76.38424, at epoch 36
Train batch 1/32 - 188.1ms/batch - loss: 47.68869 - diff: 22.18mlTrain batch 2/32 - 177.9ms/batch - loss: 45.71672 - diff: 22.25mlTrain batch 3/32 - 173.8ms/batch - loss: 44.99726 - diff: 22.51mlTrain batch 4/32 - 174.1ms/batch - loss: 45.74566 - diff: 21.84mlTrain batch 5/32 - 173.9ms/batch - loss: 53.72664 - diff: 23.72mlTrain batch 6/32 - 174.3ms/batch - loss: 52.19089 - diff: 23.33mlTrain batch 7/32 - 174.3ms/batch - loss: 52.40808 - diff: 23.54mlTrain batch 8/32 - 174.2ms/batch - loss: 51.40940 - diff: 23.23mlTrain batch 9/32 - 174.0ms/batch - loss: 52.79718 - diff: 22.96mlTrain batch 10/32 - 174.3ms/batch - loss: 70.20827 - diff: 23.74mlTrain batch 11/32 - 174.1ms/batch - loss: 70.71149 - diff: 23.95mlTrain batch 12/32 - 174.6ms/batch - loss: 68.12549 - diff: 23.86mlTrain batch 13/32 - 173.8ms/batch - loss: 113.21365 - diff: 25.18mlTrain batch 14/32 - 174.5ms/batch - loss: 111.48857 - diff: 25.44mlTrain batch 15/32 - 173.8ms/batch - loss: 114.33809 - diff: 26.29mlTrain batch 16/32 - 173.8ms/batch - loss: 122.29629 - diff: 27.21mlTrain batch 17/32 - 174.3ms/batch - loss: 121.11541 - diff: 27.35mlTrain batch 18/32 - 173.6ms/batch - loss: 120.60197 - diff: 27.61mlTrain batch 19/32 - 174.0ms/batch - loss: 116.49864 - diff: 27.26mlTrain batch 20/32 - 174.3ms/batch - loss: 112.82662 - diff: 26.93mlTrain batch 21/32 - 173.8ms/batch - loss: 112.87669 - diff: 26.97mlTrain batch 22/32 - 174.4ms/batch - loss: 109.33898 - diff: 26.64mlTrain batch 23/32 - 173.9ms/batch - loss: 107.92628 - diff: 26.71mlTrain batch 24/32 - 174.2ms/batch - loss: 107.12439 - diff: 26.83mlTrain batch 25/32 - 174.2ms/batch - loss: 103.65514 - diff: 26.31mlTrain batch 26/32 - 174.2ms/batch - loss: 103.10795 - diff: 26.24mlTrain batch 27/32 - 174.0ms/batch - loss: 106.08289 - diff: 26.76mlTrain batch 28/32 - 174.6ms/batch - loss: 104.17192 - diff: 26.73mlTrain batch 29/32 - 174.0ms/batch - loss: 102.28212 - diff: 26.63mlTrain batch 30/32 - 173.8ms/batch - loss: 102.14676 - diff: 26.70mlTrain batch 31/32 - 174.3ms/batch - loss: 100.44887 - diff: 26.64mlTrain batch 32/32 - 53.4ms/batch - loss: 100.50900 - diff: 26.57mlTrain batch 32/32 - 10.5s 53.4ms/batch - loss: 100.50900 - diff: 26.57ml
Test 1.1s: val_loss: 80.34528 - diff: 25.66ml

Epoch 38: current best loss = 76.38424, at epoch 36
Train batch 1/32 - 174.1ms/batch - loss: 34.40087 - diff: 20.84mlTrain batch 2/32 - 174.4ms/batch - loss: 32.95527 - diff: 20.72mlTrain batch 3/32 - 174.1ms/batch - loss: 37.15718 - diff: 22.01mlTrain batch 4/32 - 174.3ms/batch - loss: 52.53157 - diff: 22.92mlTrain batch 5/32 - 174.1ms/batch - loss: 94.54197 - diff: 27.27mlTrain batch 6/32 - 174.6ms/batch - loss: 94.39260 - diff: 27.06mlTrain batch 7/32 - 174.3ms/batch - loss: 95.11044 - diff: 27.88mlTrain batch 8/32 - 174.3ms/batch - loss: 89.70555 - diff: 26.75mlTrain batch 9/32 - 174.4ms/batch - loss: 81.83592 - diff: 25.36mlTrain batch 10/32 - 173.7ms/batch - loss: 76.78852 - diff: 24.64mlTrain batch 11/32 - 173.9ms/batch - loss: 130.36789 - diff: 26.47mlTrain batch 12/32 - 173.8ms/batch - loss: 126.41066 - diff: 26.54mlTrain batch 13/32 - 174.3ms/batch - loss: 121.92872 - diff: 26.62mlTrain batch 14/32 - 174.4ms/batch - loss: 119.15329 - diff: 26.74mlTrain batch 15/32 - 174.1ms/batch - loss: 115.25941 - diff: 26.59mlTrain batch 16/32 - 174.4ms/batch - loss: 121.73586 - diff: 27.52mlTrain batch 17/32 - 174.0ms/batch - loss: 116.28178 - diff: 26.95mlTrain batch 18/32 - 174.3ms/batch - loss: 113.38341 - diff: 26.88mlTrain batch 19/32 - 174.4ms/batch - loss: 112.06996 - diff: 26.88mlTrain batch 20/32 - 174.6ms/batch - loss: 109.05898 - diff: 26.80mlTrain batch 21/32 - 174.5ms/batch - loss: 107.95625 - diff: 26.84mlTrain batch 22/32 - 174.4ms/batch - loss: 104.32307 - diff: 26.38mlTrain batch 23/32 - 174.5ms/batch - loss: 106.49943 - diff: 26.74mlTrain batch 24/32 - 174.5ms/batch - loss: 104.23727 - diff: 26.62mlTrain batch 25/32 - 174.7ms/batch - loss: 101.70081 - diff: 26.39mlTrain batch 26/32 - 174.5ms/batch - loss: 99.77655 - diff: 26.18mlTrain batch 27/32 - 174.0ms/batch - loss: 99.58219 - diff: 26.15mlTrain batch 28/32 - 174.4ms/batch - loss: 104.34774 - diff: 26.45mlTrain batch 29/32 - 174.0ms/batch - loss: 101.99935 - diff: 26.25mlTrain batch 30/32 - 174.3ms/batch - loss: 99.89109 - diff: 25.98mlTrain batch 31/32 - 173.6ms/batch - loss: 97.87811 - diff: 25.74mlTrain batch 32/32 - 53.3ms/batch - loss: 99.74619 - diff: 25.75mlTrain batch 32/32 - 10.5s 53.3ms/batch - loss: 99.74619 - diff: 25.75ml
Test 1.1s: val_loss: 72.96481 - diff: 23.66ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Systole_WideResNet50_0_Adam-0.001_MSE_DA3_best

Epoch 39: current best loss = 72.96481, at epoch 38
Train batch 1/32 - 188.2ms/batch - loss: 98.99672 - diff: 31.03mlTrain batch 2/32 - 178.9ms/batch - loss: 78.07525 - diff: 28.86mlTrain batch 3/32 - 173.9ms/batch - loss: 67.85477 - diff: 26.90mlTrain batch 4/32 - 173.5ms/batch - loss: 75.00318 - diff: 26.28mlTrain batch 5/32 - 173.9ms/batch - loss: 64.24493 - diff: 24.04mlTrain batch 6/32 - 173.2ms/batch - loss: 63.61838 - diff: 23.71mlTrain batch 7/32 - 174.0ms/batch - loss: 76.53075 - diff: 24.54mlTrain batch 8/32 - 174.3ms/batch - loss: 85.01840 - diff: 25.57mlTrain batch 9/32 - 174.3ms/batch - loss: 79.23950 - diff: 24.96mlTrain batch 10/32 - 174.3ms/batch - loss: 76.56456 - diff: 24.64mlTrain batch 11/32 - 174.3ms/batch - loss: 74.07366 - diff: 24.24mlTrain batch 12/32 - 174.3ms/batch - loss: 130.37691 - diff: 27.13mlTrain batch 13/32 - 173.8ms/batch - loss: 142.46055 - diff: 28.58mlTrain batch 14/32 - 174.3ms/batch - loss: 134.97136 - diff: 28.01mlTrain batch 15/32 - 174.1ms/batch - loss: 135.48435 - diff: 28.24mlTrain batch 16/32 - 174.6ms/batch - loss: 131.36392 - diff: 28.29mlTrain batch 17/32 - 174.3ms/batch - loss: 128.56579 - diff: 28.67mlTrain batch 18/32 - 174.6ms/batch - loss: 125.48374 - diff: 28.43mlTrain batch 19/32 - 173.8ms/batch - loss: 121.84221 - diff: 28.29mlTrain batch 20/32 - 174.4ms/batch - loss: 121.94126 - diff: 28.55mlTrain batch 21/32 - 174.2ms/batch - loss: 117.31292 - diff: 27.96mlTrain batch 22/32 - 174.2ms/batch - loss: 113.62578 - diff: 27.62mlTrain batch 23/32 - 174.1ms/batch - loss: 110.11870 - diff: 27.17mlTrain batch 24/32 - 174.4ms/batch - loss: 112.13458 - diff: 27.46mlTrain batch 25/32 - 174.2ms/batch - loss: 109.63239 - diff: 27.39mlTrain batch 26/32 - 174.1ms/batch - loss: 106.61719 - diff: 27.11mlTrain batch 27/32 - 173.9ms/batch - loss: 104.41048 - diff: 26.96mlTrain batch 28/32 - 174.5ms/batch - loss: 102.52324 - diff: 26.85mlTrain batch 29/32 - 174.3ms/batch - loss: 101.39106 - diff: 26.90mlTrain batch 30/32 - 174.2ms/batch - loss: 101.20071 - diff: 26.98mlTrain batch 31/32 - 174.2ms/batch - loss: 99.06528 - diff: 26.72mlTrain batch 32/32 - 53.4ms/batch - loss: 99.24668 - diff: 26.67mlTrain batch 32/32 - 10.5s 53.4ms/batch - loss: 99.24668 - diff: 26.67ml
Test 1.1s: val_loss: 78.23666 - diff: 23.25ml

Epoch 40: current best loss = 72.96481, at epoch 38
Train batch 1/32 - 174.2ms/batch - loss: 63.48653 - diff: 19.48mlTrain batch 2/32 - 174.0ms/batch - loss: 122.78150 - diff: 28.86mlTrain batch 3/32 - 174.0ms/batch - loss: 110.06481 - diff: 28.20mlTrain batch 4/32 - 174.4ms/batch - loss: 98.30442 - diff: 26.64mlTrain batch 5/32 - 174.4ms/batch - loss: 112.44487 - diff: 28.58mlTrain batch 6/32 - 174.6ms/batch - loss: 133.24906 - diff: 29.37mlTrain batch 7/32 - 174.4ms/batch - loss: 124.88198 - diff: 28.89mlTrain batch 8/32 - 174.3ms/batch - loss: 117.94773 - diff: 28.53mlTrain batch 9/32 - 174.5ms/batch - loss: 115.49296 - diff: 27.83mlTrain batch 10/32 - 173.7ms/batch - loss: 119.56042 - diff: 28.05mlTrain batch 11/32 - 173.8ms/batch - loss: 115.22752 - diff: 27.45mlTrain batch 12/32 - 173.6ms/batch - loss: 108.31356 - diff: 26.74mlTrain batch 13/32 - 173.7ms/batch - loss: 106.17423 - diff: 26.85mlTrain batch 14/32 - 174.6ms/batch - loss: 101.22003 - diff: 26.38mlTrain batch 15/32 - 174.3ms/batch - loss: 96.83139 - diff: 25.91mlTrain batch 16/32 - 174.2ms/batch - loss: 133.58818 - diff: 27.20mlTrain batch 17/32 - 174.2ms/batch - loss: 128.59138 - diff: 26.93mlTrain batch 18/32 - 174.5ms/batch - loss: 126.67738 - diff: 26.80mlTrain batch 19/32 - 174.4ms/batch - loss: 122.21596 - diff: 26.39mlTrain batch 20/32 - 174.5ms/batch - loss: 118.37213 - diff: 26.20mlTrain batch 21/32 - 174.4ms/batch - loss: 114.39326 - diff: 25.92mlTrain batch 22/32 - 174.5ms/batch - loss: 111.34151 - diff: 25.82mlTrain batch 23/32 - 173.8ms/batch - loss: 109.59700 - diff: 25.93mlTrain batch 24/32 - 173.7ms/batch - loss: 106.33224 - diff: 25.62mlTrain batch 25/32 - 174.5ms/batch - loss: 105.14965 - diff: 25.75mlTrain batch 26/32 - 174.6ms/batch - loss: 104.04813 - diff: 25.88mlTrain batch 27/32 - 174.2ms/batch - loss: 103.04258 - diff: 25.96mlTrain batch 28/32 - 174.6ms/batch - loss: 102.27102 - diff: 26.01mlTrain batch 29/32 - 174.3ms/batch - loss: 100.02696 - diff: 25.85mlTrain batch 30/32 - 174.6ms/batch - loss: 99.16049 - diff: 25.89mlTrain batch 31/32 - 174.4ms/batch - loss: 97.37588 - diff: 25.68mlTrain batch 32/32 - 53.4ms/batch - loss: 97.41316 - diff: 25.58mlTrain batch 32/32 - 10.6s 53.4ms/batch - loss: 97.41316 - diff: 25.58ml
Test 1.1s: val_loss: 72.63996 - diff: 23.51ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Systole_WideResNet50_0_Adam-0.001_MSE_DA3_best

Epoch 41: current best loss = 72.63996, at epoch 40
Train batch 1/32 - 173.9ms/batch - loss: 28.50893 - diff: 17.80mlTrain batch 2/32 - 173.9ms/batch - loss: 52.58339 - diff: 20.66mlTrain batch 3/32 - 174.2ms/batch - loss: 55.20011 - diff: 21.38mlTrain batch 4/32 - 174.1ms/batch - loss: 76.25819 - diff: 23.48mlTrain batch 5/32 - 173.9ms/batch - loss: 76.91494 - diff: 22.92mlTrain batch 6/32 - 174.3ms/batch - loss: 70.80842 - diff: 22.61mlTrain batch 7/32 - 174.3ms/batch - loss: 71.10984 - diff: 22.85mlTrain batch 8/32 - 174.6ms/batch - loss: 94.21592 - diff: 24.80mlTrain batch 9/32 - 174.6ms/batch - loss: 90.10472 - diff: 24.43mlTrain batch 10/32 - 174.7ms/batch - loss: 90.49244 - diff: 24.88mlTrain batch 11/32 - 174.4ms/batch - loss: 90.56856 - diff: 25.20mlTrain batch 12/32 - 174.6ms/batch - loss: 86.86721 - diff: 25.06mlTrain batch 13/32 - 174.3ms/batch - loss: 134.14258 - diff: 26.86mlTrain batch 14/32 - 173.8ms/batch - loss: 126.81110 - diff: 26.19mlTrain batch 15/32 - 174.3ms/batch - loss: 121.77834 - diff: 26.10mlTrain batch 16/32 - 174.7ms/batch - loss: 120.62968 - diff: 26.28mlTrain batch 17/32 - 174.4ms/batch - loss: 117.04537 - diff: 26.03mlTrain batch 18/32 - 174.0ms/batch - loss: 116.21876 - diff: 26.14mlTrain batch 19/32 - 173.9ms/batch - loss: 113.59531 - diff: 25.94mlTrain batch 20/32 - 174.5ms/batch - loss: 110.78596 - diff: 25.69mlTrain batch 21/32 - 173.9ms/batch - loss: 116.57112 - diff: 26.04mlTrain batch 22/32 - 174.8ms/batch - loss: 115.89321 - diff: 26.00mlTrain batch 23/32 - 174.3ms/batch - loss: 113.24683 - diff: 25.88mlTrain batch 24/32 - 174.5ms/batch - loss: 111.08353 - diff: 25.85mlTrain batch 25/32 - 174.4ms/batch - loss: 107.82665 - diff: 25.55mlTrain batch 26/32 - 174.7ms/batch - loss: 106.38384 - diff: 25.55mlTrain batch 27/32 - 174.6ms/batch - loss: 104.74887 - diff: 25.56mlTrain batch 28/32 - 174.6ms/batch - loss: 102.12851 - diff: 25.31mlTrain batch 29/32 - 174.4ms/batch - loss: 100.21939 - diff: 25.23mlTrain batch 30/32 - 174.1ms/batch - loss: 99.11600 - diff: 25.28mlTrain batch 31/32 - 174.4ms/batch - loss: 97.56364 - diff: 25.24mlTrain batch 32/32 - 53.4ms/batch - loss: 104.97312 - diff: 25.41mlTrain batch 32/32 - 10.5s 53.4ms/batch - loss: 104.97312 - diff: 25.41ml
Test 1.1s: val_loss: 74.53363 - diff: 25.71ml

Epoch 42: current best loss = 72.63996, at epoch 40
Train batch 1/32 - 174.1ms/batch - loss: 70.09269 - diff: 24.55mlTrain batch 2/32 - 174.0ms/batch - loss: 93.77152 - diff: 27.78mlTrain batch 3/32 - 174.3ms/batch - loss: 91.63631 - diff: 28.58mlTrain batch 4/32 - 174.6ms/batch - loss: 78.69410 - diff: 27.02mlTrain batch 5/32 - 174.3ms/batch - loss: 94.33315 - diff: 28.51mlTrain batch 6/32 - 175.0ms/batch - loss: 188.28303 - diff: 31.39mlTrain batch 7/32 - 174.4ms/batch - loss: 168.93901 - diff: 30.63mlTrain batch 8/32 - 174.3ms/batch - loss: 158.21533 - diff: 30.08mlTrain batch 9/32 - 174.4ms/batch - loss: 150.48897 - diff: 29.59mlTrain batch 10/32 - 174.5ms/batch - loss: 165.77076 - diff: 30.67mlTrain batch 11/32 - 174.1ms/batch - loss: 154.32263 - diff: 29.92mlTrain batch 12/32 - 174.1ms/batch - loss: 146.58295 - diff: 29.30mlTrain batch 13/32 - 173.9ms/batch - loss: 144.62483 - diff: 29.02mlTrain batch 14/32 - 174.3ms/batch - loss: 138.03031 - diff: 28.81mlTrain batch 15/32 - 173.8ms/batch - loss: 131.31533 - diff: 28.39mlTrain batch 16/32 - 174.0ms/batch - loss: 126.40157 - diff: 28.14mlTrain batch 17/32 - 174.2ms/batch - loss: 122.71898 - diff: 28.03mlTrain batch 18/32 - 174.3ms/batch - loss: 119.33868 - diff: 27.89mlTrain batch 19/32 - 174.3ms/batch - loss: 114.66145 - diff: 27.39mlTrain batch 20/32 - 174.6ms/batch - loss: 112.00995 - diff: 27.39mlTrain batch 21/32 - 174.4ms/batch - loss: 108.43579 - diff: 27.08mlTrain batch 22/32 - 174.7ms/batch - loss: 106.08573 - diff: 27.02mlTrain batch 23/32 - 174.6ms/batch - loss: 105.86932 - diff: 27.03mlTrain batch 24/32 - 174.7ms/batch - loss: 103.70826 - diff: 26.93mlTrain batch 25/32 - 174.4ms/batch - loss: 100.85908 - diff: 26.60mlTrain batch 26/32 - 174.8ms/batch - loss: 101.00539 - diff: 26.80mlTrain batch 27/32 - 174.0ms/batch - loss: 98.78073 - diff: 26.51mlTrain batch 28/32 - 174.4ms/batch - loss: 99.23001 - diff: 26.62mlTrain batch 29/32 - 174.2ms/batch - loss: 96.80054 - diff: 26.27mlTrain batch 30/32 - 174.4ms/batch - loss: 95.37915 - diff: 26.14mlTrain batch 31/32 - 173.9ms/batch - loss: 94.16428 - diff: 25.98mlTrain batch 32/32 - 53.6ms/batch - loss: 101.23417 - diff: 26.20mlTrain batch 32/32 - 10.5s 53.6ms/batch - loss: 101.23417 - diff: 26.20ml
Test 1.1s: val_loss: 71.37224 - diff: 24.02ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Systole_WideResNet50_0_Adam-0.001_MSE_DA3_best

Epoch 43: current best loss = 71.37224, at epoch 42
Train batch 1/32 - 174.0ms/batch - loss: 27.09727 - diff: 15.17mlTrain batch 2/32 - 174.5ms/batch - loss: 50.25330 - diff: 21.61mlTrain batch 3/32 - 174.1ms/batch - loss: 62.40148 - diff: 21.89mlTrain batch 4/32 - 174.1ms/batch - loss: 62.63490 - diff: 22.34mlTrain batch 5/32 - 174.1ms/batch - loss: 55.34659 - diff: 21.53mlTrain batch 6/32 - 174.1ms/batch - loss: 56.37276 - diff: 22.46mlTrain batch 7/32 - 174.1ms/batch - loss: 55.96757 - diff: 22.35mlTrain batch 8/32 - 174.3ms/batch - loss: 63.55616 - diff: 23.28mlTrain batch 9/32 - 174.0ms/batch - loss: 73.91256 - diff: 24.49mlTrain batch 10/32 - 174.5ms/batch - loss: 71.23714 - diff: 24.27mlTrain batch 11/32 - 174.1ms/batch - loss: 74.07007 - diff: 24.56mlTrain batch 12/32 - 174.3ms/batch - loss: 76.58615 - diff: 24.76mlTrain batch 13/32 - 174.2ms/batch - loss: 95.21331 - diff: 26.15mlTrain batch 14/32 - 174.3ms/batch - loss: 93.47012 - diff: 26.24mlTrain batch 15/32 - 174.0ms/batch - loss: 90.52546 - diff: 26.12mlTrain batch 16/32 - 174.7ms/batch - loss: 88.05362 - diff: 25.72mlTrain batch 17/32 - 174.5ms/batch - loss: 85.42794 - diff: 25.29mlTrain batch 18/32 - 174.3ms/batch - loss: 89.56325 - diff: 25.89mlTrain batch 19/32 - 173.9ms/batch - loss: 87.77503 - diff: 25.87mlTrain batch 20/32 - 173.7ms/batch - loss: 87.35200 - diff: 25.70mlTrain batch 21/32 - 174.0ms/batch - loss: 88.48473 - diff: 25.92mlTrain batch 22/32 - 174.1ms/batch - loss: 87.70122 - diff: 26.02mlTrain batch 23/32 - 174.2ms/batch - loss: 85.84439 - diff: 25.79mlTrain batch 24/32 - 174.4ms/batch - loss: 84.00904 - diff: 25.69mlTrain batch 25/32 - 174.7ms/batch - loss: 83.05196 - diff: 25.69mlTrain batch 26/32 - 174.6ms/batch - loss: 103.47566 - diff: 26.35mlTrain batch 27/32 - 174.3ms/batch - loss: 101.00975 - diff: 26.04mlTrain batch 28/32 - 174.5ms/batch - loss: 99.78764 - diff: 25.91mlTrain batch 29/32 - 174.6ms/batch - loss: 98.75574 - diff: 25.81mlTrain batch 30/32 - 174.6ms/batch - loss: 96.94230 - diff: 25.70mlTrain batch 31/32 - 174.5ms/batch - loss: 95.47884 - diff: 25.67mlTrain batch 32/32 - 53.4ms/batch - loss: 95.69235 - diff: 25.61mlTrain batch 32/32 - 10.5s 53.4ms/batch - loss: 95.69235 - diff: 25.61ml
Test 1.1s: val_loss: 87.06332 - diff: 27.29ml

Epoch 44: current best loss = 71.37224, at epoch 42
Train batch 1/32 - 174.2ms/batch - loss: 38.82209 - diff: 21.43mlTrain batch 2/32 - 174.0ms/batch - loss: 85.41281 - diff: 27.93mlTrain batch 3/32 - 173.9ms/batch - loss: 70.63286 - diff: 25.64mlTrain batch 4/32 - 174.2ms/batch - loss: 77.06981 - diff: 26.44mlTrain batch 5/32 - 174.4ms/batch - loss: 70.96986 - diff: 26.00mlTrain batch 6/32 - 174.7ms/batch - loss: 67.38830 - diff: 26.04mlTrain batch 7/32 - 174.2ms/batch - loss: 61.42345 - diff: 24.65mlTrain batch 8/32 - 174.8ms/batch - loss: 56.04103 - diff: 23.31mlTrain batch 9/32 - 174.3ms/batch - loss: 67.92112 - diff: 25.17mlTrain batch 10/32 - 173.8ms/batch - loss: 75.30135 - diff: 25.68mlTrain batch 11/32 - 174.5ms/batch - loss: 73.43794 - diff: 25.45mlTrain batch 12/32 - 174.6ms/batch - loss: 73.81881 - diff: 25.56mlTrain batch 13/32 - 174.5ms/batch - loss: 72.53827 - diff: 25.47mlTrain batch 14/32 - 174.5ms/batch - loss: 73.05584 - diff: 25.31mlTrain batch 15/32 - 174.4ms/batch - loss: 70.51942 - diff: 24.93mlTrain batch 16/32 - 174.6ms/batch - loss: 67.02363 - diff: 24.17mlTrain batch 17/32 - 174.3ms/batch - loss: 66.10607 - diff: 24.09mlTrain batch 18/32 - 174.5ms/batch - loss: 66.91118 - diff: 24.25mlTrain batch 19/32 - 174.4ms/batch - loss: 71.09057 - diff: 24.51mlTrain batch 20/32 - 174.5ms/batch - loss: 72.89743 - diff: 24.50mlTrain batch 21/32 - 174.5ms/batch - loss: 71.14526 - diff: 24.20mlTrain batch 22/32 - 173.8ms/batch - loss: 71.17757 - diff: 24.30mlTrain batch 23/32 - 174.1ms/batch - loss: 70.58238 - diff: 24.20mlTrain batch 24/32 - 174.5ms/batch - loss: 68.91796 - diff: 23.98mlTrain batch 25/32 - 174.6ms/batch - loss: 68.73281 - diff: 24.06mlTrain batch 26/32 - 174.4ms/batch - loss: 93.11652 - diff: 25.04mlTrain batch 27/32 - 174.4ms/batch - loss: 91.92749 - diff: 24.97mlTrain batch 28/32 - 174.6ms/batch - loss: 94.42065 - diff: 25.41mlTrain batch 29/32 - 174.3ms/batch - loss: 92.60334 - diff: 25.27mlTrain batch 30/32 - 174.4ms/batch - loss: 91.24986 - diff: 25.16mlTrain batch 31/32 - 174.4ms/batch - loss: 96.43200 - diff: 25.50mlTrain batch 32/32 - 53.4ms/batch - loss: 97.08454 - diff: 25.46mlTrain batch 32/32 - 10.6s 53.4ms/batch - loss: 97.08454 - diff: 25.46ml
Test 1.1s: val_loss: 73.99805 - diff: 24.92ml

Epoch 45: current best loss = 71.37224, at epoch 42
Going to unfreeze the pretrained weights
Train batch 1/32 - 235.2ms/batch - loss: 116.59724 - diff: 29.82mlTrain batch 2/32 - 236.9ms/batch - loss: 145.95205 - diff: 38.40mlTrain batch 3/32 - 237.0ms/batch - loss: 108.78171 - diff: 32.44mlTrain batch 4/32 - 237.2ms/batch - loss: 101.29973 - diff: 30.55mlTrain batch 5/32 - 237.3ms/batch - loss: 111.61222 - diff: 31.38mlTrain batch 6/32 - 237.2ms/batch - loss: 108.06989 - diff: 30.29mlTrain batch 7/32 - 236.8ms/batch - loss: 102.74341 - diff: 30.05mlTrain batch 8/32 - 237.5ms/batch - loss: 101.14237 - diff: 30.34mlTrain batch 9/32 - 237.0ms/batch - loss: 91.93683 - diff: 28.59mlTrain batch 10/32 - 237.5ms/batch - loss: 91.41555 - diff: 28.52mlTrain batch 11/32 - 237.3ms/batch - loss: 92.88770 - diff: 28.42mlTrain batch 12/32 - 237.5ms/batch - loss: 90.12386 - diff: 28.37mlTrain batch 13/32 - 237.1ms/batch - loss: 139.45604 - diff: 30.76mlTrain batch 14/32 - 237.5ms/batch - loss: 147.53514 - diff: 31.59mlTrain batch 15/32 - 237.5ms/batch - loss: 141.88087 - diff: 31.21mlTrain batch 16/32 - 237.2ms/batch - loss: 142.79397 - diff: 31.38mlTrain batch 17/32 - 237.4ms/batch - loss: 139.95761 - diff: 31.30mlTrain batch 18/32 - 237.4ms/batch - loss: 138.27579 - diff: 31.13mlTrain batch 19/32 - 236.9ms/batch - loss: 132.33840 - diff: 30.32mlTrain batch 20/32 - 237.4ms/batch - loss: 132.39089 - diff: 30.65mlTrain batch 21/32 - 237.4ms/batch - loss: 131.49005 - diff: 30.67mlTrain batch 22/32 - 237.2ms/batch - loss: 129.50071 - diff: 30.45mlTrain batch 23/32 - 237.2ms/batch - loss: 129.88605 - diff: 30.43mlTrain batch 24/32 - 237.5ms/batch - loss: 132.48565 - diff: 30.85mlTrain batch 25/32 - 236.9ms/batch - loss: 129.98152 - diff: 30.77mlTrain batch 26/32 - 237.2ms/batch - loss: 127.03708 - diff: 30.51mlTrain batch 27/32 - 237.2ms/batch - loss: 125.30749 - diff: 30.42mlTrain batch 28/32 - 237.3ms/batch - loss: 125.80645 - diff: 30.58mlTrain batch 29/32 - 237.5ms/batch - loss: 123.19571 - diff: 30.34mlTrain batch 30/32 - 237.3ms/batch - loss: 120.35885 - diff: 30.02mlTrain batch 31/32 - 237.3ms/batch - loss: 117.25854 - diff: 29.56mlTrain batch 32/32 - 76.4ms/batch - loss: 117.18745 - diff: 29.49mlTrain batch 32/32 - 10.6s 76.4ms/batch - loss: 117.18745 - diff: 29.49ml
Test 1.1s: val_loss: 102.07088 - diff: 30.54ml

Epoch 46: current best loss = 71.37224, at epoch 42
Train batch 1/32 - 237.2ms/batch - loss: 97.01157 - diff: 25.42mlTrain batch 2/32 - 237.3ms/batch - loss: 60.29703 - diff: 20.80mlTrain batch 3/32 - 237.4ms/batch - loss: 58.49952 - diff: 21.98mlTrain batch 4/32 - 237.2ms/batch - loss: 120.96732 - diff: 30.40mlTrain batch 5/32 - 236.9ms/batch - loss: 104.61989 - diff: 28.23mlTrain batch 6/32 - 237.2ms/batch - loss: 104.09401 - diff: 28.84mlTrain batch 7/32 - 236.9ms/batch - loss: 100.30425 - diff: 29.28mlTrain batch 8/32 - 237.6ms/batch - loss: 101.28772 - diff: 29.96mlTrain batch 9/32 - 237.1ms/batch - loss: 98.08813 - diff: 29.84mlTrain batch 10/32 - 237.6ms/batch - loss: 99.54354 - diff: 29.95mlTrain batch 11/32 - 237.1ms/batch - loss: 94.55544 - diff: 29.26mlTrain batch 12/32 - 237.5ms/batch - loss: 89.88368 - diff: 28.43mlTrain batch 13/32 - 237.4ms/batch - loss: 106.59400 - diff: 28.70mlTrain batch 14/32 - 237.5ms/batch - loss: 102.46133 - diff: 28.27mlTrain batch 15/32 - 237.0ms/batch - loss: 99.87831 - diff: 27.90mlTrain batch 16/32 - 237.4ms/batch - loss: 126.31371 - diff: 28.57mlTrain batch 17/32 - 237.3ms/batch - loss: 123.14487 - diff: 28.26mlTrain batch 18/32 - 237.1ms/batch - loss: 124.76309 - diff: 28.33mlTrain batch 19/32 - 236.8ms/batch - loss: 122.50333 - diff: 28.18mlTrain batch 20/32 - 237.2ms/batch - loss: 120.90895 - diff: 28.33mlTrain batch 21/32 - 237.4ms/batch - loss: 116.87725 - diff: 27.96mlTrain batch 22/32 - 237.6ms/batch - loss: 113.82577 - diff: 27.68mlTrain batch 23/32 - 237.2ms/batch - loss: 110.78324 - diff: 27.41mlTrain batch 24/32 - 237.4ms/batch - loss: 109.01060 - diff: 27.42mlTrain batch 25/32 - 237.0ms/batch - loss: 108.10390 - diff: 27.46mlTrain batch 26/32 - 237.7ms/batch - loss: 106.40435 - diff: 27.28mlTrain batch 27/32 - 237.2ms/batch - loss: 106.01208 - diff: 27.34mlTrain batch 28/32 - 237.8ms/batch - loss: 103.76656 - diff: 27.14mlTrain batch 29/32 - 236.9ms/batch - loss: 102.56190 - diff: 27.07mlTrain batch 30/32 - 237.3ms/batch - loss: 101.78710 - diff: 27.04mlTrain batch 31/32 - 237.2ms/batch - loss: 100.55023 - diff: 26.88mlTrain batch 32/32 - 76.6ms/batch - loss: 100.21807 - diff: 26.77mlTrain batch 32/32 - 10.6s 76.6ms/batch - loss: 100.21807 - diff: 26.77ml
Test 1.2s: val_loss: 16369.83875 - diff: 415.88ml

Epoch 47: current best loss = 71.37224, at epoch 42
Train batch 1/32 - 237.3ms/batch - loss: 136.49126 - diff: 26.18mlTrain batch 2/32 - 237.1ms/batch - loss: 83.23864 - diff: 21.00mlTrain batch 3/32 - 237.0ms/batch - loss: 94.37671 - diff: 23.96mlTrain batch 4/32 - 237.2ms/batch - loss: 83.26067 - diff: 23.66mlTrain batch 5/32 - 236.8ms/batch - loss: 74.24115 - diff: 23.02mlTrain batch 6/32 - 238.1ms/batch - loss: 83.74475 - diff: 25.29mlTrain batch 7/32 - 237.2ms/batch - loss: 78.90672 - diff: 25.34mlTrain batch 8/32 - 238.3ms/batch - loss: 103.50626 - diff: 26.89mlTrain batch 9/32 - 236.9ms/batch - loss: 150.27392 - diff: 29.24mlTrain batch 10/32 - 237.5ms/batch - loss: 143.98543 - diff: 28.98mlTrain batch 11/32 - 237.4ms/batch - loss: 136.36634 - diff: 28.91mlTrain batch 12/32 - 237.4ms/batch - loss: 127.87912 - diff: 27.98mlTrain batch 13/32 - 237.7ms/batch - loss: 123.68954 - diff: 27.62mlTrain batch 14/32 - 237.7ms/batch - loss: 117.46279 - diff: 27.10mlTrain batch 15/32 - 237.4ms/batch - loss: 116.74645 - diff: 27.64mlTrain batch 16/32 - 237.4ms/batch - loss: 112.21271 - diff: 27.18mlTrain batch 17/32 - 237.4ms/batch - loss: 110.50153 - diff: 26.94mlTrain batch 18/32 - 237.8ms/batch - loss: 107.75157 - diff: 26.76mlTrain batch 19/32 - 237.3ms/batch - loss: 103.78600 - diff: 26.34mlTrain batch 20/32 - 237.5ms/batch - loss: 101.36719 - diff: 26.13mlTrain batch 21/32 - 237.1ms/batch - loss: 97.70466 - diff: 25.66mlTrain batch 22/32 - 237.5ms/batch - loss: 94.34755 - diff: 25.16mlTrain batch 23/32 - 237.4ms/batch - loss: 91.49665 - diff: 24.84mlTrain batch 24/32 - 238.1ms/batch - loss: 89.38450 - diff: 24.57mlTrain batch 25/32 - 237.3ms/batch - loss: 93.11402 - diff: 25.03mlTrain batch 26/32 - 237.3ms/batch - loss: 91.62498 - diff: 25.06mlTrain batch 27/32 - 237.6ms/batch - loss: 90.46543 - diff: 25.08mlTrain batch 28/32 - 238.5ms/batch - loss: 89.00315 - diff: 25.00mlTrain batch 29/32 - 237.9ms/batch - loss: 88.47854 - diff: 25.00mlTrain batch 30/32 - 238.9ms/batch - loss: 86.57317 - diff: 24.79mlTrain batch 31/32 - 237.3ms/batch - loss: 85.25388 - diff: 24.75mlTrain batch 32/32 - 76.5ms/batch - loss: 85.06918 - diff: 24.66mlTrain batch 32/32 - 10.6s 76.5ms/batch - loss: 85.06918 - diff: 24.66ml
Test 1.2s: val_loss: 65.61265 - diff: 24.28ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Systole_WideResNet50_0_Adam-0.001_MSE_DA3_best

Epoch 48: current best loss = 65.61265, at epoch 47
Train batch 1/32 - 237.0ms/batch - loss: 61.27555 - diff: 24.42mlTrain batch 2/32 - 237.0ms/batch - loss: 41.41777 - diff: 19.16mlTrain batch 3/32 - 236.9ms/batch - loss: 38.54155 - diff: 18.95mlTrain batch 4/32 - 237.2ms/batch - loss: 56.08564 - diff: 20.79mlTrain batch 5/32 - 237.2ms/batch - loss: 60.69155 - diff: 21.91mlTrain batch 6/32 - 237.6ms/batch - loss: 57.79790 - diff: 21.47mlTrain batch 7/32 - 237.0ms/batch - loss: 54.73822 - diff: 20.71mlTrain batch 8/32 - 237.3ms/batch - loss: 53.00380 - diff: 20.46mlTrain batch 9/32 - 237.1ms/batch - loss: 59.06361 - diff: 21.43mlTrain batch 10/32 - 238.1ms/batch - loss: 56.97051 - diff: 21.53mlTrain batch 11/32 - 237.1ms/batch - loss: 58.83069 - diff: 21.80mlTrain batch 12/32 - 238.7ms/batch - loss: 57.94535 - diff: 21.87mlTrain batch 13/32 - 237.3ms/batch - loss: 57.91245 - diff: 22.29mlTrain batch 14/32 - 238.1ms/batch - loss: 56.98924 - diff: 22.41mlTrain batch 15/32 - 237.4ms/batch - loss: 54.95301 - diff: 21.99mlTrain batch 16/32 - 237.6ms/batch - loss: 52.20946 - diff: 21.35mlTrain batch 17/32 - 237.2ms/batch - loss: 51.32772 - diff: 21.17mlTrain batch 18/32 - 237.3ms/batch - loss: 70.46146 - diff: 22.66mlTrain batch 19/32 - 237.7ms/batch - loss: 69.62702 - diff: 22.75mlTrain batch 20/32 - 237.5ms/batch - loss: 67.22822 - diff: 22.28mlTrain batch 21/32 - 237.4ms/batch - loss: 65.26594 - diff: 22.03mlTrain batch 22/32 - 237.5ms/batch - loss: 63.24924 - diff: 21.72mlTrain batch 23/32 - 237.2ms/batch - loss: 85.34487 - diff: 22.72mlTrain batch 24/32 - 237.6ms/batch - loss: 85.90326 - diff: 22.83mlTrain batch 25/32 - 237.4ms/batch - loss: 83.84912 - diff: 22.70mlTrain batch 26/32 - 237.7ms/batch - loss: 85.55672 - diff: 23.13mlTrain batch 27/32 - 237.4ms/batch - loss: 83.58013 - diff: 22.93mlTrain batch 28/32 - 238.0ms/batch - loss: 82.31515 - diff: 22.92mlTrain batch 29/32 - 237.7ms/batch - loss: 80.75570 - diff: 22.82mlTrain batch 30/32 - 240.1ms/batch - loss: 80.23375 - diff: 23.00mlTrain batch 31/32 - 237.6ms/batch - loss: 80.54906 - diff: 23.27mlTrain batch 32/32 - 77.8ms/batch - loss: 81.61570 - diff: 23.31mlTrain batch 32/32 - 10.6s 77.8ms/batch - loss: 81.61570 - diff: 23.31ml
Test 1.1s: val_loss: 112.53070 - diff: 29.92ml

Epoch 49: current best loss = 65.61265, at epoch 47
Train batch 1/32 - 237.1ms/batch - loss: 78.26216 - diff: 29.64mlTrain batch 2/32 - 238.2ms/batch - loss: 110.33045 - diff: 33.54mlTrain batch 3/32 - 237.1ms/batch - loss: 102.80455 - diff: 32.82mlTrain batch 4/32 - 238.0ms/batch - loss: 96.10902 - diff: 32.06mlTrain batch 5/32 - 237.2ms/batch - loss: 89.58063 - diff: 30.64mlTrain batch 6/32 - 238.6ms/batch - loss: 82.67950 - diff: 29.46mlTrain batch 7/32 - 238.6ms/batch - loss: 79.97972 - diff: 29.02mlTrain batch 8/32 - 240.0ms/batch - loss: 72.97532 - diff: 27.41mlTrain batch 9/32 - 237.6ms/batch - loss: 107.96126 - diff: 28.45mlTrain batch 10/32 - 237.8ms/batch - loss: 103.06727 - diff: 27.59mlTrain batch 11/32 - 238.4ms/batch - loss: 97.58205 - diff: 27.03mlTrain batch 12/32 - 237.9ms/batch - loss: 92.84869 - diff: 26.68mlTrain batch 13/32 - 237.4ms/batch - loss: 89.96101 - diff: 26.63mlTrain batch 14/32 - 237.9ms/batch - loss: 89.03744 - diff: 26.47mlTrain batch 15/32 - 237.6ms/batch - loss: 86.09376 - diff: 26.18mlTrain batch 16/32 - 240.1ms/batch - loss: 82.33436 - diff: 25.71mlTrain batch 17/32 - 237.4ms/batch - loss: 79.89815 - diff: 25.35mlTrain batch 18/32 - 237.8ms/batch - loss: 77.95844 - diff: 25.21mlTrain batch 19/32 - 237.9ms/batch - loss: 77.08456 - diff: 25.36mlTrain batch 20/32 - 237.3ms/batch - loss: 75.69482 - diff: 25.15mlTrain batch 21/32 - 237.7ms/batch - loss: 73.90224 - diff: 24.89mlTrain batch 22/32 - 240.2ms/batch - loss: 74.54985 - diff: 24.78mlTrain batch 23/32 - 237.5ms/batch - loss: 73.48339 - diff: 24.59mlTrain batch 24/32 - 239.3ms/batch - loss: 72.30345 - diff: 24.40mlTrain batch 25/32 - 237.7ms/batch - loss: 70.57055 - diff: 24.12mlTrain batch 26/32 - 240.3ms/batch - loss: 68.94309 - diff: 23.81mlTrain batch 27/32 - 238.0ms/batch - loss: 67.76620 - diff: 23.68mlTrain batch 28/32 - 240.1ms/batch - loss: 67.60177 - diff: 23.74mlTrain batch 29/32 - 237.7ms/batch - loss: 65.65898 - diff: 23.28mlTrain batch 30/32 - 239.1ms/batch - loss: 65.57595 - diff: 23.24mlTrain batch 31/32 - 237.5ms/batch - loss: 73.31586 - diff: 23.73mlTrain batch 32/32 - 76.5ms/batch - loss: 73.51644 - diff: 23.69mlTrain batch 32/32 - 10.6s 76.5ms/batch - loss: 73.51644 - diff: 23.69ml
Test 1.1s: val_loss: 133.81497 - diff: 29.18ml

Epoch 50: current best loss = 65.61265, at epoch 47
Train batch 1/32 - 237.4ms/batch - loss: 68.59412 - diff: 27.81mlTrain batch 2/32 - 237.9ms/batch - loss: 46.84803 - diff: 21.76mlTrain batch 3/32 - 238.3ms/batch - loss: 46.68328 - diff: 22.01mlTrain batch 4/32 - 240.2ms/batch - loss: 44.48285 - diff: 21.28mlTrain batch 5/32 - 238.4ms/batch - loss: 39.48948 - diff: 19.80mlTrain batch 6/32 - 239.7ms/batch - loss: 42.94155 - diff: 20.12mlTrain batch 7/32 - 238.1ms/batch - loss: 43.85105 - diff: 20.63mlTrain batch 8/32 - 238.5ms/batch - loss: 42.12425 - diff: 20.45mlTrain batch 9/32 - 237.7ms/batch - loss: 40.60083 - diff: 19.98mlTrain batch 10/32 - 238.3ms/batch - loss: 37.79962 - diff: 19.04mlTrain batch 11/32 - 237.6ms/batch - loss: 48.57051 - diff: 20.07mlTrain batch 12/32 - 240.1ms/batch - loss: 50.57829 - diff: 20.60mlTrain batch 13/32 - 237.4ms/batch - loss: 89.53080 - diff: 22.30mlTrain batch 14/32 - 240.1ms/batch - loss: 86.79874 - diff: 22.18mlTrain batch 15/32 - 238.1ms/batch - loss: 82.91367 - diff: 21.71mlTrain batch 16/32 - 238.0ms/batch - loss: 80.41033 - diff: 21.67mlTrain batch 17/32 - 237.3ms/batch - loss: 78.03851 - diff: 21.66mlTrain batch 18/32 - 240.3ms/batch - loss: 76.12416 - diff: 21.65mlTrain batch 19/32 - 237.5ms/batch - loss: 73.54551 - diff: 21.33mlTrain batch 20/32 - 240.3ms/batch - loss: 73.13499 - diff: 21.53mlTrain batch 21/32 - 237.3ms/batch - loss: 73.08400 - diff: 21.77mlTrain batch 22/32 - 240.0ms/batch - loss: 73.68971 - diff: 22.22mlTrain batch 23/32 - 237.8ms/batch - loss: 74.43248 - diff: 22.50mlTrain batch 24/32 - 240.2ms/batch - loss: 84.24191 - diff: 23.60mlTrain batch 25/32 - 238.2ms/batch - loss: 83.70547 - diff: 23.70mlTrain batch 26/32 - 240.0ms/batch - loss: 83.26782 - diff: 23.70mlTrain batch 27/32 - 237.1ms/batch - loss: 81.25783 - diff: 23.45mlTrain batch 28/32 - 238.8ms/batch - loss: 80.34398 - diff: 23.44mlTrain batch 29/32 - 238.5ms/batch - loss: 79.09411 - diff: 23.33mlTrain batch 30/32 - 239.9ms/batch - loss: 77.95798 - diff: 23.19mlTrain batch 31/32 - 238.6ms/batch - loss: 80.78226 - diff: 23.58mlTrain batch 32/32 - 77.7ms/batch - loss: 88.69086 - diff: 23.76mlTrain batch 32/32 - 10.6s 77.7ms/batch - loss: 88.69086 - diff: 23.76ml
Test 1.1s: val_loss: 98.00860 - diff: 26.86ml

Epoch 51: current best loss = 65.61265, at epoch 47
Train batch 1/32 - 237.2ms/batch - loss: 191.33054 - diff: 32.18mlTrain batch 2/32 - 238.5ms/batch - loss: 132.14024 - diff: 31.22mlTrain batch 3/32 - 237.3ms/batch - loss: 137.34557 - diff: 33.68mlTrain batch 4/32 - 238.9ms/batch - loss: 120.96712 - diff: 32.60mlTrain batch 5/32 - 238.0ms/batch - loss: 106.55560 - diff: 30.63mlTrain batch 6/32 - 238.1ms/batch - loss: 106.55485 - diff: 30.57mlTrain batch 7/32 - 238.1ms/batch - loss: 104.02010 - diff: 30.19mlTrain batch 8/32 - 239.4ms/batch - loss: 101.84291 - diff: 30.49mlTrain batch 9/32 - 237.3ms/batch - loss: 94.97542 - diff: 29.25mlTrain batch 10/32 - 239.9ms/batch - loss: 91.68404 - diff: 28.62mlTrain batch 11/32 - 237.3ms/batch - loss: 110.68256 - diff: 29.38mlTrain batch 12/32 - 240.1ms/batch - loss: 103.76357 - diff: 28.45mlTrain batch 13/32 - 238.4ms/batch - loss: 97.63587 - diff: 27.56mlTrain batch 14/32 - 237.9ms/batch - loss: 91.97010 - diff: 26.65mlTrain batch 15/32 - 237.3ms/batch - loss: 88.70327 - diff: 26.11mlTrain batch 16/32 - 240.3ms/batch - loss: 84.58082 - diff: 25.49mlTrain batch 17/32 - 237.4ms/batch - loss: 84.14569 - diff: 25.26mlTrain batch 18/32 - 240.0ms/batch - loss: 85.21639 - diff: 25.56mlTrain batch 19/32 - 237.8ms/batch - loss: 83.17953 - diff: 25.41mlTrain batch 20/32 - 239.9ms/batch - loss: 82.04119 - diff: 25.34mlTrain batch 21/32 - 237.6ms/batch - loss: 80.87800 - diff: 25.30mlTrain batch 22/32 - 239.9ms/batch - loss: 81.58129 - diff: 25.35mlTrain batch 23/32 - 238.0ms/batch - loss: 80.71748 - diff: 25.22mlTrain batch 24/32 - 239.9ms/batch - loss: 79.91940 - diff: 25.23mlTrain batch 25/32 - 238.7ms/batch - loss: 79.94728 - diff: 25.24mlTrain batch 26/32 - 240.0ms/batch - loss: 79.15661 - diff: 25.21mlTrain batch 27/32 - 238.2ms/batch - loss: 77.59674 - diff: 25.00mlTrain batch 28/32 - 238.8ms/batch - loss: 77.62350 - diff: 25.02mlTrain batch 29/32 - 237.4ms/batch - loss: 76.54170 - diff: 24.89mlTrain batch 30/32 - 240.4ms/batch - loss: 76.08770 - diff: 24.92mlTrain batch 31/32 - 237.4ms/batch - loss: 75.52693 - diff: 24.93mlTrain batch 32/32 - 78.5ms/batch - loss: 75.24611 - diff: 24.81mlTrain batch 32/32 - 10.6s 78.5ms/batch - loss: 75.24611 - diff: 24.81ml
Test 1.1s: val_loss: 340.63451 - diff: 58.39ml

Epoch 52: current best loss = 65.61265, at epoch 47
Train batch 1/32 - 237.4ms/batch - loss: 203.86679 - diff: 31.02mlTrain batch 2/32 - 237.3ms/batch - loss: 111.58639 - diff: 22.81mlTrain batch 3/32 - 237.4ms/batch - loss: 88.16260 - diff: 22.27mlTrain batch 4/32 - 240.2ms/batch - loss: 82.03597 - diff: 23.82mlTrain batch 5/32 - 237.0ms/batch - loss: 85.15695 - diff: 24.21mlTrain batch 6/32 - 239.6ms/batch - loss: 81.68046 - diff: 24.76mlTrain batch 7/32 - 237.6ms/batch - loss: 74.79705 - diff: 24.14mlTrain batch 8/32 - 240.1ms/batch - loss: 76.90005 - diff: 24.68mlTrain batch 9/32 - 238.3ms/batch - loss: 75.91808 - diff: 25.08mlTrain batch 10/32 - 240.3ms/batch - loss: 71.48634 - diff: 24.47mlTrain batch 11/32 - 237.0ms/batch - loss: 69.32186 - diff: 24.36mlTrain batch 12/32 - 238.6ms/batch - loss: 68.47938 - diff: 24.62mlTrain batch 13/32 - 238.3ms/batch - loss: 65.98599 - diff: 24.31mlTrain batch 14/32 - 239.7ms/batch - loss: 62.98390 - diff: 23.76mlTrain batch 15/32 - 237.3ms/batch - loss: 63.95011 - diff: 23.82mlTrain batch 16/32 - 238.1ms/batch - loss: 62.59632 - diff: 23.61mlTrain batch 17/32 - 237.3ms/batch - loss: 60.56380 - diff: 23.28mlTrain batch 18/32 - 239.8ms/batch - loss: 58.99076 - diff: 22.98mlTrain batch 19/32 - 237.3ms/batch - loss: 58.68976 - diff: 22.93mlTrain batch 20/32 - 240.2ms/batch - loss: 58.58405 - diff: 22.85mlTrain batch 21/32 - 237.6ms/batch - loss: 58.47335 - diff: 22.83mlTrain batch 22/32 - 240.6ms/batch - loss: 74.94126 - diff: 23.91mlTrain batch 23/32 - 237.8ms/batch - loss: 74.67823 - diff: 24.09mlTrain batch 24/32 - 239.9ms/batch - loss: 76.58601 - diff: 24.36mlTrain batch 25/32 - 237.3ms/batch - loss: 74.32998 - diff: 23.95mlTrain batch 26/32 - 239.8ms/batch - loss: 72.89945 - diff: 23.74mlTrain batch 27/32 - 237.7ms/batch - loss: 71.37448 - diff: 23.56mlTrain batch 28/32 - 240.3ms/batch - loss: 71.76618 - diff: 23.71mlTrain batch 29/32 - 238.3ms/batch - loss: 72.16880 - diff: 23.90mlTrain batch 30/32 - 240.1ms/batch - loss: 72.45468 - diff: 24.17mlTrain batch 31/32 - 237.5ms/batch - loss: 72.81167 - diff: 24.23mlTrain batch 32/32 - 76.9ms/batch - loss: 75.62678 - diff: 24.32mlTrain batch 32/32 - 10.6s 76.9ms/batch - loss: 75.62678 - diff: 24.32ml
Test 1.2s: val_loss: 56.23684 - diff: 22.58ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Systole_WideResNet50_0_Adam-0.001_MSE_DA3_best

Epoch 53: current best loss = 56.23684, at epoch 52
Train batch 1/32 - 256.0ms/batch - loss: 41.09866 - diff: 22.73mlTrain batch 2/32 - 237.3ms/batch - loss: 34.06453 - diff: 20.03mlTrain batch 3/32 - 237.9ms/batch - loss: 33.34624 - diff: 18.71mlTrain batch 4/32 - 238.0ms/batch - loss: 33.46319 - diff: 18.92mlTrain batch 5/32 - 236.9ms/batch - loss: 35.72449 - diff: 19.49mlTrain batch 6/32 - 239.1ms/batch - loss: 43.08808 - diff: 20.62mlTrain batch 7/32 - 237.7ms/batch - loss: 41.37235 - diff: 20.45mlTrain batch 8/32 - 239.6ms/batch - loss: 45.02225 - diff: 21.17mlTrain batch 9/32 - 238.1ms/batch - loss: 49.44675 - diff: 21.96mlTrain batch 10/32 - 240.2ms/batch - loss: 53.78733 - diff: 22.18mlTrain batch 11/32 - 237.4ms/batch - loss: 51.81774 - diff: 21.88mlTrain batch 12/32 - 239.0ms/batch - loss: 51.08417 - diff: 21.66mlTrain batch 13/32 - 238.6ms/batch - loss: 55.52389 - diff: 22.04mlTrain batch 14/32 - 239.0ms/batch - loss: 53.80518 - diff: 21.84mlTrain batch 15/32 - 237.3ms/batch - loss: 52.75739 - diff: 21.50mlTrain batch 16/32 - 237.5ms/batch - loss: 51.60396 - diff: 21.12mlTrain batch 17/32 - 237.8ms/batch - loss: 50.01999 - diff: 20.89mlTrain batch 18/32 - 240.1ms/batch - loss: 49.51903 - diff: 20.96mlTrain batch 19/32 - 237.4ms/batch - loss: 54.90036 - diff: 21.61mlTrain batch 20/32 - 240.2ms/batch - loss: 54.52844 - diff: 21.55mlTrain batch 21/32 - 237.8ms/batch - loss: 54.09667 - diff: 21.46mlTrain batch 22/32 - 240.4ms/batch - loss: 53.62849 - diff: 21.53mlTrain batch 23/32 - 237.5ms/batch - loss: 52.99223 - diff: 21.39mlTrain batch 24/32 - 240.2ms/batch - loss: 52.30393 - diff: 21.30mlTrain batch 25/32 - 237.8ms/batch - loss: 60.07896 - diff: 21.71mlTrain batch 26/32 - 240.1ms/batch - loss: 62.21622 - diff: 22.07mlTrain batch 27/32 - 237.2ms/batch - loss: 60.60037 - diff: 21.75mlTrain batch 28/32 - 238.6ms/batch - loss: 59.48127 - diff: 21.65mlTrain batch 29/32 - 238.4ms/batch - loss: 58.14115 - diff: 21.42mlTrain batch 30/32 - 239.4ms/batch - loss: 70.35504 - diff: 22.08mlTrain batch 31/32 - 237.4ms/batch - loss: 69.08615 - diff: 21.98mlTrain batch 32/32 - 76.6ms/batch - loss: 71.06080 - diff: 22.06mlTrain batch 32/32 - 10.6s 76.6ms/batch - loss: 71.06080 - diff: 22.06ml
Test 1.1s: val_loss: 186.62121 - diff: 44.62ml

Epoch 54: current best loss = 56.23684, at epoch 52
Train batch 1/32 - 237.4ms/batch - loss: 101.01874 - diff: 30.54mlTrain batch 2/32 - 237.7ms/batch - loss: 60.62962 - diff: 22.79mlTrain batch 3/32 - 237.1ms/batch - loss: 77.52215 - diff: 25.62mlTrain batch 4/32 - 239.7ms/batch - loss: 65.21677 - diff: 23.53mlTrain batch 5/32 - 237.3ms/batch - loss: 57.43182 - diff: 21.82mlTrain batch 6/32 - 239.9ms/batch - loss: 59.69359 - diff: 22.70mlTrain batch 7/32 - 237.4ms/batch - loss: 60.96759 - diff: 23.19mlTrain batch 8/32 - 237.7ms/batch - loss: 56.88779 - diff: 22.29mlTrain batch 9/32 - 237.6ms/batch - loss: 81.66423 - diff: 23.27mlTrain batch 10/32 - 240.2ms/batch - loss: 102.53239 - diff: 24.56mlTrain batch 11/32 - 237.6ms/batch - loss: 96.92242 - diff: 24.16mlTrain batch 12/32 - 240.3ms/batch - loss: 93.18334 - diff: 24.02mlTrain batch 13/32 - 237.7ms/batch - loss: 91.97734 - diff: 24.14mlTrain batch 14/32 - 240.0ms/batch - loss: 91.42770 - diff: 24.11mlTrain batch 15/32 - 237.1ms/batch - loss: 91.87456 - diff: 24.35mlTrain batch 16/32 - 238.7ms/batch - loss: 90.50299 - diff: 24.35mlTrain batch 17/32 - 237.6ms/batch - loss: 90.07831 - diff: 24.59mlTrain batch 18/32 - 239.4ms/batch - loss: 89.98114 - diff: 24.89mlTrain batch 19/32 - 237.9ms/batch - loss: 93.84369 - diff: 25.36mlTrain batch 20/32 - 239.5ms/batch - loss: 91.82105 - diff: 25.10mlTrain batch 21/32 - 237.9ms/batch - loss: 88.65878 - diff: 24.59mlTrain batch 22/32 - 238.1ms/batch - loss: 86.03434 - diff: 24.34mlTrain batch 23/32 - 237.4ms/batch - loss: 84.02868 - diff: 24.23mlTrain batch 24/32 - 237.7ms/batch - loss: 83.75223 - diff: 24.10mlTrain batch 25/32 - 237.4ms/batch - loss: 81.94537 - diff: 23.96mlTrain batch 26/32 - 239.9ms/batch - loss: 79.79146 - diff: 23.66mlTrain batch 27/32 - 238.2ms/batch - loss: 78.00951 - diff: 23.40mlTrain batch 28/32 - 240.2ms/batch - loss: 76.60373 - diff: 23.22mlTrain batch 29/32 - 238.3ms/batch - loss: 75.95290 - diff: 23.27mlTrain batch 30/32 - 237.7ms/batch - loss: 74.05145 - diff: 23.00mlTrain batch 31/32 - 237.8ms/batch - loss: 74.01478 - diff: 23.14mlTrain batch 32/32 - 78.8ms/batch - loss: 74.57915 - diff: 23.09mlTrain batch 32/32 - 10.6s 78.8ms/batch - loss: 74.57915 - diff: 23.09ml
Test 1.1s: val_loss: 293.83423 - diff: 58.50ml

Epoch 55: current best loss = 56.23684, at epoch 52
Train batch 1/32 - 237.5ms/batch - loss: 451.79871 - diff: 45.59mlTrain batch 2/32 - 237.5ms/batch - loss: 249.84370 - diff: 33.98mlTrain batch 3/32 - 237.8ms/batch - loss: 179.64719 - diff: 29.91mlTrain batch 4/32 - 240.3ms/batch - loss: 146.65368 - diff: 28.03mlTrain batch 5/32 - 237.4ms/batch - loss: 130.85180 - diff: 26.93mlTrain batch 6/32 - 240.0ms/batch - loss: 125.96328 - diff: 27.92mlTrain batch 7/32 - 237.4ms/batch - loss: 114.76642 - diff: 27.21mlTrain batch 8/32 - 239.8ms/batch - loss: 108.69354 - diff: 26.84mlTrain batch 9/32 - 237.9ms/batch - loss: 100.00892 - diff: 25.90mlTrain batch 10/32 - 240.1ms/batch - loss: 94.31366 - diff: 25.54mlTrain batch 11/32 - 237.5ms/batch - loss: 90.16896 - diff: 25.12mlTrain batch 12/32 - 240.1ms/batch - loss: 91.78257 - diff: 25.54mlTrain batch 13/32 - 237.6ms/batch - loss: 88.69932 - diff: 25.30mlTrain batch 14/32 - 238.7ms/batch - loss: 85.28172 - diff: 24.99mlTrain batch 15/32 - 238.5ms/batch - loss: 81.09341 - diff: 24.37mlTrain batch 16/32 - 239.9ms/batch - loss: 79.20409 - diff: 24.33mlTrain batch 17/32 - 238.2ms/batch - loss: 77.74076 - diff: 24.26mlTrain batch 18/32 - 239.4ms/batch - loss: 75.47709 - diff: 23.87mlTrain batch 19/32 - 237.4ms/batch - loss: 73.70613 - diff: 23.70mlTrain batch 20/32 - 238.5ms/batch - loss: 82.29583 - diff: 23.96mlTrain batch 21/32 - 237.3ms/batch - loss: 82.20916 - diff: 24.01mlTrain batch 22/32 - 239.7ms/batch - loss: 80.15557 - diff: 23.75mlTrain batch 23/32 - 237.9ms/batch - loss: 77.57773 - diff: 23.37mlTrain batch 24/32 - 240.2ms/batch - loss: 75.68730 - diff: 23.05mlTrain batch 25/32 - 237.5ms/batch - loss: 75.02242 - diff: 23.18mlTrain batch 26/32 - 240.2ms/batch - loss: 74.60789 - diff: 23.05mlTrain batch 27/32 - 237.4ms/batch - loss: 74.18052 - diff: 23.07mlTrain batch 28/32 - 240.5ms/batch - loss: 73.64405 - diff: 23.16mlTrain batch 29/32 - 238.8ms/batch - loss: 72.30035 - diff: 22.99mlTrain batch 30/32 - 240.2ms/batch - loss: 71.32452 - diff: 22.97mlTrain batch 31/32 - 237.6ms/batch - loss: 70.02540 - diff: 22.72mlTrain batch 32/32 - 78.4ms/batch - loss: 72.32606 - diff: 22.79mlTrain batch 32/32 - 10.6s 78.4ms/batch - loss: 72.32606 - diff: 22.79ml
Test 1.1s: val_loss: 55.20759 - diff: 19.16ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Systole_WideResNet50_0_Adam-0.001_MSE_DA3_best

Epoch 56: current best loss = 55.20759, at epoch 55
Train batch 1/32 - 236.8ms/batch - loss: 320.60883 - diff: 34.80mlTrain batch 2/32 - 237.6ms/batch - loss: 177.43702 - diff: 26.83mlTrain batch 3/32 - 237.8ms/batch - loss: 161.76238 - diff: 28.13mlTrain batch 4/32 - 240.0ms/batch - loss: 135.59055 - diff: 26.74mlTrain batch 5/32 - 237.2ms/batch - loss: 117.47755 - diff: 25.98mlTrain batch 6/32 - 238.6ms/batch - loss: 112.67739 - diff: 26.22mlTrain batch 7/32 - 238.5ms/batch - loss: 105.24045 - diff: 26.23mlTrain batch 8/32 - 239.8ms/batch - loss: 97.26653 - diff: 25.41mlTrain batch 9/32 - 240.6ms/batch - loss: 91.88926 - diff: 25.31mlTrain batch 10/32 - 238.0ms/batch - loss: 87.38455 - diff: 25.23mlTrain batch 11/32 - 237.8ms/batch - loss: 95.63885 - diff: 25.73mlTrain batch 12/32 - 238.6ms/batch - loss: 92.52149 - diff: 25.40mlTrain batch 13/32 - 237.4ms/batch - loss: 92.60630 - diff: 25.45mlTrain batch 14/32 - 240.1ms/batch - loss: 90.03547 - diff: 25.45mlTrain batch 15/32 - 237.3ms/batch - loss: 88.23321 - diff: 25.08mlTrain batch 16/32 - 240.0ms/batch - loss: 85.23306 - diff: 24.80mlTrain batch 17/32 - 237.7ms/batch - loss: 82.81224 - diff: 24.59mlTrain batch 18/32 - 240.3ms/batch - loss: 83.20812 - diff: 24.76mlTrain batch 19/32 - 237.5ms/batch - loss: 81.80222 - diff: 24.77mlTrain batch 20/32 - 238.6ms/batch - loss: 79.56219 - diff: 24.46mlTrain batch 21/32 - 238.0ms/batch - loss: 78.12649 - diff: 24.16mlTrain batch 22/32 - 240.0ms/batch - loss: 76.07445 - diff: 23.93mlTrain batch 23/32 - 240.9ms/batch - loss: 73.52249 - diff: 23.49mlTrain batch 24/32 - 240.1ms/batch - loss: 74.01831 - diff: 23.59mlTrain batch 25/32 - 237.8ms/batch - loss: 72.46611 - diff: 23.44mlTrain batch 26/32 - 239.5ms/batch - loss: 71.23126 - diff: 23.30mlTrain batch 27/32 - 237.4ms/batch - loss: 70.76581 - diff: 23.33mlTrain batch 28/32 - 237.0ms/batch - loss: 69.84243 - diff: 23.27mlTrain batch 29/32 - 237.5ms/batch - loss: 69.00624 - diff: 23.23mlTrain batch 30/32 - 238.8ms/batch - loss: 68.09937 - diff: 23.20mlTrain batch 31/32 - 237.3ms/batch - loss: 68.50978 - diff: 23.21mlTrain batch 32/32 - 78.0ms/batch - loss: 68.33937 - diff: 23.12mlTrain batch 32/32 - 10.7s 78.0ms/batch - loss: 68.33937 - diff: 23.12ml
Test 1.1s: val_loss: 318.63247 - diff: 56.35ml

Epoch 57: current best loss = 55.20759, at epoch 55
Train batch 1/32 - 237.0ms/batch - loss: 38.92805 - diff: 19.43mlTrain batch 2/32 - 239.3ms/batch - loss: 48.09178 - diff: 21.14mlTrain batch 3/32 - 237.4ms/batch - loss: 42.43154 - diff: 21.00mlTrain batch 4/32 - 237.4ms/batch - loss: 43.48489 - diff: 20.82mlTrain batch 5/32 - 238.8ms/batch - loss: 57.09568 - diff: 22.93mlTrain batch 6/32 - 240.5ms/batch - loss: 54.43973 - diff: 22.80mlTrain batch 7/32 - 237.5ms/batch - loss: 51.89521 - diff: 22.31mlTrain batch 8/32 - 240.1ms/batch - loss: 49.59753 - diff: 21.72mlTrain batch 9/32 - 237.5ms/batch - loss: 50.31895 - diff: 21.95mlTrain batch 10/32 - 239.6ms/batch - loss: 47.61619 - diff: 21.45mlTrain batch 11/32 - 237.7ms/batch - loss: 73.51797 - diff: 22.70mlTrain batch 12/32 - 239.7ms/batch - loss: 69.20033 - diff: 22.02mlTrain batch 13/32 - 237.3ms/batch - loss: 66.88050 - diff: 21.92mlTrain batch 14/32 - 238.7ms/batch - loss: 65.04180 - diff: 21.87mlTrain batch 15/32 - 238.0ms/batch - loss: 76.49964 - diff: 22.48mlTrain batch 16/32 - 239.8ms/batch - loss: 74.04543 - diff: 22.30mlTrain batch 17/32 - 238.2ms/batch - loss: 71.61495 - diff: 22.11mlTrain batch 18/32 - 239.2ms/batch - loss: 68.67292 - diff: 21.70mlTrain batch 19/32 - 237.9ms/batch - loss: 68.83925 - diff: 22.06mlTrain batch 20/32 - 238.8ms/batch - loss: 68.61687 - diff: 22.00mlTrain batch 21/32 - 237.4ms/batch - loss: 71.06511 - diff: 22.46mlTrain batch 22/32 - 238.3ms/batch - loss: 70.05408 - diff: 22.38mlTrain batch 23/32 - 237.5ms/batch - loss: 69.08903 - diff: 22.31mlTrain batch 24/32 - 240.2ms/batch - loss: 67.22216 - diff: 22.07mlTrain batch 25/32 - 238.1ms/batch - loss: 66.09172 - diff: 22.01mlTrain batch 26/32 - 240.1ms/batch - loss: 64.98646 - diff: 21.95mlTrain batch 27/32 - 237.3ms/batch - loss: 64.00348 - diff: 21.84mlTrain batch 28/32 - 240.2ms/batch - loss: 62.88881 - diff: 21.66mlTrain batch 29/32 - 237.4ms/batch - loss: 62.30911 - diff: 21.74mlTrain batch 30/32 - 240.4ms/batch - loss: 63.52361 - diff: 21.95mlTrain batch 31/32 - 237.7ms/batch - loss: 63.43205 - diff: 22.09mlTrain batch 32/32 - 78.4ms/batch - loss: 64.46855 - diff: 22.07mlTrain batch 32/32 - 10.6s 78.4ms/batch - loss: 64.46855 - diff: 22.07ml
Test 1.1s: val_loss: 57.76588 - diff: 20.36ml

Epoch 58: current best loss = 55.20759, at epoch 55
Train batch 1/32 - 237.3ms/batch - loss: 240.57803 - diff: 33.03mlTrain batch 2/32 - 239.2ms/batch - loss: 149.00133 - diff: 28.91mlTrain batch 3/32 - 237.8ms/batch - loss: 124.20870 - diff: 29.00mlTrain batch 4/32 - 240.2ms/batch - loss: 106.43053 - diff: 27.53mlTrain batch 5/32 - 237.4ms/batch - loss: 94.35964 - diff: 26.29mlTrain batch 6/32 - 238.3ms/batch - loss: 85.82891 - diff: 25.15mlTrain batch 7/32 - 237.2ms/batch - loss: 78.54724 - diff: 24.17mlTrain batch 8/32 - 238.9ms/batch - loss: 72.82108 - diff: 23.37mlTrain batch 9/32 - 238.0ms/batch - loss: 71.34102 - diff: 23.54mlTrain batch 10/32 - 239.8ms/batch - loss: 68.63401 - diff: 23.15mlTrain batch 11/32 - 237.9ms/batch - loss: 65.74294 - diff: 22.57mlTrain batch 12/32 - 239.2ms/batch - loss: 67.49637 - diff: 23.06mlTrain batch 13/32 - 237.4ms/batch - loss: 67.21029 - diff: 23.21mlTrain batch 14/32 - 239.7ms/batch - loss: 65.30832 - diff: 22.92mlTrain batch 15/32 - 237.3ms/batch - loss: 64.22382 - diff: 22.78mlTrain batch 16/32 - 240.2ms/batch - loss: 61.81779 - diff: 22.45mlTrain batch 17/32 - 237.4ms/batch - loss: 77.26389 - diff: 23.35mlTrain batch 18/32 - 263.7ms/batch - loss: 77.17945 - diff: 23.27mlTrain batch 19/32 - 237.3ms/batch - loss: 75.09809 - diff: 22.98mlTrain batch 20/32 - 240.9ms/batch - loss: 72.86493 - diff: 22.73mlTrain batch 21/32 - 237.4ms/batch - loss: 73.91157 - diff: 22.83mlTrain batch 22/32 - 239.9ms/batch - loss: 74.34633 - diff: 22.92mlTrain batch 23/32 - 237.6ms/batch - loss: 74.67796 - diff: 23.20mlTrain batch 24/32 - 240.1ms/batch - loss: 74.39219 - diff: 23.27mlTrain batch 25/32 - 237.9ms/batch - loss: 73.59995 - diff: 23.16mlTrain batch 26/32 - 240.1ms/batch - loss: 72.07772 - diff: 22.97mlTrain batch 27/32 - 237.2ms/batch - loss: 71.13070 - diff: 22.97mlTrain batch 28/32 - 239.2ms/batch - loss: 69.23087 - diff: 22.63mlTrain batch 29/32 - 237.7ms/batch - loss: 68.88285 - diff: 22.64mlTrain batch 30/32 - 239.8ms/batch - loss: 67.58668 - diff: 22.51mlTrain batch 31/32 - 238.2ms/batch - loss: 66.61842 - diff: 22.42mlTrain batch 32/32 - 77.3ms/batch - loss: 66.43829 - diff: 22.33mlTrain batch 32/32 - 10.6s 77.3ms/batch - loss: 66.43829 - diff: 22.33ml
Test 1.1s: val_loss: 69.64063 - diff: 21.56ml

Epoch 59: current best loss = 55.20759, at epoch 55
Train batch 1/32 - 237.5ms/batch - loss: 52.72092 - diff: 21.62mlTrain batch 2/32 - 238.6ms/batch - loss: 38.97989 - diff: 19.15mlTrain batch 3/32 - 238.2ms/batch - loss: 41.89887 - diff: 19.62mlTrain batch 4/32 - 239.2ms/batch - loss: 57.73522 - diff: 21.49mlTrain batch 5/32 - 237.5ms/batch - loss: 58.65118 - diff: 22.12mlTrain batch 6/32 - 239.3ms/batch - loss: 103.92440 - diff: 23.51mlTrain batch 7/32 - 237.4ms/batch - loss: 94.30961 - diff: 22.92mlTrain batch 8/32 - 240.0ms/batch - loss: 87.00857 - diff: 22.47mlTrain batch 9/32 - 238.3ms/batch - loss: 80.65284 - diff: 21.61mlTrain batch 10/32 - 240.2ms/batch - loss: 81.34689 - diff: 22.24mlTrain batch 11/32 - 237.1ms/batch - loss: 80.03037 - diff: 22.54mlTrain batch 12/32 - 240.1ms/batch - loss: 76.57793 - diff: 22.41mlTrain batch 13/32 - 237.2ms/batch - loss: 72.51031 - diff: 21.98mlTrain batch 14/32 - 240.2ms/batch - loss: 71.50616 - diff: 22.01mlTrain batch 15/32 - 237.3ms/batch - loss: 68.13996 - diff: 21.50mlTrain batch 16/32 - 240.1ms/batch - loss: 66.66172 - diff: 21.44mlTrain batch 17/32 - 237.8ms/batch - loss: 66.24144 - diff: 21.29mlTrain batch 18/32 - 240.3ms/batch - loss: 77.54679 - diff: 21.86mlTrain batch 19/32 - 237.5ms/batch - loss: 76.72003 - diff: 21.84mlTrain batch 20/32 - 238.9ms/batch - loss: 76.84638 - diff: 22.02mlTrain batch 21/32 - 237.5ms/batch - loss: 75.63373 - diff: 22.04mlTrain batch 22/32 - 239.4ms/batch - loss: 75.15580 - diff: 22.18mlTrain batch 23/32 - 238.2ms/batch - loss: 75.73289 - diff: 22.52mlTrain batch 24/32 - 239.7ms/batch - loss: 74.24064 - diff: 22.41mlTrain batch 25/32 - 238.4ms/batch - loss: 72.93079 - diff: 22.25mlTrain batch 26/32 - 240.0ms/batch - loss: 73.03366 - diff: 22.31mlTrain batch 27/32 - 237.3ms/batch - loss: 72.19918 - diff: 22.31mlTrain batch 28/32 - 238.9ms/batch - loss: 70.75939 - diff: 22.14mlTrain batch 29/32 - 237.3ms/batch - loss: 69.50939 - diff: 22.05mlTrain batch 30/32 - 239.6ms/batch - loss: 69.09243 - diff: 22.10mlTrain batch 31/32 - 238.0ms/batch - loss: 67.63553 - diff: 21.84mlTrain batch 32/32 - 77.9ms/batch - loss: 68.13338 - diff: 21.81mlTrain batch 32/32 - 10.6s 77.9ms/batch - loss: 68.13338 - diff: 21.81ml
Test 1.1s: val_loss: 68.26651 - diff: 22.87ml

Epoch 60: current best loss = 55.20759, at epoch 55
Train batch 1/32 - 237.4ms/batch - loss: 48.92805 - diff: 22.04mlTrain batch 2/32 - 237.2ms/batch - loss: 84.65109 - diff: 27.10mlTrain batch 3/32 - 237.6ms/batch - loss: 64.52569 - diff: 23.23mlTrain batch 4/32 - 240.2ms/batch - loss: 60.57585 - diff: 22.22mlTrain batch 5/32 - 237.1ms/batch - loss: 63.68703 - diff: 22.24mlTrain batch 6/32 - 240.2ms/batch - loss: 60.76163 - diff: 21.57mlTrain batch 7/32 - 237.3ms/batch - loss: 62.60296 - diff: 22.54mlTrain batch 8/32 - 240.2ms/batch - loss: 59.31908 - diff: 22.35mlTrain batch 9/32 - 237.6ms/batch - loss: 57.42513 - diff: 22.07mlTrain batch 10/32 - 240.1ms/batch - loss: 56.79794 - diff: 22.32mlTrain batch 11/32 - 237.5ms/batch - loss: 58.15140 - diff: 22.70mlTrain batch 12/32 - 240.1ms/batch - loss: 55.44533 - diff: 22.21mlTrain batch 13/32 - 238.0ms/batch - loss: 55.27977 - diff: 22.27mlTrain batch 14/32 - 240.4ms/batch - loss: 54.43449 - diff: 22.03mlTrain batch 15/32 - 241.4ms/batch - loss: 52.43768 - diff: 21.44mlTrain batch 16/32 - 240.2ms/batch - loss: 52.72296 - diff: 21.52mlTrain batch 17/32 - 237.6ms/batch - loss: 60.15738 - diff: 22.00mlTrain batch 18/32 - 239.7ms/batch - loss: 58.51547 - diff: 21.70mlTrain batch 19/32 - 238.1ms/batch - loss: 57.87189 - diff: 21.71mlTrain batch 20/32 - 239.3ms/batch - loss: 59.77108 - diff: 21.94mlTrain batch 21/32 - 237.9ms/batch - loss: 59.02371 - diff: 21.87mlTrain batch 22/32 - 239.2ms/batch - loss: 57.29345 - diff: 21.44mlTrain batch 23/32 - 237.3ms/batch - loss: 58.11183 - diff: 21.45mlTrain batch 24/32 - 240.3ms/batch - loss: 56.91267 - diff: 21.20mlTrain batch 25/32 - 237.5ms/batch - loss: 55.32589 - diff: 20.88mlTrain batch 26/32 - 240.2ms/batch - loss: 62.38940 - diff: 21.20mlTrain batch 27/32 - 237.4ms/batch - loss: 61.51334 - diff: 21.23mlTrain batch 28/32 - 240.3ms/batch - loss: 60.39585 - diff: 21.10mlTrain batch 29/32 - 241.7ms/batch - loss: 59.57033 - diff: 21.09mlTrain batch 30/32 - 240.5ms/batch - loss: 59.93323 - diff: 21.36mlTrain batch 31/32 - 237.4ms/batch - loss: 59.82469 - diff: 21.36mlTrain batch 32/32 - 77.4ms/batch - loss: 62.13912 - diff: 21.46mlTrain batch 32/32 - 10.6s 77.4ms/batch - loss: 62.13912 - diff: 21.46ml
Test 1.2s: val_loss: 105.96500 - diff: 27.37ml

Epoch 61: current best loss = 55.20759, at epoch 55
Train batch 1/32 - 237.8ms/batch - loss: 43.76686 - diff: 22.04mlTrain batch 2/32 - 240.3ms/batch - loss: 90.58569 - diff: 26.27mlTrain batch 3/32 - 237.8ms/batch - loss: 79.90051 - diff: 25.56mlTrain batch 4/32 - 239.9ms/batch - loss: 72.54214 - diff: 24.62mlTrain batch 5/32 - 237.9ms/batch - loss: 78.87770 - diff: 25.93mlTrain batch 6/32 - 239.5ms/batch - loss: 73.98947 - diff: 25.22mlTrain batch 7/32 - 238.3ms/batch - loss: 87.85147 - diff: 25.49mlTrain batch 8/32 - 239.6ms/batch - loss: 81.88286 - diff: 24.56mlTrain batch 9/32 - 238.3ms/batch - loss: 76.39146 - diff: 23.89mlTrain batch 10/32 - 238.7ms/batch - loss: 72.38089 - diff: 23.36mlTrain batch 11/32 - 236.9ms/batch - loss: 69.41280 - diff: 22.92mlTrain batch 12/32 - 240.2ms/batch - loss: 67.92518 - diff: 22.76mlTrain batch 13/32 - 238.5ms/batch - loss: 66.02791 - diff: 22.46mlTrain batch 14/32 - 239.6ms/batch - loss: 64.29844 - diff: 22.14mlTrain batch 15/32 - 238.2ms/batch - loss: 62.67224 - diff: 22.04mlTrain batch 16/32 - 240.4ms/batch - loss: 64.37873 - diff: 22.18mlTrain batch 17/32 - 237.3ms/batch - loss: 64.18107 - diff: 22.52mlTrain batch 18/32 - 240.2ms/batch - loss: 63.22758 - diff: 22.52mlTrain batch 19/32 - 237.5ms/batch - loss: 60.39264 - diff: 21.93mlTrain batch 20/32 - 240.4ms/batch - loss: 59.82087 - diff: 21.98mlTrain batch 21/32 - 238.0ms/batch - loss: 58.80057 - diff: 21.93mlTrain batch 22/32 - 240.3ms/batch - loss: 58.12528 - diff: 21.68mlTrain batch 23/32 - 237.8ms/batch - loss: 56.33399 - diff: 21.30mlTrain batch 24/32 - 240.5ms/batch - loss: 55.22035 - diff: 21.13mlTrain batch 25/32 - 237.4ms/batch - loss: 55.91645 - diff: 21.30mlTrain batch 26/32 - 239.7ms/batch - loss: 54.42994 - diff: 21.06mlTrain batch 27/32 - 237.4ms/batch - loss: 66.99099 - diff: 21.83mlTrain batch 28/32 - 239.4ms/batch - loss: 66.43279 - diff: 21.79mlTrain batch 29/32 - 238.4ms/batch - loss: 68.66747 - diff: 22.08mlTrain batch 30/32 - 240.3ms/batch - loss: 68.61548 - diff: 22.21mlTrain batch 31/32 - 238.4ms/batch - loss: 68.61225 - diff: 22.37mlTrain batch 32/32 - 77.9ms/batch - loss: 71.64823 - diff: 22.47mlTrain batch 32/32 - 10.6s 77.9ms/batch - loss: 71.64823 - diff: 22.47ml
Test 1.2s: val_loss: 89.21950 - diff: 26.68ml

Epoch 62: current best loss = 55.20759, at epoch 55
Train batch 1/32 - 238.2ms/batch - loss: 60.44787 - diff: 20.75mlTrain batch 2/32 - 236.8ms/batch - loss: 46.27229 - diff: 20.10mlTrain batch 3/32 - 238.2ms/batch - loss: 40.64849 - diff: 19.52mlTrain batch 4/32 - 239.7ms/batch - loss: 41.87829 - diff: 19.85mlTrain batch 5/32 - 237.0ms/batch - loss: 40.63501 - diff: 19.27mlTrain batch 6/32 - 237.9ms/batch - loss: 37.20447 - diff: 18.36mlTrain batch 7/32 - 237.4ms/batch - loss: 37.48286 - diff: 18.65mlTrain batch 8/32 - 239.8ms/batch - loss: 35.88508 - diff: 18.22mlTrain batch 9/32 - 237.1ms/batch - loss: 71.02629 - diff: 20.70mlTrain batch 10/32 - 240.0ms/batch - loss: 66.49983 - diff: 20.05mlTrain batch 11/32 - 238.4ms/batch - loss: 65.02313 - diff: 20.10mlTrain batch 12/32 - 240.3ms/batch - loss: 85.63505 - diff: 22.79mlTrain batch 13/32 - 237.4ms/batch - loss: 81.63161 - diff: 22.54mlTrain batch 14/32 - 240.3ms/batch - loss: 79.07429 - diff: 22.42mlTrain batch 15/32 - 237.3ms/batch - loss: 78.95195 - diff: 22.46mlTrain batch 16/32 - 240.4ms/batch - loss: 78.16338 - diff: 22.76mlTrain batch 17/32 - 238.0ms/batch - loss: 78.63160 - diff: 22.97mlTrain batch 18/32 - 240.3ms/batch - loss: 78.48472 - diff: 23.29mlTrain batch 19/32 - 237.8ms/batch - loss: 77.69915 - diff: 23.35mlTrain batch 20/32 - 240.2ms/batch - loss: 76.03142 - diff: 23.33mlTrain batch 21/32 - 238.1ms/batch - loss: 75.44581 - diff: 23.37mlTrain batch 22/32 - 240.4ms/batch - loss: 74.11851 - diff: 23.35mlTrain batch 23/32 - 238.2ms/batch - loss: 72.41688 - diff: 23.12mlTrain batch 24/32 - 240.3ms/batch - loss: 71.49698 - diff: 23.11mlTrain batch 25/32 - 238.0ms/batch - loss: 69.73251 - diff: 22.86mlTrain batch 26/32 - 240.1ms/batch - loss: 68.64926 - diff: 22.77mlTrain batch 27/32 - 238.7ms/batch - loss: 66.43730 - diff: 22.27mlTrain batch 28/32 - 240.1ms/batch - loss: 64.88128 - diff: 22.02mlTrain batch 29/32 - 238.2ms/batch - loss: 63.74801 - diff: 21.89mlTrain batch 30/32 - 238.9ms/batch - loss: 64.34644 - diff: 22.10mlTrain batch 31/32 - 237.3ms/batch - loss: 65.12538 - diff: 22.22mlTrain batch 32/32 - 76.7ms/batch - loss: 64.79126 - diff: 22.10mlTrain batch 32/32 - 10.6s 76.7ms/batch - loss: 64.79126 - diff: 22.10ml
Test 1.1s: val_loss: 72.88521 - diff: 22.57ml

Epoch 63: current best loss = 55.20759, at epoch 55
Train batch 1/32 - 237.6ms/batch - loss: 77.90710 - diff: 25.20mlTrain batch 2/32 - 236.9ms/batch - loss: 52.80749 - diff: 21.03mlTrain batch 3/32 - 237.3ms/batch - loss: 98.31030 - diff: 28.33mlTrain batch 4/32 - 240.2ms/batch - loss: 77.50854 - diff: 24.68mlTrain batch 5/32 - 238.3ms/batch - loss: 108.27456 - diff: 25.29mlTrain batch 6/32 - 240.4ms/batch - loss: 101.11106 - diff: 25.08mlTrain batch 7/32 - 246.3ms/batch - loss: 91.41368 - diff: 24.14mlTrain batch 8/32 - 237.8ms/batch - loss: 83.49101 - diff: 23.43mlTrain batch 9/32 - 241.9ms/batch - loss: 79.71021 - diff: 23.42mlTrain batch 10/32 - 240.4ms/batch - loss: 79.44674 - diff: 23.70mlTrain batch 11/32 - 238.0ms/batch - loss: 73.82796 - diff: 22.53mlTrain batch 12/32 - 240.1ms/batch - loss: 73.12149 - diff: 22.45mlTrain batch 13/32 - 237.6ms/batch - loss: 73.06230 - diff: 22.46mlTrain batch 14/32 - 237.4ms/batch - loss: 72.20838 - diff: 22.46mlTrain batch 15/32 - 238.5ms/batch - loss: 70.14118 - diff: 22.34mlTrain batch 16/32 - 240.3ms/batch - loss: 68.06728 - diff: 22.08mlTrain batch 17/32 - 238.7ms/batch - loss: 87.04611 - diff: 23.21mlTrain batch 18/32 - 240.0ms/batch - loss: 85.90349 - diff: 23.31mlTrain batch 19/32 - 237.8ms/batch - loss: 84.08931 - diff: 23.21mlTrain batch 20/32 - 239.6ms/batch - loss: 83.40555 - diff: 23.48mlTrain batch 21/32 - 237.7ms/batch - loss: 81.11456 - diff: 23.20mlTrain batch 22/32 - 240.4ms/batch - loss: 81.29715 - diff: 23.41mlTrain batch 23/32 - 238.5ms/batch - loss: 78.83896 - diff: 22.97mlTrain batch 24/32 - 240.3ms/batch - loss: 76.70520 - diff: 22.64mlTrain batch 25/32 - 237.5ms/batch - loss: 75.00472 - diff: 22.54mlTrain batch 26/32 - 240.2ms/batch - loss: 74.10415 - diff: 22.44mlTrain batch 27/32 - 237.4ms/batch - loss: 72.91818 - diff: 22.39mlTrain batch 28/32 - 240.5ms/batch - loss: 71.11735 - diff: 22.18mlTrain batch 29/32 - 237.5ms/batch - loss: 70.95492 - diff: 22.20mlTrain batch 30/32 - 240.5ms/batch - loss: 69.03078 - diff: 21.88mlTrain batch 31/32 - 237.6ms/batch - loss: 68.22195 - diff: 21.93mlTrain batch 32/32 - 77.5ms/batch - loss: 68.57296 - diff: 21.89mlTrain batch 32/32 - 10.6s 77.5ms/batch - loss: 68.57296 - diff: 21.89ml
Test 1.1s: val_loss: 82.39218 - diff: 24.76ml

Epoch 64: current best loss = 55.20759, at epoch 55
Train batch 1/32 - 237.3ms/batch - loss: 44.36353 - diff: 20.59mlTrain batch 2/32 - 242.1ms/batch - loss: 56.89277 - diff: 22.85mlTrain batch 3/32 - 237.3ms/batch - loss: 50.42843 - diff: 21.57mlTrain batch 4/32 - 239.9ms/batch - loss: 51.46309 - diff: 21.43mlTrain batch 5/32 - 237.9ms/batch - loss: 50.48622 - diff: 21.21mlTrain batch 6/32 - 240.2ms/batch - loss: 52.01919 - diff: 21.79mlTrain batch 7/32 - 237.1ms/batch - loss: 77.45792 - diff: 23.42mlTrain batch 8/32 - 239.3ms/batch - loss: 73.94223 - diff: 23.26mlTrain batch 9/32 - 237.8ms/batch - loss: 68.56164 - diff: 22.50mlTrain batch 10/32 - 239.9ms/batch - loss: 68.11683 - diff: 22.84mlTrain batch 11/32 - 238.5ms/batch - loss: 67.66512 - diff: 22.81mlTrain batch 12/32 - 239.7ms/batch - loss: 66.50670 - diff: 22.68mlTrain batch 13/32 - 237.2ms/batch - loss: 64.79745 - diff: 22.57mlTrain batch 14/32 - 237.5ms/batch - loss: 64.16818 - diff: 22.68mlTrain batch 15/32 - 237.7ms/batch - loss: 62.41781 - diff: 22.44mlTrain batch 16/32 - 240.2ms/batch - loss: 68.09167 - diff: 22.69mlTrain batch 17/32 - 238.2ms/batch - loss: 66.10779 - diff: 22.38mlTrain batch 18/32 - 240.3ms/batch - loss: 64.09320 - diff: 22.18mlTrain batch 19/32 - 237.4ms/batch - loss: 64.90901 - diff: 22.35mlTrain batch 20/32 - 240.5ms/batch - loss: 64.02209 - diff: 22.31mlTrain batch 21/32 - 237.3ms/batch - loss: 63.78852 - diff: 22.36mlTrain batch 22/32 - 240.6ms/batch - loss: 63.39826 - diff: 22.29mlTrain batch 23/32 - 237.3ms/batch - loss: 65.28798 - diff: 22.59mlTrain batch 24/32 - 239.9ms/batch - loss: 63.09708 - diff: 22.11mlTrain batch 25/32 - 238.3ms/batch - loss: 61.84882 - diff: 21.99mlTrain batch 26/32 - 240.3ms/batch - loss: 61.95575 - diff: 22.11mlTrain batch 27/32 - 237.9ms/batch - loss: 60.57369 - diff: 21.93mlTrain batch 28/32 - 240.3ms/batch - loss: 59.76361 - diff: 21.82mlTrain batch 29/32 - 237.6ms/batch - loss: 59.40409 - diff: 21.81mlTrain batch 30/32 - 239.7ms/batch - loss: 58.27143 - diff: 21.62mlTrain batch 31/32 - 238.1ms/batch - loss: 57.46308 - diff: 21.55mlTrain batch 32/32 - 78.6ms/batch - loss: 58.43204 - diff: 21.58mlTrain batch 32/32 - 10.6s 78.6ms/batch - loss: 58.43204 - diff: 21.58ml
Test 1.1s: val_loss: 642.71872 - diff: 86.18ml

Epoch 65: current best loss = 55.20759, at epoch 55
Train batch 1/32 - 238.0ms/batch - loss: 22.06271 - diff: 15.07mlTrain batch 2/32 - 239.9ms/batch - loss: 40.99646 - diff: 19.11mlTrain batch 3/32 - 237.9ms/batch - loss: 35.95702 - diff: 18.24mlTrain batch 4/32 - 240.2ms/batch - loss: 45.16957 - diff: 20.15mlTrain batch 5/32 - 237.8ms/batch - loss: 45.50706 - diff: 20.01mlTrain batch 6/32 - 239.5ms/batch - loss: 40.93813 - diff: 19.12mlTrain batch 7/32 - 240.6ms/batch - loss: 87.39643 - diff: 22.47mlTrain batch 8/32 - 240.5ms/batch - loss: 82.69853 - diff: 21.84mlTrain batch 9/32 - 238.3ms/batch - loss: 77.76806 - diff: 21.36mlTrain batch 10/32 - 240.0ms/batch - loss: 74.18337 - diff: 21.18mlTrain batch 11/32 - 237.4ms/batch - loss: 68.44753 - diff: 20.18mlTrain batch 12/32 - 239.6ms/batch - loss: 65.55963 - diff: 20.20mlTrain batch 13/32 - 237.5ms/batch - loss: 62.52033 - diff: 19.75mlTrain batch 14/32 - 249.1ms/batch - loss: 59.69686 - diff: 19.49mlTrain batch 15/32 - 237.4ms/batch - loss: 57.63622 - diff: 19.39mlTrain batch 16/32 - 240.2ms/batch - loss: 55.89864 - diff: 19.38mlTrain batch 17/32 - 237.5ms/batch - loss: 56.51787 - diff: 19.68mlTrain batch 18/32 - 240.2ms/batch - loss: 56.37073 - diff: 19.86mlTrain batch 19/32 - 237.7ms/batch - loss: 54.96452 - diff: 19.76mlTrain batch 20/32 - 240.2ms/batch - loss: 55.00034 - diff: 20.05mlTrain batch 21/32 - 244.3ms/batch - loss: 55.25796 - diff: 20.35mlTrain batch 22/32 - 240.6ms/batch - loss: 55.03662 - diff: 20.49mlTrain batch 23/32 - 237.7ms/batch - loss: 55.24563 - diff: 20.69mlTrain batch 24/32 - 242.6ms/batch - loss: 67.95414 - diff: 21.23mlTrain batch 25/32 - 237.9ms/batch - loss: 66.38496 - diff: 21.08mlTrain batch 26/32 - 240.1ms/batch - loss: 65.96493 - diff: 21.21mlTrain batch 27/32 - 238.1ms/batch - loss: 65.60278 - diff: 21.35mlTrain batch 28/32 - 240.1ms/batch - loss: 64.45125 - diff: 21.25mlTrain batch 29/32 - 238.5ms/batch - loss: 64.04537 - diff: 21.29mlTrain batch 30/32 - 239.8ms/batch - loss: 63.63450 - diff: 21.36mlTrain batch 31/32 - 237.7ms/batch - loss: 64.19489 - diff: 21.41mlTrain batch 32/32 - 77.1ms/batch - loss: 64.34908 - diff: 21.36mlTrain batch 32/32 - 10.6s 77.1ms/batch - loss: 64.34908 - diff: 21.36ml
Test 1.1s: val_loss: 55.01709 - diff: 19.70ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Systole_WideResNet50_0_Adam-0.001_MSE_DA3_best

Epoch 66: current best loss = 55.01709, at epoch 65
Train batch 1/32 - 236.8ms/batch - loss: 28.42674 - diff: 16.19mlTrain batch 2/32 - 238.3ms/batch - loss: 25.44266 - diff: 14.89mlTrain batch 3/32 - 238.1ms/batch - loss: 27.75854 - diff: 15.84mlTrain batch 4/32 - 238.8ms/batch - loss: 31.34919 - diff: 17.04mlTrain batch 5/32 - 237.0ms/batch - loss: 29.87599 - diff: 16.72mlTrain batch 6/32 - 240.3ms/batch - loss: 38.54235 - diff: 18.04mlTrain batch 7/32 - 237.7ms/batch - loss: 42.36267 - diff: 19.12mlTrain batch 8/32 - 239.1ms/batch - loss: 38.92895 - diff: 18.30mlTrain batch 9/32 - 237.3ms/batch - loss: 40.52456 - diff: 18.79mlTrain batch 10/32 - 240.5ms/batch - loss: 39.68053 - diff: 18.79mlTrain batch 11/32 - 237.3ms/batch - loss: 41.33858 - diff: 18.84mlTrain batch 12/32 - 240.5ms/batch - loss: 43.63580 - diff: 19.25mlTrain batch 13/32 - 237.3ms/batch - loss: 53.91689 - diff: 19.85mlTrain batch 14/32 - 240.0ms/batch - loss: 52.10691 - diff: 19.54mlTrain batch 15/32 - 237.7ms/batch - loss: 50.90109 - diff: 19.53mlTrain batch 16/32 - 240.3ms/batch - loss: 51.25079 - diff: 19.61mlTrain batch 17/32 - 237.4ms/batch - loss: 51.33924 - diff: 19.86mlTrain batch 18/32 - 240.4ms/batch - loss: 50.06923 - diff: 19.77mlTrain batch 19/32 - 240.0ms/batch - loss: 54.89582 - diff: 20.15mlTrain batch 20/32 - 240.6ms/batch - loss: 56.13974 - diff: 20.41mlTrain batch 21/32 - 238.8ms/batch - loss: 56.95776 - diff: 20.71mlTrain batch 22/32 - 239.9ms/batch - loss: 60.67198 - diff: 21.47mlTrain batch 23/32 - 238.1ms/batch - loss: 60.46337 - diff: 21.51mlTrain batch 24/32 - 239.0ms/batch - loss: 62.06872 - diff: 21.66mlTrain batch 25/32 - 237.3ms/batch - loss: 61.95128 - diff: 21.44mlTrain batch 26/32 - 239.9ms/batch - loss: 60.75895 - diff: 21.28mlTrain batch 27/32 - 237.1ms/batch - loss: 59.84458 - diff: 21.19mlTrain batch 28/32 - 240.2ms/batch - loss: 58.75191 - diff: 21.02mlTrain batch 29/32 - 237.5ms/batch - loss: 59.65925 - diff: 21.15mlTrain batch 30/32 - 240.3ms/batch - loss: 59.28870 - diff: 21.15mlTrain batch 31/32 - 241.5ms/batch - loss: 58.87876 - diff: 21.14mlTrain batch 32/32 - 78.8ms/batch - loss: 59.04499 - diff: 21.11mlTrain batch 32/32 - 10.7s 78.8ms/batch - loss: 59.04499 - diff: 21.11ml
Test 1.2s: val_loss: 79.18031 - diff: 22.27ml

Epoch 67: current best loss = 55.01709, at epoch 65
Train batch 1/32 - 237.4ms/batch - loss: 137.91998 - diff: 24.87mlTrain batch 2/32 - 239.1ms/batch - loss: 88.46060 - diff: 20.55mlTrain batch 3/32 - 237.8ms/batch - loss: 70.22520 - diff: 19.43mlTrain batch 4/32 - 239.9ms/batch - loss: 72.40274 - diff: 21.21mlTrain batch 5/32 - 237.3ms/batch - loss: 66.98289 - diff: 21.15mlTrain batch 6/32 - 238.0ms/batch - loss: 60.52263 - diff: 20.52mlTrain batch 7/32 - 237.7ms/batch - loss: 57.50048 - diff: 20.34mlTrain batch 8/32 - 239.6ms/batch - loss: 57.78943 - diff: 20.92mlTrain batch 9/32 - 238.2ms/batch - loss: 52.47367 - diff: 19.80mlTrain batch 10/32 - 239.5ms/batch - loss: 51.08681 - diff: 19.70mlTrain batch 11/32 - 238.7ms/batch - loss: 57.12942 - diff: 20.98mlTrain batch 12/32 - 238.8ms/batch - loss: 53.37825 - diff: 20.09mlTrain batch 13/32 - 237.2ms/batch - loss: 52.62026 - diff: 20.23mlTrain batch 14/32 - 240.2ms/batch - loss: 53.77436 - diff: 20.41mlTrain batch 15/32 - 238.1ms/batch - loss: 51.87863 - diff: 20.19mlTrain batch 16/32 - 240.2ms/batch - loss: 51.04414 - diff: 19.92mlTrain batch 17/32 - 237.6ms/batch - loss: 50.77382 - diff: 19.87mlTrain batch 18/32 - 240.3ms/batch - loss: 51.66057 - diff: 20.29mlTrain batch 19/32 - 237.3ms/batch - loss: 52.07311 - diff: 20.38mlTrain batch 20/32 - 240.0ms/batch - loss: 50.95111 - diff: 20.26mlTrain batch 21/32 - 237.7ms/batch - loss: 51.20705 - diff: 20.44mlTrain batch 22/32 - 240.1ms/batch - loss: 50.92039 - diff: 20.51mlTrain batch 23/32 - 238.2ms/batch - loss: 50.12239 - diff: 20.47mlTrain batch 24/32 - 240.3ms/batch - loss: 50.78332 - diff: 20.57mlTrain batch 25/32 - 237.6ms/batch - loss: 50.42725 - diff: 20.51mlTrain batch 26/32 - 238.9ms/batch - loss: 49.79179 - diff: 20.41mlTrain batch 27/32 - 238.4ms/batch - loss: 49.32864 - diff: 20.35mlTrain batch 28/32 - 239.9ms/batch - loss: 49.11460 - diff: 20.33mlTrain batch 29/32 - 238.2ms/batch - loss: 61.04047 - diff: 21.05mlTrain batch 30/32 - 239.4ms/batch - loss: 60.10832 - diff: 20.90mlTrain batch 31/32 - 237.3ms/batch - loss: 59.03578 - diff: 20.77mlTrain batch 32/32 - 76.8ms/batch - loss: 66.34719 - diff: 20.99mlTrain batch 32/32 - 10.7s 76.8ms/batch - loss: 66.34719 - diff: 20.99ml
Test 1.2s: val_loss: 81.75976 - diff: 24.83ml

Epoch 68: current best loss = 55.01709, at epoch 65
Train batch 1/32 - 237.5ms/batch - loss: 42.41756 - diff: 20.46mlTrain batch 2/32 - 252.2ms/batch - loss: 40.85801 - diff: 20.22mlTrain batch 3/32 - 237.2ms/batch - loss: 41.99122 - diff: 20.22mlTrain batch 4/32 - 240.2ms/batch - loss: 50.99633 - diff: 22.39mlTrain batch 5/32 - 237.5ms/batch - loss: 45.83122 - diff: 20.92mlTrain batch 6/32 - 240.4ms/batch - loss: 44.07556 - diff: 20.29mlTrain batch 7/32 - 237.3ms/batch - loss: 40.85456 - diff: 19.32mlTrain batch 8/32 - 240.4ms/batch - loss: 39.26829 - diff: 18.80mlTrain batch 9/32 - 237.8ms/batch - loss: 43.71768 - diff: 19.63mlTrain batch 10/32 - 240.4ms/batch - loss: 45.98889 - diff: 20.50mlTrain batch 11/32 - 237.8ms/batch - loss: 44.71373 - diff: 20.02mlTrain batch 12/32 - 240.2ms/batch - loss: 44.41457 - diff: 19.93mlTrain batch 13/32 - 237.4ms/batch - loss: 44.16268 - diff: 19.91mlTrain batch 14/32 - 239.2ms/batch - loss: 43.54657 - diff: 19.86mlTrain batch 15/32 - 237.3ms/batch - loss: 45.39535 - diff: 20.24mlTrain batch 16/32 - 239.2ms/batch - loss: 46.91114 - diff: 20.58mlTrain batch 17/32 - 238.0ms/batch - loss: 47.25244 - diff: 20.60mlTrain batch 18/32 - 239.2ms/batch - loss: 45.98649 - diff: 20.26mlTrain batch 19/32 - 238.3ms/batch - loss: 45.39417 - diff: 20.17mlTrain batch 20/32 - 239.6ms/batch - loss: 46.63605 - diff: 20.28mlTrain batch 21/32 - 237.4ms/batch - loss: 46.73099 - diff: 20.34mlTrain batch 22/32 - 240.0ms/batch - loss: 45.95417 - diff: 20.18mlTrain batch 23/32 - 237.2ms/batch - loss: 44.81462 - diff: 19.95mlTrain batch 24/32 - 240.1ms/batch - loss: 43.98485 - diff: 19.78mlTrain batch 25/32 - 238.5ms/batch - loss: 43.42955 - diff: 19.70mlTrain batch 26/32 - 240.2ms/batch - loss: 42.81182 - diff: 19.58mlTrain batch 27/32 - 237.4ms/batch - loss: 53.63677 - diff: 20.15mlTrain batch 28/32 - 240.4ms/batch - loss: 54.88640 - diff: 20.28mlTrain batch 29/32 - 237.6ms/batch - loss: 54.31347 - diff: 20.25mlTrain batch 30/32 - 240.4ms/batch - loss: 53.78995 - diff: 20.30mlTrain batch 31/32 - 237.4ms/batch - loss: 64.28681 - diff: 20.91mlTrain batch 32/32 - 77.4ms/batch - loss: 66.80448 - diff: 21.02mlTrain batch 32/32 - 10.6s 77.4ms/batch - loss: 66.80448 - diff: 21.02ml
Test 1.1s: val_loss: 97.27149 - diff: 28.42ml

Epoch 69: current best loss = 55.01709, at epoch 65
Train batch 1/32 - 237.4ms/batch - loss: 34.19181 - diff: 18.38mlTrain batch 2/32 - 244.0ms/batch - loss: 38.11512 - diff: 19.55mlTrain batch 3/32 - 237.4ms/batch - loss: 33.77405 - diff: 18.69mlTrain batch 4/32 - 240.1ms/batch - loss: 35.91852 - diff: 19.51mlTrain batch 5/32 - 239.4ms/batch - loss: 31.04851 - diff: 17.71mlTrain batch 6/32 - 240.1ms/batch - loss: 31.67718 - diff: 17.63mlTrain batch 7/32 - 238.2ms/batch - loss: 37.91526 - diff: 18.63mlTrain batch 8/32 - 241.5ms/batch - loss: 42.85695 - diff: 19.22mlTrain batch 9/32 - 237.4ms/batch - loss: 40.84040 - diff: 19.00mlTrain batch 10/32 - 239.3ms/batch - loss: 58.92535 - diff: 20.01mlTrain batch 11/32 - 238.1ms/batch - loss: 59.63526 - diff: 20.13mlTrain batch 12/32 - 240.1ms/batch - loss: 56.43779 - diff: 19.83mlTrain batch 13/32 - 238.3ms/batch - loss: 54.09603 - diff: 19.53mlTrain batch 14/32 - 239.5ms/batch - loss: 53.88684 - diff: 19.43mlTrain batch 15/32 - 238.6ms/batch - loss: 53.65739 - diff: 19.61mlTrain batch 16/32 - 239.6ms/batch - loss: 51.90716 - diff: 19.39mlTrain batch 17/32 - 237.1ms/batch - loss: 51.19691 - diff: 19.56mlTrain batch 18/32 - 240.0ms/batch - loss: 49.89516 - diff: 19.29mlTrain batch 19/32 - 237.9ms/batch - loss: 49.51311 - diff: 19.38mlTrain batch 20/32 - 240.1ms/batch - loss: 52.53198 - diff: 19.95mlTrain batch 21/32 - 237.5ms/batch - loss: 52.82362 - diff: 20.23mlTrain batch 22/32 - 240.2ms/batch - loss: 53.05087 - diff: 20.47mlTrain batch 23/32 - 237.6ms/batch - loss: 52.76209 - diff: 20.46mlTrain batch 24/32 - 240.5ms/batch - loss: 54.51272 - diff: 20.76mlTrain batch 25/32 - 237.0ms/batch - loss: 61.77154 - diff: 20.99mlTrain batch 26/32 - 240.6ms/batch - loss: 61.44599 - diff: 21.12mlTrain batch 27/32 - 237.1ms/batch - loss: 60.35476 - diff: 21.01mlTrain batch 28/32 - 241.1ms/batch - loss: 59.22265 - diff: 20.87mlTrain batch 29/32 - 237.9ms/batch - loss: 58.38843 - diff: 20.86mlTrain batch 30/32 - 240.4ms/batch - loss: 57.80376 - diff: 20.88mlTrain batch 31/32 - 237.9ms/batch - loss: 57.62782 - diff: 20.92mlTrain batch 32/32 - 78.7ms/batch - loss: 59.11324 - diff: 20.98mlTrain batch 32/32 - 10.6s 78.7ms/batch - loss: 59.11324 - diff: 20.98ml
Test 1.1s: val_loss: 57.02406 - diff: 21.40ml

Epoch 70: current best loss = 55.01709, at epoch 65
Train batch 1/32 - 237.0ms/batch - loss: 30.50339 - diff: 16.42mlTrain batch 2/32 - 238.5ms/batch - loss: 99.85111 - diff: 24.22mlTrain batch 3/32 - 237.3ms/batch - loss: 76.04451 - diff: 21.60mlTrain batch 4/32 - 238.9ms/batch - loss: 66.52195 - diff: 20.90mlTrain batch 5/32 - 238.3ms/batch - loss: 63.28086 - diff: 20.58mlTrain batch 6/32 - 239.3ms/batch - loss: 61.39490 - diff: 21.16mlTrain batch 7/32 - 237.6ms/batch - loss: 58.68690 - diff: 20.98mlTrain batch 8/32 - 238.8ms/batch - loss: 58.64381 - diff: 21.33mlTrain batch 9/32 - 237.4ms/batch - loss: 59.84799 - diff: 21.37mlTrain batch 10/32 - 239.5ms/batch - loss: 57.15850 - diff: 21.01mlTrain batch 11/32 - 237.2ms/batch - loss: 59.80013 - diff: 21.39mlTrain batch 12/32 - 240.5ms/batch - loss: 59.75303 - diff: 21.68mlTrain batch 13/32 - 238.0ms/batch - loss: 57.61868 - diff: 21.27mlTrain batch 14/32 - 240.1ms/batch - loss: 57.19977 - diff: 21.41mlTrain batch 15/32 - 237.5ms/batch - loss: 57.37839 - diff: 21.32mlTrain batch 16/32 - 240.2ms/batch - loss: 56.01883 - diff: 21.19mlTrain batch 17/32 - 243.7ms/batch - loss: 55.66114 - diff: 20.90mlTrain batch 18/32 - 238.5ms/batch - loss: 54.38697 - diff: 20.77mlTrain batch 19/32 - 237.8ms/batch - loss: 53.43517 - diff: 20.67mlTrain batch 20/32 - 240.4ms/batch - loss: 51.61426 - diff: 20.36mlTrain batch 21/32 - 238.3ms/batch - loss: 50.70204 - diff: 20.30mlTrain batch 22/32 - 240.1ms/batch - loss: 49.64745 - diff: 20.14mlTrain batch 23/32 - 238.4ms/batch - loss: 48.62288 - diff: 20.05mlTrain batch 24/32 - 240.1ms/batch - loss: 50.91905 - diff: 20.42mlTrain batch 25/32 - 238.4ms/batch - loss: 60.73079 - diff: 20.95mlTrain batch 26/32 - 239.2ms/batch - loss: 61.27799 - diff: 21.14mlTrain batch 27/32 - 237.4ms/batch - loss: 60.43143 - diff: 21.05mlTrain batch 28/32 - 238.8ms/batch - loss: 59.62089 - diff: 20.98mlTrain batch 29/32 - 238.4ms/batch - loss: 59.21705 - diff: 20.90mlTrain batch 30/32 - 240.2ms/batch - loss: 58.81465 - diff: 20.87mlTrain batch 31/32 - 246.0ms/batch - loss: 58.08099 - diff: 20.81mlTrain batch 32/32 - 76.8ms/batch - loss: 58.94808 - diff: 20.85mlTrain batch 32/32 - 10.7s 76.8ms/batch - loss: 58.94808 - diff: 20.85ml
Test 1.1s: val_loss: 1026.12450 - diff: 104.53ml

Epoch 71: current best loss = 55.01709, at epoch 65
Train batch 1/32 - 237.2ms/batch - loss: 42.83237 - diff: 23.11mlTrain batch 2/32 - 237.3ms/batch - loss: 61.76663 - diff: 26.41mlTrain batch 3/32 - 237.2ms/batch - loss: 50.87405 - diff: 22.85mlTrain batch 4/32 - 240.5ms/batch - loss: 50.58791 - diff: 22.46mlTrain batch 5/32 - 237.0ms/batch - loss: 50.50732 - diff: 21.88mlTrain batch 6/32 - 239.4ms/batch - loss: 50.64161 - diff: 22.00mlTrain batch 7/32 - 238.1ms/batch - loss: 46.42972 - diff: 20.95mlTrain batch 8/32 - 240.2ms/batch - loss: 45.12553 - diff: 20.62mlTrain batch 9/32 - 238.2ms/batch - loss: 43.68703 - diff: 20.11mlTrain batch 10/32 - 240.1ms/batch - loss: 53.29149 - diff: 20.48mlTrain batch 11/32 - 241.3ms/batch - loss: 51.04952 - diff: 19.95mlTrain batch 12/32 - 237.9ms/batch - loss: 52.36376 - diff: 20.05mlTrain batch 13/32 - 238.3ms/batch - loss: 50.83086 - diff: 19.83mlTrain batch 14/32 - 239.7ms/batch - loss: 51.91611 - diff: 20.37mlTrain batch 15/32 - 237.5ms/batch - loss: 57.15946 - diff: 21.21mlTrain batch 16/32 - 237.7ms/batch - loss: 61.02279 - diff: 21.71mlTrain batch 17/32 - 237.2ms/batch - loss: 60.05056 - diff: 21.64mlTrain batch 18/32 - 239.9ms/batch - loss: 58.07922 - diff: 21.40mlTrain batch 19/32 - 238.3ms/batch - loss: 56.36198 - diff: 21.11mlTrain batch 20/32 - 240.4ms/batch - loss: 57.22413 - diff: 21.38mlTrain batch 21/32 - 238.1ms/batch - loss: 57.54107 - diff: 21.56mlTrain batch 22/32 - 240.6ms/batch - loss: 64.94087 - diff: 21.82mlTrain batch 23/32 - 237.4ms/batch - loss: 64.05595 - diff: 21.79mlTrain batch 24/32 - 240.6ms/batch - loss: 63.41318 - diff: 21.86mlTrain batch 25/32 - 237.2ms/batch - loss: 61.98853 - diff: 21.67mlTrain batch 26/32 - 240.6ms/batch - loss: 60.26480 - diff: 21.38mlTrain batch 27/32 - 244.1ms/batch - loss: 59.88598 - diff: 21.29mlTrain batch 28/32 - 240.5ms/batch - loss: 59.05325 - diff: 21.11mlTrain batch 29/32 - 238.1ms/batch - loss: 59.40314 - diff: 21.27mlTrain batch 30/32 - 240.2ms/batch - loss: 58.55495 - diff: 21.14mlTrain batch 31/32 - 238.1ms/batch - loss: 57.56481 - diff: 21.08mlTrain batch 32/32 - 77.3ms/batch - loss: 57.26990 - diff: 20.97mlTrain batch 32/32 - 10.6s 77.3ms/batch - loss: 57.26990 - diff: 20.97ml
Test 1.1s: val_loss: 52.38548 - diff: 19.89ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Systole_WideResNet50_0_Adam-0.001_MSE_DA3_best

Epoch 72: current best loss = 52.38548, at epoch 71
Train batch 1/32 - 237.0ms/batch - loss: 46.45103 - diff: 20.82mlTrain batch 2/32 - 239.9ms/batch - loss: 41.58698 - diff: 20.22mlTrain batch 3/32 - 237.6ms/batch - loss: 160.65054 - diff: 27.33mlTrain batch 4/32 - 240.4ms/batch - loss: 128.21387 - diff: 25.06mlTrain batch 5/32 - 237.1ms/batch - loss: 112.46457 - diff: 24.17mlTrain batch 6/32 - 238.6ms/batch - loss: 98.34664 - diff: 22.85mlTrain batch 7/32 - 238.2ms/batch - loss: 91.42542 - diff: 22.82mlTrain batch 8/32 - 239.3ms/batch - loss: 85.03630 - diff: 22.39mlTrain batch 9/32 - 238.4ms/batch - loss: 78.61984 - diff: 21.80mlTrain batch 10/32 - 239.5ms/batch - loss: 76.39612 - diff: 22.12mlTrain batch 11/32 - 237.2ms/batch - loss: 73.70862 - diff: 22.15mlTrain batch 12/32 - 239.7ms/batch - loss: 72.20072 - diff: 22.09mlTrain batch 13/32 - 237.0ms/batch - loss: 70.40950 - diff: 21.74mlTrain batch 14/32 - 239.8ms/batch - loss: 70.97310 - diff: 22.28mlTrain batch 15/32 - 238.4ms/batch - loss: 67.97971 - diff: 21.98mlTrain batch 16/32 - 237.8ms/batch - loss: 66.75357 - diff: 21.89mlTrain batch 17/32 - 237.1ms/batch - loss: 65.01187 - diff: 21.75mlTrain batch 18/32 - 240.1ms/batch - loss: 62.85967 - diff: 21.40mlTrain batch 19/32 - 237.4ms/batch - loss: 61.41029 - diff: 21.20mlTrain batch 20/32 - 240.0ms/batch - loss: 62.09068 - diff: 21.38mlTrain batch 21/32 - 238.1ms/batch - loss: 60.72389 - diff: 21.29mlTrain batch 22/32 - 240.3ms/batch - loss: 59.90457 - diff: 21.40mlTrain batch 23/32 - 237.3ms/batch - loss: 58.69477 - diff: 21.25mlTrain batch 24/32 - 239.1ms/batch - loss: 58.27175 - diff: 21.13mlTrain batch 25/32 - 238.5ms/batch - loss: 58.25666 - diff: 21.12mlTrain batch 26/32 - 239.6ms/batch - loss: 57.28433 - diff: 20.99mlTrain batch 27/32 - 238.6ms/batch - loss: 56.15049 - diff: 20.89mlTrain batch 28/32 - 239.4ms/batch - loss: 55.20786 - diff: 20.82mlTrain batch 29/32 - 237.5ms/batch - loss: 54.29665 - diff: 20.73mlTrain batch 30/32 - 240.3ms/batch - loss: 59.29454 - diff: 21.01mlTrain batch 31/32 - 237.1ms/batch - loss: 59.22626 - diff: 21.06mlTrain batch 32/32 - 78.2ms/batch - loss: 60.12849 - diff: 21.07mlTrain batch 32/32 - 10.7s 78.2ms/batch - loss: 60.12849 - diff: 21.07ml
Test 1.1s: val_loss: 73.78558 - diff: 22.05ml

Epoch 73: current best loss = 52.38548, at epoch 71
Train batch 1/32 - 237.4ms/batch - loss: 38.54713 - diff: 15.74mlTrain batch 2/32 - 237.5ms/batch - loss: 42.20731 - diff: 18.22mlTrain batch 3/32 - 237.4ms/batch - loss: 40.96642 - diff: 17.93mlTrain batch 4/32 - 240.4ms/batch - loss: 42.57156 - diff: 18.56mlTrain batch 5/32 - 242.2ms/batch - loss: 43.92198 - diff: 19.28mlTrain batch 6/32 - 238.7ms/batch - loss: 45.53321 - diff: 20.02mlTrain batch 7/32 - 237.8ms/batch - loss: 80.56711 - diff: 22.36mlTrain batch 8/32 - 240.1ms/batch - loss: 75.69597 - diff: 21.87mlTrain batch 9/32 - 237.3ms/batch - loss: 73.44567 - diff: 22.10mlTrain batch 10/32 - 238.1ms/batch - loss: 68.92722 - diff: 21.66mlTrain batch 11/32 - 238.2ms/batch - loss: 67.62206 - diff: 21.66mlTrain batch 12/32 - 240.3ms/batch - loss: 65.43491 - diff: 21.57mlTrain batch 13/32 - 238.4ms/batch - loss: 62.83345 - diff: 21.09mlTrain batch 14/32 - 239.4ms/batch - loss: 60.53684 - diff: 20.84mlTrain batch 15/32 - 238.3ms/batch - loss: 65.64816 - diff: 21.21mlTrain batch 16/32 - 239.2ms/batch - loss: 63.98142 - diff: 21.23mlTrain batch 17/32 - 237.5ms/batch - loss: 63.19490 - diff: 21.25mlTrain batch 18/32 - 238.6ms/batch - loss: 61.56413 - diff: 21.07mlTrain batch 19/32 - 238.0ms/batch - loss: 61.29590 - diff: 21.11mlTrain batch 20/32 - 240.2ms/batch - loss: 59.84181 - diff: 20.99mlTrain batch 21/32 - 238.7ms/batch - loss: 58.61941 - diff: 20.82mlTrain batch 22/32 - 240.5ms/batch - loss: 56.71542 - diff: 20.45mlTrain batch 23/32 - 237.4ms/batch - loss: 56.50206 - diff: 20.40mlTrain batch 24/32 - 240.5ms/batch - loss: 58.95599 - diff: 20.68mlTrain batch 25/32 - 237.4ms/batch - loss: 59.12417 - diff: 20.87mlTrain batch 26/32 - 240.1ms/batch - loss: 58.91960 - diff: 21.00mlTrain batch 27/32 - 238.0ms/batch - loss: 58.25483 - diff: 21.03mlTrain batch 28/32 - 240.5ms/batch - loss: 57.14466 - diff: 20.87mlTrain batch 29/32 - 238.0ms/batch - loss: 57.55089 - diff: 21.13mlTrain batch 30/32 - 240.1ms/batch - loss: 57.04940 - diff: 20.98mlTrain batch 31/32 - 238.1ms/batch - loss: 56.27474 - diff: 20.90mlTrain batch 32/32 - 77.9ms/batch - loss: 56.09996 - diff: 20.81mlTrain batch 32/32 - 10.7s 77.9ms/batch - loss: 56.09996 - diff: 20.81ml
Test 1.2s: val_loss: 70.22573 - diff: 23.42ml

Epoch 74: current best loss = 52.38548, at epoch 71
Train batch 1/32 - 238.2ms/batch - loss: 29.57446 - diff: 17.26mlTrain batch 2/32 - 238.8ms/batch - loss: 32.81085 - diff: 19.23mlTrain batch 3/32 - 237.8ms/batch - loss: 83.88688 - diff: 20.92mlTrain batch 4/32 - 239.2ms/batch - loss: 75.83124 - diff: 22.16mlTrain batch 5/32 - 237.2ms/batch - loss: 64.29536 - diff: 20.21mlTrain batch 6/32 - 240.0ms/batch - loss: 58.58765 - diff: 19.77mlTrain batch 7/32 - 237.3ms/batch - loss: 56.07758 - diff: 19.52mlTrain batch 8/32 - 240.0ms/batch - loss: 51.85623 - diff: 18.91mlTrain batch 9/32 - 237.7ms/batch - loss: 51.25891 - diff: 19.30mlTrain batch 10/32 - 240.4ms/batch - loss: 49.91185 - diff: 19.23mlTrain batch 11/32 - 237.9ms/batch - loss: 50.71113 - diff: 19.21mlTrain batch 12/32 - 240.1ms/batch - loss: 50.16149 - diff: 19.38mlTrain batch 13/32 - 237.4ms/batch - loss: 49.74370 - diff: 19.58mlTrain batch 14/32 - 240.4ms/batch - loss: 48.83455 - diff: 19.58mlTrain batch 15/32 - 237.5ms/batch - loss: 48.03813 - diff: 19.49mlTrain batch 16/32 - 240.6ms/batch - loss: 47.33756 - diff: 19.49mlTrain batch 17/32 - 237.5ms/batch - loss: 48.95477 - diff: 19.91mlTrain batch 18/32 - 240.6ms/batch - loss: 49.52610 - diff: 20.07mlTrain batch 19/32 - 237.6ms/batch - loss: 47.92359 - diff: 19.79mlTrain batch 20/32 - 240.2ms/batch - loss: 47.13363 - diff: 19.79mlTrain batch 21/32 - 237.4ms/batch - loss: 47.84437 - diff: 19.97mlTrain batch 22/32 - 240.2ms/batch - loss: 47.68456 - diff: 19.90mlTrain batch 23/32 - 238.0ms/batch - loss: 48.49524 - diff: 20.06mlTrain batch 24/32 - 240.4ms/batch - loss: 54.20101 - diff: 20.56mlTrain batch 25/32 - 237.4ms/batch - loss: 52.76500 - diff: 20.30mlTrain batch 26/32 - 239.2ms/batch - loss: 53.26169 - diff: 20.37mlTrain batch 27/32 - 237.6ms/batch - loss: 52.19466 - diff: 20.19mlTrain batch 28/32 - 238.9ms/batch - loss: 51.04511 - diff: 20.00mlTrain batch 29/32 - 238.3ms/batch - loss: 49.77722 - diff: 19.71mlTrain batch 30/32 - 240.2ms/batch - loss: 49.32146 - diff: 19.68mlTrain batch 31/32 - 238.5ms/batch - loss: 48.91661 - diff: 19.51mlTrain batch 32/32 - 78.3ms/batch - loss: 49.77951 - diff: 19.54mlTrain batch 32/32 - 10.5s 78.3ms/batch - loss: 49.77951 - diff: 19.54ml
Test 1.2s: val_loss: 51.31719 - diff: 19.14ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Systole_WideResNet50_0_Adam-0.001_MSE_DA3_best

Epoch 75: current best loss = 51.31719, at epoch 74
Train batch 1/32 - 236.7ms/batch - loss: 38.41879 - diff: 18.59mlTrain batch 2/32 - 237.2ms/batch - loss: 47.29893 - diff: 20.69mlTrain batch 3/32 - 237.5ms/batch - loss: 43.70328 - diff: 21.26mlTrain batch 4/32 - 239.7ms/batch - loss: 44.89856 - diff: 20.90mlTrain batch 5/32 - 237.4ms/batch - loss: 65.53567 - diff: 23.06mlTrain batch 6/32 - 240.2ms/batch - loss: 59.12543 - diff: 21.80mlTrain batch 7/32 - 237.4ms/batch - loss: 56.41192 - diff: 21.22mlTrain batch 8/32 - 237.7ms/batch - loss: 51.71083 - diff: 20.18mlTrain batch 9/32 - 237.5ms/batch - loss: 48.66019 - diff: 19.96mlTrain batch 10/32 - 240.3ms/batch - loss: 47.64445 - diff: 19.70mlTrain batch 11/32 - 237.6ms/batch - loss: 49.08939 - diff: 19.90mlTrain batch 12/32 - 238.5ms/batch - loss: 46.24292 - diff: 19.31mlTrain batch 13/32 - 237.5ms/batch - loss: 44.02036 - diff: 18.81mlTrain batch 14/32 - 240.0ms/batch - loss: 57.08964 - diff: 19.88mlTrain batch 15/32 - 238.3ms/batch - loss: 54.81976 - diff: 19.49mlTrain batch 16/32 - 240.4ms/batch - loss: 53.04634 - diff: 19.26mlTrain batch 17/32 - 237.7ms/batch - loss: 51.29445 - diff: 19.05mlTrain batch 18/32 - 239.9ms/batch - loss: 51.83016 - diff: 19.40mlTrain batch 19/32 - 238.3ms/batch - loss: 50.24670 - diff: 19.11mlTrain batch 20/32 - 240.1ms/batch - loss: 49.48325 - diff: 19.10mlTrain batch 21/32 - 238.1ms/batch - loss: 48.34542 - diff: 19.01mlTrain batch 22/32 - 239.1ms/batch - loss: 47.65155 - diff: 19.01mlTrain batch 23/32 - 237.6ms/batch - loss: 50.06286 - diff: 19.31mlTrain batch 24/32 - 239.4ms/batch - loss: 48.94918 - diff: 19.19mlTrain batch 25/32 - 237.5ms/batch - loss: 48.25285 - diff: 19.05mlTrain batch 26/32 - 239.8ms/batch - loss: 47.94400 - diff: 19.05mlTrain batch 27/32 - 238.0ms/batch - loss: 47.43291 - diff: 18.98mlTrain batch 28/32 - 240.4ms/batch - loss: 51.74532 - diff: 19.42mlTrain batch 29/32 - 237.2ms/batch - loss: 51.42746 - diff: 19.48mlTrain batch 30/32 - 240.2ms/batch - loss: 51.53429 - diff: 19.59mlTrain batch 31/32 - 237.5ms/batch - loss: 50.62461 - diff: 19.39mlTrain batch 32/32 - 79.2ms/batch - loss: 51.52376 - diff: 19.38mlTrain batch 32/32 - 10.6s 79.2ms/batch - loss: 51.52376 - diff: 19.38ml
Test 1.2s: val_loss: 63.51023 - diff: 20.83ml

Epoch 76: current best loss = 51.31719, at epoch 74
Train batch 1/32 - 237.4ms/batch - loss: 56.31598 - diff: 23.08mlTrain batch 2/32 - 240.0ms/batch - loss: 59.62285 - diff: 22.05mlTrain batch 3/32 - 237.1ms/batch - loss: 50.39676 - diff: 20.09mlTrain batch 4/32 - 240.2ms/batch - loss: 46.74268 - diff: 20.00mlTrain batch 5/32 - 237.7ms/batch - loss: 47.04003 - diff: 19.78mlTrain batch 6/32 - 240.0ms/batch - loss: 44.94823 - diff: 19.85mlTrain batch 7/32 - 237.7ms/batch - loss: 46.39558 - diff: 19.86mlTrain batch 8/32 - 240.3ms/batch - loss: 44.64550 - diff: 19.74mlTrain batch 9/32 - 237.5ms/batch - loss: 45.09484 - diff: 19.43mlTrain batch 10/32 - 239.1ms/batch - loss: 47.55199 - diff: 20.09mlTrain batch 11/32 - 238.3ms/batch - loss: 44.94041 - diff: 19.55mlTrain batch 12/32 - 240.4ms/batch - loss: 54.40865 - diff: 20.01mlTrain batch 13/32 - 238.3ms/batch - loss: 53.37983 - diff: 19.88mlTrain batch 14/32 - 239.3ms/batch - loss: 53.40320 - diff: 19.94mlTrain batch 15/32 - 237.6ms/batch - loss: 51.81175 - diff: 19.55mlTrain batch 16/32 - 239.4ms/batch - loss: 49.72918 - diff: 19.23mlTrain batch 17/32 - 237.6ms/batch - loss: 48.30579 - diff: 19.03mlTrain batch 18/32 - 239.6ms/batch - loss: 48.55360 - diff: 19.10mlTrain batch 19/32 - 238.3ms/batch - loss: 47.85696 - diff: 19.15mlTrain batch 20/32 - 240.5ms/batch - loss: 46.73464 - diff: 19.05mlTrain batch 21/32 - 237.8ms/batch - loss: 46.25881 - diff: 18.97mlTrain batch 22/32 - 240.2ms/batch - loss: 45.44710 - diff: 18.86mlTrain batch 23/32 - 237.4ms/batch - loss: 44.25440 - diff: 18.61mlTrain batch 24/32 - 239.8ms/batch - loss: 43.53474 - diff: 18.48mlTrain batch 25/32 - 238.3ms/batch - loss: 54.50459 - diff: 19.00mlTrain batch 26/32 - 240.4ms/batch - loss: 54.60038 - diff: 19.02mlTrain batch 27/32 - 237.5ms/batch - loss: 54.08726 - diff: 19.06mlTrain batch 28/32 - 239.0ms/batch - loss: 56.05995 - diff: 19.36mlTrain batch 29/32 - 238.5ms/batch - loss: 55.28840 - diff: 19.34mlTrain batch 30/32 - 239.9ms/batch - loss: 55.41296 - diff: 19.53mlTrain batch 31/32 - 238.9ms/batch - loss: 55.53463 - diff: 19.69mlTrain batch 32/32 - 77.3ms/batch - loss: 56.44770 - diff: 19.71mlTrain batch 32/32 - 10.6s 77.3ms/batch - loss: 56.44770 - diff: 19.71ml
Test 1.1s: val_loss: 71.88825 - diff: 24.69ml

Epoch 77: current best loss = 51.31719, at epoch 74
Train batch 1/32 - 237.5ms/batch - loss: 25.92220 - diff: 16.13mlTrain batch 2/32 - 238.5ms/batch - loss: 32.81555 - diff: 17.71mlTrain batch 3/32 - 237.2ms/batch - loss: 28.85472 - diff: 16.40mlTrain batch 4/32 - 239.5ms/batch - loss: 37.16399 - diff: 18.66mlTrain batch 5/32 - 237.5ms/batch - loss: 35.08839 - diff: 18.33mlTrain batch 6/32 - 240.1ms/batch - loss: 35.16469 - diff: 18.41mlTrain batch 7/32 - 237.4ms/batch - loss: 60.21096 - diff: 19.55mlTrain batch 8/32 - 240.4ms/batch - loss: 57.75697 - diff: 19.65mlTrain batch 9/32 - 237.5ms/batch - loss: 58.29694 - diff: 20.08mlTrain batch 10/32 - 240.4ms/batch - loss: 55.88437 - diff: 19.89mlTrain batch 11/32 - 237.4ms/batch - loss: 53.99580 - diff: 19.52mlTrain batch 12/32 - 239.8ms/batch - loss: 52.12858 - diff: 19.41mlTrain batch 13/32 - 237.8ms/batch - loss: 52.97053 - diff: 19.59mlTrain batch 14/32 - 240.1ms/batch - loss: 54.38629 - diff: 20.10mlTrain batch 15/32 - 237.9ms/batch - loss: 53.43483 - diff: 20.05mlTrain batch 16/32 - 240.4ms/batch - loss: 52.68275 - diff: 20.05mlTrain batch 17/32 - 238.0ms/batch - loss: 52.54107 - diff: 20.09mlTrain batch 18/32 - 240.1ms/batch - loss: 51.74111 - diff: 20.19mlTrain batch 19/32 - 237.3ms/batch - loss: 57.48387 - diff: 20.33mlTrain batch 20/32 - 239.1ms/batch - loss: 56.22773 - diff: 20.16mlTrain batch 21/32 - 238.3ms/batch - loss: 56.80446 - diff: 20.34mlTrain batch 22/32 - 239.9ms/batch - loss: 55.76623 - diff: 20.28mlTrain batch 23/32 - 238.3ms/batch - loss: 53.86807 - diff: 19.83mlTrain batch 24/32 - 240.0ms/batch - loss: 53.60837 - diff: 19.91mlTrain batch 25/32 - 238.1ms/batch - loss: 53.02251 - diff: 19.97mlTrain batch 26/32 - 238.7ms/batch - loss: 52.17307 - diff: 19.84mlTrain batch 27/32 - 237.6ms/batch - loss: 51.05144 - diff: 19.69mlTrain batch 28/32 - 240.2ms/batch - loss: 51.66682 - diff: 19.95mlTrain batch 29/32 - 238.0ms/batch - loss: 51.37471 - diff: 20.02mlTrain batch 30/32 - 240.4ms/batch - loss: 50.63700 - diff: 19.90mlTrain batch 31/32 - 237.6ms/batch - loss: 50.01968 - diff: 19.82mlTrain batch 32/32 - 77.5ms/batch - loss: 49.71309 - diff: 19.71mlTrain batch 32/32 - 10.6s 77.5ms/batch - loss: 49.71309 - diff: 19.71ml
Test 1.2s: val_loss: 87.27559 - diff: 27.58ml

Epoch 78: current best loss = 51.31719, at epoch 74
Train batch 1/32 - 237.4ms/batch - loss: 54.66475 - diff: 21.15mlTrain batch 2/32 - 239.8ms/batch - loss: 55.45565 - diff: 21.30mlTrain batch 3/32 - 238.0ms/batch - loss: 64.23358 - diff: 22.92mlTrain batch 4/32 - 240.4ms/batch - loss: 67.01261 - diff: 24.60mlTrain batch 5/32 - 237.6ms/batch - loss: 65.33996 - diff: 23.84mlTrain batch 6/32 - 239.8ms/batch - loss: 63.45810 - diff: 23.56mlTrain batch 7/32 - 238.3ms/batch - loss: 57.71472 - diff: 22.24mlTrain batch 8/32 - 240.2ms/batch - loss: 55.09950 - diff: 21.63mlTrain batch 9/32 - 238.4ms/batch - loss: 54.43288 - diff: 21.91mlTrain batch 10/32 - 240.0ms/batch - loss: 54.77144 - diff: 21.92mlTrain batch 11/32 - 238.3ms/batch - loss: 54.77311 - diff: 21.84mlTrain batch 12/32 - 239.2ms/batch - loss: 66.05468 - diff: 22.52mlTrain batch 13/32 - 237.0ms/batch - loss: 63.91430 - diff: 22.28mlTrain batch 14/32 - 240.1ms/batch - loss: 62.72025 - diff: 21.96mlTrain batch 15/32 - 237.2ms/batch - loss: 65.89798 - diff: 22.19mlTrain batch 16/32 - 240.3ms/batch - loss: 64.31681 - diff: 21.96mlTrain batch 17/32 - 237.4ms/batch - loss: 74.46455 - diff: 22.38mlTrain batch 18/32 - 240.5ms/batch - loss: 72.07561 - diff: 22.11mlTrain batch 19/32 - 237.4ms/batch - loss: 71.87185 - diff: 22.39mlTrain batch 20/32 - 240.6ms/batch - loss: 69.84877 - diff: 22.21mlTrain batch 21/32 - 237.4ms/batch - loss: 68.57249 - diff: 22.20mlTrain batch 22/32 - 240.0ms/batch - loss: 66.94489 - diff: 21.97mlTrain batch 23/32 - 237.9ms/batch - loss: 64.99216 - diff: 21.70mlTrain batch 24/32 - 240.3ms/batch - loss: 63.85427 - diff: 21.59mlTrain batch 25/32 - 238.3ms/batch - loss: 62.48910 - diff: 21.38mlTrain batch 26/32 - 240.3ms/batch - loss: 61.38054 - diff: 21.31mlTrain batch 27/32 - 237.5ms/batch - loss: 60.47232 - diff: 21.18mlTrain batch 28/32 - 239.6ms/batch - loss: 59.57086 - diff: 21.14mlTrain batch 29/32 - 238.1ms/batch - loss: 58.62160 - diff: 21.06mlTrain batch 30/32 - 240.1ms/batch - loss: 58.62481 - diff: 21.04mlTrain batch 31/32 - 238.8ms/batch - loss: 57.65280 - diff: 20.91mlTrain batch 32/32 - 78.0ms/batch - loss: 65.66956 - diff: 21.18mlTrain batch 32/32 - 10.6s 78.0ms/batch - loss: 65.66956 - diff: 21.18ml
Test 1.2s: val_loss: 56.55997 - diff: 21.67ml

Epoch 79: current best loss = 51.31719, at epoch 74
Train batch 1/32 - 237.0ms/batch - loss: 45.96473 - diff: 21.32mlTrain batch 2/32 - 237.7ms/batch - loss: 32.60119 - diff: 17.61mlTrain batch 3/32 - 237.4ms/batch - loss: 29.48802 - diff: 16.64mlTrain batch 4/32 - 239.8ms/batch - loss: 25.46520 - diff: 15.62mlTrain batch 5/32 - 238.2ms/batch - loss: 27.04141 - diff: 16.44mlTrain batch 6/32 - 240.2ms/batch - loss: 27.11583 - diff: 16.68mlTrain batch 7/32 - 247.9ms/batch - loss: 28.06636 - diff: 16.67mlTrain batch 8/32 - 238.0ms/batch - loss: 32.41054 - diff: 17.64mlTrain batch 9/32 - 241.4ms/batch - loss: 34.86212 - diff: 18.33mlTrain batch 10/32 - 240.6ms/batch - loss: 33.43797 - diff: 17.83mlTrain batch 11/32 - 238.0ms/batch - loss: 33.16464 - diff: 17.62mlTrain batch 12/32 - 240.1ms/batch - loss: 32.93312 - diff: 17.55mlTrain batch 13/32 - 238.0ms/batch - loss: 34.95263 - diff: 17.87mlTrain batch 14/32 - 240.4ms/batch - loss: 35.15216 - diff: 17.85mlTrain batch 15/32 - 237.9ms/batch - loss: 36.00021 - diff: 18.13mlTrain batch 16/32 - 239.5ms/batch - loss: 46.62395 - diff: 18.88mlTrain batch 17/32 - 238.3ms/batch - loss: 46.44423 - diff: 18.96mlTrain batch 18/32 - 240.0ms/batch - loss: 47.74857 - diff: 19.25mlTrain batch 19/32 - 238.4ms/batch - loss: 48.14793 - diff: 19.34mlTrain batch 20/32 - 240.2ms/batch - loss: 47.52062 - diff: 19.22mlTrain batch 21/32 - 238.6ms/batch - loss: 47.12355 - diff: 19.20mlTrain batch 22/32 - 239.5ms/batch - loss: 46.75157 - diff: 19.29mlTrain batch 23/32 - 237.8ms/batch - loss: 46.13898 - diff: 19.25mlTrain batch 24/32 - 239.4ms/batch - loss: 52.62565 - diff: 19.46mlTrain batch 25/32 - 238.5ms/batch - loss: 52.21195 - diff: 19.51mlTrain batch 26/32 - 240.2ms/batch - loss: 52.67320 - diff: 19.58mlTrain batch 27/32 - 238.3ms/batch - loss: 52.92117 - diff: 19.75mlTrain batch 28/32 - 240.3ms/batch - loss: 53.64996 - diff: 19.97mlTrain batch 29/32 - 237.1ms/batch - loss: 53.22886 - diff: 19.97mlTrain batch 30/32 - 240.3ms/batch - loss: 52.61330 - diff: 19.95mlTrain batch 31/32 - 237.6ms/batch - loss: 52.82600 - diff: 20.02mlTrain batch 32/32 - 79.0ms/batch - loss: 52.53731 - diff: 19.92mlTrain batch 32/32 - 10.6s 79.0ms/batch - loss: 52.53731 - diff: 19.92ml
Test 1.1s: val_loss: 137.55131 - diff: 31.86ml

Epoch 80: current best loss = 51.31719, at epoch 74
Train batch 1/32 - 236.9ms/batch - loss: 42.19712 - diff: 17.46mlTrain batch 2/32 - 240.3ms/batch - loss: 40.99042 - diff: 19.06mlTrain batch 3/32 - 237.3ms/batch - loss: 42.14016 - diff: 20.11mlTrain batch 4/32 - 239.9ms/batch - loss: 52.97436 - diff: 21.73mlTrain batch 5/32 - 236.9ms/batch - loss: 48.63991 - diff: 21.09mlTrain batch 6/32 - 239.9ms/batch - loss: 54.08929 - diff: 22.72mlTrain batch 7/32 - 238.0ms/batch - loss: 50.36335 - diff: 21.90mlTrain batch 8/32 - 240.2ms/batch - loss: 46.45890 - diff: 20.90mlTrain batch 9/32 - 238.0ms/batch - loss: 43.49052 - diff: 20.13mlTrain batch 10/32 - 240.4ms/batch - loss: 76.10700 - diff: 22.96mlTrain batch 11/32 - 238.1ms/batch - loss: 74.69712 - diff: 22.98mlTrain batch 12/32 - 240.1ms/batch - loss: 72.25654 - diff: 22.84mlTrain batch 13/32 - 238.7ms/batch - loss: 70.03837 - diff: 22.50mlTrain batch 14/32 - 242.9ms/batch - loss: 67.82399 - diff: 22.32mlTrain batch 15/32 - 237.1ms/batch - loss: 68.35892 - diff: 22.55mlTrain batch 16/32 - 238.0ms/batch - loss: 65.39744 - diff: 22.06mlTrain batch 17/32 - 237.6ms/batch - loss: 63.79746 - diff: 21.88mlTrain batch 18/32 - 240.3ms/batch - loss: 62.48463 - diff: 21.70mlTrain batch 19/32 - 237.9ms/batch - loss: 62.04682 - diff: 21.81mlTrain batch 20/32 - 240.4ms/batch - loss: 60.17165 - diff: 21.33mlTrain batch 21/32 - 237.6ms/batch - loss: 59.95007 - diff: 21.48mlTrain batch 22/32 - 240.6ms/batch - loss: 58.97894 - diff: 21.38mlTrain batch 23/32 - 237.5ms/batch - loss: 57.77230 - diff: 21.33mlTrain batch 24/32 - 240.5ms/batch - loss: 57.78244 - diff: 21.45mlTrain batch 25/32 - 238.0ms/batch - loss: 57.30094 - diff: 21.30mlTrain batch 26/32 - 240.4ms/batch - loss: 56.61938 - diff: 21.25mlTrain batch 27/32 - 238.0ms/batch - loss: 56.03157 - diff: 21.22mlTrain batch 28/32 - 240.5ms/batch - loss: 56.03890 - diff: 21.32mlTrain batch 29/32 - 237.6ms/batch - loss: 55.17746 - diff: 21.29mlTrain batch 30/32 - 239.8ms/batch - loss: 54.07529 - diff: 21.11mlTrain batch 31/32 - 238.6ms/batch - loss: 54.03474 - diff: 21.09mlTrain batch 32/32 - 78.1ms/batch - loss: 54.10738 - diff: 21.03mlTrain batch 32/32 - 10.7s 78.1ms/batch - loss: 54.10738 - diff: 21.03ml
Test 1.1s: val_loss: 64.02120 - diff: 21.80ml

Epoch 81: current best loss = 51.31719, at epoch 74
Train batch 1/32 - 238.3ms/batch - loss: 14.82054 - diff: 13.15mlTrain batch 2/32 - 239.8ms/batch - loss: 23.19313 - diff: 16.07mlTrain batch 3/32 - 238.5ms/batch - loss: 19.93085 - diff: 14.52mlTrain batch 4/32 - 239.0ms/batch - loss: 53.11538 - diff: 18.05mlTrain batch 5/32 - 237.2ms/batch - loss: 51.83815 - diff: 18.14mlTrain batch 6/32 - 240.6ms/batch - loss: 52.00956 - diff: 18.74mlTrain batch 7/32 - 238.0ms/batch - loss: 51.37753 - diff: 18.73mlTrain batch 8/32 - 240.2ms/batch - loss: 48.85856 - diff: 18.50mlTrain batch 9/32 - 237.5ms/batch - loss: 51.53101 - diff: 19.26mlTrain batch 10/32 - 240.5ms/batch - loss: 50.53924 - diff: 19.39mlTrain batch 11/32 - 237.7ms/batch - loss: 48.41194 - diff: 19.11mlTrain batch 12/32 - 240.1ms/batch - loss: 47.59885 - diff: 19.11mlTrain batch 13/32 - 237.8ms/batch - loss: 47.83272 - diff: 19.17mlTrain batch 14/32 - 240.3ms/batch - loss: 50.35837 - diff: 19.75mlTrain batch 15/32 - 238.3ms/batch - loss: 49.39991 - diff: 19.60mlTrain batch 16/32 - 240.3ms/batch - loss: 47.72699 - diff: 19.35mlTrain batch 17/32 - 237.7ms/batch - loss: 48.09854 - diff: 19.37mlTrain batch 18/32 - 239.7ms/batch - loss: 48.31111 - diff: 19.46mlTrain batch 19/32 - 238.0ms/batch - loss: 47.19523 - diff: 19.32mlTrain batch 20/32 - 240.0ms/batch - loss: 48.18739 - diff: 19.54mlTrain batch 21/32 - 238.2ms/batch - loss: 47.89450 - diff: 19.59mlTrain batch 22/32 - 240.0ms/batch - loss: 47.09061 - diff: 19.50mlTrain batch 23/32 - 238.8ms/batch - loss: 47.61178 - diff: 19.76mlTrain batch 24/32 - 240.2ms/batch - loss: 56.19301 - diff: 20.13mlTrain batch 25/32 - 237.3ms/batch - loss: 54.69383 - diff: 19.92mlTrain batch 26/32 - 238.0ms/batch - loss: 53.59334 - diff: 19.86mlTrain batch 27/32 - 237.1ms/batch - loss: 54.12101 - diff: 20.01mlTrain batch 28/32 - 240.1ms/batch - loss: 53.61645 - diff: 20.07mlTrain batch 29/32 - 238.2ms/batch - loss: 53.21292 - diff: 20.18mlTrain batch 30/32 - 240.3ms/batch - loss: 53.09473 - diff: 20.33mlTrain batch 31/32 - 237.3ms/batch - loss: 53.16552 - diff: 20.30mlTrain batch 32/32 - 78.8ms/batch - loss: 53.28227 - diff: 20.25mlTrain batch 32/32 - 10.6s 78.8ms/batch - loss: 53.28227 - diff: 20.25ml
Test 1.1s: val_loss: 83.19228 - diff: 27.63ml

Epoch 82: current best loss = 51.31719, at epoch 74
Train batch 1/32 - 237.2ms/batch - loss: 32.58882 - diff: 17.63mlTrain batch 2/32 - 240.4ms/batch - loss: 37.69847 - diff: 17.68mlTrain batch 3/32 - 238.0ms/batch - loss: 33.83064 - diff: 17.78mlTrain batch 4/32 - 240.2ms/batch - loss: 32.98105 - diff: 17.65mlTrain batch 5/32 - 237.5ms/batch - loss: 33.30858 - diff: 17.83mlTrain batch 6/32 - 239.3ms/batch - loss: 32.02369 - diff: 17.92mlTrain batch 7/32 - 238.5ms/batch - loss: 32.35937 - diff: 17.83mlTrain batch 8/32 - 240.0ms/batch - loss: 33.02505 - diff: 18.10mlTrain batch 9/32 - 238.4ms/batch - loss: 32.46931 - diff: 18.11mlTrain batch 10/32 - 240.2ms/batch - loss: 33.05154 - diff: 17.94mlTrain batch 11/32 - 237.1ms/batch - loss: 31.84229 - diff: 17.52mlTrain batch 12/32 - 237.6ms/batch - loss: 31.85337 - diff: 17.59mlTrain batch 13/32 - 237.6ms/batch - loss: 31.29544 - diff: 17.30mlTrain batch 14/32 - 239.3ms/batch - loss: 30.00169 - diff: 16.92mlTrain batch 15/32 - 237.4ms/batch - loss: 29.36067 - diff: 16.84mlTrain batch 16/32 - 240.4ms/batch - loss: 31.03285 - diff: 17.03mlTrain batch 17/32 - 237.9ms/batch - loss: 30.92520 - diff: 17.02mlTrain batch 18/32 - 240.4ms/batch - loss: 30.55622 - diff: 17.03mlTrain batch 19/32 - 238.2ms/batch - loss: 30.14997 - diff: 16.99mlTrain batch 20/32 - 240.3ms/batch - loss: 29.91207 - diff: 16.89mlTrain batch 21/32 - 237.4ms/batch - loss: 32.56619 - diff: 17.36mlTrain batch 22/32 - 240.3ms/batch - loss: 32.39971 - diff: 17.43mlTrain batch 23/32 - 237.9ms/batch - loss: 32.64344 - diff: 17.51mlTrain batch 24/32 - 239.7ms/batch - loss: 41.84042 - diff: 18.53mlTrain batch 25/32 - 238.5ms/batch - loss: 42.15065 - diff: 18.75mlTrain batch 26/32 - 240.4ms/batch - loss: 43.09592 - diff: 18.98mlTrain batch 27/32 - 238.8ms/batch - loss: 43.57438 - diff: 19.03mlTrain batch 28/32 - 240.3ms/batch - loss: 43.54664 - diff: 19.12mlTrain batch 29/32 - 237.8ms/batch - loss: 43.49946 - diff: 19.13mlTrain batch 30/32 - 240.0ms/batch - loss: 42.99435 - diff: 19.10mlTrain batch 31/32 - 240.2ms/batch - loss: 50.71190 - diff: 19.38mlTrain batch 32/32 - 78.9ms/batch - loss: 51.68680 - diff: 19.42mlTrain batch 32/32 - 10.7s 78.9ms/batch - loss: 51.68680 - diff: 19.42ml
Test 1.2s: val_loss: 46.61215 - diff: 19.24ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Systole_WideResNet50_0_Adam-0.001_MSE_DA3_best

Epoch 83: current best loss = 46.61215, at epoch 82
Train batch 1/32 - 237.4ms/batch - loss: 20.03397 - diff: 15.54mlTrain batch 2/32 - 237.2ms/batch - loss: 42.44669 - diff: 21.46mlTrain batch 3/32 - 237.3ms/batch - loss: 36.26077 - diff: 18.98mlTrain batch 4/32 - 240.2ms/batch - loss: 35.95119 - diff: 19.07mlTrain batch 5/32 - 237.4ms/batch - loss: 34.48784 - diff: 18.68mlTrain batch 6/32 - 239.9ms/batch - loss: 34.84612 - diff: 18.61mlTrain batch 7/32 - 237.9ms/batch - loss: 41.35624 - diff: 19.41mlTrain batch 8/32 - 240.2ms/batch - loss: 37.76492 - diff: 18.40mlTrain batch 9/32 - 237.4ms/batch - loss: 44.71163 - diff: 19.47mlTrain batch 10/32 - 238.4ms/batch - loss: 43.48126 - diff: 19.07mlTrain batch 11/32 - 238.5ms/batch - loss: 41.97872 - diff: 18.79mlTrain batch 12/32 - 239.5ms/batch - loss: 40.76402 - diff: 18.48mlTrain batch 13/32 - 238.0ms/batch - loss: 41.14961 - diff: 18.65mlTrain batch 14/32 - 239.1ms/batch - loss: 40.21635 - diff: 18.37mlTrain batch 15/32 - 237.3ms/batch - loss: 40.12782 - diff: 18.41mlTrain batch 16/32 - 237.8ms/batch - loss: 39.71123 - diff: 18.52mlTrain batch 17/32 - 237.2ms/batch - loss: 41.21578 - diff: 18.76mlTrain batch 18/32 - 238.5ms/batch - loss: 47.43885 - diff: 19.18mlTrain batch 19/32 - 237.4ms/batch - loss: 46.38784 - diff: 19.08mlTrain batch 20/32 - 240.2ms/batch - loss: 46.40779 - diff: 19.04mlTrain batch 21/32 - 237.4ms/batch - loss: 48.08031 - diff: 19.40mlTrain batch 22/32 - 240.3ms/batch - loss: 47.78584 - diff: 19.56mlTrain batch 23/32 - 237.9ms/batch - loss: 47.79825 - diff: 19.63mlTrain batch 24/32 - 240.5ms/batch - loss: 47.12767 - diff: 19.56mlTrain batch 25/32 - 238.2ms/batch - loss: 48.32271 - diff: 19.91mlTrain batch 26/32 - 239.8ms/batch - loss: 49.32735 - diff: 19.96mlTrain batch 27/32 - 238.5ms/batch - loss: 50.63744 - diff: 20.25mlTrain batch 28/32 - 239.8ms/batch - loss: 49.83716 - diff: 20.10mlTrain batch 29/32 - 237.5ms/batch - loss: 49.93484 - diff: 20.22mlTrain batch 30/32 - 238.9ms/batch - loss: 49.64479 - diff: 20.20mlTrain batch 31/32 - 237.0ms/batch - loss: 49.78628 - diff: 20.30mlTrain batch 32/32 - 76.9ms/batch - loss: 51.60176 - diff: 20.34mlTrain batch 32/32 - 10.7s 76.9ms/batch - loss: 51.60176 - diff: 20.34ml
Test 1.1s: val_loss: 81.63867 - diff: 26.73ml

Epoch 84: current best loss = 46.61215, at epoch 82
Train batch 1/32 - 237.1ms/batch - loss: 49.28140 - diff: 24.26mlTrain batch 2/32 - 239.4ms/batch - loss: 203.49077 - diff: 30.58mlTrain batch 3/32 - 237.4ms/batch - loss: 144.21095 - diff: 25.09mlTrain batch 4/32 - 240.2ms/batch - loss: 119.15876 - diff: 23.96mlTrain batch 5/32 - 237.1ms/batch - loss: 109.21518 - diff: 23.74mlTrain batch 6/32 - 240.3ms/batch - loss: 94.77515 - diff: 22.52mlTrain batch 7/32 - 237.2ms/batch - loss: 83.97764 - diff: 21.23mlTrain batch 8/32 - 240.2ms/batch - loss: 78.14207 - diff: 20.82mlTrain batch 9/32 - 237.7ms/batch - loss: 75.78785 - diff: 21.34mlTrain batch 10/32 - 240.0ms/batch - loss: 71.84763 - diff: 20.94mlTrain batch 11/32 - 237.8ms/batch - loss: 67.10192 - diff: 20.31mlTrain batch 12/32 - 240.4ms/batch - loss: 65.38190 - diff: 20.23mlTrain batch 13/32 - 237.9ms/batch - loss: 62.03150 - diff: 19.81mlTrain batch 14/32 - 240.2ms/batch - loss: 59.60007 - diff: 19.62mlTrain batch 15/32 - 238.1ms/batch - loss: 56.83714 - diff: 19.28mlTrain batch 16/32 - 240.1ms/batch - loss: 59.50227 - diff: 19.78mlTrain batch 17/32 - 238.1ms/batch - loss: 57.75505 - diff: 19.60mlTrain batch 18/32 - 239.9ms/batch - loss: 57.38894 - diff: 19.87mlTrain batch 19/32 - 238.3ms/batch - loss: 56.18303 - diff: 19.76mlTrain batch 20/32 - 238.7ms/batch - loss: 55.42417 - diff: 19.88mlTrain batch 21/32 - 237.2ms/batch - loss: 56.36851 - diff: 20.24mlTrain batch 22/32 - 237.5ms/batch - loss: 54.73879 - diff: 19.93mlTrain batch 23/32 - 237.3ms/batch - loss: 53.61942 - diff: 19.78mlTrain batch 24/32 - 240.2ms/batch - loss: 52.31060 - diff: 19.56mlTrain batch 25/32 - 237.6ms/batch - loss: 51.74062 - diff: 19.57mlTrain batch 26/32 - 240.2ms/batch - loss: 51.33049 - diff: 19.58mlTrain batch 27/32 - 237.5ms/batch - loss: 51.33202 - diff: 19.58mlTrain batch 28/32 - 240.5ms/batch - loss: 50.78149 - diff: 19.45mlTrain batch 29/32 - 237.4ms/batch - loss: 52.42841 - diff: 19.66mlTrain batch 30/32 - 240.0ms/batch - loss: 52.54862 - diff: 19.82mlTrain batch 31/32 - 237.1ms/batch - loss: 51.75763 - diff: 19.75mlTrain batch 32/32 - 77.7ms/batch - loss: 51.72097 - diff: 19.69mlTrain batch 32/32 - 10.6s 77.7ms/batch - loss: 51.72097 - diff: 19.69ml
Test 1.1s: val_loss: 451.24839 - diff: 65.36ml

Epoch 85: current best loss = 46.61215, at epoch 82
Train batch 1/32 - 237.6ms/batch - loss: 189.86275 - diff: 30.41mlTrain batch 2/32 - 240.3ms/batch - loss: 239.57911 - diff: 33.36mlTrain batch 3/32 - 237.7ms/batch - loss: 168.62270 - diff: 27.62mlTrain batch 4/32 - 240.2ms/batch - loss: 135.88289 - diff: 25.55mlTrain batch 5/32 - 237.4ms/batch - loss: 122.05650 - diff: 25.37mlTrain batch 6/32 - 239.0ms/batch - loss: 106.21387 - diff: 24.12mlTrain batch 7/32 - 237.8ms/batch - loss: 100.35121 - diff: 24.61mlTrain batch 8/32 - 239.9ms/batch - loss: 92.92727 - diff: 23.87mlTrain batch 9/32 - 238.4ms/batch - loss: 92.28180 - diff: 24.79mlTrain batch 10/32 - 240.3ms/batch - loss: 88.32702 - diff: 24.60mlTrain batch 11/32 - 237.2ms/batch - loss: 85.94520 - diff: 24.74mlTrain batch 12/32 - 237.7ms/batch - loss: 82.59616 - diff: 24.58mlTrain batch 13/32 - 237.5ms/batch - loss: 83.16819 - diff: 25.03mlTrain batch 14/32 - 239.2ms/batch - loss: 82.39214 - diff: 24.82mlTrain batch 15/32 - 237.6ms/batch - loss: 79.89378 - diff: 24.42mlTrain batch 16/32 - 240.2ms/batch - loss: 77.87838 - diff: 24.28mlTrain batch 17/32 - 238.4ms/batch - loss: 76.19321 - diff: 24.18mlTrain batch 18/32 - 240.2ms/batch - loss: 75.76986 - diff: 24.07mlTrain batch 19/32 - 238.3ms/batch - loss: 73.11167 - diff: 23.63mlTrain batch 20/32 - 240.2ms/batch - loss: 72.52073 - diff: 23.65mlTrain batch 21/32 - 237.7ms/batch - loss: 69.86206 - diff: 23.14mlTrain batch 22/32 - 240.2ms/batch - loss: 67.77522 - diff: 22.82mlTrain batch 23/32 - 237.4ms/batch - loss: 66.26337 - diff: 22.55mlTrain batch 24/32 - 240.5ms/batch - loss: 64.38188 - diff: 22.24mlTrain batch 25/32 - 237.6ms/batch - loss: 62.68025 - diff: 21.94mlTrain batch 26/32 - 240.2ms/batch - loss: 60.87483 - diff: 21.60mlTrain batch 27/32 - 238.1ms/batch - loss: 60.04907 - diff: 21.52mlTrain batch 28/32 - 240.6ms/batch - loss: 58.92042 - diff: 21.27mlTrain batch 29/32 - 238.4ms/batch - loss: 59.46044 - diff: 21.40mlTrain batch 30/32 - 240.5ms/batch - loss: 59.05712 - diff: 21.33mlTrain batch 31/32 - 238.0ms/batch - loss: 58.72655 - diff: 21.28mlTrain batch 32/32 - 77.9ms/batch - loss: 58.50014 - diff: 21.20mlTrain batch 32/32 - 10.6s 77.9ms/batch - loss: 58.50014 - diff: 21.20ml
Test 1.2s: val_loss: 108.02999 - diff: 33.18ml

Epoch 86: current best loss = 46.61215, at epoch 82
Train batch 1/32 - 237.8ms/batch - loss: 28.10249 - diff: 16.90mlTrain batch 2/32 - 239.2ms/batch - loss: 35.11408 - diff: 17.43mlTrain batch 3/32 - 238.2ms/batch - loss: 37.90349 - diff: 18.20mlTrain batch 4/32 - 239.9ms/batch - loss: 43.54820 - diff: 19.68mlTrain batch 5/32 - 238.2ms/batch - loss: 42.78541 - diff: 19.57mlTrain batch 6/32 - 239.1ms/batch - loss: 39.00147 - diff: 18.70mlTrain batch 7/32 - 237.7ms/batch - loss: 41.54278 - diff: 19.26mlTrain batch 8/32 - 239.7ms/batch - loss: 39.56905 - diff: 19.03mlTrain batch 9/32 - 238.5ms/batch - loss: 40.93760 - diff: 19.40mlTrain batch 10/32 - 240.2ms/batch - loss: 40.41604 - diff: 19.25mlTrain batch 11/32 - 237.6ms/batch - loss: 39.68659 - diff: 19.17mlTrain batch 12/32 - 240.3ms/batch - loss: 41.21520 - diff: 19.82mlTrain batch 13/32 - 237.1ms/batch - loss: 43.15827 - diff: 20.20mlTrain batch 14/32 - 240.3ms/batch - loss: 41.84836 - diff: 19.85mlTrain batch 15/32 - 237.6ms/batch - loss: 42.85565 - diff: 20.04mlTrain batch 16/32 - 240.2ms/batch - loss: 41.49602 - diff: 19.65mlTrain batch 17/32 - 238.0ms/batch - loss: 42.58600 - diff: 20.03mlTrain batch 18/32 - 240.2ms/batch - loss: 41.54736 - diff: 19.64mlTrain batch 19/32 - 238.6ms/batch - loss: 41.11048 - diff: 19.71mlTrain batch 20/32 - 240.4ms/batch - loss: 41.18248 - diff: 19.71mlTrain batch 21/32 - 237.3ms/batch - loss: 40.01388 - diff: 19.39mlTrain batch 22/32 - 239.4ms/batch - loss: 39.74532 - diff: 19.34mlTrain batch 23/32 - 238.3ms/batch - loss: 39.70210 - diff: 19.29mlTrain batch 24/32 - 240.1ms/batch - loss: 39.00660 - diff: 19.13mlTrain batch 25/32 - 238.4ms/batch - loss: 39.51719 - diff: 19.27mlTrain batch 26/32 - 239.6ms/batch - loss: 39.24339 - diff: 19.22mlTrain batch 27/32 - 237.2ms/batch - loss: 47.21091 - diff: 19.70mlTrain batch 28/32 - 237.6ms/batch - loss: 47.58126 - diff: 19.83mlTrain batch 29/32 - 237.6ms/batch - loss: 47.43132 - diff: 19.84mlTrain batch 30/32 - 240.0ms/batch - loss: 46.19330 - diff: 19.51mlTrain batch 31/32 - 238.6ms/batch - loss: 53.17425 - diff: 19.94mlTrain batch 32/32 - 77.6ms/batch - loss: 53.49219 - diff: 19.91mlTrain batch 32/32 - 10.6s 77.6ms/batch - loss: 53.49219 - diff: 19.91ml
Test 1.1s: val_loss: 72.36340 - diff: 22.06ml

Epoch 87: current best loss = 46.61215, at epoch 82
Train batch 1/32 - 237.2ms/batch - loss: 25.20400 - diff: 15.28mlTrain batch 2/32 - 238.1ms/batch - loss: 46.28842 - diff: 17.77mlTrain batch 3/32 - 237.3ms/batch - loss: 46.13321 - diff: 19.29mlTrain batch 4/32 - 240.0ms/batch - loss: 42.26889 - diff: 18.94mlTrain batch 5/32 - 238.3ms/batch - loss: 38.12892 - diff: 17.97mlTrain batch 6/32 - 240.2ms/batch - loss: 41.81043 - diff: 19.15mlTrain batch 7/32 - 238.1ms/batch - loss: 39.62255 - diff: 18.66mlTrain batch 8/32 - 240.2ms/batch - loss: 39.19290 - diff: 18.47mlTrain batch 9/32 - 237.5ms/batch - loss: 42.65139 - diff: 19.21mlTrain batch 10/32 - 240.1ms/batch - loss: 41.41075 - diff: 18.92mlTrain batch 11/32 - 244.6ms/batch - loss: 40.31821 - diff: 18.81mlTrain batch 12/32 - 237.7ms/batch - loss: 44.61770 - diff: 19.58mlTrain batch 13/32 - 237.9ms/batch - loss: 54.33845 - diff: 20.04mlTrain batch 14/32 - 240.5ms/batch - loss: 54.06875 - diff: 19.96mlTrain batch 15/32 - 237.5ms/batch - loss: 53.52222 - diff: 19.98mlTrain batch 16/32 - 238.8ms/batch - loss: 51.93750 - diff: 19.68mlTrain batch 17/32 - 237.8ms/batch - loss: 50.94497 - diff: 19.46mlTrain batch 18/32 - 239.4ms/batch - loss: 49.37562 - diff: 19.25mlTrain batch 19/32 - 238.9ms/batch - loss: 47.87255 - diff: 19.05mlTrain batch 20/32 - 240.1ms/batch - loss: 49.70630 - diff: 19.39mlTrain batch 21/32 - 237.4ms/batch - loss: 48.90836 - diff: 19.36mlTrain batch 22/32 - 238.3ms/batch - loss: 48.67546 - diff: 19.40mlTrain batch 23/32 - 237.8ms/batch - loss: 47.58179 - diff: 19.27mlTrain batch 24/32 - 240.1ms/batch - loss: 47.61729 - diff: 19.45mlTrain batch 25/32 - 238.6ms/batch - loss: 46.54944 - diff: 19.33mlTrain batch 26/32 - 240.4ms/batch - loss: 45.84967 - diff: 19.27mlTrain batch 27/32 - 237.5ms/batch - loss: 45.95912 - diff: 19.31mlTrain batch 28/32 - 240.3ms/batch - loss: 46.05363 - diff: 19.39mlTrain batch 29/32 - 237.4ms/batch - loss: 45.37071 - diff: 19.29mlTrain batch 30/32 - 240.5ms/batch - loss: 50.04093 - diff: 19.59mlTrain batch 31/32 - 237.3ms/batch - loss: 50.82395 - diff: 19.80mlTrain batch 32/32 - 77.5ms/batch - loss: 51.05790 - diff: 19.77mlTrain batch 32/32 - 10.6s 77.5ms/batch - loss: 51.05790 - diff: 19.77ml
Test 1.1s: val_loss: 60.98428 - diff: 22.47ml

Epoch 88: current best loss = 46.61215, at epoch 82
Train batch 1/32 - 237.5ms/batch - loss: 34.47822 - diff: 20.01mlTrain batch 2/32 - 239.8ms/batch - loss: 25.32921 - diff: 17.24mlTrain batch 3/32 - 237.3ms/batch - loss: 24.69699 - diff: 17.16mlTrain batch 4/32 - 239.0ms/batch - loss: 27.69634 - diff: 17.03mlTrain batch 5/32 - 239.9ms/batch - loss: 30.53784 - diff: 17.96mlTrain batch 6/32 - 240.5ms/batch - loss: 28.56042 - diff: 17.41mlTrain batch 7/32 - 237.7ms/batch - loss: 34.04949 - diff: 18.50mlTrain batch 8/32 - 238.4ms/batch - loss: 35.04552 - diff: 18.57mlTrain batch 9/32 - 237.4ms/batch - loss: 36.97703 - diff: 18.72mlTrain batch 10/32 - 238.4ms/batch - loss: 56.33861 - diff: 20.17mlTrain batch 11/32 - 236.9ms/batch - loss: 65.60662 - diff: 20.97mlTrain batch 12/32 - 238.8ms/batch - loss: 63.47652 - diff: 20.99mlTrain batch 13/32 - 237.3ms/batch - loss: 63.72390 - diff: 21.32mlTrain batch 14/32 - 240.3ms/batch - loss: 60.56787 - diff: 20.80mlTrain batch 15/32 - 238.2ms/batch - loss: 57.92198 - diff: 20.39mlTrain batch 16/32 - 240.3ms/batch - loss: 56.67070 - diff: 20.21mlTrain batch 17/32 - 238.3ms/batch - loss: 55.81243 - diff: 20.24mlTrain batch 18/32 - 240.3ms/batch - loss: 54.68120 - diff: 20.15mlTrain batch 19/32 - 237.4ms/batch - loss: 53.41519 - diff: 19.85mlTrain batch 20/32 - 240.2ms/batch - loss: 52.43098 - diff: 19.83mlTrain batch 21/32 - 237.4ms/batch - loss: 50.92835 - diff: 19.63mlTrain batch 22/32 - 240.5ms/batch - loss: 49.81253 - diff: 19.48mlTrain batch 23/32 - 244.2ms/batch - loss: 51.30728 - diff: 19.76mlTrain batch 24/32 - 237.4ms/batch - loss: 51.27308 - diff: 19.82mlTrain batch 25/32 - 237.6ms/batch - loss: 51.21103 - diff: 19.93mlTrain batch 26/32 - 239.4ms/batch - loss: 51.34856 - diff: 19.99mlTrain batch 27/32 - 237.5ms/batch - loss: 50.91875 - diff: 19.98mlTrain batch 28/32 - 237.7ms/batch - loss: 50.83702 - diff: 20.03mlTrain batch 29/32 - 238.1ms/batch - loss: 50.69831 - diff: 19.97mlTrain batch 30/32 - 240.1ms/batch - loss: 50.46687 - diff: 20.02mlTrain batch 31/32 - 238.8ms/batch - loss: 50.23292 - diff: 20.04mlTrain batch 32/32 - 78.1ms/batch - loss: 52.28877 - diff: 20.11mlTrain batch 32/32 - 10.6s 78.1ms/batch - loss: 52.28877 - diff: 20.11ml
Test 1.1s: val_loss: 56.51320 - diff: 20.71ml

Epoch 89: current best loss = 46.61215, at epoch 82
Train batch 1/32 - 238.1ms/batch - loss: 25.73823 - diff: 17.51mlTrain batch 2/32 - 238.7ms/batch - loss: 23.52231 - diff: 16.24mlTrain batch 3/32 - 237.3ms/batch - loss: 36.36400 - diff: 18.94mlTrain batch 4/32 - 238.1ms/batch - loss: 35.23463 - diff: 18.44mlTrain batch 5/32 - 237.2ms/batch - loss: 32.94237 - diff: 18.04mlTrain batch 6/32 - 240.2ms/batch - loss: 33.87302 - diff: 18.79mlTrain batch 7/32 - 238.1ms/batch - loss: 32.13863 - diff: 18.36mlTrain batch 8/32 - 240.4ms/batch - loss: 35.00915 - diff: 18.89mlTrain batch 9/32 - 237.5ms/batch - loss: 34.72889 - diff: 18.58mlTrain batch 10/32 - 240.4ms/batch - loss: 37.11166 - diff: 18.49mlTrain batch 11/32 - 237.6ms/batch - loss: 35.59022 - diff: 18.06mlTrain batch 12/32 - 240.0ms/batch - loss: 38.85106 - diff: 18.73mlTrain batch 13/32 - 238.2ms/batch - loss: 40.02108 - diff: 18.87mlTrain batch 14/32 - 240.0ms/batch - loss: 38.44697 - diff: 18.49mlTrain batch 15/32 - 238.4ms/batch - loss: 47.30012 - diff: 18.87mlTrain batch 16/32 - 238.6ms/batch - loss: 45.71349 - diff: 18.55mlTrain batch 17/32 - 237.6ms/batch - loss: 46.04476 - diff: 18.87mlTrain batch 18/32 - 239.6ms/batch - loss: 44.75892 - diff: 18.75mlTrain batch 19/32 - 237.4ms/batch - loss: 45.74733 - diff: 18.97mlTrain batch 20/32 - 240.4ms/batch - loss: 46.93533 - diff: 19.25mlTrain batch 21/32 - 237.5ms/batch - loss: 45.98385 - diff: 19.05mlTrain batch 22/32 - 240.5ms/batch - loss: 45.45387 - diff: 19.00mlTrain batch 23/32 - 238.0ms/batch - loss: 44.76375 - diff: 18.82mlTrain batch 24/32 - 240.2ms/batch - loss: 43.80118 - diff: 18.58mlTrain batch 25/32 - 241.3ms/batch - loss: 44.17167 - diff: 18.73mlTrain batch 26/32 - 240.2ms/batch - loss: 43.47960 - diff: 18.67mlTrain batch 27/32 - 238.0ms/batch - loss: 42.86402 - diff: 18.65mlTrain batch 28/32 - 239.8ms/batch - loss: 52.13216 - diff: 19.29mlTrain batch 29/32 - 238.7ms/batch - loss: 51.54231 - diff: 19.19mlTrain batch 30/32 - 240.0ms/batch - loss: 51.09582 - diff: 19.17mlTrain batch 31/32 - 237.5ms/batch - loss: 50.13737 - diff: 18.99mlTrain batch 32/32 - 76.6ms/batch - loss: 56.36705 - diff: 19.13mlTrain batch 32/32 - 10.8s 76.6ms/batch - loss: 56.36705 - diff: 19.13ml
Test 1.1s: val_loss: 133.30875 - diff: 31.88ml

Epoch 90: current best loss = 46.61215, at epoch 82
Train batch 1/32 - 237.4ms/batch - loss: 65.95305 - diff: 21.81mlTrain batch 2/32 - 239.7ms/batch - loss: 100.32433 - diff: 22.14mlTrain batch 3/32 - 236.9ms/batch - loss: 76.45441 - diff: 19.96mlTrain batch 4/32 - 239.8ms/batch - loss: 66.47343 - diff: 20.06mlTrain batch 5/32 - 238.3ms/batch - loss: 64.52531 - diff: 20.64mlTrain batch 6/32 - 240.2ms/batch - loss: 57.93048 - diff: 20.01mlTrain batch 7/32 - 237.3ms/batch - loss: 58.45092 - diff: 20.81mlTrain batch 8/32 - 240.4ms/batch - loss: 56.10596 - diff: 20.43mlTrain batch 9/32 - 237.5ms/batch - loss: 51.44031 - diff: 19.52mlTrain batch 10/32 - 240.5ms/batch - loss: 53.58854 - diff: 20.18mlTrain batch 11/32 - 237.4ms/batch - loss: 53.04795 - diff: 20.15mlTrain batch 12/32 - 240.0ms/batch - loss: 51.42232 - diff: 20.14mlTrain batch 13/32 - 237.8ms/batch - loss: 51.26078 - diff: 20.06mlTrain batch 14/32 - 240.1ms/batch - loss: 49.88738 - diff: 19.95mlTrain batch 15/32 - 237.4ms/batch - loss: 49.15101 - diff: 19.93mlTrain batch 16/32 - 239.0ms/batch - loss: 47.77660 - diff: 19.66mlTrain batch 17/32 - 237.5ms/batch - loss: 48.01231 - diff: 19.66mlTrain batch 18/32 - 239.2ms/batch - loss: 46.96638 - diff: 19.55mlTrain batch 19/32 - 238.3ms/batch - loss: 45.95987 - diff: 19.33mlTrain batch 20/32 - 239.9ms/batch - loss: 44.24214 - diff: 18.86mlTrain batch 21/32 - 238.5ms/batch - loss: 44.28738 - diff: 18.97mlTrain batch 22/32 - 240.1ms/batch - loss: 44.13134 - diff: 19.04mlTrain batch 23/32 - 238.1ms/batch - loss: 43.34954 - diff: 18.91mlTrain batch 24/32 - 238.8ms/batch - loss: 43.03528 - diff: 18.90mlTrain batch 25/32 - 237.5ms/batch - loss: 49.46540 - diff: 19.42mlTrain batch 26/32 - 239.5ms/batch - loss: 48.75107 - diff: 19.35mlTrain batch 27/32 - 238.3ms/batch - loss: 49.30891 - diff: 19.54mlTrain batch 28/32 - 240.3ms/batch - loss: 49.04219 - diff: 19.54mlTrain batch 29/32 - 237.2ms/batch - loss: 48.13664 - diff: 19.38mlTrain batch 30/32 - 240.2ms/batch - loss: 47.64193 - diff: 19.34mlTrain batch 31/32 - 237.4ms/batch - loss: 48.25587 - diff: 19.52mlTrain batch 32/32 - 79.1ms/batch - loss: 50.05298 - diff: 19.56mlTrain batch 32/32 - 10.6s 79.1ms/batch - loss: 50.05298 - diff: 19.56ml
Test 1.2s: val_loss: 43.62158 - diff: 17.03ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Systole_WideResNet50_0_Adam-0.001_MSE_DA3_best

Epoch 91: current best loss = 43.62158, at epoch 90
Train batch 1/32 - 254.3ms/batch - loss: 42.79937 - diff: 19.91mlTrain batch 2/32 - 237.3ms/batch - loss: 32.84049 - diff: 17.03mlTrain batch 3/32 - 237.4ms/batch - loss: 30.43158 - diff: 16.86mlTrain batch 4/32 - 240.3ms/batch - loss: 34.98816 - diff: 18.00mlTrain batch 5/32 - 237.2ms/batch - loss: 36.82187 - diff: 18.92mlTrain batch 6/32 - 238.8ms/batch - loss: 36.61838 - diff: 19.06mlTrain batch 7/32 - 237.4ms/batch - loss: 35.62388 - diff: 18.90mlTrain batch 8/32 - 239.8ms/batch - loss: 35.45335 - diff: 18.97mlTrain batch 9/32 - 237.9ms/batch - loss: 47.76023 - diff: 20.18mlTrain batch 10/32 - 240.3ms/batch - loss: 45.79120 - diff: 19.72mlTrain batch 11/32 - 237.9ms/batch - loss: 47.37659 - diff: 20.17mlTrain batch 12/32 - 240.3ms/batch - loss: 44.46774 - diff: 19.45mlTrain batch 13/32 - 237.7ms/batch - loss: 44.28101 - diff: 19.30mlTrain batch 14/32 - 237.1ms/batch - loss: 43.52836 - diff: 19.05mlTrain batch 15/32 - 238.3ms/batch - loss: 57.24148 - diff: 19.91mlTrain batch 16/32 - 240.2ms/batch - loss: 56.47142 - diff: 20.05mlTrain batch 17/32 - 238.3ms/batch - loss: 55.08473 - diff: 19.90mlTrain batch 18/32 - 239.2ms/batch - loss: 53.99247 - diff: 20.00mlTrain batch 19/32 - 238.3ms/batch - loss: 53.13006 - diff: 19.88mlTrain batch 20/32 - 239.2ms/batch - loss: 53.77971 - diff: 20.36mlTrain batch 21/32 - 237.6ms/batch - loss: 52.85242 - diff: 20.27mlTrain batch 22/32 - 239.5ms/batch - loss: 56.74891 - diff: 20.81mlTrain batch 23/32 - 237.4ms/batch - loss: 56.57925 - diff: 20.83mlTrain batch 24/32 - 240.3ms/batch - loss: 58.14095 - diff: 21.01mlTrain batch 25/32 - 237.4ms/batch - loss: 58.39144 - diff: 21.13mlTrain batch 26/32 - 240.1ms/batch - loss: 57.47399 - diff: 21.02mlTrain batch 27/32 - 237.6ms/batch - loss: 57.78623 - diff: 21.20mlTrain batch 28/32 - 240.2ms/batch - loss: 56.93480 - diff: 21.15mlTrain batch 29/32 - 237.2ms/batch - loss: 56.03332 - diff: 21.02mlTrain batch 30/32 - 239.5ms/batch - loss: 54.80224 - diff: 20.75mlTrain batch 31/32 - 237.9ms/batch - loss: 53.83388 - diff: 20.55mlTrain batch 32/32 - 78.4ms/batch - loss: 54.65884 - diff: 20.56mlTrain batch 32/32 - 10.6s 78.4ms/batch - loss: 54.65884 - diff: 20.56ml
Test 1.2s: val_loss: 103.32444 - diff: 28.12ml

Epoch 92: current best loss = 43.62158, at epoch 90
Train batch 1/32 - 237.7ms/batch - loss: 48.19278 - diff: 21.15mlTrain batch 2/32 - 239.2ms/batch - loss: 35.40586 - diff: 17.48mlTrain batch 3/32 - 237.7ms/batch - loss: 37.23795 - diff: 18.61mlTrain batch 4/32 - 239.1ms/batch - loss: 31.28174 - diff: 17.01mlTrain batch 5/32 - 238.4ms/batch - loss: 27.16016 - diff: 15.65mlTrain batch 6/32 - 239.3ms/batch - loss: 33.79358 - diff: 16.55mlTrain batch 7/32 - 238.6ms/batch - loss: 39.16372 - diff: 17.55mlTrain batch 8/32 - 238.7ms/batch - loss: 42.48462 - diff: 18.21mlTrain batch 9/32 - 237.4ms/batch - loss: 40.92908 - diff: 17.87mlTrain batch 10/32 - 240.0ms/batch - loss: 38.88892 - diff: 17.55mlTrain batch 11/32 - 238.0ms/batch - loss: 37.07430 - diff: 17.07mlTrain batch 12/32 - 240.2ms/batch - loss: 39.61883 - diff: 17.71mlTrain batch 13/32 - 238.4ms/batch - loss: 38.50505 - diff: 17.47mlTrain batch 14/32 - 240.1ms/batch - loss: 40.60092 - diff: 18.21mlTrain batch 15/32 - 241.5ms/batch - loss: 41.26797 - diff: 18.52mlTrain batch 16/32 - 240.1ms/batch - loss: 40.52272 - diff: 18.47mlTrain batch 17/32 - 237.4ms/batch - loss: 54.77349 - diff: 19.76mlTrain batch 18/32 - 240.6ms/batch - loss: 52.80986 - diff: 19.50mlTrain batch 19/32 - 237.7ms/batch - loss: 53.23990 - diff: 19.87mlTrain batch 20/32 - 240.1ms/batch - loss: 52.51484 - diff: 19.90mlTrain batch 21/32 - 238.4ms/batch - loss: 51.70107 - diff: 19.83mlTrain batch 22/32 - 240.4ms/batch - loss: 50.31183 - diff: 19.61mlTrain batch 23/32 - 238.1ms/batch - loss: 50.03762 - diff: 19.67mlTrain batch 24/32 - 240.1ms/batch - loss: 49.25835 - diff: 19.60mlTrain batch 25/32 - 238.3ms/batch - loss: 49.12084 - diff: 19.71mlTrain batch 26/32 - 240.0ms/batch - loss: 48.20695 - diff: 19.60mlTrain batch 27/32 - 238.0ms/batch - loss: 51.10868 - diff: 19.88mlTrain batch 28/32 - 239.1ms/batch - loss: 50.38240 - diff: 19.82mlTrain batch 29/32 - 237.3ms/batch - loss: 49.91847 - diff: 19.72mlTrain batch 30/32 - 237.6ms/batch - loss: 49.13945 - diff: 19.58mlTrain batch 31/32 - 237.8ms/batch - loss: 49.77666 - diff: 19.66mlTrain batch 32/32 - 76.9ms/batch - loss: 50.98911 - diff: 19.71mlTrain batch 32/32 - 10.6s 76.9ms/batch - loss: 50.98911 - diff: 19.71ml
Test 1.1s: val_loss: 55.97097 - diff: 20.36ml

Epoch 93: current best loss = 43.62158, at epoch 90
Train batch 1/32 - 237.6ms/batch - loss: 46.15969 - diff: 20.27mlTrain batch 2/32 - 239.2ms/batch - loss: 31.20565 - diff: 16.12mlTrain batch 3/32 - 237.0ms/batch - loss: 32.43009 - diff: 16.79mlTrain batch 4/32 - 240.4ms/batch - loss: 36.52516 - diff: 17.21mlTrain batch 5/32 - 237.9ms/batch - loss: 35.77879 - diff: 17.19mlTrain batch 6/32 - 240.4ms/batch - loss: 58.70000 - diff: 18.64mlTrain batch 7/32 - 237.4ms/batch - loss: 55.71034 - diff: 18.41mlTrain batch 8/32 - 240.3ms/batch - loss: 53.18591 - diff: 18.63mlTrain batch 9/32 - 237.5ms/batch - loss: 49.96323 - diff: 18.45mlTrain batch 10/32 - 240.4ms/batch - loss: 48.07396 - diff: 18.49mlTrain batch 11/32 - 237.8ms/batch - loss: 46.08343 - diff: 18.43mlTrain batch 12/32 - 240.2ms/batch - loss: 45.02403 - diff: 18.47mlTrain batch 13/32 - 238.0ms/batch - loss: 43.78438 - diff: 18.25mlTrain batch 14/32 - 240.2ms/batch - loss: 42.68915 - diff: 17.98mlTrain batch 15/32 - 237.5ms/batch - loss: 42.73550 - diff: 17.84mlTrain batch 16/32 - 239.8ms/batch - loss: 41.05028 - diff: 17.49mlTrain batch 17/32 - 238.2ms/batch - loss: 39.86794 - diff: 17.30mlTrain batch 18/32 - 240.2ms/batch - loss: 38.59907 - diff: 17.02mlTrain batch 19/32 - 238.4ms/batch - loss: 46.00004 - diff: 17.50mlTrain batch 20/32 - 239.6ms/batch - loss: 45.49803 - diff: 17.51mlTrain batch 21/32 - 237.4ms/batch - loss: 46.53866 - diff: 17.89mlTrain batch 22/32 - 239.6ms/batch - loss: 48.67263 - diff: 18.40mlTrain batch 23/32 - 237.4ms/batch - loss: 47.27347 - diff: 18.21mlTrain batch 24/32 - 239.7ms/batch - loss: 46.88468 - diff: 18.25mlTrain batch 25/32 - 237.9ms/batch - loss: 47.46428 - diff: 18.45mlTrain batch 26/32 - 240.2ms/batch - loss: 48.21237 - diff: 18.66mlTrain batch 27/32 - 237.9ms/batch - loss: 48.29068 - diff: 18.78mlTrain batch 28/32 - 240.1ms/batch - loss: 48.76047 - diff: 18.87mlTrain batch 29/32 - 237.3ms/batch - loss: 49.01166 - diff: 18.96mlTrain batch 30/32 - 240.4ms/batch - loss: 49.66211 - diff: 19.17mlTrain batch 31/32 - 237.5ms/batch - loss: 49.15734 - diff: 19.15mlTrain batch 32/32 - 78.9ms/batch - loss: 51.70459 - diff: 19.24mlTrain batch 32/32 - 10.6s 78.9ms/batch - loss: 51.70459 - diff: 19.24ml
Test 1.1s: val_loss: 105.01805 - diff: 29.76ml

Epoch 94: current best loss = 43.62158, at epoch 90
Train batch 1/32 - 237.9ms/batch - loss: 18.33816 - diff: 12.51mlTrain batch 2/32 - 240.0ms/batch - loss: 32.36611 - diff: 15.94mlTrain batch 3/32 - 237.9ms/batch - loss: 30.69033 - diff: 16.08mlTrain batch 4/32 - 240.2ms/batch - loss: 32.12470 - diff: 17.04mlTrain batch 5/32 - 238.0ms/batch - loss: 34.63021 - diff: 17.58mlTrain batch 6/32 - 239.7ms/batch - loss: 34.61020 - diff: 17.50mlTrain batch 7/32 - 238.0ms/batch - loss: 42.15084 - diff: 18.72mlTrain batch 8/32 - 239.8ms/batch - loss: 38.44330 - diff: 17.79mlTrain batch 9/32 - 237.3ms/batch - loss: 36.25333 - diff: 17.12mlTrain batch 10/32 - 238.0ms/batch - loss: 36.86833 - diff: 17.40mlTrain batch 11/32 - 237.4ms/batch - loss: 35.13291 - diff: 17.08mlTrain batch 12/32 - 239.8ms/batch - loss: 52.31758 - diff: 18.54mlTrain batch 13/32 - 237.5ms/batch - loss: 52.40309 - diff: 18.53mlTrain batch 14/32 - 240.4ms/batch - loss: 52.94976 - diff: 18.91mlTrain batch 15/32 - 237.6ms/batch - loss: 53.68202 - diff: 19.09mlTrain batch 16/32 - 240.6ms/batch - loss: 53.30970 - diff: 19.21mlTrain batch 17/32 - 237.5ms/batch - loss: 55.28554 - diff: 19.66mlTrain batch 18/32 - 240.6ms/batch - loss: 53.87289 - diff: 19.69mlTrain batch 19/32 - 238.1ms/batch - loss: 52.29857 - diff: 19.52mlTrain batch 20/32 - 240.4ms/batch - loss: 51.31863 - diff: 19.38mlTrain batch 21/32 - 237.6ms/batch - loss: 50.31207 - diff: 19.24mlTrain batch 22/32 - 239.2ms/batch - loss: 48.44310 - diff: 18.81mlTrain batch 23/32 - 237.4ms/batch - loss: 47.61918 - diff: 18.79mlTrain batch 24/32 - 239.3ms/batch - loss: 46.61578 - diff: 18.59mlTrain batch 25/32 - 238.6ms/batch - loss: 46.32803 - diff: 18.66mlTrain batch 26/32 - 240.1ms/batch - loss: 47.09995 - diff: 19.00mlTrain batch 27/32 - 238.1ms/batch - loss: 52.89202 - diff: 19.42mlTrain batch 28/32 - 238.8ms/batch - loss: 52.24616 - diff: 19.40mlTrain batch 29/32 - 237.3ms/batch - loss: 51.08002 - diff: 19.21mlTrain batch 30/32 - 240.0ms/batch - loss: 51.70555 - diff: 19.32mlTrain batch 31/32 - 240.0ms/batch - loss: 51.66642 - diff: 19.40mlTrain batch 32/32 - 78.1ms/batch - loss: 54.36120 - diff: 19.47mlTrain batch 32/32 - 10.7s 78.1ms/batch - loss: 54.36120 - diff: 19.47ml
Test 1.2s: val_loss: 185.50483 - diff: 35.72ml

Epoch 95: current best loss = 43.62158, at epoch 90
Train batch 1/32 - 237.3ms/batch - loss: 12.03505 - diff: 11.88mlTrain batch 2/32 - 240.1ms/batch - loss: 27.54068 - diff: 16.66mlTrain batch 3/32 - 237.2ms/batch - loss: 27.26739 - diff: 16.95mlTrain batch 4/32 - 239.4ms/batch - loss: 27.54422 - diff: 16.70mlTrain batch 5/32 - 237.9ms/batch - loss: 25.09588 - diff: 15.96mlTrain batch 6/32 - 240.3ms/batch - loss: 27.67176 - diff: 16.63mlTrain batch 7/32 - 237.3ms/batch - loss: 30.14158 - diff: 17.23mlTrain batch 8/32 - 239.1ms/batch - loss: 28.30130 - diff: 16.58mlTrain batch 9/32 - 237.3ms/batch - loss: 28.56722 - diff: 16.76mlTrain batch 10/32 - 239.2ms/batch - loss: 30.52519 - diff: 17.06mlTrain batch 11/32 - 238.0ms/batch - loss: 51.64298 - diff: 18.34mlTrain batch 12/32 - 240.1ms/batch - loss: 50.25621 - diff: 18.47mlTrain batch 13/32 - 238.6ms/batch - loss: 48.68960 - diff: 18.41mlTrain batch 14/32 - 240.1ms/batch - loss: 49.03020 - diff: 18.79mlTrain batch 15/32 - 237.3ms/batch - loss: 51.94742 - diff: 19.27mlTrain batch 16/32 - 240.0ms/batch - loss: 51.04481 - diff: 19.24mlTrain batch 17/32 - 237.4ms/batch - loss: 57.03054 - diff: 19.49mlTrain batch 18/32 - 239.9ms/batch - loss: 55.01368 - diff: 19.25mlTrain batch 19/32 - 237.4ms/batch - loss: 54.57924 - diff: 19.27mlTrain batch 20/32 - 240.3ms/batch - loss: 52.82450 - diff: 18.99mlTrain batch 21/32 - 237.4ms/batch - loss: 53.55850 - diff: 19.26mlTrain batch 22/32 - 240.6ms/batch - loss: 52.44527 - diff: 19.20mlTrain batch 23/32 - 237.3ms/batch - loss: 51.65975 - diff: 19.19mlTrain batch 24/32 - 240.5ms/batch - loss: 52.53016 - diff: 19.57mlTrain batch 25/32 - 237.4ms/batch - loss: 52.91762 - diff: 19.75mlTrain batch 26/32 - 239.8ms/batch - loss: 53.37898 - diff: 20.01mlTrain batch 27/32 - 237.7ms/batch - loss: 54.05671 - diff: 20.10mlTrain batch 28/32 - 240.0ms/batch - loss: 54.97391 - diff: 20.25mlTrain batch 29/32 - 237.4ms/batch - loss: 54.66295 - diff: 20.36mlTrain batch 30/32 - 239.2ms/batch - loss: 54.80822 - diff: 20.39mlTrain batch 31/32 - 237.3ms/batch - loss: 54.23527 - diff: 20.32mlTrain batch 32/32 - 77.4ms/batch - loss: 56.25341 - diff: 20.37mlTrain batch 32/32 - 10.6s 77.4ms/batch - loss: 56.25341 - diff: 20.37ml
Test 1.1s: val_loss: 93.29023 - diff: 27.97ml

Epoch 96: current best loss = 43.62158, at epoch 90
Train batch 1/32 - 237.3ms/batch - loss: 46.40230 - diff: 18.54mlTrain batch 2/32 - 237.1ms/batch - loss: 44.07358 - diff: 19.93mlTrain batch 3/32 - 238.1ms/batch - loss: 47.49953 - diff: 20.87mlTrain batch 4/32 - 239.4ms/batch - loss: 43.10273 - diff: 19.28mlTrain batch 5/32 - 238.2ms/batch - loss: 70.38156 - diff: 21.39mlTrain batch 6/32 - 238.4ms/batch - loss: 65.66881 - diff: 20.82mlTrain batch 7/32 - 237.4ms/batch - loss: 62.84985 - diff: 20.82mlTrain batch 8/32 - 239.9ms/batch - loss: 56.95646 - diff: 19.82mlTrain batch 9/32 - 238.9ms/batch - loss: 55.00183 - diff: 19.61mlTrain batch 10/32 - 240.4ms/batch - loss: 60.54798 - diff: 20.88mlTrain batch 11/32 - 237.4ms/batch - loss: 57.43441 - diff: 20.35mlTrain batch 12/32 - 247.4ms/batch - loss: 54.57469 - diff: 20.03mlTrain batch 13/32 - 237.6ms/batch - loss: 51.50547 - diff: 19.40mlTrain batch 14/32 - 240.4ms/batch - loss: 52.11357 - diff: 19.87mlTrain batch 15/32 - 237.6ms/batch - loss: 57.03250 - diff: 20.58mlTrain batch 16/32 - 240.2ms/batch - loss: 56.20106 - diff: 20.28mlTrain batch 17/32 - 238.0ms/batch - loss: 67.18177 - diff: 20.52mlTrain batch 18/32 - 240.2ms/batch - loss: 65.56973 - diff: 20.62mlTrain batch 19/32 - 237.8ms/batch - loss: 63.91956 - diff: 20.47mlTrain batch 20/32 - 240.4ms/batch - loss: 63.18140 - diff: 20.54mlTrain batch 21/32 - 237.5ms/batch - loss: 62.20798 - diff: 20.60mlTrain batch 22/32 - 239.5ms/batch - loss: 60.60727 - diff: 20.42mlTrain batch 23/32 - 238.4ms/batch - loss: 59.50314 - diff: 20.27mlTrain batch 24/32 - 240.2ms/batch - loss: 58.01535 - diff: 20.05mlTrain batch 25/32 - 238.1ms/batch - loss: 57.24675 - diff: 20.04mlTrain batch 26/32 - 239.2ms/batch - loss: 56.28506 - diff: 20.00mlTrain batch 27/32 - 237.3ms/batch - loss: 55.28659 - diff: 19.92mlTrain batch 28/32 - 240.1ms/batch - loss: 54.51269 - diff: 19.84mlTrain batch 29/32 - 238.3ms/batch - loss: 54.64461 - diff: 19.84mlTrain batch 30/32 - 240.2ms/batch - loss: 56.00922 - diff: 20.22mlTrain batch 31/32 - 237.7ms/batch - loss: 55.23733 - diff: 20.07mlTrain batch 32/32 - 78.9ms/batch - loss: 55.35115 - diff: 20.03mlTrain batch 32/32 - 10.6s 78.9ms/batch - loss: 55.35115 - diff: 20.03ml
Test 1.1s: val_loss: 58.18456 - diff: 21.31ml

Epoch 97: current best loss = 43.62158, at epoch 90
Train batch 1/32 - 237.3ms/batch - loss: 22.19132 - diff: 14.71mlTrain batch 2/32 - 240.1ms/batch - loss: 40.31294 - diff: 17.65mlTrain batch 3/32 - 237.3ms/batch - loss: 37.25548 - diff: 15.85mlTrain batch 4/32 - 240.3ms/batch - loss: 46.42999 - diff: 17.76mlTrain batch 5/32 - 237.4ms/batch - loss: 41.97912 - diff: 16.96mlTrain batch 6/32 - 239.6ms/batch - loss: 38.12690 - diff: 16.32mlTrain batch 7/32 - 237.2ms/batch - loss: 35.56476 - diff: 16.05mlTrain batch 8/32 - 239.5ms/batch - loss: 33.73056 - diff: 15.95mlTrain batch 9/32 - 238.2ms/batch - loss: 51.75246 - diff: 17.88mlTrain batch 10/32 - 240.3ms/batch - loss: 49.33812 - diff: 17.72mlTrain batch 11/32 - 238.0ms/batch - loss: 46.18371 - diff: 17.00mlTrain batch 12/32 - 240.2ms/batch - loss: 45.61967 - diff: 17.25mlTrain batch 13/32 - 238.0ms/batch - loss: 47.30305 - diff: 17.69mlTrain batch 14/32 - 239.8ms/batch - loss: 44.93694 - diff: 17.17mlTrain batch 15/32 - 238.9ms/batch - loss: 42.96862 - diff: 16.93mlTrain batch 16/32 - 240.0ms/batch - loss: 41.55480 - diff: 16.70mlTrain batch 17/32 - 237.5ms/batch - loss: 40.07105 - diff: 16.44mlTrain batch 18/32 - 239.3ms/batch - loss: 38.70789 - diff: 16.15mlTrain batch 19/32 - 237.4ms/batch - loss: 38.83935 - diff: 16.33mlTrain batch 20/32 - 240.1ms/batch - loss: 38.00811 - diff: 16.27mlTrain batch 21/32 - 238.0ms/batch - loss: 39.42320 - diff: 16.55mlTrain batch 22/32 - 240.4ms/batch - loss: 38.50857 - diff: 16.47mlTrain batch 23/32 - 237.5ms/batch - loss: 37.44958 - diff: 16.26mlTrain batch 24/32 - 240.4ms/batch - loss: 38.18568 - diff: 16.44mlTrain batch 25/32 - 237.5ms/batch - loss: 38.47173 - diff: 16.67mlTrain batch 26/32 - 240.5ms/batch - loss: 38.27986 - diff: 16.72mlTrain batch 27/32 - 237.5ms/batch - loss: 47.30110 - diff: 17.19mlTrain batch 28/32 - 239.9ms/batch - loss: 48.97573 - diff: 17.61mlTrain batch 29/32 - 237.6ms/batch - loss: 49.51100 - diff: 17.88mlTrain batch 30/32 - 239.8ms/batch - loss: 50.23257 - diff: 18.17mlTrain batch 31/32 - 238.1ms/batch - loss: 49.17327 - diff: 17.96mlTrain batch 32/32 - 78.8ms/batch - loss: 52.26586 - diff: 18.14mlTrain batch 32/32 - 10.6s 78.8ms/batch - loss: 52.26586 - diff: 18.14ml
Test 1.1s: val_loss: 48.88512 - diff: 18.62ml

Epoch 98: current best loss = 43.62158, at epoch 90
Train batch 1/32 - 236.9ms/batch - loss: 27.86283 - diff: 16.81mlTrain batch 2/32 - 238.4ms/batch - loss: 22.06693 - diff: 14.33mlTrain batch 3/32 - 238.1ms/batch - loss: 30.01752 - diff: 16.98mlTrain batch 4/32 - 240.2ms/batch - loss: 36.85902 - diff: 18.33mlTrain batch 5/32 - 237.2ms/batch - loss: 37.20356 - diff: 18.74mlTrain batch 6/32 - 239.6ms/batch - loss: 41.02664 - diff: 19.63mlTrain batch 7/32 - 238.1ms/batch - loss: 43.49847 - diff: 20.25mlTrain batch 8/32 - 238.9ms/batch - loss: 44.91859 - diff: 20.26mlTrain batch 9/32 - 237.4ms/batch - loss: 42.75394 - diff: 19.82mlTrain batch 10/32 - 239.4ms/batch - loss: 44.21430 - diff: 19.96mlTrain batch 11/32 - 237.4ms/batch - loss: 43.78870 - diff: 20.02mlTrain batch 12/32 - 240.0ms/batch - loss: 42.16248 - diff: 19.64mlTrain batch 13/32 - 238.1ms/batch - loss: 40.85196 - diff: 19.31mlTrain batch 14/32 - 240.4ms/batch - loss: 40.84954 - diff: 19.12mlTrain batch 15/32 - 238.4ms/batch - loss: 43.88372 - diff: 19.60mlTrain batch 16/32 - 240.2ms/batch - loss: 63.45297 - diff: 21.48mlTrain batch 17/32 - 244.7ms/batch - loss: 60.82191 - diff: 20.91mlTrain batch 18/32 - 237.4ms/batch - loss: 59.51527 - diff: 20.87mlTrain batch 19/32 - 237.2ms/batch - loss: 58.50648 - diff: 20.83mlTrain batch 20/32 - 239.9ms/batch - loss: 56.44224 - diff: 20.49mlTrain batch 21/32 - 237.8ms/batch - loss: 56.40451 - diff: 20.42mlTrain batch 22/32 - 240.0ms/batch - loss: 54.88539 - diff: 20.15mlTrain batch 23/32 - 237.8ms/batch - loss: 54.41206 - diff: 20.31mlTrain batch 24/32 - 240.0ms/batch - loss: 53.21546 - diff: 20.20mlTrain batch 25/32 - 237.4ms/batch - loss: 53.02696 - diff: 20.22mlTrain batch 26/32 - 239.8ms/batch - loss: 55.49583 - diff: 20.73mlTrain batch 27/32 - 238.4ms/batch - loss: 54.11256 - diff: 20.44mlTrain batch 28/32 - 240.0ms/batch - loss: 60.39947 - diff: 20.91mlTrain batch 29/32 - 238.6ms/batch - loss: 59.10843 - diff: 20.75mlTrain batch 30/32 - 240.0ms/batch - loss: 58.75957 - diff: 20.75mlTrain batch 31/32 - 238.1ms/batch - loss: 58.07700 - diff: 20.73mlTrain batch 32/32 - 76.8ms/batch - loss: 60.31209 - diff: 20.85mlTrain batch 32/32 - 10.6s 76.8ms/batch - loss: 60.31209 - diff: 20.85ml
Test 1.1s: val_loss: 134.60600 - diff: 32.21ml

Epoch 99: current best loss = 43.62158, at epoch 90
Train batch 1/32 - 238.0ms/batch - loss: 31.66174 - diff: 15.29mlTrain batch 2/32 - 239.2ms/batch - loss: 26.92506 - diff: 14.92mlTrain batch 3/32 - 238.0ms/batch - loss: 55.03656 - diff: 17.61mlTrain batch 4/32 - 239.3ms/batch - loss: 56.05022 - diff: 19.12mlTrain batch 5/32 - 238.3ms/batch - loss: 52.48327 - diff: 19.10mlTrain batch 6/32 - 238.7ms/batch - loss: 53.16418 - diff: 20.07mlTrain batch 7/32 - 237.6ms/batch - loss: 48.50020 - diff: 19.36mlTrain batch 8/32 - 240.2ms/batch - loss: 46.06701 - diff: 19.10mlTrain batch 9/32 - 237.4ms/batch - loss: 45.09781 - diff: 18.93mlTrain batch 10/32 - 240.4ms/batch - loss: 45.81631 - diff: 19.05mlTrain batch 11/32 - 237.3ms/batch - loss: 46.25015 - diff: 19.36mlTrain batch 12/32 - 240.3ms/batch - loss: 48.45541 - diff: 19.95mlTrain batch 13/32 - 237.7ms/batch - loss: 49.47757 - diff: 20.10mlTrain batch 14/32 - 240.3ms/batch - loss: 47.91559 - diff: 19.83mlTrain batch 15/32 - 237.6ms/batch - loss: 46.31187 - diff: 19.50mlTrain batch 16/32 - 240.3ms/batch - loss: 50.55528 - diff: 19.95mlTrain batch 17/32 - 237.9ms/batch - loss: 49.32905 - diff: 19.65mlTrain batch 18/32 - 240.3ms/batch - loss: 49.08898 - diff: 19.59mlTrain batch 19/32 - 237.9ms/batch - loss: 47.76848 - diff: 19.28mlTrain batch 20/32 - 240.4ms/batch - loss: 46.87129 - diff: 19.26mlTrain batch 21/32 - 237.5ms/batch - loss: 45.47835 - diff: 19.00mlTrain batch 22/32 - 239.6ms/batch - loss: 45.66691 - diff: 19.15mlTrain batch 23/32 - 237.6ms/batch - loss: 45.36120 - diff: 19.13mlTrain batch 24/32 - 239.0ms/batch - loss: 44.99508 - diff: 19.08mlTrain batch 25/32 - 238.2ms/batch - loss: 43.83843 - diff: 18.85mlTrain batch 26/32 - 239.9ms/batch - loss: 43.44864 - diff: 18.70mlTrain batch 27/32 - 238.8ms/batch - loss: 45.14833 - diff: 19.08mlTrain batch 28/32 - 239.8ms/batch - loss: 44.92381 - diff: 19.07mlTrain batch 29/32 - 238.7ms/batch - loss: 44.43028 - diff: 18.94mlTrain batch 30/32 - 240.4ms/batch - loss: 45.33204 - diff: 19.17mlTrain batch 31/32 - 237.4ms/batch - loss: 45.24693 - diff: 19.12mlTrain batch 32/32 - 76.7ms/batch - loss: 45.76040 - diff: 19.08mlTrain batch 32/32 - 10.5s 76.7ms/batch - loss: 45.76040 - diff: 19.08ml
Test 1.2s: val_loss: 72.05154 - diff: 22.67ml

Epoch 100: current best loss = 43.62158, at epoch 90
Train batch 1/32 - 237.4ms/batch - loss: 47.76994 - diff: 20.80mlTrain batch 2/32 - 239.6ms/batch - loss: 61.24405 - diff: 23.06mlTrain batch 3/32 - 237.3ms/batch - loss: 67.49054 - diff: 22.64mlTrain batch 4/32 - 240.2ms/batch - loss: 56.92476 - diff: 21.13mlTrain batch 5/32 - 238.3ms/batch - loss: 48.97011 - diff: 19.40mlTrain batch 6/32 - 240.4ms/batch - loss: 48.73712 - diff: 20.05mlTrain batch 7/32 - 238.1ms/batch - loss: 44.98100 - diff: 19.20mlTrain batch 8/32 - 240.2ms/batch - loss: 41.69954 - diff: 18.69mlTrain batch 9/32 - 237.4ms/batch - loss: 40.24187 - diff: 18.46mlTrain batch 10/32 - 240.5ms/batch - loss: 41.04772 - diff: 18.50mlTrain batch 11/32 - 237.3ms/batch - loss: 39.20711 - diff: 18.11mlTrain batch 12/32 - 240.5ms/batch - loss: 39.44670 - diff: 18.16mlTrain batch 13/32 - 236.9ms/batch - loss: 38.91528 - diff: 18.32mlTrain batch 14/32 - 239.6ms/batch - loss: 39.42158 - diff: 18.47mlTrain batch 15/32 - 237.4ms/batch - loss: 39.18882 - diff: 18.51mlTrain batch 16/32 - 239.9ms/batch - loss: 39.67920 - diff: 18.72mlTrain batch 17/32 - 238.1ms/batch - loss: 45.15951 - diff: 19.09mlTrain batch 18/32 - 240.5ms/batch - loss: 44.02094 - diff: 18.92mlTrain batch 19/32 - 237.4ms/batch - loss: 43.68439 - diff: 18.89mlTrain batch 20/32 - 239.3ms/batch - loss: 43.93045 - diff: 19.02mlTrain batch 21/32 - 240.1ms/batch - loss: 44.25604 - diff: 19.19mlTrain batch 22/32 - 240.2ms/batch - loss: 43.50294 - diff: 19.13mlTrain batch 23/32 - 238.5ms/batch - loss: 45.64727 - diff: 19.44mlTrain batch 24/32 - 239.5ms/batch - loss: 45.33286 - diff: 19.39mlTrain batch 25/32 - 238.8ms/batch - loss: 44.62157 - diff: 19.26mlTrain batch 26/32 - 239.7ms/batch - loss: 46.04936 - diff: 19.23mlTrain batch 27/32 - 238.3ms/batch - loss: 45.80901 - diff: 19.24mlTrain batch 28/32 - 237.4ms/batch - loss: 45.01859 - diff: 19.16mlTrain batch 29/32 - 237.6ms/batch - loss: 46.50900 - diff: 19.52mlTrain batch 30/32 - 240.2ms/batch - loss: 46.81629 - diff: 19.59mlTrain batch 31/32 - 240.1ms/batch - loss: 45.59035 - diff: 19.29mlTrain batch 32/32 - 78.1ms/batch - loss: 46.01405 - diff: 19.24mlTrain batch 32/32 - 10.5s 78.1ms/batch - loss: 46.01405 - diff: 19.24ml
Test 1.2s: val_loss: 49.51657 - diff: 20.28ml

Epoch 101: current best loss = 43.62158, at epoch 90
Train batch 1/32 - 237.1ms/batch - loss: 28.77134 - diff: 17.12mlTrain batch 2/32 - 240.4ms/batch - loss: 23.06593 - diff: 15.13mlTrain batch 3/32 - 238.0ms/batch - loss: 27.39277 - diff: 16.11mlTrain batch 4/32 - 240.3ms/batch - loss: 26.81875 - diff: 16.02mlTrain batch 5/32 - 237.4ms/batch - loss: 25.75991 - diff: 15.90mlTrain batch 6/32 - 240.5ms/batch - loss: 23.09937 - diff: 14.84mlTrain batch 7/32 - 237.5ms/batch - loss: 27.28233 - diff: 15.17mlTrain batch 8/32 - 240.1ms/batch - loss: 27.59232 - diff: 15.68mlTrain batch 9/32 - 238.1ms/batch - loss: 27.54157 - diff: 15.77mlTrain batch 10/32 - 240.4ms/batch - loss: 26.71899 - diff: 15.62mlTrain batch 11/32 - 238.0ms/batch - loss: 27.19925 - diff: 15.92mlTrain batch 12/32 - 240.2ms/batch - loss: 32.24834 - diff: 17.00mlTrain batch 13/32 - 237.5ms/batch - loss: 32.86869 - diff: 16.90mlTrain batch 14/32 - 239.2ms/batch - loss: 34.12083 - diff: 17.21mlTrain batch 15/32 - 238.5ms/batch - loss: 33.73118 - diff: 17.22mlTrain batch 16/32 - 239.9ms/batch - loss: 32.78833 - diff: 17.11mlTrain batch 17/32 - 240.0ms/batch - loss: 33.96721 - diff: 17.33mlTrain batch 18/32 - 240.4ms/batch - loss: 36.32471 - diff: 17.86mlTrain batch 19/32 - 238.1ms/batch - loss: 35.68974 - diff: 17.69mlTrain batch 20/32 - 239.5ms/batch - loss: 35.32864 - diff: 17.64mlTrain batch 21/32 - 237.7ms/batch - loss: 36.31699 - diff: 17.90mlTrain batch 22/32 - 240.0ms/batch - loss: 46.25434 - diff: 18.73mlTrain batch 23/32 - 238.1ms/batch - loss: 47.33252 - diff: 18.89mlTrain batch 24/32 - 240.2ms/batch - loss: 47.29739 - diff: 19.04mlTrain batch 25/32 - 238.2ms/batch - loss: 48.11045 - diff: 19.29mlTrain batch 26/32 - 240.2ms/batch - loss: 47.70551 - diff: 19.40mlTrain batch 27/32 - 237.2ms/batch - loss: 47.58601 - diff: 19.34mlTrain batch 28/32 - 240.4ms/batch - loss: 47.50828 - diff: 19.40mlTrain batch 29/32 - 237.5ms/batch - loss: 46.35679 - diff: 19.09mlTrain batch 30/32 - 240.1ms/batch - loss: 46.58634 - diff: 19.08mlTrain batch 31/32 - 237.4ms/batch - loss: 47.87380 - diff: 19.41mlTrain batch 32/32 - 77.9ms/batch - loss: 48.62372 - diff: 19.43mlTrain batch 32/32 - 10.6s 77.9ms/batch - loss: 48.62372 - diff: 19.43ml
Test 1.1s: val_loss: 74.32173 - diff: 23.09ml
Epoch   102: reducing learning rate of group 0 to 5.0000e-04.

Epoch 102: current best loss = 43.62158, at epoch 90
Train batch 1/32 - 236.8ms/batch - loss: 28.52808 - diff: 16.99mlTrain batch 2/32 - 239.1ms/batch - loss: 34.07268 - diff: 18.24mlTrain batch 3/32 - 238.0ms/batch - loss: 38.00114 - diff: 18.76mlTrain batch 4/32 - 240.2ms/batch - loss: 36.03010 - diff: 18.73mlTrain batch 5/32 - 238.0ms/batch - loss: 36.05619 - diff: 18.61mlTrain batch 6/32 - 239.9ms/batch - loss: 33.09142 - diff: 17.69mlTrain batch 7/32 - 238.5ms/batch - loss: 58.50032 - diff: 20.32mlTrain batch 8/32 - 239.3ms/batch - loss: 54.43811 - diff: 20.02mlTrain batch 9/32 - 238.4ms/batch - loss: 53.98218 - diff: 19.87mlTrain batch 10/32 - 239.4ms/batch - loss: 51.15339 - diff: 19.55mlTrain batch 11/32 - 237.9ms/batch - loss: 49.43876 - diff: 19.41mlTrain batch 12/32 - 239.3ms/batch - loss: 46.52571 - diff: 18.75mlTrain batch 13/32 - 237.5ms/batch - loss: 44.26320 - diff: 18.40mlTrain batch 14/32 - 240.3ms/batch - loss: 42.09127 - diff: 17.92mlTrain batch 15/32 - 237.2ms/batch - loss: 43.86334 - diff: 18.43mlTrain batch 16/32 - 240.6ms/batch - loss: 43.91276 - diff: 18.36mlTrain batch 17/32 - 237.4ms/batch - loss: 42.20584 - diff: 17.98mlTrain batch 18/32 - 240.4ms/batch - loss: 40.79015 - diff: 17.75mlTrain batch 19/32 - 237.6ms/batch - loss: 40.69148 - diff: 17.78mlTrain batch 20/32 - 240.2ms/batch - loss: 40.75988 - diff: 17.84mlTrain batch 21/32 - 237.6ms/batch - loss: 40.77356 - diff: 17.89mlTrain batch 22/32 - 240.5ms/batch - loss: 41.06217 - diff: 18.16mlTrain batch 23/32 - 237.9ms/batch - loss: 40.48238 - diff: 18.11mlTrain batch 24/32 - 240.4ms/batch - loss: 39.47291 - diff: 17.89mlTrain batch 25/32 - 238.2ms/batch - loss: 38.91067 - diff: 17.80mlTrain batch 26/32 - 240.4ms/batch - loss: 38.71712 - diff: 17.79mlTrain batch 27/32 - 237.7ms/batch - loss: 39.40752 - diff: 17.81mlTrain batch 28/32 - 239.6ms/batch - loss: 40.30723 - diff: 17.90mlTrain batch 29/32 - 237.5ms/batch - loss: 39.99303 - diff: 17.83mlTrain batch 30/32 - 239.6ms/batch - loss: 39.12999 - diff: 17.62mlTrain batch 31/32 - 238.4ms/batch - loss: 41.65936 - diff: 17.73mlTrain batch 32/32 - 77.8ms/batch - loss: 41.83883 - diff: 17.69mlTrain batch 32/32 - 10.6s 77.8ms/batch - loss: 41.83883 - diff: 17.69ml
Test 1.1s: val_loss: 43.67753 - diff: 18.14ml

Epoch 103: current best loss = 43.62158, at epoch 90
Train batch 1/32 - 238.2ms/batch - loss: 157.37216 - diff: 22.33mlTrain batch 2/32 - 239.7ms/batch - loss: 101.30162 - diff: 21.15mlTrain batch 3/32 - 238.5ms/batch - loss: 73.53179 - diff: 18.21mlTrain batch 4/32 - 239.2ms/batch - loss: 65.89360 - diff: 18.98mlTrain batch 5/32 - 237.7ms/batch - loss: 59.10831 - diff: 18.54mlTrain batch 6/32 - 240.2ms/batch - loss: 53.34309 - diff: 18.24mlTrain batch 7/32 - 238.4ms/batch - loss: 49.73386 - diff: 17.69mlTrain batch 8/32 - 240.3ms/batch - loss: 49.84248 - diff: 18.13mlTrain batch 9/32 - 237.2ms/batch - loss: 52.80659 - diff: 18.73mlTrain batch 10/32 - 240.3ms/batch - loss: 51.27898 - diff: 18.57mlTrain batch 11/32 - 237.4ms/batch - loss: 49.03434 - diff: 18.41mlTrain batch 12/32 - 240.6ms/batch - loss: 49.17065 - diff: 18.95mlTrain batch 13/32 - 237.5ms/batch - loss: 47.24445 - diff: 18.66mlTrain batch 14/32 - 240.0ms/batch - loss: 46.69172 - diff: 18.65mlTrain batch 15/32 - 237.5ms/batch - loss: 45.07526 - diff: 18.39mlTrain batch 16/32 - 239.9ms/batch - loss: 44.01252 - diff: 18.34mlTrain batch 17/32 - 238.1ms/batch - loss: 43.54504 - diff: 18.32mlTrain batch 18/32 - 240.3ms/batch - loss: 45.08914 - diff: 18.75mlTrain batch 19/32 - 237.7ms/batch - loss: 44.44133 - diff: 18.70mlTrain batch 20/32 - 239.5ms/batch - loss: 45.72860 - diff: 19.05mlTrain batch 21/32 - 238.6ms/batch - loss: 46.90596 - diff: 19.02mlTrain batch 22/32 - 240.0ms/batch - loss: 46.06320 - diff: 18.95mlTrain batch 23/32 - 237.5ms/batch - loss: 45.55166 - diff: 18.85mlTrain batch 24/32 - 240.4ms/batch - loss: 45.17697 - diff: 18.85mlTrain batch 25/32 - 237.3ms/batch - loss: 44.55207 - diff: 18.90mlTrain batch 26/32 - 239.9ms/batch - loss: 44.79464 - diff: 18.98mlTrain batch 27/32 - 238.2ms/batch - loss: 43.88687 - diff: 18.80mlTrain batch 28/32 - 240.1ms/batch - loss: 43.80480 - diff: 18.71mlTrain batch 29/32 - 237.1ms/batch - loss: 43.22571 - diff: 18.66mlTrain batch 30/32 - 240.3ms/batch - loss: 42.44268 - diff: 18.53mlTrain batch 31/32 - 237.6ms/batch - loss: 42.12762 - diff: 18.53mlTrain batch 32/32 - 78.6ms/batch - loss: 42.04300 - diff: 18.46mlTrain batch 32/32 - 10.6s 78.6ms/batch - loss: 42.04300 - diff: 18.46ml
Test 1.1s: val_loss: 50.77876 - diff: 18.78ml

Epoch 104: current best loss = 43.62158, at epoch 90
Train batch 1/32 - 236.9ms/batch - loss: 31.68383 - diff: 15.52mlTrain batch 2/32 - 240.3ms/batch - loss: 24.54577 - diff: 14.11mlTrain batch 3/32 - 237.4ms/batch - loss: 74.84429 - diff: 19.29mlTrain batch 4/32 - 240.2ms/batch - loss: 64.92086 - diff: 19.16mlTrain batch 5/32 - 237.4ms/batch - loss: 55.29651 - diff: 18.32mlTrain batch 6/32 - 240.0ms/batch - loss: 52.00459 - diff: 18.56mlTrain batch 7/32 - 238.2ms/batch - loss: 46.03825 - diff: 17.29mlTrain batch 8/32 - 240.4ms/batch - loss: 43.68534 - diff: 17.37mlTrain batch 9/32 - 238.1ms/batch - loss: 40.86080 - diff: 16.84mlTrain batch 10/32 - 239.9ms/batch - loss: 39.15089 - diff: 16.67mlTrain batch 11/32 - 238.3ms/batch - loss: 39.50106 - diff: 17.04mlTrain batch 12/32 - 240.1ms/batch - loss: 40.93733 - diff: 17.63mlTrain batch 13/32 - 238.8ms/batch - loss: 40.60410 - diff: 17.78mlTrain batch 14/32 - 239.9ms/batch - loss: 41.70889 - diff: 18.22mlTrain batch 15/32 - 238.5ms/batch - loss: 41.44282 - diff: 18.12mlTrain batch 16/32 - 238.8ms/batch - loss: 41.36539 - diff: 18.23mlTrain batch 17/32 - 237.7ms/batch - loss: 40.17574 - diff: 18.06mlTrain batch 18/32 - 240.1ms/batch - loss: 40.94448 - diff: 18.05mlTrain batch 19/32 - 239.9ms/batch - loss: 41.10950 - diff: 18.15mlTrain batch 20/32 - 240.2ms/batch - loss: 42.78063 - diff: 18.46mlTrain batch 21/32 - 246.8ms/batch - loss: 42.26635 - diff: 18.29mlTrain batch 22/32 - 238.0ms/batch - loss: 40.97960 - diff: 17.94mlTrain batch 23/32 - 237.6ms/batch - loss: 41.59233 - diff: 18.05mlTrain batch 24/32 - 240.6ms/batch - loss: 42.51508 - diff: 18.24mlTrain batch 25/32 - 237.2ms/batch - loss: 41.49171 - diff: 18.00mlTrain batch 26/32 - 240.0ms/batch - loss: 41.63444 - diff: 18.05mlTrain batch 27/32 - 238.1ms/batch - loss: 40.99833 - diff: 17.94mlTrain batch 28/32 - 240.5ms/batch - loss: 40.74859 - diff: 17.98mlTrain batch 29/32 - 237.8ms/batch - loss: 41.45288 - diff: 18.19mlTrain batch 30/32 - 239.8ms/batch - loss: 40.96063 - diff: 18.16mlTrain batch 31/32 - 238.6ms/batch - loss: 39.96734 - diff: 17.90mlTrain batch 32/32 - 78.1ms/batch - loss: 40.01529 - diff: 17.84mlTrain batch 32/32 - 10.7s 78.1ms/batch - loss: 40.01529 - diff: 17.84ml
Test 1.2s: val_loss: 42.13852 - diff: 18.05ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Systole_WideResNet50_0_Adam-0.001_MSE_DA3_best

Epoch 105: current best loss = 42.13852, at epoch 104
Train batch 1/32 - 237.1ms/batch - loss: 26.75506 - diff: 17.65mlTrain batch 2/32 - 237.5ms/batch - loss: 33.78623 - diff: 19.11mlTrain batch 3/32 - 238.4ms/batch - loss: 29.22225 - diff: 17.71mlTrain batch 4/32 - 238.9ms/batch - loss: 31.82878 - diff: 18.25mlTrain batch 5/32 - 238.3ms/batch - loss: 30.20056 - diff: 17.94mlTrain batch 6/32 - 239.0ms/batch - loss: 30.23407 - diff: 17.79mlTrain batch 7/32 - 236.8ms/batch - loss: 29.00507 - diff: 17.06mlTrain batch 8/32 - 238.2ms/batch - loss: 32.77543 - diff: 17.94mlTrain batch 9/32 - 237.5ms/batch - loss: 31.04607 - diff: 17.46mlTrain batch 10/32 - 240.2ms/batch - loss: 30.10227 - diff: 17.12mlTrain batch 11/32 - 238.2ms/batch - loss: 29.40749 - diff: 16.89mlTrain batch 12/32 - 240.1ms/batch - loss: 30.92005 - diff: 16.86mlTrain batch 13/32 - 237.4ms/batch - loss: 30.76967 - diff: 17.00mlTrain batch 14/32 - 240.4ms/batch - loss: 30.81389 - diff: 17.06mlTrain batch 15/32 - 237.3ms/batch - loss: 47.03823 - diff: 18.47mlTrain batch 16/32 - 240.0ms/batch - loss: 46.11113 - diff: 18.35mlTrain batch 17/32 - 237.9ms/batch - loss: 44.93028 - diff: 18.19mlTrain batch 18/32 - 240.3ms/batch - loss: 51.54533 - diff: 18.82mlTrain batch 19/32 - 238.1ms/batch - loss: 49.72779 - diff: 18.57mlTrain batch 20/32 - 240.3ms/batch - loss: 49.09974 - diff: 18.65mlTrain batch 21/32 - 237.5ms/batch - loss: 49.33569 - diff: 18.80mlTrain batch 22/32 - 239.4ms/batch - loss: 48.12685 - diff: 18.65mlTrain batch 23/32 - 238.2ms/batch - loss: 46.92671 - diff: 18.41mlTrain batch 24/32 - 239.2ms/batch - loss: 46.32323 - diff: 18.35mlTrain batch 25/32 - 237.8ms/batch - loss: 46.40038 - diff: 18.54mlTrain batch 26/32 - 239.1ms/batch - loss: 45.69487 - diff: 18.50mlTrain batch 27/32 - 237.3ms/batch - loss: 45.22870 - diff: 18.41mlTrain batch 28/32 - 238.7ms/batch - loss: 44.66032 - diff: 18.32mlTrain batch 29/32 - 237.2ms/batch - loss: 43.81945 - diff: 18.14mlTrain batch 30/32 - 240.4ms/batch - loss: 43.48899 - diff: 18.11mlTrain batch 31/32 - 237.8ms/batch - loss: 43.74593 - diff: 18.22mlTrain batch 32/32 - 77.6ms/batch - loss: 43.67098 - diff: 18.15mlTrain batch 32/32 - 10.6s 77.6ms/batch - loss: 43.67098 - diff: 18.15ml
Test 1.1s: val_loss: 51.53162 - diff: 18.81ml

Epoch 106: current best loss = 42.13852, at epoch 104
Train batch 1/32 - 236.9ms/batch - loss: 30.70202 - diff: 17.63mlTrain batch 2/32 - 237.6ms/batch - loss: 28.77078 - diff: 16.06mlTrain batch 3/32 - 237.7ms/batch - loss: 31.27381 - diff: 17.39mlTrain batch 4/32 - 240.0ms/batch - loss: 28.33138 - diff: 16.64mlTrain batch 5/32 - 237.4ms/batch - loss: 30.27368 - diff: 16.97mlTrain batch 6/32 - 239.7ms/batch - loss: 30.19042 - diff: 17.10mlTrain batch 7/32 - 238.2ms/batch - loss: 31.86156 - diff: 17.54mlTrain batch 8/32 - 240.4ms/batch - loss: 32.24201 - diff: 17.90mlTrain batch 9/32 - 237.5ms/batch - loss: 31.65907 - diff: 17.63mlTrain batch 10/32 - 239.1ms/batch - loss: 31.59747 - diff: 17.40mlTrain batch 11/32 - 240.8ms/batch - loss: 34.24655 - diff: 17.72mlTrain batch 12/32 - 240.5ms/batch - loss: 34.22356 - diff: 17.60mlTrain batch 13/32 - 237.2ms/batch - loss: 35.88184 - diff: 17.99mlTrain batch 14/32 - 237.4ms/batch - loss: 34.76607 - diff: 17.73mlTrain batch 15/32 - 237.1ms/batch - loss: 35.49209 - diff: 18.07mlTrain batch 16/32 - 240.5ms/batch - loss: 43.79547 - diff: 19.00mlTrain batch 17/32 - 237.2ms/batch - loss: 42.65581 - diff: 18.69mlTrain batch 18/32 - 240.6ms/batch - loss: 41.43196 - diff: 18.46mlTrain batch 19/32 - 237.2ms/batch - loss: 40.00494 - diff: 18.04mlTrain batch 20/32 - 240.1ms/batch - loss: 38.43119 - diff: 17.65mlTrain batch 21/32 - 243.7ms/batch - loss: 37.17666 - diff: 17.31mlTrain batch 22/32 - 238.8ms/batch - loss: 36.05229 - diff: 17.03mlTrain batch 23/32 - 237.4ms/batch - loss: 35.34003 - diff: 16.82mlTrain batch 24/32 - 239.2ms/batch - loss: 35.12932 - diff: 16.75mlTrain batch 25/32 - 238.4ms/batch - loss: 38.29585 - diff: 17.23mlTrain batch 26/32 - 240.0ms/batch - loss: 38.18477 - diff: 17.36mlTrain batch 27/32 - 237.1ms/batch - loss: 37.96059 - diff: 17.46mlTrain batch 28/32 - 237.6ms/batch - loss: 38.00649 - diff: 17.61mlTrain batch 29/32 - 237.5ms/batch - loss: 38.06853 - diff: 17.66mlTrain batch 30/32 - 239.8ms/batch - loss: 38.37697 - diff: 17.76mlTrain batch 31/32 - 238.0ms/batch - loss: 38.39767 - diff: 17.80mlTrain batch 32/32 - 78.0ms/batch - loss: 39.52452 - diff: 17.81mlTrain batch 32/32 - 10.7s 78.0ms/batch - loss: 39.52452 - diff: 17.81ml
Test 1.2s: val_loss: 44.47874 - diff: 18.33ml

Epoch 107: current best loss = 42.13852, at epoch 104
Train batch 1/32 - 237.0ms/batch - loss: 36.37851 - diff: 17.05mlTrain batch 2/32 - 240.4ms/batch - loss: 33.29049 - diff: 17.40mlTrain batch 3/32 - 236.9ms/batch - loss: 39.88533 - diff: 19.77mlTrain batch 4/32 - 238.8ms/batch - loss: 42.20947 - diff: 19.55mlTrain batch 5/32 - 237.8ms/batch - loss: 38.98994 - diff: 18.82mlTrain batch 6/32 - 240.3ms/batch - loss: 37.67367 - diff: 18.73mlTrain batch 7/32 - 237.4ms/batch - loss: 37.44551 - diff: 18.80mlTrain batch 8/32 - 239.2ms/batch - loss: 35.25164 - diff: 18.12mlTrain batch 9/32 - 237.3ms/batch - loss: 35.98718 - diff: 18.28mlTrain batch 10/32 - 239.1ms/batch - loss: 47.35739 - diff: 18.84mlTrain batch 11/32 - 238.2ms/batch - loss: 44.11993 - diff: 18.18mlTrain batch 12/32 - 239.9ms/batch - loss: 44.40857 - diff: 18.34mlTrain batch 13/32 - 238.7ms/batch - loss: 43.34079 - diff: 18.40mlTrain batch 14/32 - 240.0ms/batch - loss: 41.70838 - diff: 18.12mlTrain batch 15/32 - 238.4ms/batch - loss: 40.69572 - diff: 18.03mlTrain batch 16/32 - 239.1ms/batch - loss: 40.83765 - diff: 18.21mlTrain batch 17/32 - 237.6ms/batch - loss: 39.89708 - diff: 18.05mlTrain batch 18/32 - 239.8ms/batch - loss: 39.85323 - diff: 18.24mlTrain batch 19/32 - 237.1ms/batch - loss: 38.91607 - diff: 18.07mlTrain batch 20/32 - 239.9ms/batch - loss: 37.46535 - diff: 17.62mlTrain batch 21/32 - 238.4ms/batch - loss: 36.44189 - diff: 17.33mlTrain batch 22/32 - 240.4ms/batch - loss: 36.01071 - diff: 17.20mlTrain batch 23/32 - 238.1ms/batch - loss: 34.79777 - diff: 16.86mlTrain batch 24/32 - 240.6ms/batch - loss: 34.10242 - diff: 16.77mlTrain batch 25/32 - 237.3ms/batch - loss: 37.18934 - diff: 17.18mlTrain batch 26/32 - 240.6ms/batch - loss: 36.69312 - diff: 17.12mlTrain batch 27/32 - 237.5ms/batch - loss: 35.92479 - diff: 16.91mlTrain batch 28/32 - 240.6ms/batch - loss: 36.57729 - diff: 17.00mlTrain batch 29/32 - 237.6ms/batch - loss: 36.48196 - diff: 17.05mlTrain batch 30/32 - 239.9ms/batch - loss: 36.82160 - diff: 17.18mlTrain batch 31/32 - 237.4ms/batch - loss: 36.07199 - diff: 17.00mlTrain batch 32/32 - 78.5ms/batch - loss: 38.84954 - diff: 17.16mlTrain batch 32/32 - 10.6s 78.5ms/batch - loss: 38.84954 - diff: 17.16ml
Test 1.1s: val_loss: 47.09016 - diff: 18.27ml

Epoch 108: current best loss = 42.13852, at epoch 104
Train batch 1/32 - 237.4ms/batch - loss: 39.13793 - diff: 19.11mlTrain batch 2/32 - 239.9ms/batch - loss: 29.68012 - diff: 15.71mlTrain batch 3/32 - 237.2ms/batch - loss: 49.61651 - diff: 17.85mlTrain batch 4/32 - 239.1ms/batch - loss: 48.49476 - diff: 18.12mlTrain batch 5/32 - 237.6ms/batch - loss: 40.89403 - diff: 16.39mlTrain batch 6/32 - 238.7ms/batch - loss: 37.65245 - diff: 16.10mlTrain batch 7/32 - 238.3ms/batch - loss: 36.73552 - diff: 16.35mlTrain batch 8/32 - 239.3ms/batch - loss: 34.80618 - diff: 16.07mlTrain batch 9/32 - 237.1ms/batch - loss: 34.28282 - diff: 15.90mlTrain batch 10/32 - 239.1ms/batch - loss: 33.51439 - diff: 15.89mlTrain batch 11/32 - 237.4ms/batch - loss: 35.47758 - diff: 16.54mlTrain batch 12/32 - 239.5ms/batch - loss: 39.22259 - diff: 17.44mlTrain batch 13/32 - 238.2ms/batch - loss: 37.93755 - diff: 17.33mlTrain batch 14/32 - 240.3ms/batch - loss: 38.37984 - diff: 17.45mlTrain batch 15/32 - 238.0ms/batch - loss: 38.09888 - diff: 17.37mlTrain batch 16/32 - 240.4ms/batch - loss: 36.74220 - diff: 17.05mlTrain batch 17/32 - 237.5ms/batch - loss: 37.69822 - diff: 17.10mlTrain batch 18/32 - 240.5ms/batch - loss: 37.26383 - diff: 17.18mlTrain batch 19/32 - 237.5ms/batch - loss: 37.44840 - diff: 17.37mlTrain batch 20/32 - 240.5ms/batch - loss: 36.35417 - diff: 17.14mlTrain batch 21/32 - 237.5ms/batch - loss: 37.54204 - diff: 17.41mlTrain batch 22/32 - 239.7ms/batch - loss: 36.80823 - diff: 17.24mlTrain batch 23/32 - 238.1ms/batch - loss: 36.49155 - diff: 17.24mlTrain batch 24/32 - 240.3ms/batch - loss: 35.35345 - diff: 16.92mlTrain batch 25/32 - 238.1ms/batch - loss: 35.88333 - diff: 17.14mlTrain batch 26/32 - 240.1ms/batch - loss: 35.65892 - diff: 17.11mlTrain batch 27/32 - 237.5ms/batch - loss: 36.68104 - diff: 17.37mlTrain batch 28/32 - 239.7ms/batch - loss: 37.21460 - diff: 17.52mlTrain batch 29/32 - 238.5ms/batch - loss: 37.58400 - diff: 17.69mlTrain batch 30/32 - 240.2ms/batch - loss: 37.40417 - diff: 17.68mlTrain batch 31/32 - 237.7ms/batch - loss: 36.99385 - diff: 17.63mlTrain batch 32/32 - 76.7ms/batch - loss: 37.97518 - diff: 17.66mlTrain batch 32/32 - 10.6s 76.7ms/batch - loss: 37.97518 - diff: 17.66ml
Test 1.1s: val_loss: 41.86942 - diff: 17.48ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Systole_WideResNet50_0_Adam-0.001_MSE_DA3_best

Epoch 109: current best loss = 41.86942, at epoch 108
Train batch 1/32 - 237.4ms/batch - loss: 47.51101 - diff: 22.48mlTrain batch 2/32 - 240.1ms/batch - loss: 34.23773 - diff: 18.64mlTrain batch 3/32 - 237.7ms/batch - loss: 32.33991 - diff: 17.81mlTrain batch 4/32 - 240.3ms/batch - loss: 29.64921 - diff: 17.28mlTrain batch 5/32 - 237.5ms/batch - loss: 33.02517 - diff: 17.66mlTrain batch 6/32 - 239.1ms/batch - loss: 31.05460 - diff: 17.14mlTrain batch 7/32 - 237.5ms/batch - loss: 28.31054 - diff: 16.20mlTrain batch 8/32 - 239.4ms/batch - loss: 27.48503 - diff: 16.01mlTrain batch 9/32 - 238.4ms/batch - loss: 27.93612 - diff: 15.73mlTrain batch 10/32 - 240.0ms/batch - loss: 27.43175 - diff: 15.48mlTrain batch 11/32 - 238.8ms/batch - loss: 26.14491 - diff: 15.03mlTrain batch 12/32 - 239.3ms/batch - loss: 25.64356 - diff: 15.09mlTrain batch 13/32 - 238.2ms/batch - loss: 27.91995 - diff: 15.56mlTrain batch 14/32 - 239.1ms/batch - loss: 28.35204 - diff: 15.48mlTrain batch 15/32 - 237.3ms/batch - loss: 27.99769 - diff: 15.48mlTrain batch 16/32 - 239.9ms/batch - loss: 29.69976 - diff: 16.17mlTrain batch 17/32 - 237.6ms/batch - loss: 30.89166 - diff: 16.32mlTrain batch 18/32 - 239.9ms/batch - loss: 31.41233 - diff: 16.33mlTrain batch 19/32 - 238.4ms/batch - loss: 40.55863 - diff: 17.07mlTrain batch 20/32 - 240.2ms/batch - loss: 40.40067 - diff: 16.94mlTrain batch 21/32 - 237.2ms/batch - loss: 39.95418 - diff: 16.95mlTrain batch 22/32 - 240.3ms/batch - loss: 39.87987 - diff: 16.99mlTrain batch 23/32 - 237.5ms/batch - loss: 40.16692 - diff: 17.07mlTrain batch 24/32 - 240.3ms/batch - loss: 39.48551 - diff: 17.04mlTrain batch 25/32 - 237.6ms/batch - loss: 38.97630 - diff: 17.06mlTrain batch 26/32 - 240.3ms/batch - loss: 40.43306 - diff: 17.40mlTrain batch 27/32 - 237.7ms/batch - loss: 40.82368 - diff: 17.50mlTrain batch 28/32 - 240.4ms/batch - loss: 40.88714 - diff: 17.67mlTrain batch 29/32 - 237.4ms/batch - loss: 40.48759 - diff: 17.54mlTrain batch 30/32 - 239.4ms/batch - loss: 40.07053 - diff: 17.47mlTrain batch 31/32 - 238.1ms/batch - loss: 39.78696 - diff: 17.52mlTrain batch 32/32 - 77.4ms/batch - loss: 39.80989 - diff: 17.47mlTrain batch 32/32 - 10.6s 77.4ms/batch - loss: 39.80989 - diff: 17.47ml
Test 1.1s: val_loss: 60.88163 - diff: 23.00ml

Epoch 110: current best loss = 41.86942, at epoch 108
Train batch 1/32 - 237.2ms/batch - loss: 40.54645 - diff: 21.50mlTrain batch 2/32 - 238.7ms/batch - loss: 33.64561 - diff: 19.27mlTrain batch 3/32 - 237.2ms/batch - loss: 30.98422 - diff: 17.95mlTrain batch 4/32 - 240.1ms/batch - loss: 34.59679 - diff: 18.93mlTrain batch 5/32 - 238.3ms/batch - loss: 38.06485 - diff: 19.34mlTrain batch 6/32 - 240.3ms/batch - loss: 37.26623 - diff: 19.47mlTrain batch 7/32 - 238.1ms/batch - loss: 39.69469 - diff: 19.94mlTrain batch 8/32 - 240.3ms/batch - loss: 39.55107 - diff: 19.83mlTrain batch 9/32 - 237.4ms/batch - loss: 37.09021 - diff: 19.23mlTrain batch 10/32 - 240.4ms/batch - loss: 35.61352 - diff: 19.01mlTrain batch 11/32 - 237.6ms/batch - loss: 34.84540 - diff: 18.65mlTrain batch 12/32 - 240.6ms/batch - loss: 33.45467 - diff: 18.22mlTrain batch 13/32 - 237.9ms/batch - loss: 34.45813 - diff: 18.23mlTrain batch 14/32 - 240.3ms/batch - loss: 32.96280 - diff: 17.66mlTrain batch 15/32 - 237.9ms/batch - loss: 33.02261 - diff: 17.58mlTrain batch 16/32 - 240.2ms/batch - loss: 32.10851 - diff: 17.28mlTrain batch 17/32 - 237.2ms/batch - loss: 44.29771 - diff: 18.34mlTrain batch 18/32 - 239.5ms/batch - loss: 43.60413 - diff: 18.30mlTrain batch 19/32 - 238.8ms/batch - loss: 42.60834 - diff: 18.15mlTrain batch 20/32 - 240.2ms/batch - loss: 44.58702 - diff: 18.44mlTrain batch 21/32 - 238.3ms/batch - loss: 46.51292 - diff: 18.90mlTrain batch 22/32 - 238.9ms/batch - loss: 46.82694 - diff: 19.08mlTrain batch 23/32 - 237.4ms/batch - loss: 46.09069 - diff: 18.95mlTrain batch 24/32 - 240.2ms/batch - loss: 47.30520 - diff: 19.15mlTrain batch 25/32 - 238.1ms/batch - loss: 46.18475 - diff: 18.99mlTrain batch 26/32 - 240.3ms/batch - loss: 45.50828 - diff: 18.95mlTrain batch 27/32 - 237.4ms/batch - loss: 46.33790 - diff: 19.18mlTrain batch 28/32 - 240.1ms/batch - loss: 45.89120 - diff: 19.22mlTrain batch 29/32 - 237.3ms/batch - loss: 45.36900 - diff: 19.23mlTrain batch 30/32 - 240.0ms/batch - loss: 45.07247 - diff: 19.27mlTrain batch 31/32 - 238.0ms/batch - loss: 47.49766 - diff: 19.43mlTrain batch 32/32 - 78.2ms/batch - loss: 48.18216 - diff: 19.41mlTrain batch 32/32 - 10.7s 78.2ms/batch - loss: 48.18216 - diff: 19.41ml
Test 1.2s: val_loss: 241.94170 - diff: 43.20ml

Epoch 111: current best loss = 41.86942, at epoch 108
Train batch 1/32 - 237.2ms/batch - loss: 48.41481 - diff: 22.37mlTrain batch 2/32 - 238.9ms/batch - loss: 35.39629 - diff: 18.73mlTrain batch 3/32 - 238.2ms/batch - loss: 35.31565 - diff: 18.57mlTrain batch 4/32 - 240.0ms/batch - loss: 30.15161 - diff: 17.40mlTrain batch 5/32 - 237.1ms/batch - loss: 29.77289 - diff: 17.60mlTrain batch 6/32 - 238.9ms/batch - loss: 28.47518 - diff: 17.29mlTrain batch 7/32 - 237.1ms/batch - loss: 30.04705 - diff: 17.68mlTrain batch 8/32 - 240.1ms/batch - loss: 30.79597 - diff: 17.70mlTrain batch 9/32 - 238.2ms/batch - loss: 28.67728 - diff: 16.88mlTrain batch 10/32 - 240.1ms/batch - loss: 28.63385 - diff: 16.73mlTrain batch 11/32 - 237.1ms/batch - loss: 34.56769 - diff: 17.33mlTrain batch 12/32 - 240.4ms/batch - loss: 32.88650 - diff: 16.91mlTrain batch 13/32 - 237.1ms/batch - loss: 33.71712 - diff: 17.11mlTrain batch 14/32 - 239.9ms/batch - loss: 35.20832 - diff: 17.39mlTrain batch 15/32 - 238.2ms/batch - loss: 34.68305 - diff: 17.29mlTrain batch 16/32 - 240.4ms/batch - loss: 34.07743 - diff: 17.23mlTrain batch 17/32 - 237.5ms/batch - loss: 33.35210 - diff: 17.04mlTrain batch 18/32 - 240.0ms/batch - loss: 33.42341 - diff: 17.22mlTrain batch 19/32 - 238.2ms/batch - loss: 32.83421 - diff: 17.14mlTrain batch 20/32 - 240.0ms/batch - loss: 32.37919 - diff: 16.92mlTrain batch 21/32 - 238.5ms/batch - loss: 33.29196 - diff: 16.97mlTrain batch 22/32 - 239.7ms/batch - loss: 33.67350 - diff: 16.96mlTrain batch 23/32 - 237.5ms/batch - loss: 33.91636 - diff: 17.02mlTrain batch 24/32 - 239.0ms/batch - loss: 34.26124 - diff: 17.13mlTrain batch 25/32 - 237.4ms/batch - loss: 33.56455 - diff: 16.99mlTrain batch 26/32 - 240.0ms/batch - loss: 33.75635 - diff: 17.07mlTrain batch 27/32 - 238.4ms/batch - loss: 34.12729 - diff: 17.22mlTrain batch 28/32 - 240.1ms/batch - loss: 34.20788 - diff: 17.27mlTrain batch 29/32 - 237.5ms/batch - loss: 34.74679 - diff: 17.48mlTrain batch 30/32 - 240.4ms/batch - loss: 34.16189 - diff: 17.36mlTrain batch 31/32 - 237.4ms/batch - loss: 33.80269 - diff: 17.24mlTrain batch 32/32 - 78.9ms/batch - loss: 34.17461 - diff: 17.22mlTrain batch 32/32 - 10.6s 78.9ms/batch - loss: 34.17461 - diff: 17.22ml
Test 1.2s: val_loss: 47.26913 - diff: 19.03ml

Epoch 112: current best loss = 41.86942, at epoch 108
Train batch 1/32 - 237.4ms/batch - loss: 35.62952 - diff: 18.75mlTrain batch 2/32 - 239.4ms/batch - loss: 32.87758 - diff: 19.05mlTrain batch 3/32 - 237.2ms/batch - loss: 41.43103 - diff: 20.30mlTrain batch 4/32 - 239.8ms/batch - loss: 45.29899 - diff: 21.14mlTrain batch 5/32 - 237.7ms/batch - loss: 51.77185 - diff: 20.99mlTrain batch 6/32 - 239.8ms/batch - loss: 48.51484 - diff: 20.77mlTrain batch 7/32 - 237.9ms/batch - loss: 45.34352 - diff: 20.23mlTrain batch 8/32 - 239.8ms/batch - loss: 41.91659 - diff: 19.57mlTrain batch 9/32 - 237.9ms/batch - loss: 39.01581 - diff: 18.80mlTrain batch 10/32 - 239.6ms/batch - loss: 36.94223 - diff: 18.47mlTrain batch 11/32 - 238.5ms/batch - loss: 35.37256 - diff: 17.97mlTrain batch 12/32 - 240.0ms/batch - loss: 34.85145 - diff: 17.86mlTrain batch 13/32 - 238.4ms/batch - loss: 33.18322 - diff: 17.42mlTrain batch 14/32 - 239.2ms/batch - loss: 33.25753 - diff: 17.25mlTrain batch 15/32 - 236.9ms/batch - loss: 32.91126 - diff: 17.21mlTrain batch 16/32 - 240.0ms/batch - loss: 31.92577 - diff: 16.90mlTrain batch 17/32 - 238.0ms/batch - loss: 32.21715 - diff: 17.07mlTrain batch 18/32 - 240.2ms/batch - loss: 31.87166 - diff: 16.99mlTrain batch 19/32 - 238.3ms/batch - loss: 33.59366 - diff: 17.32mlTrain batch 20/32 - 240.0ms/batch - loss: 34.76069 - diff: 17.57mlTrain batch 21/32 - 237.4ms/batch - loss: 33.66374 - diff: 17.26mlTrain batch 22/32 - 240.3ms/batch - loss: 33.57913 - diff: 17.28mlTrain batch 23/32 - 237.2ms/batch - loss: 33.39442 - diff: 17.29mlTrain batch 24/32 - 240.3ms/batch - loss: 33.94392 - diff: 17.49mlTrain batch 25/32 - 238.2ms/batch - loss: 33.33981 - diff: 17.35mlTrain batch 26/32 - 240.4ms/batch - loss: 33.83764 - diff: 17.30mlTrain batch 27/32 - 244.6ms/batch - loss: 33.25868 - diff: 17.13mlTrain batch 28/32 - 238.1ms/batch - loss: 33.58054 - diff: 17.22mlTrain batch 29/32 - 238.0ms/batch - loss: 33.68905 - diff: 17.33mlTrain batch 30/32 - 240.5ms/batch - loss: 33.12162 - diff: 17.14mlTrain batch 31/32 - 237.5ms/batch - loss: 33.53419 - diff: 17.27mlTrain batch 32/32 - 76.6ms/batch - loss: 34.76085 - diff: 17.27mlTrain batch 32/32 - 10.6s 76.6ms/batch - loss: 34.76085 - diff: 17.27ml
Test 1.1s: val_loss: 48.31553 - diff: 19.28ml

Epoch 113: current best loss = 41.86942, at epoch 108
Train batch 1/32 - 237.1ms/batch - loss: 27.88442 - diff: 15.27mlTrain batch 2/32 - 238.6ms/batch - loss: 28.22165 - diff: 16.17mlTrain batch 3/32 - 238.2ms/batch - loss: 30.29599 - diff: 16.72mlTrain batch 4/32 - 240.2ms/batch - loss: 38.73702 - diff: 18.89mlTrain batch 5/32 - 238.7ms/batch - loss: 35.34114 - diff: 18.28mlTrain batch 6/32 - 239.9ms/batch - loss: 31.57749 - diff: 17.03mlTrain batch 7/32 - 238.4ms/batch - loss: 30.58178 - diff: 16.74mlTrain batch 8/32 - 240.2ms/batch - loss: 29.33915 - diff: 16.38mlTrain batch 9/32 - 237.7ms/batch - loss: 30.36784 - diff: 16.55mlTrain batch 10/32 - 240.2ms/batch - loss: 28.81602 - diff: 16.12mlTrain batch 11/32 - 237.2ms/batch - loss: 27.47562 - diff: 15.82mlTrain batch 12/32 - 240.4ms/batch - loss: 26.34792 - diff: 15.49mlTrain batch 13/32 - 237.4ms/batch - loss: 26.24783 - diff: 15.42mlTrain batch 14/32 - 240.7ms/batch - loss: 26.19502 - diff: 15.40mlTrain batch 15/32 - 237.5ms/batch - loss: 26.17229 - diff: 15.47mlTrain batch 16/32 - 239.9ms/batch - loss: 25.63479 - diff: 15.31mlTrain batch 17/32 - 238.0ms/batch - loss: 24.78822 - diff: 15.08mlTrain batch 18/32 - 240.3ms/batch - loss: 24.24504 - diff: 14.96mlTrain batch 19/32 - 237.6ms/batch - loss: 31.85955 - diff: 16.23mlTrain batch 20/32 - 239.5ms/batch - loss: 31.63844 - diff: 16.13mlTrain batch 21/32 - 238.6ms/batch - loss: 30.96898 - diff: 15.95mlTrain batch 22/32 - 240.0ms/batch - loss: 30.83873 - diff: 15.96mlTrain batch 23/32 - 238.8ms/batch - loss: 31.52336 - diff: 15.94mlTrain batch 24/32 - 240.3ms/batch - loss: 32.50626 - diff: 16.17mlTrain batch 25/32 - 237.2ms/batch - loss: 32.20390 - diff: 16.16mlTrain batch 26/32 - 240.1ms/batch - loss: 31.97921 - diff: 16.14mlTrain batch 27/32 - 238.5ms/batch - loss: 31.52615 - diff: 16.09mlTrain batch 28/32 - 240.3ms/batch - loss: 31.71622 - diff: 16.08mlTrain batch 29/32 - 237.3ms/batch - loss: 35.04405 - diff: 16.37mlTrain batch 30/32 - 240.4ms/batch - loss: 35.26818 - diff: 16.40mlTrain batch 31/32 - 237.2ms/batch - loss: 35.44622 - diff: 16.49mlTrain batch 32/32 - 78.3ms/batch - loss: 36.63768 - diff: 16.55mlTrain batch 32/32 - 10.7s 78.3ms/batch - loss: 36.63768 - diff: 16.55ml
Test 1.2s: val_loss: 50.78379 - diff: 19.50ml

Epoch 114: current best loss = 41.86942, at epoch 108
Train batch 1/32 - 237.3ms/batch - loss: 32.29540 - diff: 18.66mlTrain batch 2/32 - 238.9ms/batch - loss: 35.22714 - diff: 19.34mlTrain batch 3/32 - 237.2ms/batch - loss: 41.12529 - diff: 20.28mlTrain batch 4/32 - 239.9ms/batch - loss: 38.12845 - diff: 19.70mlTrain batch 5/32 - 238.1ms/batch - loss: 32.84107 - diff: 18.00mlTrain batch 6/32 - 240.4ms/batch - loss: 34.82547 - diff: 18.43mlTrain batch 7/32 - 238.0ms/batch - loss: 33.64471 - diff: 18.21mlTrain batch 8/32 - 240.5ms/batch - loss: 33.38358 - diff: 18.15mlTrain batch 9/32 - 238.1ms/batch - loss: 30.97054 - diff: 17.45mlTrain batch 10/32 - 240.1ms/batch - loss: 30.58467 - diff: 17.25mlTrain batch 11/32 - 238.7ms/batch - loss: 30.09773 - diff: 17.26mlTrain batch 12/32 - 240.1ms/batch - loss: 30.05933 - diff: 17.26mlTrain batch 13/32 - 237.2ms/batch - loss: 34.29694 - diff: 17.98mlTrain batch 14/32 - 240.4ms/batch - loss: 33.65392 - diff: 17.72mlTrain batch 15/32 - 237.4ms/batch - loss: 33.22273 - diff: 17.53mlTrain batch 16/32 - 240.2ms/batch - loss: 33.90042 - diff: 17.65mlTrain batch 17/32 - 237.4ms/batch - loss: 33.46315 - diff: 17.59mlTrain batch 18/32 - 240.5ms/batch - loss: 44.60118 - diff: 18.81mlTrain batch 19/32 - 237.6ms/batch - loss: 44.66177 - diff: 18.87mlTrain batch 20/32 - 240.4ms/batch - loss: 44.07746 - diff: 18.72mlTrain batch 21/32 - 237.6ms/batch - loss: 42.95169 - diff: 18.53mlTrain batch 22/32 - 240.1ms/batch - loss: 42.34953 - diff: 18.48mlTrain batch 23/32 - 237.8ms/batch - loss: 41.78284 - diff: 18.45mlTrain batch 24/32 - 240.3ms/batch - loss: 41.81250 - diff: 18.51mlTrain batch 25/32 - 238.0ms/batch - loss: 41.39449 - diff: 18.52mlTrain batch 26/32 - 240.4ms/batch - loss: 41.92266 - diff: 18.63mlTrain batch 27/32 - 237.4ms/batch - loss: 42.19437 - diff: 18.68mlTrain batch 28/32 - 239.2ms/batch - loss: 41.42696 - diff: 18.54mlTrain batch 29/32 - 238.2ms/batch - loss: 41.74999 - diff: 18.75mlTrain batch 30/32 - 240.1ms/batch - loss: 41.56017 - diff: 18.73mlTrain batch 31/32 - 238.4ms/batch - loss: 41.14054 - diff: 18.74mlTrain batch 32/32 - 77.8ms/batch - loss: 41.42151 - diff: 18.71mlTrain batch 32/32 - 10.6s 77.8ms/batch - loss: 41.42151 - diff: 18.71ml
Test 1.1s: val_loss: 47.52588 - diff: 20.37ml

Epoch 115: current best loss = 41.86942, at epoch 108
Train batch 1/32 - 237.8ms/batch - loss: 12.00537 - diff: 10.92mlTrain batch 2/32 - 239.3ms/batch - loss: 14.26506 - diff: 12.02mlTrain batch 3/32 - 238.2ms/batch - loss: 16.98693 - diff: 13.33mlTrain batch 4/32 - 239.7ms/batch - loss: 15.52226 - diff: 12.52mlTrain batch 5/32 - 237.4ms/batch - loss: 14.41212 - diff: 12.06mlTrain batch 6/32 - 239.2ms/batch - loss: 17.21088 - diff: 12.89mlTrain batch 7/32 - 237.6ms/batch - loss: 18.80031 - diff: 13.24mlTrain batch 8/32 - 240.1ms/batch - loss: 19.42540 - diff: 13.56mlTrain batch 9/32 - 238.1ms/batch - loss: 19.81579 - diff: 13.76mlTrain batch 10/32 - 240.2ms/batch - loss: 24.23551 - diff: 14.24mlTrain batch 11/32 - 237.3ms/batch - loss: 25.70781 - diff: 14.59mlTrain batch 12/32 - 240.4ms/batch - loss: 24.50777 - diff: 14.22mlTrain batch 13/32 - 237.4ms/batch - loss: 25.09077 - diff: 14.38mlTrain batch 14/32 - 240.5ms/batch - loss: 24.65935 - diff: 14.23mlTrain batch 15/32 - 238.0ms/batch - loss: 24.49522 - diff: 14.17mlTrain batch 16/32 - 240.4ms/batch - loss: 25.60258 - diff: 14.54mlTrain batch 17/32 - 238.0ms/batch - loss: 26.05054 - diff: 14.73mlTrain batch 18/32 - 240.4ms/batch - loss: 27.48803 - diff: 15.10mlTrain batch 19/32 - 237.7ms/batch - loss: 27.32210 - diff: 15.15mlTrain batch 20/32 - 239.7ms/batch - loss: 26.85248 - diff: 15.09mlTrain batch 21/32 - 237.5ms/batch - loss: 26.18093 - diff: 14.87mlTrain batch 22/32 - 239.6ms/batch - loss: 26.96642 - diff: 15.01mlTrain batch 23/32 - 238.3ms/batch - loss: 28.71901 - diff: 15.50mlTrain batch 24/32 - 240.1ms/batch - loss: 28.32649 - diff: 15.43mlTrain batch 25/32 - 238.9ms/batch - loss: 31.12652 - diff: 15.85mlTrain batch 26/32 - 240.2ms/batch - loss: 30.52001 - diff: 15.75mlTrain batch 27/32 - 237.6ms/batch - loss: 30.55554 - diff: 15.84mlTrain batch 28/32 - 239.9ms/batch - loss: 31.50765 - diff: 15.89mlTrain batch 29/32 - 240.2ms/batch - loss: 31.83486 - diff: 15.95mlTrain batch 30/32 - 240.5ms/batch - loss: 32.15460 - diff: 16.14mlTrain batch 31/32 - 237.5ms/batch - loss: 36.26331 - diff: 16.68mlTrain batch 32/32 - 78.5ms/batch - loss: 40.68249 - diff: 16.76mlTrain batch 32/32 - 10.6s 78.5ms/batch - loss: 40.68249 - diff: 16.76ml
Test 1.1s: val_loss: 75.39558 - diff: 23.91ml

Epoch 116: current best loss = 41.86942, at epoch 108
Train batch 1/32 - 237.4ms/batch - loss: 42.70051 - diff: 22.22mlTrain batch 2/32 - 242.4ms/batch - loss: 38.15164 - diff: 20.75mlTrain batch 3/32 - 237.4ms/batch - loss: 43.18715 - diff: 21.11mlTrain batch 4/32 - 240.3ms/batch - loss: 40.07750 - diff: 20.50mlTrain batch 5/32 - 238.1ms/batch - loss: 40.24912 - diff: 20.46mlTrain batch 6/32 - 240.3ms/batch - loss: 39.40522 - diff: 20.34mlTrain batch 7/32 - 237.8ms/batch - loss: 35.26901 - diff: 18.94mlTrain batch 8/32 - 240.0ms/batch - loss: 35.39055 - diff: 18.96mlTrain batch 9/32 - 237.5ms/batch - loss: 37.09621 - diff: 19.41mlTrain batch 10/32 - 239.4ms/batch - loss: 37.19525 - diff: 19.12mlTrain batch 11/32 - 238.4ms/batch - loss: 35.25077 - diff: 18.66mlTrain batch 12/32 - 240.2ms/batch - loss: 37.33101 - diff: 19.08mlTrain batch 13/32 - 238.5ms/batch - loss: 40.34199 - diff: 19.62mlTrain batch 14/32 - 239.0ms/batch - loss: 40.23027 - diff: 19.47mlTrain batch 15/32 - 237.6ms/batch - loss: 40.82546 - diff: 19.59mlTrain batch 16/32 - 239.0ms/batch - loss: 39.37917 - diff: 19.21mlTrain batch 17/32 - 237.4ms/batch - loss: 38.89786 - diff: 19.13mlTrain batch 18/32 - 240.2ms/batch - loss: 37.70884 - diff: 18.86mlTrain batch 19/32 - 237.3ms/batch - loss: 37.27429 - diff: 18.85mlTrain batch 20/32 - 240.3ms/batch - loss: 36.43619 - diff: 18.70mlTrain batch 21/32 - 237.4ms/batch - loss: 36.07554 - diff: 18.55mlTrain batch 22/32 - 240.5ms/batch - loss: 35.58871 - diff: 18.49mlTrain batch 23/32 - 237.5ms/batch - loss: 35.78302 - diff: 18.54mlTrain batch 24/32 - 239.7ms/batch - loss: 34.91653 - diff: 18.25mlTrain batch 25/32 - 237.8ms/batch - loss: 34.11909 - diff: 18.02mlTrain batch 26/32 - 240.2ms/batch - loss: 34.70549 - diff: 18.21mlTrain batch 27/32 - 238.0ms/batch - loss: 34.25446 - diff: 18.07mlTrain batch 28/32 - 240.3ms/batch - loss: 40.61239 - diff: 18.86mlTrain batch 29/32 - 237.4ms/batch - loss: 40.86642 - diff: 18.98mlTrain batch 30/32 - 240.2ms/batch - loss: 42.58492 - diff: 19.11mlTrain batch 31/32 - 238.5ms/batch - loss: 42.88163 - diff: 19.14mlTrain batch 32/32 - 77.6ms/batch - loss: 44.58005 - diff: 19.20mlTrain batch 32/32 - 10.6s 77.6ms/batch - loss: 44.58005 - diff: 19.20ml
Test 1.2s: val_loss: 64.30429 - diff: 20.66ml

Epoch 117: current best loss = 41.86942, at epoch 108
Train batch 1/32 - 237.7ms/batch - loss: 25.95008 - diff: 16.38mlTrain batch 2/32 - 238.4ms/batch - loss: 24.68866 - diff: 15.81mlTrain batch 3/32 - 237.5ms/batch - loss: 26.23078 - diff: 16.36mlTrain batch 4/32 - 240.1ms/batch - loss: 26.80847 - diff: 16.52mlTrain batch 5/32 - 238.3ms/batch - loss: 25.29244 - diff: 15.97mlTrain batch 6/32 - 240.3ms/batch - loss: 29.25933 - diff: 16.85mlTrain batch 7/32 - 237.1ms/batch - loss: 32.70493 - diff: 17.37mlTrain batch 8/32 - 240.3ms/batch - loss: 32.31829 - diff: 17.09mlTrain batch 9/32 - 237.8ms/batch - loss: 36.80419 - diff: 18.49mlTrain batch 10/32 - 240.0ms/batch - loss: 35.48451 - diff: 18.24mlTrain batch 11/32 - 237.4ms/batch - loss: 48.10003 - diff: 19.09mlTrain batch 12/32 - 240.1ms/batch - loss: 46.71331 - diff: 18.93mlTrain batch 13/32 - 238.0ms/batch - loss: 44.82788 - diff: 18.65mlTrain batch 14/32 - 240.4ms/batch - loss: 44.08080 - diff: 18.47mlTrain batch 15/32 - 238.0ms/batch - loss: 44.53337 - diff: 18.45mlTrain batch 16/32 - 240.2ms/batch - loss: 45.82659 - diff: 18.79mlTrain batch 17/32 - 237.6ms/batch - loss: 45.21579 - diff: 18.79mlTrain batch 18/32 - 239.5ms/batch - loss: 44.54098 - diff: 18.59mlTrain batch 19/32 - 238.6ms/batch - loss: 46.50583 - diff: 18.69mlTrain batch 20/32 - 240.1ms/batch - loss: 45.52763 - diff: 18.57mlTrain batch 21/32 - 238.6ms/batch - loss: 44.10437 - diff: 18.19mlTrain batch 22/32 - 240.1ms/batch - loss: 43.21766 - diff: 18.19mlTrain batch 23/32 - 237.4ms/batch - loss: 42.92678 - diff: 18.08mlTrain batch 24/32 - 240.2ms/batch - loss: 42.38650 - diff: 18.00mlTrain batch 25/32 - 237.9ms/batch - loss: 42.49352 - diff: 18.07mlTrain batch 26/32 - 240.2ms/batch - loss: 42.39974 - diff: 18.08mlTrain batch 27/32 - 237.3ms/batch - loss: 42.03052 - diff: 18.13mlTrain batch 28/32 - 240.4ms/batch - loss: 41.78262 - diff: 18.03mlTrain batch 29/32 - 237.5ms/batch - loss: 41.92367 - diff: 18.18mlTrain batch 30/32 - 240.7ms/batch - loss: 41.93088 - diff: 18.20mlTrain batch 31/32 - 237.6ms/batch - loss: 41.77344 - diff: 18.23mlTrain batch 32/32 - 78.4ms/batch - loss: 42.07700 - diff: 18.21mlTrain batch 32/32 - 10.6s 78.4ms/batch - loss: 42.07700 - diff: 18.21ml
Test 1.1s: val_loss: 49.49833 - diff: 20.11ml

Epoch 118: current best loss = 41.86942, at epoch 108
Train batch 1/32 - 238.0ms/batch - loss: 35.24923 - diff: 20.19mlTrain batch 2/32 - 240.5ms/batch - loss: 27.70560 - diff: 16.94mlTrain batch 3/32 - 237.1ms/batch - loss: 26.85175 - diff: 16.16mlTrain batch 4/32 - 239.9ms/batch - loss: 27.05336 - diff: 15.83mlTrain batch 5/32 - 238.0ms/batch - loss: 24.86435 - diff: 15.25mlTrain batch 6/32 - 240.1ms/batch - loss: 25.07781 - diff: 15.24mlTrain batch 7/32 - 237.5ms/batch - loss: 24.87777 - diff: 15.06mlTrain batch 8/32 - 239.1ms/batch - loss: 27.93090 - diff: 15.97mlTrain batch 9/32 - 238.6ms/batch - loss: 29.05004 - diff: 16.54mlTrain batch 10/32 - 240.2ms/batch - loss: 27.94432 - diff: 16.25mlTrain batch 11/32 - 238.5ms/batch - loss: 27.88711 - diff: 16.20mlTrain batch 12/32 - 240.1ms/batch - loss: 27.37416 - diff: 16.10mlTrain batch 13/32 - 237.4ms/batch - loss: 28.36141 - diff: 16.42mlTrain batch 14/32 - 240.9ms/batch - loss: 27.71575 - diff: 16.32mlTrain batch 15/32 - 237.4ms/batch - loss: 27.49485 - diff: 16.21mlTrain batch 16/32 - 240.1ms/batch - loss: 30.24888 - diff: 16.55mlTrain batch 17/32 - 238.2ms/batch - loss: 31.30047 - diff: 16.90mlTrain batch 18/32 - 240.1ms/batch - loss: 31.14207 - diff: 16.83mlTrain batch 19/32 - 237.5ms/batch - loss: 30.61985 - diff: 16.71mlTrain batch 20/32 - 240.5ms/batch - loss: 29.93031 - diff: 16.51mlTrain batch 21/32 - 237.5ms/batch - loss: 30.34854 - diff: 16.57mlTrain batch 22/32 - 240.1ms/batch - loss: 31.14245 - diff: 16.70mlTrain batch 23/32 - 237.5ms/batch - loss: 31.25845 - diff: 16.86mlTrain batch 24/32 - 240.0ms/batch - loss: 30.49596 - diff: 16.63mlTrain batch 25/32 - 238.1ms/batch - loss: 30.40702 - diff: 16.62mlTrain batch 26/32 - 240.4ms/batch - loss: 30.47237 - diff: 16.63mlTrain batch 27/32 - 238.1ms/batch - loss: 30.38577 - diff: 16.68mlTrain batch 28/32 - 240.2ms/batch - loss: 29.78948 - diff: 16.49mlTrain batch 29/32 - 237.5ms/batch - loss: 29.38892 - diff: 16.42mlTrain batch 30/32 - 239.5ms/batch - loss: 28.83881 - diff: 16.26mlTrain batch 31/32 - 238.5ms/batch - loss: 31.02200 - diff: 16.60mlTrain batch 32/32 - 78.3ms/batch - loss: 32.16276 - diff: 16.62mlTrain batch 32/32 - 10.6s 78.3ms/batch - loss: 32.16276 - diff: 16.62ml
Test 1.2s: val_loss: 43.00482 - diff: 18.06ml

Epoch 119: current best loss = 41.86942, at epoch 108
Train batch 1/32 - 237.3ms/batch - loss: 10.12656 - diff: 9.16mlTrain batch 2/32 - 238.9ms/batch - loss: 15.64579 - diff: 12.55mlTrain batch 3/32 - 237.6ms/batch - loss: 19.77016 - diff: 13.95mlTrain batch 4/32 - 240.2ms/batch - loss: 19.99949 - diff: 13.97mlTrain batch 5/32 - 238.2ms/batch - loss: 24.19290 - diff: 14.21mlTrain batch 6/32 - 240.5ms/batch - loss: 21.74352 - diff: 13.46mlTrain batch 7/32 - 237.4ms/batch - loss: 23.84324 - diff: 14.06mlTrain batch 8/32 - 240.6ms/batch - loss: 34.22373 - diff: 15.65mlTrain batch 9/32 - 237.6ms/batch - loss: 46.55154 - diff: 18.03mlTrain batch 10/32 - 240.3ms/batch - loss: 48.02377 - diff: 18.58mlTrain batch 11/32 - 237.9ms/batch - loss: 45.18500 - diff: 18.02mlTrain batch 12/32 - 240.4ms/batch - loss: 46.75094 - diff: 18.71mlTrain batch 13/32 - 238.3ms/batch - loss: 45.21916 - diff: 18.68mlTrain batch 14/32 - 240.3ms/batch - loss: 43.86862 - diff: 18.54mlTrain batch 15/32 - 238.4ms/batch - loss: 42.67055 - diff: 18.40mlTrain batch 16/32 - 240.1ms/batch - loss: 42.04239 - diff: 18.32mlTrain batch 17/32 - 237.2ms/batch - loss: 40.67956 - diff: 18.10mlTrain batch 18/32 - 238.3ms/batch - loss: 40.48608 - diff: 17.97mlTrain batch 19/32 - 237.6ms/batch - loss: 41.50372 - diff: 18.30mlTrain batch 20/32 - 239.8ms/batch - loss: 40.49949 - diff: 18.13mlTrain batch 21/32 - 240.0ms/batch - loss: 40.58083 - diff: 18.28mlTrain batch 22/32 - 240.5ms/batch - loss: 40.02582 - diff: 18.23mlTrain batch 23/32 - 237.8ms/batch - loss: 40.15104 - diff: 18.36mlTrain batch 24/32 - 240.4ms/batch - loss: 39.60150 - diff: 18.24mlTrain batch 25/32 - 237.5ms/batch - loss: 39.81194 - diff: 18.23mlTrain batch 26/32 - 240.4ms/batch - loss: 39.53522 - diff: 18.18mlTrain batch 27/32 - 237.4ms/batch - loss: 39.69937 - diff: 18.25mlTrain batch 28/32 - 240.6ms/batch - loss: 39.13874 - diff: 18.15mlTrain batch 29/32 - 237.9ms/batch - loss: 38.97400 - diff: 18.20mlTrain batch 30/32 - 240.5ms/batch - loss: 38.35839 - diff: 18.01mlTrain batch 31/32 - 237.8ms/batch - loss: 38.19235 - diff: 18.01mlTrain batch 32/32 - 78.7ms/batch - loss: 39.42283 - diff: 18.01mlTrain batch 32/32 - 10.7s 78.7ms/batch - loss: 39.42283 - diff: 18.01ml
Test 1.1s: val_loss: 45.68202 - diff: 19.20ml
Epoch   120: reducing learning rate of group 0 to 2.5000e-04.

Epoch 120: current best loss = 41.86942, at epoch 108
Train batch 1/32 - 237.3ms/batch - loss: 17.19917 - diff: 13.22mlTrain batch 2/32 - 238.0ms/batch - loss: 28.40798 - diff: 14.78mlTrain batch 3/32 - 238.3ms/batch - loss: 24.23214 - diff: 14.32mlTrain batch 4/32 - 240.1ms/batch - loss: 21.83365 - diff: 13.87mlTrain batch 5/32 - 238.5ms/batch - loss: 28.61436 - diff: 15.78mlTrain batch 6/32 - 239.9ms/batch - loss: 25.91569 - diff: 14.90mlTrain batch 7/32 - 237.8ms/batch - loss: 27.44205 - diff: 15.55mlTrain batch 8/32 - 239.7ms/batch - loss: 26.97641 - diff: 15.69mlTrain batch 9/32 - 237.5ms/batch - loss: 39.48078 - diff: 17.86mlTrain batch 10/32 - 240.2ms/batch - loss: 37.56357 - diff: 17.47mlTrain batch 11/32 - 240.4ms/batch - loss: 36.44599 - diff: 17.41mlTrain batch 12/32 - 240.4ms/batch - loss: 34.34868 - diff: 16.98mlTrain batch 13/32 - 237.3ms/batch - loss: 34.94587 - diff: 17.44mlTrain batch 14/32 - 240.4ms/batch - loss: 34.21710 - diff: 17.28mlTrain batch 15/32 - 237.6ms/batch - loss: 32.89368 - diff: 17.03mlTrain batch 16/32 - 239.9ms/batch - loss: 32.47108 - diff: 16.92mlTrain batch 17/32 - 237.5ms/batch - loss: 33.32588 - diff: 17.11mlTrain batch 18/32 - 239.6ms/batch - loss: 32.40626 - diff: 16.88mlTrain batch 19/32 - 238.0ms/batch - loss: 31.57351 - diff: 16.57mlTrain batch 20/32 - 240.3ms/batch - loss: 35.53327 - diff: 16.75mlTrain batch 21/32 - 238.5ms/batch - loss: 35.22659 - diff: 16.75mlTrain batch 22/32 - 240.1ms/batch - loss: 37.14653 - diff: 16.92mlTrain batch 23/32 - 240.5ms/batch - loss: 36.45303 - diff: 16.76mlTrain batch 24/32 - 240.5ms/batch - loss: 36.05532 - diff: 16.81mlTrain batch 25/32 - 238.6ms/batch - loss: 37.05280 - diff: 17.15mlTrain batch 26/32 - 240.0ms/batch - loss: 37.72684 - diff: 17.36mlTrain batch 27/32 - 237.5ms/batch - loss: 37.45929 - diff: 17.39mlTrain batch 28/32 - 237.8ms/batch - loss: 37.13376 - diff: 17.35mlTrain batch 29/32 - 237.4ms/batch - loss: 36.63963 - diff: 17.29mlTrain batch 30/32 - 240.0ms/batch - loss: 36.34456 - diff: 17.36mlTrain batch 31/32 - 240.2ms/batch - loss: 36.35182 - diff: 17.43mlTrain batch 32/32 - 79.2ms/batch - loss: 37.60765 - diff: 17.45mlTrain batch 32/32 - 10.7s 79.2ms/batch - loss: 37.60765 - diff: 17.45ml
Test 1.2s: val_loss: 39.54451 - diff: 18.25ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Systole_WideResNet50_0_Adam-0.001_MSE_DA3_best

Epoch 121: current best loss = 39.54451, at epoch 120
Train batch 1/32 - 237.0ms/batch - loss: 54.96276 - diff: 20.97mlTrain batch 2/32 - 237.1ms/batch - loss: 37.88562 - diff: 16.46mlTrain batch 3/32 - 237.2ms/batch - loss: 33.97016 - diff: 16.52mlTrain batch 4/32 - 240.2ms/batch - loss: 35.52774 - diff: 16.50mlTrain batch 5/32 - 237.1ms/batch - loss: 34.78908 - diff: 16.81mlTrain batch 6/32 - 239.7ms/batch - loss: 33.46549 - diff: 16.71mlTrain batch 7/32 - 237.1ms/batch - loss: 33.18010 - diff: 16.68mlTrain batch 8/32 - 238.7ms/batch - loss: 30.77084 - diff: 16.17mlTrain batch 9/32 - 237.6ms/batch - loss: 31.66291 - diff: 16.62mlTrain batch 10/32 - 239.3ms/batch - loss: 31.53494 - diff: 16.59mlTrain batch 11/32 - 238.1ms/batch - loss: 31.70523 - diff: 16.58mlTrain batch 12/32 - 239.4ms/batch - loss: 30.80484 - diff: 16.39mlTrain batch 13/32 - 237.4ms/batch - loss: 30.64938 - diff: 16.48mlTrain batch 14/32 - 237.9ms/batch - loss: 29.83701 - diff: 16.31mlTrain batch 15/32 - 237.6ms/batch - loss: 30.34623 - diff: 16.56mlTrain batch 16/32 - 240.2ms/batch - loss: 29.74761 - diff: 16.38mlTrain batch 17/32 - 237.4ms/batch - loss: 30.53314 - diff: 16.61mlTrain batch 18/32 - 240.2ms/batch - loss: 30.15047 - diff: 16.58mlTrain batch 19/32 - 237.8ms/batch - loss: 32.93968 - diff: 17.14mlTrain batch 20/32 - 240.3ms/batch - loss: 31.83504 - diff: 16.76mlTrain batch 21/32 - 237.3ms/batch - loss: 31.43912 - diff: 16.59mlTrain batch 22/32 - 240.0ms/batch - loss: 30.90235 - diff: 16.55mlTrain batch 23/32 - 237.9ms/batch - loss: 30.34170 - diff: 16.42mlTrain batch 24/32 - 240.2ms/batch - loss: 30.29586 - diff: 16.43mlTrain batch 25/32 - 237.6ms/batch - loss: 30.10688 - diff: 16.39mlTrain batch 26/32 - 239.6ms/batch - loss: 29.59444 - diff: 16.26mlTrain batch 27/32 - 237.5ms/batch - loss: 29.90601 - diff: 16.39mlTrain batch 28/32 - 239.5ms/batch - loss: 29.76010 - diff: 16.44mlTrain batch 29/32 - 238.4ms/batch - loss: 29.50893 - diff: 16.39mlTrain batch 30/32 - 240.2ms/batch - loss: 29.42493 - diff: 16.35mlTrain batch 31/32 - 238.8ms/batch - loss: 29.59938 - diff: 16.42mlTrain batch 32/32 - 78.0ms/batch - loss: 31.81672 - diff: 16.49mlTrain batch 32/32 - 10.7s 78.0ms/batch - loss: 31.81672 - diff: 16.49ml
Test 1.2s: val_loss: 37.47716 - diff: 17.72ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Systole_WideResNet50_0_Adam-0.001_MSE_DA3_best

Epoch 122: current best loss = 37.47716, at epoch 121
Train batch 1/32 - 254.0ms/batch - loss: 13.55446 - diff: 11.96mlTrain batch 2/32 - 237.3ms/batch - loss: 19.22073 - diff: 14.37mlTrain batch 3/32 - 237.1ms/batch - loss: 19.37420 - diff: 14.37mlTrain batch 4/32 - 239.0ms/batch - loss: 24.17072 - diff: 16.41mlTrain batch 5/32 - 237.9ms/batch - loss: 24.77077 - diff: 16.40mlTrain batch 6/32 - 240.0ms/batch - loss: 25.48109 - diff: 16.30mlTrain batch 7/32 - 238.0ms/batch - loss: 26.67012 - diff: 16.18mlTrain batch 8/32 - 240.0ms/batch - loss: 31.25634 - diff: 17.25mlTrain batch 9/32 - 237.8ms/batch - loss: 28.82605 - diff: 16.41mlTrain batch 10/32 - 239.0ms/batch - loss: 28.43537 - diff: 16.27mlTrain batch 11/32 - 237.7ms/batch - loss: 28.58249 - diff: 16.27mlTrain batch 12/32 - 238.2ms/batch - loss: 28.17186 - diff: 16.24mlTrain batch 13/32 - 237.5ms/batch - loss: 26.90447 - diff: 15.87mlTrain batch 14/32 - 239.0ms/batch - loss: 28.13480 - diff: 16.17mlTrain batch 15/32 - 237.4ms/batch - loss: 27.80133 - diff: 15.98mlTrain batch 16/32 - 240.5ms/batch - loss: 29.14815 - diff: 16.24mlTrain batch 17/32 - 238.4ms/batch - loss: 29.34595 - diff: 16.29mlTrain batch 18/32 - 237.4ms/batch - loss: 28.56774 - diff: 16.06mlTrain batch 19/32 - 237.3ms/batch - loss: 28.11189 - diff: 15.84mlTrain batch 20/32 - 240.4ms/batch - loss: 27.38324 - diff: 15.62mlTrain batch 21/32 - 237.4ms/batch - loss: 26.78658 - diff: 15.47mlTrain batch 22/32 - 239.4ms/batch - loss: 27.74831 - diff: 15.67mlTrain batch 23/32 - 237.9ms/batch - loss: 28.51823 - diff: 15.80mlTrain batch 24/32 - 240.3ms/batch - loss: 27.91353 - diff: 15.68mlTrain batch 25/32 - 237.4ms/batch - loss: 28.77965 - diff: 16.02mlTrain batch 26/32 - 239.1ms/batch - loss: 28.91451 - diff: 16.06mlTrain batch 27/32 - 237.9ms/batch - loss: 30.65779 - diff: 16.28mlTrain batch 28/32 - 239.9ms/batch - loss: 30.82502 - diff: 16.41mlTrain batch 29/32 - 238.0ms/batch - loss: 30.38874 - diff: 16.30mlTrain batch 30/32 - 239.7ms/batch - loss: 30.30163 - diff: 16.35mlTrain batch 31/32 - 238.6ms/batch - loss: 30.32912 - diff: 16.44mlTrain batch 32/32 - 77.6ms/batch - loss: 32.84198 - diff: 16.59mlTrain batch 32/32 - 10.7s 77.6ms/batch - loss: 32.84198 - diff: 16.59ml
Test 1.1s: val_loss: 48.55847 - diff: 18.79ml

Epoch 123: current best loss = 37.47716, at epoch 121
Train batch 1/32 - 237.3ms/batch - loss: 22.93277 - diff: 16.62mlTrain batch 2/32 - 239.9ms/batch - loss: 20.99495 - diff: 13.99mlTrain batch 3/32 - 237.3ms/batch - loss: 28.20177 - diff: 16.21mlTrain batch 4/32 - 239.6ms/batch - loss: 27.37362 - diff: 16.01mlTrain batch 5/32 - 237.4ms/batch - loss: 28.39298 - diff: 16.45mlTrain batch 6/32 - 240.4ms/batch - loss: 32.12935 - diff: 17.22mlTrain batch 7/32 - 238.2ms/batch - loss: 29.02089 - diff: 16.21mlTrain batch 8/32 - 237.8ms/batch - loss: 29.97136 - diff: 16.60mlTrain batch 9/32 - 237.3ms/batch - loss: 29.90030 - diff: 16.66mlTrain batch 10/32 - 240.5ms/batch - loss: 28.53135 - diff: 16.23mlTrain batch 11/32 - 237.0ms/batch - loss: 37.71299 - diff: 17.54mlTrain batch 12/32 - 239.2ms/batch - loss: 48.87221 - diff: 18.91mlTrain batch 13/32 - 237.8ms/batch - loss: 47.71636 - diff: 18.59mlTrain batch 14/32 - 240.1ms/batch - loss: 47.86630 - diff: 18.91mlTrain batch 15/32 - 237.5ms/batch - loss: 46.68994 - diff: 18.72mlTrain batch 16/32 - 239.4ms/batch - loss: 45.23831 - diff: 18.52mlTrain batch 17/32 - 237.6ms/batch - loss: 46.92915 - diff: 18.72mlTrain batch 18/32 - 239.1ms/batch - loss: 47.53899 - diff: 18.77mlTrain batch 19/32 - 238.3ms/batch - loss: 46.70793 - diff: 18.77mlTrain batch 20/32 - 239.6ms/batch - loss: 47.18020 - diff: 18.99mlTrain batch 21/32 - 237.4ms/batch - loss: 46.28451 - diff: 18.95mlTrain batch 22/32 - 237.6ms/batch - loss: 44.99513 - diff: 18.65mlTrain batch 23/32 - 237.1ms/batch - loss: 44.14681 - diff: 18.53mlTrain batch 24/32 - 240.0ms/batch - loss: 43.49481 - diff: 18.46mlTrain batch 25/32 - 238.2ms/batch - loss: 44.47208 - diff: 18.69mlTrain batch 26/32 - 240.4ms/batch - loss: 43.18044 - diff: 18.32mlTrain batch 27/32 - 238.2ms/batch - loss: 43.19858 - diff: 18.36mlTrain batch 28/32 - 240.2ms/batch - loss: 42.38853 - diff: 18.23mlTrain batch 29/32 - 237.5ms/batch - loss: 41.38515 - diff: 18.03mlTrain batch 30/32 - 240.4ms/batch - loss: 40.61101 - diff: 17.88mlTrain batch 31/32 - 237.3ms/batch - loss: 39.85475 - diff: 17.72mlTrain batch 32/32 - 78.9ms/batch - loss: 40.64915 - diff: 17.75mlTrain batch 32/32 - 10.6s 78.9ms/batch - loss: 40.64915 - diff: 17.75ml
Test 1.2s: val_loss: 42.05883 - diff: 18.91ml

Epoch 124: current best loss = 37.47716, at epoch 121
Train batch 1/32 - 236.9ms/batch - loss: 25.80740 - diff: 16.16mlTrain batch 2/32 - 238.4ms/batch - loss: 21.98716 - diff: 15.08mlTrain batch 3/32 - 237.8ms/batch - loss: 23.71229 - diff: 16.19mlTrain batch 4/32 - 240.0ms/batch - loss: 29.32964 - diff: 17.15mlTrain batch 5/32 - 237.4ms/batch - loss: 43.54342 - diff: 18.88mlTrain batch 6/32 - 238.8ms/batch - loss: 42.50297 - diff: 19.03mlTrain batch 7/32 - 237.8ms/batch - loss: 37.74293 - diff: 17.70mlTrain batch 8/32 - 239.5ms/batch - loss: 38.66076 - diff: 18.20mlTrain batch 9/32 - 237.1ms/batch - loss: 37.00228 - diff: 17.89mlTrain batch 10/32 - 237.6ms/batch - loss: 35.50132 - diff: 17.65mlTrain batch 11/32 - 237.6ms/batch - loss: 33.49255 - diff: 17.14mlTrain batch 12/32 - 239.7ms/batch - loss: 39.33128 - diff: 18.22mlTrain batch 13/32 - 237.9ms/batch - loss: 38.73672 - diff: 18.05mlTrain batch 14/32 - 240.4ms/batch - loss: 37.44167 - diff: 17.85mlTrain batch 15/32 - 237.3ms/batch - loss: 36.62661 - diff: 17.57mlTrain batch 16/32 - 240.2ms/batch - loss: 35.60791 - diff: 17.38mlTrain batch 17/32 - 237.6ms/batch - loss: 35.43205 - diff: 17.29mlTrain batch 18/32 - 240.1ms/batch - loss: 34.47662 - diff: 17.08mlTrain batch 19/32 - 238.1ms/batch - loss: 33.83924 - diff: 16.97mlTrain batch 20/32 - 240.3ms/batch - loss: 34.08659 - diff: 17.08mlTrain batch 21/32 - 237.5ms/batch - loss: 35.64777 - diff: 17.19mlTrain batch 22/32 - 239.0ms/batch - loss: 35.16246 - diff: 17.03mlTrain batch 23/32 - 238.6ms/batch - loss: 34.38908 - diff: 16.77mlTrain batch 24/32 - 240.3ms/batch - loss: 34.60900 - diff: 16.89mlTrain batch 25/32 - 238.6ms/batch - loss: 34.43474 - diff: 16.87mlTrain batch 26/32 - 239.8ms/batch - loss: 33.81489 - diff: 16.73mlTrain batch 27/32 - 237.5ms/batch - loss: 33.45449 - diff: 16.66mlTrain batch 28/32 - 240.1ms/batch - loss: 32.74792 - diff: 16.51mlTrain batch 29/32 - 237.7ms/batch - loss: 32.31296 - diff: 16.40mlTrain batch 30/32 - 240.2ms/batch - loss: 31.82841 - diff: 16.30mlTrain batch 31/32 - 237.6ms/batch - loss: 31.58842 - diff: 16.29mlTrain batch 32/32 - 78.2ms/batch - loss: 33.29233 - diff: 16.36mlTrain batch 32/32 - 10.7s 78.2ms/batch - loss: 33.29233 - diff: 16.36ml
Test 1.2s: val_loss: 43.22193 - diff: 18.69ml

Epoch 125: current best loss = 37.47716, at epoch 121
Train batch 1/32 - 237.5ms/batch - loss: 18.04675 - diff: 14.31mlTrain batch 2/32 - 239.7ms/batch - loss: 25.10325 - diff: 14.84mlTrain batch 3/32 - 237.5ms/batch - loss: 23.02168 - diff: 14.36mlTrain batch 4/32 - 239.9ms/batch - loss: 25.26445 - diff: 14.65mlTrain batch 5/32 - 237.3ms/batch - loss: 26.52376 - diff: 15.38mlTrain batch 6/32 - 238.7ms/batch - loss: 29.08201 - diff: 15.29mlTrain batch 7/32 - 238.4ms/batch - loss: 28.92174 - diff: 15.63mlTrain batch 8/32 - 239.4ms/batch - loss: 27.49035 - diff: 15.36mlTrain batch 9/32 - 238.5ms/batch - loss: 28.14902 - diff: 15.51mlTrain batch 10/32 - 239.2ms/batch - loss: 27.43875 - diff: 15.41mlTrain batch 11/32 - 237.3ms/batch - loss: 25.69337 - diff: 14.73mlTrain batch 12/32 - 239.8ms/batch - loss: 26.55341 - diff: 15.21mlTrain batch 13/32 - 237.4ms/batch - loss: 25.60907 - diff: 14.99mlTrain batch 14/32 - 240.1ms/batch - loss: 25.70120 - diff: 14.92mlTrain batch 15/32 - 238.4ms/batch - loss: 27.33910 - diff: 15.06mlTrain batch 16/32 - 240.1ms/batch - loss: 26.58916 - diff: 14.89mlTrain batch 17/32 - 237.3ms/batch - loss: 34.47942 - diff: 16.18mlTrain batch 18/32 - 240.3ms/batch - loss: 33.72873 - diff: 16.14mlTrain batch 19/32 - 237.4ms/batch - loss: 33.28329 - diff: 16.02mlTrain batch 20/32 - 240.2ms/batch - loss: 33.98572 - diff: 16.27mlTrain batch 21/32 - 237.9ms/batch - loss: 33.37562 - diff: 16.07mlTrain batch 22/32 - 240.2ms/batch - loss: 33.68793 - diff: 16.17mlTrain batch 23/32 - 237.7ms/batch - loss: 33.24422 - diff: 16.07mlTrain batch 24/32 - 240.3ms/batch - loss: 32.86274 - diff: 16.11mlTrain batch 25/32 - 237.6ms/batch - loss: 33.25549 - diff: 16.25mlTrain batch 26/32 - 239.6ms/batch - loss: 32.83817 - diff: 16.26mlTrain batch 27/32 - 237.5ms/batch - loss: 32.67689 - diff: 16.33mlTrain batch 28/32 - 239.8ms/batch - loss: 32.43369 - diff: 16.32mlTrain batch 29/32 - 238.1ms/batch - loss: 32.65040 - diff: 16.42mlTrain batch 30/32 - 240.1ms/batch - loss: 32.88185 - diff: 16.44mlTrain batch 31/32 - 238.3ms/batch - loss: 32.24109 - diff: 16.31mlTrain batch 32/32 - 77.8ms/batch - loss: 32.54376 - diff: 16.27mlTrain batch 32/32 - 10.6s 77.8ms/batch - loss: 32.54376 - diff: 16.27ml
Test 1.2s: val_loss: 38.41515 - diff: 17.22ml

Epoch 126: current best loss = 37.47716, at epoch 121
Train batch 1/32 - 237.4ms/batch - loss: 16.60155 - diff: 12.82mlTrain batch 2/32 - 240.3ms/batch - loss: 14.13056 - diff: 11.89mlTrain batch 3/32 - 238.1ms/batch - loss: 14.43237 - diff: 11.84mlTrain batch 4/32 - 237.4ms/batch - loss: 28.35917 - diff: 15.01mlTrain batch 5/32 - 237.5ms/batch - loss: 31.68448 - diff: 16.04mlTrain batch 6/32 - 240.4ms/batch - loss: 29.78550 - diff: 15.62mlTrain batch 7/32 - 237.1ms/batch - loss: 33.09750 - diff: 16.32mlTrain batch 8/32 - 240.5ms/batch - loss: 31.10052 - diff: 15.86mlTrain batch 9/32 - 238.0ms/batch - loss: 29.64243 - diff: 15.58mlTrain batch 10/32 - 240.4ms/batch - loss: 29.57351 - diff: 15.60mlTrain batch 11/32 - 237.8ms/batch - loss: 28.17967 - diff: 15.38mlTrain batch 12/32 - 240.4ms/batch - loss: 28.32648 - diff: 15.41mlTrain batch 13/32 - 237.7ms/batch - loss: 28.82727 - diff: 15.53mlTrain batch 14/32 - 239.6ms/batch - loss: 28.40534 - diff: 15.54mlTrain batch 15/32 - 238.4ms/batch - loss: 29.16212 - diff: 15.77mlTrain batch 16/32 - 240.0ms/batch - loss: 30.81512 - diff: 16.33mlTrain batch 17/32 - 238.2ms/batch - loss: 29.77447 - diff: 16.03mlTrain batch 18/32 - 240.0ms/batch - loss: 29.34717 - diff: 15.97mlTrain batch 19/32 - 238.4ms/batch - loss: 30.51755 - diff: 16.18mlTrain batch 20/32 - 239.2ms/batch - loss: 30.45650 - diff: 16.20mlTrain batch 21/32 - 237.5ms/batch - loss: 29.87111 - diff: 16.07mlTrain batch 22/32 - 239.1ms/batch - loss: 31.32375 - diff: 16.36mlTrain batch 23/32 - 238.5ms/batch - loss: 31.81930 - diff: 16.54mlTrain batch 24/32 - 240.2ms/batch - loss: 31.09413 - diff: 16.32mlTrain batch 25/32 - 237.3ms/batch - loss: 30.88301 - diff: 16.29mlTrain batch 26/32 - 240.3ms/batch - loss: 30.96785 - diff: 16.19mlTrain batch 27/32 - 237.5ms/batch - loss: 31.39154 - diff: 16.34mlTrain batch 28/32 - 240.5ms/batch - loss: 30.58675 - diff: 16.07mlTrain batch 29/32 - 237.9ms/batch - loss: 30.52149 - diff: 16.08mlTrain batch 30/32 - 240.4ms/batch - loss: 30.02335 - diff: 15.98mlTrain batch 31/32 - 238.4ms/batch - loss: 29.76916 - diff: 15.95mlTrain batch 32/32 - 78.9ms/batch - loss: 29.64880 - diff: 15.88mlTrain batch 32/32 - 10.7s 78.9ms/batch - loss: 29.64880 - diff: 15.88ml
Test 1.2s: val_loss: 37.47573 - diff: 16.88ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Systole_WideResNet50_0_Adam-0.001_MSE_DA3_best

Epoch 127: current best loss = 37.47573, at epoch 126
Train batch 1/32 - 246.7ms/batch - loss: 8.90470 - diff: 9.69mlTrain batch 2/32 - 237.4ms/batch - loss: 18.65114 - diff: 13.29mlTrain batch 3/32 - 237.3ms/batch - loss: 20.32892 - diff: 14.44mlTrain batch 4/32 - 237.5ms/batch - loss: 24.20759 - diff: 15.14mlTrain batch 5/32 - 236.9ms/batch - loss: 35.27687 - diff: 17.40mlTrain batch 6/32 - 238.5ms/batch - loss: 32.18601 - diff: 16.64mlTrain batch 7/32 - 237.8ms/batch - loss: 31.79437 - diff: 16.44mlTrain batch 8/32 - 239.2ms/batch - loss: 31.33673 - diff: 16.33mlTrain batch 9/32 - 238.1ms/batch - loss: 30.54925 - diff: 16.17mlTrain batch 10/32 - 239.1ms/batch - loss: 29.78099 - diff: 15.98mlTrain batch 11/32 - 237.5ms/batch - loss: 36.41285 - diff: 16.98mlTrain batch 12/32 - 239.4ms/batch - loss: 36.05957 - diff: 17.01mlTrain batch 13/32 - 237.4ms/batch - loss: 35.02751 - diff: 16.90mlTrain batch 14/32 - 239.6ms/batch - loss: 34.49946 - diff: 16.71mlTrain batch 15/32 - 237.4ms/batch - loss: 33.89999 - diff: 16.56mlTrain batch 16/32 - 240.3ms/batch - loss: 32.64358 - diff: 16.26mlTrain batch 17/32 - 237.5ms/batch - loss: 33.40327 - diff: 16.68mlTrain batch 18/32 - 240.2ms/batch - loss: 33.70880 - diff: 16.90mlTrain batch 19/32 - 237.4ms/batch - loss: 33.99393 - diff: 16.80mlTrain batch 20/32 - 240.3ms/batch - loss: 32.87047 - diff: 16.53mlTrain batch 21/32 - 237.3ms/batch - loss: 32.44643 - diff: 16.44mlTrain batch 22/32 - 239.5ms/batch - loss: 31.84888 - diff: 16.31mlTrain batch 23/32 - 237.7ms/batch - loss: 31.20033 - diff: 16.18mlTrain batch 24/32 - 240.2ms/batch - loss: 30.80584 - diff: 16.12mlTrain batch 25/32 - 237.5ms/batch - loss: 31.88775 - diff: 16.37mlTrain batch 26/32 - 239.1ms/batch - loss: 31.36650 - diff: 16.23mlTrain batch 27/32 - 237.7ms/batch - loss: 30.98986 - diff: 16.21mlTrain batch 28/32 - 239.5ms/batch - loss: 30.44169 - diff: 16.07mlTrain batch 29/32 - 238.4ms/batch - loss: 32.77719 - diff: 16.39mlTrain batch 30/32 - 239.5ms/batch - loss: 32.41017 - diff: 16.31mlTrain batch 31/32 - 238.4ms/batch - loss: 31.83196 - diff: 16.19mlTrain batch 32/32 - 77.3ms/batch - loss: 32.19289 - diff: 16.17mlTrain batch 32/32 - 10.6s 77.3ms/batch - loss: 32.19289 - diff: 16.17ml
Test 1.2s: val_loss: 36.88583 - diff: 17.35ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Systole_WideResNet50_0_Adam-0.001_MSE_DA3_best

Epoch 128: current best loss = 36.88583, at epoch 127
Train batch 1/32 - 236.8ms/batch - loss: 13.07749 - diff: 11.30mlTrain batch 2/32 - 237.5ms/batch - loss: 15.99383 - diff: 12.15mlTrain batch 3/32 - 237.4ms/batch - loss: 15.43283 - diff: 12.09mlTrain batch 4/32 - 237.5ms/batch - loss: 20.41702 - diff: 14.03mlTrain batch 5/32 - 237.4ms/batch - loss: 18.51350 - diff: 13.33mlTrain batch 6/32 - 240.2ms/batch - loss: 18.05483 - diff: 13.19mlTrain batch 7/32 - 237.5ms/batch - loss: 21.96094 - diff: 14.18mlTrain batch 8/32 - 240.0ms/batch - loss: 21.38360 - diff: 13.95mlTrain batch 9/32 - 237.4ms/batch - loss: 22.64705 - diff: 14.43mlTrain batch 10/32 - 239.6ms/batch - loss: 22.00790 - diff: 14.38mlTrain batch 11/32 - 237.6ms/batch - loss: 20.92533 - diff: 13.99mlTrain batch 12/32 - 240.1ms/batch - loss: 20.93373 - diff: 14.08mlTrain batch 13/32 - 237.8ms/batch - loss: 20.98027 - diff: 13.95mlTrain batch 14/32 - 240.1ms/batch - loss: 20.44697 - diff: 13.85mlTrain batch 15/32 - 237.5ms/batch - loss: 22.80576 - diff: 14.53mlTrain batch 16/32 - 238.5ms/batch - loss: 22.52197 - diff: 14.52mlTrain batch 17/32 - 238.3ms/batch - loss: 22.20635 - diff: 14.50mlTrain batch 18/32 - 239.8ms/batch - loss: 21.52829 - diff: 14.30mlTrain batch 19/32 - 238.7ms/batch - loss: 22.97631 - diff: 14.71mlTrain batch 20/32 - 240.0ms/batch - loss: 23.35769 - diff: 14.87mlTrain batch 21/32 - 237.3ms/batch - loss: 24.11988 - diff: 15.03mlTrain batch 22/32 - 240.0ms/batch - loss: 25.61195 - diff: 15.44mlTrain batch 23/32 - 237.0ms/batch - loss: 26.19743 - diff: 15.56mlTrain batch 24/32 - 240.2ms/batch - loss: 26.31421 - diff: 15.61mlTrain batch 25/32 - 237.4ms/batch - loss: 25.83002 - diff: 15.46mlTrain batch 26/32 - 240.2ms/batch - loss: 25.69481 - diff: 15.42mlTrain batch 27/32 - 237.8ms/batch - loss: 25.46811 - diff: 15.35mlTrain batch 28/32 - 240.2ms/batch - loss: 25.39881 - diff: 15.38mlTrain batch 29/32 - 237.2ms/batch - loss: 25.03699 - diff: 15.29mlTrain batch 30/32 - 240.4ms/batch - loss: 24.92454 - diff: 15.20mlTrain batch 31/32 - 237.5ms/batch - loss: 25.13541 - diff: 15.27mlTrain batch 32/32 - 77.3ms/batch - loss: 26.11580 - diff: 15.27mlTrain batch 32/32 - 10.6s 77.3ms/batch - loss: 26.11580 - diff: 15.27ml
Test 1.2s: val_loss: 37.34884 - diff: 17.22ml

Epoch 129: current best loss = 36.88583, at epoch 127
Train batch 1/32 - 237.1ms/batch - loss: 19.13859 - diff: 14.03mlTrain batch 2/32 - 238.6ms/batch - loss: 16.34137 - diff: 12.45mlTrain batch 3/32 - 237.8ms/batch - loss: 17.71049 - diff: 12.75mlTrain batch 4/32 - 240.3ms/batch - loss: 18.07645 - diff: 13.08mlTrain batch 5/32 - 238.0ms/batch - loss: 19.48808 - diff: 13.67mlTrain batch 6/32 - 240.2ms/batch - loss: 20.00413 - diff: 13.87mlTrain batch 7/32 - 238.1ms/batch - loss: 19.64545 - diff: 13.73mlTrain batch 8/32 - 238.6ms/batch - loss: 20.05191 - diff: 14.17mlTrain batch 9/32 - 238.4ms/batch - loss: 22.61160 - diff: 14.50mlTrain batch 10/32 - 239.7ms/batch - loss: 22.16693 - diff: 14.48mlTrain batch 11/32 - 237.8ms/batch - loss: 22.17504 - diff: 14.44mlTrain batch 12/32 - 239.8ms/batch - loss: 24.36923 - diff: 14.52mlTrain batch 13/32 - 237.2ms/batch - loss: 23.72963 - diff: 14.43mlTrain batch 14/32 - 240.1ms/batch - loss: 22.91747 - diff: 14.19mlTrain batch 15/32 - 237.6ms/batch - loss: 23.74804 - diff: 14.50mlTrain batch 16/32 - 240.1ms/batch - loss: 24.58413 - diff: 14.61mlTrain batch 17/32 - 237.5ms/batch - loss: 24.71483 - diff: 14.66mlTrain batch 18/32 - 240.3ms/batch - loss: 24.22256 - diff: 14.56mlTrain batch 19/32 - 237.7ms/batch - loss: 24.29456 - diff: 14.64mlTrain batch 20/32 - 240.1ms/batch - loss: 26.98940 - diff: 14.99mlTrain batch 21/32 - 237.9ms/batch - loss: 26.89496 - diff: 15.02mlTrain batch 22/32 - 240.4ms/batch - loss: 26.23910 - diff: 14.83mlTrain batch 23/32 - 238.0ms/batch - loss: 26.14722 - diff: 14.90mlTrain batch 24/32 - 240.5ms/batch - loss: 25.58468 - diff: 14.76mlTrain batch 25/32 - 237.6ms/batch - loss: 25.60956 - diff: 14.83mlTrain batch 26/32 - 239.9ms/batch - loss: 25.45490 - diff: 14.71mlTrain batch 27/32 - 238.2ms/batch - loss: 25.92979 - diff: 14.85mlTrain batch 28/32 - 240.0ms/batch - loss: 25.96459 - diff: 14.93mlTrain batch 29/32 - 238.8ms/batch - loss: 28.05453 - diff: 15.25mlTrain batch 30/32 - 240.2ms/batch - loss: 28.01096 - diff: 15.28mlTrain batch 31/32 - 237.7ms/batch - loss: 27.56573 - diff: 15.18mlTrain batch 32/32 - 77.1ms/batch - loss: 28.00663 - diff: 15.18mlTrain batch 32/32 - 10.7s 77.1ms/batch - loss: 28.00663 - diff: 15.18ml
Test 1.2s: val_loss: 43.62752 - diff: 18.80ml

Epoch 130: current best loss = 36.88583, at epoch 127
Train batch 1/32 - 237.3ms/batch - loss: 18.09521 - diff: 12.64mlTrain batch 2/32 - 240.5ms/batch - loss: 31.97609 - diff: 16.58mlTrain batch 3/32 - 237.2ms/batch - loss: 24.52236 - diff: 14.56mlTrain batch 4/32 - 240.2ms/batch - loss: 22.91083 - diff: 14.29mlTrain batch 5/32 - 237.6ms/batch - loss: 21.63678 - diff: 13.74mlTrain batch 6/32 - 239.7ms/batch - loss: 24.03905 - diff: 14.12mlTrain batch 7/32 - 237.7ms/batch - loss: 23.81022 - diff: 14.28mlTrain batch 8/32 - 239.9ms/batch - loss: 22.01763 - diff: 13.83mlTrain batch 9/32 - 238.0ms/batch - loss: 28.23934 - diff: 15.42mlTrain batch 10/32 - 239.9ms/batch - loss: 28.33383 - diff: 15.46mlTrain batch 11/32 - 238.2ms/batch - loss: 29.37282 - diff: 15.65mlTrain batch 12/32 - 239.9ms/batch - loss: 27.93054 - diff: 15.28mlTrain batch 13/32 - 242.6ms/batch - loss: 33.82363 - diff: 16.59mlTrain batch 14/32 - 239.6ms/batch - loss: 35.37499 - diff: 17.02mlTrain batch 15/32 - 237.2ms/batch - loss: 36.66110 - diff: 17.44mlTrain batch 16/32 - 240.0ms/batch - loss: 35.40712 - diff: 17.16mlTrain batch 17/32 - 237.2ms/batch - loss: 35.02103 - diff: 17.16mlTrain batch 18/32 - 240.5ms/batch - loss: 34.16095 - diff: 17.04mlTrain batch 19/32 - 237.4ms/batch - loss: 34.47971 - diff: 17.37mlTrain batch 20/32 - 240.2ms/batch - loss: 33.98499 - diff: 17.28mlTrain batch 21/32 - 237.2ms/batch - loss: 33.41017 - diff: 17.20mlTrain batch 22/32 - 240.5ms/batch - loss: 32.27013 - diff: 16.85mlTrain batch 23/32 - 237.3ms/batch - loss: 31.91195 - diff: 16.80mlTrain batch 24/32 - 239.8ms/batch - loss: 32.24604 - diff: 17.00mlTrain batch 25/32 - 237.8ms/batch - loss: 31.86201 - diff: 16.95mlTrain batch 26/32 - 240.4ms/batch - loss: 32.11636 - diff: 17.02mlTrain batch 27/32 - 238.0ms/batch - loss: 32.27473 - diff: 17.13mlTrain batch 28/32 - 240.3ms/batch - loss: 31.66687 - diff: 16.99mlTrain batch 29/32 - 238.2ms/batch - loss: 31.68823 - diff: 16.97mlTrain batch 30/32 - 240.3ms/batch - loss: 31.31888 - diff: 16.89mlTrain batch 31/32 - 238.6ms/batch - loss: 30.85682 - diff: 16.68mlTrain batch 32/32 - 77.7ms/batch - loss: 31.69548 - diff: 16.73mlTrain batch 32/32 - 10.7s 77.7ms/batch - loss: 31.69548 - diff: 16.73ml
Test 1.1s: val_loss: 34.89543 - diff: 16.80ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Systole_WideResNet50_0_Adam-0.001_MSE_DA3_best

Epoch 131: current best loss = 34.89543, at epoch 130
Train batch 1/32 - 254.2ms/batch - loss: 31.23309 - diff: 19.08mlTrain batch 2/32 - 237.5ms/batch - loss: 25.90494 - diff: 16.27mlTrain batch 3/32 - 237.3ms/batch - loss: 23.19045 - diff: 15.39mlTrain batch 4/32 - 237.9ms/batch - loss: 27.10756 - diff: 16.04mlTrain batch 5/32 - 237.7ms/batch - loss: 24.84766 - diff: 15.33mlTrain batch 6/32 - 239.8ms/batch - loss: 23.30547 - diff: 14.97mlTrain batch 7/32 - 238.0ms/batch - loss: 25.26341 - diff: 15.55mlTrain batch 8/32 - 240.2ms/batch - loss: 27.61789 - diff: 15.74mlTrain batch 9/32 - 237.3ms/batch - loss: 28.08581 - diff: 16.14mlTrain batch 10/32 - 238.8ms/batch - loss: 30.75128 - diff: 16.78mlTrain batch 11/32 - 237.4ms/batch - loss: 30.39815 - diff: 16.73mlTrain batch 12/32 - 239.2ms/batch - loss: 29.12467 - diff: 16.23mlTrain batch 13/32 - 238.6ms/batch - loss: 27.87585 - diff: 15.91mlTrain batch 14/32 - 239.7ms/batch - loss: 28.89568 - diff: 16.10mlTrain batch 15/32 - 237.5ms/batch - loss: 27.62954 - diff: 15.60mlTrain batch 16/32 - 238.2ms/batch - loss: 37.23318 - diff: 16.81mlTrain batch 17/32 - 237.4ms/batch - loss: 36.50735 - diff: 16.73mlTrain batch 18/32 - 240.0ms/batch - loss: 36.83334 - diff: 16.98mlTrain batch 19/32 - 237.0ms/batch - loss: 36.18124 - diff: 16.83mlTrain batch 20/32 - 240.3ms/batch - loss: 35.50077 - diff: 16.67mlTrain batch 21/32 - 237.2ms/batch - loss: 34.76924 - diff: 16.57mlTrain batch 22/32 - 240.1ms/batch - loss: 34.42183 - diff: 16.52mlTrain batch 23/32 - 237.4ms/batch - loss: 33.58272 - diff: 16.29mlTrain batch 24/32 - 240.2ms/batch - loss: 33.08041 - diff: 16.22mlTrain batch 25/32 - 237.4ms/batch - loss: 33.04646 - diff: 16.25mlTrain batch 26/32 - 240.1ms/batch - loss: 32.40035 - diff: 16.08mlTrain batch 27/32 - 237.7ms/batch - loss: 32.30280 - diff: 16.13mlTrain batch 28/32 - 240.2ms/batch - loss: 31.79086 - diff: 16.00mlTrain batch 29/32 - 237.7ms/batch - loss: 32.21942 - diff: 16.16mlTrain batch 30/32 - 240.1ms/batch - loss: 31.96866 - diff: 16.15mlTrain batch 31/32 - 237.5ms/batch - loss: 31.55801 - diff: 16.01mlTrain batch 32/32 - 77.1ms/batch - loss: 31.88956 - diff: 16.00mlTrain batch 32/32 - 10.6s 77.1ms/batch - loss: 31.88956 - diff: 16.00ml
Test 1.1s: val_loss: 101.30692 - diff: 26.05ml

Epoch 132: current best loss = 34.89543, at epoch 130
Train batch 1/32 - 237.7ms/batch - loss: 17.30644 - diff: 14.41mlTrain batch 2/32 - 240.1ms/batch - loss: 15.52248 - diff: 13.24mlTrain batch 3/32 - 238.0ms/batch - loss: 25.00326 - diff: 16.19mlTrain batch 4/32 - 239.7ms/batch - loss: 24.87269 - diff: 15.70mlTrain batch 5/32 - 237.8ms/batch - loss: 24.43134 - diff: 15.58mlTrain batch 6/32 - 239.7ms/batch - loss: 25.07476 - diff: 15.75mlTrain batch 7/32 - 238.2ms/batch - loss: 24.76030 - diff: 15.73mlTrain batch 8/32 - 239.1ms/batch - loss: 23.87407 - diff: 15.28mlTrain batch 9/32 - 237.0ms/batch - loss: 23.07451 - diff: 15.04mlTrain batch 10/32 - 237.9ms/batch - loss: 24.00734 - diff: 15.35mlTrain batch 11/32 - 237.4ms/batch - loss: 29.32517 - diff: 16.06mlTrain batch 12/32 - 240.1ms/batch - loss: 28.12430 - diff: 15.77mlTrain batch 13/32 - 238.0ms/batch - loss: 27.61840 - diff: 15.73mlTrain batch 14/32 - 240.1ms/batch - loss: 28.19466 - diff: 15.89mlTrain batch 15/32 - 237.0ms/batch - loss: 27.73831 - diff: 15.87mlTrain batch 16/32 - 240.1ms/batch - loss: 27.56512 - diff: 15.90mlTrain batch 17/32 - 237.6ms/batch - loss: 26.90476 - diff: 15.67mlTrain batch 18/32 - 240.0ms/batch - loss: 26.44025 - diff: 15.56mlTrain batch 19/32 - 237.5ms/batch - loss: 25.79348 - diff: 15.34mlTrain batch 20/32 - 240.1ms/batch - loss: 25.90510 - diff: 15.26mlTrain batch 21/32 - 237.8ms/batch - loss: 26.41185 - diff: 15.40mlTrain batch 22/32 - 240.1ms/batch - loss: 25.72441 - diff: 15.21mlTrain batch 23/32 - 237.8ms/batch - loss: 25.66727 - diff: 15.26mlTrain batch 24/32 - 240.3ms/batch - loss: 25.58182 - diff: 15.27mlTrain batch 25/32 - 237.5ms/batch - loss: 25.38961 - diff: 15.26mlTrain batch 26/32 - 239.0ms/batch - loss: 25.35926 - diff: 15.21mlTrain batch 27/32 - 238.1ms/batch - loss: 25.51848 - diff: 15.33mlTrain batch 28/32 - 239.9ms/batch - loss: 25.40442 - diff: 15.34mlTrain batch 29/32 - 238.2ms/batch - loss: 24.98422 - diff: 15.22mlTrain batch 30/32 - 239.9ms/batch - loss: 24.84880 - diff: 15.15mlTrain batch 31/32 - 237.5ms/batch - loss: 25.22853 - diff: 15.18mlTrain batch 32/32 - 76.7ms/batch - loss: 25.65708 - diff: 15.18mlTrain batch 32/32 - 10.6s 76.7ms/batch - loss: 25.65708 - diff: 15.18ml
Test 1.2s: val_loss: 39.76155 - diff: 17.47ml

Epoch 133: current best loss = 34.89543, at epoch 130
Train batch 1/32 - 236.8ms/batch - loss: 13.82032 - diff: 13.06mlTrain batch 2/32 - 237.4ms/batch - loss: 19.42663 - diff: 14.94mlTrain batch 3/32 - 237.0ms/batch - loss: 17.45988 - diff: 13.59mlTrain batch 4/32 - 240.2ms/batch - loss: 24.62558 - diff: 15.27mlTrain batch 5/32 - 237.3ms/batch - loss: 27.03546 - diff: 16.32mlTrain batch 6/32 - 239.3ms/batch - loss: 26.92425 - diff: 16.39mlTrain batch 7/32 - 237.9ms/batch - loss: 27.61651 - diff: 16.72mlTrain batch 8/32 - 239.7ms/batch - loss: 25.36022 - diff: 15.90mlTrain batch 9/32 - 237.1ms/batch - loss: 25.62395 - diff: 16.04mlTrain batch 10/32 - 238.6ms/batch - loss: 29.49334 - diff: 16.59mlTrain batch 11/32 - 238.7ms/batch - loss: 28.71717 - diff: 16.27mlTrain batch 12/32 - 240.0ms/batch - loss: 27.47304 - diff: 15.97mlTrain batch 13/32 - 237.3ms/batch - loss: 26.84429 - diff: 15.75mlTrain batch 14/32 - 237.6ms/batch - loss: 27.64126 - diff: 16.07mlTrain batch 15/32 - 237.7ms/batch - loss: 26.80389 - diff: 15.83mlTrain batch 16/32 - 240.1ms/batch - loss: 26.96823 - diff: 15.93mlTrain batch 17/32 - 238.2ms/batch - loss: 27.63464 - diff: 16.20mlTrain batch 18/32 - 240.3ms/batch - loss: 26.59850 - diff: 15.86mlTrain batch 19/32 - 237.2ms/batch - loss: 27.01265 - diff: 15.88mlTrain batch 20/32 - 240.2ms/batch - loss: 27.51276 - diff: 15.97mlTrain batch 21/32 - 237.3ms/batch - loss: 27.34364 - diff: 16.03mlTrain batch 22/32 - 240.4ms/batch - loss: 27.86082 - diff: 16.21mlTrain batch 23/32 - 237.5ms/batch - loss: 27.44147 - diff: 16.14mlTrain batch 24/32 - 239.8ms/batch - loss: 27.33804 - diff: 16.20mlTrain batch 25/32 - 237.9ms/batch - loss: 27.09460 - diff: 16.12mlTrain batch 26/32 - 239.4ms/batch - loss: 27.21791 - diff: 16.13mlTrain batch 27/32 - 237.5ms/batch - loss: 26.93174 - diff: 16.04mlTrain batch 28/32 - 239.5ms/batch - loss: 26.34858 - diff: 15.85mlTrain batch 29/32 - 238.6ms/batch - loss: 25.95131 - diff: 15.73mlTrain batch 30/32 - 240.0ms/batch - loss: 25.83028 - diff: 15.70mlTrain batch 31/32 - 238.5ms/batch - loss: 25.42187 - diff: 15.55mlTrain batch 32/32 - 77.3ms/batch - loss: 26.23731 - diff: 15.59mlTrain batch 32/32 - 10.7s 77.3ms/batch - loss: 26.23731 - diff: 15.59ml
Test 1.2s: val_loss: 38.75557 - diff: 17.78ml

Epoch 134: current best loss = 34.89543, at epoch 130
Train batch 1/32 - 237.3ms/batch - loss: 25.35299 - diff: 16.90mlTrain batch 2/32 - 240.2ms/batch - loss: 47.28402 - diff: 20.96mlTrain batch 3/32 - 237.1ms/batch - loss: 39.49851 - diff: 18.67mlTrain batch 4/32 - 240.4ms/batch - loss: 34.39103 - diff: 17.40mlTrain batch 5/32 - 237.5ms/batch - loss: 29.81579 - diff: 16.16mlTrain batch 6/32 - 240.0ms/batch - loss: 27.53176 - diff: 15.73mlTrain batch 7/32 - 238.2ms/batch - loss: 27.22855 - diff: 15.55mlTrain batch 8/32 - 240.3ms/batch - loss: 25.70185 - diff: 15.11mlTrain batch 9/32 - 238.1ms/batch - loss: 24.99471 - diff: 15.06mlTrain batch 10/32 - 239.1ms/batch - loss: 23.87107 - diff: 14.75mlTrain batch 11/32 - 238.2ms/batch - loss: 30.05512 - diff: 15.70mlTrain batch 12/32 - 239.8ms/batch - loss: 28.79476 - diff: 15.43mlTrain batch 13/32 - 237.6ms/batch - loss: 27.91148 - diff: 15.31mlTrain batch 14/32 - 240.2ms/batch - loss: 26.87665 - diff: 15.07mlTrain batch 15/32 - 236.9ms/batch - loss: 34.20696 - diff: 16.38mlTrain batch 16/32 - 240.3ms/batch - loss: 33.02297 - diff: 16.09mlTrain batch 17/32 - 237.4ms/batch - loss: 32.82010 - diff: 16.19mlTrain batch 18/32 - 240.4ms/batch - loss: 32.51691 - diff: 16.26mlTrain batch 19/32 - 237.3ms/batch - loss: 32.12602 - diff: 16.27mlTrain batch 20/32 - 240.0ms/batch - loss: 33.10453 - diff: 16.59mlTrain batch 21/32 - 237.3ms/batch - loss: 33.52081 - diff: 16.56mlTrain batch 22/32 - 239.8ms/batch - loss: 32.75434 - diff: 16.39mlTrain batch 23/32 - 237.9ms/batch - loss: 32.34013 - diff: 16.23mlTrain batch 24/32 - 240.4ms/batch - loss: 32.24557 - diff: 16.18mlTrain batch 25/32 - 238.1ms/batch - loss: 32.49775 - diff: 16.29mlTrain batch 26/32 - 240.5ms/batch - loss: 32.10949 - diff: 16.23mlTrain batch 27/32 - 237.5ms/batch - loss: 32.19857 - diff: 16.35mlTrain batch 28/32 - 239.3ms/batch - loss: 32.26973 - diff: 16.42mlTrain batch 29/32 - 238.7ms/batch - loss: 31.62417 - diff: 16.28mlTrain batch 30/32 - 240.0ms/batch - loss: 31.31064 - diff: 16.21mlTrain batch 31/32 - 238.6ms/batch - loss: 31.18279 - diff: 16.20mlTrain batch 32/32 - 77.7ms/batch - loss: 31.64235 - diff: 16.22mlTrain batch 32/32 - 10.7s 77.7ms/batch - loss: 31.64235 - diff: 16.22ml
Test 1.2s: val_loss: 39.66816 - diff: 17.46ml

Epoch 135: current best loss = 34.89543, at epoch 130
Train batch 1/32 - 237.0ms/batch - loss: 18.58935 - diff: 11.92mlTrain batch 2/32 - 237.9ms/batch - loss: 13.09372 - diff: 10.53mlTrain batch 3/32 - 237.2ms/batch - loss: 12.13096 - diff: 10.52mlTrain batch 4/32 - 240.0ms/batch - loss: 14.86926 - diff: 11.15mlTrain batch 5/32 - 237.2ms/batch - loss: 22.16603 - diff: 12.95mlTrain batch 6/32 - 240.2ms/batch - loss: 25.67626 - diff: 14.14mlTrain batch 7/32 - 237.4ms/batch - loss: 23.92404 - diff: 13.81mlTrain batch 8/32 - 240.3ms/batch - loss: 26.17316 - diff: 14.47mlTrain batch 9/32 - 237.8ms/batch - loss: 25.87295 - diff: 14.69mlTrain batch 10/32 - 240.1ms/batch - loss: 24.81541 - diff: 14.43mlTrain batch 11/32 - 238.0ms/batch - loss: 25.68502 - diff: 14.69mlTrain batch 12/32 - 240.2ms/batch - loss: 26.48372 - diff: 14.82mlTrain batch 13/32 - 237.9ms/batch - loss: 25.95401 - diff: 14.76mlTrain batch 14/32 - 239.9ms/batch - loss: 25.63941 - diff: 14.76mlTrain batch 15/32 - 237.6ms/batch - loss: 24.24984 - diff: 14.27mlTrain batch 16/32 - 239.7ms/batch - loss: 23.63403 - diff: 14.09mlTrain batch 17/32 - 238.7ms/batch - loss: 24.13020 - diff: 14.35mlTrain batch 18/32 - 239.5ms/batch - loss: 24.62560 - diff: 14.47mlTrain batch 19/32 - 237.4ms/batch - loss: 25.43277 - diff: 14.82mlTrain batch 20/32 - 237.9ms/batch - loss: 27.74774 - diff: 15.13mlTrain batch 21/32 - 237.6ms/batch - loss: 27.52738 - diff: 15.13mlTrain batch 22/32 - 240.1ms/batch - loss: 27.28561 - diff: 15.09mlTrain batch 23/32 - 238.1ms/batch - loss: 28.07431 - diff: 15.33mlTrain batch 24/32 - 240.4ms/batch - loss: 27.46230 - diff: 15.14mlTrain batch 25/32 - 237.4ms/batch - loss: 27.53393 - diff: 15.15mlTrain batch 26/32 - 240.4ms/batch - loss: 28.41253 - diff: 15.18mlTrain batch 27/32 - 237.5ms/batch - loss: 27.96588 - diff: 15.09mlTrain batch 28/32 - 240.1ms/batch - loss: 27.65987 - diff: 15.08mlTrain batch 29/32 - 237.1ms/batch - loss: 28.08673 - diff: 15.25mlTrain batch 30/32 - 240.0ms/batch - loss: 27.43369 - diff: 15.06mlTrain batch 31/32 - 238.1ms/batch - loss: 27.10963 - diff: 15.01mlTrain batch 32/32 - 78.2ms/batch - loss: 29.18253 - diff: 15.12mlTrain batch 32/32 - 10.7s 78.2ms/batch - loss: 29.18253 - diff: 15.12ml
Test 1.2s: val_loss: 47.33851 - diff: 18.58ml

Epoch 136: current best loss = 34.89543, at epoch 130
Train batch 1/32 - 237.3ms/batch - loss: 13.00311 - diff: 11.76mlTrain batch 2/32 - 237.5ms/batch - loss: 15.58308 - diff: 13.04mlTrain batch 3/32 - 236.9ms/batch - loss: 13.41916 - diff: 12.03mlTrain batch 4/32 - 239.9ms/batch - loss: 14.34418 - diff: 12.32mlTrain batch 5/32 - 237.1ms/batch - loss: 16.59880 - diff: 12.76mlTrain batch 6/32 - 240.0ms/batch - loss: 38.81592 - diff: 17.14mlTrain batch 7/32 - 238.3ms/batch - loss: 40.25108 - diff: 17.75mlTrain batch 8/32 - 240.2ms/batch - loss: 39.96303 - diff: 18.00mlTrain batch 9/32 - 236.9ms/batch - loss: 37.35288 - diff: 17.41mlTrain batch 10/32 - 240.3ms/batch - loss: 36.48972 - diff: 17.38mlTrain batch 11/32 - 237.4ms/batch - loss: 35.44569 - diff: 17.37mlTrain batch 12/32 - 240.2ms/batch - loss: 35.62714 - diff: 17.53mlTrain batch 13/32 - 237.4ms/batch - loss: 34.19098 - diff: 17.14mlTrain batch 14/32 - 239.8ms/batch - loss: 35.13851 - diff: 17.37mlTrain batch 15/32 - 238.3ms/batch - loss: 34.56784 - diff: 17.22mlTrain batch 16/32 - 240.3ms/batch - loss: 34.30799 - diff: 17.15mlTrain batch 17/32 - 237.6ms/batch - loss: 39.12569 - diff: 17.97mlTrain batch 18/32 - 239.2ms/batch - loss: 40.10100 - diff: 18.33mlTrain batch 19/32 - 238.4ms/batch - loss: 39.71112 - diff: 18.25mlTrain batch 20/32 - 239.8ms/batch - loss: 39.54791 - diff: 18.37mlTrain batch 21/32 - 238.4ms/batch - loss: 38.29135 - diff: 18.06mlTrain batch 22/32 - 240.1ms/batch - loss: 37.96192 - diff: 18.04mlTrain batch 23/32 - 237.4ms/batch - loss: 37.93951 - diff: 18.01mlTrain batch 24/32 - 239.6ms/batch - loss: 36.86180 - diff: 17.70mlTrain batch 25/32 - 238.2ms/batch - loss: 36.32854 - diff: 17.56mlTrain batch 26/32 - 240.3ms/batch - loss: 35.61853 - diff: 17.45mlTrain batch 27/32 - 237.5ms/batch - loss: 34.73925 - diff: 17.22mlTrain batch 28/32 - 240.5ms/batch - loss: 34.87480 - diff: 17.23mlTrain batch 29/32 - 237.4ms/batch - loss: 34.56179 - diff: 17.19mlTrain batch 30/32 - 240.1ms/batch - loss: 34.64725 - diff: 17.25mlTrain batch 31/32 - 237.3ms/batch - loss: 34.28154 - diff: 17.20mlTrain batch 32/32 - 77.5ms/batch - loss: 34.11443 - diff: 17.10mlTrain batch 32/32 - 10.6s 77.5ms/batch - loss: 34.11443 - diff: 17.10ml
Test 1.2s: val_loss: 37.84531 - diff: 16.56ml

Epoch 137: current best loss = 34.89543, at epoch 130
Train batch 1/32 - 237.2ms/batch - loss: 13.72863 - diff: 11.73mlTrain batch 2/32 - 239.8ms/batch - loss: 17.79839 - diff: 13.30mlTrain batch 3/32 - 237.4ms/batch - loss: 27.85258 - diff: 15.25mlTrain batch 4/32 - 239.2ms/batch - loss: 26.70138 - diff: 14.59mlTrain batch 5/32 - 238.2ms/batch - loss: 25.05289 - diff: 14.33mlTrain batch 6/32 - 240.0ms/batch - loss: 23.09152 - diff: 13.86mlTrain batch 7/32 - 238.5ms/batch - loss: 22.60643 - diff: 13.65mlTrain batch 8/32 - 239.8ms/batch - loss: 22.12197 - diff: 13.73mlTrain batch 9/32 - 237.0ms/batch - loss: 20.87044 - diff: 13.26mlTrain batch 10/32 - 240.1ms/batch - loss: 20.79836 - diff: 13.29mlTrain batch 11/32 - 237.3ms/batch - loss: 21.58512 - diff: 13.55mlTrain batch 12/32 - 239.7ms/batch - loss: 21.23887 - diff: 13.56mlTrain batch 13/32 - 238.1ms/batch - loss: 21.84291 - diff: 13.79mlTrain batch 14/32 - 240.2ms/batch - loss: 22.20753 - diff: 13.79mlTrain batch 15/32 - 237.3ms/batch - loss: 22.75999 - diff: 14.05mlTrain batch 16/32 - 240.6ms/batch - loss: 23.80895 - diff: 14.44mlTrain batch 17/32 - 237.3ms/batch - loss: 24.30351 - diff: 14.59mlTrain batch 18/32 - 240.0ms/batch - loss: 23.59145 - diff: 14.30mlTrain batch 19/32 - 237.1ms/batch - loss: 23.98305 - diff: 14.36mlTrain batch 20/32 - 240.0ms/batch - loss: 23.72349 - diff: 14.36mlTrain batch 21/32 - 238.1ms/batch - loss: 23.27825 - diff: 14.24mlTrain batch 22/32 - 240.4ms/batch - loss: 22.82145 - diff: 14.15mlTrain batch 23/32 - 237.4ms/batch - loss: 22.83191 - diff: 14.16mlTrain batch 24/32 - 239.8ms/batch - loss: 22.44498 - diff: 14.10mlTrain batch 25/32 - 237.9ms/batch - loss: 22.20617 - diff: 14.04mlTrain batch 26/32 - 239.5ms/batch - loss: 22.72565 - diff: 14.16mlTrain batch 27/32 - 238.1ms/batch - loss: 22.51531 - diff: 14.15mlTrain batch 28/32 - 239.9ms/batch - loss: 22.60108 - diff: 14.10mlTrain batch 29/32 - 238.4ms/batch - loss: 23.76347 - diff: 14.43mlTrain batch 30/32 - 239.9ms/batch - loss: 23.42062 - diff: 14.30mlTrain batch 31/32 - 238.8ms/batch - loss: 23.93926 - diff: 14.50mlTrain batch 32/32 - 77.8ms/batch - loss: 24.35402 - diff: 14.49mlTrain batch 32/32 - 10.6s 77.8ms/batch - loss: 24.35402 - diff: 14.49ml
Test 1.2s: val_loss: 41.06457 - diff: 16.45ml

Epoch 138: current best loss = 34.89543, at epoch 130
Train batch 1/32 - 237.0ms/batch - loss: 12.57362 - diff: 10.55mlTrain batch 2/32 - 238.1ms/batch - loss: 46.12645 - diff: 17.82mlTrain batch 3/32 - 237.2ms/batch - loss: 52.05141 - diff: 20.28mlTrain batch 4/32 - 240.1ms/batch - loss: 45.45390 - diff: 19.07mlTrain batch 5/32 - 237.0ms/batch - loss: 39.59316 - diff: 17.25mlTrain batch 6/32 - 240.2ms/batch - loss: 40.92411 - diff: 17.50mlTrain batch 7/32 - 248.8ms/batch - loss: 38.30736 - diff: 17.11mlTrain batch 8/32 - 237.6ms/batch - loss: 36.30875 - diff: 16.73mlTrain batch 9/32 - 237.7ms/batch - loss: 34.23087 - diff: 16.33mlTrain batch 10/32 - 240.2ms/batch - loss: 33.61400 - diff: 16.32mlTrain batch 11/32 - 238.0ms/batch - loss: 33.20074 - diff: 16.32mlTrain batch 12/32 - 240.4ms/batch - loss: 32.40106 - diff: 16.30mlTrain batch 13/32 - 237.9ms/batch - loss: 30.98287 - diff: 16.05mlTrain batch 14/32 - 240.2ms/batch - loss: 30.24189 - diff: 15.98mlTrain batch 15/32 - 238.1ms/batch - loss: 29.18607 - diff: 15.71mlTrain batch 16/32 - 239.9ms/batch - loss: 28.19478 - diff: 15.34mlTrain batch 17/32 - 238.2ms/batch - loss: 28.60475 - diff: 15.40mlTrain batch 18/32 - 239.9ms/batch - loss: 28.12095 - diff: 15.37mlTrain batch 19/32 - 238.6ms/batch - loss: 27.07301 - diff: 15.01mlTrain batch 20/32 - 239.3ms/batch - loss: 26.70608 - diff: 14.92mlTrain batch 21/32 - 238.7ms/batch - loss: 26.10991 - diff: 14.80mlTrain batch 22/32 - 239.2ms/batch - loss: 27.43935 - diff: 15.17mlTrain batch 23/32 - 237.5ms/batch - loss: 26.81630 - diff: 15.02mlTrain batch 24/32 - 240.2ms/batch - loss: 27.29648 - diff: 15.18mlTrain batch 25/32 - 238.7ms/batch - loss: 27.25282 - diff: 15.21mlTrain batch 26/32 - 240.2ms/batch - loss: 27.48477 - diff: 15.28mlTrain batch 27/32 - 238.2ms/batch - loss: 27.33676 - diff: 15.23mlTrain batch 28/32 - 240.4ms/batch - loss: 27.76279 - diff: 15.26mlTrain batch 29/32 - 237.8ms/batch - loss: 27.90577 - diff: 15.29mlTrain batch 30/32 - 240.0ms/batch - loss: 27.96246 - diff: 15.40mlTrain batch 31/32 - 237.5ms/batch - loss: 27.96727 - diff: 15.50mlTrain batch 32/32 - 78.6ms/batch - loss: 29.65001 - diff: 15.59mlTrain batch 32/32 - 10.6s 78.6ms/batch - loss: 29.65001 - diff: 15.59ml
Test 1.2s: val_loss: 74.51973 - diff: 21.64ml

Epoch 139: current best loss = 34.89543, at epoch 130
Train batch 1/32 - 238.0ms/batch - loss: 24.31378 - diff: 16.99mlTrain batch 2/32 - 240.2ms/batch - loss: 26.17319 - diff: 17.05mlTrain batch 3/32 - 238.0ms/batch - loss: 24.35161 - diff: 15.53mlTrain batch 4/32 - 240.2ms/batch - loss: 29.17048 - diff: 16.59mlTrain batch 5/32 - 237.7ms/batch - loss: 25.94567 - diff: 15.26mlTrain batch 6/32 - 239.5ms/batch - loss: 24.84698 - diff: 15.10mlTrain batch 7/32 - 238.5ms/batch - loss: 24.74164 - diff: 15.24mlTrain batch 8/32 - 240.1ms/batch - loss: 24.79203 - diff: 15.34mlTrain batch 9/32 - 237.0ms/batch - loss: 25.17783 - diff: 15.45mlTrain batch 10/32 - 237.8ms/batch - loss: 26.35642 - diff: 15.72mlTrain batch 11/32 - 237.0ms/batch - loss: 25.21002 - diff: 15.29mlTrain batch 12/32 - 240.5ms/batch - loss: 26.16346 - diff: 15.47mlTrain batch 13/32 - 238.1ms/batch - loss: 26.42149 - diff: 15.64mlTrain batch 14/32 - 240.2ms/batch - loss: 25.32591 - diff: 15.36mlTrain batch 15/32 - 237.2ms/batch - loss: 25.21348 - diff: 15.36mlTrain batch 16/32 - 240.7ms/batch - loss: 24.55132 - diff: 15.17mlTrain batch 17/32 - 237.4ms/batch - loss: 24.16926 - diff: 15.11mlTrain batch 18/32 - 240.2ms/batch - loss: 24.13248 - diff: 15.04mlTrain batch 19/32 - 237.1ms/batch - loss: 23.49296 - diff: 14.88mlTrain batch 20/32 - 239.9ms/batch - loss: 23.84255 - diff: 15.02mlTrain batch 21/32 - 237.8ms/batch - loss: 23.28158 - diff: 14.86mlTrain batch 22/32 - 240.3ms/batch - loss: 23.57631 - diff: 14.90mlTrain batch 23/32 - 237.5ms/batch - loss: 24.58356 - diff: 15.05mlTrain batch 24/32 - 240.2ms/batch - loss: 25.22973 - diff: 15.24mlTrain batch 25/32 - 237.8ms/batch - loss: 24.75139 - diff: 15.11mlTrain batch 26/32 - 239.7ms/batch - loss: 24.59650 - diff: 15.07mlTrain batch 27/32 - 238.7ms/batch - loss: 24.65382 - diff: 14.96mlTrain batch 28/32 - 240.3ms/batch - loss: 25.76518 - diff: 15.28mlTrain batch 29/32 - 237.7ms/batch - loss: 26.04486 - diff: 15.48mlTrain batch 30/32 - 240.9ms/batch - loss: 25.73782 - diff: 15.39mlTrain batch 31/32 - 237.1ms/batch - loss: 26.13343 - diff: 15.44mlTrain batch 32/32 - 76.9ms/batch - loss: 26.49104 - diff: 15.42mlTrain batch 32/32 - 10.6s 76.9ms/batch - loss: 26.49104 - diff: 15.42ml
Test 1.2s: val_loss: 34.41095 - diff: 17.25ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Systole_WideResNet50_0_Adam-0.001_MSE_DA3_best

Epoch 140: current best loss = 34.41095, at epoch 139
Train batch 1/32 - 237.1ms/batch - loss: 16.33699 - diff: 13.17mlTrain batch 2/32 - 237.6ms/batch - loss: 18.63808 - diff: 13.74mlTrain batch 3/32 - 238.2ms/batch - loss: 16.39067 - diff: 12.89mlTrain batch 4/32 - 239.5ms/batch - loss: 14.54088 - diff: 12.19mlTrain batch 5/32 - 237.1ms/batch - loss: 16.61587 - diff: 12.61mlTrain batch 6/32 - 240.0ms/batch - loss: 15.89160 - diff: 12.32mlTrain batch 7/32 - 238.3ms/batch - loss: 15.65233 - diff: 12.11mlTrain batch 8/32 - 240.2ms/batch - loss: 16.41602 - diff: 12.38mlTrain batch 9/32 - 238.1ms/batch - loss: 16.21723 - diff: 12.33mlTrain batch 10/32 - 240.1ms/batch - loss: 24.26180 - diff: 14.17mlTrain batch 11/32 - 237.4ms/batch - loss: 23.56277 - diff: 14.09mlTrain batch 12/32 - 240.1ms/batch - loss: 23.47961 - diff: 14.33mlTrain batch 13/32 - 237.6ms/batch - loss: 22.41248 - diff: 13.99mlTrain batch 14/32 - 240.0ms/batch - loss: 22.04148 - diff: 13.90mlTrain batch 15/32 - 238.0ms/batch - loss: 22.06815 - diff: 14.03mlTrain batch 16/32 - 240.4ms/batch - loss: 25.46191 - diff: 14.58mlTrain batch 17/32 - 237.9ms/batch - loss: 26.67449 - diff: 14.89mlTrain batch 18/32 - 240.4ms/batch - loss: 26.45330 - diff: 14.93mlTrain batch 19/32 - 237.2ms/batch - loss: 26.01469 - diff: 14.83mlTrain batch 20/32 - 239.7ms/batch - loss: 25.92035 - diff: 14.87mlTrain batch 21/32 - 238.2ms/batch - loss: 25.35907 - diff: 14.72mlTrain batch 22/32 - 238.8ms/batch - loss: 26.23958 - diff: 14.84mlTrain batch 23/32 - 238.2ms/batch - loss: 26.41173 - diff: 15.02mlTrain batch 24/32 - 238.9ms/batch - loss: 26.94122 - diff: 15.19mlTrain batch 25/32 - 237.5ms/batch - loss: 26.75522 - diff: 15.19mlTrain batch 26/32 - 240.3ms/batch - loss: 29.02392 - diff: 15.63mlTrain batch 27/32 - 238.4ms/batch - loss: 28.90082 - diff: 15.70mlTrain batch 28/32 - 240.2ms/batch - loss: 28.12203 - diff: 15.47mlTrain batch 29/32 - 237.4ms/batch - loss: 28.05414 - diff: 15.49mlTrain batch 30/32 - 240.4ms/batch - loss: 28.19126 - diff: 15.51mlTrain batch 31/32 - 237.4ms/batch - loss: 28.62505 - diff: 15.73mlTrain batch 32/32 - 79.1ms/batch - loss: 28.56932 - diff: 15.67mlTrain batch 32/32 - 10.6s 79.1ms/batch - loss: 28.56932 - diff: 15.67ml
Test 1.2s: val_loss: 38.91052 - diff: 17.80ml

Epoch 141: current best loss = 34.41095, at epoch 139
Train batch 1/32 - 237.6ms/batch - loss: 34.44010 - diff: 16.57mlTrain batch 2/32 - 240.0ms/batch - loss: 32.42965 - diff: 16.83mlTrain batch 3/32 - 238.0ms/batch - loss: 26.37136 - diff: 15.69mlTrain batch 4/32 - 240.1ms/batch - loss: 26.23301 - diff: 15.05mlTrain batch 5/32 - 238.1ms/batch - loss: 23.70901 - diff: 14.50mlTrain batch 6/32 - 240.1ms/batch - loss: 21.86571 - diff: 14.03mlTrain batch 7/32 - 237.6ms/batch - loss: 22.56484 - diff: 13.98mlTrain batch 8/32 - 238.0ms/batch - loss: 23.22863 - diff: 14.43mlTrain batch 9/32 - 237.2ms/batch - loss: 21.79860 - diff: 13.94mlTrain batch 10/32 - 240.1ms/batch - loss: 22.45901 - diff: 13.97mlTrain batch 11/32 - 237.6ms/batch - loss: 24.42094 - diff: 14.44mlTrain batch 12/32 - 240.3ms/batch - loss: 24.88672 - diff: 14.62mlTrain batch 13/32 - 237.4ms/batch - loss: 24.51185 - diff: 14.58mlTrain batch 14/32 - 240.2ms/batch - loss: 24.79826 - diff: 14.71mlTrain batch 15/32 - 237.1ms/batch - loss: 23.94016 - diff: 14.47mlTrain batch 16/32 - 239.9ms/batch - loss: 23.97379 - diff: 14.60mlTrain batch 17/32 - 237.6ms/batch - loss: 23.03349 - diff: 14.27mlTrain batch 18/32 - 240.3ms/batch - loss: 23.63754 - diff: 14.39mlTrain batch 19/32 - 237.7ms/batch - loss: 24.81966 - diff: 14.58mlTrain batch 20/32 - 239.4ms/batch - loss: 27.97772 - diff: 15.14mlTrain batch 21/32 - 238.2ms/batch - loss: 28.62950 - diff: 15.37mlTrain batch 22/32 - 240.0ms/batch - loss: 28.19345 - diff: 15.25mlTrain batch 23/32 - 238.9ms/batch - loss: 27.82389 - diff: 15.17mlTrain batch 24/32 - 239.9ms/batch - loss: 27.09033 - diff: 14.92mlTrain batch 25/32 - 237.4ms/batch - loss: 26.66025 - diff: 14.87mlTrain batch 26/32 - 239.4ms/batch - loss: 27.46422 - diff: 15.10mlTrain batch 27/32 - 238.6ms/batch - loss: 27.35527 - diff: 15.16mlTrain batch 28/32 - 240.3ms/batch - loss: 27.21491 - diff: 15.09mlTrain batch 29/32 - 237.4ms/batch - loss: 27.90284 - diff: 15.26mlTrain batch 30/32 - 240.5ms/batch - loss: 27.88325 - diff: 15.34mlTrain batch 31/32 - 237.4ms/batch - loss: 28.15965 - diff: 15.54mlTrain batch 32/32 - 78.9ms/batch - loss: 30.17353 - diff: 15.66mlTrain batch 32/32 - 10.7s 78.9ms/batch - loss: 30.17353 - diff: 15.66ml
Test 1.1s: val_loss: 33.72785 - diff: 16.33ml
Saving new best model in models/checkpoints/2CH_preproc1_150x150_bySlices_dataset_allViews_Systole_WideResNet50_0_Adam-0.001_MSE_DA3_best

Epoch 142: current best loss = 33.72785, at epoch 141
Train batch 1/32 - 247.9ms/batch - loss: 23.66405 - diff: 13.22mlTrain batch 2/32 - 237.5ms/batch - loss: 23.38088 - diff: 13.78mlTrain batch 3/32 - 237.3ms/batch - loss: 26.09582 - diff: 14.62mlTrain batch 4/32 - 239.8ms/batch - loss: 27.83616 - diff: 15.37mlTrain batch 5/32 - 237.7ms/batch - loss: 27.13496 - diff: 15.20mlTrain batch 6/32 - 240.3ms/batch - loss: 30.47778 - diff: 16.19mlTrain batch 7/32 - 237.0ms/batch - loss: 29.74770 - diff: 16.15mlTrain batch 8/32 - 238.4ms/batch - loss: 27.98402 - diff: 15.78mlTrain batch 9/32 - 237.3ms/batch - loss: 26.66664 - diff: 15.40mlTrain batch 10/32 - 239.2ms/batch - loss: 28.60591 - diff: 16.11mlTrain batch 11/32 - 238.6ms/batch - loss: 28.23491 - diff: 16.00mlTrain batch 12/32 - 239.0ms/batch - loss: 26.64357 - diff: 15.50mlTrain batch 13/32 - 238.3ms/batch - loss: 26.58063 - diff: 15.67mlTrain batch 14/32 - 237.5ms/batch - loss: 26.96758 - diff: 15.80mlTrain batch 15/32 - 236.9ms/batch - loss: 26.58102 - diff: 15.82mlTrain batch 16/32 - 240.1ms/batch - loss: 26.11606 - diff: 15.64mlTrain batch 17/32 - 237.3ms/batch - loss: 25.41930 - diff: 15.41mlTrain batch 18/32 - 240.1ms/batch - loss: 26.20807 - diff: 15.62mlTrain batch 19/32 - 237.2ms/batch - loss: 25.89995 - diff: 15.51mlTrain batch 20/32 - 240.1ms/batch - loss: 25.12817 - diff: 15.20mlTrain batch 21/32 - 237.8ms/batch - loss: 25.11631 - diff: 15.29mlTrain batch 22/32 - 239.9ms/batch - loss: 24.74205 - diff: 15.15mlTrain batch 23/32 - 243.2ms/batch - loss: 24.29539 - diff: 15.06mlTrain batch 24/32 - 237.9ms/batch - loss: 24.43403 - diff: 15.09mlTrain batch 25/32 - 240.7ms/batch - loss: 24.33156 - diff: 15.06mlTrain batch 26/32 - 237.6ms/batch - loss: 24.72354 - diff: 15.14mlTrain batch 27/32 - 238.2ms/batch - loss: 24.79155 - diff: 15.13mlTrain batch 28/32 - 239.0ms/batch - loss: 24.27758 - diff: 14.98mlTrain batch 29/32 - 238.3ms/batch - loss: 24.02357 - diff: 14.94mlTrain batch 30/32 - 239.8ms/batch - loss: 24.41575 - diff: 15.14mlTrain batch 31/32 - 238.2ms/batch - loss: 24.80688 - diff: 15.16mlTrain batch 32/32 - 77.5ms/batch - loss: 25.35249 - diff: 15.16mlTrain batch 32/32 - 10.7s 77.5ms/batch - loss: 25.35249 - diff: 15.16ml
Test 1.1s: val_loss: 36.62146 - diff: 16.66ml

Epoch 143: current best loss = 33.72785, at epoch 141
Train batch 1/32 - 236.9ms/batch - loss: 21.87380 - diff: 15.35mlTrain batch 2/32 - 237.5ms/batch - loss: 17.23993 - diff: 13.43mlTrain batch 3/32 - 237.8ms/batch - loss: 22.41691 - diff: 13.96mlTrain batch 4/32 - 237.3ms/batch - loss: 19.67144 - diff: 13.31mlTrain batch 5/32 - 237.2ms/batch - loss: 19.30791 - diff: 13.10mlTrain batch 6/32 - 240.1ms/batch - loss: 21.73092 - diff: 13.97mlTrain batch 7/32 - 237.2ms/batch - loss: 27.05769 - diff: 14.85mlTrain batch 8/32 - 240.3ms/batch - loss: 25.44575 - diff: 14.37mlTrain batch 9/32 - 237.8ms/batch - loss: 23.53084 - diff: 13.93mlTrain batch 10/32 - 240.0ms/batch - loss: 25.31293 - diff: 14.75mlTrain batch 11/32 - 237.3ms/batch - loss: 23.88716 - diff: 14.34mlTrain batch 12/32 - 238.6ms/batch - loss: 23.27705 - diff: 14.31mlTrain batch 13/32 - 237.3ms/batch - loss: 25.03445 - diff: 14.81mlTrain batch 14/32 - 239.7ms/batch - loss: 24.78291 - diff: 14.84mlTrain batch 15/32 - 237.1ms/batch - loss: 25.17923 - diff: 15.09mlTrain batch 16/32 - 240.0ms/batch - loss: 25.45275 - diff: 15.20mlTrain batch 17/32 - 238.0ms/batch - loss: 25.07869 - diff: 15.07mlTrain batch 18/32 - 237.8ms/batch - loss: 24.80482 - diff: 15.02mlTrain batch 19/32 - 237.5ms/batch - loss: 24.52255 - diff: 14.93mlTrain batch 20/32 - 240.2ms/batch - loss: 24.24108 - diff: 14.87mlTrain batch 21/32 - 237.4ms/batch - loss: 23.69179 - diff: 14.70mlTrain batch 22/32 - 240.5ms/batch - loss: 24.02402 - diff: 14.88mlTrain batch 23/32 - 237.1ms/batch - loss: 23.49635 - diff: 14.73mlTrain batch 24/32 - 240.6ms/batch - loss: 22.76437 - diff: 14.43mlTrain batch 25/32 - 237.3ms/batch - loss: 22.82659 - diff: 14.45mlTrain batch 26/32 - 239.9ms/batch - loss: 22.38059 - diff: 14.34mlTrain batch 27/32 - 237.9ms/batch - loss: 22.04371 - diff: 14.29mlTrain batch 28/32 - 240.1ms/batch - loss: 22.03072 - diff: 14.29mlTrain batch 29/32 - 237.9ms/batch - loss: 21.80747 - diff: 14.27mlTrain batch 30/32 - 240.1ms/batch - loss: 22.15942 - diff: 14.35mlTrain batch 31/32 - 237.5ms/batch - loss: 22.15614 - diff: 14.27mlTrain batch 32/32 - 76.8ms/batch - loss: 22.41258 - diff: 14.27mlTrain batch 32/32 - 10.7s 76.8ms/batch - loss: 22.41258 - diff: 14.27ml
Test 1.1s: val_loss: 42.36617 - diff: 17.82ml

Epoch 144: current best loss = 33.72785, at epoch 141
Train batch 1/32 - 237.0ms/batch - loss: 18.55263 - diff: 13.34mlTrain batch 2/32 - 238.4ms/batch - loss: 16.15695 - diff: 12.50mlTrain batch 3/32 - 237.9ms/batch - loss: 16.66673 - diff: 13.18mlTrain batch 4/32 - 239.4ms/batch - loss: 20.54610 - diff: 14.35mlTrain batch 5/32 - 238.5ms/batch - loss: 22.22573 - diff: 14.89mlTrain batch 6/32 - 239.4ms/batch - loss: 19.99085 - diff: 14.03mlTrain batch 7/32 - 237.4ms/batch - loss: 23.46974 - diff: 14.90mlTrain batch 8/32 - 238.2ms/batch - loss: 22.34024 - diff: 14.46mlTrain batch 9/32 - 237.1ms/batch - loss: 22.78300 - diff: 14.49mlTrain batch 10/32 - 240.0ms/batch - loss: 23.07312 - diff: 14.62mlTrain batch 11/32 - 236.6ms/batch - loss: 21.69648 - diff: 14.14mlTrain batch 12/32 - 240.1ms/batch - loss: 21.14389 - diff: 14.09mlTrain batch 13/32 - 238.0ms/batch - loss: 20.52314 - diff: 13.88mlTrain batch 14/32 - 240.1ms/batch - loss: 19.90879 - diff: 13.71mlTrain batch 15/32 - 237.3ms/batch - loss: 19.41376 - diff: 13.43mlTrain batch 16/32 - 240.3ms/batch - loss: 21.88984 - diff: 14.06mlTrain batch 17/32 - 237.4ms/batch - loss: 21.45738 - diff: 13.85mlTrain batch 18/32 - 240.0ms/batch - loss: 21.30948 - diff: 13.83mlTrain batch 19/32 - 237.8ms/batch - loss: 21.06463 - diff: 13.82mlTrain batch 20/32 - 240.5ms/batch - loss: 21.17167 - diff: 13.95mlTrain batch 21/32 - 237.5ms/batch - loss: 20.65434 - diff: 13.82mlTrain batch 22/32 - 240.3ms/batch - loss: 20.25311 - diff: 13.70mlTrain batch 23/32 - 237.4ms/batch - loss: 20.39513 - diff: 13.84mlTrain batch 24/32 - 239.4ms/batch - loss: 20.50629 - diff: 13.90mlTrain batch 25/32 - 237.4ms/batch - loss: 20.53256 - diff: 13.94mlTrain batch 26/32 - 239.1ms/batch - loss: 20.26999 - diff: 13.86mlTrain batch 27/32 - 238.3ms/batch - loss: 20.60343 - diff: 13.95mlTrain batch 28/32 - 240.0ms/batch - loss: 20.59467 - diff: 13.97mlTrain batch 29/32 - 237.4ms/batch - loss: 20.56505 - diff: 13.98mlTrain batch 30/32 - 237.5ms/batch - loss: 20.99707 - diff: 14.10mlTrain batch 31/32 - 238.3ms/batch - loss: 20.88527 - diff: 14.07mlTrain batch 32/32 - 77.4ms/batch - loss: 42.33785 - diff: 14.41mlTrain batch 32/32 - 10.6s 77.4ms/batch - loss: 42.33785 - diff: 14.41ml
Test 1.2s: val_loss: 35.63877 - diff: 16.27ml

Epoch 145: current best loss = 33.72785, at epoch 141
Train batch 1/32 - 237.0ms/batch - loss: 32.62484 - diff: 18.79mlTrain batch 2/32 - 240.1ms/batch - loss: 27.12517 - diff: 17.31mlTrain batch 3/32 - 237.4ms/batch - loss: 31.22603 - diff: 18.08mlTrain batch 4/32 - 240.2ms/batch - loss: 32.86021 - diff: 18.44mlTrain batch 5/32 - 237.2ms/batch - loss: 28.64603 - diff: 17.16mlTrain batch 6/32 - 240.4ms/batch - loss: 30.42828 - diff: 17.41mlTrain batch 7/32 - 243.3ms/batch - loss: 29.99284 - diff: 17.58mlTrain batch 8/32 - 237.3ms/batch - loss: 29.48842 - diff: 17.62mlTrain batch 9/32 - 238.0ms/batch - loss: 31.62769 - diff: 18.12mlTrain batch 10/32 - 240.3ms/batch - loss: 30.68527 - diff: 17.91mlTrain batch 11/32 - 237.5ms/batch - loss: 31.23500 - diff: 18.05mlTrain batch 12/32 - 239.2ms/batch - loss: 30.14442 - diff: 17.67mlTrain batch 13/32 - 238.4ms/batch - loss: 29.48442 - diff: 17.51mlTrain batch 14/32 - 239.0ms/batch - loss: 28.34206 - diff: 17.11mlTrain batch 15/32 - 237.2ms/batch - loss: 28.73198 - diff: 17.03mlTrain batch 16/32 - 238.6ms/batch - loss: 28.94381 - diff: 17.09mlTrain batch 17/32 - 237.4ms/batch - loss: 28.93422 - diff: 17.07mlTrain batch 18/32 - 240.4ms/batch - loss: 28.48803 - diff: 16.85mlTrain batch 19/32 - 253.5ms/batch - loss: 28.19493 - diff: 16.79mlTrain batch 20/32 - 237.4ms/batch - loss: 28.72307 - diff: 16.73mlTrain batch 21/32 - 237.6ms/batch - loss: 28.11002 - diff: 16.59mlTrain batch 22/32 - 240.3ms/batch - loss: 27.59306 - diff: 16.45mlTrain batch 23/32 - 237.7ms/batch - loss: 26.96844 - diff: 16.24mlTrain batch 24/32 - 240.5ms/batch - loss: 26.39944 - diff: 16.05mlTrain batch 25/32 - 237.6ms/batch - loss: 27.15370 - diff: 16.23mlTrain batch 26/32 - 239.2ms/batch - loss: 27.20452 - diff: 16.22mlTrain batch 27/32 - 238.4ms/batch - loss: 27.32693 - diff: 16.21mlTrain batch 28/32 - 240.0ms/batch - loss: 26.89990 - diff: 16.07mlTrain batch 29/32 - 238.5ms/batch - loss: 27.02135 - diff: 15.98mlTrain batch 30/32 - 240.1ms/batch - loss: 26.82666 - diff: 15.97mlTrain batch 31/32 - 238.1ms/batch - loss: 27.80470 - diff: 16.15mlTrain batch 32/32 - 76.6ms/batch - loss: 28.28507 - diff: 16.14mlTrain batch 32/32 - 10.7s 76.6ms/batch - loss: 28.28507 - diff: 16.14ml
Test 1.1s: val_loss: 40.18891 - diff: 18.18ml

Epoch 146: current best loss = 33.72785, at epoch 141
Train batch 1/32 - 237.1ms/batch - loss: 16.55637 - diff: 12.74mlTrain batch 2/32 - 238.1ms/batch - loss: 17.28886 - diff: 13.56mlTrain batch 3/32 - 236.9ms/batch - loss: 15.81147 - diff: 12.83mlTrain batch 4/32 - 240.3ms/batch - loss: 16.37145 - diff: 13.15mlTrain batch 5/32 - 237.4ms/batch - loss: 14.91944 - diff: 12.32mlTrain batch 6/32 - 240.4ms/batch - loss: 20.21968 - diff: 13.54mlTrain batch 7/32 - 237.4ms/batch - loss: 20.91014 - diff: 14.03mlTrain batch 8/32 - 240.1ms/batch - loss: 20.99336 - diff: 14.26mlTrain batch 9/32 - 237.1ms/batch - loss: 22.79049 - diff: 15.01mlTrain batch 10/32 - 239.9ms/batch - loss: 22.80416 - diff: 15.05mlTrain batch 11/32 - 238.0ms/batch - loss: 22.22645 - diff: 14.83mlTrain batch 12/32 - 240.3ms/batch - loss: 23.32942 - diff: 15.36mlTrain batch 13/32 - 238.2ms/batch - loss: 24.41010 - diff: 15.52mlTrain batch 14/32 - 240.0ms/batch - loss: 23.83976 - diff: 15.32mlTrain batch 15/32 - 238.3ms/batch - loss: 24.33486 - diff: 15.45mlTrain batch 16/32 - 238.7ms/batch - loss: 24.21738 - diff: 15.47mlTrain batch 17/32 - 237.5ms/batch - loss: 24.28018 - diff: 15.51mlTrain batch 18/32 - 239.9ms/batch - loss: 24.88046 - diff: 15.66mlTrain batch 19/32 - 237.4ms/batch - loss: 25.02819 - diff: 15.81mlTrain batch 20/32 - 240.1ms/batch - loss: 24.91939 - diff: 15.80mlTrain batch 21/32 - 237.3ms/batch - loss: 25.98128 - diff: 16.08mlTrain batch 22/32 - 240.3ms/batch - loss: 25.44485 - diff: 15.89mlTrain batch 23/32 - 241.3ms/batch - loss: 25.14851 - diff: 15.84mlTrain batch 24/32 - 240.5ms/batch - loss: 24.84307 - diff: 15.74mlTrain batch 25/32 - 238.3ms/batch - loss: 24.35391 - diff: 15.56mlTrain batch 26/32 - 244.0ms/batch - loss: 24.14779 - diff: 15.52mlTrain batch 27/32 - 238.3ms/batch - loss: 24.00723 - diff: 15.39mlTrain batch 28/32 - 240.3ms/batch - loss: 24.26138 - diff: 15.30mlTrain batch 29/32 - 237.5ms/batch - loss: 23.97957 - diff: 15.23mlTrain batch 30/32 - 239.2ms/batch - loss: 23.87963 - diff: 15.22mlTrain batch 31/32 - 238.1ms/batch - loss: 23.96723 - diff: 15.24mlTrain batch 32/32 - 77.7ms/batch - loss: 27.82392 - diff: 15.43mlTrain batch 32/32 - 10.7s 77.7ms/batch - loss: 27.82392 - diff: 15.43ml
Test 1.1s: val_loss: 59.28266 - diff: 21.81ml

Epoch 147: current best loss = 33.72785, at epoch 141
Train batch 1/32 - 238.3ms/batch - loss: 15.23514 - diff: 11.03mlTrain batch 2/32 - 239.2ms/batch - loss: 32.22994 - diff: 16.43mlTrain batch 3/32 - 238.4ms/batch - loss: 32.67604 - diff: 17.15mlTrain batch 4/32 - 239.3ms/batch - loss: 28.39192 - diff: 16.25mlTrain batch 5/32 - 237.2ms/batch - loss: 25.30145 - diff: 15.24mlTrain batch 6/32 - 238.5ms/batch - loss: 26.35736 - diff: 15.52mlTrain batch 7/32 - 237.4ms/batch - loss: 25.13921 - diff: 15.17mlTrain batch 8/32 - 240.2ms/batch - loss: 23.32169 - diff: 14.70mlTrain batch 9/32 - 237.9ms/batch - loss: 23.98634 - diff: 15.07mlTrain batch 10/32 - 240.2ms/batch - loss: 23.22140 - diff: 14.86mlTrain batch 11/32 - 237.4ms/batch - loss: 23.50382 - diff: 14.90mlTrain batch 12/32 - 240.4ms/batch - loss: 23.68048 - diff: 15.05mlTrain batch 13/32 - 237.3ms/batch - loss: 23.32165 - diff: 14.99mlTrain batch 14/32 - 239.9ms/batch - loss: 23.64513 - diff: 15.12mlTrain batch 15/32 - 236.7ms/batch - loss: 23.16316 - diff: 14.85mlTrain batch 16/32 - 239.9ms/batch - loss: 22.82946 - diff: 14.85mlTrain batch 17/32 - 242.3ms/batch - loss: 22.99557 - diff: 14.91mlTrain batch 18/32 - 240.7ms/batch - loss: 24.21326 - diff: 15.23mlTrain batch 19/32 - 238.0ms/batch - loss: 26.03022 - diff: 15.47mlTrain batch 20/32 - 240.3ms/batch - loss: 26.06550 - diff: 15.61mlTrain batch 21/32 - 238.1ms/batch - loss: 25.62444 - diff: 15.52mlTrain batch 22/32 - 240.0ms/batch - loss: 25.86569 - diff: 15.64mlTrain batch 23/32 - 238.3ms/batch - loss: 25.98549 - diff: 15.72mlTrain batch 24/32 - 240.0ms/batch - loss: 25.70416 - diff: 15.67mlTrain batch 25/32 - 237.7ms/batch - loss: 26.01594 - diff: 15.77mlTrain batch 26/32 - 238.8ms/batch - loss: 26.15131 - diff: 15.84mlTrain batch 27/32 - 237.3ms/batch - loss: 25.88455 - diff: 15.84mlTrain batch 28/32 - 239.6ms/batch - loss: 26.61589 - diff: 15.79mlTrain batch 29/32 - 238.3ms/batch - loss: 27.01110 - diff: 15.87mlTrain batch 30/32 - 240.3ms/batch - loss: 26.96006 - diff: 15.87mlTrain batch 31/32 - 243.8ms/batch - loss: 26.56159 - diff: 15.79mlTrain batch 32/32 - 76.6ms/batch - loss: 26.91470 - diff: 15.78mlTrain batch 32/32 - 10.6s 76.6ms/batch - loss: 26.91470 - diff: 15.78ml
Test 1.1s: val_loss: 42.05956 - diff: 17.24ml

Epoch 148: current best loss = 33.72785, at epoch 141
Train batch 1/32 - 237.1ms/batch - loss: 13.22570 - diff: 11.87mlTrain batch 2/32 - 240.2ms/batch - loss: 14.80868 - diff: 12.00mlTrain batch 3/32 - 237.2ms/batch - loss: 26.49285 - diff: 15.98mlTrain batch 4/32 - 240.5ms/batch - loss: 24.78540 - diff: 15.19mlTrain batch 5/32 - 237.8ms/batch - loss: 28.12419 - diff: 16.22mlTrain batch 6/32 - 240.4ms/batch - loss: 25.12491 - diff: 15.32mlTrain batch 7/32 - 237.9ms/batch - loss: 24.07512 - diff: 14.63mlTrain batch 8/32 - 240.2ms/batch - loss: 22.87043 - diff: 14.24mlTrain batch 9/32 - 237.4ms/batch - loss: 21.28600 - diff: 13.73mlTrain batch 10/32 - 239.4ms/batch - loss: 20.88141 - diff: 13.68mlTrain batch 11/32 - 238.3ms/batch - loss: 20.28301 - diff: 13.68mlTrain batch 12/32 - 239.8ms/batch - loss: 20.00637 - diff: 13.59mlTrain batch 13/32 - 238.3ms/batch - loss: 21.57493 - diff: 14.15mlTrain batch 14/32 - 238.9ms/batch - loss: 23.02555 - diff: 14.45mlTrain batch 15/32 - 237.0ms/batch - loss: 23.36418 - diff: 14.45mlTrain batch 16/32 - 240.0ms/batch - loss: 22.94743 - diff: 14.39mlTrain batch 17/32 - 237.9ms/batch - loss: 23.31996 - diff: 14.53mlTrain batch 18/32 - 240.6ms/batch - loss: 22.69242 - diff: 14.41mlTrain batch 19/32 - 238.2ms/batch - loss: 22.70030 - diff: 14.50mlTrain batch 20/32 - 240.3ms/batch - loss: 24.37796 - diff: 14.81mlTrain batch 21/32 - 237.4ms/batch - loss: 23.86018 - diff: 14.67mlTrain batch 22/32 - 240.6ms/batch - loss: 23.95357 - diff: 14.77mlTrain batch 23/32 - 237.5ms/batch - loss: 24.29097 - diff: 14.87mlTrain batch 24/32 - 240.2ms/batch - loss: 24.68992 - diff: 14.96mlTrain batch 25/32 - 237.7ms/batch - loss: 24.12953 - diff: 14.72mlTrain batch 26/32 - 240.4ms/batch - loss: 24.54557 - diff: 14.80mlTrain batch 27/32 - 238.1ms/batch - loss: 23.81524 - diff: 14.52mlTrain batch 28/32 - 240.5ms/batch - loss: 25.15924 - diff: 14.69mlTrain batch 29/32 - 237.9ms/batch - loss: 24.94842 - diff: 14.58mlTrain batch 30/32 - 239.9ms/batch - loss: 24.55299 - diff: 14.50mlTrain batch 31/32 - 238.7ms/batch - loss: 24.30766 - diff: 14.48mlTrain batch 32/32 - 77.7ms/batch - loss: 24.51563 - diff: 14.47mlTrain batch 32/32 - 10.6s 77.7ms/batch - loss: 24.51563 - diff: 14.47ml
Test 1.1s: val_loss: 42.89970 - diff: 18.75ml

Epoch 149: current best loss = 33.72785, at epoch 141
Train batch 1/32 - 237.4ms/batch - loss: 22.90857 - diff: 14.67mlTrain batch 2/32 - 237.9ms/batch - loss: 25.02724 - diff: 15.76mlTrain batch 3/32 - 237.0ms/batch - loss: 30.92798 - diff: 17.58mlTrain batch 4/32 - 237.8ms/batch - loss: 29.31958 - diff: 17.19mlTrain batch 5/32 - 237.8ms/batch - loss: 25.01146 - diff: 15.69mlTrain batch 6/32 - 240.2ms/batch - loss: 23.79421 - diff: 15.18mlTrain batch 7/32 - 238.0ms/batch - loss: 25.27372 - diff: 16.06mlTrain batch 8/32 - 240.4ms/batch - loss: 25.18167 - diff: 16.11mlTrain batch 9/32 - 237.6ms/batch - loss: 23.81505 - diff: 15.64mlTrain batch 10/32 - 240.6ms/batch - loss: 23.44676 - diff: 15.41mlTrain batch 11/32 - 237.8ms/batch - loss: 22.02928 - diff: 14.81mlTrain batch 12/32 - 240.3ms/batch - loss: 21.26286 - diff: 14.43mlTrain batch 13/32 - 238.1ms/batch - loss: 21.21257 - diff: 14.46mlTrain batch 14/32 - 240.3ms/batch - loss: 20.19915 - diff: 14.01mlTrain batch 15/32 - 237.6ms/batch - loss: 19.98480 - diff: 13.86mlTrain batch 16/32 - 239.4ms/batch - loss: 20.61332 - diff: 14.06mlTrain batch 17/32 - 237.5ms/batch - loss: 21.03283 - diff: 14.16mlTrain batch 18/32 - 239.5ms/batch - loss: 20.79940 - diff: 14.09mlTrain batch 19/32 - 238.3ms/batch - loss: 20.34783 - diff: 14.02mlTrain batch 20/32 - 240.2ms/batch - loss: 21.90566 - diff: 14.45mlTrain batch 21/32 - 237.5ms/batch - loss: 21.88698 - diff: 14.51mlTrain batch 22/32 - 238.7ms/batch - loss: 21.33854 - diff: 14.35mlTrain batch 23/32 - 237.2ms/batch - loss: 21.68519 - diff: 14.43mlTrain batch 24/32 - 239.5ms/batch - loss: 21.75677 - diff: 14.45mlTrain batch 25/32 - 238.3ms/batch - loss: 22.56758 - diff: 14.72mlTrain batch 26/32 - 240.3ms/batch - loss: 22.35950 - diff: 14.65mlTrain batch 27/32 - 238.4ms/batch - loss: 22.79346 - diff: 14.78mlTrain batch 28/32 - 240.2ms/batch - loss: 22.54585 - diff: 14.70mlTrain batch 29/32 - 237.6ms/batch - loss: 22.13111 - diff: 14.55mlTrain batch 30/32 - 240.4ms/batch - loss: 21.65914 - diff: 14.37mlTrain batch 31/32 - 237.6ms/batch - loss: 21.40872 - diff: 14.30mlTrain batch 32/32 - 78.0ms/batch - loss: 21.45746 - diff: 14.26mlTrain batch 32/32 - 10.6s 78.0ms/batch - loss: 21.45746 - diff: 14.26ml
Test 1.2s: val_loss: 35.57522 - diff: 16.95ml

Traceback (most recent call last):
  File "train.py", line 266, in <module>
    plot_results(train_losses, test_losses, title=f"Loss {target_label}", save_as=exp_name + "_loss")
  File "/home/allochi/tfm/workspace/lib/utils.py", line 345, in plot_results
    plt.plot(train_values, "r", label="train")
  File "/home/allochi/.conda/envs/DL_env/lib/python3.8/site-packages/matplotlib/pyplot.py", line 2824, in plot
    return gca().plot(
  File "/home/allochi/.conda/envs/DL_env/lib/python3.8/site-packages/matplotlib/pyplot.py", line 2352, in gca
    return gcf().gca(**kwargs)
  File "/home/allochi/.conda/envs/DL_env/lib/python3.8/site-packages/matplotlib/pyplot.py", line 731, in gcf
    return figure()
  File "/home/allochi/.conda/envs/DL_env/lib/python3.8/site-packages/matplotlib/pyplot.py", line 671, in figure
    figManager = new_figure_manager(num, figsize=figsize,
  File "/home/allochi/.conda/envs/DL_env/lib/python3.8/site-packages/matplotlib/pyplot.py", line 299, in new_figure_manager
    return _backend_mod.new_figure_manager(*args, **kwargs)
  File "/home/allochi/.conda/envs/DL_env/lib/python3.8/site-packages/matplotlib/backend_bases.py", line 3494, in new_figure_manager
    return cls.new_figure_manager_given_figure(num, fig)
  File "/home/allochi/.conda/envs/DL_env/lib/python3.8/site-packages/matplotlib/backends/_backend_tk.py", line 868, in new_figure_manager_given_figure
    window = tk.Tk(className="matplotlib")
  File "/home/allochi/.conda/envs/DL_env/lib/python3.8/tkinter/__init__.py", line 2261, in __init__
    self.tk = _tkinter.create(screenName, baseName, className, interactive, wantobjects, useTk, sync, use)
_tkinter.TclError: couldn't connect to display "localhost:10.0"
