nohup: ignoring input
Running experiment 4CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_WideResNet50_0_Adam-0.001_MSE_DA3
Going to train with the GPU in the slot 1 -> device model: GeForce RTX 2080
Model architecture:
 WideResNet50_0(
  (first_conv): Conv2d(30, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (pretrained_block): Sequential(
    (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): ReLU(inplace=True)
    (2): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (3): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (4): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (5): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (4): Bottleneck(
        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (5): Bottleneck(
        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
  )
  (reduction_block): Sequential(
    (0): AdaptiveAvgPool2d(output_size=(1, 1))
    (1): Flatten()
  )
  (dense_block): Sequential(
    (0): Linear(in_features=1024, out_features=512, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.4, inplace=False)
    (3): Linear(in_features=512, out_features=1, bias=True)
  )
) 


############################
# TRAIN PHASE:  150 epochs #
############################

Epoch 0: 
Train batch 1/31 - 200.2ms/batch - loss: 1801.11609 - diff: 164.32mlTrain batch 2/31 - 185.7ms/batch - loss: 1908.57037 - diff: 166.95mlTrain batch 3/31 - 180.3ms/batch - loss: 1877.03662 - diff: 165.50mlTrain batch 4/31 - 167.2ms/batch - loss: 1814.55792 - diff: 162.84mlTrain batch 5/31 - 167.1ms/batch - loss: 1899.82700 - diff: 166.64mlTrain batch 6/31 - 167.6ms/batch - loss: 1823.93132 - diff: 163.57mlTrain batch 7/31 - 167.6ms/batch - loss: 1842.51168 - diff: 164.11mlTrain batch 8/31 - 167.7ms/batch - loss: 1781.93556 - diff: 161.38mlTrain batch 9/31 - 167.6ms/batch - loss: 1815.10527 - diff: 162.26mlTrain batch 10/31 - 167.6ms/batch - loss: 1797.11383 - diff: 161.98mlTrain batch 11/31 - 167.8ms/batch - loss: 1802.82909 - diff: 162.47mlTrain batch 12/31 - 167.6ms/batch - loss: 1840.38278 - diff: 164.29mlTrain batch 13/31 - 167.9ms/batch - loss: 1855.55937 - diff: 164.15mlTrain batch 14/31 - 167.5ms/batch - loss: 1819.68413 - diff: 162.09mlTrain batch 15/31 - 167.4ms/batch - loss: 1804.01207 - diff: 161.57mlTrain batch 16/31 - 167.6ms/batch - loss: 1809.75877 - diff: 161.84mlTrain batch 17/31 - 167.5ms/batch - loss: 1805.70723 - diff: 161.33mlTrain batch 18/31 - 167.7ms/batch - loss: 1857.92223 - diff: 163.27mlTrain batch 19/31 - 167.7ms/batch - loss: 1855.98584 - diff: 163.28mlTrain batch 20/31 - 167.4ms/batch - loss: 1821.00085 - diff: 161.03mlTrain batch 21/31 - 167.5ms/batch - loss: 1813.01171 - diff: 160.87mlTrain batch 22/31 - 167.8ms/batch - loss: 1802.23931 - diff: 160.16mlTrain batch 23/31 - 167.4ms/batch - loss: 1816.82837 - diff: 160.80mlTrain batch 24/31 - 167.7ms/batch - loss: 1822.82512 - diff: 161.25mlTrain batch 25/31 - 167.7ms/batch - loss: 1809.47622 - diff: 160.75mlTrain batch 26/31 - 167.9ms/batch - loss: 1779.99003 - diff: 159.26mlTrain batch 27/31 - 167.8ms/batch - loss: 1762.53623 - diff: 158.53mlTrain batch 28/31 - 167.9ms/batch - loss: 1743.85973 - diff: 157.25mlTrain batch 29/31 - 167.7ms/batch - loss: 1744.65952 - diff: 157.38mlTrain batch 30/31 - 167.8ms/batch - loss: 1746.89537 - diff: 157.57mlTrain batch 31/31 - 84.0ms/batch - loss: 1858.84797 - diff: 158.39mlTrain batch 31/31 - 11.6s 84.0ms/batch - loss: 1858.84797 - diff: 158.39ml
Test 1.1s: val_loss: 1555.27876 - diff: 140.01ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_WideResNet50_0_Adam-0.001_MSE_DA3_best

Epoch 1: current best loss = 1555.27876, at epoch 0
Train batch 1/31 - 167.8ms/batch - loss: 1620.32166 - diff: 143.17mlTrain batch 2/31 - 168.1ms/batch - loss: 1910.57635 - diff: 157.55mlTrain batch 3/31 - 167.9ms/batch - loss: 1767.04431 - diff: 154.20mlTrain batch 4/31 - 167.9ms/batch - loss: 1643.33975 - diff: 149.33mlTrain batch 5/31 - 167.8ms/batch - loss: 1599.84092 - diff: 148.09mlTrain batch 6/31 - 168.0ms/batch - loss: 1590.86951 - diff: 147.68mlTrain batch 7/31 - 167.9ms/batch - loss: 1554.96331 - diff: 146.73mlTrain batch 8/31 - 168.1ms/batch - loss: 1524.76611 - diff: 145.49mlTrain batch 9/31 - 167.9ms/batch - loss: 1499.53514 - diff: 144.50mlTrain batch 10/31 - 168.1ms/batch - loss: 1487.07333 - diff: 143.55mlTrain batch 11/31 - 168.0ms/batch - loss: 1436.30784 - diff: 141.08mlTrain batch 12/31 - 168.0ms/batch - loss: 1413.90552 - diff: 139.95mlTrain batch 13/31 - 167.9ms/batch - loss: 1449.22437 - diff: 141.08mlTrain batch 14/31 - 168.0ms/batch - loss: 1417.97288 - diff: 139.58mlTrain batch 15/31 - 168.0ms/batch - loss: 1397.76946 - diff: 138.35mlTrain batch 16/31 - 168.1ms/batch - loss: 1356.92561 - diff: 136.02mlTrain batch 17/31 - 168.0ms/batch - loss: 1341.98686 - diff: 135.24mlTrain batch 18/31 - 168.1ms/batch - loss: 1350.31865 - diff: 135.47mlTrain batch 19/31 - 168.0ms/batch - loss: 1344.63978 - diff: 135.25mlTrain batch 20/31 - 168.4ms/batch - loss: 1328.00135 - diff: 134.21mlTrain batch 21/31 - 168.4ms/batch - loss: 1309.70928 - diff: 133.30mlTrain batch 22/31 - 167.5ms/batch - loss: 1290.13912 - diff: 132.42mlTrain batch 23/31 - 167.8ms/batch - loss: 1284.69567 - diff: 132.13mlTrain batch 24/31 - 167.7ms/batch - loss: 1308.28036 - diff: 131.98mlTrain batch 25/31 - 168.4ms/batch - loss: 1283.76873 - diff: 130.71mlTrain batch 26/31 - 168.3ms/batch - loss: 1272.45166 - diff: 130.00mlTrain batch 27/31 - 167.9ms/batch - loss: 1254.52787 - diff: 128.68mlTrain batch 28/31 - 168.1ms/batch - loss: 1230.15509 - diff: 127.25mlTrain batch 29/31 - 168.4ms/batch - loss: 1222.87668 - diff: 127.00mlTrain batch 30/31 - 168.5ms/batch - loss: 1197.62582 - diff: 125.24mlTrain batch 31/31 - 84.4ms/batch - loss: 1194.16456 - diff: 124.51mlTrain batch 31/31 - 10.0s 84.4ms/batch - loss: 1194.16456 - diff: 124.51ml
Test 1.1s: val_loss: 688.13548 - diff: 90.04ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_WideResNet50_0_Adam-0.001_MSE_DA3_best

Epoch 2: current best loss = 688.13548, at epoch 1
Train batch 1/31 - 168.4ms/batch - loss: 947.11804 - diff: 108.28mlTrain batch 2/31 - 168.2ms/batch - loss: 1007.72888 - diff: 112.31mlTrain batch 3/31 - 168.5ms/batch - loss: 1233.00708 - diff: 116.06mlTrain batch 4/31 - 168.6ms/batch - loss: 1014.49702 - diff: 102.83mlTrain batch 5/31 - 168.3ms/batch - loss: 926.98643 - diff: 99.60mlTrain batch 6/31 - 168.6ms/batch - loss: 925.59392 - diff: 100.39mlTrain batch 7/31 - 168.5ms/batch - loss: 891.01273 - diff: 97.52mlTrain batch 8/31 - 168.5ms/batch - loss: 845.17816 - diff: 95.29mlTrain batch 9/31 - 168.3ms/batch - loss: 778.81582 - diff: 90.94mlTrain batch 10/31 - 168.6ms/batch - loss: 746.67945 - diff: 88.74mlTrain batch 11/31 - 168.5ms/batch - loss: 711.57458 - diff: 86.90mlTrain batch 12/31 - 168.5ms/batch - loss: 703.98823 - diff: 87.00mlTrain batch 13/31 - 168.5ms/batch - loss: 677.18408 - diff: 84.85mlTrain batch 14/31 - 168.4ms/batch - loss: 650.54716 - diff: 83.16mlTrain batch 15/31 - 168.4ms/batch - loss: 644.67999 - diff: 82.92mlTrain batch 16/31 - 168.2ms/batch - loss: 633.69543 - diff: 81.92mlTrain batch 17/31 - 168.4ms/batch - loss: 610.07316 - diff: 80.13mlTrain batch 18/31 - 168.4ms/batch - loss: 600.28540 - diff: 79.20mlTrain batch 19/31 - 168.1ms/batch - loss: 585.08824 - diff: 78.21mlTrain batch 20/31 - 168.5ms/batch - loss: 565.31081 - diff: 76.68mlTrain batch 21/31 - 168.5ms/batch - loss: 553.19977 - diff: 75.53mlTrain batch 22/31 - 168.7ms/batch - loss: 541.18582 - diff: 74.56mlTrain batch 23/31 - 168.2ms/batch - loss: 525.83516 - diff: 73.03mlTrain batch 24/31 - 168.6ms/batch - loss: 523.23557 - diff: 72.72mlTrain batch 25/31 - 168.4ms/batch - loss: 512.77449 - diff: 71.45mlTrain batch 26/31 - 168.5ms/batch - loss: 501.39166 - diff: 70.54mlTrain batch 27/31 - 168.2ms/batch - loss: 489.18203 - diff: 69.50mlTrain batch 28/31 - 168.7ms/batch - loss: 488.77606 - diff: 69.34mlTrain batch 29/31 - 168.3ms/batch - loss: 476.59720 - diff: 68.21mlTrain batch 30/31 - 168.8ms/batch - loss: 466.83688 - diff: 67.46mlTrain batch 31/31 - 84.6ms/batch - loss: 467.17402 - diff: 67.20mlTrain batch 31/31 - 10.0s 84.6ms/batch - loss: 467.17402 - diff: 67.20ml
Test 1.1s: val_loss: 210.64771 - diff: 42.81ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_WideResNet50_0_Adam-0.001_MSE_DA3_best

Epoch 3: current best loss = 210.64771, at epoch 2
Train batch 1/31 - 182.7ms/batch - loss: 242.35596 - diff: 51.02mlTrain batch 2/31 - 172.1ms/batch - loss: 165.18821 - diff: 39.98mlTrain batch 3/31 - 168.5ms/batch - loss: 163.78489 - diff: 38.71mlTrain batch 4/31 - 168.1ms/batch - loss: 172.98344 - diff: 41.26mlTrain batch 5/31 - 168.2ms/batch - loss: 165.45617 - diff: 39.56mlTrain batch 6/31 - 168.7ms/batch - loss: 154.62556 - diff: 38.35mlTrain batch 7/31 - 168.6ms/batch - loss: 181.39651 - diff: 40.32mlTrain batch 8/31 - 168.8ms/batch - loss: 200.79100 - diff: 41.03mlTrain batch 9/31 - 168.8ms/batch - loss: 205.59533 - diff: 41.75mlTrain batch 10/31 - 168.8ms/batch - loss: 205.58882 - diff: 41.74mlTrain batch 11/31 - 168.4ms/batch - loss: 198.66116 - diff: 41.15mlTrain batch 12/31 - 168.8ms/batch - loss: 208.49730 - diff: 42.17mlTrain batch 13/31 - 168.6ms/batch - loss: 212.90891 - diff: 42.15mlTrain batch 14/31 - 168.9ms/batch - loss: 212.51739 - diff: 41.93mlTrain batch 15/31 - 169.0ms/batch - loss: 205.36807 - diff: 41.21mlTrain batch 16/31 - 169.0ms/batch - loss: 199.86047 - diff: 40.74mlTrain batch 17/31 - 168.6ms/batch - loss: 195.93768 - diff: 40.44mlTrain batch 18/31 - 168.4ms/batch - loss: 196.64852 - diff: 40.46mlTrain batch 19/31 - 168.9ms/batch - loss: 196.69844 - diff: 40.58mlTrain batch 20/31 - 168.9ms/batch - loss: 197.74926 - diff: 40.89mlTrain batch 21/31 - 168.9ms/batch - loss: 220.71293 - diff: 41.73mlTrain batch 22/31 - 168.9ms/batch - loss: 216.86307 - diff: 41.49mlTrain batch 23/31 - 168.8ms/batch - loss: 218.17903 - diff: 42.01mlTrain batch 24/31 - 168.9ms/batch - loss: 214.30810 - diff: 41.61mlTrain batch 25/31 - 168.9ms/batch - loss: 216.96784 - diff: 42.19mlTrain batch 26/31 - 169.0ms/batch - loss: 213.14650 - diff: 41.97mlTrain batch 27/31 - 168.7ms/batch - loss: 214.09768 - diff: 42.27mlTrain batch 28/31 - 168.8ms/batch - loss: 211.43747 - diff: 42.09mlTrain batch 29/31 - 168.8ms/batch - loss: 207.19009 - diff: 41.63mlTrain batch 30/31 - 169.2ms/batch - loss: 203.20076 - diff: 41.32mlTrain batch 31/31 - 84.8ms/batch - loss: 202.87847 - diff: 41.18mlTrain batch 31/31 - 10.2s 84.8ms/batch - loss: 202.87847 - diff: 41.18ml
Test 1.1s: val_loss: 191.49791 - diff: 42.57ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_WideResNet50_0_Adam-0.001_MSE_DA3_best

Epoch 4: current best loss = 191.49791, at epoch 3
Train batch 1/31 - 168.9ms/batch - loss: 301.25949 - diff: 61.51mlTrain batch 2/31 - 168.9ms/batch - loss: 211.20575 - diff: 47.74mlTrain batch 3/31 - 168.9ms/batch - loss: 259.17725 - diff: 50.78mlTrain batch 4/31 - 169.0ms/batch - loss: 379.54184 - diff: 54.07mlTrain batch 5/31 - 168.8ms/batch - loss: 314.71632 - diff: 48.15mlTrain batch 6/31 - 169.1ms/batch - loss: 284.24660 - diff: 46.37mlTrain batch 7/31 - 169.0ms/batch - loss: 262.14088 - diff: 45.62mlTrain batch 8/31 - 169.0ms/batch - loss: 246.96109 - diff: 44.81mlTrain batch 9/31 - 168.7ms/batch - loss: 229.00229 - diff: 42.81mlTrain batch 10/31 - 169.0ms/batch - loss: 215.40087 - diff: 41.87mlTrain batch 11/31 - 168.9ms/batch - loss: 212.48723 - diff: 42.02mlTrain batch 12/31 - 169.1ms/batch - loss: 203.38858 - diff: 41.38mlTrain batch 13/31 - 169.0ms/batch - loss: 199.19780 - diff: 41.02mlTrain batch 14/31 - 169.1ms/batch - loss: 189.94523 - diff: 40.00mlTrain batch 15/31 - 168.9ms/batch - loss: 183.36983 - diff: 39.29mlTrain batch 16/31 - 169.1ms/batch - loss: 181.36753 - diff: 39.15mlTrain batch 17/31 - 168.8ms/batch - loss: 187.52864 - diff: 39.43mlTrain batch 18/31 - 169.2ms/batch - loss: 183.67509 - diff: 39.41mlTrain batch 19/31 - 168.9ms/batch - loss: 179.98116 - diff: 39.17mlTrain batch 20/31 - 169.1ms/batch - loss: 183.32575 - diff: 39.64mlTrain batch 21/31 - 168.9ms/batch - loss: 178.66477 - diff: 39.13mlTrain batch 22/31 - 169.2ms/batch - loss: 179.55619 - diff: 39.61mlTrain batch 23/31 - 169.0ms/batch - loss: 176.41940 - diff: 39.25mlTrain batch 24/31 - 169.1ms/batch - loss: 180.56788 - diff: 39.84mlTrain batch 25/31 - 169.1ms/batch - loss: 182.86570 - diff: 40.15mlTrain batch 26/31 - 169.2ms/batch - loss: 184.20798 - diff: 40.39mlTrain batch 27/31 - 168.9ms/batch - loss: 183.84984 - diff: 40.48mlTrain batch 28/31 - 169.1ms/batch - loss: 189.10504 - diff: 40.89mlTrain batch 29/31 - 169.1ms/batch - loss: 185.58740 - diff: 40.44mlTrain batch 30/31 - 169.1ms/batch - loss: 185.36403 - diff: 40.59mlTrain batch 31/31 - 84.9ms/batch - loss: 198.26269 - diff: 40.89mlTrain batch 31/31 - 10.0s 84.9ms/batch - loss: 198.26269 - diff: 40.89ml
Test 1.1s: val_loss: 200.85178 - diff: 42.68ml

Epoch 5: current best loss = 191.49791, at epoch 3
Train batch 1/31 - 169.1ms/batch - loss: 355.48877 - diff: 53.00mlTrain batch 2/31 - 168.5ms/batch - loss: 241.46834 - diff: 45.51mlTrain batch 3/31 - 168.9ms/batch - loss: 177.57430 - diff: 38.42mlTrain batch 4/31 - 168.8ms/batch - loss: 186.02309 - diff: 39.49mlTrain batch 5/31 - 169.1ms/batch - loss: 192.26714 - diff: 41.18mlTrain batch 6/31 - 169.6ms/batch - loss: 184.22741 - diff: 40.83mlTrain batch 7/31 - 169.2ms/batch - loss: 185.87194 - diff: 41.33mlTrain batch 8/31 - 169.5ms/batch - loss: 178.50511 - diff: 40.48mlTrain batch 9/31 - 169.2ms/batch - loss: 199.23270 - diff: 42.83mlTrain batch 10/31 - 169.5ms/batch - loss: 204.34618 - diff: 42.59mlTrain batch 11/31 - 169.1ms/batch - loss: 202.93257 - diff: 42.87mlTrain batch 12/31 - 169.2ms/batch - loss: 206.26697 - diff: 43.31mlTrain batch 13/31 - 169.0ms/batch - loss: 259.56563 - diff: 45.96mlTrain batch 14/31 - 169.7ms/batch - loss: 250.43110 - diff: 45.34mlTrain batch 15/31 - 169.5ms/batch - loss: 250.23822 - diff: 45.07mlTrain batch 16/31 - 169.5ms/batch - loss: 243.65273 - diff: 44.60mlTrain batch 17/31 - 169.4ms/batch - loss: 238.86793 - diff: 44.27mlTrain batch 18/31 - 169.7ms/batch - loss: 231.60625 - diff: 43.58mlTrain batch 19/31 - 169.1ms/batch - loss: 227.64876 - diff: 43.31mlTrain batch 20/31 - 169.3ms/batch - loss: 221.86751 - diff: 42.85mlTrain batch 21/31 - 169.1ms/batch - loss: 219.75865 - diff: 42.95mlTrain batch 22/31 - 169.3ms/batch - loss: 213.19178 - diff: 42.17mlTrain batch 23/31 - 169.3ms/batch - loss: 210.40003 - diff: 42.04mlTrain batch 24/31 - 169.6ms/batch - loss: 204.58978 - diff: 41.43mlTrain batch 25/31 - 169.5ms/batch - loss: 201.58300 - diff: 41.21mlTrain batch 26/31 - 169.7ms/batch - loss: 199.57967 - diff: 40.96mlTrain batch 27/31 - 169.2ms/batch - loss: 197.11855 - diff: 40.81mlTrain batch 28/31 - 169.7ms/batch - loss: 196.10852 - diff: 40.96mlTrain batch 29/31 - 169.6ms/batch - loss: 193.91591 - diff: 40.93mlTrain batch 30/31 - 169.1ms/batch - loss: 191.16771 - diff: 40.80mlTrain batch 31/31 - 85.3ms/batch - loss: 193.12137 - diff: 40.82mlTrain batch 31/31 - 10.1s 85.3ms/batch - loss: 193.12137 - diff: 40.82ml
Test 1.1s: val_loss: 182.74237 - diff: 41.18ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_WideResNet50_0_Adam-0.001_MSE_DA3_best

Epoch 6: current best loss = 182.74237, at epoch 5
Train batch 1/31 - 184.4ms/batch - loss: 86.28537 - diff: 31.19mlTrain batch 2/31 - 169.6ms/batch - loss: 107.36538 - diff: 32.47mlTrain batch 3/31 - 169.0ms/batch - loss: 105.77776 - diff: 33.68mlTrain batch 4/31 - 169.5ms/batch - loss: 153.44417 - diff: 36.22mlTrain batch 5/31 - 169.5ms/batch - loss: 156.02582 - diff: 37.70mlTrain batch 6/31 - 169.7ms/batch - loss: 173.46297 - diff: 40.36mlTrain batch 7/31 - 169.4ms/batch - loss: 162.32453 - diff: 39.44mlTrain batch 8/31 - 169.8ms/batch - loss: 178.56245 - diff: 40.22mlTrain batch 9/31 - 169.6ms/batch - loss: 165.11793 - diff: 38.48mlTrain batch 10/31 - 169.8ms/batch - loss: 167.00305 - diff: 38.85mlTrain batch 11/31 - 169.7ms/batch - loss: 170.84832 - diff: 39.29mlTrain batch 12/31 - 169.9ms/batch - loss: 170.74425 - diff: 39.40mlTrain batch 13/31 - 169.7ms/batch - loss: 166.23222 - diff: 38.95mlTrain batch 14/31 - 169.3ms/batch - loss: 160.58715 - diff: 38.12mlTrain batch 15/31 - 169.6ms/batch - loss: 174.48146 - diff: 39.40mlTrain batch 16/31 - 168.8ms/batch - loss: 178.61098 - diff: 40.03mlTrain batch 17/31 - 169.4ms/batch - loss: 171.27581 - diff: 39.05mlTrain batch 18/31 - 169.2ms/batch - loss: 170.25856 - diff: 39.12mlTrain batch 19/31 - 169.3ms/batch - loss: 164.76582 - diff: 38.42mlTrain batch 20/31 - 169.6ms/batch - loss: 162.78965 - diff: 38.32mlTrain batch 21/31 - 169.5ms/batch - loss: 166.35011 - diff: 38.73mlTrain batch 22/31 - 169.9ms/batch - loss: 192.46380 - diff: 39.69mlTrain batch 23/31 - 169.5ms/batch - loss: 195.63958 - diff: 40.17mlTrain batch 24/31 - 169.7ms/batch - loss: 192.89950 - diff: 39.96mlTrain batch 25/31 - 169.5ms/batch - loss: 191.59033 - diff: 40.03mlTrain batch 26/31 - 169.9ms/batch - loss: 194.16181 - diff: 40.55mlTrain batch 27/31 - 169.6ms/batch - loss: 196.83568 - diff: 40.75mlTrain batch 28/31 - 169.7ms/batch - loss: 196.51389 - diff: 40.89mlTrain batch 29/31 - 169.7ms/batch - loss: 196.29764 - diff: 40.92mlTrain batch 30/31 - 170.0ms/batch - loss: 192.39737 - diff: 40.51mlTrain batch 31/31 - 85.4ms/batch - loss: 195.02166 - diff: 40.55mlTrain batch 31/31 - 10.1s 85.4ms/batch - loss: 195.02166 - diff: 40.55ml
Test 1.1s: val_loss: 183.54514 - diff: 41.65ml

Epoch 7: current best loss = 182.74237, at epoch 5
Train batch 1/31 - 169.4ms/batch - loss: 118.93863 - diff: 38.05mlTrain batch 2/31 - 169.8ms/batch - loss: 114.72847 - diff: 36.07mlTrain batch 3/31 - 169.4ms/batch - loss: 139.24598 - diff: 38.23mlTrain batch 4/31 - 169.9ms/batch - loss: 168.50033 - diff: 40.50mlTrain batch 5/31 - 169.5ms/batch - loss: 170.96359 - diff: 41.22mlTrain batch 6/31 - 170.0ms/batch - loss: 149.36964 - diff: 37.97mlTrain batch 7/31 - 169.5ms/batch - loss: 152.53359 - diff: 38.13mlTrain batch 8/31 - 170.0ms/batch - loss: 156.12560 - diff: 38.62mlTrain batch 9/31 - 169.3ms/batch - loss: 145.40852 - diff: 37.17mlTrain batch 10/31 - 170.0ms/batch - loss: 147.70851 - diff: 37.39mlTrain batch 11/31 - 169.7ms/batch - loss: 150.67030 - diff: 37.87mlTrain batch 12/31 - 169.7ms/batch - loss: 147.40303 - diff: 37.42mlTrain batch 13/31 - 169.5ms/batch - loss: 149.46945 - diff: 37.71mlTrain batch 14/31 - 169.8ms/batch - loss: 157.69202 - diff: 38.50mlTrain batch 15/31 - 169.8ms/batch - loss: 153.93033 - diff: 38.09mlTrain batch 16/31 - 168.8ms/batch - loss: 154.34210 - diff: 38.30mlTrain batch 17/31 - 169.8ms/batch - loss: 156.82538 - diff: 38.64mlTrain batch 18/31 - 169.9ms/batch - loss: 160.28615 - diff: 39.05mlTrain batch 19/31 - 169.7ms/batch - loss: 161.07648 - diff: 39.52mlTrain batch 20/31 - 170.0ms/batch - loss: 162.19593 - diff: 39.83mlTrain batch 21/31 - 170.0ms/batch - loss: 164.29660 - diff: 39.74mlTrain batch 22/31 - 170.0ms/batch - loss: 167.21387 - diff: 39.65mlTrain batch 23/31 - 169.6ms/batch - loss: 167.74148 - diff: 39.87mlTrain batch 24/31 - 169.8ms/batch - loss: 168.39614 - diff: 39.90mlTrain batch 25/31 - 169.5ms/batch - loss: 168.48785 - diff: 39.85mlTrain batch 26/31 - 170.0ms/batch - loss: 166.13927 - diff: 39.67mlTrain batch 27/31 - 169.8ms/batch - loss: 165.12143 - diff: 39.47mlTrain batch 28/31 - 170.0ms/batch - loss: 163.24681 - diff: 39.30mlTrain batch 29/31 - 169.9ms/batch - loss: 165.03066 - diff: 39.64mlTrain batch 30/31 - 170.0ms/batch - loss: 170.48510 - diff: 39.87mlTrain batch 31/31 - 85.4ms/batch - loss: 220.50690 - diff: 40.64mlTrain batch 31/31 - 10.0s 85.4ms/batch - loss: 220.50690 - diff: 40.64ml
Test 1.1s: val_loss: 183.00854 - diff: 40.53ml

Epoch 8: current best loss = 182.74237, at epoch 5
Train batch 1/31 - 169.9ms/batch - loss: 91.88381 - diff: 28.22mlTrain batch 2/31 - 170.2ms/batch - loss: 81.55552 - diff: 28.50mlTrain batch 3/31 - 169.9ms/batch - loss: 148.95976 - diff: 34.60mlTrain batch 4/31 - 170.2ms/batch - loss: 191.64252 - diff: 39.36mlTrain batch 5/31 - 169.6ms/batch - loss: 190.44352 - diff: 40.30mlTrain batch 6/31 - 169.9ms/batch - loss: 176.33919 - diff: 39.29mlTrain batch 7/31 - 169.6ms/batch - loss: 167.91297 - diff: 39.02mlTrain batch 8/31 - 170.0ms/batch - loss: 171.33489 - diff: 39.32mlTrain batch 9/31 - 169.5ms/batch - loss: 176.61909 - diff: 39.57mlTrain batch 10/31 - 169.8ms/batch - loss: 168.23387 - diff: 38.92mlTrain batch 11/31 - 169.8ms/batch - loss: 188.35439 - diff: 40.34mlTrain batch 12/31 - 170.0ms/batch - loss: 192.09875 - diff: 40.84mlTrain batch 13/31 - 169.8ms/batch - loss: 189.70052 - diff: 40.53mlTrain batch 14/31 - 169.9ms/batch - loss: 192.03057 - diff: 41.00mlTrain batch 15/31 - 169.6ms/batch - loss: 185.30318 - diff: 40.25mlTrain batch 16/31 - 169.8ms/batch - loss: 179.48059 - diff: 39.50mlTrain batch 17/31 - 169.8ms/batch - loss: 176.68638 - diff: 39.34mlTrain batch 18/31 - 170.0ms/batch - loss: 175.95314 - diff: 39.33mlTrain batch 19/31 - 169.7ms/batch - loss: 170.98125 - diff: 38.73mlTrain batch 20/31 - 169.9ms/batch - loss: 176.11260 - diff: 39.58mlTrain batch 21/31 - 169.9ms/batch - loss: 174.51799 - diff: 39.49mlTrain batch 22/31 - 170.0ms/batch - loss: 173.06572 - diff: 39.47mlTrain batch 23/31 - 170.0ms/batch - loss: 173.15671 - diff: 39.65mlTrain batch 24/31 - 170.2ms/batch - loss: 197.84566 - diff: 40.53mlTrain batch 25/31 - 169.8ms/batch - loss: 192.53761 - diff: 39.90mlTrain batch 26/31 - 170.6ms/batch - loss: 194.92155 - diff: 40.14mlTrain batch 27/31 - 169.5ms/batch - loss: 195.02733 - diff: 40.43mlTrain batch 28/31 - 169.5ms/batch - loss: 195.53592 - diff: 40.63mlTrain batch 29/31 - 170.1ms/batch - loss: 194.54010 - diff: 40.60mlTrain batch 30/31 - 170.4ms/batch - loss: 192.33165 - diff: 40.60mlTrain batch 31/31 - 85.6ms/batch - loss: 195.43080 - diff: 40.61mlTrain batch 31/31 - 10.1s 85.6ms/batch - loss: 195.43080 - diff: 40.61ml
Test 1.1s: val_loss: 179.14294 - diff: 41.14ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_WideResNet50_0_Adam-0.001_MSE_DA3_best

Epoch 9: current best loss = 179.14294, at epoch 8
Train batch 1/31 - 169.9ms/batch - loss: 114.99289 - diff: 31.34mlTrain batch 2/31 - 169.5ms/batch - loss: 178.56366 - diff: 40.92mlTrain batch 3/31 - 169.7ms/batch - loss: 213.55998 - diff: 45.37mlTrain batch 4/31 - 169.5ms/batch - loss: 203.94904 - diff: 44.56mlTrain batch 5/31 - 169.9ms/batch - loss: 211.74291 - diff: 45.87mlTrain batch 6/31 - 169.6ms/batch - loss: 210.31557 - diff: 46.56mlTrain batch 7/31 - 169.8ms/batch - loss: 207.75215 - diff: 45.42mlTrain batch 8/31 - 170.3ms/batch - loss: 226.04213 - diff: 46.43mlTrain batch 9/31 - 170.0ms/batch - loss: 231.26664 - diff: 47.11mlTrain batch 10/31 - 170.5ms/batch - loss: 221.97616 - diff: 46.38mlTrain batch 11/31 - 170.3ms/batch - loss: 265.12347 - diff: 47.12mlTrain batch 12/31 - 170.2ms/batch - loss: 256.88842 - diff: 46.08mlTrain batch 13/31 - 170.0ms/batch - loss: 242.46099 - diff: 44.50mlTrain batch 14/31 - 170.4ms/batch - loss: 231.14699 - diff: 43.55mlTrain batch 15/31 - 170.0ms/batch - loss: 222.00528 - diff: 42.65mlTrain batch 16/31 - 170.4ms/batch - loss: 221.69274 - diff: 42.55mlTrain batch 17/31 - 170.2ms/batch - loss: 216.01278 - diff: 42.34mlTrain batch 18/31 - 170.9ms/batch - loss: 214.53749 - diff: 42.64mlTrain batch 19/31 - 170.2ms/batch - loss: 209.79206 - diff: 42.20mlTrain batch 20/31 - 170.3ms/batch - loss: 203.71916 - diff: 41.52mlTrain batch 21/31 - 170.2ms/batch - loss: 201.08952 - diff: 41.48mlTrain batch 22/31 - 170.4ms/batch - loss: 199.08228 - diff: 41.32mlTrain batch 23/31 - 169.7ms/batch - loss: 202.38689 - diff: 41.77mlTrain batch 24/31 - 169.8ms/batch - loss: 205.38879 - diff: 41.91mlTrain batch 25/31 - 170.5ms/batch - loss: 200.84409 - diff: 41.48mlTrain batch 26/31 - 170.3ms/batch - loss: 198.12993 - diff: 41.22mlTrain batch 27/31 - 170.1ms/batch - loss: 195.49666 - diff: 41.04mlTrain batch 28/31 - 170.4ms/batch - loss: 190.87994 - diff: 40.52mlTrain batch 29/31 - 170.2ms/batch - loss: 187.38468 - diff: 40.13mlTrain batch 30/31 - 170.7ms/batch - loss: 186.63441 - diff: 40.33mlTrain batch 31/31 - 85.8ms/batch - loss: 189.35598 - diff: 40.34mlTrain batch 31/31 - 10.0s 85.8ms/batch - loss: 189.35598 - diff: 40.34ml
Test 1.1s: val_loss: 185.30207 - diff: 39.79ml

Epoch 10: current best loss = 179.14294, at epoch 8
Train batch 1/31 - 170.3ms/batch - loss: 140.89417 - diff: 42.59mlTrain batch 2/31 - 169.7ms/batch - loss: 161.44840 - diff: 41.64mlTrain batch 3/31 - 169.8ms/batch - loss: 186.26636 - diff: 39.93mlTrain batch 4/31 - 169.7ms/batch - loss: 194.74689 - diff: 41.06mlTrain batch 5/31 - 170.3ms/batch - loss: 197.97795 - diff: 41.61mlTrain batch 6/31 - 170.3ms/batch - loss: 189.78527 - diff: 40.67mlTrain batch 7/31 - 170.1ms/batch - loss: 187.85535 - diff: 40.13mlTrain batch 8/31 - 170.6ms/batch - loss: 183.48421 - diff: 40.38mlTrain batch 9/31 - 170.0ms/batch - loss: 170.80397 - diff: 39.07mlTrain batch 10/31 - 170.7ms/batch - loss: 183.05188 - diff: 40.52mlTrain batch 11/31 - 170.3ms/batch - loss: 241.28835 - diff: 43.39mlTrain batch 12/31 - 170.2ms/batch - loss: 239.60256 - diff: 43.80mlTrain batch 13/31 - 170.3ms/batch - loss: 230.40521 - diff: 42.88mlTrain batch 14/31 - 170.8ms/batch - loss: 220.59952 - diff: 42.14mlTrain batch 15/31 - 170.4ms/batch - loss: 217.53118 - diff: 42.11mlTrain batch 16/31 - 170.4ms/batch - loss: 213.75599 - diff: 42.14mlTrain batch 17/31 - 170.4ms/batch - loss: 208.48759 - diff: 41.71mlTrain batch 18/31 - 170.4ms/batch - loss: 206.77802 - diff: 41.87mlTrain batch 19/31 - 170.4ms/batch - loss: 199.52597 - diff: 41.10mlTrain batch 20/31 - 169.7ms/batch - loss: 195.08539 - diff: 40.63mlTrain batch 21/31 - 169.9ms/batch - loss: 194.02353 - diff: 40.85mlTrain batch 22/31 - 169.6ms/batch - loss: 196.01822 - diff: 40.71mlTrain batch 23/31 - 170.4ms/batch - loss: 192.59440 - diff: 40.47mlTrain batch 24/31 - 170.3ms/batch - loss: 194.99418 - diff: 40.87mlTrain batch 25/31 - 170.2ms/batch - loss: 190.67493 - diff: 40.44mlTrain batch 26/31 - 170.8ms/batch - loss: 188.31870 - diff: 40.14mlTrain batch 27/31 - 170.1ms/batch - loss: 186.85848 - diff: 40.07mlTrain batch 28/31 - 170.7ms/batch - loss: 187.62367 - diff: 40.29mlTrain batch 29/31 - 170.2ms/batch - loss: 185.08665 - diff: 40.15mlTrain batch 30/31 - 170.8ms/batch - loss: 184.99428 - diff: 39.97mlTrain batch 31/31 - 86.6ms/batch - loss: 186.58294 - diff: 40.01mlTrain batch 31/31 - 10.1s 86.6ms/batch - loss: 186.58294 - diff: 40.01ml
Test 1.1s: val_loss: 161.86158 - diff: 39.34ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_WideResNet50_0_Adam-0.001_MSE_DA3_best

Epoch 11: current best loss = 161.86158, at epoch 10
Train batch 1/31 - 182.7ms/batch - loss: 157.82094 - diff: 37.62mlTrain batch 2/31 - 170.3ms/batch - loss: 400.14625 - diff: 46.45mlTrain batch 3/31 - 170.3ms/batch - loss: 333.18971 - diff: 46.77mlTrain batch 4/31 - 170.6ms/batch - loss: 283.53675 - diff: 43.96mlTrain batch 5/31 - 170.4ms/batch - loss: 259.27793 - diff: 43.36mlTrain batch 6/31 - 170.7ms/batch - loss: 235.69196 - diff: 42.07mlTrain batch 7/31 - 170.3ms/batch - loss: 245.55728 - diff: 43.99mlTrain batch 8/31 - 170.9ms/batch - loss: 228.09497 - diff: 42.37mlTrain batch 9/31 - 170.2ms/batch - loss: 219.43954 - diff: 41.93mlTrain batch 10/31 - 170.9ms/batch - loss: 204.15368 - diff: 40.42mlTrain batch 11/31 - 170.3ms/batch - loss: 210.00354 - diff: 41.41mlTrain batch 12/31 - 170.6ms/batch - loss: 209.45682 - diff: 42.05mlTrain batch 13/31 - 170.4ms/batch - loss: 202.22431 - diff: 40.84mlTrain batch 14/31 - 169.8ms/batch - loss: 196.97414 - diff: 40.66mlTrain batch 15/31 - 170.5ms/batch - loss: 194.00250 - diff: 40.53mlTrain batch 16/31 - 169.6ms/batch - loss: 196.00486 - diff: 41.01mlTrain batch 17/31 - 170.5ms/batch - loss: 194.75685 - diff: 40.99mlTrain batch 18/31 - 170.6ms/batch - loss: 189.48664 - diff: 40.29mlTrain batch 19/31 - 170.3ms/batch - loss: 196.56073 - diff: 40.44mlTrain batch 20/31 - 170.7ms/batch - loss: 194.19872 - diff: 40.22mlTrain batch 21/31 - 170.5ms/batch - loss: 193.22746 - diff: 40.22mlTrain batch 22/31 - 170.6ms/batch - loss: 191.98667 - diff: 40.12mlTrain batch 23/31 - 170.5ms/batch - loss: 188.65571 - diff: 40.00mlTrain batch 24/31 - 170.6ms/batch - loss: 187.29891 - diff: 39.95mlTrain batch 25/31 - 170.5ms/batch - loss: 184.27900 - diff: 39.77mlTrain batch 26/31 - 170.6ms/batch - loss: 186.12397 - diff: 40.10mlTrain batch 27/31 - 170.3ms/batch - loss: 186.27034 - diff: 40.38mlTrain batch 28/31 - 170.7ms/batch - loss: 187.37376 - diff: 40.37mlTrain batch 29/31 - 170.5ms/batch - loss: 184.90438 - diff: 40.09mlTrain batch 30/31 - 170.0ms/batch - loss: 182.44992 - diff: 39.81mlTrain batch 31/31 - 85.9ms/batch - loss: 182.77942 - diff: 39.67mlTrain batch 31/31 - 10.1s 85.9ms/batch - loss: 182.77942 - diff: 39.67ml
Test 1.1s: val_loss: 189.58980 - diff: 40.21ml

Epoch 12: current best loss = 161.86158, at epoch 10
Train batch 1/31 - 170.3ms/batch - loss: 240.66644 - diff: 47.47mlTrain batch 2/31 - 170.6ms/batch - loss: 150.39179 - diff: 35.67mlTrain batch 3/31 - 170.4ms/batch - loss: 153.39378 - diff: 36.91mlTrain batch 4/31 - 170.7ms/batch - loss: 289.85274 - diff: 41.97mlTrain batch 5/31 - 170.4ms/batch - loss: 256.38078 - diff: 41.30mlTrain batch 6/31 - 170.9ms/batch - loss: 226.16383 - diff: 39.43mlTrain batch 7/31 - 170.5ms/batch - loss: 217.92186 - diff: 40.47mlTrain batch 8/31 - 170.6ms/batch - loss: 201.21364 - diff: 38.83mlTrain batch 9/31 - 170.3ms/batch - loss: 215.87550 - diff: 40.53mlTrain batch 10/31 - 170.1ms/batch - loss: 215.12565 - diff: 41.02mlTrain batch 11/31 - 170.1ms/batch - loss: 207.83358 - diff: 40.16mlTrain batch 12/31 - 170.8ms/batch - loss: 213.44769 - diff: 40.93mlTrain batch 13/31 - 170.4ms/batch - loss: 200.95215 - diff: 39.61mlTrain batch 14/31 - 170.7ms/batch - loss: 196.35508 - diff: 39.28mlTrain batch 15/31 - 170.5ms/batch - loss: 198.13714 - diff: 39.87mlTrain batch 16/31 - 170.7ms/batch - loss: 191.68158 - diff: 39.12mlTrain batch 17/31 - 170.4ms/batch - loss: 185.04363 - diff: 38.61mlTrain batch 18/31 - 170.7ms/batch - loss: 181.94872 - diff: 38.38mlTrain batch 19/31 - 170.4ms/batch - loss: 193.33536 - diff: 39.38mlTrain batch 20/31 - 170.7ms/batch - loss: 189.91547 - diff: 39.01mlTrain batch 21/31 - 170.3ms/batch - loss: 187.07502 - diff: 38.94mlTrain batch 22/31 - 170.8ms/batch - loss: 190.38189 - diff: 39.21mlTrain batch 23/31 - 170.4ms/batch - loss: 192.76405 - diff: 39.65mlTrain batch 24/31 - 170.8ms/batch - loss: 191.32384 - diff: 39.81mlTrain batch 25/31 - 170.6ms/batch - loss: 188.95089 - diff: 39.77mlTrain batch 26/31 - 170.4ms/batch - loss: 184.67700 - diff: 39.43mlTrain batch 27/31 - 170.0ms/batch - loss: 182.06724 - diff: 39.28mlTrain batch 28/31 - 169.9ms/batch - loss: 182.06272 - diff: 39.43mlTrain batch 29/31 - 170.2ms/batch - loss: 183.22859 - diff: 39.78mlTrain batch 30/31 - 170.7ms/batch - loss: 187.27186 - diff: 40.25mlTrain batch 31/31 - 85.7ms/batch - loss: 186.28391 - diff: 40.02mlTrain batch 31/31 - 10.1s 85.7ms/batch - loss: 186.28391 - diff: 40.02ml
Test 1.1s: val_loss: 169.94405 - diff: 40.29ml

Epoch 13: current best loss = 161.86158, at epoch 10
Train batch 1/31 - 170.7ms/batch - loss: 100.29437 - diff: 33.73mlTrain batch 2/31 - 170.7ms/batch - loss: 143.43466 - diff: 39.91mlTrain batch 3/31 - 170.5ms/batch - loss: 149.60835 - diff: 39.96mlTrain batch 4/31 - 170.9ms/batch - loss: 195.76461 - diff: 43.18mlTrain batch 5/31 - 170.6ms/batch - loss: 308.59977 - diff: 47.20mlTrain batch 6/31 - 170.0ms/batch - loss: 287.46223 - diff: 46.62mlTrain batch 7/31 - 169.8ms/batch - loss: 259.88409 - diff: 44.16mlTrain batch 8/31 - 169.9ms/batch - loss: 247.80375 - diff: 43.54mlTrain batch 9/31 - 170.2ms/batch - loss: 244.69365 - diff: 43.83mlTrain batch 10/31 - 169.7ms/batch - loss: 234.53956 - diff: 43.33mlTrain batch 11/31 - 170.4ms/batch - loss: 230.56429 - diff: 43.63mlTrain batch 12/31 - 170.0ms/batch - loss: 223.11192 - diff: 42.68mlTrain batch 13/31 - 170.6ms/batch - loss: 217.71389 - diff: 42.88mlTrain batch 14/31 - 170.7ms/batch - loss: 209.23728 - diff: 42.20mlTrain batch 15/31 - 170.6ms/batch - loss: 204.98589 - diff: 41.81mlTrain batch 16/31 - 170.9ms/batch - loss: 208.36577 - diff: 42.08mlTrain batch 17/31 - 170.6ms/batch - loss: 202.04046 - diff: 41.53mlTrain batch 18/31 - 170.9ms/batch - loss: 208.76830 - diff: 41.75mlTrain batch 19/31 - 170.4ms/batch - loss: 201.69234 - diff: 41.16mlTrain batch 20/31 - 170.8ms/batch - loss: 197.35006 - diff: 40.89mlTrain batch 21/31 - 170.6ms/batch - loss: 199.90611 - diff: 40.96mlTrain batch 22/31 - 170.9ms/batch - loss: 197.75049 - diff: 40.94mlTrain batch 23/31 - 170.4ms/batch - loss: 194.12659 - diff: 40.73mlTrain batch 24/31 - 169.5ms/batch - loss: 191.30762 - diff: 40.35mlTrain batch 25/31 - 170.2ms/batch - loss: 191.98731 - diff: 40.71mlTrain batch 26/31 - 170.5ms/batch - loss: 188.42223 - diff: 40.44mlTrain batch 27/31 - 170.6ms/batch - loss: 188.52813 - diff: 40.43mlTrain batch 28/31 - 170.7ms/batch - loss: 183.12298 - diff: 39.68mlTrain batch 29/31 - 170.7ms/batch - loss: 182.52282 - diff: 39.53mlTrain batch 30/31 - 170.9ms/batch - loss: 181.98748 - diff: 39.57mlTrain batch 31/31 - 85.8ms/batch - loss: 186.00547 - diff: 39.73mlTrain batch 31/31 - 10.1s 85.8ms/batch - loss: 186.00547 - diff: 39.73ml
Test 1.1s: val_loss: 162.30352 - diff: 39.65ml

Epoch 14: current best loss = 161.86158, at epoch 10
Train batch 1/31 - 170.6ms/batch - loss: 147.03731 - diff: 33.32mlTrain batch 2/31 - 171.0ms/batch - loss: 112.81765 - diff: 32.16mlTrain batch 3/31 - 171.0ms/batch - loss: 137.83720 - diff: 36.14mlTrain batch 4/31 - 170.5ms/batch - loss: 124.25017 - diff: 34.78mlTrain batch 5/31 - 170.2ms/batch - loss: 121.32559 - diff: 33.97mlTrain batch 6/31 - 170.0ms/batch - loss: 124.62310 - diff: 33.47mlTrain batch 7/31 - 171.0ms/batch - loss: 114.78607 - diff: 32.17mlTrain batch 8/31 - 170.7ms/batch - loss: 116.45156 - diff: 32.64mlTrain batch 9/31 - 170.9ms/batch - loss: 117.58371 - diff: 33.05mlTrain batch 10/31 - 171.1ms/batch - loss: 120.38529 - diff: 33.36mlTrain batch 11/31 - 170.9ms/batch - loss: 131.75815 - diff: 34.80mlTrain batch 12/31 - 171.2ms/batch - loss: 142.59791 - diff: 35.31mlTrain batch 13/31 - 171.0ms/batch - loss: 144.70723 - diff: 35.79mlTrain batch 14/31 - 171.3ms/batch - loss: 155.73661 - diff: 36.97mlTrain batch 15/31 - 170.8ms/batch - loss: 155.91575 - diff: 37.43mlTrain batch 16/31 - 171.2ms/batch - loss: 162.33428 - diff: 37.80mlTrain batch 17/31 - 171.0ms/batch - loss: 172.77834 - diff: 38.99mlTrain batch 18/31 - 171.1ms/batch - loss: 170.30573 - diff: 38.50mlTrain batch 19/31 - 170.8ms/batch - loss: 174.57203 - diff: 39.14mlTrain batch 20/31 - 171.3ms/batch - loss: 169.61570 - diff: 38.60mlTrain batch 21/31 - 171.0ms/batch - loss: 168.28104 - diff: 38.71mlTrain batch 22/31 - 170.2ms/batch - loss: 195.71803 - diff: 39.93mlTrain batch 23/31 - 171.0ms/batch - loss: 194.83568 - diff: 40.20mlTrain batch 24/31 - 171.1ms/batch - loss: 195.80019 - diff: 40.70mlTrain batch 25/31 - 170.8ms/batch - loss: 193.15586 - diff: 40.65mlTrain batch 26/31 - 171.2ms/batch - loss: 190.20781 - diff: 40.39mlTrain batch 27/31 - 171.0ms/batch - loss: 190.32039 - diff: 40.61mlTrain batch 28/31 - 170.9ms/batch - loss: 187.35274 - diff: 40.32mlTrain batch 29/31 - 171.0ms/batch - loss: 185.50859 - diff: 40.14mlTrain batch 30/31 - 171.3ms/batch - loss: 182.49720 - diff: 39.85mlTrain batch 31/31 - 86.1ms/batch - loss: 199.12082 - diff: 40.31mlTrain batch 31/31 - 10.1s 86.1ms/batch - loss: 199.12082 - diff: 40.31ml
Test 1.1s: val_loss: 164.57769 - diff: 39.45ml

Epoch 15: current best loss = 161.86158, at epoch 10
Train batch 1/31 - 171.1ms/batch - loss: 341.50146 - diff: 56.36mlTrain batch 2/31 - 171.3ms/batch - loss: 271.49900 - diff: 48.25mlTrain batch 3/31 - 170.8ms/batch - loss: 220.94922 - diff: 43.77mlTrain batch 4/31 - 171.4ms/batch - loss: 201.18785 - diff: 40.86mlTrain batch 5/31 - 171.0ms/batch - loss: 188.84243 - diff: 40.54mlTrain batch 6/31 - 171.2ms/batch - loss: 192.17998 - diff: 41.66mlTrain batch 7/31 - 170.7ms/batch - loss: 192.47363 - diff: 41.80mlTrain batch 8/31 - 171.4ms/batch - loss: 191.71395 - diff: 42.45mlTrain batch 9/31 - 171.0ms/batch - loss: 181.33300 - diff: 41.06mlTrain batch 10/31 - 170.9ms/batch - loss: 171.40048 - diff: 39.95mlTrain batch 11/31 - 170.9ms/batch - loss: 164.56284 - diff: 39.46mlTrain batch 12/31 - 171.2ms/batch - loss: 175.42751 - diff: 40.21mlTrain batch 13/31 - 170.7ms/batch - loss: 175.94283 - diff: 40.84mlTrain batch 14/31 - 170.4ms/batch - loss: 174.53166 - diff: 40.33mlTrain batch 15/31 - 170.7ms/batch - loss: 169.70996 - diff: 39.89mlTrain batch 16/31 - 171.4ms/batch - loss: 164.88996 - diff: 39.32mlTrain batch 17/31 - 171.1ms/batch - loss: 161.72165 - diff: 39.04mlTrain batch 18/31 - 171.3ms/batch - loss: 159.51147 - diff: 39.00mlTrain batch 19/31 - 170.9ms/batch - loss: 160.60443 - diff: 39.01mlTrain batch 20/31 - 171.1ms/batch - loss: 159.93756 - diff: 38.82mlTrain batch 21/31 - 171.1ms/batch - loss: 165.36243 - diff: 39.67mlTrain batch 22/31 - 171.5ms/batch - loss: 170.87237 - diff: 39.94mlTrain batch 23/31 - 171.1ms/batch - loss: 169.63261 - diff: 39.78mlTrain batch 24/31 - 171.3ms/batch - loss: 166.80530 - diff: 39.54mlTrain batch 25/31 - 171.0ms/batch - loss: 169.55374 - diff: 39.94mlTrain batch 26/31 - 170.5ms/batch - loss: 169.06534 - diff: 39.98mlTrain batch 27/31 - 170.8ms/batch - loss: 170.34926 - diff: 40.12mlTrain batch 28/31 - 170.6ms/batch - loss: 169.23473 - diff: 39.99mlTrain batch 29/31 - 171.0ms/batch - loss: 168.48382 - diff: 39.80mlTrain batch 30/31 - 171.3ms/batch - loss: 166.45683 - diff: 39.60mlTrain batch 31/31 - 86.2ms/batch - loss: 209.77754 - diff: 40.02mlTrain batch 31/31 - 10.1s 86.2ms/batch - loss: 209.77754 - diff: 40.02ml
Test 1.1s: val_loss: 176.36346 - diff: 39.84ml

Epoch 16: current best loss = 161.86158, at epoch 10
Train batch 1/31 - 170.8ms/batch - loss: 153.19351 - diff: 42.67mlTrain batch 2/31 - 171.3ms/batch - loss: 118.51301 - diff: 35.98mlTrain batch 3/31 - 171.1ms/batch - loss: 131.97723 - diff: 36.92mlTrain batch 4/31 - 171.5ms/batch - loss: 162.63334 - diff: 38.29mlTrain batch 5/31 - 170.8ms/batch - loss: 168.97872 - diff: 39.75mlTrain batch 6/31 - 171.5ms/batch - loss: 165.08658 - diff: 39.27mlTrain batch 7/31 - 171.1ms/batch - loss: 160.69516 - diff: 38.17mlTrain batch 8/31 - 171.4ms/batch - loss: 173.33602 - diff: 39.43mlTrain batch 9/31 - 171.0ms/batch - loss: 175.03040 - diff: 39.86mlTrain batch 10/31 - 171.4ms/batch - loss: 172.65697 - diff: 39.78mlTrain batch 11/31 - 170.9ms/batch - loss: 176.58254 - diff: 40.71mlTrain batch 12/31 - 171.5ms/batch - loss: 167.69644 - diff: 39.43mlTrain batch 13/31 - 171.1ms/batch - loss: 163.09725 - diff: 38.82mlTrain batch 14/31 - 171.4ms/batch - loss: 160.44415 - diff: 38.71mlTrain batch 15/31 - 171.0ms/batch - loss: 161.34143 - diff: 38.94mlTrain batch 16/31 - 171.3ms/batch - loss: 158.50984 - diff: 38.78mlTrain batch 17/31 - 170.9ms/batch - loss: 157.49653 - diff: 38.68mlTrain batch 18/31 - 170.6ms/batch - loss: 158.59346 - diff: 38.87mlTrain batch 19/31 - 171.1ms/batch - loss: 162.48126 - diff: 39.43mlTrain batch 20/31 - 171.4ms/batch - loss: 160.40477 - diff: 39.14mlTrain batch 21/31 - 170.7ms/batch - loss: 156.21647 - diff: 38.53mlTrain batch 22/31 - 171.2ms/batch - loss: 159.76475 - diff: 38.33mlTrain batch 23/31 - 170.8ms/batch - loss: 157.42141 - diff: 38.31mlTrain batch 24/31 - 171.3ms/batch - loss: 157.95629 - diff: 38.49mlTrain batch 25/31 - 171.2ms/batch - loss: 160.93476 - diff: 38.78mlTrain batch 26/31 - 171.4ms/batch - loss: 160.05047 - diff: 38.69mlTrain batch 27/31 - 171.1ms/batch - loss: 157.88783 - diff: 38.57mlTrain batch 28/31 - 171.7ms/batch - loss: 159.31544 - diff: 38.86mlTrain batch 29/31 - 171.1ms/batch - loss: 157.03266 - diff: 38.47mlTrain batch 30/31 - 171.7ms/batch - loss: 176.78515 - diff: 39.13mlTrain batch 31/31 - 86.2ms/batch - loss: 179.22377 - diff: 39.06mlTrain batch 31/31 - 10.1s 86.2ms/batch - loss: 179.22377 - diff: 39.06ml
Test 1.1s: val_loss: 150.12318 - diff: 38.50ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_WideResNet50_0_Adam-0.001_MSE_DA3_best

Epoch 17: current best loss = 150.12318, at epoch 16
Train batch 1/31 - 171.0ms/batch - loss: 41.42986 - diff: 22.16mlTrain batch 2/31 - 171.4ms/batch - loss: 148.29908 - diff: 35.69mlTrain batch 3/31 - 170.7ms/batch - loss: 152.60396 - diff: 35.56mlTrain batch 4/31 - 171.4ms/batch - loss: 136.45188 - diff: 34.52mlTrain batch 5/31 - 171.2ms/batch - loss: 127.20551 - diff: 33.40mlTrain batch 6/31 - 171.0ms/batch - loss: 136.09018 - diff: 34.91mlTrain batch 7/31 - 170.6ms/batch - loss: 133.91207 - diff: 35.08mlTrain batch 8/31 - 170.3ms/batch - loss: 126.92765 - diff: 34.07mlTrain batch 9/31 - 171.1ms/batch - loss: 136.44727 - diff: 35.06mlTrain batch 10/31 - 171.4ms/batch - loss: 137.44779 - diff: 35.17mlTrain batch 11/31 - 170.8ms/batch - loss: 137.71159 - diff: 34.97mlTrain batch 12/31 - 171.3ms/batch - loss: 193.53114 - diff: 37.44mlTrain batch 13/31 - 171.2ms/batch - loss: 190.64521 - diff: 37.39mlTrain batch 14/31 - 171.6ms/batch - loss: 179.78475 - diff: 36.23mlTrain batch 15/31 - 171.0ms/batch - loss: 174.47872 - diff: 36.02mlTrain batch 16/31 - 171.7ms/batch - loss: 172.55482 - diff: 36.29mlTrain batch 17/31 - 171.2ms/batch - loss: 170.65600 - diff: 36.49mlTrain batch 18/31 - 171.1ms/batch - loss: 167.66630 - diff: 36.42mlTrain batch 19/31 - 171.1ms/batch - loss: 163.24339 - diff: 36.19mlTrain batch 20/31 - 171.2ms/batch - loss: 159.77829 - diff: 35.93mlTrain batch 21/31 - 171.1ms/batch - loss: 160.12386 - diff: 36.21mlTrain batch 22/31 - 171.4ms/batch - loss: 164.61327 - diff: 36.48mlTrain batch 23/31 - 171.1ms/batch - loss: 165.55495 - diff: 36.82mlTrain batch 24/31 - 171.3ms/batch - loss: 169.43523 - diff: 37.34mlTrain batch 25/31 - 171.3ms/batch - loss: 164.90216 - diff: 36.86mlTrain batch 26/31 - 171.3ms/batch - loss: 173.82836 - diff: 37.84mlTrain batch 27/31 - 170.8ms/batch - loss: 174.72579 - diff: 37.92mlTrain batch 28/31 - 171.4ms/batch - loss: 173.89553 - diff: 37.99mlTrain batch 29/31 - 171.0ms/batch - loss: 172.16042 - diff: 37.96mlTrain batch 30/31 - 170.2ms/batch - loss: 175.63571 - diff: 38.31mlTrain batch 31/31 - 86.2ms/batch - loss: 182.80316 - diff: 38.52mlTrain batch 31/31 - 10.2s 86.2ms/batch - loss: 182.80316 - diff: 38.52ml
Test 1.1s: val_loss: 160.99211 - diff: 38.10ml

Epoch 18: current best loss = 150.12318, at epoch 16
Train batch 1/31 - 171.1ms/batch - loss: 83.78828 - diff: 26.89mlTrain batch 2/31 - 171.4ms/batch - loss: 142.25419 - diff: 33.93mlTrain batch 3/31 - 171.1ms/batch - loss: 122.36646 - diff: 32.11mlTrain batch 4/31 - 171.6ms/batch - loss: 119.86699 - diff: 32.90mlTrain batch 5/31 - 171.2ms/batch - loss: 116.58980 - diff: 32.64mlTrain batch 6/31 - 172.0ms/batch - loss: 117.35735 - diff: 33.27mlTrain batch 7/31 - 171.1ms/batch - loss: 109.82505 - diff: 32.14mlTrain batch 8/31 - 170.5ms/batch - loss: 123.68662 - diff: 34.22mlTrain batch 9/31 - 171.1ms/batch - loss: 127.34968 - diff: 35.05mlTrain batch 10/31 - 171.5ms/batch - loss: 131.67912 - diff: 35.22mlTrain batch 11/31 - 171.0ms/batch - loss: 137.82908 - diff: 36.61mlTrain batch 12/31 - 170.7ms/batch - loss: 139.59138 - diff: 36.72mlTrain batch 13/31 - 171.3ms/batch - loss: 136.70476 - diff: 36.58mlTrain batch 14/31 - 171.2ms/batch - loss: 129.46328 - diff: 35.28mlTrain batch 15/31 - 171.0ms/batch - loss: 128.98984 - diff: 35.26mlTrain batch 16/31 - 171.8ms/batch - loss: 128.20478 - diff: 35.31mlTrain batch 17/31 - 171.5ms/batch - loss: 124.97209 - diff: 34.83mlTrain batch 18/31 - 171.6ms/batch - loss: 126.72490 - diff: 35.15mlTrain batch 19/31 - 171.3ms/batch - loss: 125.61948 - diff: 34.92mlTrain batch 20/31 - 171.2ms/batch - loss: 132.68164 - diff: 35.34mlTrain batch 21/31 - 171.1ms/batch - loss: 141.75323 - diff: 36.21mlTrain batch 22/31 - 171.3ms/batch - loss: 140.55913 - diff: 36.09mlTrain batch 23/31 - 171.2ms/batch - loss: 141.36436 - diff: 36.22mlTrain batch 24/31 - 171.5ms/batch - loss: 141.04936 - diff: 36.29mlTrain batch 25/31 - 171.1ms/batch - loss: 165.96262 - diff: 37.49mlTrain batch 26/31 - 171.4ms/batch - loss: 166.47669 - diff: 37.66mlTrain batch 27/31 - 170.9ms/batch - loss: 170.53365 - diff: 38.26mlTrain batch 28/31 - 170.6ms/batch - loss: 178.22747 - diff: 38.85mlTrain batch 29/31 - 171.2ms/batch - loss: 174.57077 - diff: 38.46mlTrain batch 30/31 - 171.5ms/batch - loss: 172.40722 - diff: 38.37mlTrain batch 31/31 - 85.8ms/batch - loss: 177.86379 - diff: 38.61mlTrain batch 31/31 - 10.1s 85.8ms/batch - loss: 177.86379 - diff: 38.61ml
Test 1.1s: val_loss: 170.77919 - diff: 40.78ml

Epoch 19: current best loss = 150.12318, at epoch 16
Train batch 1/31 - 171.2ms/batch - loss: 101.22759 - diff: 29.82mlTrain batch 2/31 - 171.5ms/batch - loss: 99.56610 - diff: 32.23mlTrain batch 3/31 - 171.2ms/batch - loss: 148.70977 - diff: 37.59mlTrain batch 4/31 - 170.6ms/batch - loss: 141.97777 - diff: 36.54mlTrain batch 5/31 - 170.9ms/batch - loss: 151.35526 - diff: 37.60mlTrain batch 6/31 - 171.4ms/batch - loss: 150.52278 - diff: 37.70mlTrain batch 7/31 - 171.2ms/batch - loss: 172.43458 - diff: 40.30mlTrain batch 8/31 - 170.6ms/batch - loss: 160.34010 - diff: 38.70mlTrain batch 9/31 - 171.2ms/batch - loss: 170.14699 - diff: 38.80mlTrain batch 10/31 - 171.6ms/batch - loss: 167.66403 - diff: 38.85mlTrain batch 11/31 - 171.4ms/batch - loss: 159.24143 - diff: 37.75mlTrain batch 12/31 - 171.7ms/batch - loss: 155.82583 - diff: 37.36mlTrain batch 13/31 - 171.2ms/batch - loss: 155.76482 - diff: 37.70mlTrain batch 14/31 - 171.4ms/batch - loss: 151.63393 - diff: 37.37mlTrain batch 15/31 - 171.3ms/batch - loss: 153.02405 - diff: 37.71mlTrain batch 16/31 - 171.5ms/batch - loss: 154.00698 - diff: 38.15mlTrain batch 17/31 - 171.3ms/batch - loss: 159.98482 - diff: 38.33mlTrain batch 18/31 - 171.5ms/batch - loss: 155.02295 - diff: 37.71mlTrain batch 19/31 - 171.2ms/batch - loss: 154.76911 - diff: 37.83mlTrain batch 20/31 - 171.4ms/batch - loss: 150.00303 - diff: 37.25mlTrain batch 21/31 - 171.1ms/batch - loss: 152.48798 - diff: 37.51mlTrain batch 22/31 - 171.3ms/batch - loss: 180.22843 - diff: 38.62mlTrain batch 23/31 - 171.2ms/batch - loss: 176.70834 - diff: 38.28mlTrain batch 24/31 - 171.3ms/batch - loss: 173.51010 - diff: 37.91mlTrain batch 25/31 - 171.3ms/batch - loss: 173.03220 - diff: 37.84mlTrain batch 26/31 - 171.3ms/batch - loss: 170.35591 - diff: 37.67mlTrain batch 27/31 - 171.3ms/batch - loss: 168.84724 - diff: 37.62mlTrain batch 28/31 - 171.4ms/batch - loss: 169.20789 - diff: 37.60mlTrain batch 29/31 - 171.4ms/batch - loss: 171.82019 - diff: 38.03mlTrain batch 30/31 - 171.5ms/batch - loss: 172.81149 - diff: 38.30mlTrain batch 31/31 - 86.2ms/batch - loss: 175.08199 - diff: 38.29mlTrain batch 31/31 - 10.1s 86.2ms/batch - loss: 175.08199 - diff: 38.29ml
Test 1.1s: val_loss: 163.63464 - diff: 38.10ml

Epoch 20: current best loss = 150.12318, at epoch 16
Train batch 1/31 - 171.5ms/batch - loss: 732.11407 - diff: 62.21mlTrain batch 2/31 - 170.9ms/batch - loss: 437.63097 - diff: 48.51mlTrain batch 3/31 - 171.0ms/batch - loss: 333.76833 - diff: 44.58mlTrain batch 4/31 - 171.0ms/batch - loss: 282.72657 - diff: 42.71mlTrain batch 5/31 - 171.2ms/batch - loss: 260.36106 - diff: 41.11mlTrain batch 6/31 - 171.5ms/batch - loss: 239.31492 - diff: 40.86mlTrain batch 7/31 - 171.2ms/batch - loss: 232.72711 - diff: 40.60mlTrain batch 8/31 - 171.6ms/batch - loss: 214.81334 - diff: 39.44mlTrain batch 9/31 - 171.3ms/batch - loss: 212.87921 - diff: 39.21mlTrain batch 10/31 - 171.6ms/batch - loss: 223.81637 - diff: 40.69mlTrain batch 11/31 - 171.3ms/batch - loss: 217.93391 - diff: 40.74mlTrain batch 12/31 - 171.3ms/batch - loss: 214.81197 - diff: 40.91mlTrain batch 13/31 - 171.3ms/batch - loss: 210.96034 - diff: 40.60mlTrain batch 14/31 - 171.6ms/batch - loss: 198.97561 - diff: 39.27mlTrain batch 15/31 - 171.4ms/batch - loss: 193.17296 - diff: 38.81mlTrain batch 16/31 - 171.3ms/batch - loss: 186.71009 - diff: 38.25mlTrain batch 17/31 - 171.1ms/batch - loss: 181.80443 - diff: 38.06mlTrain batch 18/31 - 171.5ms/batch - loss: 182.44311 - diff: 38.20mlTrain batch 19/31 - 171.3ms/batch - loss: 176.30988 - diff: 37.71mlTrain batch 20/31 - 171.3ms/batch - loss: 175.12988 - diff: 37.85mlTrain batch 21/31 - 171.2ms/batch - loss: 173.78774 - diff: 37.85mlTrain batch 22/31 - 171.3ms/batch - loss: 181.43903 - diff: 38.49mlTrain batch 23/31 - 171.3ms/batch - loss: 177.87115 - diff: 38.32mlTrain batch 24/31 - 171.6ms/batch - loss: 180.63968 - diff: 38.88mlTrain batch 25/31 - 171.3ms/batch - loss: 178.73386 - diff: 38.89mlTrain batch 26/31 - 171.4ms/batch - loss: 178.02879 - diff: 39.11mlTrain batch 27/31 - 171.4ms/batch - loss: 180.23607 - diff: 39.38mlTrain batch 28/31 - 171.6ms/batch - loss: 177.30963 - diff: 39.05mlTrain batch 29/31 - 171.3ms/batch - loss: 173.78068 - diff: 38.67mlTrain batch 30/31 - 171.5ms/batch - loss: 172.65478 - diff: 38.57mlTrain batch 31/31 - 86.3ms/batch - loss: 177.53982 - diff: 38.74mlTrain batch 31/31 - 10.1s 86.3ms/batch - loss: 177.53982 - diff: 38.74ml
Test 1.1s: val_loss: 160.76752 - diff: 37.27ml

Epoch 21: current best loss = 150.12318, at epoch 16
Train batch 1/31 - 171.2ms/batch - loss: 85.29739 - diff: 29.17mlTrain batch 2/31 - 171.7ms/batch - loss: 107.83507 - diff: 33.63mlTrain batch 3/31 - 171.3ms/batch - loss: 147.54758 - diff: 37.37mlTrain batch 4/31 - 172.0ms/batch - loss: 142.08524 - diff: 37.43mlTrain batch 5/31 - 171.3ms/batch - loss: 135.11877 - diff: 36.97mlTrain batch 6/31 - 171.6ms/batch - loss: 159.54930 - diff: 40.04mlTrain batch 7/31 - 171.2ms/batch - loss: 183.98541 - diff: 41.86mlTrain batch 8/31 - 171.1ms/batch - loss: 190.88923 - diff: 42.36mlTrain batch 9/31 - 170.7ms/batch - loss: 183.18405 - diff: 41.21mlTrain batch 10/31 - 170.8ms/batch - loss: 172.78857 - diff: 40.03mlTrain batch 11/31 - 171.0ms/batch - loss: 167.67707 - diff: 39.37mlTrain batch 12/31 - 171.1ms/batch - loss: 169.64582 - diff: 39.84mlTrain batch 13/31 - 171.2ms/batch - loss: 165.17036 - diff: 39.17mlTrain batch 14/31 - 171.5ms/batch - loss: 166.53708 - diff: 39.51mlTrain batch 15/31 - 171.4ms/batch - loss: 159.02290 - diff: 38.53mlTrain batch 16/31 - 171.6ms/batch - loss: 166.88075 - diff: 39.43mlTrain batch 17/31 - 171.3ms/batch - loss: 194.28382 - diff: 40.04mlTrain batch 18/31 - 171.3ms/batch - loss: 191.54907 - diff: 40.07mlTrain batch 19/31 - 171.2ms/batch - loss: 185.59183 - diff: 39.42mlTrain batch 20/31 - 171.5ms/batch - loss: 181.06502 - diff: 39.18mlTrain batch 21/31 - 171.4ms/batch - loss: 180.62997 - diff: 39.12mlTrain batch 22/31 - 171.5ms/batch - loss: 174.87179 - diff: 38.44mlTrain batch 23/31 - 171.3ms/batch - loss: 171.84082 - diff: 38.25mlTrain batch 24/31 - 171.5ms/batch - loss: 171.55006 - diff: 38.42mlTrain batch 25/31 - 171.0ms/batch - loss: 167.07485 - diff: 37.87mlTrain batch 26/31 - 170.5ms/batch - loss: 164.78299 - diff: 37.54mlTrain batch 27/31 - 171.3ms/batch - loss: 165.82297 - diff: 37.68mlTrain batch 28/31 - 171.4ms/batch - loss: 163.28510 - diff: 37.49mlTrain batch 29/31 - 171.2ms/batch - loss: 163.47527 - diff: 37.79mlTrain batch 30/31 - 172.0ms/batch - loss: 165.39106 - diff: 38.17mlTrain batch 31/31 - 86.3ms/batch - loss: 164.44267 - diff: 37.92mlTrain batch 31/31 - 10.1s 86.3ms/batch - loss: 164.44267 - diff: 37.92ml
Test 1.1s: val_loss: 151.33695 - diff: 38.19ml

Epoch 22: current best loss = 150.12318, at epoch 16
Train batch 1/31 - 171.5ms/batch - loss: 97.31754 - diff: 30.64mlTrain batch 2/31 - 171.2ms/batch - loss: 75.07487 - diff: 27.86mlTrain batch 3/31 - 171.2ms/batch - loss: 132.29358 - diff: 37.47mlTrain batch 4/31 - 171.6ms/batch - loss: 173.76016 - diff: 38.69mlTrain batch 5/31 - 171.0ms/batch - loss: 163.00112 - diff: 38.15mlTrain batch 6/31 - 171.2ms/batch - loss: 166.29825 - diff: 38.94mlTrain batch 7/31 - 171.1ms/batch - loss: 158.82423 - diff: 38.51mlTrain batch 8/31 - 171.5ms/batch - loss: 151.75207 - diff: 38.02mlTrain batch 9/31 - 171.4ms/batch - loss: 149.04977 - diff: 38.06mlTrain batch 10/31 - 171.9ms/batch - loss: 148.57200 - diff: 38.05mlTrain batch 11/31 - 171.3ms/batch - loss: 155.87694 - diff: 37.54mlTrain batch 12/31 - 171.5ms/batch - loss: 162.40884 - diff: 37.93mlTrain batch 13/31 - 171.2ms/batch - loss: 162.26710 - diff: 38.16mlTrain batch 14/31 - 171.9ms/batch - loss: 161.68699 - diff: 38.25mlTrain batch 15/31 - 171.4ms/batch - loss: 158.34995 - diff: 37.91mlTrain batch 16/31 - 171.5ms/batch - loss: 156.72923 - diff: 38.00mlTrain batch 17/31 - 171.3ms/batch - loss: 153.50274 - diff: 37.45mlTrain batch 18/31 - 171.4ms/batch - loss: 153.81304 - diff: 37.70mlTrain batch 19/31 - 171.2ms/batch - loss: 151.45750 - diff: 37.42mlTrain batch 20/31 - 171.5ms/batch - loss: 182.24491 - diff: 38.77mlTrain batch 21/31 - 171.0ms/batch - loss: 180.04660 - diff: 38.63mlTrain batch 22/31 - 171.3ms/batch - loss: 181.46696 - diff: 39.07mlTrain batch 23/31 - 171.1ms/batch - loss: 176.46926 - diff: 38.56mlTrain batch 24/31 - 171.7ms/batch - loss: 173.78797 - diff: 38.36mlTrain batch 25/31 - 171.3ms/batch - loss: 169.79984 - diff: 38.07mlTrain batch 26/31 - 171.5ms/batch - loss: 169.51355 - diff: 38.04mlTrain batch 27/31 - 171.4ms/batch - loss: 168.83522 - diff: 38.21mlTrain batch 28/31 - 171.5ms/batch - loss: 172.54431 - diff: 38.67mlTrain batch 29/31 - 171.3ms/batch - loss: 172.23941 - diff: 38.83mlTrain batch 30/31 - 171.7ms/batch - loss: 169.95056 - diff: 38.73mlTrain batch 31/31 - 86.4ms/batch - loss: 170.77893 - diff: 38.65mlTrain batch 31/31 - 10.1s 86.4ms/batch - loss: 170.77893 - diff: 38.65ml
Test 1.1s: val_loss: 151.07039 - diff: 36.95ml

Epoch 23: current best loss = 150.12318, at epoch 16
Train batch 1/31 - 171.3ms/batch - loss: 144.86137 - diff: 41.67mlTrain batch 2/31 - 171.4ms/batch - loss: 178.14996 - diff: 42.34mlTrain batch 3/31 - 171.2ms/batch - loss: 147.64965 - diff: 39.17mlTrain batch 4/31 - 171.4ms/batch - loss: 150.04370 - diff: 39.80mlTrain batch 5/31 - 171.2ms/batch - loss: 143.48426 - diff: 39.09mlTrain batch 6/31 - 171.8ms/batch - loss: 130.56790 - diff: 36.79mlTrain batch 7/31 - 171.4ms/batch - loss: 122.11646 - diff: 35.58mlTrain batch 8/31 - 172.0ms/batch - loss: 136.48403 - diff: 37.02mlTrain batch 9/31 - 171.4ms/batch - loss: 138.32591 - diff: 37.65mlTrain batch 10/31 - 171.4ms/batch - loss: 146.87838 - diff: 38.74mlTrain batch 11/31 - 171.3ms/batch - loss: 140.72115 - diff: 37.85mlTrain batch 12/31 - 170.4ms/batch - loss: 147.86679 - diff: 38.39mlTrain batch 13/31 - 171.1ms/batch - loss: 151.04902 - diff: 38.57mlTrain batch 14/31 - 171.8ms/batch - loss: 163.55275 - diff: 39.92mlTrain batch 15/31 - 171.5ms/batch - loss: 158.02727 - diff: 39.25mlTrain batch 16/31 - 171.4ms/batch - loss: 158.81328 - diff: 39.38mlTrain batch 17/31 - 171.3ms/batch - loss: 155.24649 - diff: 38.98mlTrain batch 18/31 - 171.7ms/batch - loss: 165.85079 - diff: 39.90mlTrain batch 19/31 - 171.3ms/batch - loss: 160.43292 - diff: 39.16mlTrain batch 20/31 - 171.5ms/batch - loss: 160.38618 - diff: 39.09mlTrain batch 21/31 - 171.2ms/batch - loss: 155.50332 - diff: 38.47mlTrain batch 22/31 - 170.6ms/batch - loss: 154.44967 - diff: 38.43mlTrain batch 23/31 - 171.2ms/batch - loss: 153.75422 - diff: 38.31mlTrain batch 24/31 - 170.7ms/batch - loss: 152.19407 - diff: 38.16mlTrain batch 25/31 - 171.2ms/batch - loss: 147.72740 - diff: 37.46mlTrain batch 26/31 - 170.8ms/batch - loss: 151.31748 - diff: 37.68mlTrain batch 27/31 - 171.5ms/batch - loss: 168.73527 - diff: 38.36mlTrain batch 28/31 - 171.4ms/batch - loss: 169.03868 - diff: 38.49mlTrain batch 29/31 - 171.3ms/batch - loss: 171.20285 - diff: 38.66mlTrain batch 30/31 - 171.7ms/batch - loss: 167.82375 - diff: 38.25mlTrain batch 31/31 - 86.7ms/batch - loss: 167.28108 - diff: 38.10mlTrain batch 31/31 - 10.2s 86.7ms/batch - loss: 167.28108 - diff: 38.10ml
Test 1.1s: val_loss: 158.89745 - diff: 37.88ml

Epoch 24: current best loss = 150.12318, at epoch 16
Train batch 1/31 - 171.3ms/batch - loss: 82.58637 - diff: 28.53mlTrain batch 2/31 - 171.6ms/batch - loss: 138.20578 - diff: 36.07mlTrain batch 3/31 - 171.3ms/batch - loss: 145.01972 - diff: 36.16mlTrain batch 4/31 - 171.8ms/batch - loss: 152.67348 - diff: 36.54mlTrain batch 5/31 - 171.3ms/batch - loss: 148.84244 - diff: 36.74mlTrain batch 6/31 - 171.5ms/batch - loss: 157.46125 - diff: 38.01mlTrain batch 7/31 - 171.2ms/batch - loss: 143.59618 - diff: 36.60mlTrain batch 8/31 - 171.7ms/batch - loss: 130.90160 - diff: 34.83mlTrain batch 9/31 - 171.4ms/batch - loss: 151.40862 - diff: 36.98mlTrain batch 10/31 - 171.7ms/batch - loss: 150.75914 - diff: 36.91mlTrain batch 11/31 - 171.3ms/batch - loss: 155.44029 - diff: 37.26mlTrain batch 12/31 - 171.7ms/batch - loss: 150.70688 - diff: 36.86mlTrain batch 13/31 - 171.4ms/batch - loss: 147.54287 - diff: 36.76mlTrain batch 14/31 - 171.3ms/batch - loss: 142.96491 - diff: 36.25mlTrain batch 15/31 - 171.2ms/batch - loss: 155.99801 - diff: 37.19mlTrain batch 16/31 - 171.7ms/batch - loss: 160.17389 - diff: 37.66mlTrain batch 17/31 - 171.4ms/batch - loss: 156.69940 - diff: 37.42mlTrain batch 18/31 - 171.5ms/batch - loss: 187.29183 - diff: 38.59mlTrain batch 19/31 - 171.4ms/batch - loss: 187.58423 - diff: 38.60mlTrain batch 20/31 - 171.4ms/batch - loss: 187.21871 - diff: 38.77mlTrain batch 21/31 - 171.3ms/batch - loss: 182.23389 - diff: 38.39mlTrain batch 22/31 - 171.7ms/batch - loss: 180.02380 - diff: 38.56mlTrain batch 23/31 - 171.3ms/batch - loss: 180.38576 - diff: 38.78mlTrain batch 24/31 - 171.6ms/batch - loss: 176.17661 - diff: 38.46mlTrain batch 25/31 - 171.4ms/batch - loss: 176.58022 - diff: 38.71mlTrain batch 26/31 - 172.1ms/batch - loss: 178.54197 - diff: 39.23mlTrain batch 27/31 - 171.3ms/batch - loss: 177.54900 - diff: 39.09mlTrain batch 28/31 - 171.8ms/batch - loss: 174.43132 - diff: 38.80mlTrain batch 29/31 - 171.4ms/batch - loss: 173.30355 - diff: 38.69mlTrain batch 30/31 - 171.9ms/batch - loss: 171.63510 - diff: 38.54mlTrain batch 31/31 - 86.3ms/batch - loss: 173.58709 - diff: 38.53mlTrain batch 31/31 - 10.1s 86.3ms/batch - loss: 173.58709 - diff: 38.53ml
Test 1.1s: val_loss: 148.20383 - diff: 38.22ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_WideResNet50_0_Adam-0.001_MSE_DA3_best

Epoch 25: current best loss = 148.20383, at epoch 24
Train batch 1/31 - 171.4ms/batch - loss: 128.99641 - diff: 38.26mlTrain batch 2/31 - 172.1ms/batch - loss: 152.11510 - diff: 39.42mlTrain batch 3/31 - 171.2ms/batch - loss: 153.79646 - diff: 40.03mlTrain batch 4/31 - 171.5ms/batch - loss: 142.77919 - diff: 38.86mlTrain batch 5/31 - 171.5ms/batch - loss: 127.58466 - diff: 36.14mlTrain batch 6/31 - 171.5ms/batch - loss: 124.09830 - diff: 35.37mlTrain batch 7/31 - 171.5ms/batch - loss: 118.96384 - diff: 34.77mlTrain batch 8/31 - 170.4ms/batch - loss: 116.85993 - diff: 34.59mlTrain batch 9/31 - 171.5ms/batch - loss: 116.78766 - diff: 34.57mlTrain batch 10/31 - 171.5ms/batch - loss: 125.72610 - diff: 34.89mlTrain batch 11/31 - 171.4ms/batch - loss: 131.80225 - diff: 35.31mlTrain batch 12/31 - 171.4ms/batch - loss: 129.94018 - diff: 34.78mlTrain batch 13/31 - 171.3ms/batch - loss: 130.33051 - diff: 34.81mlTrain batch 14/31 - 171.8ms/batch - loss: 136.16485 - diff: 35.73mlTrain batch 15/31 - 171.3ms/batch - loss: 130.79664 - diff: 34.96mlTrain batch 16/31 - 171.6ms/batch - loss: 126.37549 - diff: 34.46mlTrain batch 17/31 - 171.3ms/batch - loss: 129.58130 - diff: 34.48mlTrain batch 18/31 - 171.7ms/batch - loss: 131.18432 - diff: 34.78mlTrain batch 19/31 - 171.3ms/batch - loss: 134.30625 - diff: 35.31mlTrain batch 20/31 - 171.7ms/batch - loss: 136.44561 - diff: 35.58mlTrain batch 21/31 - 171.2ms/batch - loss: 133.73242 - diff: 35.35mlTrain batch 22/31 - 171.7ms/batch - loss: 146.63659 - diff: 36.67mlTrain batch 23/31 - 171.4ms/batch - loss: 145.62284 - diff: 36.70mlTrain batch 24/31 - 171.7ms/batch - loss: 144.39951 - diff: 36.62mlTrain batch 25/31 - 171.2ms/batch - loss: 140.92360 - diff: 36.16mlTrain batch 26/31 - 171.8ms/batch - loss: 160.35455 - diff: 36.82mlTrain batch 27/31 - 171.6ms/batch - loss: 164.04943 - diff: 37.00mlTrain batch 28/31 - 171.8ms/batch - loss: 167.40614 - diff: 37.52mlTrain batch 29/31 - 171.4ms/batch - loss: 165.16738 - diff: 37.30mlTrain batch 30/31 - 171.8ms/batch - loss: 162.04734 - diff: 37.00mlTrain batch 31/31 - 86.3ms/batch - loss: 163.38043 - diff: 36.91mlTrain batch 31/31 - 10.1s 86.3ms/batch - loss: 163.38043 - diff: 36.91ml
Test 1.1s: val_loss: 139.41615 - diff: 36.93ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_WideResNet50_0_Adam-0.001_MSE_DA3_best

Epoch 26: current best loss = 139.41615, at epoch 25
Train batch 1/31 - 171.5ms/batch - loss: 108.54776 - diff: 33.31mlTrain batch 2/31 - 171.4ms/batch - loss: 101.21349 - diff: 32.56mlTrain batch 3/31 - 171.4ms/batch - loss: 83.81395 - diff: 30.38mlTrain batch 4/31 - 171.7ms/batch - loss: 82.28548 - diff: 30.38mlTrain batch 5/31 - 171.2ms/batch - loss: 88.44473 - diff: 31.47mlTrain batch 6/31 - 172.0ms/batch - loss: 99.36021 - diff: 33.41mlTrain batch 7/31 - 171.4ms/batch - loss: 102.08881 - diff: 33.27mlTrain batch 8/31 - 170.5ms/batch - loss: 165.08264 - diff: 35.74mlTrain batch 9/31 - 171.3ms/batch - loss: 168.28703 - diff: 36.39mlTrain batch 10/31 - 170.6ms/batch - loss: 178.97987 - diff: 38.41mlTrain batch 11/31 - 171.5ms/batch - loss: 175.01918 - diff: 38.15mlTrain batch 12/31 - 171.8ms/batch - loss: 165.03540 - diff: 37.09mlTrain batch 13/31 - 171.4ms/batch - loss: 166.40993 - diff: 37.83mlTrain batch 14/31 - 171.9ms/batch - loss: 165.61246 - diff: 37.73mlTrain batch 15/31 - 171.5ms/batch - loss: 162.27438 - diff: 37.61mlTrain batch 16/31 - 171.8ms/batch - loss: 169.28106 - diff: 37.99mlTrain batch 17/31 - 171.3ms/batch - loss: 169.89828 - diff: 38.39mlTrain batch 18/31 - 171.8ms/batch - loss: 170.54112 - diff: 38.48mlTrain batch 19/31 - 171.4ms/batch - loss: 173.18069 - diff: 38.70mlTrain batch 20/31 - 172.0ms/batch - loss: 176.24117 - diff: 39.02mlTrain batch 21/31 - 171.3ms/batch - loss: 176.73471 - diff: 39.34mlTrain batch 22/31 - 171.2ms/batch - loss: 178.98074 - diff: 39.36mlTrain batch 23/31 - 171.2ms/batch - loss: 174.99056 - diff: 38.94mlTrain batch 24/31 - 171.6ms/batch - loss: 171.16094 - diff: 38.62mlTrain batch 25/31 - 171.6ms/batch - loss: 172.18026 - diff: 38.76mlTrain batch 26/31 - 171.8ms/batch - loss: 172.98586 - diff: 38.82mlTrain batch 27/31 - 171.3ms/batch - loss: 170.18556 - diff: 38.46mlTrain batch 28/31 - 172.2ms/batch - loss: 167.25165 - diff: 38.17mlTrain batch 29/31 - 171.6ms/batch - loss: 166.62531 - diff: 38.24mlTrain batch 30/31 - 171.4ms/batch - loss: 163.32270 - diff: 37.85mlTrain batch 31/31 - 86.2ms/batch - loss: 162.61890 - diff: 37.65mlTrain batch 31/31 - 10.1s 86.2ms/batch - loss: 162.61890 - diff: 37.65ml
Test 1.1s: val_loss: 151.91532 - diff: 37.72ml

Epoch 27: current best loss = 139.41615, at epoch 25
Train batch 1/31 - 171.5ms/batch - loss: 166.52640 - diff: 44.23mlTrain batch 2/31 - 170.5ms/batch - loss: 188.18187 - diff: 46.98mlTrain batch 3/31 - 171.5ms/batch - loss: 156.20331 - diff: 42.23mlTrain batch 4/31 - 171.4ms/batch - loss: 146.87304 - diff: 40.20mlTrain batch 5/31 - 171.5ms/batch - loss: 151.96604 - diff: 41.27mlTrain batch 6/31 - 171.7ms/batch - loss: 149.26466 - diff: 40.33mlTrain batch 7/31 - 171.5ms/batch - loss: 186.87793 - diff: 42.69mlTrain batch 8/31 - 171.4ms/batch - loss: 188.51324 - diff: 43.45mlTrain batch 9/31 - 171.9ms/batch - loss: 176.72681 - diff: 41.88mlTrain batch 10/31 - 171.9ms/batch - loss: 174.50976 - diff: 41.86mlTrain batch 11/31 - 171.3ms/batch - loss: 170.29892 - diff: 41.32mlTrain batch 12/31 - 172.0ms/batch - loss: 160.41088 - diff: 39.62mlTrain batch 13/31 - 171.4ms/batch - loss: 156.63106 - diff: 39.14mlTrain batch 14/31 - 171.4ms/batch - loss: 162.32484 - diff: 39.72mlTrain batch 15/31 - 171.4ms/batch - loss: 160.52662 - diff: 39.59mlTrain batch 16/31 - 171.5ms/batch - loss: 159.98071 - diff: 39.18mlTrain batch 17/31 - 171.7ms/batch - loss: 155.32677 - diff: 38.35mlTrain batch 18/31 - 171.8ms/batch - loss: 156.74969 - diff: 38.76mlTrain batch 19/31 - 171.4ms/batch - loss: 151.35654 - diff: 37.97mlTrain batch 20/31 - 171.7ms/batch - loss: 150.60076 - diff: 37.54mlTrain batch 21/31 - 171.4ms/batch - loss: 148.25629 - diff: 37.19mlTrain batch 22/31 - 171.7ms/batch - loss: 144.51698 - diff: 36.73mlTrain batch 23/31 - 171.5ms/batch - loss: 144.73020 - diff: 36.83mlTrain batch 24/31 - 171.7ms/batch - loss: 175.69272 - diff: 38.38mlTrain batch 25/31 - 171.4ms/batch - loss: 170.55028 - diff: 37.77mlTrain batch 26/31 - 171.7ms/batch - loss: 166.67701 - diff: 37.34mlTrain batch 27/31 - 171.3ms/batch - loss: 162.76301 - diff: 36.88mlTrain batch 28/31 - 171.7ms/batch - loss: 167.27833 - diff: 37.25mlTrain batch 29/31 - 171.4ms/batch - loss: 164.06061 - diff: 36.77mlTrain batch 30/31 - 171.6ms/batch - loss: 163.06532 - diff: 36.73mlTrain batch 31/31 - 86.3ms/batch - loss: 167.50724 - diff: 36.75mlTrain batch 31/31 - 10.1s 86.3ms/batch - loss: 167.50724 - diff: 36.75ml
Test 1.1s: val_loss: 161.55578 - diff: 40.23ml

Epoch 28: current best loss = 139.41615, at epoch 25
Train batch 1/31 - 171.3ms/batch - loss: 51.63862 - diff: 23.74mlTrain batch 2/31 - 171.9ms/batch - loss: 362.77546 - diff: 41.80mlTrain batch 3/31 - 171.4ms/batch - loss: 283.38627 - diff: 40.13mlTrain batch 4/31 - 175.3ms/batch - loss: 231.86480 - diff: 37.61mlTrain batch 5/31 - 171.6ms/batch - loss: 218.87103 - diff: 38.76mlTrain batch 6/31 - 172.3ms/batch - loss: 197.32933 - diff: 37.25mlTrain batch 7/31 - 171.7ms/batch - loss: 202.97942 - diff: 39.24mlTrain batch 8/31 - 171.8ms/batch - loss: 204.36177 - diff: 40.59mlTrain batch 9/31 - 171.3ms/batch - loss: 193.39107 - diff: 40.00mlTrain batch 10/31 - 171.1ms/batch - loss: 181.16179 - diff: 38.40mlTrain batch 11/31 - 171.2ms/batch - loss: 177.63233 - diff: 38.36mlTrain batch 12/31 - 171.7ms/batch - loss: 173.90383 - diff: 37.81mlTrain batch 13/31 - 171.4ms/batch - loss: 172.20881 - diff: 37.86mlTrain batch 14/31 - 172.0ms/batch - loss: 166.87372 - diff: 37.33mlTrain batch 15/31 - 171.5ms/batch - loss: 169.96674 - diff: 38.11mlTrain batch 16/31 - 171.7ms/batch - loss: 165.43678 - diff: 37.75mlTrain batch 17/31 - 171.4ms/batch - loss: 170.79785 - diff: 38.39mlTrain batch 18/31 - 171.8ms/batch - loss: 167.93972 - diff: 38.16mlTrain batch 19/31 - 171.3ms/batch - loss: 167.20081 - diff: 38.22mlTrain batch 20/31 - 171.8ms/batch - loss: 162.33067 - diff: 37.64mlTrain batch 21/31 - 171.4ms/batch - loss: 159.45638 - diff: 37.38mlTrain batch 22/31 - 171.7ms/batch - loss: 155.87309 - diff: 37.04mlTrain batch 23/31 - 171.2ms/batch - loss: 157.25306 - diff: 37.31mlTrain batch 24/31 - 171.4ms/batch - loss: 168.88675 - diff: 38.16mlTrain batch 25/31 - 171.4ms/batch - loss: 167.01606 - diff: 38.06mlTrain batch 26/31 - 171.7ms/batch - loss: 166.27566 - diff: 37.88mlTrain batch 27/31 - 171.3ms/batch - loss: 165.32970 - diff: 37.78mlTrain batch 28/31 - 171.7ms/batch - loss: 162.07433 - diff: 37.45mlTrain batch 29/31 - 171.3ms/batch - loss: 162.02148 - diff: 37.49mlTrain batch 30/31 - 171.7ms/batch - loss: 161.80487 - diff: 37.64mlTrain batch 31/31 - 86.3ms/batch - loss: 162.11356 - diff: 37.55mlTrain batch 31/31 - 10.1s 86.3ms/batch - loss: 162.11356 - diff: 37.55ml
Test 1.1s: val_loss: 148.49048 - diff: 36.94ml

Epoch 29: current best loss = 139.41615, at epoch 25
Train batch 1/31 - 171.6ms/batch - loss: 215.87976 - diff: 46.03mlTrain batch 2/31 - 170.5ms/batch - loss: 166.77951 - diff: 38.12mlTrain batch 3/31 - 171.4ms/batch - loss: 158.42904 - diff: 39.48mlTrain batch 4/31 - 171.5ms/batch - loss: 178.53973 - diff: 39.50mlTrain batch 5/31 - 171.6ms/batch - loss: 154.09452 - diff: 36.52mlTrain batch 6/31 - 171.7ms/batch - loss: 152.11673 - diff: 36.94mlTrain batch 7/31 - 171.3ms/batch - loss: 143.89272 - diff: 36.16mlTrain batch 8/31 - 171.9ms/batch - loss: 136.87767 - diff: 35.66mlTrain batch 9/31 - 171.6ms/batch - loss: 142.97840 - diff: 36.23mlTrain batch 10/31 - 171.7ms/batch - loss: 140.92154 - diff: 36.33mlTrain batch 11/31 - 171.1ms/batch - loss: 133.33341 - diff: 35.22mlTrain batch 12/31 - 171.8ms/batch - loss: 131.35029 - diff: 35.06mlTrain batch 13/31 - 171.4ms/batch - loss: 131.07079 - diff: 34.76mlTrain batch 14/31 - 171.7ms/batch - loss: 133.49106 - diff: 35.18mlTrain batch 15/31 - 171.4ms/batch - loss: 133.08867 - diff: 35.04mlTrain batch 16/31 - 171.8ms/batch - loss: 130.33900 - diff: 34.65mlTrain batch 17/31 - 171.7ms/batch - loss: 128.77824 - diff: 34.69mlTrain batch 18/31 - 171.7ms/batch - loss: 126.17264 - diff: 34.33mlTrain batch 19/31 - 171.6ms/batch - loss: 133.46289 - diff: 34.95mlTrain batch 20/31 - 171.8ms/batch - loss: 131.75556 - diff: 34.63mlTrain batch 21/31 - 171.5ms/batch - loss: 129.02620 - diff: 34.34mlTrain batch 22/31 - 171.6ms/batch - loss: 129.04249 - diff: 34.41mlTrain batch 23/31 - 171.4ms/batch - loss: 130.84699 - diff: 34.72mlTrain batch 24/31 - 171.7ms/batch - loss: 132.75228 - diff: 35.05mlTrain batch 25/31 - 171.2ms/batch - loss: 132.69391 - diff: 34.90mlTrain batch 26/31 - 171.8ms/batch - loss: 131.30073 - diff: 34.72mlTrain batch 27/31 - 171.4ms/batch - loss: 137.94863 - diff: 35.45mlTrain batch 28/31 - 171.8ms/batch - loss: 156.73705 - diff: 36.11mlTrain batch 29/31 - 171.9ms/batch - loss: 156.61269 - diff: 36.23mlTrain batch 30/31 - 171.7ms/batch - loss: 159.65621 - diff: 36.83mlTrain batch 31/31 - 85.8ms/batch - loss: 163.09730 - diff: 36.94mlTrain batch 31/31 - 10.2s 85.8ms/batch - loss: 163.09730 - diff: 36.94ml
Test 1.1s: val_loss: 144.02885 - diff: 37.42ml

Epoch 30: current best loss = 139.41615, at epoch 25
Train batch 1/31 - 171.4ms/batch - loss: 166.17053 - diff: 37.64mlTrain batch 2/31 - 170.6ms/batch - loss: 131.91332 - diff: 34.84mlTrain batch 3/31 - 171.7ms/batch - loss: 176.64267 - diff: 42.95mlTrain batch 4/31 - 171.7ms/batch - loss: 174.65686 - diff: 42.87mlTrain batch 5/31 - 171.2ms/batch - loss: 170.14445 - diff: 42.03mlTrain batch 6/31 - 171.7ms/batch - loss: 154.71159 - diff: 40.10mlTrain batch 7/31 - 171.6ms/batch - loss: 165.04121 - diff: 42.00mlTrain batch 8/31 - 172.2ms/batch - loss: 153.84694 - diff: 40.58mlTrain batch 9/31 - 171.7ms/batch - loss: 139.23055 - diff: 37.96mlTrain batch 10/31 - 172.0ms/batch - loss: 133.67166 - diff: 37.29mlTrain batch 11/31 - 171.5ms/batch - loss: 129.46290 - diff: 36.72mlTrain batch 12/31 - 172.0ms/batch - loss: 138.81065 - diff: 37.39mlTrain batch 13/31 - 171.4ms/batch - loss: 149.18989 - diff: 38.60mlTrain batch 14/31 - 170.7ms/batch - loss: 153.23076 - diff: 38.79mlTrain batch 15/31 - 171.5ms/batch - loss: 160.08197 - diff: 39.65mlTrain batch 16/31 - 171.7ms/batch - loss: 157.45100 - diff: 39.27mlTrain batch 17/31 - 171.6ms/batch - loss: 153.52002 - diff: 38.67mlTrain batch 18/31 - 171.9ms/batch - loss: 153.66425 - diff: 38.83mlTrain batch 19/31 - 171.5ms/batch - loss: 157.85375 - diff: 39.16mlTrain batch 20/31 - 172.3ms/batch - loss: 157.70094 - diff: 39.07mlTrain batch 21/31 - 171.7ms/batch - loss: 154.25600 - diff: 38.57mlTrain batch 22/31 - 170.7ms/batch - loss: 152.96033 - diff: 38.47mlTrain batch 23/31 - 171.5ms/batch - loss: 152.22399 - diff: 38.35mlTrain batch 24/31 - 171.6ms/batch - loss: 149.21610 - diff: 38.00mlTrain batch 25/31 - 171.6ms/batch - loss: 148.89156 - diff: 38.02mlTrain batch 26/31 - 172.3ms/batch - loss: 146.46517 - diff: 37.59mlTrain batch 27/31 - 171.3ms/batch - loss: 161.70365 - diff: 37.92mlTrain batch 28/31 - 171.8ms/batch - loss: 158.31183 - diff: 37.58mlTrain batch 29/31 - 171.4ms/batch - loss: 154.57562 - diff: 37.13mlTrain batch 30/31 - 172.0ms/batch - loss: 155.43062 - diff: 37.25mlTrain batch 31/31 - 87.3ms/batch - loss: 158.70107 - diff: 37.34mlTrain batch 31/31 - 10.5s 87.3ms/batch - loss: 158.70107 - diff: 37.34ml
Test 1.2s: val_loss: 164.26498 - diff: 39.14ml

Epoch 31: current best loss = 139.41615, at epoch 25
Train batch 1/31 - 171.4ms/batch - loss: 73.67003 - diff: 24.70mlTrain batch 2/31 - 171.5ms/batch - loss: 105.31898 - diff: 31.39mlTrain batch 3/31 - 171.4ms/batch - loss: 117.73978 - diff: 34.52mlTrain batch 4/31 - 171.7ms/batch - loss: 101.74057 - diff: 31.94mlTrain batch 5/31 - 171.6ms/batch - loss: 109.63242 - diff: 33.96mlTrain batch 6/31 - 171.5ms/batch - loss: 108.88524 - diff: 33.10mlTrain batch 7/31 - 171.6ms/batch - loss: 109.85818 - diff: 33.20mlTrain batch 8/31 - 171.3ms/batch - loss: 124.79605 - diff: 34.35mlTrain batch 9/31 - 171.2ms/batch - loss: 128.61416 - diff: 35.23mlTrain batch 10/31 - 171.6ms/batch - loss: 124.64110 - diff: 34.79mlTrain batch 11/31 - 171.3ms/batch - loss: 131.20318 - diff: 35.43mlTrain batch 12/31 - 171.7ms/batch - loss: 129.61751 - diff: 35.42mlTrain batch 13/31 - 171.3ms/batch - loss: 133.42245 - diff: 35.24mlTrain batch 14/31 - 171.5ms/batch - loss: 136.15050 - diff: 36.06mlTrain batch 15/31 - 171.7ms/batch - loss: 131.19802 - diff: 35.30mlTrain batch 16/31 - 171.6ms/batch - loss: 163.39797 - diff: 36.35mlTrain batch 17/31 - 171.6ms/batch - loss: 162.78922 - diff: 36.62mlTrain batch 18/31 - 171.3ms/batch - loss: 156.71857 - diff: 35.92mlTrain batch 19/31 - 171.8ms/batch - loss: 156.18432 - diff: 35.90mlTrain batch 20/31 - 171.4ms/batch - loss: 159.03859 - diff: 36.06mlTrain batch 21/31 - 171.8ms/batch - loss: 155.67088 - diff: 35.87mlTrain batch 22/31 - 171.3ms/batch - loss: 153.31415 - diff: 35.70mlTrain batch 23/31 - 171.7ms/batch - loss: 153.68204 - diff: 36.05mlTrain batch 24/31 - 171.6ms/batch - loss: 152.89242 - diff: 36.18mlTrain batch 25/31 - 171.8ms/batch - loss: 150.53672 - diff: 36.01mlTrain batch 26/31 - 171.5ms/batch - loss: 157.07898 - diff: 36.77mlTrain batch 27/31 - 171.4ms/batch - loss: 159.22111 - diff: 36.97mlTrain batch 28/31 - 171.4ms/batch - loss: 158.04466 - diff: 36.95mlTrain batch 29/31 - 171.4ms/batch - loss: 154.31229 - diff: 36.38mlTrain batch 30/31 - 171.5ms/batch - loss: 152.25625 - diff: 36.28mlTrain batch 31/31 - 86.5ms/batch - loss: 153.62977 - diff: 36.22mlTrain batch 31/31 - 11.4s 86.5ms/batch - loss: 153.62977 - diff: 36.22ml
Test 1.2s: val_loss: 183.14832 - diff: 42.38ml

Epoch 32: current best loss = 139.41615, at epoch 25
Train batch 1/31 - 171.6ms/batch - loss: 166.26425 - diff: 39.71mlTrain batch 2/31 - 171.5ms/batch - loss: 375.71828 - diff: 47.46mlTrain batch 3/31 - 171.5ms/batch - loss: 309.52833 - diff: 44.44mlTrain batch 4/31 - 171.6ms/batch - loss: 259.09392 - diff: 41.93mlTrain batch 5/31 - 171.7ms/batch - loss: 228.49303 - diff: 40.16mlTrain batch 6/31 - 171.8ms/batch - loss: 200.87703 - diff: 37.34mlTrain batch 7/31 - 171.3ms/batch - loss: 189.49724 - diff: 36.64mlTrain batch 8/31 - 171.7ms/batch - loss: 176.65687 - diff: 35.95mlTrain batch 9/31 - 171.5ms/batch - loss: 176.29079 - diff: 37.00mlTrain batch 10/31 - 171.5ms/batch - loss: 166.42497 - diff: 36.34mlTrain batch 11/31 - 171.4ms/batch - loss: 170.29290 - diff: 37.39mlTrain batch 12/31 - 171.7ms/batch - loss: 165.22138 - diff: 36.76mlTrain batch 13/31 - 171.4ms/batch - loss: 161.78286 - diff: 36.59mlTrain batch 14/31 - 171.7ms/batch - loss: 169.19234 - diff: 37.25mlTrain batch 15/31 - 171.6ms/batch - loss: 165.40166 - diff: 37.30mlTrain batch 16/31 - 171.7ms/batch - loss: 160.53781 - diff: 36.74mlTrain batch 17/31 - 171.4ms/batch - loss: 158.47691 - diff: 36.81mlTrain batch 18/31 - 171.2ms/batch - loss: 153.03932 - diff: 36.05mlTrain batch 19/31 - 171.7ms/batch - loss: 159.32487 - diff: 36.45mlTrain batch 20/31 - 171.7ms/batch - loss: 157.09020 - diff: 36.49mlTrain batch 21/31 - 171.5ms/batch - loss: 159.29756 - diff: 36.91mlTrain batch 22/31 - 171.6ms/batch - loss: 156.68948 - diff: 36.62mlTrain batch 23/31 - 171.3ms/batch - loss: 155.44119 - diff: 36.44mlTrain batch 24/31 - 171.7ms/batch - loss: 153.73211 - diff: 36.39mlTrain batch 25/31 - 171.6ms/batch - loss: 153.59773 - diff: 36.50mlTrain batch 26/31 - 171.8ms/batch - loss: 158.10883 - diff: 37.14mlTrain batch 27/31 - 171.2ms/batch - loss: 154.05732 - diff: 36.64mlTrain batch 28/31 - 171.7ms/batch - loss: 152.91152 - diff: 36.53mlTrain batch 29/31 - 171.2ms/batch - loss: 150.97488 - diff: 36.43mlTrain batch 30/31 - 171.7ms/batch - loss: 148.54894 - diff: 36.22mlTrain batch 31/31 - 86.5ms/batch - loss: 149.16258 - diff: 36.10mlTrain batch 31/31 - 10.5s 86.5ms/batch - loss: 149.16258 - diff: 36.10ml
Test 1.2s: val_loss: 149.11164 - diff: 37.71ml

Epoch 33: current best loss = 139.41615, at epoch 25
Train batch 1/31 - 171.6ms/batch - loss: 79.04477 - diff: 27.64mlTrain batch 2/31 - 171.4ms/batch - loss: 110.79604 - diff: 32.93mlTrain batch 3/31 - 171.5ms/batch - loss: 126.68988 - diff: 35.48mlTrain batch 4/31 - 171.8ms/batch - loss: 115.55972 - diff: 34.26mlTrain batch 5/31 - 171.5ms/batch - loss: 108.92828 - diff: 33.43mlTrain batch 6/31 - 171.9ms/batch - loss: 103.92243 - diff: 32.67mlTrain batch 7/31 - 171.8ms/batch - loss: 118.77601 - diff: 34.03mlTrain batch 8/31 - 172.0ms/batch - loss: 117.94074 - diff: 34.33mlTrain batch 9/31 - 171.7ms/batch - loss: 129.90897 - diff: 35.35mlTrain batch 10/31 - 172.0ms/batch - loss: 123.33728 - diff: 34.44mlTrain batch 11/31 - 171.9ms/batch - loss: 126.54097 - diff: 34.87mlTrain batch 12/31 - 171.9ms/batch - loss: 138.69754 - diff: 35.89mlTrain batch 13/31 - 171.8ms/batch - loss: 135.95967 - diff: 35.56mlTrain batch 14/31 - 172.1ms/batch - loss: 139.05346 - diff: 36.00mlTrain batch 15/31 - 171.9ms/batch - loss: 138.45139 - diff: 36.12mlTrain batch 16/31 - 171.9ms/batch - loss: 139.95973 - diff: 36.38mlTrain batch 17/31 - 171.8ms/batch - loss: 147.93185 - diff: 36.84mlTrain batch 18/31 - 172.1ms/batch - loss: 148.63335 - diff: 36.95mlTrain batch 19/31 - 171.6ms/batch - loss: 149.49897 - diff: 37.27mlTrain batch 20/31 - 171.9ms/batch - loss: 147.62281 - diff: 36.94mlTrain batch 21/31 - 171.8ms/batch - loss: 146.38344 - diff: 36.75mlTrain batch 22/31 - 172.0ms/batch - loss: 142.96854 - diff: 36.33mlTrain batch 23/31 - 171.8ms/batch - loss: 142.11993 - diff: 36.24mlTrain batch 24/31 - 171.9ms/batch - loss: 140.65850 - diff: 36.08mlTrain batch 25/31 - 171.8ms/batch - loss: 139.41841 - diff: 36.02mlTrain batch 26/31 - 171.8ms/batch - loss: 158.01552 - diff: 36.56mlTrain batch 27/31 - 171.8ms/batch - loss: 154.22660 - diff: 36.16mlTrain batch 28/31 - 171.8ms/batch - loss: 153.29000 - diff: 36.13mlTrain batch 29/31 - 172.0ms/batch - loss: 153.33639 - diff: 36.17mlTrain batch 30/31 - 171.2ms/batch - loss: 152.16704 - diff: 36.04mlTrain batch 31/31 - 86.4ms/batch - loss: 155.41643 - diff: 36.13mlTrain batch 31/31 - 11.4s 86.4ms/batch - loss: 155.41643 - diff: 36.13ml
Test 1.2s: val_loss: 136.34681 - diff: 36.31ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_WideResNet50_0_Adam-0.001_MSE_DA3_best

Epoch 34: current best loss = 136.34681, at epoch 33
Train batch 1/31 - 171.4ms/batch - loss: 160.87515 - diff: 42.48mlTrain batch 2/31 - 171.8ms/batch - loss: 116.56497 - diff: 33.88mlTrain batch 3/31 - 171.3ms/batch - loss: 131.95451 - diff: 37.17mlTrain batch 4/31 - 170.8ms/batch - loss: 118.99464 - diff: 35.57mlTrain batch 5/31 - 171.4ms/batch - loss: 128.88352 - diff: 37.16mlTrain batch 6/31 - 172.0ms/batch - loss: 146.73356 - diff: 39.28mlTrain batch 7/31 - 171.5ms/batch - loss: 146.65748 - diff: 39.30mlTrain batch 8/31 - 172.5ms/batch - loss: 137.49780 - diff: 37.73mlTrain batch 9/31 - 171.4ms/batch - loss: 137.81184 - diff: 37.60mlTrain batch 10/31 - 170.8ms/batch - loss: 137.02657 - diff: 38.07mlTrain batch 11/31 - 170.8ms/batch - loss: 137.05860 - diff: 38.05mlTrain batch 12/31 - 172.0ms/batch - loss: 143.64812 - diff: 38.50mlTrain batch 13/31 - 171.3ms/batch - loss: 145.10787 - diff: 38.16mlTrain batch 14/31 - 171.6ms/batch - loss: 147.40146 - diff: 37.63mlTrain batch 15/31 - 171.7ms/batch - loss: 150.64616 - diff: 37.09mlTrain batch 16/31 - 171.6ms/batch - loss: 147.67386 - diff: 37.00mlTrain batch 17/31 - 171.2ms/batch - loss: 145.76448 - diff: 36.82mlTrain batch 18/31 - 171.8ms/batch - loss: 143.65114 - diff: 36.78mlTrain batch 19/31 - 171.8ms/batch - loss: 142.51670 - diff: 36.78mlTrain batch 20/31 - 172.2ms/batch - loss: 138.71892 - diff: 36.18mlTrain batch 21/31 - 171.3ms/batch - loss: 137.60695 - diff: 35.89mlTrain batch 22/31 - 171.7ms/batch - loss: 134.66315 - diff: 35.47mlTrain batch 23/31 - 171.6ms/batch - loss: 137.15454 - diff: 36.01mlTrain batch 24/31 - 171.8ms/batch - loss: 137.49553 - diff: 36.22mlTrain batch 25/31 - 171.3ms/batch - loss: 136.80203 - diff: 36.14mlTrain batch 26/31 - 171.9ms/batch - loss: 138.88977 - diff: 36.31mlTrain batch 27/31 - 171.6ms/batch - loss: 160.05331 - diff: 37.19mlTrain batch 28/31 - 172.1ms/batch - loss: 157.96432 - diff: 37.08mlTrain batch 29/31 - 171.3ms/batch - loss: 154.83443 - diff: 36.75mlTrain batch 30/31 - 171.9ms/batch - loss: 154.24824 - diff: 36.46mlTrain batch 31/31 - 86.5ms/batch - loss: 154.83345 - diff: 36.35mlTrain batch 31/31 - 10.7s 86.5ms/batch - loss: 154.83345 - diff: 36.35ml
Test 1.2s: val_loss: 120.87568 - diff: 33.18ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_WideResNet50_0_Adam-0.001_MSE_DA3_best

Epoch 35: current best loss = 120.87568, at epoch 34
Train batch 1/31 - 183.4ms/batch - loss: 720.02789 - diff: 60.55mlTrain batch 2/31 - 174.0ms/batch - loss: 421.05637 - diff: 45.25mlTrain batch 3/31 - 171.3ms/batch - loss: 314.72247 - diff: 41.38mlTrain batch 4/31 - 171.8ms/batch - loss: 280.07103 - diff: 41.62mlTrain batch 5/31 - 171.5ms/batch - loss: 241.66123 - diff: 39.44mlTrain batch 6/31 - 171.6ms/batch - loss: 214.18248 - diff: 37.76mlTrain batch 7/31 - 171.6ms/batch - loss: 202.16022 - diff: 37.34mlTrain batch 8/31 - 171.6ms/batch - loss: 192.78523 - diff: 37.05mlTrain batch 9/31 - 171.3ms/batch - loss: 192.98501 - diff: 38.16mlTrain batch 10/31 - 172.0ms/batch - loss: 185.09444 - diff: 37.30mlTrain batch 11/31 - 171.4ms/batch - loss: 187.63057 - diff: 37.11mlTrain batch 12/31 - 172.2ms/batch - loss: 182.91895 - diff: 36.92mlTrain batch 13/31 - 171.4ms/batch - loss: 175.37724 - diff: 36.38mlTrain batch 14/31 - 171.8ms/batch - loss: 175.61318 - diff: 36.58mlTrain batch 15/31 - 171.5ms/batch - loss: 170.19066 - diff: 36.02mlTrain batch 16/31 - 171.8ms/batch - loss: 166.00753 - diff: 35.66mlTrain batch 17/31 - 171.7ms/batch - loss: 161.99707 - diff: 35.60mlTrain batch 18/31 - 172.1ms/batch - loss: 160.84243 - diff: 35.80mlTrain batch 19/31 - 171.2ms/batch - loss: 156.40583 - diff: 35.40mlTrain batch 20/31 - 171.7ms/batch - loss: 156.48820 - diff: 35.48mlTrain batch 21/31 - 171.6ms/batch - loss: 153.69920 - diff: 35.45mlTrain batch 22/31 - 171.4ms/batch - loss: 152.84881 - diff: 35.47mlTrain batch 23/31 - 171.7ms/batch - loss: 150.23273 - diff: 35.33mlTrain batch 24/31 - 171.5ms/batch - loss: 147.61608 - diff: 35.11mlTrain batch 25/31 - 171.6ms/batch - loss: 146.09779 - diff: 34.95mlTrain batch 26/31 - 171.8ms/batch - loss: 144.16263 - diff: 34.83mlTrain batch 27/31 - 171.6ms/batch - loss: 144.37464 - diff: 34.89mlTrain batch 28/31 - 171.4ms/batch - loss: 144.98126 - diff: 34.94mlTrain batch 29/31 - 171.9ms/batch - loss: 145.80113 - diff: 35.15mlTrain batch 30/31 - 171.5ms/batch - loss: 150.41845 - diff: 35.56mlTrain batch 31/31 - 86.4ms/batch - loss: 152.52423 - diff: 35.57mlTrain batch 31/31 - 11.7s 86.4ms/batch - loss: 152.52423 - diff: 35.57ml
Test 1.2s: val_loss: 123.09413 - diff: 33.61ml

Epoch 36: current best loss = 120.87568, at epoch 34
Train batch 1/31 - 171.7ms/batch - loss: 154.23140 - diff: 34.33mlTrain batch 2/31 - 171.7ms/batch - loss: 109.30706 - diff: 29.85mlTrain batch 3/31 - 171.4ms/batch - loss: 112.32444 - diff: 30.37mlTrain batch 4/31 - 171.8ms/batch - loss: 105.17776 - diff: 30.91mlTrain batch 5/31 - 171.4ms/batch - loss: 120.75033 - diff: 32.89mlTrain batch 6/31 - 171.7ms/batch - loss: 119.52949 - diff: 33.00mlTrain batch 7/31 - 171.6ms/batch - loss: 125.79569 - diff: 34.33mlTrain batch 8/31 - 171.6ms/batch - loss: 181.55047 - diff: 37.00mlTrain batch 9/31 - 171.5ms/batch - loss: 180.75078 - diff: 37.36mlTrain batch 10/31 - 171.8ms/batch - loss: 178.62653 - diff: 37.47mlTrain batch 11/31 - 171.4ms/batch - loss: 174.39781 - diff: 37.59mlTrain batch 12/31 - 171.9ms/batch - loss: 164.93999 - diff: 36.65mlTrain batch 13/31 - 171.8ms/batch - loss: 171.81891 - diff: 37.89mlTrain batch 14/31 - 172.2ms/batch - loss: 167.03737 - diff: 37.64mlTrain batch 15/31 - 171.7ms/batch - loss: 160.31027 - diff: 36.95mlTrain batch 16/31 - 172.1ms/batch - loss: 165.19225 - diff: 37.47mlTrain batch 17/31 - 171.6ms/batch - loss: 158.09351 - diff: 36.53mlTrain batch 18/31 - 171.4ms/batch - loss: 152.54238 - diff: 35.80mlTrain batch 19/31 - 171.3ms/batch - loss: 149.39137 - diff: 35.60mlTrain batch 20/31 - 170.9ms/batch - loss: 147.49939 - diff: 35.64mlTrain batch 21/31 - 171.7ms/batch - loss: 146.40813 - diff: 35.67mlTrain batch 22/31 - 171.7ms/batch - loss: 145.27376 - diff: 35.43mlTrain batch 23/31 - 171.6ms/batch - loss: 144.37890 - diff: 35.56mlTrain batch 24/31 - 171.9ms/batch - loss: 141.22681 - diff: 35.14mlTrain batch 25/31 - 171.5ms/batch - loss: 140.68323 - diff: 35.16mlTrain batch 26/31 - 171.4ms/batch - loss: 141.51854 - diff: 35.49mlTrain batch 27/31 - 171.1ms/batch - loss: 139.11540 - diff: 35.31mlTrain batch 28/31 - 171.3ms/batch - loss: 145.17165 - diff: 35.76mlTrain batch 29/31 - 171.3ms/batch - loss: 142.49977 - diff: 35.47mlTrain batch 30/31 - 170.8ms/batch - loss: 144.87821 - diff: 35.35mlTrain batch 31/31 - 86.5ms/batch - loss: 145.50804 - diff: 35.20mlTrain batch 31/31 - 10.9s 86.5ms/batch - loss: 145.50804 - diff: 35.20ml
Test 1.2s: val_loss: 123.68632 - diff: 33.56ml

Epoch 37: current best loss = 120.87568, at epoch 34
Train batch 1/31 - 171.4ms/batch - loss: 647.27527 - diff: 52.11mlTrain batch 2/31 - 170.7ms/batch - loss: 364.59776 - diff: 39.59mlTrain batch 3/31 - 171.3ms/batch - loss: 327.94885 - diff: 40.10mlTrain batch 4/31 - 171.7ms/batch - loss: 274.45533 - diff: 38.02mlTrain batch 5/31 - 171.5ms/batch - loss: 234.28258 - diff: 35.46mlTrain batch 6/31 - 171.6ms/batch - loss: 232.35549 - diff: 37.50mlTrain batch 7/31 - 171.4ms/batch - loss: 217.45246 - diff: 37.79mlTrain batch 8/31 - 171.8ms/batch - loss: 205.40476 - diff: 37.56mlTrain batch 9/31 - 171.6ms/batch - loss: 196.28542 - diff: 37.23mlTrain batch 10/31 - 171.8ms/batch - loss: 190.07679 - diff: 36.79mlTrain batch 11/31 - 171.6ms/batch - loss: 185.32356 - diff: 37.04mlTrain batch 12/31 - 171.7ms/batch - loss: 175.44417 - diff: 36.11mlTrain batch 13/31 - 171.4ms/batch - loss: 174.87617 - diff: 36.49mlTrain batch 14/31 - 171.7ms/batch - loss: 167.91152 - diff: 35.98mlTrain batch 15/31 - 171.7ms/batch - loss: 169.07862 - diff: 36.38mlTrain batch 16/31 - 171.8ms/batch - loss: 164.45444 - diff: 36.02mlTrain batch 17/31 - 171.6ms/batch - loss: 157.55850 - diff: 35.19mlTrain batch 18/31 - 171.8ms/batch - loss: 151.78340 - diff: 34.56mlTrain batch 19/31 - 171.4ms/batch - loss: 147.75735 - diff: 34.10mlTrain batch 20/31 - 171.6ms/batch - loss: 146.07949 - diff: 34.22mlTrain batch 21/31 - 171.3ms/batch - loss: 147.85945 - diff: 34.50mlTrain batch 22/31 - 171.8ms/batch - loss: 146.02798 - diff: 34.32mlTrain batch 23/31 - 171.6ms/batch - loss: 146.23271 - diff: 34.48mlTrain batch 24/31 - 171.8ms/batch - loss: 146.35521 - diff: 34.50mlTrain batch 25/31 - 171.6ms/batch - loss: 152.21052 - diff: 35.05mlTrain batch 26/31 - 172.0ms/batch - loss: 154.59781 - diff: 35.40mlTrain batch 27/31 - 171.5ms/batch - loss: 151.90699 - diff: 35.00mlTrain batch 28/31 - 171.8ms/batch - loss: 153.51217 - diff: 35.33mlTrain batch 29/31 - 171.6ms/batch - loss: 151.53733 - diff: 35.27mlTrain batch 30/31 - 172.0ms/batch - loss: 153.65851 - diff: 35.67mlTrain batch 31/31 - 86.4ms/batch - loss: 152.77854 - diff: 35.43mlTrain batch 31/31 - 10.5s 86.4ms/batch - loss: 152.77854 - diff: 35.43ml
Test 1.1s: val_loss: 126.74154 - diff: 34.77ml

Epoch 38: current best loss = 120.87568, at epoch 34
Train batch 1/31 - 171.7ms/batch - loss: 96.29189 - diff: 34.69mlTrain batch 2/31 - 171.2ms/batch - loss: 126.26049 - diff: 34.27mlTrain batch 3/31 - 171.6ms/batch - loss: 113.25134 - diff: 33.07mlTrain batch 4/31 - 171.8ms/batch - loss: 123.75118 - diff: 34.52mlTrain batch 5/31 - 171.5ms/batch - loss: 118.90050 - diff: 34.82mlTrain batch 6/31 - 171.9ms/batch - loss: 119.45058 - diff: 35.36mlTrain batch 7/31 - 171.8ms/batch - loss: 125.95393 - diff: 36.28mlTrain batch 8/31 - 171.7ms/batch - loss: 126.75891 - diff: 36.26mlTrain batch 9/31 - 171.6ms/batch - loss: 126.99693 - diff: 35.59mlTrain batch 10/31 - 171.4ms/batch - loss: 134.89939 - diff: 37.26mlTrain batch 11/31 - 171.9ms/batch - loss: 130.69405 - diff: 36.32mlTrain batch 12/31 - 171.6ms/batch - loss: 162.37504 - diff: 37.41mlTrain batch 13/31 - 171.9ms/batch - loss: 161.37120 - diff: 37.30mlTrain batch 14/31 - 171.6ms/batch - loss: 157.28723 - diff: 37.03mlTrain batch 15/31 - 171.7ms/batch - loss: 151.47097 - diff: 36.43mlTrain batch 16/31 - 171.3ms/batch - loss: 147.96087 - diff: 35.86mlTrain batch 17/31 - 171.7ms/batch - loss: 150.91473 - diff: 36.38mlTrain batch 18/31 - 171.7ms/batch - loss: 147.28683 - diff: 36.06mlTrain batch 19/31 - 171.4ms/batch - loss: 151.37961 - diff: 36.77mlTrain batch 20/31 - 171.6ms/batch - loss: 155.91802 - diff: 37.35mlTrain batch 21/31 - 171.4ms/batch - loss: 158.54060 - diff: 38.05mlTrain batch 22/31 - 171.8ms/batch - loss: 157.48750 - diff: 37.92mlTrain batch 23/31 - 171.5ms/batch - loss: 154.73384 - diff: 37.53mlTrain batch 24/31 - 171.8ms/batch - loss: 157.45035 - diff: 38.00mlTrain batch 25/31 - 171.4ms/batch - loss: 152.52119 - diff: 37.24mlTrain batch 26/31 - 171.4ms/batch - loss: 148.31761 - diff: 36.56mlTrain batch 27/31 - 171.8ms/batch - loss: 143.80908 - diff: 35.83mlTrain batch 28/31 - 171.6ms/batch - loss: 141.07975 - diff: 35.45mlTrain batch 29/31 - 171.5ms/batch - loss: 139.04931 - diff: 35.32mlTrain batch 30/31 - 171.4ms/batch - loss: 145.01557 - diff: 35.96mlTrain batch 31/31 - 86.3ms/batch - loss: 147.52360 - diff: 35.99mlTrain batch 31/31 - 11.3s 86.3ms/batch - loss: 147.52360 - diff: 35.99ml
Test 1.1s: val_loss: 128.19824 - diff: 33.03ml

Epoch 39: current best loss = 120.87568, at epoch 34
Train batch 1/31 - 171.6ms/batch - loss: 75.94977 - diff: 27.51mlTrain batch 2/31 - 171.6ms/batch - loss: 73.67106 - diff: 25.99mlTrain batch 3/31 - 171.7ms/batch - loss: 74.11176 - diff: 26.69mlTrain batch 4/31 - 171.6ms/batch - loss: 97.88678 - diff: 29.16mlTrain batch 5/31 - 171.5ms/batch - loss: 91.36063 - diff: 28.00mlTrain batch 6/31 - 171.9ms/batch - loss: 142.58507 - diff: 33.62mlTrain batch 7/31 - 171.5ms/batch - loss: 131.61068 - diff: 32.47mlTrain batch 8/31 - 171.6ms/batch - loss: 130.79027 - diff: 33.08mlTrain batch 9/31 - 171.6ms/batch - loss: 122.97472 - diff: 32.02mlTrain batch 10/31 - 171.7ms/batch - loss: 118.63561 - diff: 31.82mlTrain batch 11/31 - 171.6ms/batch - loss: 158.71479 - diff: 33.40mlTrain batch 12/31 - 171.6ms/batch - loss: 166.86987 - diff: 34.68mlTrain batch 13/31 - 171.5ms/batch - loss: 159.51226 - diff: 33.87mlTrain batch 14/31 - 171.8ms/batch - loss: 161.04370 - diff: 34.14mlTrain batch 15/31 - 171.9ms/batch - loss: 159.22594 - diff: 34.56mlTrain batch 16/31 - 171.8ms/batch - loss: 158.17059 - diff: 34.78mlTrain batch 17/31 - 171.5ms/batch - loss: 157.10626 - diff: 35.13mlTrain batch 18/31 - 171.6ms/batch - loss: 156.84956 - diff: 35.03mlTrain batch 19/31 - 171.6ms/batch - loss: 152.77075 - diff: 34.56mlTrain batch 20/31 - 171.5ms/batch - loss: 149.07051 - diff: 34.39mlTrain batch 21/31 - 171.7ms/batch - loss: 148.44726 - diff: 34.52mlTrain batch 22/31 - 171.7ms/batch - loss: 150.21630 - diff: 34.60mlTrain batch 23/31 - 171.8ms/batch - loss: 149.28290 - diff: 34.79mlTrain batch 24/31 - 171.8ms/batch - loss: 144.71038 - diff: 34.28mlTrain batch 25/31 - 171.5ms/batch - loss: 144.78212 - diff: 34.48mlTrain batch 26/31 - 171.5ms/batch - loss: 142.10489 - diff: 34.24mlTrain batch 27/31 - 171.7ms/batch - loss: 139.62821 - diff: 33.93mlTrain batch 28/31 - 171.5ms/batch - loss: 139.55604 - diff: 33.99mlTrain batch 29/31 - 171.7ms/batch - loss: 140.00132 - diff: 34.08mlTrain batch 30/31 - 171.3ms/batch - loss: 140.95489 - diff: 34.30mlTrain batch 31/31 - 86.4ms/batch - loss: 139.55972 - diff: 34.04mlTrain batch 31/31 - 10.8s 86.4ms/batch - loss: 139.55972 - diff: 34.04ml
Test 1.1s: val_loss: 130.80053 - diff: 37.65ml

Epoch 40: current best loss = 120.87568, at epoch 34
Train batch 1/31 - 171.4ms/batch - loss: 38.06095 - diff: 19.79mlTrain batch 2/31 - 171.9ms/batch - loss: 114.78672 - diff: 32.55mlTrain batch 3/31 - 171.4ms/batch - loss: 93.39668 - diff: 29.09mlTrain batch 4/31 - 171.8ms/batch - loss: 90.40917 - diff: 28.80mlTrain batch 5/31 - 171.5ms/batch - loss: 103.43731 - diff: 30.12mlTrain batch 6/31 - 171.3ms/batch - loss: 112.55086 - diff: 31.60mlTrain batch 7/31 - 171.9ms/batch - loss: 104.31971 - diff: 30.50mlTrain batch 8/31 - 171.5ms/batch - loss: 100.43389 - diff: 30.19mlTrain batch 9/31 - 172.0ms/batch - loss: 101.95433 - diff: 30.32mlTrain batch 10/31 - 171.6ms/batch - loss: 109.08004 - diff: 31.92mlTrain batch 11/31 - 171.8ms/batch - loss: 110.54368 - diff: 32.48mlTrain batch 12/31 - 171.8ms/batch - loss: 110.10412 - diff: 32.70mlTrain batch 13/31 - 171.2ms/batch - loss: 121.36531 - diff: 33.76mlTrain batch 14/31 - 171.6ms/batch - loss: 115.92282 - diff: 32.96mlTrain batch 15/31 - 172.0ms/batch - loss: 116.23406 - diff: 32.89mlTrain batch 16/31 - 171.8ms/batch - loss: 112.77187 - diff: 32.51mlTrain batch 17/31 - 171.3ms/batch - loss: 111.20449 - diff: 32.44mlTrain batch 18/31 - 171.3ms/batch - loss: 109.43318 - diff: 32.28mlTrain batch 19/31 - 170.8ms/batch - loss: 114.37875 - diff: 32.66mlTrain batch 20/31 - 171.8ms/batch - loss: 110.85682 - diff: 31.98mlTrain batch 21/31 - 172.1ms/batch - loss: 116.23021 - diff: 32.38mlTrain batch 22/31 - 172.2ms/batch - loss: 118.08389 - diff: 32.84mlTrain batch 23/31 - 172.3ms/batch - loss: 117.97204 - diff: 32.89mlTrain batch 24/31 - 171.8ms/batch - loss: 116.66122 - diff: 32.60mlTrain batch 25/31 - 172.5ms/batch - loss: 146.85737 - diff: 34.38mlTrain batch 26/31 - 171.8ms/batch - loss: 143.88218 - diff: 34.11mlTrain batch 27/31 - 171.7ms/batch - loss: 143.44411 - diff: 34.27mlTrain batch 28/31 - 171.9ms/batch - loss: 141.50982 - diff: 34.10mlTrain batch 29/31 - 171.9ms/batch - loss: 141.69475 - diff: 34.30mlTrain batch 30/31 - 172.2ms/batch - loss: 139.32314 - diff: 34.14mlTrain batch 31/31 - 86.6ms/batch - loss: 139.88960 - diff: 34.14mlTrain batch 31/31 - 10.9s 86.6ms/batch - loss: 139.88960 - diff: 34.14ml
Test 1.2s: val_loss: 127.26382 - diff: 33.37ml

Epoch 41: current best loss = 120.87568, at epoch 34
Train batch 1/31 - 171.8ms/batch - loss: 75.45612 - diff: 28.11mlTrain batch 2/31 - 171.9ms/batch - loss: 85.31740 - diff: 30.39mlTrain batch 3/31 - 171.3ms/batch - loss: 98.35402 - diff: 32.62mlTrain batch 4/31 - 172.2ms/batch - loss: 93.65155 - diff: 31.47mlTrain batch 5/31 - 171.4ms/batch - loss: 86.40085 - diff: 30.11mlTrain batch 6/31 - 171.8ms/batch - loss: 87.25973 - diff: 29.51mlTrain batch 7/31 - 171.6ms/batch - loss: 91.94183 - diff: 30.47mlTrain batch 8/31 - 172.3ms/batch - loss: 84.09452 - diff: 28.91mlTrain batch 9/31 - 171.8ms/batch - loss: 84.21678 - diff: 29.06mlTrain batch 10/31 - 172.1ms/batch - loss: 84.95466 - diff: 29.45mlTrain batch 11/31 - 171.5ms/batch - loss: 90.85982 - diff: 30.40mlTrain batch 12/31 - 171.8ms/batch - loss: 107.72982 - diff: 32.11mlTrain batch 13/31 - 170.8ms/batch - loss: 108.16057 - diff: 32.01mlTrain batch 14/31 - 170.5ms/batch - loss: 108.88568 - diff: 31.66mlTrain batch 15/31 - 171.4ms/batch - loss: 110.27733 - diff: 31.90mlTrain batch 16/31 - 172.0ms/batch - loss: 108.42420 - diff: 31.72mlTrain batch 17/31 - 171.6ms/batch - loss: 138.21682 - diff: 33.03mlTrain batch 18/31 - 171.9ms/batch - loss: 143.79063 - diff: 33.71mlTrain batch 19/31 - 171.3ms/batch - loss: 140.35164 - diff: 33.45mlTrain batch 20/31 - 172.0ms/batch - loss: 141.47210 - diff: 33.61mlTrain batch 21/31 - 172.3ms/batch - loss: 137.49634 - diff: 33.22mlTrain batch 22/31 - 172.3ms/batch - loss: 142.85077 - diff: 33.70mlTrain batch 23/31 - 171.8ms/batch - loss: 148.39825 - diff: 33.97mlTrain batch 24/31 - 172.1ms/batch - loss: 143.62155 - diff: 33.27mlTrain batch 25/31 - 172.0ms/batch - loss: 141.94298 - diff: 33.31mlTrain batch 26/31 - 172.2ms/batch - loss: 139.26261 - diff: 33.06mlTrain batch 27/31 - 172.1ms/batch - loss: 139.00680 - diff: 33.24mlTrain batch 28/31 - 172.4ms/batch - loss: 136.83613 - diff: 33.15mlTrain batch 29/31 - 172.1ms/batch - loss: 136.18813 - diff: 33.28mlTrain batch 30/31 - 172.3ms/batch - loss: 135.74818 - diff: 33.44mlTrain batch 31/31 - 87.0ms/batch - loss: 134.88996 - diff: 33.22mlTrain batch 31/31 - 11.1s 87.0ms/batch - loss: 134.88996 - diff: 33.22ml
Test 1.1s: val_loss: 118.11815 - diff: 33.10ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_WideResNet50_0_Adam-0.001_MSE_DA3_best

Epoch 42: current best loss = 118.11815, at epoch 41
Train batch 1/31 - 173.3ms/batch - loss: 110.15683 - diff: 34.75mlTrain batch 2/31 - 172.8ms/batch - loss: 94.37794 - diff: 31.39mlTrain batch 3/31 - 171.5ms/batch - loss: 101.95823 - diff: 33.27mlTrain batch 4/31 - 171.9ms/batch - loss: 105.39893 - diff: 33.38mlTrain batch 5/31 - 171.4ms/batch - loss: 184.76530 - diff: 36.33mlTrain batch 6/31 - 171.5ms/batch - loss: 186.74073 - diff: 37.81mlTrain batch 7/31 - 171.9ms/batch - loss: 178.23111 - diff: 37.80mlTrain batch 8/31 - 171.6ms/batch - loss: 171.81388 - diff: 37.79mlTrain batch 9/31 - 171.8ms/batch - loss: 163.64946 - diff: 37.05mlTrain batch 10/31 - 171.6ms/batch - loss: 160.17794 - diff: 37.24mlTrain batch 11/31 - 171.4ms/batch - loss: 161.69874 - diff: 37.89mlTrain batch 12/31 - 171.4ms/batch - loss: 158.27391 - diff: 37.86mlTrain batch 13/31 - 171.7ms/batch - loss: 163.53122 - diff: 38.12mlTrain batch 14/31 - 171.7ms/batch - loss: 159.02673 - diff: 37.86mlTrain batch 15/31 - 171.4ms/batch - loss: 152.97747 - diff: 37.23mlTrain batch 16/31 - 171.6ms/batch - loss: 147.69465 - diff: 36.42mlTrain batch 17/31 - 171.6ms/batch - loss: 142.12787 - diff: 35.72mlTrain batch 18/31 - 171.7ms/batch - loss: 139.00454 - diff: 35.42mlTrain batch 19/31 - 171.7ms/batch - loss: 139.82322 - diff: 35.66mlTrain batch 20/31 - 171.5ms/batch - loss: 137.85728 - diff: 35.53mlTrain batch 21/31 - 171.6ms/batch - loss: 138.43835 - diff: 35.55mlTrain batch 22/31 - 171.7ms/batch - loss: 142.93732 - diff: 35.87mlTrain batch 23/31 - 171.4ms/batch - loss: 142.19171 - diff: 35.89mlTrain batch 24/31 - 172.0ms/batch - loss: 141.29020 - diff: 35.60mlTrain batch 25/31 - 171.7ms/batch - loss: 142.96761 - diff: 35.65mlTrain batch 26/31 - 171.8ms/batch - loss: 140.26764 - diff: 35.33mlTrain batch 27/31 - 171.7ms/batch - loss: 136.56352 - diff: 34.73mlTrain batch 28/31 - 171.3ms/batch - loss: 134.74784 - diff: 34.59mlTrain batch 29/31 - 171.7ms/batch - loss: 133.31295 - diff: 34.41mlTrain batch 30/31 - 171.7ms/batch - loss: 131.74432 - diff: 34.33mlTrain batch 31/31 - 86.6ms/batch - loss: 132.26305 - diff: 34.22mlTrain batch 31/31 - 10.7s 86.6ms/batch - loss: 132.26305 - diff: 34.22ml
Test 1.2s: val_loss: 133.65098 - diff: 37.70ml

Epoch 43: current best loss = 118.11815, at epoch 41
Train batch 1/31 - 171.5ms/batch - loss: 110.14445 - diff: 32.27mlTrain batch 2/31 - 170.9ms/batch - loss: 131.64753 - diff: 35.68mlTrain batch 3/31 - 171.4ms/batch - loss: 126.41975 - diff: 35.72mlTrain batch 4/31 - 171.2ms/batch - loss: 113.23973 - diff: 34.43mlTrain batch 5/31 - 171.9ms/batch - loss: 116.63059 - diff: 35.16mlTrain batch 6/31 - 171.8ms/batch - loss: 129.72127 - diff: 36.87mlTrain batch 7/31 - 171.7ms/batch - loss: 126.18222 - diff: 36.50mlTrain batch 8/31 - 171.6ms/batch - loss: 123.48285 - diff: 35.81mlTrain batch 9/31 - 171.6ms/batch - loss: 136.05755 - diff: 37.37mlTrain batch 10/31 - 171.6ms/batch - loss: 145.79247 - diff: 37.50mlTrain batch 11/31 - 171.5ms/batch - loss: 144.25017 - diff: 37.48mlTrain batch 12/31 - 171.6ms/batch - loss: 138.02001 - diff: 36.63mlTrain batch 13/31 - 171.7ms/batch - loss: 134.65487 - diff: 36.35mlTrain batch 14/31 - 171.4ms/batch - loss: 131.39595 - diff: 35.88mlTrain batch 15/31 - 171.5ms/batch - loss: 133.90431 - diff: 36.21mlTrain batch 16/31 - 171.4ms/batch - loss: 132.66975 - diff: 35.82mlTrain batch 17/31 - 171.8ms/batch - loss: 128.28222 - diff: 35.09mlTrain batch 18/31 - 171.4ms/batch - loss: 132.97366 - diff: 35.63mlTrain batch 19/31 - 171.7ms/batch - loss: 129.05868 - diff: 35.06mlTrain batch 20/31 - 172.1ms/batch - loss: 125.54116 - diff: 34.64mlTrain batch 21/31 - 172.3ms/batch - loss: 124.20392 - diff: 34.30mlTrain batch 22/31 - 171.4ms/batch - loss: 121.25150 - diff: 33.87mlTrain batch 23/31 - 172.1ms/batch - loss: 121.00933 - diff: 33.98mlTrain batch 24/31 - 171.4ms/batch - loss: 120.90456 - diff: 34.00mlTrain batch 25/31 - 171.8ms/batch - loss: 117.90149 - diff: 33.44mlTrain batch 26/31 - 171.5ms/batch - loss: 116.50960 - diff: 33.21mlTrain batch 27/31 - 171.9ms/batch - loss: 114.91533 - diff: 32.97mlTrain batch 28/31 - 171.8ms/batch - loss: 114.47084 - diff: 32.86mlTrain batch 29/31 - 172.4ms/batch - loss: 129.03539 - diff: 33.41mlTrain batch 30/31 - 171.8ms/batch - loss: 136.39568 - diff: 34.10mlTrain batch 31/31 - 86.7ms/batch - loss: 136.84561 - diff: 34.02mlTrain batch 31/31 - 11.7s 86.7ms/batch - loss: 136.84561 - diff: 34.02ml
Test 1.1s: val_loss: 115.85033 - diff: 31.07ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_WideResNet50_0_Adam-0.001_MSE_DA3_best

Epoch 44: current best loss = 115.85033, at epoch 43
Train batch 1/31 - 171.5ms/batch - loss: 86.16745 - diff: 30.73mlTrain batch 2/31 - 171.8ms/batch - loss: 155.04265 - diff: 37.83mlTrain batch 3/31 - 171.5ms/batch - loss: 156.00128 - diff: 39.87mlTrain batch 4/31 - 171.9ms/batch - loss: 130.37714 - diff: 35.47mlTrain batch 5/31 - 171.6ms/batch - loss: 128.40380 - diff: 34.48mlTrain batch 6/31 - 171.6ms/batch - loss: 115.48571 - diff: 33.08mlTrain batch 7/31 - 171.5ms/batch - loss: 110.70168 - diff: 32.37mlTrain batch 8/31 - 171.9ms/batch - loss: 111.06914 - diff: 32.69mlTrain batch 9/31 - 171.7ms/batch - loss: 105.05512 - diff: 31.95mlTrain batch 10/31 - 170.9ms/batch - loss: 100.83802 - diff: 31.24mlTrain batch 11/31 - 171.3ms/batch - loss: 97.66163 - diff: 30.60mlTrain batch 12/31 - 171.8ms/batch - loss: 96.81702 - diff: 30.15mlTrain batch 13/31 - 171.7ms/batch - loss: 97.15888 - diff: 30.49mlTrain batch 14/31 - 170.9ms/batch - loss: 94.44947 - diff: 30.15mlTrain batch 15/31 - 171.8ms/batch - loss: 123.93888 - diff: 31.66mlTrain batch 16/31 - 171.0ms/batch - loss: 126.30542 - diff: 32.08mlTrain batch 17/31 - 171.6ms/batch - loss: 124.72777 - diff: 32.19mlTrain batch 18/31 - 172.5ms/batch - loss: 124.30953 - diff: 32.15mlTrain batch 19/31 - 171.7ms/batch - loss: 123.03846 - diff: 32.13mlTrain batch 20/31 - 172.1ms/batch - loss: 120.06691 - diff: 31.81mlTrain batch 21/31 - 172.0ms/batch - loss: 128.63738 - diff: 32.34mlTrain batch 22/31 - 172.2ms/batch - loss: 133.07661 - diff: 32.64mlTrain batch 23/31 - 171.2ms/batch - loss: 132.90366 - diff: 32.86mlTrain batch 24/31 - 171.1ms/batch - loss: 133.54217 - diff: 32.94mlTrain batch 25/31 - 171.5ms/batch - loss: 134.79102 - diff: 33.36mlTrain batch 26/31 - 171.8ms/batch - loss: 133.83205 - diff: 33.36mlTrain batch 27/31 - 171.8ms/batch - loss: 135.02203 - diff: 33.56mlTrain batch 28/31 - 171.4ms/batch - loss: 134.11513 - diff: 33.69mlTrain batch 29/31 - 171.6ms/batch - loss: 132.07789 - diff: 33.46mlTrain batch 30/31 - 171.7ms/batch - loss: 130.75917 - diff: 33.43mlTrain batch 31/31 - 86.4ms/batch - loss: 131.53304 - diff: 33.42mlTrain batch 31/31 - 11.4s 86.4ms/batch - loss: 131.53304 - diff: 33.42ml
Test 1.1s: val_loss: 112.22080 - diff: 33.36ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_WideResNet50_0_Adam-0.001_MSE_DA3_best

Epoch 45: current best loss = 112.22080, at epoch 44
Going to unfreeze the pretrained weights
Train batch 1/31 - 233.3ms/batch - loss: 649.58545 - diff: 57.54mlTrain batch 2/31 - 233.5ms/batch - loss: 473.83218 - diff: 60.13mlTrain batch 3/31 - 235.1ms/batch - loss: 383.55737 - diff: 54.01mlTrain batch 4/31 - 235.5ms/batch - loss: 341.61245 - diff: 52.01mlTrain batch 5/31 - 234.6ms/batch - loss: 293.11234 - diff: 47.50mlTrain batch 6/31 - 235.4ms/batch - loss: 280.34117 - diff: 47.00mlTrain batch 7/31 - 234.7ms/batch - loss: 263.26671 - diff: 45.83mlTrain batch 8/31 - 235.3ms/batch - loss: 258.39420 - diff: 46.58mlTrain batch 9/31 - 235.3ms/batch - loss: 246.02992 - diff: 45.64mlTrain batch 10/31 - 235.8ms/batch - loss: 237.16512 - diff: 45.00mlTrain batch 11/31 - 235.3ms/batch - loss: 233.87286 - diff: 44.06mlTrain batch 12/31 - 235.8ms/batch - loss: 227.47470 - diff: 43.90mlTrain batch 13/31 - 235.6ms/batch - loss: 218.46122 - diff: 43.03mlTrain batch 14/31 - 235.4ms/batch - loss: 223.52990 - diff: 43.54mlTrain batch 15/31 - 235.2ms/batch - loss: 215.04134 - diff: 42.71mlTrain batch 16/31 - 235.8ms/batch - loss: 210.55296 - diff: 42.47mlTrain batch 17/31 - 235.2ms/batch - loss: 206.65039 - diff: 41.86mlTrain batch 18/31 - 235.8ms/batch - loss: 203.68367 - diff: 41.80mlTrain batch 19/31 - 235.8ms/batch - loss: 199.92005 - diff: 41.65mlTrain batch 20/31 - 235.6ms/batch - loss: 194.08348 - diff: 41.11mlTrain batch 21/31 - 235.3ms/batch - loss: 192.87002 - diff: 40.88mlTrain batch 22/31 - 235.8ms/batch - loss: 193.46353 - diff: 40.80mlTrain batch 23/31 - 235.3ms/batch - loss: 186.98729 - diff: 40.03mlTrain batch 24/31 - 235.4ms/batch - loss: 182.22906 - diff: 39.55mlTrain batch 25/31 - 235.6ms/batch - loss: 177.53405 - diff: 39.09mlTrain batch 26/31 - 235.7ms/batch - loss: 178.23312 - diff: 39.53mlTrain batch 27/31 - 235.6ms/batch - loss: 176.15261 - diff: 39.36mlTrain batch 28/31 - 235.4ms/batch - loss: 171.23045 - diff: 38.73mlTrain batch 29/31 - 235.7ms/batch - loss: 171.92435 - diff: 38.73mlTrain batch 30/31 - 235.1ms/batch - loss: 171.63960 - diff: 38.76mlTrain batch 31/31 - 121.6ms/batch - loss: 179.34566 - diff: 39.11mlTrain batch 31/31 - 11.6s 121.6ms/batch - loss: 179.34566 - diff: 39.11ml
Test 1.1s: val_loss: 152.64412 - diff: 34.12ml

Epoch 46: current best loss = 112.22080, at epoch 44
Train batch 1/31 - 234.9ms/batch - loss: 166.22853 - diff: 42.63mlTrain batch 2/31 - 235.2ms/batch - loss: 144.78666 - diff: 39.17mlTrain batch 3/31 - 234.8ms/batch - loss: 151.98609 - diff: 38.98mlTrain batch 4/31 - 236.2ms/batch - loss: 168.36488 - diff: 40.21mlTrain batch 5/31 - 235.6ms/batch - loss: 159.05062 - diff: 40.34mlTrain batch 6/31 - 235.9ms/batch - loss: 142.74817 - diff: 37.83mlTrain batch 7/31 - 235.2ms/batch - loss: 131.58281 - diff: 36.28mlTrain batch 8/31 - 235.6ms/batch - loss: 143.43067 - diff: 36.76mlTrain batch 9/31 - 235.4ms/batch - loss: 143.58539 - diff: 36.60mlTrain batch 10/31 - 235.7ms/batch - loss: 145.98251 - diff: 36.87mlTrain batch 11/31 - 235.5ms/batch - loss: 140.82233 - diff: 36.23mlTrain batch 12/31 - 235.9ms/batch - loss: 141.08151 - diff: 36.28mlTrain batch 13/31 - 235.2ms/batch - loss: 142.48961 - diff: 36.80mlTrain batch 14/31 - 236.1ms/batch - loss: 138.58932 - diff: 36.49mlTrain batch 15/31 - 235.6ms/batch - loss: 137.95129 - diff: 36.63mlTrain batch 16/31 - 235.7ms/batch - loss: 139.85914 - diff: 36.88mlTrain batch 17/31 - 235.7ms/batch - loss: 142.23563 - diff: 37.27mlTrain batch 18/31 - 235.5ms/batch - loss: 137.74008 - diff: 36.72mlTrain batch 19/31 - 235.8ms/batch - loss: 134.55167 - diff: 36.42mlTrain batch 20/31 - 236.1ms/batch - loss: 138.78240 - diff: 37.21mlTrain batch 21/31 - 235.3ms/batch - loss: 138.76455 - diff: 37.21mlTrain batch 22/31 - 236.0ms/batch - loss: 139.30073 - diff: 37.29mlTrain batch 23/31 - 235.6ms/batch - loss: 136.87409 - diff: 37.05mlTrain batch 24/31 - 235.5ms/batch - loss: 135.80125 - diff: 36.94mlTrain batch 25/31 - 235.7ms/batch - loss: 132.40484 - diff: 36.35mlTrain batch 26/31 - 235.6ms/batch - loss: 132.16128 - diff: 36.33mlTrain batch 27/31 - 235.5ms/batch - loss: 128.75090 - diff: 35.72mlTrain batch 28/31 - 236.4ms/batch - loss: 158.99529 - diff: 37.02mlTrain batch 29/31 - 235.8ms/batch - loss: 156.64135 - diff: 36.79mlTrain batch 30/31 - 235.8ms/batch - loss: 157.23205 - diff: 36.91mlTrain batch 31/31 - 121.8ms/batch - loss: 160.21225 - diff: 36.96mlTrain batch 31/31 - 11.8s 121.8ms/batch - loss: 160.21225 - diff: 36.96ml
Test 1.1s: val_loss: 104.86725 - diff: 30.25ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_WideResNet50_0_Adam-0.001_MSE_DA3_best

Epoch 47: current best loss = 104.86725, at epoch 46
Train batch 1/31 - 234.6ms/batch - loss: 39.36008 - diff: 21.03mlTrain batch 2/31 - 235.3ms/batch - loss: 39.13836 - diff: 21.00mlTrain batch 3/31 - 235.3ms/batch - loss: 195.78858 - diff: 33.06mlTrain batch 4/31 - 235.9ms/batch - loss: 176.38243 - diff: 33.77mlTrain batch 5/31 - 235.5ms/batch - loss: 156.73852 - diff: 33.07mlTrain batch 6/31 - 236.1ms/batch - loss: 151.79960 - diff: 34.53mlTrain batch 7/31 - 235.6ms/batch - loss: 145.44294 - diff: 34.24mlTrain batch 8/31 - 236.2ms/batch - loss: 142.48657 - diff: 34.62mlTrain batch 9/31 - 235.1ms/batch - loss: 139.68535 - diff: 34.46mlTrain batch 10/31 - 235.5ms/batch - loss: 138.23939 - diff: 34.63mlTrain batch 11/31 - 235.4ms/batch - loss: 135.13080 - diff: 33.97mlTrain batch 12/31 - 235.9ms/batch - loss: 150.64507 - diff: 35.97mlTrain batch 13/31 - 234.8ms/batch - loss: 146.95737 - diff: 35.72mlTrain batch 14/31 - 235.2ms/batch - loss: 152.79329 - diff: 36.58mlTrain batch 15/31 - 235.8ms/batch - loss: 146.30577 - diff: 35.96mlTrain batch 16/31 - 236.0ms/batch - loss: 151.97123 - diff: 36.26mlTrain batch 17/31 - 235.6ms/batch - loss: 147.49529 - diff: 35.71mlTrain batch 18/31 - 236.2ms/batch - loss: 153.83672 - diff: 36.72mlTrain batch 19/31 - 235.5ms/batch - loss: 150.32582 - diff: 36.60mlTrain batch 20/31 - 237.9ms/batch - loss: 145.65297 - diff: 36.09mlTrain batch 21/31 - 235.3ms/batch - loss: 141.62495 - diff: 35.63mlTrain batch 22/31 - 236.3ms/batch - loss: 141.68519 - diff: 35.66mlTrain batch 23/31 - 235.9ms/batch - loss: 140.59010 - diff: 35.59mlTrain batch 24/31 - 236.3ms/batch - loss: 140.80182 - diff: 35.70mlTrain batch 25/31 - 235.9ms/batch - loss: 137.41107 - diff: 35.24mlTrain batch 26/31 - 236.0ms/batch - loss: 135.90898 - diff: 35.05mlTrain batch 27/31 - 235.4ms/batch - loss: 136.12305 - diff: 35.09mlTrain batch 28/31 - 236.1ms/batch - loss: 136.84043 - diff: 35.31mlTrain batch 29/31 - 235.3ms/batch - loss: 135.67649 - diff: 35.23mlTrain batch 30/31 - 236.1ms/batch - loss: 138.32455 - diff: 35.45mlTrain batch 31/31 - 121.7ms/batch - loss: 144.47809 - diff: 35.61mlTrain batch 31/31 - 11.9s 121.7ms/batch - loss: 144.47809 - diff: 35.61ml
Test 1.1s: val_loss: 96.12500 - diff: 30.38ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_WideResNet50_0_Adam-0.001_MSE_DA3_best

Epoch 48: current best loss = 96.12500, at epoch 47
Train batch 1/31 - 237.4ms/batch - loss: 55.75132 - diff: 23.11mlTrain batch 2/31 - 235.9ms/batch - loss: 84.55020 - diff: 25.89mlTrain batch 3/31 - 235.0ms/batch - loss: 95.19393 - diff: 28.57mlTrain batch 4/31 - 235.9ms/batch - loss: 99.13599 - diff: 29.88mlTrain batch 5/31 - 235.3ms/batch - loss: 102.72785 - diff: 31.80mlTrain batch 6/31 - 234.5ms/batch - loss: 144.07738 - diff: 33.44mlTrain batch 7/31 - 235.5ms/batch - loss: 135.20969 - diff: 32.91mlTrain batch 8/31 - 236.0ms/batch - loss: 142.53190 - diff: 35.18mlTrain batch 9/31 - 236.1ms/batch - loss: 136.21626 - diff: 34.57mlTrain batch 10/31 - 235.9ms/batch - loss: 134.04562 - diff: 34.47mlTrain batch 11/31 - 235.9ms/batch - loss: 148.05234 - diff: 35.59mlTrain batch 12/31 - 236.7ms/batch - loss: 139.80659 - diff: 34.45mlTrain batch 13/31 - 235.7ms/batch - loss: 133.92712 - diff: 33.71mlTrain batch 14/31 - 236.1ms/batch - loss: 137.06209 - diff: 33.93mlTrain batch 15/31 - 235.9ms/batch - loss: 139.78180 - diff: 34.63mlTrain batch 16/31 - 238.0ms/batch - loss: 139.74182 - diff: 34.78mlTrain batch 17/31 - 235.2ms/batch - loss: 138.68831 - diff: 34.93mlTrain batch 18/31 - 236.2ms/batch - loss: 148.27599 - diff: 35.89mlTrain batch 19/31 - 235.3ms/batch - loss: 147.68259 - diff: 35.96mlTrain batch 20/31 - 236.1ms/batch - loss: 142.74942 - diff: 35.34mlTrain batch 21/31 - 235.6ms/batch - loss: 141.31015 - diff: 35.16mlTrain batch 22/31 - 235.0ms/batch - loss: 137.98324 - diff: 34.81mlTrain batch 23/31 - 235.5ms/batch - loss: 136.34498 - diff: 34.73mlTrain batch 24/31 - 235.6ms/batch - loss: 134.15299 - diff: 34.62mlTrain batch 25/31 - 235.5ms/batch - loss: 131.27877 - diff: 34.17mlTrain batch 26/31 - 236.1ms/batch - loss: 130.77436 - diff: 34.28mlTrain batch 27/31 - 236.1ms/batch - loss: 131.38832 - diff: 34.46mlTrain batch 28/31 - 236.2ms/batch - loss: 131.69502 - diff: 34.64mlTrain batch 29/31 - 235.3ms/batch - loss: 130.30253 - diff: 34.46mlTrain batch 30/31 - 236.2ms/batch - loss: 129.19348 - diff: 34.44mlTrain batch 31/31 - 121.9ms/batch - loss: 129.58001 - diff: 34.29mlTrain batch 31/31 - 12.1s 121.9ms/batch - loss: 129.58001 - diff: 34.29ml
Test 1.1s: val_loss: 92.83033 - diff: 28.85ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_WideResNet50_0_Adam-0.001_MSE_DA3_best

Epoch 49: current best loss = 92.83033, at epoch 48
Train batch 1/31 - 235.0ms/batch - loss: 144.48160 - diff: 33.14mlTrain batch 2/31 - 235.4ms/batch - loss: 326.04994 - diff: 43.87mlTrain batch 3/31 - 235.1ms/batch - loss: 294.06334 - diff: 46.83mlTrain batch 4/31 - 235.2ms/batch - loss: 230.94864 - diff: 40.63mlTrain batch 5/31 - 235.3ms/batch - loss: 206.81286 - diff: 38.87mlTrain batch 6/31 - 235.8ms/batch - loss: 186.19323 - diff: 37.30mlTrain batch 7/31 - 235.1ms/batch - loss: 186.59885 - diff: 37.33mlTrain batch 8/31 - 235.8ms/batch - loss: 192.32767 - diff: 38.41mlTrain batch 9/31 - 236.0ms/batch - loss: 184.16865 - diff: 38.14mlTrain batch 10/31 - 236.5ms/batch - loss: 172.49797 - diff: 37.17mlTrain batch 11/31 - 234.9ms/batch - loss: 161.40354 - diff: 35.76mlTrain batch 12/31 - 235.3ms/batch - loss: 155.50844 - diff: 35.44mlTrain batch 13/31 - 235.4ms/batch - loss: 150.60005 - diff: 35.24mlTrain batch 14/31 - 235.6ms/batch - loss: 147.72422 - diff: 35.20mlTrain batch 15/31 - 235.4ms/batch - loss: 142.69404 - diff: 34.80mlTrain batch 16/31 - 235.6ms/batch - loss: 136.83835 - diff: 33.95mlTrain batch 17/31 - 235.6ms/batch - loss: 131.23819 - diff: 33.23mlTrain batch 18/31 - 236.1ms/batch - loss: 133.02002 - diff: 33.65mlTrain batch 19/31 - 235.7ms/batch - loss: 137.40570 - diff: 33.87mlTrain batch 20/31 - 236.3ms/batch - loss: 136.54078 - diff: 33.91mlTrain batch 21/31 - 235.7ms/batch - loss: 136.45848 - diff: 34.02mlTrain batch 22/31 - 236.1ms/batch - loss: 132.56010 - diff: 33.49mlTrain batch 23/31 - 235.6ms/batch - loss: 129.78766 - diff: 33.23mlTrain batch 24/31 - 236.2ms/batch - loss: 127.56530 - diff: 33.02mlTrain batch 25/31 - 235.9ms/batch - loss: 124.92155 - diff: 32.77mlTrain batch 26/31 - 236.0ms/batch - loss: 127.01065 - diff: 33.06mlTrain batch 27/31 - 234.5ms/batch - loss: 125.44660 - diff: 32.86mlTrain batch 28/31 - 235.9ms/batch - loss: 122.33585 - diff: 32.38mlTrain batch 29/31 - 235.5ms/batch - loss: 121.30692 - diff: 32.30mlTrain batch 30/31 - 236.1ms/batch - loss: 120.53787 - diff: 32.42mlTrain batch 31/31 - 121.9ms/batch - loss: 122.59323 - diff: 32.47mlTrain batch 31/31 - 12.2s 121.9ms/batch - loss: 122.59323 - diff: 32.47ml
Test 1.1s: val_loss: 91.07070 - diff: 29.72ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_WideResNet50_0_Adam-0.001_MSE_DA3_best

Epoch 50: current best loss = 91.07070, at epoch 49
Train batch 1/31 - 235.1ms/batch - loss: 73.58987 - diff: 28.09mlTrain batch 2/31 - 235.7ms/batch - loss: 83.59618 - diff: 30.24mlTrain batch 3/31 - 235.3ms/batch - loss: 80.63847 - diff: 28.33mlTrain batch 4/31 - 235.5ms/batch - loss: 97.57607 - diff: 29.59mlTrain batch 5/31 - 235.7ms/batch - loss: 92.02276 - diff: 29.03mlTrain batch 6/31 - 236.3ms/batch - loss: 104.38315 - diff: 31.14mlTrain batch 7/31 - 236.1ms/batch - loss: 97.08704 - diff: 30.21mlTrain batch 8/31 - 236.1ms/batch - loss: 92.24901 - diff: 29.04mlTrain batch 9/31 - 236.0ms/batch - loss: 98.60112 - diff: 29.51mlTrain batch 10/31 - 236.0ms/batch - loss: 93.97338 - diff: 28.88mlTrain batch 11/31 - 235.8ms/batch - loss: 89.92110 - diff: 28.06mlTrain batch 12/31 - 236.0ms/batch - loss: 87.05651 - diff: 27.88mlTrain batch 13/31 - 235.9ms/batch - loss: 88.92172 - diff: 27.60mlTrain batch 14/31 - 236.1ms/batch - loss: 93.56050 - diff: 27.91mlTrain batch 15/31 - 235.7ms/batch - loss: 93.97875 - diff: 28.32mlTrain batch 16/31 - 236.2ms/batch - loss: 99.44300 - diff: 28.84mlTrain batch 17/31 - 236.1ms/batch - loss: 96.53383 - diff: 28.49mlTrain batch 18/31 - 236.2ms/batch - loss: 95.07458 - diff: 28.55mlTrain batch 19/31 - 235.9ms/batch - loss: 95.28414 - diff: 28.60mlTrain batch 20/31 - 236.1ms/batch - loss: 98.00131 - diff: 29.01mlTrain batch 21/31 - 236.0ms/batch - loss: 97.55468 - diff: 29.07mlTrain batch 22/31 - 236.1ms/batch - loss: 105.95627 - diff: 29.45mlTrain batch 23/31 - 235.9ms/batch - loss: 105.48008 - diff: 29.50mlTrain batch 24/31 - 235.9ms/batch - loss: 104.30435 - diff: 29.36mlTrain batch 25/31 - 235.9ms/batch - loss: 103.09766 - diff: 29.26mlTrain batch 26/31 - 236.2ms/batch - loss: 103.18096 - diff: 29.37mlTrain batch 27/31 - 235.9ms/batch - loss: 101.48453 - diff: 29.03mlTrain batch 28/31 - 236.3ms/batch - loss: 99.57090 - diff: 28.77mlTrain batch 29/31 - 236.2ms/batch - loss: 100.07110 - diff: 28.92mlTrain batch 30/31 - 236.0ms/batch - loss: 100.43265 - diff: 29.13mlTrain batch 31/31 - 123.2ms/batch - loss: 101.22268 - diff: 29.10mlTrain batch 31/31 - 10.5s 123.2ms/batch - loss: 101.22268 - diff: 29.10ml
Test 1.1s: val_loss: 137.98366 - diff: 38.71ml

Epoch 51: current best loss = 91.07070, at epoch 49
Train batch 1/31 - 235.7ms/batch - loss: 40.47389 - diff: 19.94mlTrain batch 2/31 - 236.5ms/batch - loss: 43.23808 - diff: 20.67mlTrain batch 3/31 - 236.0ms/batch - loss: 68.14530 - diff: 25.60mlTrain batch 4/31 - 236.3ms/batch - loss: 73.69711 - diff: 27.32mlTrain batch 5/31 - 235.8ms/batch - loss: 80.32013 - diff: 27.67mlTrain batch 6/31 - 236.4ms/batch - loss: 81.95441 - diff: 27.47mlTrain batch 7/31 - 235.6ms/batch - loss: 85.80739 - diff: 27.84mlTrain batch 8/31 - 236.2ms/batch - loss: 93.07782 - diff: 29.40mlTrain batch 9/31 - 235.7ms/batch - loss: 94.00671 - diff: 29.30mlTrain batch 10/31 - 236.2ms/batch - loss: 94.39190 - diff: 29.22mlTrain batch 11/31 - 236.0ms/batch - loss: 93.64666 - diff: 29.55mlTrain batch 12/31 - 236.1ms/batch - loss: 101.43259 - diff: 30.91mlTrain batch 13/31 - 236.0ms/batch - loss: 97.77348 - diff: 30.48mlTrain batch 14/31 - 236.3ms/batch - loss: 93.64137 - diff: 29.80mlTrain batch 15/31 - 235.9ms/batch - loss: 95.79211 - diff: 30.27mlTrain batch 16/31 - 236.1ms/batch - loss: 92.75608 - diff: 29.62mlTrain batch 17/31 - 236.2ms/batch - loss: 96.59115 - diff: 30.23mlTrain batch 18/31 - 236.1ms/batch - loss: 95.29865 - diff: 29.95mlTrain batch 19/31 - 235.5ms/batch - loss: 98.97998 - diff: 30.53mlTrain batch 20/31 - 236.5ms/batch - loss: 100.65381 - diff: 31.11mlTrain batch 21/31 - 235.9ms/batch - loss: 100.29227 - diff: 31.20mlTrain batch 22/31 - 236.3ms/batch - loss: 98.37061 - diff: 30.87mlTrain batch 23/31 - 235.9ms/batch - loss: 111.26801 - diff: 31.76mlTrain batch 24/31 - 236.2ms/batch - loss: 110.37026 - diff: 31.66mlTrain batch 25/31 - 235.9ms/batch - loss: 109.45522 - diff: 31.50mlTrain batch 26/31 - 236.4ms/batch - loss: 107.20820 - diff: 30.92mlTrain batch 27/31 - 235.9ms/batch - loss: 106.42984 - diff: 30.91mlTrain batch 28/31 - 236.2ms/batch - loss: 105.97247 - diff: 30.93mlTrain batch 29/31 - 235.9ms/batch - loss: 106.74111 - diff: 31.19mlTrain batch 30/31 - 236.3ms/batch - loss: 107.99623 - diff: 31.37mlTrain batch 31/31 - 123.1ms/batch - loss: 108.12629 - diff: 31.25mlTrain batch 31/31 - 12.6s 123.1ms/batch - loss: 108.12629 - diff: 31.25ml
Test 1.2s: val_loss: 230.57515 - diff: 47.20ml

Epoch 52: current best loss = 91.07070, at epoch 49
Train batch 1/31 - 235.8ms/batch - loss: 128.33252 - diff: 35.33mlTrain batch 2/31 - 236.2ms/batch - loss: 149.47569 - diff: 38.43mlTrain batch 3/31 - 235.9ms/batch - loss: 122.38113 - diff: 34.88mlTrain batch 4/31 - 236.7ms/batch - loss: 107.99233 - diff: 32.59mlTrain batch 5/31 - 236.5ms/batch - loss: 98.38046 - diff: 31.18mlTrain batch 6/31 - 235.8ms/batch - loss: 98.51472 - diff: 31.06mlTrain batch 7/31 - 235.9ms/batch - loss: 149.45936 - diff: 34.08mlTrain batch 8/31 - 236.2ms/batch - loss: 155.18243 - diff: 35.89mlTrain batch 9/31 - 236.1ms/batch - loss: 152.56880 - diff: 35.75mlTrain batch 10/31 - 236.3ms/batch - loss: 147.48792 - diff: 35.65mlTrain batch 11/31 - 236.0ms/batch - loss: 142.46824 - diff: 35.36mlTrain batch 12/31 - 237.0ms/batch - loss: 142.01671 - diff: 35.26mlTrain batch 13/31 - 236.1ms/batch - loss: 138.42971 - diff: 34.74mlTrain batch 14/31 - 236.3ms/batch - loss: 134.63987 - diff: 34.28mlTrain batch 15/31 - 236.0ms/batch - loss: 133.12511 - diff: 34.21mlTrain batch 16/31 - 236.3ms/batch - loss: 128.41615 - diff: 33.62mlTrain batch 17/31 - 236.2ms/batch - loss: 125.14609 - diff: 33.17mlTrain batch 18/31 - 237.1ms/batch - loss: 124.23846 - diff: 33.10mlTrain batch 19/31 - 235.8ms/batch - loss: 120.19556 - diff: 32.63mlTrain batch 20/31 - 236.5ms/batch - loss: 119.28861 - diff: 32.52mlTrain batch 21/31 - 236.3ms/batch - loss: 120.02973 - diff: 32.54mlTrain batch 22/31 - 236.7ms/batch - loss: 119.17010 - diff: 32.63mlTrain batch 23/31 - 235.7ms/batch - loss: 120.58699 - diff: 32.83mlTrain batch 24/31 - 236.6ms/batch - loss: 118.26358 - diff: 32.61mlTrain batch 25/31 - 235.6ms/batch - loss: 119.56233 - diff: 32.94mlTrain batch 26/31 - 236.7ms/batch - loss: 120.13597 - diff: 33.12mlTrain batch 27/31 - 236.2ms/batch - loss: 117.85707 - diff: 32.71mlTrain batch 28/31 - 236.8ms/batch - loss: 117.32398 - diff: 32.82mlTrain batch 29/31 - 235.6ms/batch - loss: 117.10116 - diff: 32.77mlTrain batch 30/31 - 236.3ms/batch - loss: 114.37796 - diff: 32.32mlTrain batch 31/31 - 123.3ms/batch - loss: 114.46162 - diff: 32.19mlTrain batch 31/31 - 11.3s 123.3ms/batch - loss: 114.46162 - diff: 32.19ml
Test 1.2s: val_loss: 104.58363 - diff: 29.52ml

Epoch 53: current best loss = 91.07070, at epoch 49
Train batch 1/31 - 235.7ms/batch - loss: 195.73389 - diff: 41.66mlTrain batch 2/31 - 236.4ms/batch - loss: 134.27379 - diff: 35.51mlTrain batch 3/31 - 236.1ms/batch - loss: 119.47574 - diff: 33.49mlTrain batch 4/31 - 236.3ms/batch - loss: 101.88506 - diff: 30.41mlTrain batch 5/31 - 235.9ms/batch - loss: 106.79361 - diff: 31.90mlTrain batch 6/31 - 236.4ms/batch - loss: 92.72262 - diff: 29.25mlTrain batch 7/31 - 237.9ms/batch - loss: 152.45818 - diff: 32.98mlTrain batch 8/31 - 236.0ms/batch - loss: 150.00266 - diff: 33.35mlTrain batch 9/31 - 235.7ms/batch - loss: 140.80226 - diff: 32.42mlTrain batch 10/31 - 237.2ms/batch - loss: 138.47242 - diff: 32.65mlTrain batch 11/31 - 242.1ms/batch - loss: 134.70317 - diff: 32.64mlTrain batch 12/31 - 237.2ms/batch - loss: 131.59500 - diff: 32.50mlTrain batch 13/31 - 236.2ms/batch - loss: 130.95409 - diff: 32.70mlTrain batch 14/31 - 236.9ms/batch - loss: 123.38567 - diff: 31.64mlTrain batch 15/31 - 236.0ms/batch - loss: 124.28895 - diff: 32.01mlTrain batch 16/31 - 236.9ms/batch - loss: 120.81152 - diff: 31.46mlTrain batch 17/31 - 236.0ms/batch - loss: 124.23877 - diff: 31.94mlTrain batch 18/31 - 236.7ms/batch - loss: 122.55731 - diff: 31.78mlTrain batch 19/31 - 236.2ms/batch - loss: 119.08723 - diff: 31.52mlTrain batch 20/31 - 236.7ms/batch - loss: 120.17609 - diff: 31.96mlTrain batch 21/31 - 236.0ms/batch - loss: 119.75714 - diff: 32.19mlTrain batch 22/31 - 236.8ms/batch - loss: 117.96354 - diff: 32.09mlTrain batch 23/31 - 236.1ms/batch - loss: 116.05192 - diff: 31.93mlTrain batch 24/31 - 236.7ms/batch - loss: 117.42602 - diff: 32.08mlTrain batch 25/31 - 236.2ms/batch - loss: 117.02211 - diff: 32.14mlTrain batch 26/31 - 236.7ms/batch - loss: 114.11371 - diff: 31.70mlTrain batch 27/31 - 236.3ms/batch - loss: 113.71528 - diff: 31.76mlTrain batch 28/31 - 236.1ms/batch - loss: 116.46068 - diff: 32.02mlTrain batch 29/31 - 236.1ms/batch - loss: 115.61691 - diff: 32.10mlTrain batch 30/31 - 237.0ms/batch - loss: 113.94713 - diff: 31.98mlTrain batch 31/31 - 123.9ms/batch - loss: 113.27714 - diff: 31.74mlTrain batch 31/31 - 11.3s 123.9ms/batch - loss: 113.27714 - diff: 31.74ml
Test 1.2s: val_loss: 109.03019 - diff: 31.03ml

Epoch 54: current best loss = 91.07070, at epoch 49
Train batch 1/31 - 235.9ms/batch - loss: 76.35496 - diff: 23.78mlTrain batch 2/31 - 236.4ms/batch - loss: 62.80621 - diff: 23.14mlTrain batch 3/31 - 236.0ms/batch - loss: 88.75508 - diff: 28.77mlTrain batch 4/31 - 236.2ms/batch - loss: 92.49243 - diff: 30.14mlTrain batch 5/31 - 236.0ms/batch - loss: 93.28330 - diff: 30.77mlTrain batch 6/31 - 237.0ms/batch - loss: 89.02980 - diff: 30.14mlTrain batch 7/31 - 236.3ms/batch - loss: 93.80316 - diff: 30.56mlTrain batch 8/31 - 236.5ms/batch - loss: 89.39053 - diff: 29.71mlTrain batch 9/31 - 236.2ms/batch - loss: 94.25549 - diff: 30.42mlTrain batch 10/31 - 236.0ms/batch - loss: 91.88656 - diff: 30.08mlTrain batch 11/31 - 236.6ms/batch - loss: 94.89743 - diff: 30.39mlTrain batch 12/31 - 236.0ms/batch - loss: 97.43710 - diff: 30.48mlTrain batch 13/31 - 236.7ms/batch - loss: 100.01962 - diff: 30.51mlTrain batch 14/31 - 238.1ms/batch - loss: 99.20865 - diff: 30.11mlTrain batch 15/31 - 236.0ms/batch - loss: 97.98822 - diff: 30.02mlTrain batch 16/31 - 236.3ms/batch - loss: 97.44372 - diff: 30.09mlTrain batch 17/31 - 236.9ms/batch - loss: 102.60752 - diff: 31.00mlTrain batch 18/31 - 236.9ms/batch - loss: 101.37305 - diff: 30.67mlTrain batch 19/31 - 236.6ms/batch - loss: 101.19081 - diff: 30.66mlTrain batch 20/31 - 236.2ms/batch - loss: 97.76797 - diff: 30.04mlTrain batch 21/31 - 239.6ms/batch - loss: 98.22660 - diff: 30.10mlTrain batch 22/31 - 236.2ms/batch - loss: 98.51723 - diff: 30.27mlTrain batch 23/31 - 236.5ms/batch - loss: 98.85900 - diff: 30.41mlTrain batch 24/31 - 236.4ms/batch - loss: 101.05960 - diff: 30.86mlTrain batch 25/31 - 237.3ms/batch - loss: 98.71764 - diff: 30.48mlTrain batch 26/31 - 236.4ms/batch - loss: 99.33287 - diff: 30.55mlTrain batch 27/31 - 236.8ms/batch - loss: 113.14040 - diff: 31.56mlTrain batch 28/31 - 236.1ms/batch - loss: 111.82515 - diff: 31.40mlTrain batch 29/31 - 236.2ms/batch - loss: 109.49890 - diff: 31.00mlTrain batch 30/31 - 237.0ms/batch - loss: 109.03185 - diff: 30.97mlTrain batch 31/31 - 123.0ms/batch - loss: 109.04562 - diff: 30.82mlTrain batch 31/31 - 11.0s 123.0ms/batch - loss: 109.04562 - diff: 30.82ml
Test 1.2s: val_loss: 93.34654 - diff: 27.04ml

Epoch 55: current best loss = 91.07070, at epoch 49
Train batch 1/31 - 236.0ms/batch - loss: 189.49159 - diff: 41.84mlTrain batch 2/31 - 235.0ms/batch - loss: 128.93082 - diff: 32.98mlTrain batch 3/31 - 236.1ms/batch - loss: 94.16715 - diff: 27.64mlTrain batch 4/31 - 235.8ms/batch - loss: 106.74585 - diff: 30.85mlTrain batch 5/31 - 235.9ms/batch - loss: 94.59533 - diff: 28.97mlTrain batch 6/31 - 236.3ms/batch - loss: 87.14211 - diff: 28.10mlTrain batch 7/31 - 236.0ms/batch - loss: 97.58563 - diff: 29.69mlTrain batch 8/31 - 236.6ms/batch - loss: 116.24540 - diff: 29.97mlTrain batch 9/31 - 236.3ms/batch - loss: 113.86755 - diff: 30.02mlTrain batch 10/31 - 237.0ms/batch - loss: 109.85582 - diff: 29.56mlTrain batch 11/31 - 236.0ms/batch - loss: 105.79169 - diff: 29.41mlTrain batch 12/31 - 237.0ms/batch - loss: 104.12756 - diff: 29.74mlTrain batch 13/31 - 236.3ms/batch - loss: 98.80212 - diff: 29.00mlTrain batch 14/31 - 237.4ms/batch - loss: 101.40959 - diff: 29.54mlTrain batch 15/31 - 236.1ms/batch - loss: 100.46412 - diff: 29.76mlTrain batch 16/31 - 237.4ms/batch - loss: 104.65873 - diff: 30.35mlTrain batch 17/31 - 239.7ms/batch - loss: 105.62438 - diff: 30.25mlTrain batch 18/31 - 236.7ms/batch - loss: 105.96448 - diff: 30.40mlTrain batch 19/31 - 235.9ms/batch - loss: 104.57921 - diff: 30.32mlTrain batch 20/31 - 236.9ms/batch - loss: 104.74214 - diff: 30.28mlTrain batch 21/31 - 236.2ms/batch - loss: 108.54368 - diff: 30.78mlTrain batch 22/31 - 237.3ms/batch - loss: 107.42428 - diff: 30.67mlTrain batch 23/31 - 236.0ms/batch - loss: 111.25457 - diff: 30.99mlTrain batch 24/31 - 237.0ms/batch - loss: 109.52634 - diff: 30.84mlTrain batch 25/31 - 236.1ms/batch - loss: 107.01753 - diff: 30.59mlTrain batch 26/31 - 237.7ms/batch - loss: 104.66534 - diff: 30.25mlTrain batch 27/31 - 236.2ms/batch - loss: 102.08706 - diff: 29.81mlTrain batch 28/31 - 236.9ms/batch - loss: 104.07847 - diff: 30.15mlTrain batch 29/31 - 236.4ms/batch - loss: 102.73660 - diff: 30.14mlTrain batch 30/31 - 236.9ms/batch - loss: 104.43550 - diff: 30.49mlTrain batch 31/31 - 123.2ms/batch - loss: 104.88398 - diff: 30.35mlTrain batch 31/31 - 11.5s 123.2ms/batch - loss: 104.88398 - diff: 30.35ml
Test 1.2s: val_loss: 95.91791 - diff: 31.01ml

Epoch 56: current best loss = 91.07070, at epoch 49
Train batch 1/31 - 236.1ms/batch - loss: 68.84559 - diff: 25.72mlTrain batch 2/31 - 237.5ms/batch - loss: 71.50671 - diff: 27.77mlTrain batch 3/31 - 237.4ms/batch - loss: 119.72263 - diff: 29.85mlTrain batch 4/31 - 236.3ms/batch - loss: 121.79480 - diff: 30.96mlTrain batch 5/31 - 236.5ms/batch - loss: 114.96228 - diff: 29.86mlTrain batch 6/31 - 237.8ms/batch - loss: 108.46192 - diff: 29.40mlTrain batch 7/31 - 236.7ms/batch - loss: 103.92910 - diff: 29.26mlTrain batch 8/31 - 237.0ms/batch - loss: 110.49528 - diff: 30.95mlTrain batch 9/31 - 236.0ms/batch - loss: 114.29395 - diff: 31.87mlTrain batch 10/31 - 235.4ms/batch - loss: 124.29171 - diff: 32.48mlTrain batch 11/31 - 236.5ms/batch - loss: 120.72561 - diff: 32.32mlTrain batch 12/31 - 237.2ms/batch - loss: 122.50587 - diff: 32.84mlTrain batch 13/31 - 236.3ms/batch - loss: 120.52904 - diff: 32.59mlTrain batch 14/31 - 236.9ms/batch - loss: 122.71628 - diff: 32.92mlTrain batch 15/31 - 236.5ms/batch - loss: 122.74948 - diff: 33.15mlTrain batch 16/31 - 236.5ms/batch - loss: 119.23193 - diff: 32.66mlTrain batch 17/31 - 236.1ms/batch - loss: 116.64267 - diff: 32.53mlTrain batch 18/31 - 236.6ms/batch - loss: 116.07809 - diff: 32.47mlTrain batch 19/31 - 236.5ms/batch - loss: 113.27289 - diff: 32.15mlTrain batch 20/31 - 236.9ms/batch - loss: 110.63104 - diff: 31.88mlTrain batch 21/31 - 236.1ms/batch - loss: 108.08339 - diff: 31.50mlTrain batch 22/31 - 237.0ms/batch - loss: 118.46721 - diff: 32.11mlTrain batch 23/31 - 236.0ms/batch - loss: 116.72408 - diff: 32.05mlTrain batch 24/31 - 236.8ms/batch - loss: 115.87161 - diff: 32.14mlTrain batch 25/31 - 236.3ms/batch - loss: 114.44107 - diff: 32.00mlTrain batch 26/31 - 237.2ms/batch - loss: 116.43362 - diff: 32.43mlTrain batch 27/31 - 235.9ms/batch - loss: 113.85546 - diff: 32.01mlTrain batch 28/31 - 236.8ms/batch - loss: 112.58249 - diff: 31.80mlTrain batch 29/31 - 236.3ms/batch - loss: 111.86833 - diff: 31.80mlTrain batch 30/31 - 236.3ms/batch - loss: 113.05650 - diff: 31.99mlTrain batch 31/31 - 123.1ms/batch - loss: 114.85733 - diff: 32.10mlTrain batch 31/31 - 11.7s 123.1ms/batch - loss: 114.85733 - diff: 32.10ml
Test 1.1s: val_loss: 99.28302 - diff: 29.92ml

Epoch 57: current best loss = 91.07070, at epoch 49
Train batch 1/31 - 236.2ms/batch - loss: 220.57913 - diff: 46.07mlTrain batch 2/31 - 236.7ms/batch - loss: 155.72335 - diff: 37.58mlTrain batch 3/31 - 235.8ms/batch - loss: 127.97030 - diff: 35.21mlTrain batch 4/31 - 237.6ms/batch - loss: 110.68894 - diff: 31.49mlTrain batch 5/31 - 236.1ms/batch - loss: 107.35320 - diff: 31.59mlTrain batch 6/31 - 236.4ms/batch - loss: 144.81350 - diff: 33.95mlTrain batch 7/31 - 236.0ms/batch - loss: 132.28848 - diff: 32.68mlTrain batch 8/31 - 237.2ms/batch - loss: 125.41115 - diff: 32.11mlTrain batch 9/31 - 235.8ms/batch - loss: 120.79608 - diff: 32.04mlTrain batch 10/31 - 237.4ms/batch - loss: 111.34769 - diff: 30.53mlTrain batch 11/31 - 236.5ms/batch - loss: 109.71821 - diff: 30.70mlTrain batch 12/31 - 237.3ms/batch - loss: 106.92975 - diff: 30.35mlTrain batch 13/31 - 236.3ms/batch - loss: 103.93898 - diff: 30.14mlTrain batch 14/31 - 236.9ms/batch - loss: 102.50092 - diff: 30.06mlTrain batch 15/31 - 236.4ms/batch - loss: 100.60791 - diff: 29.76mlTrain batch 16/31 - 236.9ms/batch - loss: 107.85796 - diff: 30.71mlTrain batch 17/31 - 236.4ms/batch - loss: 108.59031 - diff: 30.99mlTrain batch 18/31 - 237.0ms/batch - loss: 109.66169 - diff: 31.21mlTrain batch 19/31 - 235.5ms/batch - loss: 107.06309 - diff: 30.92mlTrain batch 20/31 - 237.0ms/batch - loss: 104.96933 - diff: 30.57mlTrain batch 21/31 - 236.1ms/batch - loss: 103.79830 - diff: 30.27mlTrain batch 22/31 - 237.5ms/batch - loss: 104.24483 - diff: 30.54mlTrain batch 23/31 - 236.1ms/batch - loss: 103.60439 - diff: 30.50mlTrain batch 24/31 - 239.5ms/batch - loss: 103.28841 - diff: 30.55mlTrain batch 25/31 - 236.5ms/batch - loss: 100.88443 - diff: 30.18mlTrain batch 26/31 - 237.0ms/batch - loss: 101.62318 - diff: 30.10mlTrain batch 27/31 - 236.6ms/batch - loss: 101.85914 - diff: 30.28mlTrain batch 28/31 - 237.6ms/batch - loss: 104.60819 - diff: 30.67mlTrain batch 29/31 - 236.3ms/batch - loss: 103.61401 - diff: 30.61mlTrain batch 30/31 - 237.2ms/batch - loss: 102.01479 - diff: 30.47mlTrain batch 31/31 - 124.0ms/batch - loss: 104.11023 - diff: 30.52mlTrain batch 31/31 - 11.6s 124.0ms/batch - loss: 104.11023 - diff: 30.52ml
Test 1.2s: val_loss: 614.82433 - diff: 89.64ml

Epoch 58: current best loss = 91.07070, at epoch 49
Train batch 1/31 - 235.8ms/batch - loss: 82.00020 - diff: 27.59mlTrain batch 2/31 - 237.0ms/batch - loss: 85.35371 - diff: 29.03mlTrain batch 3/31 - 235.8ms/batch - loss: 73.36961 - diff: 26.32mlTrain batch 4/31 - 237.5ms/batch - loss: 78.60843 - diff: 26.45mlTrain batch 5/31 - 236.2ms/batch - loss: 78.25976 - diff: 27.23mlTrain batch 6/31 - 237.2ms/batch - loss: 141.37813 - diff: 31.34mlTrain batch 7/31 - 243.1ms/batch - loss: 129.00658 - diff: 30.30mlTrain batch 8/31 - 236.9ms/batch - loss: 137.83902 - diff: 32.01mlTrain batch 9/31 - 235.8ms/batch - loss: 129.52784 - diff: 31.32mlTrain batch 10/31 - 236.3ms/batch - loss: 127.71627 - diff: 31.38mlTrain batch 11/31 - 236.4ms/batch - loss: 124.92929 - diff: 31.50mlTrain batch 12/31 - 237.1ms/batch - loss: 128.25330 - diff: 32.20mlTrain batch 13/31 - 236.2ms/batch - loss: 132.98299 - diff: 32.99mlTrain batch 14/31 - 237.2ms/batch - loss: 133.55150 - diff: 33.49mlTrain batch 15/31 - 236.2ms/batch - loss: 132.75238 - diff: 33.68mlTrain batch 16/31 - 237.3ms/batch - loss: 129.12910 - diff: 33.35mlTrain batch 17/31 - 236.2ms/batch - loss: 127.95717 - diff: 33.20mlTrain batch 18/31 - 237.1ms/batch - loss: 124.52790 - diff: 32.91mlTrain batch 19/31 - 236.3ms/batch - loss: 125.87654 - diff: 33.34mlTrain batch 20/31 - 236.6ms/batch - loss: 123.29822 - diff: 33.14mlTrain batch 21/31 - 235.8ms/batch - loss: 122.88817 - diff: 33.20mlTrain batch 22/31 - 237.2ms/batch - loss: 121.60238 - diff: 33.12mlTrain batch 23/31 - 239.7ms/batch - loss: 119.04500 - diff: 32.82mlTrain batch 24/31 - 237.1ms/batch - loss: 119.08842 - diff: 32.78mlTrain batch 25/31 - 236.3ms/batch - loss: 116.64548 - diff: 32.47mlTrain batch 26/31 - 237.2ms/batch - loss: 115.08250 - diff: 32.33mlTrain batch 27/31 - 235.9ms/batch - loss: 117.38917 - diff: 32.28mlTrain batch 28/31 - 237.1ms/batch - loss: 116.39334 - diff: 32.30mlTrain batch 29/31 - 236.5ms/batch - loss: 115.28640 - diff: 32.20mlTrain batch 30/31 - 237.4ms/batch - loss: 114.82580 - diff: 32.24mlTrain batch 31/31 - 123.8ms/batch - loss: 114.37127 - diff: 32.04mlTrain batch 31/31 - 11.2s 123.8ms/batch - loss: 114.37127 - diff: 32.04ml
Test 1.2s: val_loss: 283.37514 - diff: 54.17ml

Epoch 59: current best loss = 91.07070, at epoch 49
Train batch 1/31 - 236.4ms/batch - loss: 56.88390 - diff: 23.42mlTrain batch 2/31 - 236.8ms/batch - loss: 76.92456 - diff: 27.09mlTrain batch 3/31 - 236.4ms/batch - loss: 87.70971 - diff: 28.70mlTrain batch 4/31 - 237.1ms/batch - loss: 83.81865 - diff: 28.01mlTrain batch 5/31 - 236.2ms/batch - loss: 76.90790 - diff: 27.21mlTrain batch 6/31 - 236.9ms/batch - loss: 79.20483 - diff: 27.18mlTrain batch 7/31 - 236.1ms/batch - loss: 78.77045 - diff: 27.34mlTrain batch 8/31 - 237.1ms/batch - loss: 84.35564 - diff: 28.36mlTrain batch 9/31 - 236.3ms/batch - loss: 79.56449 - diff: 27.79mlTrain batch 10/31 - 237.0ms/batch - loss: 75.69600 - diff: 27.01mlTrain batch 11/31 - 235.9ms/batch - loss: 85.50329 - diff: 28.42mlTrain batch 12/31 - 236.0ms/batch - loss: 90.67766 - diff: 29.35mlTrain batch 13/31 - 236.1ms/batch - loss: 87.72827 - diff: 29.03mlTrain batch 14/31 - 236.3ms/batch - loss: 86.16380 - diff: 29.01mlTrain batch 15/31 - 237.1ms/batch - loss: 87.45731 - diff: 29.27mlTrain batch 16/31 - 236.1ms/batch - loss: 89.53174 - diff: 29.63mlTrain batch 17/31 - 237.1ms/batch - loss: 94.71076 - diff: 30.13mlTrain batch 18/31 - 236.2ms/batch - loss: 92.93010 - diff: 29.68mlTrain batch 19/31 - 236.7ms/batch - loss: 89.97213 - diff: 29.15mlTrain batch 20/31 - 236.0ms/batch - loss: 87.01433 - diff: 28.67mlTrain batch 21/31 - 236.8ms/batch - loss: 85.82912 - diff: 28.57mlTrain batch 22/31 - 236.2ms/batch - loss: 101.80728 - diff: 30.16mlTrain batch 23/31 - 237.0ms/batch - loss: 106.82416 - diff: 30.89mlTrain batch 24/31 - 236.2ms/batch - loss: 105.12498 - diff: 30.66mlTrain batch 25/31 - 237.3ms/batch - loss: 107.31727 - diff: 30.92mlTrain batch 26/31 - 236.1ms/batch - loss: 107.80245 - diff: 30.83mlTrain batch 27/31 - 236.7ms/batch - loss: 110.06576 - diff: 31.03mlTrain batch 28/31 - 236.1ms/batch - loss: 111.39306 - diff: 31.42mlTrain batch 29/31 - 236.9ms/batch - loss: 110.25501 - diff: 31.20mlTrain batch 30/31 - 236.2ms/batch - loss: 109.25950 - diff: 31.11mlTrain batch 31/31 - 124.0ms/batch - loss: 110.37735 - diff: 31.13mlTrain batch 31/31 - 12.4s 124.0ms/batch - loss: 110.37735 - diff: 31.13ml
Test 1.2s: val_loss: 687.47758 - diff: 96.32ml

Epoch 60: current best loss = 91.07070, at epoch 49
Train batch 1/31 - 236.1ms/batch - loss: 93.60754 - diff: 31.37mlTrain batch 2/31 - 236.0ms/batch - loss: 97.47295 - diff: 31.27mlTrain batch 3/31 - 236.2ms/batch - loss: 100.55402 - diff: 31.76mlTrain batch 4/31 - 236.2ms/batch - loss: 96.44053 - diff: 31.08mlTrain batch 5/31 - 236.2ms/batch - loss: 81.10869 - diff: 27.57mlTrain batch 6/31 - 236.3ms/batch - loss: 78.32733 - diff: 26.81mlTrain batch 7/31 - 236.6ms/batch - loss: 83.60776 - diff: 27.02mlTrain batch 8/31 - 236.0ms/batch - loss: 80.87765 - diff: 26.60mlTrain batch 9/31 - 236.5ms/batch - loss: 81.23904 - diff: 26.85mlTrain batch 10/31 - 236.1ms/batch - loss: 78.52649 - diff: 26.37mlTrain batch 11/31 - 236.6ms/batch - loss: 76.75857 - diff: 26.31mlTrain batch 12/31 - 236.3ms/batch - loss: 81.07458 - diff: 27.10mlTrain batch 13/31 - 236.8ms/batch - loss: 84.36374 - diff: 27.61mlTrain batch 14/31 - 236.2ms/batch - loss: 83.61673 - diff: 27.59mlTrain batch 15/31 - 236.7ms/batch - loss: 84.08341 - diff: 27.75mlTrain batch 16/31 - 236.3ms/batch - loss: 82.86241 - diff: 27.60mlTrain batch 17/31 - 237.1ms/batch - loss: 87.35029 - diff: 28.34mlTrain batch 18/31 - 236.0ms/batch - loss: 92.35023 - diff: 29.25mlTrain batch 19/31 - 237.1ms/batch - loss: 93.39996 - diff: 29.15mlTrain batch 20/31 - 241.8ms/batch - loss: 93.19367 - diff: 29.06mlTrain batch 21/31 - 236.8ms/batch - loss: 94.17808 - diff: 29.26mlTrain batch 22/31 - 236.0ms/batch - loss: 93.82472 - diff: 29.37mlTrain batch 23/31 - 237.3ms/batch - loss: 91.55908 - diff: 29.00mlTrain batch 24/31 - 236.6ms/batch - loss: 90.73210 - diff: 28.82mlTrain batch 25/31 - 237.2ms/batch - loss: 96.98027 - diff: 29.10mlTrain batch 26/31 - 236.3ms/batch - loss: 97.45144 - diff: 29.33mlTrain batch 27/31 - 237.9ms/batch - loss: 95.13327 - diff: 29.00mlTrain batch 28/31 - 236.3ms/batch - loss: 94.84676 - diff: 29.17mlTrain batch 29/31 - 236.9ms/batch - loss: 94.65931 - diff: 29.21mlTrain batch 30/31 - 238.5ms/batch - loss: 95.35714 - diff: 29.31mlTrain batch 31/31 - 123.3ms/batch - loss: 97.08022 - diff: 29.34mlTrain batch 31/31 - 11.1s 123.3ms/batch - loss: 97.08022 - diff: 29.34ml
Test 1.2s: val_loss: 185.83879 - diff: 42.73ml
Epoch    61: reducing learning rate of group 0 to 5.0000e-04.

Epoch 61: current best loss = 91.07070, at epoch 49
Train batch 1/31 - 236.1ms/batch - loss: 63.06852 - diff: 23.92mlTrain batch 2/31 - 236.4ms/batch - loss: 59.48610 - diff: 23.41mlTrain batch 3/31 - 236.1ms/batch - loss: 69.89949 - diff: 25.09mlTrain batch 4/31 - 237.4ms/batch - loss: 69.15933 - diff: 25.23mlTrain batch 5/31 - 236.0ms/batch - loss: 74.78182 - diff: 26.69mlTrain batch 6/31 - 237.3ms/batch - loss: 74.91588 - diff: 26.97mlTrain batch 7/31 - 236.1ms/batch - loss: 79.38376 - diff: 27.71mlTrain batch 8/31 - 236.7ms/batch - loss: 88.49983 - diff: 27.78mlTrain batch 9/31 - 236.3ms/batch - loss: 82.51263 - diff: 26.88mlTrain batch 10/31 - 237.5ms/batch - loss: 81.50845 - diff: 26.94mlTrain batch 11/31 - 236.2ms/batch - loss: 81.53846 - diff: 27.04mlTrain batch 12/31 - 237.0ms/batch - loss: 87.58996 - diff: 27.96mlTrain batch 13/31 - 236.4ms/batch - loss: 85.70906 - diff: 27.79mlTrain batch 14/31 - 237.3ms/batch - loss: 84.34375 - diff: 27.62mlTrain batch 15/31 - 236.7ms/batch - loss: 84.66391 - diff: 27.43mlTrain batch 16/31 - 236.7ms/batch - loss: 83.82623 - diff: 27.47mlTrain batch 17/31 - 236.1ms/batch - loss: 81.33249 - diff: 27.01mlTrain batch 18/31 - 236.8ms/batch - loss: 82.32415 - diff: 27.36mlTrain batch 19/31 - 236.6ms/batch - loss: 81.44596 - diff: 27.42mlTrain batch 20/31 - 236.7ms/batch - loss: 80.59223 - diff: 27.35mlTrain batch 21/31 - 236.3ms/batch - loss: 79.87528 - diff: 27.31mlTrain batch 22/31 - 236.3ms/batch - loss: 80.99131 - diff: 27.63mlTrain batch 23/31 - 236.9ms/batch - loss: 82.13186 - diff: 28.00mlTrain batch 24/31 - 236.2ms/batch - loss: 82.35685 - diff: 27.92mlTrain batch 25/31 - 237.4ms/batch - loss: 81.53277 - diff: 27.74mlTrain batch 26/31 - 236.2ms/batch - loss: 82.31548 - diff: 27.86mlTrain batch 27/31 - 237.0ms/batch - loss: 82.46650 - diff: 27.95mlTrain batch 28/31 - 236.5ms/batch - loss: 82.43648 - diff: 28.03mlTrain batch 29/31 - 236.4ms/batch - loss: 81.83703 - diff: 27.97mlTrain batch 30/31 - 236.5ms/batch - loss: 82.71602 - diff: 28.07mlTrain batch 31/31 - 123.7ms/batch - loss: 82.41798 - diff: 27.89mlTrain batch 31/31 - 11.3s 123.7ms/batch - loss: 82.41798 - diff: 27.89ml
Test 1.2s: val_loss: 68.70338 - diff: 24.68ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_WideResNet50_0_Adam-0.001_MSE_DA3_best

Epoch 62: current best loss = 68.70338, at epoch 61
Train batch 1/31 - 252.2ms/batch - loss: 51.44453 - diff: 23.31mlTrain batch 2/31 - 236.7ms/batch - loss: 67.43690 - diff: 25.35mlTrain batch 3/31 - 235.7ms/batch - loss: 71.38445 - diff: 26.29mlTrain batch 4/31 - 236.3ms/batch - loss: 76.07821 - diff: 27.10mlTrain batch 5/31 - 236.2ms/batch - loss: 76.86258 - diff: 26.83mlTrain batch 6/31 - 236.1ms/batch - loss: 77.54243 - diff: 27.05mlTrain batch 7/31 - 236.4ms/batch - loss: 72.89948 - diff: 25.99mlTrain batch 8/31 - 236.9ms/batch - loss: 71.01076 - diff: 25.84mlTrain batch 9/31 - 236.2ms/batch - loss: 69.30213 - diff: 25.27mlTrain batch 10/31 - 237.0ms/batch - loss: 68.11769 - diff: 25.14mlTrain batch 11/31 - 235.8ms/batch - loss: 64.68380 - diff: 24.57mlTrain batch 12/31 - 236.4ms/batch - loss: 63.77162 - diff: 24.45mlTrain batch 13/31 - 236.0ms/batch - loss: 66.25303 - diff: 25.10mlTrain batch 14/31 - 236.6ms/batch - loss: 64.67139 - diff: 25.02mlTrain batch 15/31 - 236.2ms/batch - loss: 68.22039 - diff: 25.52mlTrain batch 16/31 - 236.3ms/batch - loss: 66.48909 - diff: 25.22mlTrain batch 17/31 - 236.1ms/batch - loss: 68.08723 - diff: 25.50mlTrain batch 18/31 - 236.8ms/batch - loss: 72.72494 - diff: 26.04mlTrain batch 19/31 - 236.0ms/batch - loss: 71.51382 - diff: 25.87mlTrain batch 20/31 - 237.3ms/batch - loss: 74.64246 - diff: 26.28mlTrain batch 21/31 - 236.1ms/batch - loss: 73.01022 - diff: 25.96mlTrain batch 22/31 - 236.5ms/batch - loss: 73.60042 - diff: 26.14mlTrain batch 23/31 - 236.5ms/batch - loss: 71.93817 - diff: 25.75mlTrain batch 24/31 - 236.2ms/batch - loss: 72.44600 - diff: 25.98mlTrain batch 25/31 - 236.5ms/batch - loss: 72.49953 - diff: 26.06mlTrain batch 26/31 - 237.3ms/batch - loss: 71.41252 - diff: 25.83mlTrain batch 27/31 - 236.2ms/batch - loss: 71.85397 - diff: 26.01mlTrain batch 28/31 - 237.3ms/batch - loss: 71.36517 - diff: 25.88mlTrain batch 29/31 - 236.4ms/batch - loss: 70.77408 - diff: 25.88mlTrain batch 30/31 - 237.0ms/batch - loss: 80.76234 - diff: 26.67mlTrain batch 31/31 - 122.8ms/batch - loss: 80.30219 - diff: 26.51mlTrain batch 31/31 - 12.4s 122.8ms/batch - loss: 80.30219 - diff: 26.51ml
Test 1.2s: val_loss: 85.02437 - diff: 26.75ml

Epoch 63: current best loss = 68.70338, at epoch 61
Train batch 1/31 - 236.3ms/batch - loss: 33.76614 - diff: 20.41mlTrain batch 2/31 - 236.3ms/batch - loss: 56.58602 - diff: 23.96mlTrain batch 3/31 - 236.3ms/batch - loss: 54.87518 - diff: 24.10mlTrain batch 4/31 - 237.3ms/batch - loss: 89.29095 - diff: 26.89mlTrain batch 5/31 - 236.0ms/batch - loss: 88.86753 - diff: 27.72mlTrain batch 6/31 - 241.4ms/batch - loss: 87.22007 - diff: 27.28mlTrain batch 7/31 - 236.2ms/batch - loss: 80.97694 - diff: 26.50mlTrain batch 8/31 - 236.8ms/batch - loss: 76.33965 - diff: 25.90mlTrain batch 9/31 - 236.5ms/batch - loss: 73.40124 - diff: 25.74mlTrain batch 10/31 - 237.4ms/batch - loss: 68.84849 - diff: 24.84mlTrain batch 11/31 - 236.2ms/batch - loss: 67.38000 - diff: 24.91mlTrain batch 12/31 - 236.8ms/batch - loss: 68.38286 - diff: 25.24mlTrain batch 13/31 - 236.4ms/batch - loss: 67.58387 - diff: 25.09mlTrain batch 14/31 - 237.1ms/batch - loss: 68.26784 - diff: 25.30mlTrain batch 15/31 - 235.9ms/batch - loss: 65.86049 - diff: 24.97mlTrain batch 16/31 - 237.3ms/batch - loss: 66.01518 - diff: 25.11mlTrain batch 17/31 - 236.0ms/batch - loss: 66.07496 - diff: 25.27mlTrain batch 18/31 - 236.8ms/batch - loss: 65.21782 - diff: 25.05mlTrain batch 19/31 - 236.2ms/batch - loss: 67.62970 - diff: 25.44mlTrain batch 20/31 - 237.2ms/batch - loss: 70.98635 - diff: 25.92mlTrain batch 21/31 - 236.8ms/batch - loss: 70.53538 - diff: 25.89mlTrain batch 22/31 - 237.4ms/batch - loss: 71.88952 - diff: 26.32mlTrain batch 23/31 - 236.1ms/batch - loss: 71.98948 - diff: 26.23mlTrain batch 24/31 - 237.4ms/batch - loss: 71.51790 - diff: 26.20mlTrain batch 25/31 - 236.2ms/batch - loss: 72.41943 - diff: 26.44mlTrain batch 26/31 - 237.1ms/batch - loss: 73.87905 - diff: 26.56mlTrain batch 27/31 - 236.3ms/batch - loss: 74.51451 - diff: 26.66mlTrain batch 28/31 - 237.8ms/batch - loss: 75.54367 - diff: 26.86mlTrain batch 29/31 - 236.3ms/batch - loss: 77.01887 - diff: 27.01mlTrain batch 30/31 - 236.5ms/batch - loss: 76.02756 - diff: 26.84mlTrain batch 31/31 - 123.5ms/batch - loss: 76.55734 - diff: 26.80mlTrain batch 31/31 - 11.4s 123.5ms/batch - loss: 76.55734 - diff: 26.80ml
Test 1.1s: val_loss: 70.99383 - diff: 24.50ml

Epoch 64: current best loss = 68.70338, at epoch 61
Train batch 1/31 - 236.1ms/batch - loss: 116.06859 - diff: 27.82mlTrain batch 2/31 - 236.3ms/batch - loss: 108.87230 - diff: 31.01mlTrain batch 3/31 - 236.1ms/batch - loss: 84.95692 - diff: 26.89mlTrain batch 4/31 - 237.1ms/batch - loss: 86.90953 - diff: 27.42mlTrain batch 5/31 - 236.1ms/batch - loss: 118.99608 - diff: 29.41mlTrain batch 6/31 - 236.3ms/batch - loss: 120.64790 - diff: 30.91mlTrain batch 7/31 - 236.2ms/batch - loss: 113.26297 - diff: 29.50mlTrain batch 8/31 - 236.9ms/batch - loss: 112.99171 - diff: 29.47mlTrain batch 9/31 - 236.2ms/batch - loss: 108.72953 - diff: 29.30mlTrain batch 10/31 - 236.7ms/batch - loss: 106.29281 - diff: 29.59mlTrain batch 11/31 - 235.7ms/batch - loss: 105.50656 - diff: 29.56mlTrain batch 12/31 - 237.2ms/batch - loss: 99.88903 - diff: 28.83mlTrain batch 13/31 - 236.1ms/batch - loss: 95.17109 - diff: 28.25mlTrain batch 14/31 - 237.1ms/batch - loss: 94.70866 - diff: 28.51mlTrain batch 15/31 - 236.4ms/batch - loss: 96.11138 - diff: 28.98mlTrain batch 16/31 - 236.9ms/batch - loss: 101.69438 - diff: 30.02mlTrain batch 17/31 - 236.4ms/batch - loss: 100.29318 - diff: 29.95mlTrain batch 18/31 - 237.2ms/batch - loss: 102.62093 - diff: 30.08mlTrain batch 19/31 - 236.4ms/batch - loss: 100.10043 - diff: 29.88mlTrain batch 20/31 - 237.5ms/batch - loss: 98.34979 - diff: 29.54mlTrain batch 21/31 - 236.3ms/batch - loss: 101.27596 - diff: 30.12mlTrain batch 22/31 - 237.9ms/batch - loss: 99.32531 - diff: 29.85mlTrain batch 23/31 - 237.0ms/batch - loss: 96.91064 - diff: 29.52mlTrain batch 24/31 - 237.6ms/batch - loss: 95.33932 - diff: 29.34mlTrain batch 25/31 - 236.2ms/batch - loss: 93.21244 - diff: 28.92mlTrain batch 26/31 - 237.1ms/batch - loss: 92.17352 - diff: 28.74mlTrain batch 27/31 - 236.5ms/batch - loss: 91.51062 - diff: 28.69mlTrain batch 28/31 - 237.2ms/batch - loss: 89.96747 - diff: 28.49mlTrain batch 29/31 - 236.2ms/batch - loss: 89.35397 - diff: 28.53mlTrain batch 30/31 - 237.4ms/batch - loss: 88.47980 - diff: 28.33mlTrain batch 31/31 - 123.9ms/batch - loss: 93.19761 - diff: 28.59mlTrain batch 31/31 - 12.0s 123.9ms/batch - loss: 93.19761 - diff: 28.59ml
Test 1.1s: val_loss: 79.99992 - diff: 25.47ml

Epoch 65: current best loss = 68.70338, at epoch 61
Train batch 1/31 - 236.2ms/batch - loss: 78.57785 - diff: 28.56mlTrain batch 2/31 - 236.8ms/batch - loss: 83.38576 - diff: 28.14mlTrain batch 3/31 - 236.4ms/batch - loss: 74.81637 - diff: 26.25mlTrain batch 4/31 - 236.2ms/batch - loss: 72.65717 - diff: 25.49mlTrain batch 5/31 - 237.6ms/batch - loss: 73.80891 - diff: 26.00mlTrain batch 6/31 - 236.0ms/batch - loss: 73.35077 - diff: 26.12mlTrain batch 7/31 - 237.5ms/batch - loss: 82.15674 - diff: 27.82mlTrain batch 8/31 - 236.4ms/batch - loss: 75.66901 - diff: 26.82mlTrain batch 9/31 - 236.8ms/batch - loss: 73.04398 - diff: 26.55mlTrain batch 10/31 - 236.4ms/batch - loss: 72.13881 - diff: 26.48mlTrain batch 11/31 - 237.0ms/batch - loss: 92.93354 - diff: 27.53mlTrain batch 12/31 - 236.3ms/batch - loss: 88.97437 - diff: 26.95mlTrain batch 13/31 - 237.2ms/batch - loss: 88.29301 - diff: 27.10mlTrain batch 14/31 - 236.3ms/batch - loss: 87.76428 - diff: 27.13mlTrain batch 15/31 - 236.8ms/batch - loss: 85.70639 - diff: 27.10mlTrain batch 16/31 - 236.2ms/batch - loss: 82.63947 - diff: 26.69mlTrain batch 17/31 - 237.2ms/batch - loss: 81.86433 - diff: 26.70mlTrain batch 18/31 - 236.1ms/batch - loss: 84.86593 - diff: 27.43mlTrain batch 19/31 - 236.7ms/batch - loss: 83.49755 - diff: 27.17mlTrain batch 20/31 - 236.4ms/batch - loss: 82.09032 - diff: 27.05mlTrain batch 21/31 - 237.5ms/batch - loss: 81.73455 - diff: 27.25mlTrain batch 22/31 - 236.3ms/batch - loss: 79.80512 - diff: 26.87mlTrain batch 23/31 - 237.1ms/batch - loss: 79.25174 - diff: 26.65mlTrain batch 24/31 - 237.3ms/batch - loss: 78.74418 - diff: 26.64mlTrain batch 25/31 - 237.3ms/batch - loss: 78.77011 - diff: 26.68mlTrain batch 26/31 - 236.1ms/batch - loss: 82.25885 - diff: 27.25mlTrain batch 27/31 - 236.2ms/batch - loss: 80.94079 - diff: 26.95mlTrain batch 28/31 - 236.9ms/batch - loss: 79.69016 - diff: 26.74mlTrain batch 29/31 - 235.9ms/batch - loss: 78.93232 - diff: 26.66mlTrain batch 30/31 - 237.4ms/batch - loss: 78.03856 - diff: 26.61mlTrain batch 31/31 - 123.8ms/batch - loss: 79.81787 - diff: 26.71mlTrain batch 31/31 - 11.8s 123.8ms/batch - loss: 79.81787 - diff: 26.71ml
Test 1.2s: val_loss: 75.66440 - diff: 26.61ml

Epoch 66: current best loss = 68.70338, at epoch 61
Train batch 1/31 - 236.3ms/batch - loss: 33.94581 - diff: 17.56mlTrain batch 2/31 - 236.7ms/batch - loss: 43.55605 - diff: 21.01mlTrain batch 3/31 - 236.3ms/batch - loss: 54.91783 - diff: 22.54mlTrain batch 4/31 - 236.5ms/batch - loss: 60.70675 - diff: 24.48mlTrain batch 5/31 - 236.1ms/batch - loss: 64.46756 - diff: 25.15mlTrain batch 6/31 - 236.4ms/batch - loss: 62.64047 - diff: 24.76mlTrain batch 7/31 - 236.4ms/batch - loss: 58.10106 - diff: 23.86mlTrain batch 8/31 - 237.1ms/batch - loss: 59.96142 - diff: 24.52mlTrain batch 9/31 - 236.4ms/batch - loss: 59.82446 - diff: 24.49mlTrain batch 10/31 - 236.8ms/batch - loss: 65.33462 - diff: 25.44mlTrain batch 11/31 - 236.1ms/batch - loss: 63.49423 - diff: 25.12mlTrain batch 12/31 - 237.3ms/batch - loss: 65.14354 - diff: 25.15mlTrain batch 13/31 - 236.2ms/batch - loss: 65.83165 - diff: 25.22mlTrain batch 14/31 - 237.1ms/batch - loss: 64.11523 - diff: 24.92mlTrain batch 15/31 - 236.7ms/batch - loss: 65.75809 - diff: 25.29mlTrain batch 16/31 - 237.4ms/batch - loss: 64.23755 - diff: 24.97mlTrain batch 17/31 - 236.0ms/batch - loss: 61.43708 - diff: 24.30mlTrain batch 18/31 - 237.2ms/batch - loss: 60.37807 - diff: 24.13mlTrain batch 19/31 - 236.2ms/batch - loss: 58.42047 - diff: 23.77mlTrain batch 20/31 - 237.0ms/batch - loss: 59.88589 - diff: 23.97mlTrain batch 21/31 - 236.1ms/batch - loss: 59.49555 - diff: 23.88mlTrain batch 22/31 - 237.0ms/batch - loss: 59.35788 - diff: 23.88mlTrain batch 23/31 - 236.3ms/batch - loss: 59.37797 - diff: 23.98mlTrain batch 24/31 - 237.2ms/batch - loss: 59.20907 - diff: 24.00mlTrain batch 25/31 - 236.2ms/batch - loss: 61.72725 - diff: 24.40mlTrain batch 26/31 - 236.1ms/batch - loss: 61.99078 - diff: 24.52mlTrain batch 27/31 - 236.6ms/batch - loss: 64.48142 - diff: 24.90mlTrain batch 28/31 - 237.6ms/batch - loss: 66.64152 - diff: 25.33mlTrain batch 29/31 - 236.0ms/batch - loss: 66.26355 - diff: 25.31mlTrain batch 30/31 - 237.6ms/batch - loss: 67.07960 - diff: 25.61mlTrain batch 31/31 - 123.6ms/batch - loss: 69.71016 - diff: 25.69mlTrain batch 31/31 - 11.5s 123.6ms/batch - loss: 69.71016 - diff: 25.69ml
Test 1.2s: val_loss: 67.32351 - diff: 24.22ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_WideResNet50_0_Adam-0.001_MSE_DA3_best

Epoch 67: current best loss = 67.32351, at epoch 66
Train batch 1/31 - 235.5ms/batch - loss: 51.41294 - diff: 19.99mlTrain batch 2/31 - 236.1ms/batch - loss: 45.41781 - diff: 18.99mlTrain batch 3/31 - 235.9ms/batch - loss: 69.30867 - diff: 23.28mlTrain batch 4/31 - 236.6ms/batch - loss: 77.53950 - diff: 24.73mlTrain batch 5/31 - 236.3ms/batch - loss: 69.81233 - diff: 23.68mlTrain batch 6/31 - 236.9ms/batch - loss: 74.67893 - diff: 24.11mlTrain batch 7/31 - 236.1ms/batch - loss: 72.48619 - diff: 24.14mlTrain batch 8/31 - 236.4ms/batch - loss: 66.73537 - diff: 23.29mlTrain batch 9/31 - 235.8ms/batch - loss: 62.59226 - diff: 22.54mlTrain batch 10/31 - 237.2ms/batch - loss: 62.76067 - diff: 22.54mlTrain batch 11/31 - 236.1ms/batch - loss: 63.50121 - diff: 22.89mlTrain batch 12/31 - 237.0ms/batch - loss: 61.45596 - diff: 22.60mlTrain batch 13/31 - 236.2ms/batch - loss: 65.44942 - diff: 23.12mlTrain batch 14/31 - 237.5ms/batch - loss: 64.32008 - diff: 23.07mlTrain batch 15/31 - 236.4ms/batch - loss: 64.56087 - diff: 23.26mlTrain batch 16/31 - 237.2ms/batch - loss: 62.83035 - diff: 23.02mlTrain batch 17/31 - 236.2ms/batch - loss: 63.09518 - diff: 23.26mlTrain batch 18/31 - 237.5ms/batch - loss: 64.72871 - diff: 23.68mlTrain batch 19/31 - 240.3ms/batch - loss: 65.58530 - diff: 23.96mlTrain batch 20/31 - 237.4ms/batch - loss: 66.86830 - diff: 24.28mlTrain batch 21/31 - 236.6ms/batch - loss: 65.40099 - diff: 24.03mlTrain batch 22/31 - 237.0ms/batch - loss: 65.12652 - diff: 24.18mlTrain batch 23/31 - 236.2ms/batch - loss: 65.60568 - diff: 24.35mlTrain batch 24/31 - 236.6ms/batch - loss: 66.92740 - diff: 24.66mlTrain batch 25/31 - 236.1ms/batch - loss: 66.83829 - diff: 24.73mlTrain batch 26/31 - 237.3ms/batch - loss: 66.55416 - diff: 24.55mlTrain batch 27/31 - 236.8ms/batch - loss: 67.10917 - diff: 24.66mlTrain batch 28/31 - 236.9ms/batch - loss: 67.61346 - diff: 24.61mlTrain batch 29/31 - 236.6ms/batch - loss: 67.03179 - diff: 24.54mlTrain batch 30/31 - 236.2ms/batch - loss: 65.96970 - diff: 24.33mlTrain batch 31/31 - 123.7ms/batch - loss: 66.37661 - diff: 24.28mlTrain batch 31/31 - 11.7s 123.7ms/batch - loss: 66.37661 - diff: 24.28ml
Test 1.2s: val_loss: 103.42526 - diff: 28.92ml

Epoch 68: current best loss = 67.32351, at epoch 66
Train batch 1/31 - 235.9ms/batch - loss: 41.36356 - diff: 20.23mlTrain batch 2/31 - 237.1ms/batch - loss: 41.58938 - diff: 21.47mlTrain batch 3/31 - 236.2ms/batch - loss: 43.27299 - diff: 21.34mlTrain batch 4/31 - 237.1ms/batch - loss: 87.85173 - diff: 26.57mlTrain batch 5/31 - 236.5ms/batch - loss: 86.62922 - diff: 27.60mlTrain batch 6/31 - 237.5ms/batch - loss: 85.01264 - diff: 27.26mlTrain batch 7/31 - 235.9ms/batch - loss: 100.43280 - diff: 29.42mlTrain batch 8/31 - 237.6ms/batch - loss: 94.61285 - diff: 28.42mlTrain batch 9/31 - 236.0ms/batch - loss: 89.96971 - diff: 27.84mlTrain batch 10/31 - 236.4ms/batch - loss: 89.11812 - diff: 27.85mlTrain batch 11/31 - 236.5ms/batch - loss: 89.48558 - diff: 28.11mlTrain batch 12/31 - 237.2ms/batch - loss: 85.32584 - diff: 27.38mlTrain batch 13/31 - 236.1ms/batch - loss: 81.68897 - diff: 26.63mlTrain batch 14/31 - 236.8ms/batch - loss: 78.41595 - diff: 26.26mlTrain batch 15/31 - 236.3ms/batch - loss: 76.21539 - diff: 26.03mlTrain batch 16/31 - 236.9ms/batch - loss: 77.80485 - diff: 26.47mlTrain batch 17/31 - 236.0ms/batch - loss: 76.36442 - diff: 26.41mlTrain batch 18/31 - 237.4ms/batch - loss: 74.81012 - diff: 26.19mlTrain batch 19/31 - 235.9ms/batch - loss: 74.84304 - diff: 26.25mlTrain batch 20/31 - 237.2ms/batch - loss: 73.05849 - diff: 25.91mlTrain batch 21/31 - 236.1ms/batch - loss: 71.40640 - diff: 25.60mlTrain batch 22/31 - 237.2ms/batch - loss: 81.56952 - diff: 26.14mlTrain batch 23/31 - 236.0ms/batch - loss: 79.58640 - diff: 25.86mlTrain batch 24/31 - 238.0ms/batch - loss: 80.86340 - diff: 26.31mlTrain batch 25/31 - 236.7ms/batch - loss: 81.29701 - diff: 26.47mlTrain batch 26/31 - 237.1ms/batch - loss: 80.70713 - diff: 26.54mlTrain batch 27/31 - 236.2ms/batch - loss: 80.95632 - diff: 26.62mlTrain batch 28/31 - 236.6ms/batch - loss: 81.65618 - diff: 26.82mlTrain batch 29/31 - 236.6ms/batch - loss: 80.74363 - diff: 26.66mlTrain batch 30/31 - 237.0ms/batch - loss: 79.62441 - diff: 26.57mlTrain batch 31/31 - 123.7ms/batch - loss: 80.92831 - diff: 26.56mlTrain batch 31/31 - 12.4s 123.7ms/batch - loss: 80.92831 - diff: 26.56ml
Test 1.2s: val_loss: 85.87542 - diff: 27.85ml

Epoch 69: current best loss = 67.32351, at epoch 66
Train batch 1/31 - 236.2ms/batch - loss: 33.88593 - diff: 18.67mlTrain batch 2/31 - 236.5ms/batch - loss: 57.16165 - diff: 23.31mlTrain batch 3/31 - 236.2ms/batch - loss: 92.84824 - diff: 27.76mlTrain batch 4/31 - 237.2ms/batch - loss: 89.89540 - diff: 28.07mlTrain batch 5/31 - 236.7ms/batch - loss: 79.31989 - diff: 26.82mlTrain batch 6/31 - 237.5ms/batch - loss: 94.72924 - diff: 28.78mlTrain batch 7/31 - 236.2ms/batch - loss: 87.65585 - diff: 27.97mlTrain batch 8/31 - 237.3ms/batch - loss: 85.60381 - diff: 28.28mlTrain batch 9/31 - 236.2ms/batch - loss: 82.73964 - diff: 28.07mlTrain batch 10/31 - 235.9ms/batch - loss: 78.73085 - diff: 27.34mlTrain batch 11/31 - 236.3ms/batch - loss: 91.81591 - diff: 29.34mlTrain batch 12/31 - 237.3ms/batch - loss: 88.16200 - diff: 28.81mlTrain batch 13/31 - 236.1ms/batch - loss: 87.02515 - diff: 28.87mlTrain batch 14/31 - 237.5ms/batch - loss: 87.15965 - diff: 28.98mlTrain batch 15/31 - 236.8ms/batch - loss: 85.02915 - diff: 28.51mlTrain batch 16/31 - 237.3ms/batch - loss: 84.12213 - diff: 28.28mlTrain batch 17/31 - 236.2ms/batch - loss: 83.38304 - diff: 28.13mlTrain batch 18/31 - 236.9ms/batch - loss: 85.18874 - diff: 28.46mlTrain batch 19/31 - 236.1ms/batch - loss: 85.58522 - diff: 28.57mlTrain batch 20/31 - 237.8ms/batch - loss: 84.00327 - diff: 28.33mlTrain batch 21/31 - 236.3ms/batch - loss: 81.93965 - diff: 27.93mlTrain batch 22/31 - 237.5ms/batch - loss: 82.85423 - diff: 28.18mlTrain batch 23/31 - 236.1ms/batch - loss: 81.44425 - diff: 28.01mlTrain batch 24/31 - 237.3ms/batch - loss: 80.95877 - diff: 28.04mlTrain batch 25/31 - 236.2ms/batch - loss: 80.66248 - diff: 27.88mlTrain batch 26/31 - 237.1ms/batch - loss: 81.44355 - diff: 28.07mlTrain batch 27/31 - 236.3ms/batch - loss: 82.34717 - diff: 28.21mlTrain batch 28/31 - 237.3ms/batch - loss: 82.71453 - diff: 28.29mlTrain batch 29/31 - 236.4ms/batch - loss: 83.87631 - diff: 28.42mlTrain batch 30/31 - 237.5ms/batch - loss: 84.30306 - diff: 28.56mlTrain batch 31/31 - 123.8ms/batch - loss: 85.00250 - diff: 28.54mlTrain batch 31/31 - 11.4s 123.8ms/batch - loss: 85.00250 - diff: 28.54ml
Test 1.1s: val_loss: 74.78824 - diff: 25.33ml

Epoch 70: current best loss = 67.32351, at epoch 66
Train batch 1/31 - 236.5ms/batch - loss: 119.34290 - diff: 29.96mlTrain batch 2/31 - 237.0ms/batch - loss: 88.77762 - diff: 28.46mlTrain batch 3/31 - 236.2ms/batch - loss: 78.86657 - diff: 27.54mlTrain batch 4/31 - 237.1ms/batch - loss: 104.35999 - diff: 28.96mlTrain batch 5/31 - 236.4ms/batch - loss: 96.12040 - diff: 28.32mlTrain batch 6/31 - 237.0ms/batch - loss: 86.22937 - diff: 27.13mlTrain batch 7/31 - 236.1ms/batch - loss: 82.98849 - diff: 26.70mlTrain batch 8/31 - 237.1ms/batch - loss: 83.47497 - diff: 27.30mlTrain batch 9/31 - 236.4ms/batch - loss: 92.68770 - diff: 28.84mlTrain batch 10/31 - 236.6ms/batch - loss: 89.17294 - diff: 28.35mlTrain batch 11/31 - 236.4ms/batch - loss: 94.55553 - diff: 29.42mlTrain batch 12/31 - 237.1ms/batch - loss: 102.79408 - diff: 30.12mlTrain batch 13/31 - 236.2ms/batch - loss: 98.29593 - diff: 29.47mlTrain batch 14/31 - 237.5ms/batch - loss: 97.24636 - diff: 29.17mlTrain batch 15/31 - 236.2ms/batch - loss: 92.74634 - diff: 28.38mlTrain batch 16/31 - 236.7ms/batch - loss: 92.58571 - diff: 28.46mlTrain batch 17/31 - 236.3ms/batch - loss: 93.93873 - diff: 28.57mlTrain batch 18/31 - 237.5ms/batch - loss: 90.70008 - diff: 27.96mlTrain batch 19/31 - 236.2ms/batch - loss: 87.74576 - diff: 27.50mlTrain batch 20/31 - 237.3ms/batch - loss: 87.59437 - diff: 27.64mlTrain batch 21/31 - 236.4ms/batch - loss: 84.89476 - diff: 27.14mlTrain batch 22/31 - 237.1ms/batch - loss: 84.66740 - diff: 27.24mlTrain batch 23/31 - 236.8ms/batch - loss: 83.91348 - diff: 27.14mlTrain batch 24/31 - 237.5ms/batch - loss: 83.91071 - diff: 27.19mlTrain batch 25/31 - 236.3ms/batch - loss: 83.48997 - diff: 27.18mlTrain batch 26/31 - 236.8ms/batch - loss: 82.94689 - diff: 27.17mlTrain batch 27/31 - 236.6ms/batch - loss: 81.72759 - diff: 26.85mlTrain batch 28/31 - 236.9ms/batch - loss: 81.67323 - diff: 27.02mlTrain batch 29/31 - 236.7ms/batch - loss: 80.02290 - diff: 26.74mlTrain batch 30/31 - 237.3ms/batch - loss: 80.08398 - diff: 26.93mlTrain batch 31/31 - 123.7ms/batch - loss: 81.36115 - diff: 26.94mlTrain batch 31/31 - 11.1s 123.7ms/batch - loss: 81.36115 - diff: 26.94ml
Test 1.1s: val_loss: 72.92366 - diff: 25.20ml

Epoch 71: current best loss = 67.32351, at epoch 66
Train batch 1/31 - 236.9ms/batch - loss: 94.25557 - diff: 29.85mlTrain batch 2/31 - 237.3ms/batch - loss: 88.35720 - diff: 28.62mlTrain batch 3/31 - 236.1ms/batch - loss: 71.60103 - diff: 26.04mlTrain batch 4/31 - 237.5ms/batch - loss: 61.22926 - diff: 24.12mlTrain batch 5/31 - 236.3ms/batch - loss: 63.76703 - diff: 25.38mlTrain batch 6/31 - 237.4ms/batch - loss: 63.24852 - diff: 25.63mlTrain batch 7/31 - 236.8ms/batch - loss: 63.17078 - diff: 25.18mlTrain batch 8/31 - 236.8ms/batch - loss: 61.96992 - diff: 24.77mlTrain batch 9/31 - 236.3ms/batch - loss: 63.86379 - diff: 24.92mlTrain batch 10/31 - 237.5ms/batch - loss: 64.02520 - diff: 25.11mlTrain batch 11/31 - 236.5ms/batch - loss: 64.56086 - diff: 25.41mlTrain batch 12/31 - 237.8ms/batch - loss: 65.44635 - diff: 25.58mlTrain batch 13/31 - 236.5ms/batch - loss: 70.30178 - diff: 26.24mlTrain batch 14/31 - 237.1ms/batch - loss: 90.23396 - diff: 27.76mlTrain batch 15/31 - 236.3ms/batch - loss: 88.22743 - diff: 27.58mlTrain batch 16/31 - 236.9ms/batch - loss: 87.07762 - diff: 27.54mlTrain batch 17/31 - 236.5ms/batch - loss: 85.03759 - diff: 27.37mlTrain batch 18/31 - 236.9ms/batch - loss: 81.61717 - diff: 26.76mlTrain batch 19/31 - 236.2ms/batch - loss: 80.03286 - diff: 26.66mlTrain batch 20/31 - 236.5ms/batch - loss: 82.08824 - diff: 27.18mlTrain batch 21/31 - 236.3ms/batch - loss: 81.55447 - diff: 27.23mlTrain batch 22/31 - 237.1ms/batch - loss: 80.71497 - diff: 27.09mlTrain batch 23/31 - 236.4ms/batch - loss: 84.69528 - diff: 27.49mlTrain batch 24/31 - 237.4ms/batch - loss: 82.46525 - diff: 26.99mlTrain batch 25/31 - 236.2ms/batch - loss: 83.65133 - diff: 27.30mlTrain batch 26/31 - 237.4ms/batch - loss: 84.97666 - diff: 27.64mlTrain batch 27/31 - 236.2ms/batch - loss: 84.31664 - diff: 27.58mlTrain batch 28/31 - 239.3ms/batch - loss: 82.84463 - diff: 27.33mlTrain batch 29/31 - 236.6ms/batch - loss: 80.19388 - diff: 26.66mlTrain batch 30/31 - 238.0ms/batch - loss: 78.96329 - diff: 26.52mlTrain batch 31/31 - 123.8ms/batch - loss: 80.06346 - diff: 26.55mlTrain batch 31/31 - 11.4s 123.8ms/batch - loss: 80.06346 - diff: 26.55ml
Test 1.2s: val_loss: 114.80007 - diff: 32.42ml

Epoch 72: current best loss = 67.32351, at epoch 66
Train batch 1/31 - 236.5ms/batch - loss: 83.44904 - diff: 27.73mlTrain batch 2/31 - 237.0ms/batch - loss: 68.39003 - diff: 25.71mlTrain batch 3/31 - 236.1ms/batch - loss: 55.38995 - diff: 22.93mlTrain batch 4/31 - 237.1ms/batch - loss: 56.45379 - diff: 23.47mlTrain batch 5/31 - 236.5ms/batch - loss: 57.86899 - diff: 23.94mlTrain batch 6/31 - 237.4ms/batch - loss: 81.06732 - diff: 27.93mlTrain batch 7/31 - 236.9ms/batch - loss: 78.50563 - diff: 27.47mlTrain batch 8/31 - 237.0ms/batch - loss: 90.40697 - diff: 28.64mlTrain batch 9/31 - 236.1ms/batch - loss: 88.95898 - diff: 28.30mlTrain batch 10/31 - 237.2ms/batch - loss: 88.80690 - diff: 28.59mlTrain batch 11/31 - 237.0ms/batch - loss: 88.42458 - diff: 28.50mlTrain batch 12/31 - 236.4ms/batch - loss: 84.36252 - diff: 27.83mlTrain batch 13/31 - 236.1ms/batch - loss: 79.92198 - diff: 26.98mlTrain batch 14/31 - 236.9ms/batch - loss: 80.20590 - diff: 27.07mlTrain batch 15/31 - 236.3ms/batch - loss: 78.76014 - diff: 26.85mlTrain batch 16/31 - 236.5ms/batch - loss: 78.28835 - diff: 26.81mlTrain batch 17/31 - 237.6ms/batch - loss: 80.26504 - diff: 27.37mlTrain batch 18/31 - 236.5ms/batch - loss: 78.98043 - diff: 27.31mlTrain batch 19/31 - 237.5ms/batch - loss: 80.24202 - diff: 27.51mlTrain batch 20/31 - 236.4ms/batch - loss: 78.69510 - diff: 27.16mlTrain batch 21/31 - 237.3ms/batch - loss: 80.61634 - diff: 27.33mlTrain batch 22/31 - 236.2ms/batch - loss: 82.19192 - diff: 27.58mlTrain batch 23/31 - 237.2ms/batch - loss: 81.99737 - diff: 27.46mlTrain batch 24/31 - 236.3ms/batch - loss: 80.57577 - diff: 27.13mlTrain batch 25/31 - 237.2ms/batch - loss: 78.73279 - diff: 26.82mlTrain batch 26/31 - 236.4ms/batch - loss: 78.74531 - diff: 26.93mlTrain batch 27/31 - 237.3ms/batch - loss: 78.84509 - diff: 26.97mlTrain batch 28/31 - 236.2ms/batch - loss: 78.74682 - diff: 27.05mlTrain batch 29/31 - 237.3ms/batch - loss: 77.16900 - diff: 26.82mlTrain batch 30/31 - 236.2ms/batch - loss: 78.60255 - diff: 27.13mlTrain batch 31/31 - 123.5ms/batch - loss: 80.17861 - diff: 27.20mlTrain batch 31/31 - 11.6s 123.5ms/batch - loss: 80.17861 - diff: 27.20ml
Test 1.1s: val_loss: 73.80007 - diff: 24.93ml

Epoch 73: current best loss = 67.32351, at epoch 66
Train batch 1/31 - 236.4ms/batch - loss: 67.47944 - diff: 23.72mlTrain batch 2/31 - 237.6ms/batch - loss: 45.75074 - diff: 19.98mlTrain batch 3/31 - 236.3ms/batch - loss: 74.07486 - diff: 25.49mlTrain batch 4/31 - 236.9ms/batch - loss: 61.51989 - diff: 22.72mlTrain batch 5/31 - 236.2ms/batch - loss: 63.09593 - diff: 23.70mlTrain batch 6/31 - 237.2ms/batch - loss: 83.19506 - diff: 25.21mlTrain batch 7/31 - 236.2ms/batch - loss: 76.84743 - diff: 24.60mlTrain batch 8/31 - 237.6ms/batch - loss: 72.36610 - diff: 24.10mlTrain batch 9/31 - 236.0ms/batch - loss: 69.78293 - diff: 23.77mlTrain batch 10/31 - 237.8ms/batch - loss: 67.68540 - diff: 23.75mlTrain batch 11/31 - 236.3ms/batch - loss: 69.25713 - diff: 24.15mlTrain batch 12/31 - 237.6ms/batch - loss: 68.89158 - diff: 24.41mlTrain batch 13/31 - 236.2ms/batch - loss: 67.14112 - diff: 24.13mlTrain batch 14/31 - 237.0ms/batch - loss: 65.43926 - diff: 24.01mlTrain batch 15/31 - 236.0ms/batch - loss: 66.37506 - diff: 24.32mlTrain batch 16/31 - 237.4ms/batch - loss: 68.43510 - diff: 24.86mlTrain batch 17/31 - 236.2ms/batch - loss: 72.88171 - diff: 25.60mlTrain batch 18/31 - 236.5ms/batch - loss: 71.70240 - diff: 25.48mlTrain batch 19/31 - 236.9ms/batch - loss: 70.35249 - diff: 25.28mlTrain batch 20/31 - 236.2ms/batch - loss: 69.26837 - diff: 25.14mlTrain batch 21/31 - 237.0ms/batch - loss: 68.42305 - diff: 24.96mlTrain batch 22/31 - 236.5ms/batch - loss: 67.80230 - diff: 24.85mlTrain batch 23/31 - 236.5ms/batch - loss: 66.69452 - diff: 24.68mlTrain batch 24/31 - 236.3ms/batch - loss: 66.19507 - diff: 24.58mlTrain batch 25/31 - 236.4ms/batch - loss: 65.61180 - diff: 24.54mlTrain batch 26/31 - 236.2ms/batch - loss: 65.88033 - diff: 24.66mlTrain batch 27/31 - 237.3ms/batch - loss: 65.62484 - diff: 24.49mlTrain batch 28/31 - 236.4ms/batch - loss: 66.11123 - diff: 24.55mlTrain batch 29/31 - 237.3ms/batch - loss: 67.87133 - diff: 24.89mlTrain batch 30/31 - 236.3ms/batch - loss: 67.08949 - diff: 24.80mlTrain batch 31/31 - 122.8ms/batch - loss: 67.97737 - diff: 24.80mlTrain batch 31/31 - 11.3s 122.8ms/batch - loss: 67.97737 - diff: 24.80ml
Test 1.1s: val_loss: 63.96793 - diff: 23.83ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_WideResNet50_0_Adam-0.001_MSE_DA3_best

Epoch 74: current best loss = 63.96793, at epoch 73
Train batch 1/31 - 235.7ms/batch - loss: 49.59124 - diff: 21.98mlTrain batch 2/31 - 236.9ms/batch - loss: 63.17458 - diff: 24.17mlTrain batch 3/31 - 236.2ms/batch - loss: 58.56303 - diff: 24.06mlTrain batch 4/31 - 237.2ms/batch - loss: 48.09277 - diff: 21.53mlTrain batch 5/31 - 236.1ms/batch - loss: 45.83445 - diff: 21.08mlTrain batch 6/31 - 237.4ms/batch - loss: 46.58474 - diff: 21.04mlTrain batch 7/31 - 236.1ms/batch - loss: 48.50649 - diff: 21.25mlTrain batch 8/31 - 236.3ms/batch - loss: 45.48354 - diff: 20.47mlTrain batch 9/31 - 236.1ms/batch - loss: 50.46274 - diff: 21.29mlTrain batch 10/31 - 236.6ms/batch - loss: 54.93009 - diff: 22.33mlTrain batch 11/31 - 236.0ms/batch - loss: 54.86921 - diff: 22.58mlTrain batch 12/31 - 237.2ms/batch - loss: 53.42646 - diff: 22.42mlTrain batch 13/31 - 236.2ms/batch - loss: 53.93173 - diff: 22.63mlTrain batch 14/31 - 240.5ms/batch - loss: 53.91072 - diff: 22.51mlTrain batch 15/31 - 236.2ms/batch - loss: 62.11047 - diff: 23.58mlTrain batch 16/31 - 237.1ms/batch - loss: 63.43191 - diff: 23.81mlTrain batch 17/31 - 239.9ms/batch - loss: 62.88764 - diff: 23.76mlTrain batch 18/31 - 236.4ms/batch - loss: 63.43486 - diff: 24.01mlTrain batch 19/31 - 236.0ms/batch - loss: 64.82454 - diff: 24.04mlTrain batch 20/31 - 236.9ms/batch - loss: 62.81436 - diff: 23.71mlTrain batch 21/31 - 236.5ms/batch - loss: 61.13052 - diff: 23.46mlTrain batch 22/31 - 237.3ms/batch - loss: 62.32088 - diff: 23.73mlTrain batch 23/31 - 236.2ms/batch - loss: 61.44283 - diff: 23.60mlTrain batch 24/31 - 237.0ms/batch - loss: 60.98677 - diff: 23.57mlTrain batch 25/31 - 236.0ms/batch - loss: 59.93511 - diff: 23.38mlTrain batch 26/31 - 237.2ms/batch - loss: 61.23314 - diff: 23.60mlTrain batch 27/31 - 236.3ms/batch - loss: 62.61908 - diff: 24.06mlTrain batch 28/31 - 236.5ms/batch - loss: 62.39653 - diff: 24.07mlTrain batch 29/31 - 236.1ms/batch - loss: 62.75044 - diff: 24.18mlTrain batch 30/31 - 237.5ms/batch - loss: 63.97057 - diff: 24.48mlTrain batch 31/31 - 123.9ms/batch - loss: 64.91433 - diff: 24.50mlTrain batch 31/31 - 11.9s 123.9ms/batch - loss: 64.91433 - diff: 24.50ml
Test 1.2s: val_loss: 74.58595 - diff: 23.12ml

Epoch 75: current best loss = 63.96793, at epoch 73
Train batch 1/31 - 236.1ms/batch - loss: 45.58074 - diff: 23.22mlTrain batch 2/31 - 237.2ms/batch - loss: 41.18690 - diff: 21.64mlTrain batch 3/31 - 236.0ms/batch - loss: 37.48065 - diff: 20.14mlTrain batch 4/31 - 238.2ms/batch - loss: 44.25348 - diff: 20.93mlTrain batch 5/31 - 236.2ms/batch - loss: 41.23718 - diff: 20.19mlTrain batch 6/31 - 237.3ms/batch - loss: 39.41282 - diff: 19.99mlTrain batch 7/31 - 236.2ms/batch - loss: 47.30705 - diff: 21.65mlTrain batch 8/31 - 237.5ms/batch - loss: 44.81094 - diff: 21.03mlTrain batch 9/31 - 236.1ms/batch - loss: 43.72283 - diff: 20.81mlTrain batch 10/31 - 236.9ms/batch - loss: 57.03852 - diff: 22.63mlTrain batch 11/31 - 236.6ms/batch - loss: 57.75030 - diff: 22.95mlTrain batch 12/31 - 237.3ms/batch - loss: 56.01051 - diff: 22.73mlTrain batch 13/31 - 236.3ms/batch - loss: 56.26904 - diff: 23.03mlTrain batch 14/31 - 237.1ms/batch - loss: 58.68752 - diff: 23.16mlTrain batch 15/31 - 236.2ms/batch - loss: 58.87696 - diff: 23.28mlTrain batch 16/31 - 237.0ms/batch - loss: 57.86748 - diff: 23.16mlTrain batch 17/31 - 236.1ms/batch - loss: 56.56719 - diff: 23.03mlTrain batch 18/31 - 236.7ms/batch - loss: 60.19430 - diff: 23.50mlTrain batch 19/31 - 236.4ms/batch - loss: 58.37934 - diff: 23.14mlTrain batch 20/31 - 237.1ms/batch - loss: 57.84471 - diff: 22.93mlTrain batch 21/31 - 236.1ms/batch - loss: 58.04328 - diff: 23.00mlTrain batch 22/31 - 237.3ms/batch - loss: 56.82560 - diff: 22.78mlTrain batch 23/31 - 236.0ms/batch - loss: 58.71410 - diff: 23.28mlTrain batch 24/31 - 237.3ms/batch - loss: 58.42690 - diff: 23.11mlTrain batch 25/31 - 236.2ms/batch - loss: 58.91075 - diff: 23.15mlTrain batch 26/31 - 237.1ms/batch - loss: 62.63979 - diff: 23.87mlTrain batch 27/31 - 236.3ms/batch - loss: 63.43359 - diff: 24.04mlTrain batch 28/31 - 237.4ms/batch - loss: 63.45807 - diff: 24.14mlTrain batch 29/31 - 236.1ms/batch - loss: 63.80116 - diff: 24.28mlTrain batch 30/31 - 236.8ms/batch - loss: 64.20135 - diff: 24.39mlTrain batch 31/31 - 123.6ms/batch - loss: 63.63461 - diff: 24.21mlTrain batch 31/31 - 11.0s 123.6ms/batch - loss: 63.63461 - diff: 24.21ml
Test 1.2s: val_loss: 66.53164 - diff: 24.00ml

Epoch 76: current best loss = 63.96793, at epoch 73
Train batch 1/31 - 236.5ms/batch - loss: 73.28316 - diff: 28.02mlTrain batch 2/31 - 237.1ms/batch - loss: 61.21166 - diff: 25.92mlTrain batch 3/31 - 236.5ms/batch - loss: 61.60301 - diff: 25.66mlTrain batch 4/31 - 239.0ms/batch - loss: 59.64987 - diff: 24.51mlTrain batch 5/31 - 239.1ms/batch - loss: 55.20862 - diff: 23.79mlTrain batch 6/31 - 237.0ms/batch - loss: 56.31735 - diff: 24.09mlTrain batch 7/31 - 236.2ms/batch - loss: 53.53731 - diff: 23.44mlTrain batch 8/31 - 237.4ms/batch - loss: 61.83119 - diff: 24.83mlTrain batch 9/31 - 236.1ms/batch - loss: 59.41177 - diff: 24.56mlTrain batch 10/31 - 237.1ms/batch - loss: 57.37909 - diff: 24.10mlTrain batch 11/31 - 235.9ms/batch - loss: 56.52648 - diff: 23.89mlTrain batch 12/31 - 237.6ms/batch - loss: 56.89048 - diff: 23.93mlTrain batch 13/31 - 236.5ms/batch - loss: 55.40695 - diff: 23.50mlTrain batch 14/31 - 237.4ms/batch - loss: 60.43364 - diff: 24.36mlTrain batch 15/31 - 235.9ms/batch - loss: 63.04671 - diff: 24.70mlTrain batch 16/31 - 237.4ms/batch - loss: 61.97884 - diff: 24.57mlTrain batch 17/31 - 236.2ms/batch - loss: 77.70379 - diff: 26.83mlTrain batch 18/31 - 238.4ms/batch - loss: 75.95755 - diff: 26.47mlTrain batch 19/31 - 236.1ms/batch - loss: 73.66878 - diff: 25.98mlTrain batch 20/31 - 237.1ms/batch - loss: 74.50845 - diff: 26.35mlTrain batch 21/31 - 236.5ms/batch - loss: 74.29927 - diff: 26.42mlTrain batch 22/31 - 237.3ms/batch - loss: 72.50500 - diff: 26.12mlTrain batch 23/31 - 235.8ms/batch - loss: 71.45126 - diff: 25.82mlTrain batch 24/31 - 237.4ms/batch - loss: 72.14840 - diff: 26.02mlTrain batch 25/31 - 236.7ms/batch - loss: 73.97723 - diff: 26.22mlTrain batch 26/31 - 237.4ms/batch - loss: 73.17986 - diff: 26.11mlTrain batch 27/31 - 236.4ms/batch - loss: 72.43336 - diff: 25.92mlTrain batch 28/31 - 237.5ms/batch - loss: 72.59958 - diff: 25.99mlTrain batch 29/31 - 236.7ms/batch - loss: 71.62796 - diff: 25.85mlTrain batch 30/31 - 237.0ms/batch - loss: 70.23762 - diff: 25.57mlTrain batch 31/31 - 123.9ms/batch - loss: 71.30881 - diff: 25.62mlTrain batch 31/31 - 10.8s 123.9ms/batch - loss: 71.30881 - diff: 25.62ml
Test 1.1s: val_loss: 69.73040 - diff: 23.72ml

Epoch 77: current best loss = 63.96793, at epoch 73
Train batch 1/31 - 236.4ms/batch - loss: 72.93252 - diff: 25.20mlTrain batch 2/31 - 237.2ms/batch - loss: 73.52929 - diff: 26.12mlTrain batch 3/31 - 236.1ms/batch - loss: 68.86455 - diff: 25.70mlTrain batch 4/31 - 238.0ms/batch - loss: 68.55250 - diff: 26.27mlTrain batch 5/31 - 237.1ms/batch - loss: 65.52839 - diff: 25.87mlTrain batch 6/31 - 237.2ms/batch - loss: 60.67166 - diff: 24.76mlTrain batch 7/31 - 235.9ms/batch - loss: 60.99632 - diff: 24.85mlTrain batch 8/31 - 236.8ms/batch - loss: 60.42530 - diff: 24.71mlTrain batch 9/31 - 236.4ms/batch - loss: 63.23706 - diff: 25.05mlTrain batch 10/31 - 237.2ms/batch - loss: 70.18317 - diff: 26.57mlTrain batch 11/31 - 236.1ms/batch - loss: 69.82699 - diff: 26.63mlTrain batch 12/31 - 237.1ms/batch - loss: 68.48922 - diff: 26.55mlTrain batch 13/31 - 236.3ms/batch - loss: 68.93368 - diff: 26.46mlTrain batch 14/31 - 237.0ms/batch - loss: 66.33889 - diff: 25.95mlTrain batch 15/31 - 236.0ms/batch - loss: 65.77744 - diff: 25.49mlTrain batch 16/31 - 237.4ms/batch - loss: 64.98064 - diff: 25.40mlTrain batch 17/31 - 236.3ms/batch - loss: 68.26136 - diff: 25.89mlTrain batch 18/31 - 237.4ms/batch - loss: 66.75634 - diff: 25.58mlTrain batch 19/31 - 237.5ms/batch - loss: 69.45407 - diff: 25.66mlTrain batch 20/31 - 237.5ms/batch - loss: 68.49376 - diff: 25.34mlTrain batch 21/31 - 236.7ms/batch - loss: 67.66433 - diff: 25.27mlTrain batch 22/31 - 238.0ms/batch - loss: 68.07481 - diff: 25.46mlTrain batch 23/31 - 235.7ms/batch - loss: 67.36048 - diff: 25.38mlTrain batch 24/31 - 237.2ms/batch - loss: 65.90368 - diff: 25.08mlTrain batch 25/31 - 238.8ms/batch - loss: 65.09431 - diff: 24.98mlTrain batch 26/31 - 237.7ms/batch - loss: 63.82192 - diff: 24.72mlTrain batch 27/31 - 236.3ms/batch - loss: 63.39764 - diff: 24.68mlTrain batch 28/31 - 237.2ms/batch - loss: 62.27547 - diff: 24.44mlTrain batch 29/31 - 236.1ms/batch - loss: 61.38494 - diff: 24.21mlTrain batch 30/31 - 236.5ms/batch - loss: 60.98898 - diff: 24.19mlTrain batch 31/31 - 123.3ms/batch - loss: 61.93197 - diff: 24.19mlTrain batch 31/31 - 11.8s 123.3ms/batch - loss: 61.93197 - diff: 24.19ml
Test 1.2s: val_loss: 64.17235 - diff: 24.14ml

Epoch 78: current best loss = 63.96793, at epoch 73
Train batch 1/31 - 236.2ms/batch - loss: 58.40685 - diff: 24.69mlTrain batch 2/31 - 237.6ms/batch - loss: 63.19843 - diff: 24.37mlTrain batch 3/31 - 236.1ms/batch - loss: 68.30325 - diff: 25.84mlTrain batch 4/31 - 237.4ms/batch - loss: 73.02922 - diff: 27.34mlTrain batch 5/31 - 236.4ms/batch - loss: 62.26391 - diff: 24.66mlTrain batch 6/31 - 236.6ms/batch - loss: 62.78135 - diff: 25.36mlTrain batch 7/31 - 236.4ms/batch - loss: 62.25315 - diff: 25.00mlTrain batch 8/31 - 237.5ms/batch - loss: 60.21264 - diff: 24.01mlTrain batch 9/31 - 236.4ms/batch - loss: 64.44525 - diff: 24.67mlTrain batch 10/31 - 237.1ms/batch - loss: 64.10611 - diff: 25.02mlTrain batch 11/31 - 236.2ms/batch - loss: 65.53246 - diff: 25.62mlTrain batch 12/31 - 237.1ms/batch - loss: 64.95940 - diff: 25.68mlTrain batch 13/31 - 236.2ms/batch - loss: 72.53125 - diff: 26.39mlTrain batch 14/31 - 237.4ms/batch - loss: 69.67969 - diff: 25.86mlTrain batch 15/31 - 236.9ms/batch - loss: 70.13068 - diff: 25.82mlTrain batch 16/31 - 237.8ms/batch - loss: 68.32798 - diff: 25.44mlTrain batch 17/31 - 236.3ms/batch - loss: 67.94974 - diff: 25.42mlTrain batch 18/31 - 237.0ms/batch - loss: 71.36458 - diff: 26.01mlTrain batch 19/31 - 236.2ms/batch - loss: 72.97821 - diff: 25.82mlTrain batch 20/31 - 237.4ms/batch - loss: 72.13403 - diff: 25.85mlTrain batch 21/31 - 236.1ms/batch - loss: 75.54630 - diff: 26.44mlTrain batch 22/31 - 237.2ms/batch - loss: 75.75006 - diff: 26.52mlTrain batch 23/31 - 236.3ms/batch - loss: 75.60819 - diff: 26.43mlTrain batch 24/31 - 237.0ms/batch - loss: 73.92873 - diff: 26.06mlTrain batch 25/31 - 236.0ms/batch - loss: 74.21356 - diff: 26.20mlTrain batch 26/31 - 236.9ms/batch - loss: 75.13235 - diff: 26.46mlTrain batch 27/31 - 237.7ms/batch - loss: 75.35653 - diff: 26.52mlTrain batch 28/31 - 237.5ms/batch - loss: 73.56346 - diff: 26.16mlTrain batch 29/31 - 236.0ms/batch - loss: 75.51747 - diff: 26.54mlTrain batch 30/31 - 237.1ms/batch - loss: 75.03763 - diff: 26.41mlTrain batch 31/31 - 123.5ms/batch - loss: 75.17908 - diff: 26.35mlTrain batch 31/31 - 11.6s 123.5ms/batch - loss: 75.17908 - diff: 26.35ml
Test 1.2s: val_loss: 87.11294 - diff: 26.98ml

Epoch 79: current best loss = 63.96793, at epoch 73
Train batch 1/31 - 236.5ms/batch - loss: 50.86634 - diff: 21.77mlTrain batch 2/31 - 236.8ms/batch - loss: 48.47039 - diff: 22.76mlTrain batch 3/31 - 236.5ms/batch - loss: 39.22673 - diff: 20.03mlTrain batch 4/31 - 236.9ms/batch - loss: 40.01438 - diff: 20.32mlTrain batch 5/31 - 236.5ms/batch - loss: 53.48969 - diff: 23.49mlTrain batch 6/31 - 236.6ms/batch - loss: 52.98095 - diff: 23.32mlTrain batch 7/31 - 236.6ms/batch - loss: 57.84384 - diff: 23.91mlTrain batch 8/31 - 236.7ms/batch - loss: 54.03758 - diff: 22.80mlTrain batch 9/31 - 237.6ms/batch - loss: 50.28519 - diff: 21.96mlTrain batch 10/31 - 236.2ms/batch - loss: 54.50751 - diff: 22.67mlTrain batch 11/31 - 235.9ms/batch - loss: 57.34377 - diff: 23.25mlTrain batch 12/31 - 236.6ms/batch - loss: 67.77901 - diff: 24.41mlTrain batch 13/31 - 237.6ms/batch - loss: 66.07041 - diff: 24.13mlTrain batch 14/31 - 236.3ms/batch - loss: 65.99960 - diff: 24.16mlTrain batch 15/31 - 234.2ms/batch - loss: 70.42822 - diff: 25.01mlTrain batch 16/31 - 236.4ms/batch - loss: 68.05733 - diff: 24.74mlTrain batch 17/31 - 237.5ms/batch - loss: 66.10059 - diff: 24.40mlTrain batch 18/31 - 236.3ms/batch - loss: 64.95861 - diff: 24.22mlTrain batch 19/31 - 237.0ms/batch - loss: 64.81049 - diff: 24.17mlTrain batch 20/31 - 236.4ms/batch - loss: 66.23537 - diff: 24.61mlTrain batch 21/31 - 237.3ms/batch - loss: 67.80591 - diff: 24.89mlTrain batch 22/31 - 236.2ms/batch - loss: 68.47718 - diff: 25.14mlTrain batch 23/31 - 237.0ms/batch - loss: 68.41542 - diff: 25.25mlTrain batch 24/31 - 236.2ms/batch - loss: 67.17536 - diff: 25.10mlTrain batch 25/31 - 236.5ms/batch - loss: 68.83578 - diff: 25.34mlTrain batch 26/31 - 236.4ms/batch - loss: 68.13979 - diff: 25.20mlTrain batch 27/31 - 237.0ms/batch - loss: 68.04863 - diff: 25.21mlTrain batch 28/31 - 236.9ms/batch - loss: 67.48612 - diff: 25.17mlTrain batch 29/31 - 237.5ms/batch - loss: 66.59172 - diff: 25.07mlTrain batch 30/31 - 237.1ms/batch - loss: 66.59954 - diff: 25.11mlTrain batch 31/31 - 123.6ms/batch - loss: 67.13692 - diff: 25.03mlTrain batch 31/31 - 11.9s 123.6ms/batch - loss: 67.13692 - diff: 25.03ml
Test 1.2s: val_loss: 66.05509 - diff: 23.98ml

Epoch 80: current best loss = 63.96793, at epoch 73
Train batch 1/31 - 236.0ms/batch - loss: 35.66564 - diff: 17.90mlTrain batch 2/31 - 236.8ms/batch - loss: 70.08612 - diff: 23.64mlTrain batch 3/31 - 236.2ms/batch - loss: 64.11935 - diff: 21.66mlTrain batch 4/31 - 237.0ms/batch - loss: 57.62757 - diff: 21.43mlTrain batch 5/31 - 236.1ms/batch - loss: 53.52759 - diff: 20.96mlTrain batch 6/31 - 236.2ms/batch - loss: 64.34191 - diff: 23.41mlTrain batch 7/31 - 236.1ms/batch - loss: 66.81547 - diff: 24.17mlTrain batch 8/31 - 237.4ms/batch - loss: 93.13600 - diff: 26.56mlTrain batch 9/31 - 236.7ms/batch - loss: 88.29951 - diff: 26.31mlTrain batch 10/31 - 237.7ms/batch - loss: 84.70840 - diff: 25.56mlTrain batch 11/31 - 235.9ms/batch - loss: 78.63568 - diff: 24.57mlTrain batch 12/31 - 237.5ms/batch - loss: 75.62934 - diff: 24.49mlTrain batch 13/31 - 236.7ms/batch - loss: 72.86261 - diff: 24.20mlTrain batch 14/31 - 237.2ms/batch - loss: 71.49801 - diff: 24.22mlTrain batch 15/31 - 236.2ms/batch - loss: 69.35222 - diff: 24.04mlTrain batch 16/31 - 237.4ms/batch - loss: 68.22858 - diff: 23.80mlTrain batch 17/31 - 236.1ms/batch - loss: 66.10352 - diff: 23.37mlTrain batch 18/31 - 237.2ms/batch - loss: 64.38060 - diff: 23.18mlTrain batch 19/31 - 238.1ms/batch - loss: 63.93236 - diff: 23.24mlTrain batch 20/31 - 237.7ms/batch - loss: 62.62874 - diff: 23.03mlTrain batch 21/31 - 240.1ms/batch - loss: 61.69057 - diff: 22.99mlTrain batch 22/31 - 236.7ms/batch - loss: 62.01772 - diff: 23.08mlTrain batch 23/31 - 236.3ms/batch - loss: 61.74638 - diff: 23.15mlTrain batch 24/31 - 237.1ms/batch - loss: 60.45802 - diff: 22.93mlTrain batch 25/31 - 236.3ms/batch - loss: 60.55644 - diff: 22.95mlTrain batch 26/31 - 236.7ms/batch - loss: 59.78961 - diff: 22.97mlTrain batch 27/31 - 236.1ms/batch - loss: 61.13243 - diff: 23.23mlTrain batch 28/31 - 236.2ms/batch - loss: 60.22617 - diff: 23.04mlTrain batch 29/31 - 236.2ms/batch - loss: 59.84949 - diff: 23.04mlTrain batch 30/31 - 236.8ms/batch - loss: 60.82497 - diff: 23.19mlTrain batch 31/31 - 123.4ms/batch - loss: 63.78874 - diff: 23.38mlTrain batch 31/31 - 11.8s 123.4ms/batch - loss: 63.78874 - diff: 23.38ml
Test 1.2s: val_loss: 71.81737 - diff: 23.11ml

Epoch 81: current best loss = 63.96793, at epoch 73
Train batch 1/31 - 236.1ms/batch - loss: 58.43111 - diff: 26.65mlTrain batch 2/31 - 237.1ms/batch - loss: 51.13606 - diff: 23.71mlTrain batch 3/31 - 236.3ms/batch - loss: 48.29390 - diff: 22.68mlTrain batch 4/31 - 237.0ms/batch - loss: 46.39108 - diff: 22.21mlTrain batch 5/31 - 236.2ms/batch - loss: 68.38175 - diff: 25.41mlTrain batch 6/31 - 239.1ms/batch - loss: 69.02448 - diff: 25.74mlTrain batch 7/31 - 236.4ms/batch - loss: 66.51816 - diff: 25.35mlTrain batch 8/31 - 237.5ms/batch - loss: 69.53291 - diff: 26.02mlTrain batch 9/31 - 236.1ms/batch - loss: 65.09353 - diff: 25.17mlTrain batch 10/31 - 237.1ms/batch - loss: 66.36467 - diff: 25.73mlTrain batch 11/31 - 236.2ms/batch - loss: 62.16833 - diff: 24.80mlTrain batch 12/31 - 237.2ms/batch - loss: 63.48527 - diff: 25.32mlTrain batch 13/31 - 239.9ms/batch - loss: 62.23887 - diff: 25.09mlTrain batch 14/31 - 236.2ms/batch - loss: 60.16406 - diff: 24.66mlTrain batch 15/31 - 236.2ms/batch - loss: 59.18973 - diff: 24.38mlTrain batch 16/31 - 237.0ms/batch - loss: 60.90911 - diff: 24.63mlTrain batch 17/31 - 235.8ms/batch - loss: 59.79206 - diff: 24.45mlTrain batch 18/31 - 237.3ms/batch - loss: 58.90376 - diff: 24.24mlTrain batch 19/31 - 236.3ms/batch - loss: 56.91032 - diff: 23.71mlTrain batch 20/31 - 237.1ms/batch - loss: 57.90222 - diff: 23.95mlTrain batch 21/31 - 235.9ms/batch - loss: 57.14882 - diff: 23.75mlTrain batch 22/31 - 237.3ms/batch - loss: 56.46349 - diff: 23.63mlTrain batch 23/31 - 236.3ms/batch - loss: 57.49072 - diff: 23.80mlTrain batch 24/31 - 237.8ms/batch - loss: 56.65254 - diff: 23.61mlTrain batch 25/31 - 236.7ms/batch - loss: 58.02734 - diff: 23.72mlTrain batch 26/31 - 237.6ms/batch - loss: 58.27854 - diff: 23.82mlTrain batch 27/31 - 236.4ms/batch - loss: 57.82117 - diff: 23.67mlTrain batch 28/31 - 237.3ms/batch - loss: 58.63021 - diff: 23.75mlTrain batch 29/31 - 236.3ms/batch - loss: 58.16162 - diff: 23.74mlTrain batch 30/31 - 237.3ms/batch - loss: 57.53603 - diff: 23.59mlTrain batch 31/31 - 123.1ms/batch - loss: 58.00811 - diff: 23.52mlTrain batch 31/31 - 11.2s 123.1ms/batch - loss: 58.00811 - diff: 23.52ml
Test 1.1s: val_loss: 58.08430 - diff: 22.70ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_WideResNet50_0_Adam-0.001_MSE_DA3_best

Epoch 82: current best loss = 58.08430, at epoch 81
Train batch 1/31 - 250.8ms/batch - loss: 65.26621 - diff: 24.64mlTrain batch 2/31 - 236.1ms/batch - loss: 53.67164 - diff: 22.88mlTrain batch 3/31 - 236.2ms/batch - loss: 48.91160 - diff: 22.48mlTrain batch 4/31 - 236.9ms/batch - loss: 46.53767 - diff: 22.14mlTrain batch 5/31 - 236.3ms/batch - loss: 49.26432 - diff: 21.99mlTrain batch 6/31 - 237.2ms/batch - loss: 47.27534 - diff: 21.51mlTrain batch 7/31 - 236.0ms/batch - loss: 46.14315 - diff: 21.05mlTrain batch 8/31 - 237.6ms/batch - loss: 46.60807 - diff: 21.03mlTrain batch 9/31 - 236.1ms/batch - loss: 47.97123 - diff: 21.55mlTrain batch 10/31 - 237.0ms/batch - loss: 49.97481 - diff: 22.04mlTrain batch 11/31 - 236.4ms/batch - loss: 51.02337 - diff: 22.48mlTrain batch 12/31 - 237.0ms/batch - loss: 51.46629 - diff: 22.67mlTrain batch 13/31 - 236.3ms/batch - loss: 51.02096 - diff: 22.69mlTrain batch 14/31 - 236.9ms/batch - loss: 52.66677 - diff: 23.07mlTrain batch 15/31 - 236.1ms/batch - loss: 52.42708 - diff: 22.97mlTrain batch 16/31 - 237.2ms/batch - loss: 52.27523 - diff: 22.81mlTrain batch 17/31 - 235.8ms/batch - loss: 53.53757 - diff: 23.23mlTrain batch 18/31 - 237.4ms/batch - loss: 53.22792 - diff: 23.18mlTrain batch 19/31 - 244.2ms/batch - loss: 53.11611 - diff: 23.09mlTrain batch 20/31 - 236.5ms/batch - loss: 54.70734 - diff: 23.07mlTrain batch 21/31 - 236.0ms/batch - loss: 54.96567 - diff: 23.04mlTrain batch 22/31 - 236.3ms/batch - loss: 54.26127 - diff: 22.92mlTrain batch 23/31 - 235.9ms/batch - loss: 54.12806 - diff: 23.00mlTrain batch 24/31 - 237.3ms/batch - loss: 55.59565 - diff: 23.20mlTrain batch 25/31 - 236.6ms/batch - loss: 54.94537 - diff: 23.09mlTrain batch 26/31 - 237.4ms/batch - loss: 54.75045 - diff: 23.18mlTrain batch 27/31 - 236.1ms/batch - loss: 64.07876 - diff: 24.26mlTrain batch 28/31 - 237.6ms/batch - loss: 65.22192 - diff: 24.46mlTrain batch 29/31 - 236.4ms/batch - loss: 64.17004 - diff: 24.32mlTrain batch 30/31 - 236.9ms/batch - loss: 63.93819 - diff: 24.17mlTrain batch 31/31 - 123.3ms/batch - loss: 64.91847 - diff: 24.22mlTrain batch 31/31 - 11.3s 123.3ms/batch - loss: 64.91847 - diff: 24.22ml
Test 1.1s: val_loss: 114.69558 - diff: 31.29ml

Epoch 83: current best loss = 58.08430, at epoch 81
Train batch 1/31 - 236.0ms/batch - loss: 60.70899 - diff: 21.39mlTrain batch 2/31 - 237.1ms/batch - loss: 70.20374 - diff: 24.18mlTrain batch 3/31 - 236.4ms/batch - loss: 94.50741 - diff: 27.56mlTrain batch 4/31 - 237.0ms/batch - loss: 78.11532 - diff: 25.23mlTrain batch 5/31 - 236.0ms/batch - loss: 66.23142 - diff: 23.13mlTrain batch 6/31 - 237.2ms/batch - loss: 65.40071 - diff: 23.79mlTrain batch 7/31 - 236.8ms/batch - loss: 60.51436 - diff: 23.11mlTrain batch 8/31 - 236.1ms/batch - loss: 55.91194 - diff: 22.10mlTrain batch 9/31 - 236.8ms/batch - loss: 57.61481 - diff: 22.39mlTrain batch 10/31 - 236.2ms/batch - loss: 64.04255 - diff: 23.80mlTrain batch 11/31 - 237.0ms/batch - loss: 62.07605 - diff: 23.68mlTrain batch 12/31 - 236.4ms/batch - loss: 65.16943 - diff: 24.64mlTrain batch 13/31 - 237.7ms/batch - loss: 63.06054 - diff: 24.48mlTrain batch 14/31 - 238.7ms/batch - loss: 68.97568 - diff: 25.25mlTrain batch 15/31 - 237.8ms/batch - loss: 68.21106 - diff: 24.92mlTrain batch 16/31 - 236.4ms/batch - loss: 66.08625 - diff: 24.61mlTrain batch 17/31 - 237.0ms/batch - loss: 66.62100 - diff: 24.72mlTrain batch 18/31 - 236.2ms/batch - loss: 68.00600 - diff: 24.92mlTrain batch 19/31 - 237.7ms/batch - loss: 65.88330 - diff: 24.52mlTrain batch 20/31 - 236.4ms/batch - loss: 68.50551 - diff: 25.26mlTrain batch 21/31 - 237.3ms/batch - loss: 66.61454 - diff: 24.96mlTrain batch 22/31 - 236.3ms/batch - loss: 65.59004 - diff: 24.85mlTrain batch 23/31 - 237.0ms/batch - loss: 66.57779 - diff: 25.02mlTrain batch 24/31 - 236.5ms/batch - loss: 64.91412 - diff: 24.71mlTrain batch 25/31 - 237.3ms/batch - loss: 64.87104 - diff: 24.82mlTrain batch 26/31 - 236.2ms/batch - loss: 68.45578 - diff: 25.26mlTrain batch 27/31 - 237.7ms/batch - loss: 68.21685 - diff: 25.34mlTrain batch 28/31 - 236.7ms/batch - loss: 67.37637 - diff: 25.22mlTrain batch 29/31 - 236.7ms/batch - loss: 67.74865 - diff: 25.28mlTrain batch 30/31 - 236.7ms/batch - loss: 71.93717 - diff: 25.92mlTrain batch 31/31 - 123.9ms/batch - loss: 77.36489 - diff: 26.10mlTrain batch 31/31 - 11.5s 123.9ms/batch - loss: 77.36489 - diff: 26.10ml
Test 1.1s: val_loss: 77.82254 - diff: 25.63ml

Epoch 84: current best loss = 58.08430, at epoch 81
Train batch 1/31 - 236.5ms/batch - loss: 49.82176 - diff: 24.24mlTrain batch 2/31 - 238.7ms/batch - loss: 36.75661 - diff: 20.54mlTrain batch 3/31 - 236.1ms/batch - loss: 41.87569 - diff: 22.15mlTrain batch 4/31 - 237.4ms/batch - loss: 38.42644 - diff: 20.66mlTrain batch 5/31 - 236.2ms/batch - loss: 39.46499 - diff: 20.87mlTrain batch 6/31 - 237.0ms/batch - loss: 53.59829 - diff: 24.15mlTrain batch 7/31 - 236.4ms/batch - loss: 59.62569 - diff: 25.43mlTrain batch 8/31 - 237.1ms/batch - loss: 60.54196 - diff: 25.27mlTrain batch 9/31 - 236.3ms/batch - loss: 57.95666 - diff: 24.76mlTrain batch 10/31 - 236.9ms/batch - loss: 66.24430 - diff: 26.33mlTrain batch 11/31 - 236.2ms/batch - loss: 74.93778 - diff: 26.89mlTrain batch 12/31 - 236.8ms/batch - loss: 74.04905 - diff: 26.84mlTrain batch 13/31 - 236.3ms/batch - loss: 76.30502 - diff: 26.94mlTrain batch 14/31 - 237.4ms/batch - loss: 73.80081 - diff: 26.51mlTrain batch 15/31 - 236.7ms/batch - loss: 72.05156 - diff: 26.20mlTrain batch 16/31 - 237.5ms/batch - loss: 70.65877 - diff: 25.88mlTrain batch 17/31 - 236.9ms/batch - loss: 67.93358 - diff: 25.36mlTrain batch 18/31 - 236.9ms/batch - loss: 66.62134 - diff: 25.15mlTrain batch 19/31 - 236.7ms/batch - loss: 68.17047 - diff: 25.25mlTrain batch 20/31 - 237.5ms/batch - loss: 67.83843 - diff: 25.29mlTrain batch 21/31 - 237.3ms/batch - loss: 65.58710 - diff: 24.80mlTrain batch 22/31 - 236.6ms/batch - loss: 67.17460 - diff: 25.18mlTrain batch 23/31 - 237.2ms/batch - loss: 70.89465 - diff: 25.64mlTrain batch 24/31 - 236.5ms/batch - loss: 70.07471 - diff: 25.46mlTrain batch 25/31 - 237.6ms/batch - loss: 71.23891 - diff: 25.76mlTrain batch 26/31 - 236.5ms/batch - loss: 70.39016 - diff: 25.47mlTrain batch 27/31 - 237.8ms/batch - loss: 71.18571 - diff: 25.70mlTrain batch 28/31 - 236.5ms/batch - loss: 70.15726 - diff: 25.51mlTrain batch 29/31 - 237.1ms/batch - loss: 70.83547 - diff: 25.68mlTrain batch 30/31 - 236.1ms/batch - loss: 69.73264 - diff: 25.48mlTrain batch 31/31 - 123.1ms/batch - loss: 73.04844 - diff: 25.67mlTrain batch 31/31 - 11.5s 123.1ms/batch - loss: 73.04844 - diff: 25.67ml
Test 1.1s: val_loss: 61.19381 - diff: 23.01ml

Epoch 85: current best loss = 58.08430, at epoch 81
Train batch 1/31 - 236.5ms/batch - loss: 25.05776 - diff: 16.92mlTrain batch 2/31 - 238.1ms/batch - loss: 47.56514 - diff: 22.15mlTrain batch 3/31 - 236.1ms/batch - loss: 141.68244 - diff: 26.67mlTrain batch 4/31 - 236.3ms/batch - loss: 117.56924 - diff: 25.29mlTrain batch 5/31 - 236.6ms/batch - loss: 112.60052 - diff: 26.66mlTrain batch 6/31 - 236.9ms/batch - loss: 107.38350 - diff: 26.88mlTrain batch 7/31 - 238.3ms/batch - loss: 98.72342 - diff: 26.19mlTrain batch 8/31 - 239.4ms/batch - loss: 91.40276 - diff: 25.36mlTrain batch 9/31 - 237.0ms/batch - loss: 85.72854 - diff: 25.02mlTrain batch 10/31 - 236.3ms/batch - loss: 79.02320 - diff: 23.94mlTrain batch 11/31 - 237.2ms/batch - loss: 77.30399 - diff: 23.86mlTrain batch 12/31 - 236.5ms/batch - loss: 76.87521 - diff: 24.19mlTrain batch 13/31 - 236.8ms/batch - loss: 74.13278 - diff: 24.00mlTrain batch 14/31 - 236.4ms/batch - loss: 71.64849 - diff: 23.82mlTrain batch 15/31 - 237.6ms/batch - loss: 75.19099 - diff: 24.61mlTrain batch 16/31 - 236.2ms/batch - loss: 73.11195 - diff: 24.35mlTrain batch 17/31 - 237.2ms/batch - loss: 70.50361 - diff: 23.93mlTrain batch 18/31 - 237.0ms/batch - loss: 69.32738 - diff: 23.88mlTrain batch 19/31 - 236.0ms/batch - loss: 67.51076 - diff: 23.64mlTrain batch 20/31 - 237.7ms/batch - loss: 71.13683 - diff: 24.19mlTrain batch 21/31 - 236.4ms/batch - loss: 71.55769 - diff: 24.51mlTrain batch 22/31 - 236.9ms/batch - loss: 76.00928 - diff: 25.06mlTrain batch 23/31 - 236.3ms/batch - loss: 74.96324 - diff: 24.99mlTrain batch 24/31 - 237.1ms/batch - loss: 74.05306 - diff: 24.84mlTrain batch 25/31 - 236.0ms/batch - loss: 71.97218 - diff: 24.45mlTrain batch 26/31 - 237.2ms/batch - loss: 71.37378 - diff: 24.42mlTrain batch 27/31 - 236.4ms/batch - loss: 70.27777 - diff: 24.25mlTrain batch 28/31 - 237.2ms/batch - loss: 68.76309 - diff: 24.03mlTrain batch 29/31 - 236.3ms/batch - loss: 68.40873 - diff: 24.11mlTrain batch 30/31 - 237.4ms/batch - loss: 67.97925 - diff: 24.09mlTrain batch 31/31 - 123.4ms/batch - loss: 67.94544 - diff: 23.96mlTrain batch 31/31 - 11.7s 123.4ms/batch - loss: 67.94544 - diff: 23.96ml
Test 1.2s: val_loss: 70.40015 - diff: 24.00ml

Epoch 86: current best loss = 58.08430, at epoch 81
Train batch 1/31 - 236.2ms/batch - loss: 54.22873 - diff: 25.05mlTrain batch 2/31 - 237.5ms/batch - loss: 68.58950 - diff: 24.28mlTrain batch 3/31 - 236.1ms/batch - loss: 61.15233 - diff: 22.93mlTrain batch 4/31 - 237.1ms/batch - loss: 77.48626 - diff: 25.29mlTrain batch 5/31 - 236.4ms/batch - loss: 84.34968 - diff: 27.45mlTrain batch 6/31 - 237.5ms/batch - loss: 77.82245 - diff: 26.35mlTrain batch 7/31 - 236.3ms/batch - loss: 83.24439 - diff: 26.70mlTrain batch 8/31 - 237.1ms/batch - loss: 82.13836 - diff: 26.85mlTrain batch 9/31 - 236.3ms/batch - loss: 82.97518 - diff: 27.17mlTrain batch 10/31 - 237.4ms/batch - loss: 78.45962 - diff: 26.33mlTrain batch 11/31 - 236.1ms/batch - loss: 76.05871 - diff: 26.24mlTrain batch 12/31 - 237.8ms/batch - loss: 74.04888 - diff: 25.92mlTrain batch 13/31 - 236.3ms/batch - loss: 70.51632 - diff: 25.21mlTrain batch 14/31 - 237.2ms/batch - loss: 72.19415 - diff: 25.56mlTrain batch 15/31 - 236.1ms/batch - loss: 71.96890 - diff: 25.54mlTrain batch 16/31 - 237.2ms/batch - loss: 69.01718 - diff: 24.77mlTrain batch 17/31 - 236.5ms/batch - loss: 68.45273 - diff: 24.29mlTrain batch 18/31 - 237.0ms/batch - loss: 66.78145 - diff: 24.05mlTrain batch 19/31 - 236.1ms/batch - loss: 64.78923 - diff: 23.79mlTrain batch 20/31 - 237.0ms/batch - loss: 69.51529 - diff: 23.90mlTrain batch 21/31 - 236.9ms/batch - loss: 69.90190 - diff: 24.10mlTrain batch 22/31 - 237.5ms/batch - loss: 69.44128 - diff: 23.91mlTrain batch 23/31 - 236.6ms/batch - loss: 67.78835 - diff: 23.75mlTrain batch 24/31 - 237.4ms/batch - loss: 67.86935 - diff: 23.87mlTrain batch 25/31 - 236.4ms/batch - loss: 67.01247 - diff: 23.69mlTrain batch 26/31 - 237.8ms/batch - loss: 68.55342 - diff: 24.10mlTrain batch 27/31 - 236.5ms/batch - loss: 68.11803 - diff: 24.13mlTrain batch 28/31 - 237.4ms/batch - loss: 67.10230 - diff: 24.01mlTrain batch 29/31 - 236.5ms/batch - loss: 66.02832 - diff: 23.83mlTrain batch 30/31 - 237.3ms/batch - loss: 65.66940 - diff: 23.77mlTrain batch 31/31 - 123.7ms/batch - loss: 66.76901 - diff: 23.78mlTrain batch 31/31 - 11.0s 123.7ms/batch - loss: 66.76901 - diff: 23.78ml
Test 1.1s: val_loss: 70.34498 - diff: 24.60ml

Epoch 87: current best loss = 58.08430, at epoch 81
Train batch 1/31 - 236.1ms/batch - loss: 35.69593 - diff: 20.93mlTrain batch 2/31 - 236.9ms/batch - loss: 52.84376 - diff: 21.92mlTrain batch 3/31 - 236.1ms/batch - loss: 50.26501 - diff: 21.42mlTrain batch 4/31 - 237.5ms/batch - loss: 66.21920 - diff: 24.12mlTrain batch 5/31 - 237.9ms/batch - loss: 60.68195 - diff: 23.42mlTrain batch 6/31 - 236.9ms/batch - loss: 59.72090 - diff: 23.31mlTrain batch 7/31 - 236.4ms/batch - loss: 55.01902 - diff: 22.46mlTrain batch 8/31 - 237.2ms/batch - loss: 55.00446 - diff: 22.74mlTrain batch 9/31 - 236.2ms/batch - loss: 50.84602 - diff: 21.82mlTrain batch 10/31 - 236.8ms/batch - loss: 51.78001 - diff: 22.19mlTrain batch 11/31 - 236.2ms/batch - loss: 54.27665 - diff: 22.47mlTrain batch 12/31 - 237.3ms/batch - loss: 59.30310 - diff: 23.23mlTrain batch 13/31 - 246.3ms/batch - loss: 57.92618 - diff: 23.08mlTrain batch 14/31 - 236.9ms/batch - loss: 57.96340 - diff: 23.22mlTrain batch 15/31 - 236.7ms/batch - loss: 58.66523 - diff: 23.40mlTrain batch 16/31 - 237.5ms/batch - loss: 58.35847 - diff: 23.47mlTrain batch 17/31 - 236.5ms/batch - loss: 56.99713 - diff: 23.23mlTrain batch 18/31 - 236.8ms/batch - loss: 55.94419 - diff: 23.09mlTrain batch 19/31 - 236.0ms/batch - loss: 54.51401 - diff: 22.83mlTrain batch 20/31 - 236.2ms/batch - loss: 54.28150 - diff: 22.82mlTrain batch 21/31 - 236.5ms/batch - loss: 54.94741 - diff: 22.94mlTrain batch 22/31 - 236.6ms/batch - loss: 54.66422 - diff: 22.92mlTrain batch 23/31 - 237.0ms/batch - loss: 55.04641 - diff: 22.85mlTrain batch 24/31 - 236.2ms/batch - loss: 54.16847 - diff: 22.59mlTrain batch 25/31 - 237.6ms/batch - loss: 53.05344 - diff: 22.39mlTrain batch 26/31 - 243.9ms/batch - loss: 52.13203 - diff: 22.19mlTrain batch 27/31 - 238.0ms/batch - loss: 52.09686 - diff: 22.29mlTrain batch 28/31 - 236.0ms/batch - loss: 52.23529 - diff: 22.26mlTrain batch 29/31 - 237.5ms/batch - loss: 51.03939 - diff: 21.96mlTrain batch 30/31 - 236.4ms/batch - loss: 50.40609 - diff: 21.85mlTrain batch 31/31 - 123.4ms/batch - loss: 50.79813 - diff: 21.82mlTrain batch 31/31 - 11.9s 123.4ms/batch - loss: 50.79813 - diff: 21.82ml
Test 1.1s: val_loss: 62.18668 - diff: 23.02ml

Epoch 88: current best loss = 58.08430, at epoch 81
Train batch 1/31 - 236.0ms/batch - loss: 46.71510 - diff: 22.58mlTrain batch 2/31 - 237.2ms/batch - loss: 40.44441 - diff: 20.61mlTrain batch 3/31 - 236.4ms/batch - loss: 44.41352 - diff: 21.82mlTrain batch 4/31 - 237.1ms/batch - loss: 47.49025 - diff: 22.51mlTrain batch 5/31 - 236.1ms/batch - loss: 82.54632 - diff: 28.46mlTrain batch 6/31 - 237.2ms/batch - loss: 78.46531 - diff: 27.64mlTrain batch 7/31 - 236.2ms/batch - loss: 70.75105 - diff: 25.96mlTrain batch 8/31 - 236.9ms/batch - loss: 71.14479 - diff: 26.36mlTrain batch 9/31 - 236.1ms/batch - loss: 66.28046 - diff: 25.37mlTrain batch 10/31 - 237.4ms/batch - loss: 75.18930 - diff: 27.05mlTrain batch 11/31 - 236.4ms/batch - loss: 73.49305 - diff: 26.87mlTrain batch 12/31 - 237.3ms/batch - loss: 72.25504 - diff: 26.64mlTrain batch 13/31 - 236.5ms/batch - loss: 70.28343 - diff: 26.29mlTrain batch 14/31 - 237.7ms/batch - loss: 69.00435 - diff: 26.05mlTrain batch 15/31 - 236.2ms/batch - loss: 68.12080 - diff: 26.07mlTrain batch 16/31 - 237.7ms/batch - loss: 67.63596 - diff: 25.95mlTrain batch 17/31 - 236.3ms/batch - loss: 65.85681 - diff: 25.59mlTrain batch 18/31 - 236.8ms/batch - loss: 66.21481 - diff: 25.63mlTrain batch 19/31 - 236.6ms/batch - loss: 68.82695 - diff: 26.27mlTrain batch 20/31 - 237.4ms/batch - loss: 67.18593 - diff: 25.99mlTrain batch 21/31 - 236.2ms/batch - loss: 66.59783 - diff: 25.96mlTrain batch 22/31 - 236.8ms/batch - loss: 66.77261 - diff: 25.94mlTrain batch 23/31 - 236.7ms/batch - loss: 65.32014 - diff: 25.60mlTrain batch 24/31 - 237.3ms/batch - loss: 67.06783 - diff: 25.89mlTrain batch 25/31 - 236.7ms/batch - loss: 65.53222 - diff: 25.46mlTrain batch 26/31 - 238.5ms/batch - loss: 64.13783 - diff: 25.24mlTrain batch 27/31 - 236.2ms/batch - loss: 62.96132 - diff: 24.93mlTrain batch 28/31 - 236.8ms/batch - loss: 64.24903 - diff: 25.03mlTrain batch 29/31 - 236.6ms/batch - loss: 62.46973 - diff: 24.56mlTrain batch 30/31 - 236.5ms/batch - loss: 62.47001 - diff: 24.64mlTrain batch 31/31 - 123.4ms/batch - loss: 64.71506 - diff: 24.74mlTrain batch 31/31 - 10.8s 123.4ms/batch - loss: 64.71506 - diff: 24.74ml
Test 1.2s: val_loss: 62.26543 - diff: 23.40ml

Epoch 89: current best loss = 58.08430, at epoch 81
Train batch 1/31 - 236.2ms/batch - loss: 86.99487 - diff: 29.99mlTrain batch 2/31 - 237.5ms/batch - loss: 73.86737 - diff: 25.95mlTrain batch 3/31 - 236.4ms/batch - loss: 71.14144 - diff: 25.42mlTrain batch 4/31 - 237.4ms/batch - loss: 60.98892 - diff: 23.78mlTrain batch 5/31 - 236.2ms/batch - loss: 63.57354 - diff: 24.82mlTrain batch 6/31 - 237.5ms/batch - loss: 64.18049 - diff: 24.42mlTrain batch 7/31 - 236.7ms/batch - loss: 59.55343 - diff: 23.41mlTrain batch 8/31 - 237.2ms/batch - loss: 56.25096 - diff: 22.73mlTrain batch 9/31 - 236.5ms/batch - loss: 54.49196 - diff: 22.73mlTrain batch 10/31 - 237.6ms/batch - loss: 61.88547 - diff: 23.19mlTrain batch 11/31 - 236.0ms/batch - loss: 59.23421 - diff: 22.69mlTrain batch 12/31 - 237.3ms/batch - loss: 57.09526 - diff: 22.24mlTrain batch 13/31 - 236.2ms/batch - loss: 54.03075 - diff: 21.55mlTrain batch 14/31 - 237.4ms/batch - loss: 54.47493 - diff: 22.07mlTrain batch 15/31 - 236.4ms/batch - loss: 55.83211 - diff: 22.52mlTrain batch 16/31 - 237.4ms/batch - loss: 54.09574 - diff: 22.12mlTrain batch 17/31 - 236.1ms/batch - loss: 52.39172 - diff: 21.69mlTrain batch 18/31 - 237.8ms/batch - loss: 54.05218 - diff: 22.01mlTrain batch 19/31 - 236.2ms/batch - loss: 54.68546 - diff: 22.29mlTrain batch 20/31 - 237.2ms/batch - loss: 55.95716 - diff: 22.59mlTrain batch 21/31 - 236.4ms/batch - loss: 55.58514 - diff: 22.65mlTrain batch 22/31 - 237.4ms/batch - loss: 56.38719 - diff: 22.90mlTrain batch 23/31 - 236.6ms/batch - loss: 55.15306 - diff: 22.61mlTrain batch 24/31 - 237.4ms/batch - loss: 54.88229 - diff: 22.63mlTrain batch 25/31 - 236.5ms/batch - loss: 54.29887 - diff: 22.55mlTrain batch 26/31 - 237.5ms/batch - loss: 54.22163 - diff: 22.62mlTrain batch 27/31 - 236.3ms/batch - loss: 55.68442 - diff: 22.86mlTrain batch 28/31 - 237.7ms/batch - loss: 55.52904 - diff: 22.78mlTrain batch 29/31 - 236.7ms/batch - loss: 54.96923 - diff: 22.71mlTrain batch 30/31 - 237.4ms/batch - loss: 56.01463 - diff: 22.91mlTrain batch 31/31 - 123.7ms/batch - loss: 56.56939 - diff: 22.91mlTrain batch 31/31 - 11.3s 123.7ms/batch - loss: 56.56939 - diff: 22.91ml
Test 1.2s: val_loss: 69.47957 - diff: 23.70ml

Epoch 90: current best loss = 58.08430, at epoch 81
Train batch 1/31 - 236.6ms/batch - loss: 17.24302 - diff: 14.78mlTrain batch 2/31 - 237.6ms/batch - loss: 29.81570 - diff: 17.48mlTrain batch 3/31 - 236.2ms/batch - loss: 32.74217 - diff: 18.82mlTrain batch 4/31 - 236.3ms/batch - loss: 35.09624 - diff: 19.36mlTrain batch 5/31 - 236.5ms/batch - loss: 45.24650 - diff: 21.05mlTrain batch 6/31 - 236.3ms/batch - loss: 48.60626 - diff: 21.68mlTrain batch 7/31 - 237.5ms/batch - loss: 45.40325 - diff: 20.84mlTrain batch 8/31 - 235.9ms/batch - loss: 46.76497 - diff: 21.28mlTrain batch 9/31 - 237.0ms/batch - loss: 46.17603 - diff: 21.15mlTrain batch 10/31 - 236.0ms/batch - loss: 51.25945 - diff: 21.82mlTrain batch 11/31 - 236.9ms/batch - loss: 49.70800 - diff: 21.56mlTrain batch 12/31 - 236.4ms/batch - loss: 51.33505 - diff: 22.08mlTrain batch 13/31 - 237.2ms/batch - loss: 52.20700 - diff: 22.19mlTrain batch 14/31 - 236.3ms/batch - loss: 53.53783 - diff: 22.52mlTrain batch 15/31 - 237.2ms/batch - loss: 53.62216 - diff: 22.57mlTrain batch 16/31 - 236.6ms/batch - loss: 52.08367 - diff: 22.29mlTrain batch 17/31 - 236.2ms/batch - loss: 51.58939 - diff: 22.32mlTrain batch 18/31 - 236.9ms/batch - loss: 51.45557 - diff: 22.39mlTrain batch 19/31 - 236.2ms/batch - loss: 52.51389 - diff: 22.65mlTrain batch 20/31 - 237.0ms/batch - loss: 52.26799 - diff: 22.62mlTrain batch 21/31 - 238.6ms/batch - loss: 50.67373 - diff: 22.22mlTrain batch 22/31 - 237.2ms/batch - loss: 51.54714 - diff: 22.39mlTrain batch 23/31 - 236.1ms/batch - loss: 50.40155 - diff: 21.99mlTrain batch 24/31 - 237.4ms/batch - loss: 50.99469 - diff: 22.23mlTrain batch 25/31 - 236.3ms/batch - loss: 52.01273 - diff: 22.56mlTrain batch 26/31 - 236.8ms/batch - loss: 51.12968 - diff: 22.38mlTrain batch 27/31 - 236.0ms/batch - loss: 50.93023 - diff: 22.43mlTrain batch 28/31 - 237.3ms/batch - loss: 50.33961 - diff: 22.32mlTrain batch 29/31 - 236.4ms/batch - loss: 54.59252 - diff: 22.86mlTrain batch 30/31 - 237.3ms/batch - loss: 56.96628 - diff: 23.18mlTrain batch 31/31 - 123.6ms/batch - loss: 57.18449 - diff: 23.10mlTrain batch 31/31 - 11.9s 123.6ms/batch - loss: 57.18449 - diff: 23.10ml
Test 1.1s: val_loss: 91.76503 - diff: 29.04ml

Epoch 91: current best loss = 58.08430, at epoch 81
Train batch 1/31 - 236.1ms/batch - loss: 38.82133 - diff: 20.16mlTrain batch 2/31 - 236.7ms/batch - loss: 57.94191 - diff: 25.70mlTrain batch 3/31 - 239.4ms/batch - loss: 51.28101 - diff: 23.13mlTrain batch 4/31 - 236.6ms/batch - loss: 44.32308 - diff: 21.06mlTrain batch 5/31 - 242.3ms/batch - loss: 39.75646 - diff: 19.80mlTrain batch 6/31 - 244.3ms/batch - loss: 45.05869 - diff: 20.05mlTrain batch 7/31 - 238.6ms/batch - loss: 45.42823 - diff: 20.27mlTrain batch 8/31 - 236.5ms/batch - loss: 46.30061 - diff: 20.56mlTrain batch 9/31 - 236.7ms/batch - loss: 55.52971 - diff: 22.01mlTrain batch 10/31 - 236.4ms/batch - loss: 57.35446 - diff: 22.77mlTrain batch 11/31 - 236.6ms/batch - loss: 56.85676 - diff: 22.98mlTrain batch 12/31 - 236.7ms/batch - loss: 55.14692 - diff: 22.77mlTrain batch 13/31 - 236.2ms/batch - loss: 53.47885 - diff: 22.61mlTrain batch 14/31 - 237.2ms/batch - loss: 55.34327 - diff: 22.74mlTrain batch 15/31 - 236.3ms/batch - loss: 54.23004 - diff: 22.63mlTrain batch 16/31 - 237.1ms/batch - loss: 53.40943 - diff: 22.49mlTrain batch 17/31 - 237.7ms/batch - loss: 55.54236 - diff: 22.97mlTrain batch 18/31 - 236.8ms/batch - loss: 60.07494 - diff: 23.68mlTrain batch 19/31 - 236.4ms/batch - loss: 60.18315 - diff: 23.70mlTrain batch 20/31 - 237.6ms/batch - loss: 60.55745 - diff: 23.70mlTrain batch 21/31 - 236.1ms/batch - loss: 62.46963 - diff: 24.12mlTrain batch 22/31 - 237.2ms/batch - loss: 65.06970 - diff: 24.51mlTrain batch 23/31 - 242.6ms/batch - loss: 67.90707 - diff: 25.02mlTrain batch 24/31 - 237.1ms/batch - loss: 66.22225 - diff: 24.71mlTrain batch 25/31 - 238.0ms/batch - loss: 67.13668 - diff: 24.89mlTrain batch 26/31 - 238.2ms/batch - loss: 67.52607 - diff: 25.00mlTrain batch 27/31 - 236.2ms/batch - loss: 65.96659 - diff: 24.65mlTrain batch 28/31 - 239.2ms/batch - loss: 65.22920 - diff: 24.49mlTrain batch 29/31 - 238.4ms/batch - loss: 66.00229 - diff: 24.64mlTrain batch 30/31 - 237.2ms/batch - loss: 65.09068 - diff: 24.52mlTrain batch 31/31 - 123.7ms/batch - loss: 65.73749 - diff: 24.48mlTrain batch 31/31 - 12.2s 123.7ms/batch - loss: 65.73749 - diff: 24.48ml
Test 1.2s: val_loss: 167.25141 - diff: 42.92ml

Epoch 92: current best loss = 58.08430, at epoch 81
Train batch 1/31 - 236.0ms/batch - loss: 41.38093 - diff: 20.61mlTrain batch 2/31 - 236.5ms/batch - loss: 45.28818 - diff: 19.66mlTrain batch 3/31 - 236.4ms/batch - loss: 54.96399 - diff: 21.07mlTrain batch 4/31 - 236.8ms/batch - loss: 66.63156 - diff: 23.77mlTrain batch 5/31 - 236.1ms/batch - loss: 68.66678 - diff: 24.81mlTrain batch 6/31 - 237.8ms/batch - loss: 65.55469 - diff: 24.13mlTrain batch 7/31 - 235.2ms/batch - loss: 62.81264 - diff: 23.65mlTrain batch 8/31 - 236.8ms/batch - loss: 65.25434 - diff: 23.61mlTrain batch 9/31 - 236.0ms/batch - loss: 66.58970 - diff: 24.50mlTrain batch 10/31 - 236.6ms/batch - loss: 63.09763 - diff: 23.86mlTrain batch 11/31 - 236.4ms/batch - loss: 63.54580 - diff: 24.15mlTrain batch 12/31 - 237.0ms/batch - loss: 63.69126 - diff: 24.09mlTrain batch 13/31 - 236.3ms/batch - loss: 62.22410 - diff: 23.83mlTrain batch 14/31 - 237.0ms/batch - loss: 69.70694 - diff: 24.28mlTrain batch 15/31 - 236.4ms/batch - loss: 72.67544 - diff: 24.56mlTrain batch 16/31 - 237.5ms/batch - loss: 71.34564 - diff: 24.50mlTrain batch 17/31 - 236.4ms/batch - loss: 70.64796 - diff: 24.59mlTrain batch 18/31 - 237.6ms/batch - loss: 71.17327 - diff: 24.89mlTrain batch 19/31 - 236.0ms/batch - loss: 69.62008 - diff: 24.71mlTrain batch 20/31 - 237.2ms/batch - loss: 70.19757 - diff: 24.98mlTrain batch 21/31 - 238.1ms/batch - loss: 70.47353 - diff: 25.18mlTrain batch 22/31 - 237.3ms/batch - loss: 70.03417 - diff: 25.24mlTrain batch 23/31 - 236.1ms/batch - loss: 69.31232 - diff: 25.19mlTrain batch 24/31 - 237.5ms/batch - loss: 67.78411 - diff: 24.91mlTrain batch 25/31 - 238.9ms/batch - loss: 68.05945 - diff: 25.07mlTrain batch 26/31 - 236.0ms/batch - loss: 67.54229 - diff: 25.03mlTrain batch 27/31 - 236.4ms/batch - loss: 66.33037 - diff: 24.71mlTrain batch 28/31 - 237.8ms/batch - loss: 66.02100 - diff: 24.68mlTrain batch 29/31 - 235.9ms/batch - loss: 65.69237 - diff: 24.62mlTrain batch 30/31 - 236.5ms/batch - loss: 65.22394 - diff: 24.54mlTrain batch 31/31 - 123.1ms/batch - loss: 65.06505 - diff: 24.38mlTrain batch 31/31 - 11.3s 123.1ms/batch - loss: 65.06505 - diff: 24.38ml
Test 1.2s: val_loss: 110.67918 - diff: 31.59ml
Epoch    93: reducing learning rate of group 0 to 2.5000e-04.

Epoch 93: current best loss = 58.08430, at epoch 81
Train batch 1/31 - 236.3ms/batch - loss: 32.48492 - diff: 19.81mlTrain batch 2/31 - 238.1ms/batch - loss: 22.95432 - diff: 16.28mlTrain batch 3/31 - 236.3ms/batch - loss: 27.01202 - diff: 17.20mlTrain batch 4/31 - 236.2ms/batch - loss: 40.99327 - diff: 20.97mlTrain batch 5/31 - 237.1ms/batch - loss: 38.75501 - diff: 20.49mlTrain batch 6/31 - 236.2ms/batch - loss: 50.68209 - diff: 21.17mlTrain batch 7/31 - 236.7ms/batch - loss: 51.83881 - diff: 21.69mlTrain batch 8/31 - 236.2ms/batch - loss: 49.23447 - diff: 21.07mlTrain batch 9/31 - 236.9ms/batch - loss: 49.59571 - diff: 21.24mlTrain batch 10/31 - 236.4ms/batch - loss: 47.78046 - diff: 20.92mlTrain batch 11/31 - 237.2ms/batch - loss: 48.79536 - diff: 21.12mlTrain batch 12/31 - 236.4ms/batch - loss: 47.87069 - diff: 21.05mlTrain batch 13/31 - 237.9ms/batch - loss: 49.65704 - diff: 21.73mlTrain batch 14/31 - 236.4ms/batch - loss: 48.40166 - diff: 21.47mlTrain batch 15/31 - 237.0ms/batch - loss: 47.83619 - diff: 21.38mlTrain batch 16/31 - 236.3ms/batch - loss: 47.80168 - diff: 21.41mlTrain batch 17/31 - 237.1ms/batch - loss: 48.43518 - diff: 21.62mlTrain batch 18/31 - 236.4ms/batch - loss: 46.95212 - diff: 21.23mlTrain batch 19/31 - 237.1ms/batch - loss: 47.23983 - diff: 21.46mlTrain batch 20/31 - 236.3ms/batch - loss: 46.70215 - diff: 21.39mlTrain batch 21/31 - 236.7ms/batch - loss: 46.05880 - diff: 21.27mlTrain batch 22/31 - 236.2ms/batch - loss: 46.49345 - diff: 21.46mlTrain batch 23/31 - 237.3ms/batch - loss: 46.88433 - diff: 21.60mlTrain batch 24/31 - 236.2ms/batch - loss: 46.63824 - diff: 21.50mlTrain batch 25/31 - 237.4ms/batch - loss: 46.04992 - diff: 21.28mlTrain batch 26/31 - 239.8ms/batch - loss: 45.55212 - diff: 21.13mlTrain batch 27/31 - 236.5ms/batch - loss: 48.11869 - diff: 21.61mlTrain batch 28/31 - 236.5ms/batch - loss: 47.78871 - diff: 21.53mlTrain batch 29/31 - 237.2ms/batch - loss: 46.78993 - diff: 21.28mlTrain batch 30/31 - 236.4ms/batch - loss: 46.79345 - diff: 21.28mlTrain batch 31/31 - 123.7ms/batch - loss: 47.23173 - diff: 21.22mlTrain batch 31/31 - 11.4s 123.7ms/batch - loss: 47.23173 - diff: 21.22ml
Test 1.2s: val_loss: 68.62184 - diff: 23.94ml

Epoch 94: current best loss = 58.08430, at epoch 81
Train batch 1/31 - 236.1ms/batch - loss: 57.49975 - diff: 25.54mlTrain batch 2/31 - 236.7ms/batch - loss: 43.24621 - diff: 21.10mlTrain batch 3/31 - 235.9ms/batch - loss: 37.31287 - diff: 19.27mlTrain batch 4/31 - 236.6ms/batch - loss: 36.48379 - diff: 18.78mlTrain batch 5/31 - 236.4ms/batch - loss: 38.10296 - diff: 19.69mlTrain batch 6/31 - 236.3ms/batch - loss: 41.91477 - diff: 20.67mlTrain batch 7/31 - 237.1ms/batch - loss: 43.22056 - diff: 20.87mlTrain batch 8/31 - 236.4ms/batch - loss: 40.80679 - diff: 20.17mlTrain batch 9/31 - 236.9ms/batch - loss: 52.54286 - diff: 21.88mlTrain batch 10/31 - 236.2ms/batch - loss: 55.28832 - diff: 22.36mlTrain batch 11/31 - 236.7ms/batch - loss: 55.11702 - diff: 22.54mlTrain batch 12/31 - 236.2ms/batch - loss: 54.36445 - diff: 22.52mlTrain batch 13/31 - 237.3ms/batch - loss: 55.94386 - diff: 22.97mlTrain batch 14/31 - 236.2ms/batch - loss: 54.41164 - diff: 22.60mlTrain batch 15/31 - 236.9ms/batch - loss: 57.68347 - diff: 23.10mlTrain batch 16/31 - 236.8ms/batch - loss: 55.88029 - diff: 22.87mlTrain batch 17/31 - 237.1ms/batch - loss: 54.71737 - diff: 22.69mlTrain batch 18/31 - 236.8ms/batch - loss: 53.54153 - diff: 22.40mlTrain batch 19/31 - 237.4ms/batch - loss: 52.93857 - diff: 22.36mlTrain batch 20/31 - 236.5ms/batch - loss: 52.22213 - diff: 22.23mlTrain batch 21/31 - 237.1ms/batch - loss: 51.41095 - diff: 22.05mlTrain batch 22/31 - 236.2ms/batch - loss: 51.09136 - diff: 22.02mlTrain batch 23/31 - 237.3ms/batch - loss: 49.95263 - diff: 21.76mlTrain batch 24/31 - 236.9ms/batch - loss: 49.77019 - diff: 21.74mlTrain batch 25/31 - 237.7ms/batch - loss: 50.26117 - diff: 21.89mlTrain batch 26/31 - 236.2ms/batch - loss: 49.39871 - diff: 21.69mlTrain batch 27/31 - 237.7ms/batch - loss: 47.96352 - diff: 21.25mlTrain batch 28/31 - 236.9ms/batch - loss: 47.83486 - diff: 21.15mlTrain batch 29/31 - 237.2ms/batch - loss: 47.90750 - diff: 21.15mlTrain batch 30/31 - 236.5ms/batch - loss: 46.96504 - diff: 20.91mlTrain batch 31/31 - 123.7ms/batch - loss: 47.20154 - diff: 20.85mlTrain batch 31/31 - 11.5s 123.7ms/batch - loss: 47.20154 - diff: 20.85ml
Test 1.2s: val_loss: 68.59603 - diff: 25.48ml

Epoch 95: current best loss = 58.08430, at epoch 81
Train batch 1/31 - 236.2ms/batch - loss: 45.04516 - diff: 22.35mlTrain batch 2/31 - 238.3ms/batch - loss: 45.25439 - diff: 21.91mlTrain batch 3/31 - 236.7ms/batch - loss: 46.70449 - diff: 22.04mlTrain batch 4/31 - 237.2ms/batch - loss: 40.23569 - diff: 19.82mlTrain batch 5/31 - 236.3ms/batch - loss: 41.95156 - diff: 20.31mlTrain batch 6/31 - 237.7ms/batch - loss: 41.51018 - diff: 20.59mlTrain batch 7/31 - 236.1ms/batch - loss: 40.11237 - diff: 20.09mlTrain batch 8/31 - 237.6ms/batch - loss: 41.42747 - diff: 20.14mlTrain batch 9/31 - 236.1ms/batch - loss: 39.49609 - diff: 19.65mlTrain batch 10/31 - 237.4ms/batch - loss: 38.53557 - diff: 19.43mlTrain batch 11/31 - 236.0ms/batch - loss: 41.11830 - diff: 19.76mlTrain batch 12/31 - 237.1ms/batch - loss: 53.33772 - diff: 21.53mlTrain batch 13/31 - 236.4ms/batch - loss: 54.85097 - diff: 21.83mlTrain batch 14/31 - 237.6ms/batch - loss: 54.25532 - diff: 21.89mlTrain batch 15/31 - 236.5ms/batch - loss: 55.36453 - diff: 22.42mlTrain batch 16/31 - 236.9ms/batch - loss: 55.11840 - diff: 22.51mlTrain batch 17/31 - 236.4ms/batch - loss: 55.75029 - diff: 22.98mlTrain batch 18/31 - 237.3ms/batch - loss: 55.88567 - diff: 22.80mlTrain batch 19/31 - 236.0ms/batch - loss: 53.79727 - diff: 22.23mlTrain batch 20/31 - 236.5ms/batch - loss: 57.32024 - diff: 22.92mlTrain batch 21/31 - 236.1ms/batch - loss: 57.50819 - diff: 23.01mlTrain batch 22/31 - 237.2ms/batch - loss: 56.11809 - diff: 22.67mlTrain batch 23/31 - 236.8ms/batch - loss: 56.71961 - diff: 22.77mlTrain batch 24/31 - 237.5ms/batch - loss: 56.82407 - diff: 22.90mlTrain batch 25/31 - 236.3ms/batch - loss: 56.57249 - diff: 22.98mlTrain batch 26/31 - 237.0ms/batch - loss: 55.54169 - diff: 22.77mlTrain batch 27/31 - 236.7ms/batch - loss: 55.04845 - diff: 22.59mlTrain batch 28/31 - 237.3ms/batch - loss: 53.80847 - diff: 22.32mlTrain batch 29/31 - 236.2ms/batch - loss: 53.23095 - diff: 22.20mlTrain batch 30/31 - 236.1ms/batch - loss: 53.05821 - diff: 22.18mlTrain batch 31/31 - 123.9ms/batch - loss: 54.26467 - diff: 22.20mlTrain batch 31/31 - 11.7s 123.9ms/batch - loss: 54.26467 - diff: 22.20ml
Test 1.1s: val_loss: 56.82758 - diff: 22.36ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_WideResNet50_0_Adam-0.001_MSE_DA3_best

Epoch 96: current best loss = 56.82758, at epoch 95
Train batch 1/31 - 236.1ms/batch - loss: 45.25323 - diff: 22.75mlTrain batch 2/31 - 236.5ms/batch - loss: 34.03287 - diff: 19.52mlTrain batch 3/31 - 236.1ms/batch - loss: 31.68460 - diff: 18.51mlTrain batch 4/31 - 237.5ms/batch - loss: 37.24868 - diff: 19.88mlTrain batch 5/31 - 235.9ms/batch - loss: 37.56532 - diff: 20.07mlTrain batch 6/31 - 236.4ms/batch - loss: 36.59282 - diff: 19.98mlTrain batch 7/31 - 236.3ms/batch - loss: 35.94226 - diff: 19.87mlTrain batch 8/31 - 236.8ms/batch - loss: 36.16708 - diff: 19.89mlTrain batch 9/31 - 236.4ms/batch - loss: 39.30537 - diff: 20.55mlTrain batch 10/31 - 237.3ms/batch - loss: 53.42769 - diff: 22.92mlTrain batch 11/31 - 236.3ms/batch - loss: 51.46836 - diff: 22.46mlTrain batch 12/31 - 237.2ms/batch - loss: 51.18578 - diff: 22.32mlTrain batch 13/31 - 236.0ms/batch - loss: 49.31786 - diff: 22.00mlTrain batch 14/31 - 236.7ms/batch - loss: 47.13307 - diff: 21.45mlTrain batch 15/31 - 236.5ms/batch - loss: 45.90822 - diff: 21.18mlTrain batch 16/31 - 237.3ms/batch - loss: 45.25873 - diff: 21.09mlTrain batch 17/31 - 236.1ms/batch - loss: 46.53381 - diff: 21.14mlTrain batch 18/31 - 237.3ms/batch - loss: 49.43408 - diff: 21.67mlTrain batch 19/31 - 236.1ms/batch - loss: 49.79309 - diff: 21.83mlTrain batch 20/31 - 237.2ms/batch - loss: 48.25068 - diff: 21.37mlTrain batch 21/31 - 236.1ms/batch - loss: 49.09622 - diff: 21.61mlTrain batch 22/31 - 237.4ms/batch - loss: 47.87724 - diff: 21.34mlTrain batch 23/31 - 236.2ms/batch - loss: 47.88803 - diff: 21.16mlTrain batch 24/31 - 236.9ms/batch - loss: 47.44275 - diff: 21.05mlTrain batch 25/31 - 235.9ms/batch - loss: 46.63224 - diff: 20.91mlTrain batch 26/31 - 237.4ms/batch - loss: 48.27578 - diff: 21.07mlTrain batch 27/31 - 236.3ms/batch - loss: 50.68330 - diff: 21.38mlTrain batch 28/31 - 237.3ms/batch - loss: 51.51128 - diff: 21.53mlTrain batch 29/31 - 236.3ms/batch - loss: 50.51088 - diff: 21.34mlTrain batch 30/31 - 236.9ms/batch - loss: 50.16724 - diff: 21.25mlTrain batch 31/31 - 123.4ms/batch - loss: 50.67866 - diff: 21.27mlTrain batch 31/31 - 11.5s 123.4ms/batch - loss: 50.67866 - diff: 21.27ml
Test 1.1s: val_loss: 55.57058 - diff: 22.33ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_WideResNet50_0_Adam-0.001_MSE_DA3_best

Epoch 97: current best loss = 55.57058, at epoch 96
Train batch 1/31 - 235.8ms/batch - loss: 51.29775 - diff: 20.60mlTrain batch 2/31 - 236.4ms/batch - loss: 42.76120 - diff: 19.33mlTrain batch 3/31 - 236.1ms/batch - loss: 41.91329 - diff: 19.67mlTrain batch 4/31 - 237.4ms/batch - loss: 42.42424 - diff: 19.94mlTrain batch 5/31 - 237.7ms/batch - loss: 39.72906 - diff: 19.41mlTrain batch 6/31 - 237.2ms/batch - loss: 44.84753 - diff: 20.37mlTrain batch 7/31 - 236.2ms/batch - loss: 48.26179 - diff: 21.54mlTrain batch 8/31 - 237.5ms/batch - loss: 44.92448 - diff: 20.69mlTrain batch 9/31 - 236.5ms/batch - loss: 42.80303 - diff: 20.27mlTrain batch 10/31 - 237.3ms/batch - loss: 54.33510 - diff: 22.98mlTrain batch 11/31 - 236.1ms/batch - loss: 57.12337 - diff: 23.56mlTrain batch 12/31 - 235.4ms/batch - loss: 60.11226 - diff: 24.23mlTrain batch 13/31 - 236.3ms/batch - loss: 58.37148 - diff: 23.78mlTrain batch 14/31 - 237.1ms/batch - loss: 56.24085 - diff: 23.40mlTrain batch 15/31 - 236.4ms/batch - loss: 55.78422 - diff: 23.36mlTrain batch 16/31 - 237.0ms/batch - loss: 55.04303 - diff: 23.09mlTrain batch 17/31 - 236.2ms/batch - loss: 54.09104 - diff: 22.96mlTrain batch 18/31 - 236.9ms/batch - loss: 52.13970 - diff: 22.42mlTrain batch 19/31 - 236.7ms/batch - loss: 52.78559 - diff: 22.46mlTrain batch 20/31 - 238.8ms/batch - loss: 51.89212 - diff: 22.32mlTrain batch 21/31 - 236.4ms/batch - loss: 52.82267 - diff: 22.47mlTrain batch 22/31 - 237.2ms/batch - loss: 51.22410 - diff: 22.03mlTrain batch 23/31 - 236.1ms/batch - loss: 52.16720 - diff: 22.23mlTrain batch 24/31 - 237.3ms/batch - loss: 51.39300 - diff: 22.09mlTrain batch 25/31 - 236.5ms/batch - loss: 53.87603 - diff: 22.40mlTrain batch 26/31 - 237.6ms/batch - loss: 54.00858 - diff: 22.50mlTrain batch 27/31 - 236.3ms/batch - loss: 53.11905 - diff: 22.31mlTrain batch 28/31 - 236.8ms/batch - loss: 52.68973 - diff: 22.23mlTrain batch 29/31 - 236.0ms/batch - loss: 51.83884 - diff: 22.08mlTrain batch 30/31 - 237.1ms/batch - loss: 51.14975 - diff: 21.98mlTrain batch 31/31 - 123.4ms/batch - loss: 54.72326 - diff: 22.20mlTrain batch 31/31 - 10.8s 123.4ms/batch - loss: 54.72326 - diff: 22.20ml
Test 1.1s: val_loss: 52.94235 - diff: 21.89ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_WideResNet50_0_Adam-0.001_MSE_DA3_best

Epoch 98: current best loss = 52.94235, at epoch 97
Train batch 1/31 - 250.6ms/batch - loss: 90.79224 - diff: 28.04mlTrain batch 2/31 - 236.2ms/batch - loss: 60.14455 - diff: 23.36mlTrain batch 3/31 - 236.0ms/batch - loss: 50.52420 - diff: 21.70mlTrain batch 4/31 - 237.4ms/batch - loss: 49.67038 - diff: 20.98mlTrain batch 5/31 - 236.3ms/batch - loss: 49.48532 - diff: 21.14mlTrain batch 6/31 - 237.1ms/batch - loss: 50.66569 - diff: 21.61mlTrain batch 7/31 - 236.2ms/batch - loss: 47.54701 - diff: 21.16mlTrain batch 8/31 - 237.1ms/batch - loss: 48.00986 - diff: 21.30mlTrain batch 9/31 - 236.6ms/batch - loss: 49.66358 - diff: 21.77mlTrain batch 10/31 - 238.1ms/batch - loss: 47.33543 - diff: 21.32mlTrain batch 11/31 - 236.6ms/batch - loss: 47.57494 - diff: 21.39mlTrain batch 12/31 - 237.2ms/batch - loss: 47.77788 - diff: 21.54mlTrain batch 13/31 - 236.3ms/batch - loss: 46.56262 - diff: 21.33mlTrain batch 14/31 - 237.0ms/batch - loss: 45.79842 - diff: 21.30mlTrain batch 15/31 - 236.4ms/batch - loss: 46.56221 - diff: 21.38mlTrain batch 16/31 - 237.1ms/batch - loss: 45.30032 - diff: 21.02mlTrain batch 17/31 - 236.2ms/batch - loss: 43.84334 - diff: 20.71mlTrain batch 18/31 - 237.4ms/batch - loss: 42.84353 - diff: 20.43mlTrain batch 19/31 - 236.1ms/batch - loss: 42.29288 - diff: 20.27mlTrain batch 20/31 - 237.4ms/batch - loss: 42.59889 - diff: 20.39mlTrain batch 21/31 - 238.1ms/batch - loss: 43.25836 - diff: 20.72mlTrain batch 22/31 - 237.6ms/batch - loss: 42.20919 - diff: 20.44mlTrain batch 23/31 - 236.1ms/batch - loss: 41.94884 - diff: 20.46mlTrain batch 24/31 - 236.8ms/batch - loss: 41.30995 - diff: 20.25mlTrain batch 25/31 - 236.3ms/batch - loss: 42.24324 - diff: 20.47mlTrain batch 26/31 - 237.4ms/batch - loss: 42.78158 - diff: 20.48mlTrain batch 27/31 - 236.0ms/batch - loss: 43.51201 - diff: 20.66mlTrain batch 28/31 - 237.0ms/batch - loss: 44.78967 - diff: 20.91mlTrain batch 29/31 - 236.6ms/batch - loss: 44.50875 - diff: 20.90mlTrain batch 30/31 - 237.2ms/batch - loss: 45.80263 - diff: 21.09mlTrain batch 31/31 - 123.8ms/batch - loss: 45.96221 - diff: 21.01mlTrain batch 31/31 - 11.5s 123.8ms/batch - loss: 45.96221 - diff: 21.01ml
Test 1.1s: val_loss: 58.84239 - diff: 22.87ml

Epoch 99: current best loss = 52.94235, at epoch 97
Train batch 1/31 - 236.4ms/batch - loss: 33.56186 - diff: 18.51mlTrain batch 2/31 - 237.1ms/batch - loss: 35.75215 - diff: 19.54mlTrain batch 3/31 - 235.9ms/batch - loss: 45.86447 - diff: 21.42mlTrain batch 4/31 - 237.2ms/batch - loss: 43.73056 - diff: 20.80mlTrain batch 5/31 - 236.2ms/batch - loss: 38.43617 - diff: 19.25mlTrain batch 6/31 - 236.7ms/batch - loss: 38.26585 - diff: 19.35mlTrain batch 7/31 - 236.1ms/batch - loss: 37.46693 - diff: 18.74mlTrain batch 8/31 - 237.1ms/batch - loss: 39.93462 - diff: 19.40mlTrain batch 9/31 - 236.4ms/batch - loss: 38.04102 - diff: 18.87mlTrain batch 10/31 - 237.3ms/batch - loss: 38.06373 - diff: 18.84mlTrain batch 11/31 - 237.2ms/batch - loss: 38.93458 - diff: 19.26mlTrain batch 12/31 - 237.2ms/batch - loss: 39.32737 - diff: 19.56mlTrain batch 13/31 - 236.2ms/batch - loss: 37.77457 - diff: 19.21mlTrain batch 14/31 - 237.7ms/batch - loss: 40.84438 - diff: 19.61mlTrain batch 15/31 - 236.5ms/batch - loss: 42.51738 - diff: 19.95mlTrain batch 16/31 - 237.4ms/batch - loss: 41.74068 - diff: 19.91mlTrain batch 17/31 - 236.7ms/batch - loss: 40.62507 - diff: 19.73mlTrain batch 18/31 - 236.3ms/batch - loss: 40.44828 - diff: 19.68mlTrain batch 19/31 - 237.2ms/batch - loss: 40.22437 - diff: 19.74mlTrain batch 20/31 - 236.8ms/batch - loss: 39.44600 - diff: 19.55mlTrain batch 21/31 - 237.1ms/batch - loss: 39.54729 - diff: 19.66mlTrain batch 22/31 - 236.3ms/batch - loss: 39.43178 - diff: 19.50mlTrain batch 23/31 - 236.6ms/batch - loss: 41.03064 - diff: 19.71mlTrain batch 24/31 - 237.1ms/batch - loss: 40.14952 - diff: 19.52mlTrain batch 25/31 - 236.8ms/batch - loss: 39.90204 - diff: 19.40mlTrain batch 26/31 - 236.4ms/batch - loss: 40.46165 - diff: 19.53mlTrain batch 27/31 - 236.6ms/batch - loss: 41.86903 - diff: 19.87mlTrain batch 28/31 - 237.5ms/batch - loss: 42.44736 - diff: 19.90mlTrain batch 29/31 - 236.7ms/batch - loss: 43.63148 - diff: 20.15mlTrain batch 30/31 - 237.2ms/batch - loss: 43.23233 - diff: 20.08mlTrain batch 31/31 - 123.4ms/batch - loss: 43.99140 - diff: 20.09mlTrain batch 31/31 - 10.7s 123.4ms/batch - loss: 43.99140 - diff: 20.09ml
Test 1.2s: val_loss: 58.61113 - diff: 21.98ml

Epoch 100: current best loss = 52.94235, at epoch 97
Train batch 1/31 - 236.5ms/batch - loss: 32.47602 - diff: 19.59mlTrain batch 2/31 - 238.7ms/batch - loss: 36.15237 - diff: 20.89mlTrain batch 3/31 - 236.8ms/batch - loss: 43.43172 - diff: 22.15mlTrain batch 4/31 - 237.0ms/batch - loss: 45.08192 - diff: 22.58mlTrain batch 5/31 - 236.4ms/batch - loss: 59.64404 - diff: 24.57mlTrain batch 6/31 - 236.9ms/batch - loss: 53.10392 - diff: 22.86mlTrain batch 7/31 - 236.1ms/batch - loss: 53.90245 - diff: 23.40mlTrain batch 8/31 - 237.0ms/batch - loss: 50.55763 - diff: 22.45mlTrain batch 9/31 - 236.1ms/batch - loss: 49.31574 - diff: 22.10mlTrain batch 10/31 - 237.4ms/batch - loss: 48.21118 - diff: 21.78mlTrain batch 11/31 - 236.6ms/batch - loss: 48.99389 - diff: 22.12mlTrain batch 12/31 - 237.7ms/batch - loss: 52.73629 - diff: 22.84mlTrain batch 13/31 - 236.3ms/batch - loss: 50.85248 - diff: 22.55mlTrain batch 14/31 - 237.2ms/batch - loss: 53.08931 - diff: 23.06mlTrain batch 15/31 - 236.3ms/batch - loss: 51.93252 - diff: 22.82mlTrain batch 16/31 - 236.7ms/batch - loss: 51.02309 - diff: 22.70mlTrain batch 17/31 - 236.2ms/batch - loss: 51.87084 - diff: 22.79mlTrain batch 18/31 - 237.7ms/batch - loss: 51.64590 - diff: 22.55mlTrain batch 19/31 - 237.0ms/batch - loss: 51.30606 - diff: 22.48mlTrain batch 20/31 - 237.3ms/batch - loss: 49.77213 - diff: 22.05mlTrain batch 21/31 - 236.4ms/batch - loss: 52.65902 - diff: 22.45mlTrain batch 22/31 - 237.3ms/batch - loss: 54.15112 - diff: 22.78mlTrain batch 23/31 - 237.0ms/batch - loss: 53.30219 - diff: 22.62mlTrain batch 24/31 - 237.4ms/batch - loss: 54.00667 - diff: 22.83mlTrain batch 25/31 - 236.1ms/batch - loss: 55.63144 - diff: 23.19mlTrain batch 26/31 - 236.7ms/batch - loss: 54.40707 - diff: 22.84mlTrain batch 27/31 - 236.9ms/batch - loss: 53.50678 - diff: 22.65mlTrain batch 28/31 - 237.6ms/batch - loss: 52.42980 - diff: 22.39mlTrain batch 29/31 - 236.9ms/batch - loss: 51.52581 - diff: 22.22mlTrain batch 30/31 - 237.4ms/batch - loss: 51.19830 - diff: 22.20mlTrain batch 31/31 - 123.7ms/batch - loss: 53.32369 - diff: 22.34mlTrain batch 31/31 - 10.6s 123.7ms/batch - loss: 53.32369 - diff: 22.34ml
Test 1.1s: val_loss: 72.10004 - diff: 22.77ml

Epoch 101: current best loss = 52.94235, at epoch 97
Train batch 1/31 - 236.5ms/batch - loss: 48.17217 - diff: 21.17mlTrain batch 2/31 - 237.1ms/batch - loss: 40.10077 - diff: 18.90mlTrain batch 3/31 - 236.6ms/batch - loss: 50.80051 - diff: 22.02mlTrain batch 4/31 - 237.7ms/batch - loss: 44.81479 - diff: 20.85mlTrain batch 5/31 - 236.7ms/batch - loss: 42.36845 - diff: 20.35mlTrain batch 6/31 - 237.2ms/batch - loss: 40.19043 - diff: 20.14mlTrain batch 7/31 - 237.0ms/batch - loss: 42.61472 - diff: 21.00mlTrain batch 8/31 - 237.7ms/batch - loss: 40.78624 - diff: 20.52mlTrain batch 9/31 - 236.5ms/batch - loss: 39.69777 - diff: 20.10mlTrain batch 10/31 - 237.4ms/batch - loss: 37.36088 - diff: 19.41mlTrain batch 11/31 - 236.8ms/batch - loss: 38.16366 - diff: 19.71mlTrain batch 12/31 - 237.6ms/batch - loss: 39.56024 - diff: 20.00mlTrain batch 13/31 - 236.0ms/batch - loss: 38.07078 - diff: 19.41mlTrain batch 14/31 - 236.9ms/batch - loss: 39.40244 - diff: 19.89mlTrain batch 15/31 - 236.4ms/batch - loss: 38.26482 - diff: 19.63mlTrain batch 16/31 - 236.3ms/batch - loss: 37.22843 - diff: 19.42mlTrain batch 17/31 - 237.2ms/batch - loss: 37.29587 - diff: 19.59mlTrain batch 18/31 - 236.2ms/batch - loss: 37.73176 - diff: 19.48mlTrain batch 19/31 - 237.8ms/batch - loss: 36.90646 - diff: 19.29mlTrain batch 20/31 - 236.5ms/batch - loss: 37.07593 - diff: 19.26mlTrain batch 21/31 - 237.8ms/batch - loss: 37.18597 - diff: 19.25mlTrain batch 22/31 - 236.3ms/batch - loss: 37.53232 - diff: 19.37mlTrain batch 23/31 - 238.0ms/batch - loss: 37.69625 - diff: 19.36mlTrain batch 24/31 - 236.6ms/batch - loss: 39.34886 - diff: 19.67mlTrain batch 25/31 - 237.4ms/batch - loss: 38.75942 - diff: 19.56mlTrain batch 26/31 - 237.0ms/batch - loss: 37.96242 - diff: 19.38mlTrain batch 27/31 - 237.8ms/batch - loss: 37.66580 - diff: 19.27mlTrain batch 28/31 - 236.3ms/batch - loss: 37.60776 - diff: 19.28mlTrain batch 29/31 - 237.8ms/batch - loss: 38.23352 - diff: 19.35mlTrain batch 30/31 - 236.8ms/batch - loss: 38.69265 - diff: 19.47mlTrain batch 31/31 - 123.5ms/batch - loss: 39.73025 - diff: 19.51mlTrain batch 31/31 - 10.9s 123.5ms/batch - loss: 39.73025 - diff: 19.51ml
Test 1.1s: val_loss: 59.82383 - diff: 22.82ml

Epoch 102: current best loss = 52.94235, at epoch 97
Train batch 1/31 - 236.3ms/batch - loss: 78.58994 - diff: 29.01mlTrain batch 2/31 - 237.0ms/batch - loss: 52.55994 - diff: 22.94mlTrain batch 3/31 - 236.2ms/batch - loss: 55.88718 - diff: 24.41mlTrain batch 4/31 - 237.7ms/batch - loss: 51.35369 - diff: 23.78mlTrain batch 5/31 - 236.9ms/batch - loss: 56.84200 - diff: 24.77mlTrain batch 6/31 - 236.5ms/batch - loss: 50.42302 - diff: 22.74mlTrain batch 7/31 - 236.3ms/batch - loss: 45.50206 - diff: 21.19mlTrain batch 8/31 - 237.1ms/batch - loss: 43.93270 - diff: 21.14mlTrain batch 9/31 - 236.5ms/batch - loss: 41.95560 - diff: 20.67mlTrain batch 10/31 - 237.3ms/batch - loss: 40.48038 - diff: 20.31mlTrain batch 11/31 - 236.3ms/batch - loss: 39.72185 - diff: 20.20mlTrain batch 12/31 - 237.0ms/batch - loss: 38.02593 - diff: 19.79mlTrain batch 13/31 - 237.3ms/batch - loss: 37.17236 - diff: 19.53mlTrain batch 14/31 - 237.4ms/batch - loss: 37.71957 - diff: 19.73mlTrain batch 15/31 - 236.4ms/batch - loss: 38.08255 - diff: 19.92mlTrain batch 16/31 - 237.1ms/batch - loss: 38.25474 - diff: 20.01mlTrain batch 17/31 - 236.5ms/batch - loss: 37.54279 - diff: 19.85mlTrain batch 18/31 - 236.5ms/batch - loss: 39.84226 - diff: 20.33mlTrain batch 19/31 - 238.0ms/batch - loss: 39.64632 - diff: 20.37mlTrain batch 20/31 - 236.6ms/batch - loss: 40.12240 - diff: 20.45mlTrain batch 21/31 - 237.7ms/batch - loss: 44.10938 - diff: 21.06mlTrain batch 22/31 - 237.0ms/batch - loss: 44.57673 - diff: 21.21mlTrain batch 23/31 - 238.0ms/batch - loss: 45.68148 - diff: 21.23mlTrain batch 24/31 - 237.3ms/batch - loss: 45.12593 - diff: 21.18mlTrain batch 25/31 - 237.6ms/batch - loss: 45.25042 - diff: 21.08mlTrain batch 26/31 - 236.6ms/batch - loss: 44.99754 - diff: 21.03mlTrain batch 27/31 - 237.4ms/batch - loss: 44.42711 - diff: 20.92mlTrain batch 28/31 - 236.3ms/batch - loss: 44.31341 - diff: 20.86mlTrain batch 29/31 - 237.6ms/batch - loss: 45.60701 - diff: 21.18mlTrain batch 30/31 - 236.1ms/batch - loss: 45.61242 - diff: 21.18mlTrain batch 31/31 - 122.3ms/batch - loss: 46.23872 - diff: 21.18mlTrain batch 31/31 - 11.0s 122.3ms/batch - loss: 46.23872 - diff: 21.18ml
Test 1.2s: val_loss: 53.34269 - diff: 21.87ml

Epoch 103: current best loss = 52.94235, at epoch 97
Train batch 1/31 - 236.3ms/batch - loss: 55.73690 - diff: 24.13mlTrain batch 2/31 - 238.3ms/batch - loss: 65.87947 - diff: 26.35mlTrain batch 3/31 - 238.6ms/batch - loss: 72.50386 - diff: 27.70mlTrain batch 4/31 - 237.9ms/batch - loss: 67.78956 - diff: 26.51mlTrain batch 5/31 - 236.5ms/batch - loss: 62.33792 - diff: 25.44mlTrain batch 6/31 - 236.7ms/batch - loss: 64.97687 - diff: 25.89mlTrain batch 7/31 - 236.4ms/batch - loss: 60.47218 - diff: 24.98mlTrain batch 8/31 - 237.2ms/batch - loss: 56.11907 - diff: 23.84mlTrain batch 9/31 - 236.1ms/batch - loss: 54.64090 - diff: 23.47mlTrain batch 10/31 - 237.3ms/batch - loss: 52.37171 - diff: 22.95mlTrain batch 11/31 - 236.4ms/batch - loss: 49.16098 - diff: 22.00mlTrain batch 12/31 - 237.6ms/batch - loss: 48.71840 - diff: 22.03mlTrain batch 13/31 - 236.1ms/batch - loss: 49.29649 - diff: 22.28mlTrain batch 14/31 - 237.3ms/batch - loss: 50.25467 - diff: 22.55mlTrain batch 15/31 - 236.7ms/batch - loss: 48.56062 - diff: 22.11mlTrain batch 16/31 - 237.3ms/batch - loss: 47.46720 - diff: 21.71mlTrain batch 17/31 - 236.7ms/batch - loss: 46.08047 - diff: 21.28mlTrain batch 18/31 - 237.6ms/batch - loss: 46.18554 - diff: 21.38mlTrain batch 19/31 - 236.3ms/batch - loss: 45.48032 - diff: 21.17mlTrain batch 20/31 - 237.3ms/batch - loss: 45.04766 - diff: 21.09mlTrain batch 21/31 - 236.4ms/batch - loss: 44.80133 - diff: 21.06mlTrain batch 22/31 - 237.8ms/batch - loss: 44.82785 - diff: 21.01mlTrain batch 23/31 - 239.6ms/batch - loss: 45.50807 - diff: 21.16mlTrain batch 24/31 - 237.8ms/batch - loss: 44.25260 - diff: 20.83mlTrain batch 25/31 - 236.2ms/batch - loss: 44.47249 - diff: 20.86mlTrain batch 26/31 - 237.8ms/batch - loss: 43.78114 - diff: 20.76mlTrain batch 27/31 - 236.2ms/batch - loss: 44.53863 - diff: 20.76mlTrain batch 28/31 - 237.7ms/batch - loss: 45.55925 - diff: 20.92mlTrain batch 29/31 - 236.3ms/batch - loss: 45.15843 - diff: 20.84mlTrain batch 30/31 - 237.0ms/batch - loss: 44.74699 - diff: 20.77mlTrain batch 31/31 - 123.8ms/batch - loss: 46.45476 - diff: 20.88mlTrain batch 31/31 - 11.5s 123.8ms/batch - loss: 46.45476 - diff: 20.88ml
Test 1.2s: val_loss: 54.78743 - diff: 22.42ml

Epoch 104: current best loss = 52.94235, at epoch 97
Train batch 1/31 - 236.2ms/batch - loss: 23.71001 - diff: 14.34mlTrain batch 2/31 - 237.6ms/batch - loss: 24.27543 - diff: 14.59mlTrain batch 3/31 - 236.3ms/batch - loss: 27.09619 - diff: 15.52mlTrain batch 4/31 - 236.9ms/batch - loss: 27.17505 - diff: 15.51mlTrain batch 5/31 - 236.3ms/batch - loss: 27.67643 - diff: 16.21mlTrain batch 6/31 - 237.6ms/batch - loss: 29.04780 - diff: 17.08mlTrain batch 7/31 - 236.3ms/batch - loss: 28.99825 - diff: 17.06mlTrain batch 8/31 - 237.0ms/batch - loss: 40.13422 - diff: 19.33mlTrain batch 9/31 - 236.3ms/batch - loss: 37.80255 - diff: 18.72mlTrain batch 10/31 - 237.2ms/batch - loss: 36.11390 - diff: 18.26mlTrain batch 11/31 - 236.5ms/batch - loss: 35.91803 - diff: 18.17mlTrain batch 12/31 - 237.3ms/batch - loss: 34.93543 - diff: 18.00mlTrain batch 13/31 - 236.5ms/batch - loss: 34.22434 - diff: 17.85mlTrain batch 14/31 - 237.7ms/batch - loss: 34.37011 - diff: 17.98mlTrain batch 15/31 - 236.1ms/batch - loss: 35.01171 - diff: 18.23mlTrain batch 16/31 - 237.7ms/batch - loss: 35.05146 - diff: 18.15mlTrain batch 17/31 - 236.3ms/batch - loss: 41.59930 - diff: 19.28mlTrain batch 18/31 - 237.4ms/batch - loss: 41.02186 - diff: 19.26mlTrain batch 19/31 - 236.1ms/batch - loss: 40.51426 - diff: 19.19mlTrain batch 20/31 - 237.6ms/batch - loss: 43.46518 - diff: 19.72mlTrain batch 21/31 - 236.4ms/batch - loss: 43.40369 - diff: 19.73mlTrain batch 22/31 - 237.8ms/batch - loss: 43.60312 - diff: 19.71mlTrain batch 23/31 - 236.6ms/batch - loss: 43.91788 - diff: 19.81mlTrain batch 24/31 - 237.6ms/batch - loss: 43.10731 - diff: 19.65mlTrain batch 25/31 - 236.4ms/batch - loss: 42.40789 - diff: 19.40mlTrain batch 26/31 - 237.3ms/batch - loss: 41.61572 - diff: 19.27mlTrain batch 27/31 - 236.8ms/batch - loss: 40.98326 - diff: 19.20mlTrain batch 28/31 - 236.4ms/batch - loss: 44.56991 - diff: 19.75mlTrain batch 29/31 - 237.7ms/batch - loss: 45.81662 - diff: 20.08mlTrain batch 30/31 - 236.3ms/batch - loss: 46.06629 - diff: 20.14mlTrain batch 31/31 - 123.9ms/batch - loss: 47.14720 - diff: 20.15mlTrain batch 31/31 - 11.2s 123.9ms/batch - loss: 47.14720 - diff: 20.15ml
Test 1.2s: val_loss: 66.90467 - diff: 24.84ml

Epoch 105: current best loss = 52.94235, at epoch 97
Train batch 1/31 - 236.1ms/batch - loss: 33.89890 - diff: 18.18mlTrain batch 2/31 - 237.5ms/batch - loss: 33.73098 - diff: 18.65mlTrain batch 3/31 - 236.3ms/batch - loss: 31.84002 - diff: 18.25mlTrain batch 4/31 - 237.7ms/batch - loss: 37.12961 - diff: 19.87mlTrain batch 5/31 - 242.1ms/batch - loss: 38.13103 - diff: 19.77mlTrain batch 6/31 - 237.0ms/batch - loss: 36.59833 - diff: 19.46mlTrain batch 7/31 - 236.3ms/batch - loss: 41.23882 - diff: 20.81mlTrain batch 8/31 - 237.9ms/batch - loss: 39.84369 - diff: 20.42mlTrain batch 9/31 - 236.7ms/batch - loss: 41.69747 - diff: 20.85mlTrain batch 10/31 - 239.1ms/batch - loss: 41.17747 - diff: 20.67mlTrain batch 11/31 - 236.2ms/batch - loss: 40.10856 - diff: 20.33mlTrain batch 12/31 - 237.8ms/batch - loss: 39.34054 - diff: 20.16mlTrain batch 13/31 - 236.5ms/batch - loss: 38.52709 - diff: 19.81mlTrain batch 14/31 - 237.4ms/batch - loss: 38.77931 - diff: 19.96mlTrain batch 15/31 - 236.4ms/batch - loss: 40.93634 - diff: 20.48mlTrain batch 16/31 - 237.2ms/batch - loss: 40.27811 - diff: 20.30mlTrain batch 17/31 - 236.7ms/batch - loss: 39.91710 - diff: 20.20mlTrain batch 18/31 - 237.1ms/batch - loss: 38.31430 - diff: 19.70mlTrain batch 19/31 - 236.6ms/batch - loss: 39.14886 - diff: 19.94mlTrain batch 20/31 - 237.2ms/batch - loss: 39.75579 - diff: 20.04mlTrain batch 21/31 - 236.4ms/batch - loss: 40.55610 - diff: 20.25mlTrain batch 22/31 - 237.5ms/batch - loss: 39.23580 - diff: 19.88mlTrain batch 23/31 - 236.3ms/batch - loss: 39.74209 - diff: 20.00mlTrain batch 24/31 - 237.5ms/batch - loss: 39.37700 - diff: 19.91mlTrain batch 25/31 - 239.1ms/batch - loss: 41.10056 - diff: 20.22mlTrain batch 26/31 - 237.2ms/batch - loss: 41.98901 - diff: 20.33mlTrain batch 27/31 - 236.8ms/batch - loss: 41.60670 - diff: 20.30mlTrain batch 28/31 - 237.6ms/batch - loss: 41.38721 - diff: 20.28mlTrain batch 29/31 - 236.8ms/batch - loss: 40.81097 - diff: 20.08mlTrain batch 30/31 - 237.4ms/batch - loss: 40.46834 - diff: 20.04mlTrain batch 31/31 - 123.4ms/batch - loss: 40.87520 - diff: 20.05mlTrain batch 31/31 - 11.0s 123.4ms/batch - loss: 40.87520 - diff: 20.05ml
Test 1.1s: val_loss: 69.91803 - diff: 24.24ml

Epoch 106: current best loss = 52.94235, at epoch 97
Train batch 1/31 - 236.1ms/batch - loss: 47.26362 - diff: 25.02mlTrain batch 2/31 - 236.6ms/batch - loss: 38.73628 - diff: 21.84mlTrain batch 3/31 - 236.3ms/batch - loss: 30.09495 - diff: 18.33mlTrain batch 4/31 - 237.3ms/batch - loss: 31.21868 - diff: 18.42mlTrain batch 5/31 - 236.3ms/batch - loss: 38.93771 - diff: 19.69mlTrain batch 6/31 - 237.2ms/batch - loss: 37.54429 - diff: 19.19mlTrain batch 7/31 - 236.7ms/batch - loss: 40.75582 - diff: 20.03mlTrain batch 8/31 - 236.9ms/batch - loss: 41.44005 - diff: 20.04mlTrain batch 9/31 - 236.5ms/batch - loss: 42.47522 - diff: 20.02mlTrain batch 10/31 - 237.4ms/batch - loss: 41.94406 - diff: 19.90mlTrain batch 11/31 - 236.6ms/batch - loss: 42.39121 - diff: 20.00mlTrain batch 12/31 - 237.5ms/batch - loss: 40.44791 - diff: 19.48mlTrain batch 13/31 - 241.7ms/batch - loss: 39.32900 - diff: 19.28mlTrain batch 14/31 - 237.5ms/batch - loss: 38.20830 - diff: 18.93mlTrain batch 15/31 - 236.5ms/batch - loss: 36.93750 - diff: 18.60mlTrain batch 16/31 - 237.8ms/batch - loss: 36.80687 - diff: 18.52mlTrain batch 17/31 - 236.1ms/batch - loss: 37.60518 - diff: 18.64mlTrain batch 18/31 - 237.6ms/batch - loss: 40.55653 - diff: 19.14mlTrain batch 19/31 - 244.5ms/batch - loss: 40.99047 - diff: 19.11mlTrain batch 20/31 - 237.1ms/batch - loss: 40.32959 - diff: 18.95mlTrain batch 21/31 - 236.6ms/batch - loss: 39.85833 - diff: 18.90mlTrain batch 22/31 - 237.4ms/batch - loss: 40.23006 - diff: 19.12mlTrain batch 23/31 - 236.6ms/batch - loss: 39.90789 - diff: 19.06mlTrain batch 24/31 - 237.4ms/batch - loss: 39.68611 - diff: 19.02mlTrain batch 25/31 - 236.3ms/batch - loss: 40.89195 - diff: 19.22mlTrain batch 26/31 - 237.4ms/batch - loss: 40.80776 - diff: 19.19mlTrain batch 27/31 - 236.3ms/batch - loss: 43.40672 - diff: 19.68mlTrain batch 28/31 - 237.3ms/batch - loss: 43.89453 - diff: 19.87mlTrain batch 29/31 - 237.1ms/batch - loss: 43.47175 - diff: 19.84mlTrain batch 30/31 - 237.3ms/batch - loss: 43.16490 - diff: 19.82mlTrain batch 31/31 - 123.6ms/batch - loss: 42.71297 - diff: 19.64mlTrain batch 31/31 - 11.2s 123.6ms/batch - loss: 42.71297 - diff: 19.64ml
Test 1.1s: val_loss: 53.87043 - diff: 22.73ml

Epoch 107: current best loss = 52.94235, at epoch 97
Train batch 1/31 - 236.5ms/batch - loss: 109.45665 - diff: 33.46mlTrain batch 2/31 - 237.8ms/batch - loss: 73.42275 - diff: 25.88mlTrain batch 3/31 - 235.9ms/batch - loss: 55.92572 - diff: 21.43mlTrain batch 4/31 - 237.5ms/batch - loss: 49.91218 - diff: 20.83mlTrain batch 5/31 - 236.4ms/batch - loss: 49.42050 - diff: 21.00mlTrain batch 6/31 - 237.4ms/batch - loss: 50.62990 - diff: 21.47mlTrain batch 7/31 - 236.4ms/batch - loss: 47.67693 - diff: 20.96mlTrain batch 8/31 - 237.1ms/batch - loss: 50.00785 - diff: 21.51mlTrain batch 9/31 - 236.3ms/batch - loss: 47.05142 - diff: 21.03mlTrain batch 10/31 - 237.3ms/batch - loss: 45.61037 - diff: 20.87mlTrain batch 11/31 - 236.4ms/batch - loss: 45.60353 - diff: 20.79mlTrain batch 12/31 - 237.5ms/batch - loss: 45.32988 - diff: 20.63mlTrain batch 13/31 - 236.5ms/batch - loss: 43.10615 - diff: 20.00mlTrain batch 14/31 - 237.1ms/batch - loss: 43.12740 - diff: 20.03mlTrain batch 15/31 - 236.9ms/batch - loss: 44.44670 - diff: 20.58mlTrain batch 16/31 - 237.7ms/batch - loss: 43.36157 - diff: 20.40mlTrain batch 17/31 - 236.8ms/batch - loss: 42.98062 - diff: 20.35mlTrain batch 18/31 - 237.8ms/batch - loss: 42.74861 - diff: 20.37mlTrain batch 19/31 - 236.4ms/batch - loss: 44.09614 - diff: 20.90mlTrain batch 20/31 - 237.8ms/batch - loss: 43.25480 - diff: 20.59mlTrain batch 21/31 - 237.0ms/batch - loss: 42.23757 - diff: 20.32mlTrain batch 22/31 - 237.5ms/batch - loss: 41.39025 - diff: 20.13mlTrain batch 23/31 - 236.3ms/batch - loss: 41.24729 - diff: 20.20mlTrain batch 24/31 - 237.3ms/batch - loss: 40.48780 - diff: 20.00mlTrain batch 25/31 - 236.3ms/batch - loss: 40.98450 - diff: 20.15mlTrain batch 26/31 - 237.5ms/batch - loss: 43.51593 - diff: 20.79mlTrain batch 27/31 - 236.3ms/batch - loss: 43.44671 - diff: 20.83mlTrain batch 28/31 - 237.7ms/batch - loss: 44.38272 - diff: 21.09mlTrain batch 29/31 - 236.8ms/batch - loss: 44.00811 - diff: 21.03mlTrain batch 30/31 - 237.2ms/batch - loss: 43.21682 - diff: 20.76mlTrain batch 31/31 - 123.5ms/batch - loss: 43.95078 - diff: 20.78mlTrain batch 31/31 - 10.6s 123.5ms/batch - loss: 43.95078 - diff: 20.78ml
Test 1.2s: val_loss: 55.97591 - diff: 20.76ml

Epoch 108: current best loss = 52.94235, at epoch 97
Train batch 1/31 - 236.5ms/batch - loss: 33.06771 - diff: 18.43mlTrain batch 2/31 - 236.9ms/batch - loss: 27.80987 - diff: 17.14mlTrain batch 3/31 - 236.3ms/batch - loss: 23.74725 - diff: 15.37mlTrain batch 4/31 - 236.2ms/batch - loss: 28.67657 - diff: 17.23mlTrain batch 5/31 - 236.4ms/batch - loss: 29.93281 - diff: 17.45mlTrain batch 6/31 - 237.5ms/batch - loss: 29.67877 - diff: 17.68mlTrain batch 7/31 - 236.6ms/batch - loss: 29.53150 - diff: 17.66mlTrain batch 8/31 - 236.8ms/batch - loss: 27.98552 - diff: 17.13mlTrain batch 9/31 - 236.6ms/batch - loss: 28.50694 - diff: 17.20mlTrain batch 10/31 - 237.9ms/batch - loss: 31.51244 - diff: 18.04mlTrain batch 11/31 - 236.3ms/batch - loss: 32.03654 - diff: 18.18mlTrain batch 12/31 - 237.6ms/batch - loss: 33.48798 - diff: 18.29mlTrain batch 13/31 - 236.2ms/batch - loss: 37.48664 - diff: 19.01mlTrain batch 14/31 - 237.3ms/batch - loss: 37.83593 - diff: 19.16mlTrain batch 15/31 - 236.5ms/batch - loss: 37.92140 - diff: 19.27mlTrain batch 16/31 - 237.1ms/batch - loss: 39.11583 - diff: 19.59mlTrain batch 17/31 - 236.6ms/batch - loss: 37.92362 - diff: 19.19mlTrain batch 18/31 - 237.3ms/batch - loss: 36.95513 - diff: 18.95mlTrain batch 19/31 - 236.3ms/batch - loss: 36.68936 - diff: 18.96mlTrain batch 20/31 - 237.1ms/batch - loss: 37.83214 - diff: 19.31mlTrain batch 21/31 - 236.3ms/batch - loss: 39.26199 - diff: 19.67mlTrain batch 22/31 - 237.5ms/batch - loss: 38.88183 - diff: 19.56mlTrain batch 23/31 - 236.7ms/batch - loss: 38.21806 - diff: 19.40mlTrain batch 24/31 - 237.2ms/batch - loss: 37.83404 - diff: 19.31mlTrain batch 25/31 - 236.4ms/batch - loss: 37.07474 - diff: 19.04mlTrain batch 26/31 - 237.7ms/batch - loss: 37.35155 - diff: 19.03mlTrain batch 27/31 - 236.1ms/batch - loss: 36.91004 - diff: 18.83mlTrain batch 28/31 - 237.9ms/batch - loss: 37.34570 - diff: 18.97mlTrain batch 29/31 - 236.0ms/batch - loss: 37.45886 - diff: 18.90mlTrain batch 30/31 - 237.7ms/batch - loss: 38.25953 - diff: 19.06mlTrain batch 31/31 - 124.0ms/batch - loss: 38.39269 - diff: 18.94mlTrain batch 31/31 - 11.6s 124.0ms/batch - loss: 38.39269 - diff: 18.94ml
Test 1.2s: val_loss: 62.42189 - diff: 22.90ml
Epoch   109: reducing learning rate of group 0 to 1.2500e-04.

Epoch 109: current best loss = 52.94235, at epoch 97
Train batch 1/31 - 236.4ms/batch - loss: 44.50822 - diff: 22.78mlTrain batch 2/31 - 237.1ms/batch - loss: 47.78728 - diff: 21.32mlTrain batch 3/31 - 236.6ms/batch - loss: 37.95489 - diff: 18.93mlTrain batch 4/31 - 237.5ms/batch - loss: 63.05305 - diff: 22.55mlTrain batch 5/31 - 236.3ms/batch - loss: 65.85225 - diff: 24.08mlTrain batch 6/31 - 237.2ms/batch - loss: 63.57008 - diff: 24.17mlTrain batch 7/31 - 236.5ms/batch - loss: 68.14182 - diff: 25.24mlTrain batch 8/31 - 237.5ms/batch - loss: 64.85024 - diff: 24.61mlTrain batch 9/31 - 237.2ms/batch - loss: 60.13659 - diff: 23.60mlTrain batch 10/31 - 237.6ms/batch - loss: 56.60826 - diff: 22.92mlTrain batch 11/31 - 236.3ms/batch - loss: 55.92662 - diff: 22.76mlTrain batch 12/31 - 237.5ms/batch - loss: 52.62343 - diff: 21.84mlTrain batch 13/31 - 235.9ms/batch - loss: 51.38445 - diff: 21.68mlTrain batch 14/31 - 237.3ms/batch - loss: 50.24845 - diff: 21.64mlTrain batch 15/31 - 236.2ms/batch - loss: 47.65176 - diff: 20.98mlTrain batch 16/31 - 237.2ms/batch - loss: 47.33626 - diff: 21.08mlTrain batch 17/31 - 236.5ms/batch - loss: 47.77112 - diff: 21.31mlTrain batch 18/31 - 237.3ms/batch - loss: 46.37340 - diff: 21.05mlTrain batch 19/31 - 236.2ms/batch - loss: 46.53880 - diff: 21.19mlTrain batch 20/31 - 236.9ms/batch - loss: 45.52222 - diff: 20.87mlTrain batch 21/31 - 236.5ms/batch - loss: 44.56647 - diff: 20.56mlTrain batch 22/31 - 237.5ms/batch - loss: 43.84345 - diff: 20.39mlTrain batch 23/31 - 236.3ms/batch - loss: 42.79081 - diff: 20.10mlTrain batch 24/31 - 237.4ms/batch - loss: 42.42374 - diff: 19.98mlTrain batch 25/31 - 239.3ms/batch - loss: 41.81148 - diff: 19.81mlTrain batch 26/31 - 237.1ms/batch - loss: 41.10897 - diff: 19.70mlTrain batch 27/31 - 237.0ms/batch - loss: 41.04869 - diff: 19.76mlTrain batch 28/31 - 236.2ms/batch - loss: 40.10989 - diff: 19.47mlTrain batch 29/31 - 236.6ms/batch - loss: 41.01385 - diff: 19.72mlTrain batch 30/31 - 236.6ms/batch - loss: 40.51863 - diff: 19.62mlTrain batch 31/31 - 124.0ms/batch - loss: 40.80406 - diff: 19.60mlTrain batch 31/31 - 11.2s 124.0ms/batch - loss: 40.80406 - diff: 19.60ml
Test 1.2s: val_loss: 54.32353 - diff: 22.13ml

Epoch 110: current best loss = 52.94235, at epoch 97
Train batch 1/31 - 236.2ms/batch - loss: 27.12313 - diff: 15.64mlTrain batch 2/31 - 237.2ms/batch - loss: 28.26322 - diff: 16.61mlTrain batch 3/31 - 236.3ms/batch - loss: 27.40389 - diff: 16.07mlTrain batch 4/31 - 239.0ms/batch - loss: 25.58354 - diff: 15.23mlTrain batch 5/31 - 236.2ms/batch - loss: 29.39388 - diff: 16.67mlTrain batch 6/31 - 237.7ms/batch - loss: 31.45309 - diff: 17.24mlTrain batch 7/31 - 236.6ms/batch - loss: 32.42477 - diff: 17.76mlTrain batch 8/31 - 237.6ms/batch - loss: 33.07315 - diff: 18.06mlTrain batch 9/31 - 236.4ms/batch - loss: 31.71124 - diff: 17.64mlTrain batch 10/31 - 237.3ms/batch - loss: 31.25747 - diff: 17.57mlTrain batch 11/31 - 236.9ms/batch - loss: 30.61827 - diff: 17.31mlTrain batch 12/31 - 237.6ms/batch - loss: 32.63078 - diff: 17.86mlTrain batch 13/31 - 236.1ms/batch - loss: 33.24513 - diff: 18.04mlTrain batch 14/31 - 237.7ms/batch - loss: 32.40979 - diff: 17.84mlTrain batch 15/31 - 236.3ms/batch - loss: 32.93334 - diff: 17.97mlTrain batch 16/31 - 237.3ms/batch - loss: 33.09978 - diff: 18.05mlTrain batch 17/31 - 236.4ms/batch - loss: 33.02813 - diff: 18.08mlTrain batch 18/31 - 237.7ms/batch - loss: 33.76154 - diff: 18.37mlTrain batch 19/31 - 236.4ms/batch - loss: 32.88093 - diff: 18.07mlTrain batch 20/31 - 237.5ms/batch - loss: 32.91182 - diff: 18.12mlTrain batch 21/31 - 236.6ms/batch - loss: 33.63600 - diff: 18.22mlTrain batch 22/31 - 237.4ms/batch - loss: 33.65455 - diff: 18.29mlTrain batch 23/31 - 236.6ms/batch - loss: 33.39028 - diff: 18.25mlTrain batch 24/31 - 237.6ms/batch - loss: 33.02014 - diff: 18.12mlTrain batch 25/31 - 236.2ms/batch - loss: 33.59797 - diff: 18.29mlTrain batch 26/31 - 237.4ms/batch - loss: 33.76946 - diff: 18.39mlTrain batch 27/31 - 238.9ms/batch - loss: 34.49239 - diff: 18.61mlTrain batch 28/31 - 237.5ms/batch - loss: 34.21874 - diff: 18.58mlTrain batch 29/31 - 236.6ms/batch - loss: 33.97579 - diff: 18.50mlTrain batch 30/31 - 237.3ms/batch - loss: 36.11680 - diff: 19.01mlTrain batch 31/31 - 122.9ms/batch - loss: 37.63551 - diff: 19.15mlTrain batch 31/31 - 11.7s 122.9ms/batch - loss: 37.63551 - diff: 19.15ml
Test 1.1s: val_loss: 59.66746 - diff: 21.52ml

Epoch 111: current best loss = 52.94235, at epoch 97
Train batch 1/31 - 236.2ms/batch - loss: 31.34931 - diff: 17.21mlTrain batch 2/31 - 237.5ms/batch - loss: 39.65958 - diff: 20.71mlTrain batch 3/31 - 236.4ms/batch - loss: 37.29969 - diff: 20.19mlTrain batch 4/31 - 236.4ms/batch - loss: 38.14111 - diff: 20.73mlTrain batch 5/31 - 237.0ms/batch - loss: 40.79832 - diff: 21.67mlTrain batch 6/31 - 236.2ms/batch - loss: 40.01689 - diff: 21.52mlTrain batch 7/31 - 237.3ms/batch - loss: 37.38816 - diff: 20.63mlTrain batch 8/31 - 236.5ms/batch - loss: 36.54793 - diff: 20.11mlTrain batch 9/31 - 237.5ms/batch - loss: 34.90691 - diff: 19.50mlTrain batch 10/31 - 236.6ms/batch - loss: 32.85324 - diff: 18.65mlTrain batch 11/31 - 236.8ms/batch - loss: 31.55292 - diff: 18.35mlTrain batch 12/31 - 236.5ms/batch - loss: 33.13740 - diff: 18.81mlTrain batch 13/31 - 237.6ms/batch - loss: 33.01784 - diff: 18.89mlTrain batch 14/31 - 236.8ms/batch - loss: 32.20750 - diff: 18.68mlTrain batch 15/31 - 237.4ms/batch - loss: 32.37738 - diff: 18.47mlTrain batch 16/31 - 236.5ms/batch - loss: 32.91242 - diff: 18.63mlTrain batch 17/31 - 237.7ms/batch - loss: 33.65570 - diff: 18.77mlTrain batch 18/31 - 236.7ms/batch - loss: 33.71074 - diff: 18.73mlTrain batch 19/31 - 237.6ms/batch - loss: 33.70156 - diff: 18.81mlTrain batch 20/31 - 236.6ms/batch - loss: 32.87997 - diff: 18.49mlTrain batch 21/31 - 237.5ms/batch - loss: 32.48385 - diff: 18.36mlTrain batch 22/31 - 236.3ms/batch - loss: 31.87886 - diff: 18.09mlTrain batch 23/31 - 237.5ms/batch - loss: 33.45446 - diff: 18.59mlTrain batch 24/31 - 236.6ms/batch - loss: 32.67307 - diff: 18.29mlTrain batch 25/31 - 237.2ms/batch - loss: 32.86323 - diff: 18.27mlTrain batch 26/31 - 236.3ms/batch - loss: 32.85981 - diff: 18.28mlTrain batch 27/31 - 237.4ms/batch - loss: 32.88409 - diff: 18.24mlTrain batch 28/31 - 236.3ms/batch - loss: 33.18453 - diff: 18.38mlTrain batch 29/31 - 237.0ms/batch - loss: 33.31407 - diff: 18.49mlTrain batch 30/31 - 236.4ms/batch - loss: 33.22717 - diff: 18.43mlTrain batch 31/31 - 123.6ms/batch - loss: 34.51837 - diff: 18.51mlTrain batch 31/31 - 11.3s 123.6ms/batch - loss: 34.51837 - diff: 18.51ml
Test 1.2s: val_loss: 54.04750 - diff: 21.71ml

Epoch 112: current best loss = 52.94235, at epoch 97
Train batch 1/31 - 236.1ms/batch - loss: 24.35139 - diff: 15.58mlTrain batch 2/31 - 236.1ms/batch - loss: 40.63947 - diff: 19.94mlTrain batch 3/31 - 235.6ms/batch - loss: 38.48327 - diff: 18.82mlTrain batch 4/31 - 236.8ms/batch - loss: 38.77900 - diff: 18.58mlTrain batch 5/31 - 236.1ms/batch - loss: 38.39640 - diff: 18.70mlTrain batch 6/31 - 237.3ms/batch - loss: 43.77545 - diff: 19.83mlTrain batch 7/31 - 235.9ms/batch - loss: 41.77675 - diff: 19.54mlTrain batch 8/31 - 236.7ms/batch - loss: 40.57213 - diff: 19.31mlTrain batch 9/31 - 236.5ms/batch - loss: 36.82670 - diff: 18.13mlTrain batch 10/31 - 237.2ms/batch - loss: 35.90947 - diff: 18.03mlTrain batch 11/31 - 236.3ms/batch - loss: 34.43581 - diff: 17.74mlTrain batch 12/31 - 236.2ms/batch - loss: 34.73989 - diff: 17.92mlTrain batch 13/31 - 236.0ms/batch - loss: 35.87741 - diff: 18.06mlTrain batch 14/31 - 236.3ms/batch - loss: 35.96344 - diff: 18.20mlTrain batch 15/31 - 236.4ms/batch - loss: 35.47532 - diff: 18.21mlTrain batch 16/31 - 236.3ms/batch - loss: 35.47318 - diff: 18.21mlTrain batch 17/31 - 237.2ms/batch - loss: 34.58472 - diff: 18.01mlTrain batch 18/31 - 238.7ms/batch - loss: 34.08392 - diff: 17.87mlTrain batch 19/31 - 237.7ms/batch - loss: 33.62339 - diff: 17.75mlTrain batch 20/31 - 236.1ms/batch - loss: 34.15360 - diff: 17.96mlTrain batch 21/31 - 237.3ms/batch - loss: 33.10720 - diff: 17.59mlTrain batch 22/31 - 236.5ms/batch - loss: 32.63891 - diff: 17.40mlTrain batch 23/31 - 237.3ms/batch - loss: 32.93713 - diff: 17.60mlTrain batch 24/31 - 236.4ms/batch - loss: 32.56056 - diff: 17.53mlTrain batch 25/31 - 237.4ms/batch - loss: 32.46205 - diff: 17.54mlTrain batch 26/31 - 236.3ms/batch - loss: 32.48508 - diff: 17.60mlTrain batch 27/31 - 237.6ms/batch - loss: 32.25269 - diff: 17.60mlTrain batch 28/31 - 236.1ms/batch - loss: 31.66665 - diff: 17.46mlTrain batch 29/31 - 236.8ms/batch - loss: 31.67089 - diff: 17.56mlTrain batch 30/31 - 236.3ms/batch - loss: 32.54141 - diff: 17.75mlTrain batch 31/31 - 122.3ms/batch - loss: 33.90460 - diff: 17.85mlTrain batch 31/31 - 11.5s 122.3ms/batch - loss: 33.90460 - diff: 17.85ml
Test 1.2s: val_loss: 58.92841 - diff: 22.02ml

Epoch 113: current best loss = 52.94235, at epoch 97
Train batch 1/31 - 236.4ms/batch - loss: 20.43611 - diff: 14.48mlTrain batch 2/31 - 237.5ms/batch - loss: 30.47161 - diff: 17.78mlTrain batch 3/31 - 236.2ms/batch - loss: 28.12042 - diff: 16.89mlTrain batch 4/31 - 236.9ms/batch - loss: 26.71875 - diff: 16.68mlTrain batch 5/31 - 235.9ms/batch - loss: 24.17126 - diff: 15.95mlTrain batch 6/31 - 236.8ms/batch - loss: 22.19158 - diff: 15.24mlTrain batch 7/31 - 236.9ms/batch - loss: 24.60210 - diff: 15.77mlTrain batch 8/31 - 236.6ms/batch - loss: 26.33371 - diff: 16.46mlTrain batch 9/31 - 236.9ms/batch - loss: 26.89992 - diff: 16.76mlTrain batch 10/31 - 236.6ms/batch - loss: 28.39434 - diff: 17.32mlTrain batch 11/31 - 236.7ms/batch - loss: 28.79133 - diff: 17.49mlTrain batch 12/31 - 236.0ms/batch - loss: 29.36065 - diff: 17.37mlTrain batch 13/31 - 236.6ms/batch - loss: 30.82188 - diff: 17.58mlTrain batch 14/31 - 236.5ms/batch - loss: 31.51169 - diff: 17.67mlTrain batch 15/31 - 237.2ms/batch - loss: 31.54849 - diff: 17.83mlTrain batch 16/31 - 236.5ms/batch - loss: 30.71504 - diff: 17.57mlTrain batch 17/31 - 237.4ms/batch - loss: 32.85786 - diff: 18.10mlTrain batch 18/31 - 236.4ms/batch - loss: 33.12985 - diff: 18.23mlTrain batch 19/31 - 237.3ms/batch - loss: 32.72095 - diff: 18.23mlTrain batch 20/31 - 236.6ms/batch - loss: 32.33226 - diff: 18.14mlTrain batch 21/31 - 237.2ms/batch - loss: 32.09037 - diff: 18.08mlTrain batch 22/31 - 236.2ms/batch - loss: 33.39714 - diff: 18.41mlTrain batch 23/31 - 237.0ms/batch - loss: 32.61395 - diff: 18.13mlTrain batch 24/31 - 236.5ms/batch - loss: 32.23188 - diff: 18.01mlTrain batch 25/31 - 237.2ms/batch - loss: 32.77815 - diff: 18.11mlTrain batch 26/31 - 236.4ms/batch - loss: 31.97710 - diff: 17.83mlTrain batch 27/31 - 237.2ms/batch - loss: 33.24773 - diff: 18.05mlTrain batch 28/31 - 236.2ms/batch - loss: 33.68808 - diff: 18.22mlTrain batch 29/31 - 237.6ms/batch - loss: 33.40287 - diff: 18.15mlTrain batch 30/31 - 236.4ms/batch - loss: 33.18120 - diff: 18.13mlTrain batch 31/31 - 123.6ms/batch - loss: 33.50119 - diff: 18.10mlTrain batch 31/31 - 11.1s 123.6ms/batch - loss: 33.50119 - diff: 18.10ml
Test 1.2s: val_loss: 61.05323 - diff: 22.31ml

Epoch 114: current best loss = 52.94235, at epoch 97
Train batch 1/31 - 236.1ms/batch - loss: 30.26679 - diff: 16.61mlTrain batch 2/31 - 237.0ms/batch - loss: 23.99324 - diff: 15.04mlTrain batch 3/31 - 236.3ms/batch - loss: 29.00874 - diff: 17.34mlTrain batch 4/31 - 237.3ms/batch - loss: 26.85669 - diff: 16.61mlTrain batch 5/31 - 236.7ms/batch - loss: 26.61511 - diff: 16.58mlTrain batch 6/31 - 237.7ms/batch - loss: 27.70503 - diff: 17.05mlTrain batch 7/31 - 236.4ms/batch - loss: 27.90693 - diff: 17.09mlTrain batch 8/31 - 237.5ms/batch - loss: 28.95202 - diff: 17.37mlTrain batch 9/31 - 236.1ms/batch - loss: 33.29233 - diff: 18.30mlTrain batch 10/31 - 237.6ms/batch - loss: 32.09696 - diff: 18.03mlTrain batch 11/31 - 236.5ms/batch - loss: 34.52137 - diff: 18.70mlTrain batch 12/31 - 237.5ms/batch - loss: 33.40385 - diff: 18.44mlTrain batch 13/31 - 236.4ms/batch - loss: 37.31993 - diff: 19.62mlTrain batch 14/31 - 237.7ms/batch - loss: 37.31001 - diff: 19.62mlTrain batch 15/31 - 236.1ms/batch - loss: 36.42362 - diff: 19.33mlTrain batch 16/31 - 237.4ms/batch - loss: 35.54501 - diff: 19.11mlTrain batch 17/31 - 236.5ms/batch - loss: 34.41497 - diff: 18.65mlTrain batch 18/31 - 237.9ms/batch - loss: 33.34290 - diff: 18.34mlTrain batch 19/31 - 236.4ms/batch - loss: 34.42680 - diff: 18.69mlTrain batch 20/31 - 237.4ms/batch - loss: 33.48883 - diff: 18.41mlTrain batch 21/31 - 236.4ms/batch - loss: 32.45050 - diff: 18.02mlTrain batch 22/31 - 237.8ms/batch - loss: 33.16146 - diff: 18.16mlTrain batch 23/31 - 236.4ms/batch - loss: 33.12080 - diff: 18.13mlTrain batch 24/31 - 237.3ms/batch - loss: 33.18748 - diff: 18.05mlTrain batch 25/31 - 236.3ms/batch - loss: 35.23127 - diff: 18.51mlTrain batch 26/31 - 237.5ms/batch - loss: 35.25571 - diff: 18.57mlTrain batch 27/31 - 236.6ms/batch - loss: 34.94555 - diff: 18.53mlTrain batch 28/31 - 237.4ms/batch - loss: 35.18310 - diff: 18.53mlTrain batch 29/31 - 236.2ms/batch - loss: 34.74295 - diff: 18.42mlTrain batch 30/31 - 237.2ms/batch - loss: 34.14576 - diff: 18.22mlTrain batch 31/31 - 123.8ms/batch - loss: 34.27772 - diff: 18.13mlTrain batch 31/31 - 11.6s 123.8ms/batch - loss: 34.27772 - diff: 18.13ml
Test 1.2s: val_loss: 55.11591 - diff: 22.50ml

Epoch 115: current best loss = 52.94235, at epoch 97
Train batch 1/31 - 236.7ms/batch - loss: 31.90422 - diff: 18.95mlTrain batch 2/31 - 237.4ms/batch - loss: 42.06726 - diff: 20.67mlTrain batch 3/31 - 236.3ms/batch - loss: 41.65830 - diff: 20.90mlTrain batch 4/31 - 236.9ms/batch - loss: 38.98930 - diff: 19.91mlTrain batch 5/31 - 235.8ms/batch - loss: 36.33881 - diff: 18.87mlTrain batch 6/31 - 237.4ms/batch - loss: 34.02407 - diff: 17.87mlTrain batch 7/31 - 236.7ms/batch - loss: 37.18737 - diff: 18.97mlTrain batch 8/31 - 237.2ms/batch - loss: 35.54898 - diff: 18.69mlTrain batch 9/31 - 236.4ms/batch - loss: 34.46896 - diff: 18.59mlTrain batch 10/31 - 237.5ms/batch - loss: 32.65407 - diff: 18.22mlTrain batch 11/31 - 236.4ms/batch - loss: 30.51890 - diff: 17.46mlTrain batch 12/31 - 237.1ms/batch - loss: 30.25565 - diff: 17.37mlTrain batch 13/31 - 236.3ms/batch - loss: 29.31176 - diff: 16.99mlTrain batch 14/31 - 236.8ms/batch - loss: 32.35795 - diff: 17.49mlTrain batch 15/31 - 237.6ms/batch - loss: 33.53953 - diff: 17.67mlTrain batch 16/31 - 237.4ms/batch - loss: 32.28795 - diff: 17.25mlTrain batch 17/31 - 236.2ms/batch - loss: 31.91679 - diff: 17.05mlTrain batch 18/31 - 236.9ms/batch - loss: 35.28013 - diff: 17.83mlTrain batch 19/31 - 236.4ms/batch - loss: 35.91734 - diff: 17.99mlTrain batch 20/31 - 237.6ms/batch - loss: 35.62230 - diff: 17.94mlTrain batch 21/31 - 236.0ms/batch - loss: 34.93688 - diff: 17.83mlTrain batch 22/31 - 236.6ms/batch - loss: 34.18798 - diff: 17.69mlTrain batch 23/31 - 236.6ms/batch - loss: 34.26213 - diff: 17.67mlTrain batch 24/31 - 241.7ms/batch - loss: 34.62724 - diff: 17.81mlTrain batch 25/31 - 236.5ms/batch - loss: 34.65382 - diff: 17.86mlTrain batch 26/31 - 237.5ms/batch - loss: 33.97421 - diff: 17.65mlTrain batch 27/31 - 236.3ms/batch - loss: 33.50318 - diff: 17.53mlTrain batch 28/31 - 236.9ms/batch - loss: 33.02044 - diff: 17.45mlTrain batch 29/31 - 235.7ms/batch - loss: 32.61249 - diff: 17.26mlTrain batch 30/31 - 237.3ms/batch - loss: 32.63026 - diff: 17.28mlTrain batch 31/31 - 123.8ms/batch - loss: 37.46474 - diff: 17.71mlTrain batch 31/31 - 11.8s 123.8ms/batch - loss: 37.46474 - diff: 17.71ml
Test 1.2s: val_loss: 53.45338 - diff: 21.56ml

Epoch 116: current best loss = 52.94235, at epoch 97
Train batch 1/31 - 236.2ms/batch - loss: 27.68625 - diff: 16.91mlTrain batch 2/31 - 236.4ms/batch - loss: 21.90557 - diff: 14.99mlTrain batch 3/31 - 236.1ms/batch - loss: 29.13047 - diff: 16.87mlTrain batch 4/31 - 237.2ms/batch - loss: 29.67205 - diff: 16.68mlTrain batch 5/31 - 236.5ms/batch - loss: 29.26027 - diff: 16.73mlTrain batch 6/31 - 236.4ms/batch - loss: 33.62103 - diff: 17.76mlTrain batch 7/31 - 237.2ms/batch - loss: 33.17894 - diff: 17.91mlTrain batch 8/31 - 236.3ms/batch - loss: 34.00820 - diff: 18.07mlTrain batch 9/31 - 237.1ms/batch - loss: 37.06921 - diff: 19.02mlTrain batch 10/31 - 236.2ms/batch - loss: 36.96216 - diff: 19.12mlTrain batch 11/31 - 236.8ms/batch - loss: 37.53595 - diff: 19.46mlTrain batch 12/31 - 236.1ms/batch - loss: 35.57518 - diff: 18.87mlTrain batch 13/31 - 237.5ms/batch - loss: 34.90863 - diff: 18.57mlTrain batch 14/31 - 236.1ms/batch - loss: 33.33121 - diff: 18.15mlTrain batch 15/31 - 237.2ms/batch - loss: 39.92933 - diff: 19.29mlTrain batch 16/31 - 236.5ms/batch - loss: 39.74303 - diff: 19.31mlTrain batch 17/31 - 237.1ms/batch - loss: 38.09238 - diff: 18.82mlTrain batch 18/31 - 236.3ms/batch - loss: 37.05147 - diff: 18.51mlTrain batch 19/31 - 237.1ms/batch - loss: 36.05790 - diff: 18.26mlTrain batch 20/31 - 236.2ms/batch - loss: 35.72505 - diff: 18.28mlTrain batch 21/31 - 237.0ms/batch - loss: 34.87180 - diff: 18.00mlTrain batch 22/31 - 236.9ms/batch - loss: 35.17456 - diff: 18.18mlTrain batch 23/31 - 237.3ms/batch - loss: 34.62167 - diff: 18.07mlTrain batch 24/31 - 236.3ms/batch - loss: 34.65771 - diff: 18.16mlTrain batch 25/31 - 237.1ms/batch - loss: 34.85289 - diff: 18.29mlTrain batch 26/31 - 236.8ms/batch - loss: 34.35898 - diff: 18.19mlTrain batch 27/31 - 237.4ms/batch - loss: 35.89152 - diff: 18.59mlTrain batch 28/31 - 236.4ms/batch - loss: 37.85867 - diff: 19.05mlTrain batch 29/31 - 237.3ms/batch - loss: 37.70171 - diff: 19.06mlTrain batch 30/31 - 236.6ms/batch - loss: 37.43471 - diff: 18.94mlTrain batch 31/31 - 123.3ms/batch - loss: 37.18381 - diff: 18.82mlTrain batch 31/31 - 11.2s 123.3ms/batch - loss: 37.18381 - diff: 18.82ml
Test 1.2s: val_loss: 56.74655 - diff: 22.06ml

Epoch 117: current best loss = 52.94235, at epoch 97
Train batch 1/31 - 236.5ms/batch - loss: 25.52944 - diff: 15.05mlTrain batch 2/31 - 237.3ms/batch - loss: 34.48708 - diff: 18.61mlTrain batch 3/31 - 236.2ms/batch - loss: 35.67346 - diff: 18.83mlTrain batch 4/31 - 237.1ms/batch - loss: 34.83991 - diff: 18.39mlTrain batch 5/31 - 236.5ms/batch - loss: 35.18199 - diff: 18.43mlTrain batch 6/31 - 237.3ms/batch - loss: 35.06206 - diff: 18.57mlTrain batch 7/31 - 236.7ms/batch - loss: 32.99445 - diff: 17.85mlTrain batch 8/31 - 236.3ms/batch - loss: 32.24137 - diff: 17.55mlTrain batch 9/31 - 236.2ms/batch - loss: 31.17313 - diff: 17.19mlTrain batch 10/31 - 237.4ms/batch - loss: 30.12809 - diff: 17.06mlTrain batch 11/31 - 236.7ms/batch - loss: 30.28097 - diff: 17.29mlTrain batch 12/31 - 237.4ms/batch - loss: 30.54262 - diff: 17.53mlTrain batch 13/31 - 237.0ms/batch - loss: 31.72808 - diff: 17.53mlTrain batch 14/31 - 237.2ms/batch - loss: 32.45597 - diff: 17.83mlTrain batch 15/31 - 236.2ms/batch - loss: 32.85343 - diff: 17.87mlTrain batch 16/31 - 237.1ms/batch - loss: 32.50468 - diff: 17.73mlTrain batch 17/31 - 237.1ms/batch - loss: 31.49904 - diff: 17.50mlTrain batch 18/31 - 237.5ms/batch - loss: 34.16660 - diff: 18.08mlTrain batch 19/31 - 236.4ms/batch - loss: 33.24783 - diff: 17.86mlTrain batch 20/31 - 236.6ms/batch - loss: 34.41313 - diff: 18.18mlTrain batch 21/31 - 236.9ms/batch - loss: 34.20448 - diff: 18.09mlTrain batch 22/31 - 237.0ms/batch - loss: 34.09879 - diff: 18.06mlTrain batch 23/31 - 236.7ms/batch - loss: 33.97740 - diff: 18.08mlTrain batch 24/31 - 237.1ms/batch - loss: 34.66575 - diff: 18.23mlTrain batch 25/31 - 236.7ms/batch - loss: 34.07878 - diff: 18.10mlTrain batch 26/31 - 237.2ms/batch - loss: 34.41327 - diff: 18.22mlTrain batch 27/31 - 236.5ms/batch - loss: 34.40989 - diff: 18.27mlTrain batch 28/31 - 237.3ms/batch - loss: 34.15754 - diff: 18.15mlTrain batch 29/31 - 236.0ms/batch - loss: 34.76051 - diff: 18.23mlTrain batch 30/31 - 237.2ms/batch - loss: 34.28933 - diff: 18.08mlTrain batch 31/31 - 123.7ms/batch - loss: 34.41650 - diff: 18.03mlTrain batch 31/31 - 11.1s 123.7ms/batch - loss: 34.41650 - diff: 18.03ml
Test 1.1s: val_loss: 63.50366 - diff: 23.89ml

Epoch 118: current best loss = 52.94235, at epoch 97
Train batch 1/31 - 236.7ms/batch - loss: 6.98996 - diff: 7.80mlTrain batch 2/31 - 237.3ms/batch - loss: 32.90661 - diff: 16.98mlTrain batch 3/31 - 236.4ms/batch - loss: 31.15213 - diff: 16.90mlTrain batch 4/31 - 237.2ms/batch - loss: 30.49105 - diff: 17.41mlTrain batch 5/31 - 236.6ms/batch - loss: 27.82305 - diff: 16.44mlTrain batch 6/31 - 237.1ms/batch - loss: 26.95989 - diff: 16.44mlTrain batch 7/31 - 236.6ms/batch - loss: 32.75268 - diff: 17.93mlTrain batch 8/31 - 237.5ms/batch - loss: 32.19314 - diff: 17.66mlTrain batch 9/31 - 236.3ms/batch - loss: 32.35716 - diff: 17.78mlTrain batch 10/31 - 236.9ms/batch - loss: 33.55969 - diff: 18.02mlTrain batch 11/31 - 236.3ms/batch - loss: 33.70479 - diff: 18.07mlTrain batch 12/31 - 237.4ms/batch - loss: 32.10455 - diff: 17.60mlTrain batch 13/31 - 236.6ms/batch - loss: 31.26403 - diff: 17.49mlTrain batch 14/31 - 236.5ms/batch - loss: 31.34172 - diff: 17.65mlTrain batch 15/31 - 236.5ms/batch - loss: 30.99452 - diff: 17.58mlTrain batch 16/31 - 237.2ms/batch - loss: 30.23239 - diff: 17.37mlTrain batch 17/31 - 236.3ms/batch - loss: 31.57467 - diff: 17.65mlTrain batch 18/31 - 237.3ms/batch - loss: 31.52304 - diff: 17.69mlTrain batch 19/31 - 237.1ms/batch - loss: 32.26269 - diff: 17.84mlTrain batch 20/31 - 237.1ms/batch - loss: 31.96580 - diff: 17.66mlTrain batch 21/31 - 236.6ms/batch - loss: 32.48435 - diff: 17.72mlTrain batch 22/31 - 236.3ms/batch - loss: 31.99412 - diff: 17.65mlTrain batch 23/31 - 237.9ms/batch - loss: 31.40758 - diff: 17.51mlTrain batch 24/31 - 236.8ms/batch - loss: 33.40860 - diff: 17.87mlTrain batch 25/31 - 237.6ms/batch - loss: 32.48412 - diff: 17.59mlTrain batch 26/31 - 236.4ms/batch - loss: 33.87713 - diff: 17.99mlTrain batch 27/31 - 237.2ms/batch - loss: 34.47752 - diff: 18.11mlTrain batch 28/31 - 236.4ms/batch - loss: 34.10519 - diff: 18.00mlTrain batch 29/31 - 237.1ms/batch - loss: 34.13990 - diff: 18.06mlTrain batch 30/31 - 236.0ms/batch - loss: 33.96679 - diff: 18.05mlTrain batch 31/31 - 123.3ms/batch - loss: 33.97227 - diff: 17.97mlTrain batch 31/31 - 11.6s 123.3ms/batch - loss: 33.97227 - diff: 17.97ml
Test 1.1s: val_loss: 61.96359 - diff: 24.11ml

Epoch 119: current best loss = 52.94235, at epoch 97
Train batch 1/31 - 236.1ms/batch - loss: 29.73647 - diff: 16.83mlTrain batch 2/31 - 236.6ms/batch - loss: 25.66364 - diff: 14.83mlTrain batch 3/31 - 235.9ms/batch - loss: 34.13487 - diff: 18.64mlTrain batch 4/31 - 237.6ms/batch - loss: 33.67864 - diff: 18.46mlTrain batch 5/31 - 236.2ms/batch - loss: 37.63364 - diff: 19.29mlTrain batch 6/31 - 237.6ms/batch - loss: 34.00005 - diff: 18.18mlTrain batch 7/31 - 236.1ms/batch - loss: 36.92143 - diff: 19.10mlTrain batch 8/31 - 237.1ms/batch - loss: 39.44485 - diff: 19.76mlTrain batch 9/31 - 236.4ms/batch - loss: 38.28290 - diff: 19.59mlTrain batch 10/31 - 237.2ms/batch - loss: 39.42807 - diff: 19.93mlTrain batch 11/31 - 236.3ms/batch - loss: 38.33474 - diff: 19.53mlTrain batch 12/31 - 240.7ms/batch - loss: 39.11211 - diff: 19.82mlTrain batch 13/31 - 237.6ms/batch - loss: 38.09802 - diff: 19.56mlTrain batch 14/31 - 236.8ms/batch - loss: 37.06333 - diff: 19.15mlTrain batch 15/31 - 237.8ms/batch - loss: 36.93426 - diff: 19.13mlTrain batch 16/31 - 236.8ms/batch - loss: 35.79091 - diff: 18.77mlTrain batch 17/31 - 237.3ms/batch - loss: 34.71385 - diff: 18.46mlTrain batch 18/31 - 236.0ms/batch - loss: 33.96497 - diff: 18.35mlTrain batch 19/31 - 237.4ms/batch - loss: 33.85925 - diff: 18.34mlTrain batch 20/31 - 236.2ms/batch - loss: 33.03056 - diff: 18.07mlTrain batch 21/31 - 237.6ms/batch - loss: 33.46195 - diff: 18.14mlTrain batch 22/31 - 236.5ms/batch - loss: 33.47084 - diff: 18.20mlTrain batch 23/31 - 237.3ms/batch - loss: 33.79571 - diff: 18.23mlTrain batch 24/31 - 236.5ms/batch - loss: 33.25586 - diff: 18.08mlTrain batch 25/31 - 237.5ms/batch - loss: 34.04424 - diff: 18.32mlTrain batch 26/31 - 238.6ms/batch - loss: 33.67102 - diff: 18.21mlTrain batch 27/31 - 237.5ms/batch - loss: 32.83006 - diff: 17.91mlTrain batch 28/31 - 236.5ms/batch - loss: 32.53582 - diff: 17.79mlTrain batch 29/31 - 237.4ms/batch - loss: 32.78866 - diff: 17.88mlTrain batch 30/31 - 236.4ms/batch - loss: 32.47954 - diff: 17.85mlTrain batch 31/31 - 123.3ms/batch - loss: 32.55049 - diff: 17.76mlTrain batch 31/31 - 11.7s 123.3ms/batch - loss: 32.55049 - diff: 17.76ml
Test 1.2s: val_loss: 67.67706 - diff: 24.97ml
Epoch   120: reducing learning rate of group 0 to 6.2500e-05.

Epoch 120: current best loss = 52.94235, at epoch 97
Train batch 1/31 - 236.0ms/batch - loss: 22.44573 - diff: 15.76mlTrain batch 2/31 - 236.0ms/batch - loss: 29.10516 - diff: 18.03mlTrain batch 3/31 - 236.2ms/batch - loss: 31.81747 - diff: 18.28mlTrain batch 4/31 - 237.0ms/batch - loss: 31.60473 - diff: 18.05mlTrain batch 5/31 - 236.1ms/batch - loss: 30.03522 - diff: 17.36mlTrain batch 6/31 - 237.3ms/batch - loss: 28.65768 - diff: 16.80mlTrain batch 7/31 - 236.3ms/batch - loss: 28.57006 - diff: 16.89mlTrain batch 8/31 - 237.5ms/batch - loss: 29.87485 - diff: 17.43mlTrain batch 9/31 - 236.3ms/batch - loss: 28.45388 - diff: 17.02mlTrain batch 10/31 - 238.1ms/batch - loss: 27.48678 - diff: 16.79mlTrain batch 11/31 - 236.2ms/batch - loss: 27.91548 - diff: 16.81mlTrain batch 12/31 - 237.1ms/batch - loss: 27.97907 - diff: 16.84mlTrain batch 13/31 - 236.6ms/batch - loss: 28.70572 - diff: 17.11mlTrain batch 14/31 - 237.0ms/batch - loss: 28.60754 - diff: 17.18mlTrain batch 15/31 - 236.3ms/batch - loss: 29.27801 - diff: 17.22mlTrain batch 16/31 - 237.6ms/batch - loss: 28.40140 - diff: 16.89mlTrain batch 17/31 - 236.7ms/batch - loss: 29.91881 - diff: 17.42mlTrain batch 18/31 - 237.1ms/batch - loss: 29.67003 - diff: 17.40mlTrain batch 19/31 - 236.1ms/batch - loss: 29.69619 - diff: 17.40mlTrain batch 20/31 - 237.5ms/batch - loss: 29.74439 - diff: 17.47mlTrain batch 21/31 - 238.6ms/batch - loss: 28.90266 - diff: 17.17mlTrain batch 22/31 - 237.6ms/batch - loss: 28.64618 - diff: 17.13mlTrain batch 23/31 - 236.2ms/batch - loss: 28.51374 - diff: 17.02mlTrain batch 24/31 - 236.7ms/batch - loss: 27.67846 - diff: 16.70mlTrain batch 25/31 - 237.0ms/batch - loss: 27.91224 - diff: 16.76mlTrain batch 26/31 - 237.4ms/batch - loss: 27.94525 - diff: 16.76mlTrain batch 27/31 - 236.5ms/batch - loss: 30.07043 - diff: 17.27mlTrain batch 28/31 - 237.5ms/batch - loss: 29.64574 - diff: 17.14mlTrain batch 29/31 - 236.7ms/batch - loss: 29.09993 - diff: 16.94mlTrain batch 30/31 - 237.4ms/batch - loss: 29.66999 - diff: 17.06mlTrain batch 31/31 - 123.9ms/batch - loss: 30.17548 - diff: 17.06mlTrain batch 31/31 - 11.5s 123.9ms/batch - loss: 30.17548 - diff: 17.06ml
Test 1.2s: val_loss: 57.71848 - diff: 21.46ml

Epoch 121: current best loss = 52.94235, at epoch 97
Train batch 1/31 - 236.5ms/batch - loss: 26.76192 - diff: 17.93mlTrain batch 2/31 - 237.4ms/batch - loss: 30.17416 - diff: 17.28mlTrain batch 3/31 - 236.1ms/batch - loss: 25.43218 - diff: 16.10mlTrain batch 4/31 - 237.5ms/batch - loss: 25.82492 - diff: 16.42mlTrain batch 5/31 - 236.4ms/batch - loss: 25.65768 - diff: 16.58mlTrain batch 6/31 - 237.9ms/batch - loss: 25.06151 - diff: 16.38mlTrain batch 7/31 - 236.8ms/batch - loss: 23.04106 - diff: 15.65mlTrain batch 8/31 - 237.5ms/batch - loss: 23.66396 - diff: 15.71mlTrain batch 9/31 - 236.4ms/batch - loss: 23.97851 - diff: 15.82mlTrain batch 10/31 - 237.1ms/batch - loss: 23.59914 - diff: 15.68mlTrain batch 11/31 - 236.1ms/batch - loss: 22.75889 - diff: 15.41mlTrain batch 12/31 - 237.3ms/batch - loss: 23.95438 - diff: 15.73mlTrain batch 13/31 - 236.3ms/batch - loss: 24.21861 - diff: 15.88mlTrain batch 14/31 - 236.5ms/batch - loss: 23.10395 - diff: 15.41mlTrain batch 15/31 - 237.5ms/batch - loss: 22.85196 - diff: 15.38mlTrain batch 16/31 - 235.6ms/batch - loss: 22.23711 - diff: 15.20mlTrain batch 17/31 - 237.5ms/batch - loss: 22.04150 - diff: 15.16mlTrain batch 18/31 - 236.1ms/batch - loss: 22.08041 - diff: 15.18mlTrain batch 19/31 - 237.5ms/batch - loss: 22.60340 - diff: 15.30mlTrain batch 20/31 - 236.6ms/batch - loss: 24.97349 - diff: 15.91mlTrain batch 21/31 - 237.0ms/batch - loss: 24.89981 - diff: 15.92mlTrain batch 22/31 - 236.4ms/batch - loss: 25.10928 - diff: 16.04mlTrain batch 23/31 - 237.9ms/batch - loss: 25.24636 - diff: 16.01mlTrain batch 24/31 - 236.4ms/batch - loss: 26.60422 - diff: 16.46mlTrain batch 25/31 - 237.4ms/batch - loss: 26.12452 - diff: 16.31mlTrain batch 26/31 - 236.7ms/batch - loss: 25.76781 - diff: 16.23mlTrain batch 27/31 - 236.5ms/batch - loss: 25.60306 - diff: 16.20mlTrain batch 28/31 - 236.8ms/batch - loss: 25.17255 - diff: 16.08mlTrain batch 29/31 - 237.2ms/batch - loss: 26.55621 - diff: 16.35mlTrain batch 30/31 - 236.4ms/batch - loss: 26.74585 - diff: 16.28mlTrain batch 31/31 - 123.3ms/batch - loss: 27.48379 - diff: 16.29mlTrain batch 31/31 - 11.8s 123.3ms/batch - loss: 27.48379 - diff: 16.29ml
Test 1.1s: val_loss: 57.47708 - diff: 21.92ml

Epoch 122: current best loss = 52.94235, at epoch 97
Train batch 1/31 - 236.2ms/batch - loss: 22.10911 - diff: 15.66mlTrain batch 2/31 - 237.2ms/batch - loss: 19.44835 - diff: 14.79mlTrain batch 3/31 - 236.5ms/batch - loss: 21.03493 - diff: 15.53mlTrain batch 4/31 - 236.5ms/batch - loss: 21.38474 - diff: 14.99mlTrain batch 5/31 - 237.2ms/batch - loss: 22.06105 - diff: 15.52mlTrain batch 6/31 - 236.6ms/batch - loss: 25.17327 - diff: 16.55mlTrain batch 7/31 - 235.7ms/batch - loss: 25.60118 - diff: 16.85mlTrain batch 8/31 - 235.8ms/batch - loss: 27.46748 - diff: 17.47mlTrain batch 9/31 - 237.2ms/batch - loss: 29.46829 - diff: 17.68mlTrain batch 10/31 - 236.0ms/batch - loss: 28.69006 - diff: 17.32mlTrain batch 11/31 - 237.7ms/batch - loss: 28.36889 - diff: 17.42mlTrain batch 12/31 - 238.1ms/batch - loss: 29.61367 - diff: 17.40mlTrain batch 13/31 - 236.7ms/batch - loss: 28.90298 - diff: 17.12mlTrain batch 14/31 - 236.5ms/batch - loss: 30.18082 - diff: 17.21mlTrain batch 15/31 - 237.1ms/batch - loss: 29.54321 - diff: 16.99mlTrain batch 16/31 - 236.4ms/batch - loss: 28.84444 - diff: 16.76mlTrain batch 17/31 - 237.0ms/batch - loss: 28.95466 - diff: 16.69mlTrain batch 18/31 - 236.3ms/batch - loss: 28.21434 - diff: 16.40mlTrain batch 19/31 - 237.2ms/batch - loss: 27.88463 - diff: 16.37mlTrain batch 20/31 - 236.1ms/batch - loss: 27.05389 - diff: 16.06mlTrain batch 21/31 - 237.1ms/batch - loss: 27.03658 - diff: 16.13mlTrain batch 22/31 - 236.5ms/batch - loss: 26.73981 - diff: 15.97mlTrain batch 23/31 - 237.5ms/batch - loss: 27.00267 - diff: 16.05mlTrain batch 24/31 - 236.2ms/batch - loss: 27.35468 - diff: 16.16mlTrain batch 25/31 - 237.6ms/batch - loss: 28.04377 - diff: 16.11mlTrain batch 26/31 - 236.1ms/batch - loss: 28.38323 - diff: 16.22mlTrain batch 27/31 - 237.8ms/batch - loss: 27.71153 - diff: 16.02mlTrain batch 28/31 - 236.7ms/batch - loss: 28.52228 - diff: 16.14mlTrain batch 29/31 - 237.6ms/batch - loss: 28.14584 - diff: 16.07mlTrain batch 30/31 - 236.3ms/batch - loss: 28.23108 - diff: 16.18mlTrain batch 31/31 - 123.9ms/batch - loss: 29.32217 - diff: 16.26mlTrain batch 31/31 - 12.5s 123.9ms/batch - loss: 29.32217 - diff: 16.26ml
Test 1.2s: val_loss: 57.66500 - diff: 21.85ml

Epoch 123: current best loss = 52.94235, at epoch 97
Train batch 1/31 - 235.9ms/batch - loss: 41.16190 - diff: 21.93mlTrain batch 2/31 - 236.8ms/batch - loss: 33.34149 - diff: 18.85mlTrain batch 3/31 - 235.9ms/batch - loss: 37.94604 - diff: 19.19mlTrain batch 4/31 - 236.4ms/batch - loss: 34.08176 - diff: 18.09mlTrain batch 5/31 - 235.9ms/batch - loss: 29.82357 - diff: 16.64mlTrain batch 6/31 - 237.6ms/batch - loss: 27.87943 - diff: 16.25mlTrain batch 7/31 - 236.3ms/batch - loss: 28.88884 - diff: 16.79mlTrain batch 8/31 - 237.2ms/batch - loss: 29.51349 - diff: 16.87mlTrain batch 9/31 - 244.9ms/batch - loss: 29.18848 - diff: 16.80mlTrain batch 10/31 - 237.2ms/batch - loss: 28.33731 - diff: 16.56mlTrain batch 11/31 - 236.1ms/batch - loss: 27.69451 - diff: 16.42mlTrain batch 12/31 - 237.3ms/batch - loss: 32.39706 - diff: 17.31mlTrain batch 13/31 - 236.2ms/batch - loss: 32.31695 - diff: 17.43mlTrain batch 14/31 - 237.4ms/batch - loss: 31.19004 - diff: 17.16mlTrain batch 15/31 - 236.4ms/batch - loss: 30.36841 - diff: 16.99mlTrain batch 16/31 - 237.4ms/batch - loss: 29.51422 - diff: 16.80mlTrain batch 17/31 - 235.9ms/batch - loss: 29.52075 - diff: 16.85mlTrain batch 18/31 - 237.5ms/batch - loss: 30.01982 - diff: 16.90mlTrain batch 19/31 - 236.1ms/batch - loss: 31.55773 - diff: 17.43mlTrain batch 20/31 - 236.2ms/batch - loss: 30.34954 - diff: 16.98mlTrain batch 21/31 - 236.2ms/batch - loss: 30.14303 - diff: 16.93mlTrain batch 22/31 - 236.8ms/batch - loss: 29.90858 - diff: 16.96mlTrain batch 23/31 - 236.0ms/batch - loss: 29.86905 - diff: 17.02mlTrain batch 24/31 - 236.9ms/batch - loss: 30.03619 - diff: 17.03mlTrain batch 25/31 - 236.7ms/batch - loss: 30.00465 - diff: 17.09mlTrain batch 26/31 - 237.0ms/batch - loss: 29.79849 - diff: 17.03mlTrain batch 27/31 - 236.2ms/batch - loss: 29.35543 - diff: 16.88mlTrain batch 28/31 - 237.5ms/batch - loss: 29.36244 - diff: 16.94mlTrain batch 29/31 - 236.3ms/batch - loss: 29.70844 - diff: 17.08mlTrain batch 30/31 - 236.7ms/batch - loss: 29.64415 - diff: 17.13mlTrain batch 31/31 - 123.6ms/batch - loss: 33.42402 - diff: 17.41mlTrain batch 31/31 - 11.7s 123.6ms/batch - loss: 33.42402 - diff: 17.41ml
Test 1.2s: val_loss: 54.46398 - diff: 22.51ml

Epoch 124: current best loss = 52.94235, at epoch 97
Train batch 1/31 - 236.3ms/batch - loss: 27.29943 - diff: 15.58mlTrain batch 2/31 - 237.0ms/batch - loss: 21.50672 - diff: 14.76mlTrain batch 3/31 - 235.9ms/batch - loss: 20.28974 - diff: 14.72mlTrain batch 4/31 - 237.3ms/batch - loss: 24.66808 - diff: 16.07mlTrain batch 5/31 - 236.3ms/batch - loss: 31.63151 - diff: 17.52mlTrain batch 6/31 - 236.8ms/batch - loss: 30.16296 - diff: 17.27mlTrain batch 7/31 - 236.3ms/batch - loss: 31.01657 - diff: 17.55mlTrain batch 8/31 - 237.0ms/batch - loss: 27.83198 - diff: 16.30mlTrain batch 9/31 - 236.3ms/batch - loss: 27.19827 - diff: 15.92mlTrain batch 10/31 - 237.1ms/batch - loss: 28.64653 - diff: 16.40mlTrain batch 11/31 - 236.6ms/batch - loss: 28.74335 - diff: 16.58mlTrain batch 12/31 - 237.0ms/batch - loss: 27.65859 - diff: 16.23mlTrain batch 13/31 - 236.4ms/batch - loss: 27.08938 - diff: 16.03mlTrain batch 14/31 - 237.3ms/batch - loss: 26.27722 - diff: 15.81mlTrain batch 15/31 - 236.6ms/batch - loss: 25.85533 - diff: 15.75mlTrain batch 16/31 - 237.6ms/batch - loss: 28.23059 - diff: 16.21mlTrain batch 17/31 - 236.6ms/batch - loss: 28.05441 - diff: 16.28mlTrain batch 18/31 - 237.4ms/batch - loss: 27.77631 - diff: 16.16mlTrain batch 19/31 - 236.2ms/batch - loss: 27.78830 - diff: 16.09mlTrain batch 20/31 - 237.4ms/batch - loss: 26.91283 - diff: 15.83mlTrain batch 21/31 - 236.1ms/batch - loss: 26.87848 - diff: 15.82mlTrain batch 22/31 - 237.7ms/batch - loss: 26.87176 - diff: 15.82mlTrain batch 23/31 - 236.2ms/batch - loss: 26.48212 - diff: 15.73mlTrain batch 24/31 - 237.1ms/batch - loss: 26.04281 - diff: 15.62mlTrain batch 25/31 - 236.2ms/batch - loss: 25.83341 - diff: 15.56mlTrain batch 26/31 - 237.5ms/batch - loss: 26.13053 - diff: 15.65mlTrain batch 27/31 - 236.5ms/batch - loss: 26.19119 - diff: 15.66mlTrain batch 28/31 - 237.6ms/batch - loss: 25.89455 - diff: 15.63mlTrain batch 29/31 - 236.5ms/batch - loss: 25.44002 - diff: 15.51mlTrain batch 30/31 - 237.4ms/batch - loss: 25.35658 - diff: 15.51mlTrain batch 31/31 - 123.3ms/batch - loss: 25.62853 - diff: 15.51mlTrain batch 31/31 - 10.7s 123.3ms/batch - loss: 25.62853 - diff: 15.51ml
Test 1.2s: val_loss: 52.29484 - diff: 21.94ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_WideResNet50_0_Adam-0.001_MSE_DA3_best

Epoch 125: current best loss = 52.29484, at epoch 124
Train batch 1/31 - 235.8ms/batch - loss: 30.05647 - diff: 18.39mlTrain batch 2/31 - 236.6ms/batch - loss: 21.64616 - diff: 15.19mlTrain batch 3/31 - 236.0ms/batch - loss: 20.34421 - diff: 14.55mlTrain batch 4/31 - 239.2ms/batch - loss: 21.75795 - diff: 15.22mlTrain batch 5/31 - 236.1ms/batch - loss: 28.19221 - diff: 16.85mlTrain batch 6/31 - 236.8ms/batch - loss: 29.02514 - diff: 17.07mlTrain batch 7/31 - 236.0ms/batch - loss: 29.16269 - diff: 17.16mlTrain batch 8/31 - 237.3ms/batch - loss: 27.75512 - diff: 16.63mlTrain batch 9/31 - 237.3ms/batch - loss: 27.32265 - diff: 16.61mlTrain batch 10/31 - 238.1ms/batch - loss: 26.51080 - diff: 16.39mlTrain batch 11/31 - 236.2ms/batch - loss: 26.63825 - diff: 16.41mlTrain batch 12/31 - 237.8ms/batch - loss: 27.03245 - diff: 16.40mlTrain batch 13/31 - 235.9ms/batch - loss: 28.18004 - diff: 16.88mlTrain batch 14/31 - 236.4ms/batch - loss: 27.90922 - diff: 16.84mlTrain batch 15/31 - 236.2ms/batch - loss: 27.92655 - diff: 16.86mlTrain batch 16/31 - 237.2ms/batch - loss: 27.80918 - diff: 16.85mlTrain batch 17/31 - 236.7ms/batch - loss: 29.98397 - diff: 17.44mlTrain batch 18/31 - 237.2ms/batch - loss: 30.10097 - diff: 17.54mlTrain batch 19/31 - 236.2ms/batch - loss: 29.45223 - diff: 17.30mlTrain batch 20/31 - 236.8ms/batch - loss: 29.38347 - diff: 17.36mlTrain batch 21/31 - 236.5ms/batch - loss: 29.26523 - diff: 17.26mlTrain batch 22/31 - 237.2ms/batch - loss: 28.85385 - diff: 17.21mlTrain batch 23/31 - 236.3ms/batch - loss: 28.30838 - diff: 17.04mlTrain batch 24/31 - 237.4ms/batch - loss: 28.31943 - diff: 16.91mlTrain batch 25/31 - 236.1ms/batch - loss: 28.68516 - diff: 17.01mlTrain batch 26/31 - 237.3ms/batch - loss: 28.10962 - diff: 16.81mlTrain batch 27/31 - 236.3ms/batch - loss: 27.53656 - diff: 16.59mlTrain batch 28/31 - 237.3ms/batch - loss: 28.70399 - diff: 16.94mlTrain batch 29/31 - 236.3ms/batch - loss: 29.11056 - diff: 17.11mlTrain batch 30/31 - 237.1ms/batch - loss: 28.79733 - diff: 17.04mlTrain batch 31/31 - 124.0ms/batch - loss: 29.17918 - diff: 17.01mlTrain batch 31/31 - 11.3s 124.0ms/batch - loss: 29.17918 - diff: 17.01ml
Test 1.2s: val_loss: 54.95136 - diff: 21.94ml

Epoch 126: current best loss = 52.29484, at epoch 124
Train batch 1/31 - 236.1ms/batch - loss: 38.63106 - diff: 21.30mlTrain batch 2/31 - 236.7ms/batch - loss: 41.39632 - diff: 20.62mlTrain batch 3/31 - 236.2ms/batch - loss: 35.95903 - diff: 18.75mlTrain batch 4/31 - 236.3ms/batch - loss: 31.01802 - diff: 17.27mlTrain batch 5/31 - 236.4ms/batch - loss: 30.98665 - diff: 17.42mlTrain batch 6/31 - 237.3ms/batch - loss: 31.28342 - diff: 17.33mlTrain batch 7/31 - 236.0ms/batch - loss: 27.92685 - diff: 16.27mlTrain batch 8/31 - 237.2ms/batch - loss: 28.87257 - diff: 16.73mlTrain batch 9/31 - 236.5ms/batch - loss: 27.01114 - diff: 16.18mlTrain batch 10/31 - 237.3ms/batch - loss: 26.42985 - diff: 16.03mlTrain batch 11/31 - 236.1ms/batch - loss: 26.13675 - diff: 16.04mlTrain batch 12/31 - 237.3ms/batch - loss: 24.58122 - diff: 15.52mlTrain batch 13/31 - 236.4ms/batch - loss: 24.24749 - diff: 15.45mlTrain batch 14/31 - 237.2ms/batch - loss: 23.64730 - diff: 15.33mlTrain batch 15/31 - 236.4ms/batch - loss: 23.38960 - diff: 15.23mlTrain batch 16/31 - 237.4ms/batch - loss: 22.67194 - diff: 14.88mlTrain batch 17/31 - 236.3ms/batch - loss: 22.82120 - diff: 15.03mlTrain batch 18/31 - 237.8ms/batch - loss: 23.12794 - diff: 15.11mlTrain batch 19/31 - 236.4ms/batch - loss: 23.55612 - diff: 15.36mlTrain batch 20/31 - 237.7ms/batch - loss: 23.71774 - diff: 15.32mlTrain batch 21/31 - 236.2ms/batch - loss: 23.69198 - diff: 15.30mlTrain batch 22/31 - 237.9ms/batch - loss: 23.78781 - diff: 15.37mlTrain batch 23/31 - 236.2ms/batch - loss: 23.60016 - diff: 15.32mlTrain batch 24/31 - 236.6ms/batch - loss: 24.11545 - diff: 15.56mlTrain batch 25/31 - 236.3ms/batch - loss: 24.53555 - diff: 15.58mlTrain batch 26/31 - 237.0ms/batch - loss: 25.56463 - diff: 15.90mlTrain batch 27/31 - 236.3ms/batch - loss: 25.89194 - diff: 16.02mlTrain batch 28/31 - 237.5ms/batch - loss: 25.75668 - diff: 15.97mlTrain batch 29/31 - 236.3ms/batch - loss: 25.29434 - diff: 15.78mlTrain batch 30/31 - 236.9ms/batch - loss: 25.12735 - diff: 15.73mlTrain batch 31/31 - 123.3ms/batch - loss: 26.10248 - diff: 15.79mlTrain batch 31/31 - 11.4s 123.3ms/batch - loss: 26.10248 - diff: 15.79ml
Test 1.2s: val_loss: 52.34590 - diff: 21.30ml

Epoch 127: current best loss = 52.29484, at epoch 124
Train batch 1/31 - 236.4ms/batch - loss: 34.58468 - diff: 18.92mlTrain batch 2/31 - 237.3ms/batch - loss: 26.95896 - diff: 15.67mlTrain batch 3/31 - 236.2ms/batch - loss: 24.44744 - diff: 14.91mlTrain batch 4/31 - 237.5ms/batch - loss: 22.42121 - diff: 14.50mlTrain batch 5/31 - 237.8ms/batch - loss: 23.26744 - diff: 14.96mlTrain batch 6/31 - 236.7ms/batch - loss: 25.76012 - diff: 15.07mlTrain batch 7/31 - 236.4ms/batch - loss: 25.74519 - diff: 15.01mlTrain batch 8/31 - 237.4ms/batch - loss: 24.67946 - diff: 14.97mlTrain batch 9/31 - 236.2ms/batch - loss: 24.10211 - diff: 14.98mlTrain batch 10/31 - 237.0ms/batch - loss: 23.86394 - diff: 14.75mlTrain batch 11/31 - 236.1ms/batch - loss: 23.53734 - diff: 14.73mlTrain batch 12/31 - 238.0ms/batch - loss: 23.47963 - diff: 14.85mlTrain batch 13/31 - 236.3ms/batch - loss: 23.41026 - diff: 14.81mlTrain batch 14/31 - 237.2ms/batch - loss: 22.80186 - diff: 14.65mlTrain batch 15/31 - 236.4ms/batch - loss: 23.72031 - diff: 14.74mlTrain batch 16/31 - 237.1ms/batch - loss: 24.18526 - diff: 14.94mlTrain batch 17/31 - 236.4ms/batch - loss: 24.58351 - diff: 15.14mlTrain batch 18/31 - 237.8ms/batch - loss: 25.71119 - diff: 15.38mlTrain batch 19/31 - 235.9ms/batch - loss: 25.13078 - diff: 15.24mlTrain batch 20/31 - 236.6ms/batch - loss: 25.91720 - diff: 15.48mlTrain batch 21/31 - 235.9ms/batch - loss: 25.42951 - diff: 15.37mlTrain batch 22/31 - 237.6ms/batch - loss: 24.69238 - diff: 15.12mlTrain batch 23/31 - 236.5ms/batch - loss: 24.23168 - diff: 15.02mlTrain batch 24/31 - 236.9ms/batch - loss: 24.36574 - diff: 15.07mlTrain batch 25/31 - 236.1ms/batch - loss: 25.47048 - diff: 15.37mlTrain batch 26/31 - 236.9ms/batch - loss: 25.85576 - diff: 15.41mlTrain batch 27/31 - 235.9ms/batch - loss: 25.62002 - diff: 15.37mlTrain batch 28/31 - 237.2ms/batch - loss: 25.13052 - diff: 15.20mlTrain batch 29/31 - 235.9ms/batch - loss: 27.16289 - diff: 15.74mlTrain batch 30/31 - 237.2ms/batch - loss: 26.98578 - diff: 15.68mlTrain batch 31/31 - 124.0ms/batch - loss: 27.28556 - diff: 15.70mlTrain batch 31/31 - 11.3s 124.0ms/batch - loss: 27.28556 - diff: 15.70ml
Test 1.2s: val_loss: 58.02754 - diff: 22.73ml

Epoch 128: current best loss = 52.29484, at epoch 124
Train batch 1/31 - 236.3ms/batch - loss: 14.32217 - diff: 12.62mlTrain batch 2/31 - 238.6ms/batch - loss: 17.17065 - diff: 13.07mlTrain batch 3/31 - 238.4ms/batch - loss: 27.55212 - diff: 16.52mlTrain batch 4/31 - 237.3ms/batch - loss: 37.62725 - diff: 19.05mlTrain batch 5/31 - 236.3ms/batch - loss: 37.07270 - diff: 19.04mlTrain batch 6/31 - 237.4ms/batch - loss: 33.82076 - diff: 18.34mlTrain batch 7/31 - 236.4ms/batch - loss: 32.88917 - diff: 18.28mlTrain batch 8/31 - 237.5ms/batch - loss: 32.61777 - diff: 18.19mlTrain batch 9/31 - 235.9ms/batch - loss: 31.39064 - diff: 17.71mlTrain batch 10/31 - 237.2ms/batch - loss: 29.53340 - diff: 17.08mlTrain batch 11/31 - 236.4ms/batch - loss: 29.66918 - diff: 17.17mlTrain batch 12/31 - 236.7ms/batch - loss: 29.17195 - diff: 17.01mlTrain batch 13/31 - 236.3ms/batch - loss: 27.93388 - diff: 16.63mlTrain batch 14/31 - 237.3ms/batch - loss: 27.54966 - diff: 16.48mlTrain batch 15/31 - 236.3ms/batch - loss: 28.56566 - diff: 16.94mlTrain batch 16/31 - 236.9ms/batch - loss: 28.96964 - diff: 17.04mlTrain batch 17/31 - 236.4ms/batch - loss: 29.24832 - diff: 17.16mlTrain batch 18/31 - 237.3ms/batch - loss: 29.97259 - diff: 17.31mlTrain batch 19/31 - 236.7ms/batch - loss: 29.15297 - diff: 17.06mlTrain batch 20/31 - 237.5ms/batch - loss: 29.08635 - diff: 17.08mlTrain batch 21/31 - 236.5ms/batch - loss: 29.73585 - diff: 17.21mlTrain batch 22/31 - 237.4ms/batch - loss: 29.06541 - diff: 17.03mlTrain batch 23/31 - 236.1ms/batch - loss: 28.57136 - diff: 16.93mlTrain batch 24/31 - 236.9ms/batch - loss: 28.67092 - diff: 16.89mlTrain batch 25/31 - 236.3ms/batch - loss: 28.53055 - diff: 16.92mlTrain batch 26/31 - 237.2ms/batch - loss: 28.16094 - diff: 16.80mlTrain batch 27/31 - 236.3ms/batch - loss: 27.96739 - diff: 16.67mlTrain batch 28/31 - 237.2ms/batch - loss: 28.13267 - diff: 16.81mlTrain batch 29/31 - 236.3ms/batch - loss: 28.08393 - diff: 16.74mlTrain batch 30/31 - 237.7ms/batch - loss: 28.04977 - diff: 16.77mlTrain batch 31/31 - 124.0ms/batch - loss: 28.61813 - diff: 16.75mlTrain batch 31/31 - 11.1s 124.0ms/batch - loss: 28.61813 - diff: 16.75ml
Test 1.1s: val_loss: 54.32920 - diff: 21.87ml

Epoch 129: current best loss = 52.29484, at epoch 124
Train batch 1/31 - 236.5ms/batch - loss: 19.42294 - diff: 14.54mlTrain batch 2/31 - 237.3ms/batch - loss: 26.16240 - diff: 15.89mlTrain batch 3/31 - 236.3ms/batch - loss: 31.27059 - diff: 17.38mlTrain batch 4/31 - 237.5ms/batch - loss: 29.83703 - diff: 17.09mlTrain batch 5/31 - 236.1ms/batch - loss: 28.47746 - diff: 16.91mlTrain batch 6/31 - 238.3ms/batch - loss: 27.57591 - diff: 16.84mlTrain batch 7/31 - 238.8ms/batch - loss: 24.94944 - diff: 16.03mlTrain batch 8/31 - 237.5ms/batch - loss: 25.61561 - diff: 16.39mlTrain batch 9/31 - 236.2ms/batch - loss: 24.80459 - diff: 16.20mlTrain batch 10/31 - 237.4ms/batch - loss: 24.42526 - diff: 16.13mlTrain batch 11/31 - 238.3ms/batch - loss: 24.14403 - diff: 15.98mlTrain batch 12/31 - 237.4ms/batch - loss: 23.51332 - diff: 15.64mlTrain batch 13/31 - 236.1ms/batch - loss: 23.15388 - diff: 15.47mlTrain batch 14/31 - 235.2ms/batch - loss: 22.78433 - diff: 15.43mlTrain batch 15/31 - 236.1ms/batch - loss: 23.11120 - diff: 15.54mlTrain batch 16/31 - 237.4ms/batch - loss: 23.03402 - diff: 15.53mlTrain batch 17/31 - 236.1ms/batch - loss: 23.41411 - diff: 15.59mlTrain batch 18/31 - 236.8ms/batch - loss: 23.55199 - diff: 15.58mlTrain batch 19/31 - 236.7ms/batch - loss: 24.97387 - diff: 15.93mlTrain batch 20/31 - 236.6ms/batch - loss: 24.78903 - diff: 15.86mlTrain batch 21/31 - 236.5ms/batch - loss: 24.70216 - diff: 15.78mlTrain batch 22/31 - 237.1ms/batch - loss: 25.68831 - diff: 16.05mlTrain batch 23/31 - 236.1ms/batch - loss: 25.57439 - diff: 16.00mlTrain batch 24/31 - 237.2ms/batch - loss: 24.73386 - diff: 15.64mlTrain batch 25/31 - 236.2ms/batch - loss: 25.01620 - diff: 15.78mlTrain batch 26/31 - 237.4ms/batch - loss: 24.92738 - diff: 15.73mlTrain batch 27/31 - 236.5ms/batch - loss: 24.48291 - diff: 15.60mlTrain batch 28/31 - 237.5ms/batch - loss: 24.49202 - diff: 15.52mlTrain batch 29/31 - 236.1ms/batch - loss: 24.22533 - diff: 15.46mlTrain batch 30/31 - 237.3ms/batch - loss: 24.01736 - diff: 15.40mlTrain batch 31/31 - 121.2ms/batch - loss: 24.49700 - diff: 15.40mlTrain batch 31/31 - 12.2s 121.2ms/batch - loss: 24.49700 - diff: 15.40ml
Test 1.1s: val_loss: 53.75399 - diff: 21.47ml

Epoch 130: current best loss = 52.29484, at epoch 124
Train batch 1/31 - 236.1ms/batch - loss: 14.58273 - diff: 11.50mlTrain batch 2/31 - 237.2ms/batch - loss: 15.79770 - diff: 12.91mlTrain batch 3/31 - 236.6ms/batch - loss: 20.36997 - diff: 14.48mlTrain batch 4/31 - 237.1ms/batch - loss: 19.04688 - diff: 14.04mlTrain batch 5/31 - 236.4ms/batch - loss: 24.02166 - diff: 14.80mlTrain batch 6/31 - 237.0ms/batch - loss: 22.90046 - diff: 14.71mlTrain batch 7/31 - 236.0ms/batch - loss: 23.11239 - diff: 15.05mlTrain batch 8/31 - 237.8ms/batch - loss: 21.19386 - diff: 14.17mlTrain batch 9/31 - 236.3ms/batch - loss: 20.29829 - diff: 13.84mlTrain batch 10/31 - 237.2ms/batch - loss: 20.38227 - diff: 13.82mlTrain batch 11/31 - 236.3ms/batch - loss: 20.43703 - diff: 13.93mlTrain batch 12/31 - 237.6ms/batch - loss: 22.42238 - diff: 14.62mlTrain batch 13/31 - 236.4ms/batch - loss: 21.66941 - diff: 14.45mlTrain batch 14/31 - 237.0ms/batch - loss: 22.47361 - diff: 14.72mlTrain batch 15/31 - 236.4ms/batch - loss: 22.07563 - diff: 14.70mlTrain batch 16/31 - 239.5ms/batch - loss: 21.62241 - diff: 14.55mlTrain batch 17/31 - 236.3ms/batch - loss: 21.62465 - diff: 14.64mlTrain batch 18/31 - 237.3ms/batch - loss: 21.70680 - diff: 14.64mlTrain batch 19/31 - 236.3ms/batch - loss: 22.31827 - diff: 14.80mlTrain batch 20/31 - 237.6ms/batch - loss: 22.40739 - diff: 14.86mlTrain batch 21/31 - 235.8ms/batch - loss: 22.35761 - diff: 14.87mlTrain batch 22/31 - 237.4ms/batch - loss: 22.30617 - diff: 14.88mlTrain batch 23/31 - 236.4ms/batch - loss: 22.34530 - diff: 14.95mlTrain batch 24/31 - 237.4ms/batch - loss: 24.03192 - diff: 15.36mlTrain batch 25/31 - 237.2ms/batch - loss: 23.55396 - diff: 15.19mlTrain batch 26/31 - 237.1ms/batch - loss: 23.93885 - diff: 15.30mlTrain batch 27/31 - 236.3ms/batch - loss: 24.34237 - diff: 15.36mlTrain batch 28/31 - 237.5ms/batch - loss: 24.80987 - diff: 15.52mlTrain batch 29/31 - 236.4ms/batch - loss: 24.73650 - diff: 15.45mlTrain batch 30/31 - 237.4ms/batch - loss: 24.89119 - diff: 15.52mlTrain batch 31/31 - 123.7ms/batch - loss: 25.22938 - diff: 15.48mlTrain batch 31/31 - 11.0s 123.7ms/batch - loss: 25.22938 - diff: 15.48ml
Test 1.2s: val_loss: 52.65531 - diff: 21.48ml

Epoch 131: current best loss = 52.29484, at epoch 124
Train batch 1/31 - 236.7ms/batch - loss: 34.53120 - diff: 20.63mlTrain batch 2/31 - 237.3ms/batch - loss: 26.72520 - diff: 16.35mlTrain batch 3/31 - 236.1ms/batch - loss: 23.67536 - diff: 15.40mlTrain batch 4/31 - 236.9ms/batch - loss: 23.19772 - diff: 15.00mlTrain batch 5/31 - 236.0ms/batch - loss: 24.45170 - diff: 15.11mlTrain batch 6/31 - 237.8ms/batch - loss: 22.76967 - diff: 14.51mlTrain batch 7/31 - 238.5ms/batch - loss: 21.48556 - diff: 14.18mlTrain batch 8/31 - 236.3ms/batch - loss: 21.91531 - diff: 14.51mlTrain batch 9/31 - 236.2ms/batch - loss: 21.31729 - diff: 14.44mlTrain batch 10/31 - 239.8ms/batch - loss: 22.03705 - diff: 14.52mlTrain batch 11/31 - 236.1ms/batch - loss: 23.16207 - diff: 15.01mlTrain batch 12/31 - 237.0ms/batch - loss: 22.50491 - diff: 14.82mlTrain batch 13/31 - 236.1ms/batch - loss: 22.56260 - diff: 14.93mlTrain batch 14/31 - 237.4ms/batch - loss: 22.84946 - diff: 15.16mlTrain batch 15/31 - 244.6ms/batch - loss: 22.16512 - diff: 14.96mlTrain batch 16/31 - 236.7ms/batch - loss: 22.16653 - diff: 15.01mlTrain batch 17/31 - 236.1ms/batch - loss: 22.55620 - diff: 15.07mlTrain batch 18/31 - 237.6ms/batch - loss: 22.67245 - diff: 15.14mlTrain batch 19/31 - 236.2ms/batch - loss: 23.23409 - diff: 15.29mlTrain batch 20/31 - 237.3ms/batch - loss: 24.01773 - diff: 15.47mlTrain batch 21/31 - 236.3ms/batch - loss: 24.85303 - diff: 15.54mlTrain batch 22/31 - 237.4ms/batch - loss: 24.95071 - diff: 15.59mlTrain batch 23/31 - 236.4ms/batch - loss: 24.68039 - diff: 15.53mlTrain batch 24/31 - 237.0ms/batch - loss: 24.53078 - diff: 15.51mlTrain batch 25/31 - 235.9ms/batch - loss: 23.90706 - diff: 15.26mlTrain batch 26/31 - 237.9ms/batch - loss: 23.61610 - diff: 15.17mlTrain batch 27/31 - 236.4ms/batch - loss: 23.65949 - diff: 15.21mlTrain batch 28/31 - 237.5ms/batch - loss: 23.85654 - diff: 15.30mlTrain batch 29/31 - 236.1ms/batch - loss: 23.60528 - diff: 15.25mlTrain batch 30/31 - 237.3ms/batch - loss: 23.64181 - diff: 15.30mlTrain batch 31/31 - 123.6ms/batch - loss: 24.26770 - diff: 15.33mlTrain batch 31/31 - 11.2s 123.6ms/batch - loss: 24.26770 - diff: 15.33ml
Test 1.2s: val_loss: 55.57069 - diff: 22.14ml

Epoch 132: current best loss = 52.29484, at epoch 124
Train batch 1/31 - 236.3ms/batch - loss: 56.17565 - diff: 20.79mlTrain batch 2/31 - 237.3ms/batch - loss: 38.26930 - diff: 17.53mlTrain batch 3/31 - 236.6ms/batch - loss: 56.54441 - diff: 21.10mlTrain batch 4/31 - 237.7ms/batch - loss: 47.28286 - diff: 19.60mlTrain batch 5/31 - 236.1ms/batch - loss: 41.48605 - diff: 18.42mlTrain batch 6/31 - 237.2ms/batch - loss: 39.70369 - diff: 18.10mlTrain batch 7/31 - 241.9ms/batch - loss: 38.23413 - diff: 17.89mlTrain batch 8/31 - 237.5ms/batch - loss: 36.13369 - diff: 17.44mlTrain batch 9/31 - 236.1ms/batch - loss: 34.80943 - diff: 17.26mlTrain batch 10/31 - 237.6ms/batch - loss: 32.54033 - diff: 16.68mlTrain batch 11/31 - 237.7ms/batch - loss: 33.63259 - diff: 17.06mlTrain batch 12/31 - 237.2ms/batch - loss: 33.12608 - diff: 17.04mlTrain batch 13/31 - 235.9ms/batch - loss: 32.44534 - diff: 16.87mlTrain batch 14/31 - 237.6ms/batch - loss: 32.08803 - diff: 16.83mlTrain batch 15/31 - 236.1ms/batch - loss: 31.21723 - diff: 16.68mlTrain batch 16/31 - 237.4ms/batch - loss: 31.70558 - diff: 16.92mlTrain batch 17/31 - 236.6ms/batch - loss: 31.16183 - diff: 16.78mlTrain batch 18/31 - 239.5ms/batch - loss: 30.20772 - diff: 16.51mlTrain batch 19/31 - 236.2ms/batch - loss: 29.94327 - diff: 16.44mlTrain batch 20/31 - 237.3ms/batch - loss: 29.39463 - diff: 16.39mlTrain batch 21/31 - 236.5ms/batch - loss: 28.57119 - diff: 16.16mlTrain batch 22/31 - 237.4ms/batch - loss: 28.36010 - diff: 16.15mlTrain batch 23/31 - 236.6ms/batch - loss: 31.38352 - diff: 16.91mlTrain batch 24/31 - 237.6ms/batch - loss: 31.36209 - diff: 16.84mlTrain batch 25/31 - 236.2ms/batch - loss: 30.97403 - diff: 16.74mlTrain batch 26/31 - 237.9ms/batch - loss: 30.55110 - diff: 16.61mlTrain batch 27/31 - 237.0ms/batch - loss: 30.10982 - diff: 16.46mlTrain batch 28/31 - 237.5ms/batch - loss: 29.40491 - diff: 16.26mlTrain batch 29/31 - 236.4ms/batch - loss: 29.06454 - diff: 16.21mlTrain batch 30/31 - 237.3ms/batch - loss: 29.06247 - diff: 16.29mlTrain batch 31/31 - 123.6ms/batch - loss: 29.35739 - diff: 16.25mlTrain batch 31/31 - 11.3s 123.6ms/batch - loss: 29.35739 - diff: 16.25ml
Test 1.2s: val_loss: 53.16187 - diff: 21.93ml

Epoch 133: current best loss = 52.29484, at epoch 124
Train batch 1/31 - 236.1ms/batch - loss: 16.95054 - diff: 13.27mlTrain batch 2/31 - 236.2ms/batch - loss: 22.37525 - diff: 13.75mlTrain batch 3/31 - 236.8ms/batch - loss: 26.18169 - diff: 15.40mlTrain batch 4/31 - 238.0ms/batch - loss: 22.64195 - diff: 14.21mlTrain batch 5/31 - 236.9ms/batch - loss: 36.70935 - diff: 17.01mlTrain batch 6/31 - 237.6ms/batch - loss: 33.67030 - diff: 16.21mlTrain batch 7/31 - 236.0ms/batch - loss: 31.67201 - diff: 15.93mlTrain batch 8/31 - 237.3ms/batch - loss: 29.64687 - diff: 15.57mlTrain batch 9/31 - 236.3ms/batch - loss: 29.96713 - diff: 15.78mlTrain batch 10/31 - 237.5ms/batch - loss: 28.13832 - diff: 15.31mlTrain batch 11/31 - 235.9ms/batch - loss: 28.49479 - diff: 15.59mlTrain batch 12/31 - 237.6ms/batch - loss: 29.32049 - diff: 15.94mlTrain batch 13/31 - 236.4ms/batch - loss: 28.36519 - diff: 15.66mlTrain batch 14/31 - 237.1ms/batch - loss: 28.93110 - diff: 15.86mlTrain batch 15/31 - 236.5ms/batch - loss: 28.57546 - diff: 15.83mlTrain batch 16/31 - 237.2ms/batch - loss: 27.66098 - diff: 15.56mlTrain batch 17/31 - 236.6ms/batch - loss: 27.84950 - diff: 15.60mlTrain batch 18/31 - 236.8ms/batch - loss: 27.48859 - diff: 15.57mlTrain batch 19/31 - 236.1ms/batch - loss: 26.99042 - diff: 15.54mlTrain batch 20/31 - 237.2ms/batch - loss: 27.37082 - diff: 15.64mlTrain batch 21/31 - 236.9ms/batch - loss: 27.01734 - diff: 15.56mlTrain batch 22/31 - 237.4ms/batch - loss: 26.26552 - diff: 15.32mlTrain batch 23/31 - 236.6ms/batch - loss: 26.18896 - diff: 15.36mlTrain batch 24/31 - 237.3ms/batch - loss: 25.56668 - diff: 15.19mlTrain batch 25/31 - 236.6ms/batch - loss: 25.45038 - diff: 15.19mlTrain batch 26/31 - 236.4ms/batch - loss: 25.50648 - diff: 15.23mlTrain batch 27/31 - 237.2ms/batch - loss: 26.02028 - diff: 15.39mlTrain batch 28/31 - 236.3ms/batch - loss: 27.46292 - diff: 15.73mlTrain batch 29/31 - 237.4ms/batch - loss: 27.39803 - diff: 15.73mlTrain batch 30/31 - 236.1ms/batch - loss: 28.53246 - diff: 16.00mlTrain batch 31/31 - 122.7ms/batch - loss: 34.00284 - diff: 16.48mlTrain batch 31/31 - 11.2s 122.7ms/batch - loss: 34.00284 - diff: 16.48ml
Test 1.2s: val_loss: 56.38779 - diff: 22.32ml

Epoch 134: current best loss = 52.29484, at epoch 124
Train batch 1/31 - 236.3ms/batch - loss: 24.95254 - diff: 16.63mlTrain batch 2/31 - 238.1ms/batch - loss: 21.14556 - diff: 14.96mlTrain batch 3/31 - 237.3ms/batch - loss: 26.11995 - diff: 16.39mlTrain batch 4/31 - 238.2ms/batch - loss: 26.58726 - diff: 16.48mlTrain batch 5/31 - 237.8ms/batch - loss: 25.16100 - diff: 15.96mlTrain batch 6/31 - 238.4ms/batch - loss: 23.82819 - diff: 15.51mlTrain batch 7/31 - 238.7ms/batch - loss: 24.54762 - diff: 15.95mlTrain batch 8/31 - 237.1ms/batch - loss: 24.19787 - diff: 15.86mlTrain batch 9/31 - 236.3ms/batch - loss: 25.75191 - diff: 16.39mlTrain batch 10/31 - 237.2ms/batch - loss: 24.87538 - diff: 16.12mlTrain batch 11/31 - 235.9ms/batch - loss: 25.06736 - diff: 16.01mlTrain batch 12/31 - 236.6ms/batch - loss: 24.18567 - diff: 15.77mlTrain batch 13/31 - 236.5ms/batch - loss: 24.78832 - diff: 15.98mlTrain batch 14/31 - 237.2ms/batch - loss: 25.06913 - diff: 16.13mlTrain batch 15/31 - 236.1ms/batch - loss: 25.48169 - diff: 16.26mlTrain batch 16/31 - 237.1ms/batch - loss: 25.38957 - diff: 16.18mlTrain batch 17/31 - 236.5ms/batch - loss: 25.45220 - diff: 16.31mlTrain batch 18/31 - 237.3ms/batch - loss: 26.53759 - diff: 16.39mlTrain batch 19/31 - 236.2ms/batch - loss: 26.63509 - diff: 16.41mlTrain batch 20/31 - 237.7ms/batch - loss: 26.13563 - diff: 16.25mlTrain batch 21/31 - 236.4ms/batch - loss: 27.22825 - diff: 16.65mlTrain batch 22/31 - 237.4ms/batch - loss: 27.39166 - diff: 16.65mlTrain batch 23/31 - 236.2ms/batch - loss: 27.45135 - diff: 16.68mlTrain batch 24/31 - 237.1ms/batch - loss: 27.07915 - diff: 16.54mlTrain batch 25/31 - 236.0ms/batch - loss: 26.58246 - diff: 16.40mlTrain batch 26/31 - 237.4ms/batch - loss: 26.20935 - diff: 16.31mlTrain batch 27/31 - 236.3ms/batch - loss: 25.84007 - diff: 16.24mlTrain batch 28/31 - 237.3ms/batch - loss: 25.70365 - diff: 16.21mlTrain batch 29/31 - 236.1ms/batch - loss: 25.97994 - diff: 16.31mlTrain batch 30/31 - 237.0ms/batch - loss: 25.60562 - diff: 16.17mlTrain batch 31/31 - 123.4ms/batch - loss: 26.33577 - diff: 16.22mlTrain batch 31/31 - 11.7s 123.4ms/batch - loss: 26.33577 - diff: 16.22ml
Test 1.2s: val_loss: 58.43470 - diff: 22.29ml

Epoch 135: current best loss = 52.29484, at epoch 124
Train batch 1/31 - 236.2ms/batch - loss: 27.79104 - diff: 16.06mlTrain batch 2/31 - 236.7ms/batch - loss: 32.81815 - diff: 16.25mlTrain batch 3/31 - 236.4ms/batch - loss: 33.92748 - diff: 17.12mlTrain batch 4/31 - 237.5ms/batch - loss: 34.19373 - diff: 18.08mlTrain batch 5/31 - 236.0ms/batch - loss: 36.49484 - diff: 19.05mlTrain batch 6/31 - 236.6ms/batch - loss: 33.31326 - diff: 18.06mlTrain batch 7/31 - 236.6ms/batch - loss: 32.34863 - diff: 17.89mlTrain batch 8/31 - 237.5ms/batch - loss: 31.48571 - diff: 17.58mlTrain batch 9/31 - 236.1ms/batch - loss: 29.68405 - diff: 16.82mlTrain batch 10/31 - 237.3ms/batch - loss: 28.94211 - diff: 16.53mlTrain batch 11/31 - 236.2ms/batch - loss: 28.22979 - diff: 16.29mlTrain batch 12/31 - 237.5ms/batch - loss: 27.98617 - diff: 16.29mlTrain batch 13/31 - 236.4ms/batch - loss: 27.33557 - diff: 16.22mlTrain batch 14/31 - 237.8ms/batch - loss: 27.24347 - diff: 16.16mlTrain batch 15/31 - 236.2ms/batch - loss: 27.02632 - diff: 16.07mlTrain batch 16/31 - 237.7ms/batch - loss: 26.64063 - diff: 16.05mlTrain batch 17/31 - 236.5ms/batch - loss: 26.53098 - diff: 16.07mlTrain batch 18/31 - 237.6ms/batch - loss: 25.44568 - diff: 15.68mlTrain batch 19/31 - 236.9ms/batch - loss: 25.11277 - diff: 15.59mlTrain batch 20/31 - 237.1ms/batch - loss: 24.94819 - diff: 15.56mlTrain batch 21/31 - 236.5ms/batch - loss: 24.53052 - diff: 15.43mlTrain batch 22/31 - 237.0ms/batch - loss: 24.32470 - diff: 15.36mlTrain batch 23/31 - 237.0ms/batch - loss: 26.41121 - diff: 15.97mlTrain batch 24/31 - 236.9ms/batch - loss: 26.20988 - diff: 15.96mlTrain batch 25/31 - 237.1ms/batch - loss: 26.00011 - diff: 15.88mlTrain batch 26/31 - 236.9ms/batch - loss: 25.69554 - diff: 15.81mlTrain batch 27/31 - 237.3ms/batch - loss: 25.49263 - diff: 15.66mlTrain batch 28/31 - 236.4ms/batch - loss: 25.08972 - diff: 15.54mlTrain batch 29/31 - 237.2ms/batch - loss: 24.78609 - diff: 15.50mlTrain batch 30/31 - 236.4ms/batch - loss: 24.52104 - diff: 15.41mlTrain batch 31/31 - 123.3ms/batch - loss: 24.50561 - diff: 15.32mlTrain batch 31/31 - 11.0s 123.3ms/batch - loss: 24.50561 - diff: 15.32ml
Test 1.2s: val_loss: 55.96779 - diff: 21.83ml
Epoch   136: reducing learning rate of group 0 to 3.1250e-05.

Epoch 136: current best loss = 52.29484, at epoch 124
Train batch 1/31 - 236.2ms/batch - loss: 19.73803 - diff: 14.13mlTrain batch 2/31 - 236.9ms/batch - loss: 19.52033 - diff: 14.65mlTrain batch 3/31 - 236.4ms/batch - loss: 20.16468 - diff: 14.23mlTrain batch 4/31 - 237.2ms/batch - loss: 24.13934 - diff: 15.42mlTrain batch 5/31 - 236.1ms/batch - loss: 22.21150 - diff: 14.66mlTrain batch 6/31 - 237.5ms/batch - loss: 23.42606 - diff: 15.15mlTrain batch 7/31 - 236.3ms/batch - loss: 22.78565 - diff: 14.79mlTrain batch 8/31 - 237.1ms/batch - loss: 23.57408 - diff: 15.08mlTrain batch 9/31 - 236.1ms/batch - loss: 22.11728 - diff: 14.56mlTrain batch 10/31 - 236.2ms/batch - loss: 21.11110 - diff: 14.22mlTrain batch 11/31 - 236.8ms/batch - loss: 21.72420 - diff: 14.45mlTrain batch 12/31 - 236.6ms/batch - loss: 22.64809 - diff: 14.78mlTrain batch 13/31 - 236.2ms/batch - loss: 22.47008 - diff: 14.77mlTrain batch 14/31 - 237.3ms/batch - loss: 21.91444 - diff: 14.48mlTrain batch 15/31 - 237.0ms/batch - loss: 22.28767 - diff: 14.60mlTrain batch 16/31 - 237.0ms/batch - loss: 21.79100 - diff: 14.33mlTrain batch 17/31 - 236.9ms/batch - loss: 21.03427 - diff: 14.05mlTrain batch 18/31 - 237.1ms/batch - loss: 21.09288 - diff: 13.99mlTrain batch 19/31 - 236.9ms/batch - loss: 20.58745 - diff: 13.80mlTrain batch 20/31 - 236.4ms/batch - loss: 20.75347 - diff: 13.90mlTrain batch 21/31 - 237.1ms/batch - loss: 21.47661 - diff: 14.15mlTrain batch 22/31 - 236.4ms/batch - loss: 23.31982 - diff: 14.63mlTrain batch 23/31 - 237.0ms/batch - loss: 22.81574 - diff: 14.44mlTrain batch 24/31 - 236.3ms/batch - loss: 23.37490 - diff: 14.68mlTrain batch 25/31 - 237.6ms/batch - loss: 22.93671 - diff: 14.50mlTrain batch 26/31 - 236.7ms/batch - loss: 22.93348 - diff: 14.50mlTrain batch 27/31 - 237.8ms/batch - loss: 22.58381 - diff: 14.42mlTrain batch 28/31 - 236.4ms/batch - loss: 22.35718 - diff: 14.40mlTrain batch 29/31 - 237.0ms/batch - loss: 22.73541 - diff: 14.53mlTrain batch 30/31 - 236.7ms/batch - loss: 25.11779 - diff: 14.81mlTrain batch 31/31 - 123.6ms/batch - loss: 26.21105 - diff: 14.97mlTrain batch 31/31 - 10.9s 123.6ms/batch - loss: 26.21105 - diff: 14.97ml
Test 1.1s: val_loss: 51.47063 - diff: 21.38ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_WideResNet50_0_Adam-0.001_MSE_DA3_best

Epoch 137: current best loss = 51.47063, at epoch 136
Train batch 1/31 - 236.2ms/batch - loss: 15.31248 - diff: 10.45mlTrain batch 2/31 - 237.0ms/batch - loss: 12.27645 - diff: 9.62mlTrain batch 3/31 - 236.1ms/batch - loss: 16.76880 - diff: 11.79mlTrain batch 4/31 - 236.8ms/batch - loss: 18.43001 - diff: 13.09mlTrain batch 5/31 - 236.5ms/batch - loss: 18.77968 - diff: 13.18mlTrain batch 6/31 - 237.5ms/batch - loss: 18.50601 - diff: 13.00mlTrain batch 7/31 - 236.2ms/batch - loss: 18.73021 - diff: 13.11mlTrain batch 8/31 - 237.2ms/batch - loss: 17.63419 - diff: 12.63mlTrain batch 9/31 - 236.2ms/batch - loss: 17.32938 - diff: 12.60mlTrain batch 10/31 - 237.6ms/batch - loss: 19.05066 - diff: 12.89mlTrain batch 11/31 - 236.0ms/batch - loss: 19.37215 - diff: 13.19mlTrain batch 12/31 - 237.6ms/batch - loss: 18.81841 - diff: 13.09mlTrain batch 13/31 - 236.4ms/batch - loss: 20.04658 - diff: 13.51mlTrain batch 14/31 - 237.0ms/batch - loss: 23.39386 - diff: 14.64mlTrain batch 15/31 - 236.2ms/batch - loss: 26.43575 - diff: 15.55mlTrain batch 16/31 - 237.5ms/batch - loss: 27.64651 - diff: 15.81mlTrain batch 17/31 - 236.3ms/batch - loss: 27.45400 - diff: 15.84mlTrain batch 18/31 - 237.3ms/batch - loss: 27.32022 - diff: 15.90mlTrain batch 19/31 - 236.6ms/batch - loss: 26.65745 - diff: 15.67mlTrain batch 20/31 - 237.5ms/batch - loss: 26.84818 - diff: 15.78mlTrain batch 21/31 - 236.5ms/batch - loss: 26.62343 - diff: 15.70mlTrain batch 22/31 - 237.5ms/batch - loss: 26.61502 - diff: 15.70mlTrain batch 23/31 - 236.4ms/batch - loss: 25.97425 - diff: 15.50mlTrain batch 24/31 - 237.6ms/batch - loss: 25.75458 - diff: 15.48mlTrain batch 25/31 - 236.9ms/batch - loss: 25.33084 - diff: 15.28mlTrain batch 26/31 - 237.7ms/batch - loss: 25.15645 - diff: 15.18mlTrain batch 27/31 - 236.5ms/batch - loss: 24.71250 - diff: 15.10mlTrain batch 28/31 - 237.5ms/batch - loss: 24.28441 - diff: 14.93mlTrain batch 29/31 - 236.5ms/batch - loss: 24.10978 - diff: 14.92mlTrain batch 30/31 - 237.4ms/batch - loss: 24.08287 - diff: 14.94mlTrain batch 31/31 - 123.9ms/batch - loss: 24.66066 - diff: 14.95mlTrain batch 31/31 - 11.0s 123.9ms/batch - loss: 24.66066 - diff: 14.95ml
Test 1.2s: val_loss: 50.68936 - diff: 21.25ml
Saving new best model in models/checkpoints/4CH_preproc1_150x150_bySlices_dataset_allViews_Diastole_WideResNet50_0_Adam-0.001_MSE_DA3_best

Epoch 138: current best loss = 50.68936, at epoch 137
Train batch 1/31 - 250.6ms/batch - loss: 20.11744 - diff: 13.77mlTrain batch 2/31 - 236.3ms/batch - loss: 22.50899 - diff: 15.85mlTrain batch 3/31 - 236.5ms/batch - loss: 22.29963 - diff: 15.22mlTrain batch 4/31 - 237.0ms/batch - loss: 24.32843 - diff: 15.67mlTrain batch 5/31 - 236.3ms/batch - loss: 22.82080 - diff: 15.10mlTrain batch 6/31 - 237.6ms/batch - loss: 24.07767 - diff: 15.24mlTrain batch 7/31 - 236.4ms/batch - loss: 24.86004 - diff: 15.46mlTrain batch 8/31 - 237.5ms/batch - loss: 23.49825 - diff: 14.86mlTrain batch 9/31 - 236.4ms/batch - loss: 23.08854 - diff: 14.96mlTrain batch 10/31 - 237.4ms/batch - loss: 27.22930 - diff: 15.92mlTrain batch 11/31 - 236.5ms/batch - loss: 27.67997 - diff: 16.08mlTrain batch 12/31 - 237.0ms/batch - loss: 30.37002 - diff: 16.98mlTrain batch 13/31 - 236.3ms/batch - loss: 29.91963 - diff: 16.95mlTrain batch 14/31 - 236.9ms/batch - loss: 28.86334 - diff: 16.65mlTrain batch 15/31 - 236.4ms/batch - loss: 28.16089 - diff: 16.44mlTrain batch 16/31 - 237.3ms/batch - loss: 27.36639 - diff: 16.28mlTrain batch 17/31 - 236.2ms/batch - loss: 26.64801 - diff: 16.12mlTrain batch 18/31 - 236.7ms/batch - loss: 26.64076 - diff: 16.19mlTrain batch 19/31 - 236.2ms/batch - loss: 25.75336 - diff: 15.79mlTrain batch 20/31 - 237.7ms/batch - loss: 25.45430 - diff: 15.67mlTrain batch 21/31 - 236.5ms/batch - loss: 25.84285 - diff: 15.88mlTrain batch 22/31 - 237.6ms/batch - loss: 27.48630 - diff: 16.36mlTrain batch 23/31 - 236.2ms/batch - loss: 27.35232 - diff: 16.44mlTrain batch 24/31 - 237.4ms/batch - loss: 26.61797 - diff: 16.21mlTrain batch 25/31 - 236.3ms/batch - loss: 27.94847 - diff: 16.58mlTrain batch 26/31 - 237.0ms/batch - loss: 27.19593 - diff: 16.30mlTrain batch 27/31 - 236.7ms/batch - loss: 26.79107 - diff: 16.16mlTrain batch 28/31 - 237.4ms/batch - loss: 27.14653 - diff: 16.16mlTrain batch 29/31 - 236.3ms/batch - loss: 27.34746 - diff: 16.19mlTrain batch 30/31 - 237.4ms/batch - loss: 26.80839 - diff: 15.99mlTrain batch 31/31 - 123.9ms/batch - loss: 27.72150 - diff: 16.02mlTrain batch 31/31 - 11.1s 123.9ms/batch - loss: 27.72150 - diff: 16.02ml
Test 1.2s: val_loss: 53.43420 - diff: 21.58ml

Epoch 139: current best loss = 50.68936, at epoch 137
Train batch 1/31 - 236.2ms/batch - loss: 23.90693 - diff: 16.57mlTrain batch 2/31 - 237.2ms/batch - loss: 22.95657 - diff: 15.62mlTrain batch 3/31 - 236.3ms/batch - loss: 20.07945 - diff: 14.57mlTrain batch 4/31 - 237.6ms/batch - loss: 17.82207 - diff: 13.76mlTrain batch 5/31 - 236.4ms/batch - loss: 20.99375 - diff: 14.69mlTrain batch 6/31 - 237.5ms/batch - loss: 22.54843 - diff: 15.33mlTrain batch 7/31 - 236.1ms/batch - loss: 23.46036 - diff: 15.47mlTrain batch 8/31 - 237.7ms/batch - loss: 22.72820 - diff: 15.36mlTrain batch 9/31 - 236.2ms/batch - loss: 22.66362 - diff: 15.09mlTrain batch 10/31 - 237.2ms/batch - loss: 22.50105 - diff: 14.88mlTrain batch 11/31 - 236.3ms/batch - loss: 21.39748 - diff: 14.57mlTrain batch 12/31 - 237.5ms/batch - loss: 25.10786 - diff: 15.46mlTrain batch 13/31 - 236.0ms/batch - loss: 24.03640 - diff: 15.10mlTrain batch 14/31 - 237.5ms/batch - loss: 27.29180 - diff: 16.10mlTrain batch 15/31 - 236.1ms/batch - loss: 27.28262 - diff: 16.23mlTrain batch 16/31 - 237.1ms/batch - loss: 27.23964 - diff: 16.25mlTrain batch 17/31 - 236.4ms/batch - loss: 28.34520 - diff: 16.54mlTrain batch 18/31 - 237.3ms/batch - loss: 28.42476 - diff: 16.60mlTrain batch 19/31 - 236.4ms/batch - loss: 28.74601 - diff: 16.72mlTrain batch 20/31 - 237.4ms/batch - loss: 27.73198 - diff: 16.39mlTrain batch 21/31 - 236.0ms/batch - loss: 27.32266 - diff: 16.25mlTrain batch 22/31 - 237.4ms/batch - loss: 27.25885 - diff: 16.19mlTrain batch 23/31 - 236.1ms/batch - loss: 27.31160 - diff: 16.18mlTrain batch 24/31 - 237.4ms/batch - loss: 27.24808 - diff: 16.19mlTrain batch 25/31 - 236.7ms/batch - loss: 27.33209 - diff: 16.24mlTrain batch 26/31 - 237.5ms/batch - loss: 26.91764 - diff: 16.09mlTrain batch 27/31 - 236.7ms/batch - loss: 26.98828 - diff: 16.17mlTrain batch 28/31 - 237.2ms/batch - loss: 26.47648 - diff: 16.00mlTrain batch 29/31 - 236.3ms/batch - loss: 26.38736 - diff: 15.94mlTrain batch 30/31 - 236.9ms/batch - loss: 26.06425 - diff: 15.88mlTrain batch 31/31 - 123.6ms/batch - loss: 26.16958 - diff: 15.83mlTrain batch 31/31 - 11.4s 123.6ms/batch - loss: 26.16958 - diff: 15.83ml
Test 1.2s: val_loss: 53.61906 - diff: 21.60ml

Epoch 140: current best loss = 50.68936, at epoch 137
Train batch 1/31 - 236.5ms/batch - loss: 18.93620 - diff: 13.58mlTrain batch 2/31 - 236.9ms/batch - loss: 16.50808 - diff: 13.42mlTrain batch 3/31 - 236.2ms/batch - loss: 14.90419 - diff: 12.39mlTrain batch 4/31 - 236.1ms/batch - loss: 14.67905 - diff: 12.21mlTrain batch 5/31 - 237.0ms/batch - loss: 14.88992 - diff: 12.33mlTrain batch 6/31 - 236.2ms/batch - loss: 13.86425 - diff: 11.76mlTrain batch 7/31 - 237.4ms/batch - loss: 13.25912 - diff: 11.51mlTrain batch 8/31 - 236.1ms/batch - loss: 17.40789 - diff: 12.77mlTrain batch 9/31 - 237.1ms/batch - loss: 17.20060 - diff: 12.74mlTrain batch 10/31 - 236.4ms/batch - loss: 17.57440 - diff: 13.13mlTrain batch 11/31 - 237.2ms/batch - loss: 16.96877 - diff: 12.93mlTrain batch 12/31 - 236.4ms/batch - loss: 17.02308 - diff: 12.83mlTrain batch 13/31 - 237.1ms/batch - loss: 16.33666 - diff: 12.56mlTrain batch 14/31 - 236.5ms/batch - loss: 17.54327 - diff: 12.82mlTrain batch 15/31 - 237.3ms/batch - loss: 17.79454 - diff: 12.91mlTrain batch 16/31 - 236.5ms/batch - loss: 18.07778 - diff: 13.02mlTrain batch 17/31 - 237.0ms/batch - loss: 18.52684 - diff: 13.15mlTrain batch 18/31 - 236.3ms/batch - loss: 18.03301 - diff: 13.00mlTrain batch 19/31 - 236.9ms/batch - loss: 17.91492 - diff: 13.02mlTrain batch 20/31 - 236.4ms/batch - loss: 17.90956 - diff: 13.06mlTrain batch 21/31 - 237.1ms/batch - loss: 18.09530 - diff: 13.08mlTrain batch 22/31 - 236.2ms/batch - loss: 18.35721 - diff: 13.13mlTrain batch 23/31 - 237.5ms/batch - loss: 18.45705 - diff: 13.24mlTrain batch 24/31 - 236.1ms/batch - loss: 18.82740 - diff: 13.38mlTrain batch 25/31 - 236.8ms/batch - loss: 18.74937 - diff: 13.40mlTrain batch 26/31 - 236.5ms/batch - loss: 18.59764 - diff: 13.38mlTrain batch 27/31 - 237.3ms/batch - loss: 18.78784 - diff: 13.50mlTrain batch 28/31 - 236.0ms/batch - loss: 18.38979 - diff: 13.34mlTrain batch 29/31 - 236.9ms/batch - loss: 18.38772 - diff: 13.38mlTrain batch 30/31 - 236.9ms/batch - loss: 18.27037 - diff: 13.34mlTrain batch 31/31 - 123.2ms/batch - loss: 18.57404 - diff: 13.35mlTrain batch 31/31 - 11.9s 123.2ms/batch - loss: 18.57404 - diff: 13.35ml
Test 1.2s: val_loss: 52.34605 - diff: 21.69ml

Epoch 141: current best loss = 50.68936, at epoch 137
Train batch 1/31 - 236.4ms/batch - loss: 16.34017 - diff: 13.09mlTrain batch 2/31 - 236.8ms/batch - loss: 20.90653 - diff: 14.03mlTrain batch 3/31 - 236.4ms/batch - loss: 20.29348 - diff: 13.66mlTrain batch 4/31 - 237.2ms/batch - loss: 30.05938 - diff: 14.43mlTrain batch 5/31 - 236.2ms/batch - loss: 27.01092 - diff: 14.03mlTrain batch 6/31 - 237.2ms/batch - loss: 25.87517 - diff: 14.02mlTrain batch 7/31 - 236.1ms/batch - loss: 23.40800 - diff: 13.42mlTrain batch 8/31 - 237.2ms/batch - loss: 22.45755 - diff: 13.39mlTrain batch 9/31 - 235.9ms/batch - loss: 23.52764 - diff: 13.83mlTrain batch 10/31 - 237.1ms/batch - loss: 22.62960 - diff: 13.74mlTrain batch 11/31 - 236.4ms/batch - loss: 21.53796 - diff: 13.42mlTrain batch 12/31 - 237.1ms/batch - loss: 22.24358 - diff: 13.87mlTrain batch 13/31 - 236.4ms/batch - loss: 22.80809 - diff: 14.28mlTrain batch 14/31 - 237.3ms/batch - loss: 23.47495 - diff: 14.38mlTrain batch 15/31 - 235.9ms/batch - loss: 23.28075 - diff: 14.44mlTrain batch 16/31 - 237.4ms/batch - loss: 23.79367 - diff: 14.57mlTrain batch 17/31 - 236.3ms/batch - loss: 23.31951 - diff: 14.44mlTrain batch 18/31 - 237.0ms/batch - loss: 23.43951 - diff: 14.60mlTrain batch 19/31 - 247.2ms/batch - loss: 24.53570 - diff: 14.89mlTrain batch 20/31 - 237.3ms/batch - loss: 24.22968 - diff: 14.82mlTrain batch 21/31 - 236.2ms/batch - loss: 24.25732 - diff: 14.87mlTrain batch 22/31 - 236.8ms/batch - loss: 24.07411 - diff: 14.88mlTrain batch 23/31 - 236.8ms/batch - loss: 23.75379 - diff: 14.78mlTrain batch 24/31 - 237.3ms/batch - loss: 23.23559 - diff: 14.59mlTrain batch 25/31 - 236.3ms/batch - loss: 22.83075 - diff: 14.44mlTrain batch 26/31 - 237.6ms/batch - loss: 22.46008 - diff: 14.34mlTrain batch 27/31 - 236.5ms/batch - loss: 22.87524 - diff: 14.52mlTrain batch 28/31 - 237.6ms/batch - loss: 22.61814 - diff: 14.45mlTrain batch 29/31 - 236.4ms/batch - loss: 23.06130 - diff: 14.49mlTrain batch 30/31 - 237.8ms/batch - loss: 23.96880 - diff: 14.86mlTrain batch 31/31 - 123.5ms/batch - loss: 24.24605 - diff: 14.84mlTrain batch 31/31 - 11.4s 123.5ms/batch - loss: 24.24605 - diff: 14.84ml
Test 1.2s: val_loss: 51.90159 - diff: 21.49ml

Epoch 142: current best loss = 50.68936, at epoch 137
Train batch 1/31 - 236.0ms/batch - loss: 14.17662 - diff: 12.02mlTrain batch 2/31 - 237.4ms/batch - loss: 16.57065 - diff: 13.66mlTrain batch 3/31 - 236.3ms/batch - loss: 17.79065 - diff: 13.86mlTrain batch 4/31 - 236.9ms/batch - loss: 18.34270 - diff: 13.74mlTrain batch 5/31 - 236.4ms/batch - loss: 16.10038 - diff: 12.53mlTrain batch 6/31 - 237.0ms/batch - loss: 17.60550 - diff: 13.20mlTrain batch 7/31 - 236.3ms/batch - loss: 16.60702 - diff: 12.81mlTrain batch 8/31 - 237.0ms/batch - loss: 16.04072 - diff: 12.67mlTrain batch 9/31 - 236.7ms/batch - loss: 15.46937 - diff: 12.39mlTrain batch 10/31 - 236.4ms/batch - loss: 15.06019 - diff: 12.25mlTrain batch 11/31 - 236.2ms/batch - loss: 15.26766 - diff: 12.37mlTrain batch 12/31 - 237.1ms/batch - loss: 15.98878 - diff: 12.55mlTrain batch 13/31 - 236.6ms/batch - loss: 15.86973 - diff: 12.58mlTrain batch 14/31 - 237.2ms/batch - loss: 15.96826 - diff: 12.58mlTrain batch 15/31 - 236.4ms/batch - loss: 15.76645 - diff: 12.47mlTrain batch 16/31 - 237.7ms/batch - loss: 16.05199 - diff: 12.58mlTrain batch 17/31 - 236.4ms/batch - loss: 15.86368 - diff: 12.50mlTrain batch 18/31 - 237.6ms/batch - loss: 15.78897 - diff: 12.50mlTrain batch 19/31 - 236.1ms/batch - loss: 17.01012 - diff: 12.84mlTrain batch 20/31 - 236.6ms/batch - loss: 17.36999 - diff: 12.92mlTrain batch 21/31 - 236.5ms/batch - loss: 17.65754 - diff: 13.10mlTrain batch 22/31 - 237.2ms/batch - loss: 17.73424 - diff: 13.15mlTrain batch 23/31 - 238.8ms/batch - loss: 18.28349 - diff: 13.41mlTrain batch 24/31 - 237.1ms/batch - loss: 18.68164 - diff: 13.53mlTrain batch 25/31 - 236.3ms/batch - loss: 18.89492 - diff: 13.60mlTrain batch 26/31 - 237.4ms/batch - loss: 20.95398 - diff: 14.17mlTrain batch 27/31 - 236.3ms/batch - loss: 21.00908 - diff: 14.11mlTrain batch 28/31 - 237.0ms/batch - loss: 21.88790 - diff: 14.40mlTrain batch 29/31 - 236.3ms/batch - loss: 21.64685 - diff: 14.38mlTrain batch 30/31 - 237.0ms/batch - loss: 21.88619 - diff: 14.46mlTrain batch 31/31 - 123.7ms/batch - loss: 22.33153 - diff: 14.47mlTrain batch 31/31 - 11.7s 123.7ms/batch - loss: 22.33153 - diff: 14.47ml
Test 1.1s: val_loss: 56.18027 - diff: 21.60ml

Epoch 143: current best loss = 50.68936, at epoch 137
Train batch 1/31 - 236.1ms/batch - loss: 28.61899 - diff: 16.40mlTrain batch 2/31 - 237.2ms/batch - loss: 21.68657 - diff: 14.25mlTrain batch 3/31 - 236.5ms/batch - loss: 19.38849 - diff: 13.49mlTrain batch 4/31 - 237.5ms/batch - loss: 18.85922 - diff: 13.59mlTrain batch 5/31 - 236.4ms/batch - loss: 18.34711 - diff: 13.32mlTrain batch 6/31 - 237.0ms/batch - loss: 18.31471 - diff: 13.30mlTrain batch 7/31 - 236.1ms/batch - loss: 18.37527 - diff: 13.30mlTrain batch 8/31 - 236.6ms/batch - loss: 18.82829 - diff: 13.68mlTrain batch 9/31 - 236.3ms/batch - loss: 21.51945 - diff: 14.49mlTrain batch 10/31 - 237.2ms/batch - loss: 21.61830 - diff: 14.66mlTrain batch 11/31 - 236.2ms/batch - loss: 23.28930 - diff: 15.05mlTrain batch 12/31 - 237.0ms/batch - loss: 22.37696 - diff: 14.75mlTrain batch 13/31 - 235.8ms/batch - loss: 21.52115 - diff: 14.38mlTrain batch 14/31 - 237.4ms/batch - loss: 20.90072 - diff: 14.18mlTrain batch 15/31 - 236.4ms/batch - loss: 20.60377 - diff: 14.13mlTrain batch 16/31 - 237.4ms/batch - loss: 21.13743 - diff: 14.35mlTrain batch 17/31 - 236.3ms/batch - loss: 20.51611 - diff: 14.16mlTrain batch 18/31 - 237.0ms/batch - loss: 20.44150 - diff: 14.21mlTrain batch 19/31 - 236.3ms/batch - loss: 20.84677 - diff: 14.37mlTrain batch 20/31 - 237.1ms/batch - loss: 21.12438 - diff: 14.39mlTrain batch 21/31 - 236.2ms/batch - loss: 21.28972 - diff: 14.45mlTrain batch 22/31 - 237.1ms/batch - loss: 21.39834 - diff: 14.56mlTrain batch 23/31 - 236.4ms/batch - loss: 20.78489 - diff: 14.33mlTrain batch 24/31 - 236.9ms/batch - loss: 20.78769 - diff: 14.40mlTrain batch 25/31 - 236.4ms/batch - loss: 20.72902 - diff: 14.40mlTrain batch 26/31 - 237.1ms/batch - loss: 20.45783 - diff: 14.29mlTrain batch 27/31 - 236.3ms/batch - loss: 20.81969 - diff: 14.38mlTrain batch 28/31 - 236.9ms/batch - loss: 20.65651 - diff: 14.34mlTrain batch 29/31 - 236.1ms/batch - loss: 20.73653 - diff: 14.37mlTrain batch 30/31 - 237.1ms/batch - loss: 21.08158 - diff: 14.52mlTrain batch 31/31 - 123.7ms/batch - loss: 20.93425 - diff: 14.41mlTrain batch 31/31 - 11.7s 123.7ms/batch - loss: 20.93425 - diff: 14.41ml
Test 1.2s: val_loss: 72.58480 - diff: 22.09ml

Epoch 144: current best loss = 50.68936, at epoch 137
Train batch 1/31 - 236.1ms/batch - loss: 5.67832 - diff: 7.05mlTrain batch 2/31 - 237.8ms/batch - loss: 10.60437 - diff: 9.93mlTrain batch 3/31 - 236.3ms/batch - loss: 14.61427 - diff: 10.84mlTrain batch 4/31 - 237.4ms/batch - loss: 19.92845 - diff: 12.82mlTrain batch 5/31 - 236.0ms/batch - loss: 21.47781 - diff: 13.83mlTrain batch 6/31 - 237.3ms/batch - loss: 21.31860 - diff: 14.22mlTrain batch 7/31 - 236.2ms/batch - loss: 21.01674 - diff: 13.97mlTrain batch 8/31 - 237.0ms/batch - loss: 20.59514 - diff: 13.88mlTrain batch 9/31 - 236.2ms/batch - loss: 19.61218 - diff: 13.51mlTrain batch 10/31 - 237.2ms/batch - loss: 19.86652 - diff: 13.57mlTrain batch 11/31 - 236.6ms/batch - loss: 19.64568 - diff: 13.53mlTrain batch 12/31 - 237.5ms/batch - loss: 20.44051 - diff: 13.90mlTrain batch 13/31 - 236.1ms/batch - loss: 20.84451 - diff: 13.97mlTrain batch 14/31 - 237.3ms/batch - loss: 21.03436 - diff: 14.05mlTrain batch 15/31 - 236.3ms/batch - loss: 20.35080 - diff: 13.83mlTrain batch 16/31 - 237.0ms/batch - loss: 21.69609 - diff: 14.44mlTrain batch 17/31 - 236.5ms/batch - loss: 20.97783 - diff: 14.21mlTrain batch 18/31 - 237.1ms/batch - loss: 20.29351 - diff: 13.95mlTrain batch 19/31 - 236.1ms/batch - loss: 20.55163 - diff: 14.07mlTrain batch 20/31 - 237.7ms/batch - loss: 20.53558 - diff: 14.12mlTrain batch 21/31 - 236.2ms/batch - loss: 20.51337 - diff: 14.17mlTrain batch 22/31 - 237.3ms/batch - loss: 20.27678 - diff: 14.02mlTrain batch 23/31 - 236.5ms/batch - loss: 20.93071 - diff: 14.21mlTrain batch 24/31 - 237.2ms/batch - loss: 20.35593 - diff: 13.98mlTrain batch 25/31 - 236.5ms/batch - loss: 20.51354 - diff: 14.00mlTrain batch 26/31 - 237.2ms/batch - loss: 20.17584 - diff: 13.85mlTrain batch 27/31 - 236.2ms/batch - loss: 20.04449 - diff: 13.85mlTrain batch 28/31 - 237.4ms/batch - loss: 19.78060 - diff: 13.74mlTrain batch 29/31 - 236.8ms/batch - loss: 20.57822 - diff: 13.99mlTrain batch 30/31 - 237.5ms/batch - loss: 20.71948 - diff: 14.10mlTrain batch 31/31 - 123.8ms/batch - loss: 21.16787 - diff: 14.09mlTrain batch 31/31 - 11.2s 123.8ms/batch - loss: 21.16787 - diff: 14.09ml
Test 1.2s: val_loss: 55.55379 - diff: 22.20ml

Epoch 145: current best loss = 50.68936, at epoch 137
Train batch 1/31 - 236.3ms/batch - loss: 10.48352 - diff: 10.16mlTrain batch 2/31 - 237.1ms/batch - loss: 12.80054 - diff: 10.85mlTrain batch 3/31 - 236.1ms/batch - loss: 14.97504 - diff: 11.86mlTrain batch 4/31 - 237.3ms/batch - loss: 14.97308 - diff: 12.02mlTrain batch 5/31 - 236.4ms/batch - loss: 17.75041 - diff: 12.76mlTrain batch 6/31 - 236.3ms/batch - loss: 20.94527 - diff: 13.94mlTrain batch 7/31 - 237.7ms/batch - loss: 20.56612 - diff: 13.72mlTrain batch 8/31 - 236.1ms/batch - loss: 20.46936 - diff: 13.56mlTrain batch 9/31 - 237.2ms/batch - loss: 20.24931 - diff: 13.63mlTrain batch 10/31 - 236.1ms/batch - loss: 20.72594 - diff: 13.93mlTrain batch 11/31 - 237.5ms/batch - loss: 20.75426 - diff: 13.98mlTrain batch 12/31 - 236.5ms/batch - loss: 21.32844 - diff: 13.91mlTrain batch 13/31 - 237.1ms/batch - loss: 25.30828 - diff: 14.82mlTrain batch 14/31 - 235.7ms/batch - loss: 25.30355 - diff: 14.76mlTrain batch 15/31 - 237.4ms/batch - loss: 25.07916 - diff: 14.77mlTrain batch 16/31 - 237.3ms/batch - loss: 24.07293 - diff: 14.45mlTrain batch 17/31 - 237.3ms/batch - loss: 23.73408 - diff: 14.41mlTrain batch 18/31 - 237.0ms/batch - loss: 24.18719 - diff: 14.51mlTrain batch 19/31 - 237.6ms/batch - loss: 23.88138 - diff: 14.41mlTrain batch 20/31 - 236.8ms/batch - loss: 23.23039 - diff: 14.24mlTrain batch 21/31 - 237.2ms/batch - loss: 23.62931 - diff: 14.39mlTrain batch 22/31 - 236.4ms/batch - loss: 23.41213 - diff: 14.36mlTrain batch 23/31 - 237.0ms/batch - loss: 23.34232 - diff: 14.35mlTrain batch 24/31 - 236.7ms/batch - loss: 24.75012 - diff: 14.75mlTrain batch 25/31 - 237.7ms/batch - loss: 24.21336 - diff: 14.59mlTrain batch 26/31 - 236.3ms/batch - loss: 24.06057 - diff: 14.62mlTrain batch 27/31 - 236.8ms/batch - loss: 23.53289 - diff: 14.41mlTrain batch 28/31 - 236.0ms/batch - loss: 23.32987 - diff: 14.31mlTrain batch 29/31 - 237.8ms/batch - loss: 22.96562 - diff: 14.19mlTrain batch 30/31 - 236.3ms/batch - loss: 22.80844 - diff: 14.20mlTrain batch 31/31 - 123.6ms/batch - loss: 22.82348 - diff: 14.09mlTrain batch 31/31 - 11.1s 123.6ms/batch - loss: 22.82348 - diff: 14.09ml
Test 1.1s: val_loss: 58.26093 - diff: 21.70ml

Epoch 146: current best loss = 50.68936, at epoch 137
Train batch 1/31 - 236.4ms/batch - loss: 29.73436 - diff: 18.50mlTrain batch 2/31 - 236.9ms/batch - loss: 32.82430 - diff: 17.81mlTrain batch 3/31 - 236.6ms/batch - loss: 34.75417 - diff: 18.33mlTrain batch 4/31 - 237.3ms/batch - loss: 30.46837 - diff: 17.36mlTrain batch 5/31 - 236.2ms/batch - loss: 31.30845 - diff: 17.65mlTrain batch 6/31 - 236.2ms/batch - loss: 29.33164 - diff: 17.16mlTrain batch 7/31 - 237.2ms/batch - loss: 26.69444 - diff: 16.18mlTrain batch 8/31 - 236.5ms/batch - loss: 25.38099 - diff: 15.92mlTrain batch 9/31 - 237.5ms/batch - loss: 23.68504 - diff: 15.32mlTrain batch 10/31 - 236.3ms/batch - loss: 23.35106 - diff: 15.26mlTrain batch 11/31 - 236.6ms/batch - loss: 22.67686 - diff: 15.09mlTrain batch 12/31 - 236.4ms/batch - loss: 23.74814 - diff: 15.48mlTrain batch 13/31 - 237.5ms/batch - loss: 23.19597 - diff: 15.27mlTrain batch 14/31 - 236.1ms/batch - loss: 22.50040 - diff: 14.97mlTrain batch 15/31 - 236.9ms/batch - loss: 22.10411 - diff: 14.81mlTrain batch 16/31 - 236.7ms/batch - loss: 22.75073 - diff: 15.03mlTrain batch 17/31 - 240.7ms/batch - loss: 23.16117 - diff: 15.20mlTrain batch 18/31 - 236.7ms/batch - loss: 22.85173 - diff: 15.18mlTrain batch 19/31 - 237.4ms/batch - loss: 22.44845 - diff: 15.09mlTrain batch 20/31 - 236.4ms/batch - loss: 22.87404 - diff: 15.23mlTrain batch 21/31 - 237.7ms/batch - loss: 22.77223 - diff: 15.19mlTrain batch 22/31 - 236.6ms/batch - loss: 22.76587 - diff: 15.19mlTrain batch 23/31 - 237.3ms/batch - loss: 22.37310 - diff: 15.07mlTrain batch 24/31 - 236.2ms/batch - loss: 22.86034 - diff: 15.17mlTrain batch 25/31 - 237.5ms/batch - loss: 22.51817 - diff: 15.02mlTrain batch 26/31 - 237.1ms/batch - loss: 22.87541 - diff: 15.15mlTrain batch 27/31 - 237.0ms/batch - loss: 23.29117 - diff: 15.10mlTrain batch 28/31 - 236.3ms/batch - loss: 22.70803 - diff: 14.83mlTrain batch 29/31 - 236.2ms/batch - loss: 22.94596 - diff: 14.93mlTrain batch 30/31 - 237.4ms/batch - loss: 22.98540 - diff: 14.97mlTrain batch 31/31 - 123.7ms/batch - loss: 22.79648 - diff: 14.86mlTrain batch 31/31 - 11.3s 123.7ms/batch - loss: 22.79648 - diff: 14.86ml
Test 1.2s: val_loss: 54.35924 - diff: 22.01ml

Epoch 147: current best loss = 50.68936, at epoch 137
Train batch 1/31 - 236.2ms/batch - loss: 33.89921 - diff: 18.37mlTrain batch 2/31 - 237.6ms/batch - loss: 27.69660 - diff: 16.86mlTrain batch 3/31 - 236.1ms/batch - loss: 31.04421 - diff: 17.60mlTrain batch 4/31 - 237.2ms/batch - loss: 28.26149 - diff: 16.55mlTrain batch 5/31 - 236.0ms/batch - loss: 29.33833 - diff: 16.38mlTrain batch 6/31 - 237.7ms/batch - loss: 25.89035 - diff: 15.22mlTrain batch 7/31 - 236.3ms/batch - loss: 25.85300 - diff: 15.36mlTrain batch 8/31 - 237.4ms/batch - loss: 23.69037 - diff: 14.79mlTrain batch 9/31 - 236.2ms/batch - loss: 23.26280 - diff: 14.76mlTrain batch 10/31 - 237.4ms/batch - loss: 23.05566 - diff: 14.65mlTrain batch 11/31 - 236.1ms/batch - loss: 23.05499 - diff: 14.68mlTrain batch 12/31 - 236.9ms/batch - loss: 22.23066 - diff: 14.38mlTrain batch 13/31 - 236.6ms/batch - loss: 21.68503 - diff: 14.27mlTrain batch 14/31 - 237.5ms/batch - loss: 21.65239 - diff: 14.28mlTrain batch 15/31 - 236.6ms/batch - loss: 21.84144 - diff: 14.37mlTrain batch 16/31 - 237.3ms/batch - loss: 22.70786 - diff: 14.57mlTrain batch 17/31 - 236.3ms/batch - loss: 22.04694 - diff: 14.34mlTrain batch 18/31 - 237.3ms/batch - loss: 21.94929 - diff: 14.41mlTrain batch 19/31 - 236.3ms/batch - loss: 21.95270 - diff: 14.33mlTrain batch 20/31 - 237.5ms/batch - loss: 21.41452 - diff: 14.19mlTrain batch 21/31 - 236.4ms/batch - loss: 21.17511 - diff: 14.14mlTrain batch 22/31 - 237.7ms/batch - loss: 21.24094 - diff: 14.17mlTrain batch 23/31 - 236.4ms/batch - loss: 21.10741 - diff: 14.19mlTrain batch 24/31 - 237.5ms/batch - loss: 20.90145 - diff: 14.17mlTrain batch 25/31 - 236.1ms/batch - loss: 20.79692 - diff: 14.16mlTrain batch 26/31 - 237.5ms/batch - loss: 21.08565 - diff: 14.25mlTrain batch 27/31 - 236.6ms/batch - loss: 21.01091 - diff: 14.14mlTrain batch 28/31 - 237.7ms/batch - loss: 21.15136 - diff: 14.20mlTrain batch 29/31 - 236.5ms/batch - loss: 21.57070 - diff: 14.24mlTrain batch 30/31 - 237.7ms/batch - loss: 21.56726 - diff: 14.24mlTrain batch 31/31 - 123.7ms/batch - loss: 21.69217 - diff: 14.20mlTrain batch 31/31 - 11.3s 123.7ms/batch - loss: 21.69217 - diff: 14.20ml
Test 1.2s: val_loss: 54.49069 - diff: 22.25ml

Epoch 148: current best loss = 50.68936, at epoch 137
Train batch 1/31 - 236.5ms/batch - loss: 31.41894 - diff: 18.48mlTrain batch 2/31 - 237.9ms/batch - loss: 22.67762 - diff: 14.79mlTrain batch 3/31 - 236.3ms/batch - loss: 23.68188 - diff: 14.96mlTrain batch 4/31 - 237.4ms/batch - loss: 22.84685 - diff: 15.01mlTrain batch 5/31 - 236.3ms/batch - loss: 20.97409 - diff: 14.48mlTrain batch 6/31 - 237.3ms/batch - loss: 20.10638 - diff: 14.12mlTrain batch 7/31 - 236.4ms/batch - loss: 19.41379 - diff: 13.89mlTrain batch 8/31 - 237.0ms/batch - loss: 19.64364 - diff: 14.19mlTrain batch 9/31 - 236.6ms/batch - loss: 22.86345 - diff: 15.13mlTrain batch 10/31 - 236.9ms/batch - loss: 22.23102 - diff: 14.99mlTrain batch 11/31 - 236.2ms/batch - loss: 21.49547 - diff: 14.76mlTrain batch 12/31 - 237.1ms/batch - loss: 21.21406 - diff: 14.64mlTrain batch 13/31 - 236.2ms/batch - loss: 20.93739 - diff: 14.57mlTrain batch 14/31 - 237.7ms/batch - loss: 21.21765 - diff: 14.57mlTrain batch 15/31 - 236.6ms/batch - loss: 21.73123 - diff: 14.77mlTrain batch 16/31 - 237.3ms/batch - loss: 21.25485 - diff: 14.54mlTrain batch 17/31 - 236.0ms/batch - loss: 21.76633 - diff: 14.73mlTrain batch 18/31 - 237.4ms/batch - loss: 21.25324 - diff: 14.60mlTrain batch 19/31 - 236.8ms/batch - loss: 20.73876 - diff: 14.39mlTrain batch 20/31 - 237.4ms/batch - loss: 21.48221 - diff: 14.57mlTrain batch 21/31 - 236.9ms/batch - loss: 21.89052 - diff: 14.72mlTrain batch 22/31 - 237.9ms/batch - loss: 22.19957 - diff: 14.91mlTrain batch 23/31 - 236.6ms/batch - loss: 21.64881 - diff: 14.68mlTrain batch 24/31 - 237.7ms/batch - loss: 21.61195 - diff: 14.68mlTrain batch 25/31 - 236.4ms/batch - loss: 21.65238 - diff: 14.66mlTrain batch 26/31 - 237.2ms/batch - loss: 21.42673 - diff: 14.60mlTrain batch 27/31 - 236.4ms/batch - loss: 20.99779 - diff: 14.40mlTrain batch 28/31 - 237.6ms/batch - loss: 21.27349 - diff: 14.51mlTrain batch 29/31 - 236.9ms/batch - loss: 21.96336 - diff: 14.77mlTrain batch 30/31 - 237.4ms/batch - loss: 21.82039 - diff: 14.71mlTrain batch 31/31 - 123.6ms/batch - loss: 21.98847 - diff: 14.68mlTrain batch 31/31 - 11.4s 123.6ms/batch - loss: 21.98847 - diff: 14.68ml
Test 1.1s: val_loss: 54.53507 - diff: 21.72ml
Epoch   149: reducing learning rate of group 0 to 1.5625e-05.

Epoch 149: current best loss = 50.68936, at epoch 137
Train batch 1/31 - 236.5ms/batch - loss: 34.39162 - diff: 17.65mlTrain batch 2/31 - 237.0ms/batch - loss: 24.65648 - diff: 15.54mlTrain batch 3/31 - 236.1ms/batch - loss: 20.18561 - diff: 13.98mlTrain batch 4/31 - 236.7ms/batch - loss: 20.01614 - diff: 14.30mlTrain batch 5/31 - 236.2ms/batch - loss: 22.56323 - diff: 14.70mlTrain batch 6/31 - 236.5ms/batch - loss: 23.60153 - diff: 14.87mlTrain batch 7/31 - 236.0ms/batch - loss: 22.00596 - diff: 14.41mlTrain batch 8/31 - 237.3ms/batch - loss: 20.92721 - diff: 13.95mlTrain batch 9/31 - 236.3ms/batch - loss: 19.82238 - diff: 13.54mlTrain batch 10/31 - 237.4ms/batch - loss: 19.25616 - diff: 13.47mlTrain batch 11/31 - 236.6ms/batch - loss: 19.88660 - diff: 13.87mlTrain batch 12/31 - 237.0ms/batch - loss: 20.42183 - diff: 14.06mlTrain batch 13/31 - 236.1ms/batch - loss: 19.93903 - diff: 13.88mlTrain batch 14/31 - 237.3ms/batch - loss: 20.69562 - diff: 13.92mlTrain batch 15/31 - 236.8ms/batch - loss: 25.26512 - diff: 15.11mlTrain batch 16/31 - 237.2ms/batch - loss: 24.76361 - diff: 14.98mlTrain batch 17/31 - 236.4ms/batch - loss: 23.99277 - diff: 14.80mlTrain batch 18/31 - 236.8ms/batch - loss: 23.81004 - diff: 14.82mlTrain batch 19/31 - 236.3ms/batch - loss: 23.52240 - diff: 14.76mlTrain batch 20/31 - 237.1ms/batch - loss: 22.89822 - diff: 14.59mlTrain batch 21/31 - 236.4ms/batch - loss: 22.56385 - diff: 14.55mlTrain batch 22/31 - 237.0ms/batch - loss: 21.82720 - diff: 14.24mlTrain batch 23/31 - 236.2ms/batch - loss: 22.17586 - diff: 14.41mlTrain batch 24/31 - 237.5ms/batch - loss: 22.72237 - diff: 14.63mlTrain batch 25/31 - 236.1ms/batch - loss: 22.26334 - diff: 14.49mlTrain batch 26/31 - 236.3ms/batch - loss: 22.51091 - diff: 14.60mlTrain batch 27/31 - 236.1ms/batch - loss: 22.76961 - diff: 14.74mlTrain batch 28/31 - 237.8ms/batch - loss: 22.39049 - diff: 14.57mlTrain batch 29/31 - 236.2ms/batch - loss: 22.10502 - diff: 14.50mlTrain batch 30/31 - 237.6ms/batch - loss: 21.91721 - diff: 14.41mlTrain batch 31/31 - 123.9ms/batch - loss: 22.79597 - diff: 14.50mlTrain batch 31/31 - 12.1s 123.9ms/batch - loss: 22.79597 - diff: 14.50ml
Test 1.2s: val_loss: 54.52660 - diff: 22.07ml

